Summary,Issue key,Issue id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Component/s,Component/s,Component/s,Due Date,Votes,Labels,Labels,Description,Environment,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Original Estimate,Remaining Estimate,Time Spent,Work Ratio,Σ Original Estimate,Σ Remaining Estimate,Σ Time Spent,Security Level,Outward issue link (Blocker),Inward issue link (Child-Issue),Inward issue link (Child-Issue),Outward issue link (Child-Issue),Outward issue link (Child-Issue),Inward issue link (Completes),Outward issue link (Completes),Outward issue link (Dependency),Inward issue link (Duplicate),Inward issue link (Duplicate),Outward issue link (Duplicate),Inward issue link (Problem/Incident),Outward issue link (Problem/Incident),Inward issue link (Reference),Inward issue link (Reference),Inward issue link (Reference),Inward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Supercedes),Inward issue link (Testing),Outward issue link (Testing),Outward issue link (Testing),Inward issue link (dependent),Outward issue link (dependent),Attachment,Attachment,Attachment,Attachment,Custom field (Affects version (Component)),Custom field (Attachment count),Custom field (Authors),Custom field (Authors),Custom field (Authors),Custom field (Blog - New Blog Administrators),Custom field (Blog - New Blog PMC),Custom field (Blog - Write access),Custom field (Blog Administrator?),Custom field (Blogs - Admin for blog),Custom field (Blogs - Email Address),Custom field (Blogs - Existing Blog Access Level),Custom field (Blogs - Existing Blog Name),Custom field (Blogs - New Blog Write Access),Custom field (Blogs - Username),Custom field (Bug Category),Custom field (Bugzilla - Email Notification Address),Custom field (Bugzilla - List of usernames),Custom field (Bugzilla - PMC Name),Custom field (Bugzilla - Project Name),Custom field (Bugzilla Id),Custom field (Bugzilla Id),Custom field (Change Category),Custom field (Complexity),Custom field (Discovered By),Custom field (Docs Text),Custom field (Enable Automatic Patch Review),Custom field (Epic Link),Custom field (Estimated Complexity),Custom field (Evidence Of Open Source Adoption),Custom field (Evidence Of Registration),Custom field (Evidence Of Use On World Wide Web),Custom field (Existing GitBox Approval),Custom field (External issue ID),Custom field (External issue URL),Custom field (Fix version (Component)),Custom field (Git Notification Mailing List),Custom field (Git Repository Import Path),Custom field (Git Repository Name),Custom field (Git Repository Type),Custom field (GitHub Options),Custom field (Github Integration),Custom field (Github Integrations - Other),Custom field (Global Rank),Custom field (INFRA - Subversion Repository Path),Custom field (Impacts),Custom field (Initial Confluence Contributors),Custom field (Last public comment date),Custom field (Level of effort),Custom field (Machine Readable Info),Custom field (Mentor),Custom field (New-TLP-TLPName),Custom field (Original story points),Custom field (Parent Link),Custom field (Platform),Custom field (Priority),Custom field (Project),Custom field (Protected Branch),Custom field (Rank),Custom field (Rank (Obsolete)),Custom field (Review Date),Custom field (Reviewer),Custom field (Reviewer),Custom field (Reviewers),Custom field (Reviewers),Custom field (Reviewers),Custom field (Reviewers),Custom field (Severity),Custom field (Severity),Custom field (Since Version),Custom field (Skill Level),Custom field (Source Control Link),Custom field (Space Description),Custom field (Space Key),Custom field (Space Name),Custom field (Start Date),Custom field (Tags),Custom field (Target end),Custom field (Target start),Custom field (Team),Custom field (Test and Documentation Plan),Custom field (Testcase included),Custom field (Tester),Custom field (Tester),Custom field (Workaround),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment
LocalReadSizeWarningTest#failThresholdSinglePartition is flaky,CASSANDRA-17217,13418084,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bernardo.botella,adelapena,adelapena,16/Dec/21 19:53,14/May/22 01:10,13/Jul/23 08:39,12/Apr/22 20:24,4.0.4,,,,,,,Test/unit,,,,0,,,"The test {{org.apache.cassandra.distributed.test.trackwarnings.LocalReadSizeWarningTest#failThresholdSinglePartition}} seems to be flaky.

It was discovered during CASSANDRA-17195 with [this CI run|https://app.circleci.com/pipelines/github/adelapena/cassandra/1217/workflows/b366e352-0862-485a-acdc-5b75fe1ef575/jobs/11188].

The failure can be reproduced running the test repeatedly for trunk, as it can be seen [here|https://app.circleci.com/pipelines/github/adelapena/cassandra/1219/workflows/a0c1fb7f-8a07-4fcf-97a4-7caf207dad78].",,adelapena,bernardo.botella,e.dimitrova,sathyakplm,yifanc,,,,,,,,,,,"dcapwell commented on a change in pull request #1509:
URL: https://github.com/apache/cassandra/pull/1509#discussion_r832673314



##########
File path: test/distributed/org/apache/cassandra/distributed/test/trackwarnings/AbstractClientSizeWarning.java
##########
@@ -283,15 +295,26 @@ public boolean matches(InetAddress value)
         }
         assertHistogramUpdated();
         assertWarnAborts(0, 2, 1);
+    }
+
+    public void failThresholdDisabled(String cql) throws UnknownHostException
+    {
+        ICoordinator node = CLUSTER.coordinator(1);
+        for (int i = 0; i < failThresholdRowCount(); i++)
+            node.execute(""INSERT INTO "" + KEYSPACE + "".tbl (pk, ck, v) VALUES (1, ?, ?)"", ConsistencyLevel.ALL, i + 1, bytes(512));
+
+        if (shouldFlush())
+            CLUSTER.stream().forEach(i -> i.flush(KEYSPACE));
 
         // query should no longer fail
         enable(false);
+        checkpointHistogram();

Review comment:
       this has to go after the query




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Mar/22 22:17;githubbot;600","dcapwell commented on a change in pull request #1509:
URL: https://github.com/apache/cassandra/pull/1509#discussion_r837731107



##########
File path: CHANGES.txt
##########
@@ -1,3 +1,5 @@
+Add proper hitogram checkup to fix flaky failThresholdSinglePartition test

Review comment:
       not proper format, I would personally remove and leave to committer
   
   If you want it correctly (which always conflicts on merge so committer has to fix... hence why I always exclude... but thats me), you would put this under `4.1` (if its going in the 4.1 release), put it at the top and add ` * ` prefix




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Mar/22 17:29;githubbot;600","dcapwell commented on a change in pull request #1509:
URL: https://github.com/apache/cassandra/pull/1509#discussion_r837733133



##########
File path: test/distributed/org/apache/cassandra/distributed/test/trackwarnings/AbstractClientSizeWarning.java
##########
@@ -283,15 +295,26 @@ public boolean matches(InetAddress value)
         }
         assertHistogramUpdated();
         assertWarnAborts(0, 2, 1);
+    }
+
+    public void failThresholdDisabled(String cql) throws UnknownHostException
+    {
+        ICoordinator node = CLUSTER.coordinator(1);
+        for (int i = 0; i < failThresholdRowCount(); i++)
+            node.execute(""INSERT INTO "" + KEYSPACE + "".tbl (pk, ck, v) VALUES (1, ?, ?)"", ConsistencyLevel.ALL, i + 1, bytes(512));
+
+        if (shouldFlush())
+            CLUSTER.stream().forEach(i -> i.flush(KEYSPACE));
 
         // query should no longer fail
         enable(false);
         SimpleQueryResult result = node.executeWithResult(cql, ConsistencyLevel.ALL);
+        checkpointHistogram();

Review comment:
       this has to be before query, as we are checking if the query triggered the condition or not




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Mar/22 17:31;githubbot;600","yifan-c commented on a change in pull request #1509:
URL: https://github.com/apache/cassandra/pull/1509#discussion_r837735224



##########
File path: CHANGES.txt
##########
@@ -1,3 +1,5 @@
+Add proper hitogram checkup to fix flaky failThresholdSinglePartition test

Review comment:
       > not proper format, I would personally remove and leave to committer
   
   Agree. 
   
   And... this patch is to fix test only. So we will not add an entry in the `CHANGES.txt`.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Mar/22 17:34;githubbot;600","sathyakplm commented on a change in pull request #1509:
URL: https://github.com/apache/cassandra/pull/1509#discussion_r839495191



##########
File path: test/distributed/org/apache/cassandra/distributed/test/trackwarnings/AbstractClientSizeWarning.java
##########
@@ -283,15 +295,26 @@ public boolean matches(InetAddress value)
         }
         assertHistogramUpdated();
         assertWarnAborts(0, 2, 1);
+    }
+
+    public void failThresholdDisabled(String cql) throws UnknownHostException
+    {
+        ICoordinator node = CLUSTER.coordinator(1);
+        for (int i = 0; i < failThresholdRowCount(); i++)
+            node.execute(""INSERT INTO "" + KEYSPACE + "".tbl (pk, ck, v) VALUES (1, ?, ?)"", ConsistencyLevel.ALL, i + 1, bytes(512));
+
+        if (shouldFlush())
+            CLUSTER.stream().forEach(i -> i.flush(KEYSPACE));
 
         // query should no longer fail
         enable(false);
+        checkpointHistogram();
         SimpleQueryResult result = node.executeWithResult(cql, ConsistencyLevel.ALL);
         assertThat(result.warnings()).isEmpty();
         assertHistogramNotUpdated();

Review comment:
       One minor query. In Line 313, we are asserting that the warnings is empty. Isn't that sufficient? Do we still need to check if the histogram hasn't updated? Isn't it redundant?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Mar/22 11:24;githubbot;600","bbotella commented on a change in pull request #1509:
URL: https://github.com/apache/cassandra/pull/1509#discussion_r839729728



##########
File path: test/distributed/org/apache/cassandra/distributed/test/trackwarnings/AbstractClientSizeWarning.java
##########
@@ -283,15 +295,26 @@ public boolean matches(InetAddress value)
         }
         assertHistogramUpdated();
         assertWarnAborts(0, 2, 1);
+    }
+
+    public void failThresholdDisabled(String cql) throws UnknownHostException
+    {
+        ICoordinator node = CLUSTER.coordinator(1);
+        for (int i = 0; i < failThresholdRowCount(); i++)
+            node.execute(""INSERT INTO "" + KEYSPACE + "".tbl (pk, ck, v) VALUES (1, ?, ?)"", ConsistencyLevel.ALL, i + 1, bytes(512));
+
+        if (shouldFlush())
+            CLUSTER.stream().forEach(i -> i.flush(KEYSPACE));
 
         // query should no longer fail
         enable(false);
+        checkpointHistogram();
         SimpleQueryResult result = node.executeWithResult(cql, ConsistencyLevel.ALL);
         assertThat(result.warnings()).isEmpty();
         assertHistogramNotUpdated();

Review comment:
       I didn't want to change current behavior. As you can see in the original test:
   https://github.com/apache/cassandra/blob/trunk/test/distributed/org/apache/cassandra/distributed/test/trackwarnings/AbstractClientSizeWarning.java#L206-L207
   
   It was asserting both things already. Same goes for the failThreshold method:
   https://github.com/apache/cassandra/blob/trunk/test/distributed/org/apache/cassandra/distributed/test/trackwarnings/AbstractClientSizeWarning.java#L290-L291




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Mar/22 15:13;githubbot;600","bbotella closed pull request #1509: CASSANDRA-17217 Add proper histogram checkup to fix flaky failThresholdSinglePartition
URL: https://github.com/apache/cassandra/pull/1509


;12/Apr/22 23:05;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,4200,,,0,4200,,,,,,,,,,,,,,,CASSANDRA-16970,,,,,,,,,,,,,CASSANDRA-17195,,,,,,,,,,0.0,bernardo.botella,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 12 20:24:12 UTC 2022,,,,,,,All,,,,"0|z0xsvk:",9223372036854775807,,,,adelapena,ycai,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/2fe1c304835ef39093b70cbb89107383be3c3ee9,,,,,,,,,"It looks like the previous assertWarnAborts method call may create a warn in the metrics under certain conditions. Making sure that we have a histogram checkpoint after disabling the warn tracking ensures that we are in the expected state before executing the non failing query.
||PR||
|[trunk|https://github.com/apache/cassandra/pull/1509]|",,,,,"07/Mar/22 18:39;bernardo.botella;Will start taking a look;;;","07/Mar/22 18:51;e.dimitrova;Thanks [~bernardo.botella], I noticed your assignment and that the ticket was not reflecting the right status, so I did it for you.

Also, I see people who start contributing to the project, working on Jira tickets but not moving them to the right status as they think only committers can do that. I guess we have to update our docs as committer is just a contributor with write permissions to the Cassandra repo. Normally whoever works on the ticket propagates the ticket to respective status to ensure the right people are triggered (in case a committer involvement is needed or just patch available for review for example.)

Thank you for your work, let us know if you have any questions :) ;;;","07/Mar/22 18:53;bernardo.botella;Thanks for the heads up! Will take that into account from now on :);;;","17/Mar/22 22:26;bernardo.botella;It looks like the previous assertWarnAborts method call may create a warn in the metrics under certain conditions. Making sure that we have a histogram checkpoint after disabling the warn tracking ensures that we are in the expected state before executing the non failing query.
||PR||
|[trunk|https://github.com/apache/cassandra/pull/1509]|;;;","18/Mar/22 12:33;adelapena;[~bernardo.botella] thanks for looking into this. Unfortunately, it seems that [this repeated run|https://app.circleci.com/pipelines/github/adelapena/cassandra/1373/workflows/c64980f8-4f6a-439c-ac20-3f376e341f2c/jobs/13945] of {{LocalReadSizeWarningTest}} with 500 iterations still hits the same failure twice.;;;","18/Mar/22 21:47;yifanc;The flaky test is likely cause by the prior read query fails earlier than the completion of the read command execution in each replica. A read is failed as soon as one of the read command fails, and a failure is returned to client. However, there could be still inflight read commands in the other replicas. They will eventually fail and increment the counter. 

For the test in question, once the size tracking is turned off, new queries should not update the metrics, but the flakiness is cause by the prior read. 

There is nothing wrong with the behavior. Probably either wait for some time between each read query to make sure all replicas complete their read command. Or even more clean, test without changing the size tracking in between. It basically breaks the existing test into 2, read with size tracking and w/o.  ;;;","22/Mar/22 22:22;bernardo.botella;I just updated the PR following [~yifanc] suggestion and splitting the tests. I've also run the tests over 1000 times with no errors (similarly to what I did with my previous commit). Hopefully this fixes the flakiness.

Thanks a lot for checking [~adelapena];;;","29/Mar/22 17:38;yifanc;+1

Thanks for the fix. Looking at the repeated run. It is green after 4000 loops. (y);;;","31/Mar/22 13:23;sathyakplm;Hi [~yifanc] , one small query regarding the inflight read instructions. Let's say I make first read query to the cluster and the nodes 0 and 1 respond with failure and the client returns failure. The read to node 2 is in-flight; let's call this read as R1. Once the first call returns, I make second read query to the cluster. In the second query also nodes 0 and 1 respond with failure and the client returns failure. The read to node 2 is in-flight; let's call this read as R2. Does Cassandra assure that R1 is served first before R2?;;;","08/Apr/22 21:11;bernardo.botella;Besides the question for [~yifanc], can please someone take a look for a second +1? Thanks!;;;","11/Apr/22 12:41;adelapena;The changes look good to me, here are 1000 successful iterations on CircleCI:

* [j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1468/workflows/60322f29-e684-4171-b81b-b6856accc9c6]
* [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1468/workflows/30f2a556-9008-400a-aba4-a2d5947a1f9f];;;","11/Apr/22 22:25;bernardo.botella;I got the two +1s;;;","12/Apr/22 17:51;yifanc;Hi [~sathyakplm], the question is not related with the ticket. For those questions, I'd encourage to post them on the user mailing list / slack instead. See [https://cassandra.apache.org/_/community.html] on how to join, just in case not known yet. 

A brief answer to your question... I do not think that _at the node level_ Cassandra ensures monotonic read, i.e. R1 reads state prior to the one R2 reads. The read commands are served in parallel within a node.;;;","12/Apr/22 18:11;yifanc;Starting commit


CI Results:
||Branch||Source||Circle CI||
|trunk|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-17217-trunk-1710429A-1133-4BAE-8E13-41C9CCD27A4F]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-17217-trunk-1710429A-1133-4BAE-8E13-41C9CCD27A4F]|

CI looks good. The flaky test in question did not fail. A few other failures but not related. ;;;","12/Apr/22 20:24;yifanc;Committed into trunk as [2fe1c3048|https://github.com/apache/cassandra/commit/2fe1c304835ef39093b70cbb89107383be3c3ee9];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cannot restart a node when there are other nodes being down in in-jvm dtest framework,CASSANDRA-17214,13417880,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,16/Dec/21 07:04,27/May/22 19:24,13/Jul/23 08:40,26/Jan/22 12:56,4.1,4.1-alpha1,,,,,,Test/dtest/java,,,,0,,,"Such scenario:

{code:java}
    @Test
    public void test() throws Exception
    {
        try (Cluster cluster = init(Cluster.build(2).withDataDirCount(1)).start()))
        {
            FBUtilities.waitOnFuture(cluster.get(2).shutdown());
            FBUtilities.waitOnFuture(cluster.get(1).shutdown());
            cluster.get(1).startup();
            cluster.get(2).startup();
        }
    }
{code}

throws

{noformat}
java.lang.IllegalStateException: Can't use shut down instances, delegate is null

	at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper.delegate(AbstractCluster.java:210)
	at org.apache.cassandra.distributed.impl.DelegatingInvokableInstance.getMessagingVersion(DelegatingInvokableInstance.java:90)
	at org.apache.cassandra.distributed.action.GossipHelper.unsafeStatusToNormal(GossipHelper.java:95)
	at org.apache.cassandra.distributed.impl.Instance.lambda$null$10(Instance.java:640)
{noformat}

when we do not use {{Gossiper}} feature flag.
",,jlewandowski,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jlewandowski,,,,,,,,,,,,,Code,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jan 26 12:56:28 UTC 2022,,,,,,,All,,,,"0|z0xrm8:",9223372036854775807,,,,mck,,,,Low,,2.2.17,,https://github.com/apache/cassandra-in-jvm-dtest-api/commit/2aea316f85e68b4e4739b61260faf5ed91552d5f https://github.com/apache/cassandra/commit/d543dae2cd0d6540d95eb3252d79e75393fd993d,,,,,,,,,run tests,,,,,"16/Dec/21 07:47;jlewandowski;[PR for Cassandra|https://github.com/apache/cassandra/pull/1367]
[PR for DTest API|https://github.com/apache/cassandra-in-jvm-dtest-api/pull/30]
;;;","09/Jan/22 21:15;mck;Looks good to me.

To put this through CI the snapshot of dtest-api will need to be deployed to ASF's staging maven repo, and the in-tree patch to have an added ""throwaway"" commit including the ASF's staging maven repo.;;;","11/Jan/22 20:35;mck;Uploaded as https://repository.apache.org/content/repositories/snapshots/org/apache/cassandra/dtest-api/0.0.12-SNAPSHOT/dtest-api-0.0.12-20220111.195317-1.jar 

Added suggestions in https://github.com/jacek-lewandowski/cassandra/pull/1

CI  [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1360/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1360/];;;","12/Jan/22 12:37;jlewandowski;Thank you [~mck] I merged you PR to my branch - is that ok?;;;","12/Jan/22 14:50;mck;bq. Thank you Michael Semb Wever I merged you PR to my branch - is that ok?

Yup! Feel free then to squash the squash. (And remember to throwaway the throwaway - it's only for CI :);;;","12/Jan/22 16:39;mck; [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1363/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1363/];;;","13/Jan/22 10:28;mck;[~jlewandowski] , could you double check please that the additional test failures compared to trunk are not related to this patch.;;;","13/Jan/22 10:36;jlewandowski;yes, will do;;;","13/Jan/22 11:42;jlewandowski;I have analyzed the results - actually, given only distributed tests are touched, no other tests could ever be affected by this patch. The only failing distributed tests are from {{CompactionStorageUpgradeTest}}, but those are flaky on trunk as well. Therefore I conclude it does not introduce new failures.
;;;","13/Jan/22 12:26;mck;+1

steps to get this out are
# merge dtest-api patch
# cut and vote on dtest-api release
# remove throwaway commit, and merge in-tree patch;;;","13/Jan/22 13:27;mck;1. done with [2aea316f85e68b4e4739b61260faf5ed91552d5f|https://github.com/apache/cassandra-in-jvm-dtest-api/commit/2aea316f85e68b4e4739b61260faf5ed91552d5f];;;","13/Jan/22 18:18;mck;2. started with https://lists.apache.org/thread/mhkcok55rrgj62khobx5kjgxpy9tcfp9 ;;;","26/Jan/22 12:56;mck;Committed as [d543dae2cd0d6540d95eb3252d79e75393fd993d|https://github.com/apache/cassandra/commit/d543dae2cd0d6540d95eb3252d79e75393fd993d].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CompactStorageUpgradeTest.compactStorageUpgradeTest fails w/OOM,CASSANDRA-17213,13417742,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,jmckenzie,jmckenzie,15/Dec/21 14:53,05/Oct/22 22:30,13/Jul/23 08:40,31/May/22 16:25,3.0.28,3.11.14,4.0.5,4.1,4.1-alpha1,5.0,,Legacy/Local Write-Read Paths,,,,0,,,"[https://ci-cassandra.apache.org/job/Cassandra-trunk/882/testReport/org.apache.cassandra.distributed.upgrade/CompactStorageUpgradeTest/compactStorageUpgradeTest/]
h3. Error Message

GC overhead limit exceeded
h3. Stacktrace

java.lang.OutOfMemoryError: GC overhead limit exceeded at sun.net.www.ParseUtil.encodePath(ParseUtil.java:105) at sun.misc.URLClassPath$JarLoader.checkResource(URLClassPath.java:969) at sun.misc.URLClassPath$JarLoader.getResource(URLClassPath.java:1056) at sun.misc.URLClassPath.getResource(URLClassPath.java:249) at java.net.URLClassLoader$1.run(URLClassLoader.java:366) at java.net.URLClassLoader$1.run(URLClassLoader.java:363) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:362) at org.apache.cassandra.distributed.shared.InstanceClassLoader.findClass(InstanceClassLoader.java:140) at org.apache.cassandra.distributed.shared.InstanceClassLoader.loadClassInternal(InstanceClassLoader.java:123) at org.apache.cassandra.distributed.shared.InstanceClassLoader.loadClass(InstanceClassLoader.java:109) at org.codehaus.jackson.map.introspect.BasicClassIntrospector.<clinit>(BasicClassIntrospector.java:62) at org.codehaus.jackson.map.ObjectMapper.<clinit>(ObjectMapper.java:188) at org.apache.cassandra.utils.FBUtilities.<clinit>(FBUtilities.java:74) at org.apache.cassandra.distributed.impl.Instance.<init>(Instance.java:144) at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper$$Lambda$21599/1714755496.apply(Unknown Source) at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper.newInstance(AbstractCluster.java:247) at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper.<init>(AbstractCluster.java:226) at org.apache.cassandra.distributed.UpgradeableCluster.newInstanceWrapper(UpgradeableCluster.java:46) at org.apache.cassandra.distributed.UpgradeableCluster.newInstanceWrapper(UpgradeableCluster.java:36) at org.apache.cassandra.distributed.impl.AbstractCluster.newInstanceWrapperInternal(AbstractCluster.java:515) at org.apache.cassandra.distributed.impl.AbstractCluster.<init>(AbstractCluster.java:470) at org.apache.cassandra.distributed.UpgradeableCluster.<init>(UpgradeableCluster.java:40) at org.apache.cassandra.distributed.UpgradeableCluster.<init>(UpgradeableCluster.java:36) at org.apache.cassandra.distributed.UpgradeableCluster$Builder.lambda$new$0(UpgradeableCluster.java:86) at org.apache.cassandra.distributed.UpgradeableCluster$Builder$$Lambda$73/1631826609.newCluster(Unknown Source) at org.apache.cassandra.distributed.shared.AbstractBuilder.createWithoutStarting(AbstractBuilder.java:158) at org.apache.cassandra.distributed.shared.AbstractBuilder.start(AbstractBuilder.java:140) at org.apache.cassandra.distributed.UpgradeableCluster.create(UpgradeableCluster.java:73) at org.apache.cassandra.distributed.upgrade.UpgradeTestBase$TestCase.run(UpgradeTestBase.java:223) at org.apache.cassandra.distributed.upgrade.CompactStorageUpgradeTest.compactStorageUpgradeTest(CompactStorageUpgradeTest.java:159)
h3. Standard Output

out of memory on output stream

 

Appears consistent",,adelapena,e.dimitrova,jmckenzie,maedhroz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17673,CASSANDRA-17674,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jun 01 16:26:27 UTC 2022,,,,,,,All,,,,"0|z0xqrk:",9223372036854775807,,,,e.dimitrova,,,,Normal,,3.11.8,,https://github.com/apache/cassandra/commit/8a9ba8866db6162a7b7352a260122d6e3c219567,,,,,,,,,Test fix,,,,,"11/May/22 21:14;adelapena;The failure can be reproduced on CircleCI, as it's shown by [this run|https://app.circleci.com/pipelines/github/adelapena/cassandra/1540/workflows/6623b815-7379-4237-b371-e699b359c749].

It seems that the OOM goes away if we split the tests into {{CompactStorageUpgradeTest}}, with one method per class:

||Patch||CI||
|[trunk|https://github.com/adelapena/cassandra/commit/868f3e6fdeb2cc570e4dbc13bbb497b2c8b7684a]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1539/workflows/586f64cf-09ad-415d-b690-7a343dc62ba2]|

However, I don't know why we don't see the same consistent OOM on {{cassandra-4.0}} nor {{cassandra-4.1}} branches.;;;","12/May/22 17:14;adelapena;I have managed to repro the OOM on [{{cassandra-4.0}}|https://app.circleci.com/pipelines/github/adelapena/cassandra/1546/workflows/2e1a0466-eb37-4c0d-be84-f549d05fd2a0] with more repetitions, but not on [{{cassandra-4.1}}|https://app.circleci.com/pipelines/github/adelapena/cassandra/1545/workflows/55c6d848-ca74-495f-a587-665ed1e70fcd]. I don't understand why there is that difference in test flakiness between branches, but probably we should break the test class in all three branches.;;;","12/May/22 17:32;e.dimitrova;I was also looking into this on the side, I was thinking it might be Circle config on different branches (didn't find difference).  Also, we see the same behavior in Jenkins. Maybe some in-jvm difference I don't know. 

The solution SGTM;;;","13/May/22 12:03;adelapena;Here are the PRs splitting the tests for all the branches, they are identical:
||PR||CI||
|[4.0 |https://github.com/apache/cassandra/pull/1626]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1554/workflows/fe83bfb0-f206-47a4-b8ff-18f740beb2e8]|
|[4.1 |https://github.com/apache/cassandra/pull/1627]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1555/workflows/756ff32a-eaf8-4857-af14-af7d0f1a0245]|
|[trunk|https://github.com/apache/cassandra/pull/1628]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1553/workflows/18d4e88e-b030-4fb6-8d4c-7936ab7fab00]|

It seems that 4.0 is still failing, but this time with a different type of error. I think that the OOM was masking this 4.0-only test failure. To see it more clearly, [this simpler patch|https://github.com/adelapena/cassandra/commit/9f8e8f80624cd984802508d5eeab78a4018a2ce0] just removes all other tests from {{{}CompactStorageUpgradeTest{}}}, and it still reproduces the errors on [this run|https://app.circleci.com/pipelines/github/adelapena/cassandra/1557/workflows/eb22ae1e-4f0b-430f-be94-cb6d4f89cc5a].;;;","13/May/22 15:05;e.dimitrova;Interesting, I would have expected this to fail in 4.1 and trunk, not only on 4.0 Good it is disabled by default;;;","16/May/22 11:33;adelapena;I haven't found the reason for the 4.0 failure but it seems that splitting the test to prevent OOMs in all branches is something that we are going to want anyway. Would it makes sense to fix the OOM here and then open a followup ticket for the different failure in 4.0?;;;","16/May/22 11:54;e.dimitrova;Makes total sense to me, +1 to commit the split. ;;;","16/May/22 14:04;e.dimitrova;[~adelapena] , I think we need the patch also ported to 3.11? (at least the split);;;","16/May/22 17:25;adelapena;Yes, right, we should also split the tests in 3.11. The tests are quite different in that branch and their names are quite long, I hope that the new names that I have used for the classes make sense:
||PR||CI pre-fix||CI post-fix||
|[3.11|https://github.com/apache/cassandra/pull/1629]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1558/workflows/34021f5a-1543-4b8a-b67c-801b7987d1ba]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1561/workflows/bb9096e7-ebc4-46ee-90eb-53dd8d42a4c0]|

As it happened with 4.0, [the tests OOM|https://app.circleci.com/pipelines/github/adelapena/cassandra/1558/workflows/34021f5a-1543-4b8a-b67c-801b7987d1ba] quite easily without splitting them., and once we get rid of the OOMs [a new type of failure|https://app.circleci.com/pipelines/github/adelapena/cassandra/1561/workflows/bb9096e7-ebc4-46ee-90eb-53dd8d42a4c0] gets exposed. To make sure that that masked failure isn't introduced by a mistake while splitting, I have run {{CompactStorage2to3UpgradeTest#testDropCompactWithClusteringAndValueColumnWithDeletesAndWrites}} unpatched and in isolation. [That experiment|https://app.circleci.com/pipelines/github/adelapena/cassandra/1562/workflows/77329cd5-3d3d-4a8f-beb5-8f64818df0f5] shows that the test is indeed flaky independently of the OOM that we are trying to fix here.;;;","25/May/22 23:28;maedhroz;Hit a timeout in this test here: https://app.circleci.com/pipelines/github/maedhroz/cassandra/411/workflows/3f77508a-548a-4a17-a086-474afd9653f4/jobs/3151/tests#failed-test-0;;;","26/May/22 11:35;adelapena;That seems a JUnit timeout that we could fix by the proposed test splitting, same as the OOMs. [~e.dimitrova] are we ready to commit the splitting of the test? After that, we can open followup tickets for the masked non-OOM/timeout failures on 3.11 and 4.0.;;;","26/May/22 14:15;e.dimitrova;The splits look good, only I noticed you probably missed to rename the _DropCompactStorageTest_ class? You moved there the 

_testDropCompactWithClusteringAndValueColumn_ and the previous test running there was moved to its own class - _DropCompactStorageBeforeUpgradeSSTablesTest_

 

Otherwise +1, the name change can be done on commit;;;","26/May/22 14:48;adelapena;Yep, I missed renaming that class in 3.11, thanks. I have renamed it, rebased all branches and run CI one (hopefully) last time:
||PR||CI||
|[3.11 |https://github.com/apache/cassandra/pull/1629]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1623/workflows/5b7fe4ca-740d-4d99-b130-017e17770401]|
|[4.0 |https://github.com/apache/cassandra/pull/1626]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1622/workflows/0086c3b1-a552-4c7a-8278-2f759cee5bdf]|
|[4.1 |https://github.com/apache/cassandra/pull/1627]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1625/workflows/39fd6c08-b12f-4179-86a7-eb0fe5f21dc8]|
|[trunk|https://github.com/apache/cassandra/pull/1628]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1624/workflows/c4ce2b95-998f-459b-830e-8e3fa6637e15]|;;;","30/May/22 10:28;adelapena;It seems that the run for trunk has hit [a failure on {{testDropCompactStorage}} that is not an OOM|https://app.circleci.com/pipelines/github/adelapena/cassandra/1624/workflows/c4ce2b95-998f-459b-830e-8e3fa6637e15/jobs/17293/tests]. This failure can be reproduced on {{trunk}} without the patch, as it's shown by [this run|https://app.circleci.com/pipelines/github/adelapena/cassandra/1634/workflows/02fed5e0-66f7-4a82-8664-d1484ef24683/jobs/17303/artifacts]. So that's another failure marked by the OOMs addressed by this ticket, with a 1.4% flakiness.;;;","31/May/22 15:41;adelapena;[~e.dimitrova] this is ready to commit despite of the latest non-OOM test failures, isn’t it?;;;","31/May/22 15:56;e.dimitrova;I just went through the failures, the issue you were fixing is solved, we need to open tickets for the rest.

I would like to mention that I noticed once the NullPointerException from trunk on 3.11
Still +1 on committing the current fix. Thanks;;;","31/May/22 16:21;adelapena;Thanks, committed to 3.11 as [8a9ba8866db6162a7b7352a260122d6e3c219567|https://github.com/apache/cassandra/commit/8a9ba8866db6162a7b7352a260122d6e3c219567] and merged to [4.0|https://github.com/apache/cassandra/commit/fbad08979edc6cb88169c92d071b000846d6974a], [4.1|https://github.com/apache/cassandra/commit/a4196cfb30363b5a05d1ca54a5191f82e4ad64bd] and [trunk|https://github.com/apache/cassandra/commit/770733367fd84e6f9cb29083bd8bffb698cb14f5].

I'll create the followup tickets in a bit.;;;","31/May/22 17:13;adelapena;Just opened CASSANDRA-17673 and CASSANDRA-17674 for the other failures.;;;","31/May/22 17:14;e.dimitrova;Thanks! ;;;","01/Jun/22 16:26;jmckenzie;[CI Results]
Branch: 4.1, build number: 46
   butler url: https://butler.cassandra.apache.org/#/ci/upstream/compare/Cassandra-4.1/Cassandra-4.1
   jenkins url: https://ci-cassandra.apache.org/job/Cassandra-4.1/46/
   JIRA: CASSANDRA-17213
   commit url: https://gitbox.apache.org/repos/asf?p=cassandra.git;a=commit;h=8a9ba8866db6162a7b7352a260122d6e3c219567
   affected paths:
* test/distributed/org/apache/cassandra/distributed/upgrade/DropCompactStorageWithClusteringAndValueColumnTest.java
* test/distributed/org/apache/cassandra/distributed/upgrade/CompactStorageSingleColumnTest.java
* test/distributed/org/apache/cassandra/distributed/upgrade/DropCompactStorageBeforeUpgradeSSTablesTest.java
* test/distributed/org/apache/cassandra/distributed/upgrade/DropCompactStorageWithDeletesAndWritesTest.java
* test/distributed/org/apache/cassandra/distributed/upgrade/CompactStorageMultiColumnTest.java
* test/distributed/org/apache/cassandra/distributed/upgrade/DropCompactStorageTest.java
* test/distributed/org/apache/cassandra/distributed/upgrade/CompactStorage2to3UpgradeTest.java
* test/distributed/org/apache/cassandra/distributed/upgrade/DropCompactStorageTester.java

   Build Result: UNSTABLE
   Passing Tests: 47504
   Failing Tests: 10

||Test|Failures|JIRA||
|org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityV3XTest.testAvailability|7 of 44|[CASSANDRA-17310?|https://issues.apache.org/jira/browse/CASSANDRA-17310]|
|org.apache.cassandra.net.ConnectionTest.testTimeout-compression|1 of 44|[CASSANDRA-16677?|https://issues.apache.org/jira/browse/CASSANDRA-16677]|
|org.apache.cassandra.distributed.test.SchemaTest.readRepairWithCompaction|9 of 44|[CASSANDRA-17641?|https://issues.apache.org/jira/browse/CASSANDRA-17641]|
|org.apache.cassandra.distributed.test.SchemaTest.readRepair|9 of 44|[CASSANDRA-17641?|https://issues.apache.org/jira/browse/CASSANDRA-17641]|
|org.apache.cassandra.db.commitlog.GroupCommitLogTest.testExceedRecordLimitWithMultiplePartitions[3]|1 of 44|[CASSANDRA-17232?|https://issues.apache.org/jira/browse/CASSANDRA-17232]|
|org.apache.cassandra.distributed.upgrade.CompactStoragePagingTest.testPagingWithCompactStorage|1 of 44|[No JIRA found|https://issues.apache.org/jira/secure/RapidBoard.jspa?rapidView=496&quickFilter=2252]
|org.apache.cassandra.cql3.validation.entities.TupleTypeTest.testNestedTuple|5 of 44|[No JIRA found|https://issues.apache.org/jira/secure/RapidBoard.jspa?rapidView=496&quickFilter=2252]
|dtest-novnode.bootstrap_test.TestBootstrap.test_bootstrap_with_reset_bootstrap_state|1 of 44|[Multiple JIRAs found|https://issues.apache.org/jira/issues/?jql=project%20%3D%20CASSANDRA%20and%20resolution%20%3D%20unresolved%20and%20summary%20~%20""*TestBootstrap*""]
|dtest.cqlsh_tests.test_cqlsh.TestCqlsh.test_describe_describes_non_default_compaction_parameters|1 of 44|[CASSANDRA-17322?|https://issues.apache.org/jira/browse/CASSANDRA-17322]|
|org.apache.cassandra.db.SinglePartitionSliceCommandTest.testPartitionDeletionRowDeletionTie-compression|6 of 44|[CASSANDRA-17458?|https://issues.apache.org/jira/browse/CASSANDRA-17458]|;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Not able to override default transport port in cassandra 4.0,CASSANDRA-17210,13417724,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,smiklosovic,nishant__gupta,nishant__gupta,15/Dec/21 13:58,23/May/23 23:17,13/Jul/23 08:40,20/Mar/22 20:22,4.0.4,4.1,4.1-alpha1,,,,,Tool/bulk load,,,,0,,,"Bulk Loader is not honouring ""-p"" option given on the command line of the sstableloader.

The command line used is:

~/apache-cassandra-4.0.1/bin/sstableloader -d 10.14.20.148 -cph 1 -idct 0 -p 9942 -ssp 7011 -sp 7010 --verbose ~/cassandra4_experiment/nishant/employee/

 

but the call is still going to /10.14.20.148:9042. We are just passing the host information to the Cluster.Builder in NativeSSTableLoaderClient.java:
Cluster.Builder builder = Cluster.builder().addContactPointsWithPorts(hosts).allowBetaProtocolVersion();

Looks like default port is getting picked inside com.datastax.driver.core.cluster.",,e.dimitrova,nishant__gupta,RensGroothuijsen,smiklosovic,,,,,,,,,,,,"rgroothuijsen opened a new pull request #1374:
URL: https://github.com/apache/cassandra/pull/1374


   The sstableloader documentation states that the native transport port can be specified using the `--port` parameter, but this parameter is not actually used in the code. The intended effect is achieved by specifying the port on the host address instead, which this PR intends to clarify.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;30/Dec/21 18:03;githubbot;600","smiklosovic opened a new pull request #1507:
URL: https://github.com/apache/cassandra/pull/1507


   patch by Stefan Miklosovic; reviewed by Brandon Williams for CASSANDRA-17210


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Mar/22 15:46;githubbot;600","smiklosovic opened a new pull request #1507:
URL: https://github.com/apache/cassandra/pull/1507


   patch by Stefan Miklosovic; reviewed by Brandon Williams for CASSANDRA-17210


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/22 15:08;githubbot;600","smiklosovic closed pull request #1507:
URL: https://github.com/apache/cassandra/pull/1507


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Mar/22 20:23;githubbot;600","smiklosovic commented on pull request #1374:
URL: https://github.com/apache/cassandra/pull/1374#issuecomment-1073342260


   this issue was solved, see ticket for CASSANDRA-17210.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Mar/22 20:24;githubbot;600","smiklosovic closed pull request #1374:
URL: https://github.com/apache/cassandra/pull/1374


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Mar/22 20:24;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,3600,,,0,3600,,,,,,,,,,CASSANDRA-17262,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,smiklosovic,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sun Mar 20 20:16:12 UTC 2022,,,,,,,All,,,,"0|z0xqns:",9223372036854775807,,,,brandon.williams,smiklosovic,,,Low,,4.0.0,,https://github.com/apache/cassandra/commit/d48df9169d920ab9208fd1a7b3cad6a625045047,,,,,,,,,unit test,,,,,"29/Dec/21 21:18;RensGroothuijsen;It does appear the bulk loader doesn't make use of the port parameter, though as a workaround you can specify ""-d <host>:<port>"" instead of ""-d <host>"" as the address, and it will work as expected.;;;","16/Mar/22 16:59;smiklosovic;[~e.dimitrova] do you think this is something to fix?;;;","16/Mar/22 18:03;brandon.williams;It seems to be a legitimate bug and was triaged as such, do you disagree?;;;","16/Mar/22 18:12;smiklosovic;the related PR is just changing some docs (1) and there is a workaround so I was confused. 

(1) https://github.com/apache/cassandra/pull/1374/files;;;","17/Mar/22 15:44;smiklosovic;The problem is that native port is resolved after hosts are and default port is 9042 so there is no chance that hosts resoluion would use native port from the  configuration because its parsing is done after hosts are configured. Simple movement of native port resolution solves the issue.

https://github.com/apache/cassandra/pull/1507;;;","18/Mar/22 15:21;brandon.williams;+1.  It's a little sad that LoaderOptionsTest couldn't catch this.;;;","19/Mar/22 13:34;smiklosovic;ci failed on one test, fixing it ....;;;","20/Mar/22 20:16;smiklosovic;4.0 [https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1524]

trunk: [https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1525];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
File leaks will not be be detected and released due to strong self-references in the tidier,CASSANDRA-17205,13417510,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jmckenzie,jmckenzie,jmckenzie,14/Dec/21 17:16,27/May/22 19:25,13/Jul/23 08:40,17/Dec/21 16:24,4.1,4.1-alpha1,,,,,,Local/SSTable,,,,0,,,"LogTransaction.SSTableTidier holds a reference to a {{Tracker}} which holds references to both a {{ColumnFamilyStore}} and a {{View}}, both of which hold refs to SSTableReaders. As per the comment at the top of the SSTableTidier:
{quote}// must not retain a reference to the SSTableReader, else leak detection cannot kick in
{quote}
We shouldn't hold a reference to the Tracker here; long running unit tests w/-Dcassandra.debugrefcount=true had this pop up.

{code}ERROR [Strong-Reference-Leak-Detector:1] 2020-10-27T01:10:12,421 NoSpamLogger.java:97 - Strong self-ref loop detected{code}",,benedict,jeromatron,jmckenzie,maedhroz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jmckenzie,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Dec 15 13:57:45 UTC 2021,,,,,,,All,,,,"0|z0xpc8:",9223372036854775807,,,,benedict,jmckenzie,,,Normal,,3.0.0 rc1,,"https://git-wip-us.apache.org/repos/asf?p=cassandra.git;a=commit;h=f4a2135c5ba442aafd27bb7c12c85b376d5a2b87",,,,,,,,,"No new testing or documentation needed; discovered by existing long-running testing",,,,,"14/Dec/21 17:23;jmckenzie;[branch|https://github.com/apache/cassandra/compare/trunk...josh-mckenzie:cassandra-17205?expand=1]

[JDK11 CI|https://app.circleci.com/pipelines/github/josh-mckenzie/cassandra/151/workflows/ed12dd8c-a3d9-4b87-a895-903132502221]

 Functionally changes in a couple subtle ways:

Before, we'd assess if the {{Tracker}} existed and if the {{ColumnFamilyStore}} was valid *at time of tidy run*; we instead evaluate now at time of *creation* of the {{SSTableTidier}}, meaning the {{Tracker}} could go out of scope and be otherwise nullified before the two operations that relied on its presence for evaluation.

Those 2 operations are pretty benign however; clearing the {{SSTableReadMeter}} in {{system.sstable_activity}}, and decrementing the {{totalDiskSpaceUsed}} metric in the {{ColumnFamilyStore}}. Both operations we should be able to just try and gracefully fail if the Tracker's no longer active or valid by time of SSTableTidier run.

Second, we now grab a reference to the totalDiskSpaceUsed Counter inside the ColumnFamilyStore at time of {{SSTableTidier}} creation instead of at run() runtime, meaning we could theoretically hold a handle to a metric on a ColumnFamilyStore that's dropped in the interim. I don't _think_ this should be a problem; the code around releasing metrics in {{TableMetrics.releaseMetric}} should still run w/out issue and remove the metric from the top level registry, we'll just hold a ref to it and operate on the {{LongAdder}} in the {{Counter}} and then drop the ref to it when the {{SSTableTidier}} gets collected.

So in short: I don't love it and I've commented in the diff around these subtleties, but it sidesteps the current strong ref loop we have to the Tracker.

Going to give CI a bit to run, make sure things are clean before I find a reviewer.     ;;;","14/Dec/21 18:40;jmckenzie;CI looks good except {{TestClientRequestMetricsLocalRemote}} which look both new and to be failing on trunk. Thanks [Butler!|https://butler.cassandra.apache.org/#/ci/upstream/compare/Cassandra-trunk/trunk]

Going to think for a couple minutes on whether it's worth it to logically tie this ""clear out sstable_activity and clear out {{{}TableMetrics{}}}"" action together or keep it bespoke for the {{Tidier}} here...

 

Edit: Nope. Literally only used in {{SSTableTidier}};;;","14/Dec/21 18:47;jmckenzie;One other detail here to call out: this changes from runtime evaluation of whether there's a Memtable associated with a ColumnFamilyStore to SSTableTidier time creation. Currently in the codebase we don't create a Tracker w/out a Memtable in it and then later add it; this functionality straddle is there to enable both Online and Offline usage of the same infrastructure, so we should be fine here.

 

But it's a change.;;;","15/Dec/21 13:57;benedict;We could check {{totalDiskSpaceUsed != null && DatabaseDescriptor.isDaemonInitialized()}} if we can assume that it is always set in the {{Metrics}} object (which today it is), to keep functionality equivalent.

Otherwise LGTM;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Avoid unnecessary String.format in QueryProcessor when getting stored prepared statement ,CASSANDRA-17202,13416583,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,ivansenic,ivansenic,ivansenic,10/Dec/21 14:16,18/May/23 20:49,13/Jul/23 08:40,18/May/23 20:49,3.11.16,4.0.10,4.1.2,5.0,,,,Messaging/Client,,,,0,,,"In the _QueryProcessor#getStoredPreparedStatement_ if the statement is found in the prepared statements cache, there is always unnecessary string creation using String.format in order to execute the _checkTrue_ assertion. The string construction is necessary only when the queries are not equal.
{code:java}
public static ResultMessage.Prepared getStoredPreparedStatement(String queryString, String clientKeyspace)
throws InvalidRequestException
{
    MD5Digest statementId = computeId(queryString, clientKeyspace);
    Prepared existing = preparedStatements.getIfPresent(statementId);
    if (existing == null)
        return null;

    checkTrue(queryString.equals(existing.rawCQLStatement),
            String.format(""MD5 hash collision: query with the same MD5 hash was already prepared. \n Existing: '%s'"", existing.rawCQLStatement));
 {code}
Hopefully the JIT can optimize this once the _checkTrue_ is inlined, but it's getting on my nerves as it's popping up on my flame graphs all the time.

 ",,blerer,e.dimitrova,ivansenic,smiklosovic,,,,,,,,,,,,"ivansenic opened a new pull request #1358:
URL: https://github.com/apache/cassandra/pull/1358


   See [CASSANDRA-17202](https://issues.apache.org/jira/browse/CASSANDRA-17202) for details.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Dec/21 14:21;githubbot;600","ivansenic opened a new pull request #1364:
URL: https://github.com/apache/cassandra/pull/1364


   A copy of #1358 targeting `cassandra-3.11` branch.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Dec/21 14:59;githubbot;600","ivansenic opened a new pull request #1365:
URL: https://github.com/apache/cassandra/pull/1365


   A copy of #1358 targeting `cassandra-4.0` branch.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Dec/21 15:00;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,ivansenic,,,,,,,,,,,,,,,,,,,,Performance,Low Hanging Fruit,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu May 18 13:53:36 UTC 2023,,,,,,,All,,,,"0|z0xk3k:",9223372036854775807,,,,blerer,brandon.williams,smiklosovic,,,,3.11.0,,https://github.com/apache/cassandra/commit/3ca94d65d3fd8f3f010f91e196b37608b08e0828,,,,,,,,,[https://github.com/apache/cassandra/pull/1358],,,,,"10/Dec/21 14:23;ivansenic;PR: https://github.com/apache/cassandra/pull/1358;;;","10/Dec/21 15:57;e.dimitrova;Moving to Patch Available to trigger reviewers attention. Thank you;;;","10/Dec/21 16:02;brandon.williams;[Circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17202] running.;;;","10/Dec/21 16:50;brandon.williams;Only known failures in CI, +1 from me.;;;","13/Dec/21 14:03;blerer;{{checkTrue}} perform the {{String.format}} operation only after checking the value so removing the String.format is enough.

{code}
    checkTrue(queryString.equals(existing.rawCQLStatement), ""MD5 hash collision: query with the same MD5 hash was already prepared. \n Existing: '%s'"", existing.rawCQLStatement);
{code} ;;;","13/Dec/21 15:06;ivansenic;[~blerer] I missed that.. Sure that's better and involves less changes.. Should I update the PR?;;;","14/Dec/21 18:02;blerer;Yes. Please. ;;;","15/Dec/21 11:03;blerer;In fact it seems that it also affect earlier releases. I think we also need a patch for 3.0 (it will merge cleanly into 3.11) and the patch for 4.0 (it will merge cleanly in trunk).
I you can make those patches. I will run CI for them :-) ;;;","15/Dec/21 13:25;ivansenic;The GitHub PR is updated as per request.

[~blerer] Are you saying I should create two more PRs, one targeting the _cassandra-3.11_ and one _cassandra-4.0_ branch? The current PR targets the {_}trunk{_}.;;;","15/Dec/21 13:38;blerer; [~ivansenic] Yes, if you do not mind. ;;;","15/Dec/21 15:00;ivansenic;Done.

3.11: [https://github.com/apache/cassandra/pull/1364]
4.0: [https://github.com/apache/cassandra/pull/1365]

 ;;;","15/May/23 18:27;smiklosovic;rebased patch for trunk: https://github.com/apache/cassandra/pull/2335
j8: https://app.circleci.com/pipelines/github/instaclustr/cassandra/2201/workflows/d31afba8-8b29-43aa-86f2-ce88cd5b1ec7
j11: https://app.circleci.com/pipelines/github/instaclustr/cassandra/2201/workflows/a8c6ecb0-f798-4c61-8a38-8cf4c9a8ebe9

+1;;;","15/May/23 18:51;brandon.williams;We need a branch for 4.1, and CI for everything earlier than trunk.  I can help with the latter when the 4.1 branch is ready.;;;","15/May/23 18:57;smiklosovic;Ah right, I saw 5.x so I went with trunk only. I will prepare the branches, sure.;;;","18/May/23 08:13;smiklosovic;I ve added the builds and PRs, [~brandon.williams]. Tell me if you need something else.

3.11 PR https://github.com/apache/cassandra/pull/2342
3.11 pre-commit https://app.circleci.com/pipelines/github/instaclustr/cassandra/2233/workflows/89f0741e-77bc-4077-9a95-64e4fb466d19

4.0 PR https://github.com/apache/cassandra/pull/2340
4.0 j8 https://app.circleci.com/pipelines/github/instaclustr/cassandra/2232/workflows/49dbba70-2110-4039-ab8c-b6ad69a8f71e
4.0 j11 https://app.circleci.com/pipelines/github/instaclustr/cassandra/2232/workflows/7d752769-ee9f-4859-b960-f3eaf4adfeb5

4.1 PR https://github.com/apache/cassandra/pull/2341
4.1 j8 https://app.circleci.com/pipelines/github/instaclustr/cassandra/2231/workflows/c76bcc8e-a416-4edb-bd47-1689666e893f
4.1 j11 https://app.circleci.com/pipelines/github/instaclustr/cassandra/2231/workflows/b0b21d1e-c9dc-4174-be37-09e6dee9dddc;;;","18/May/23 13:53;brandon.williams;The one odd 3.11 failure is actually my fault and fixed [here|https://github.com/apache/cassandra-dtest/commit/39c1c113e101b437ec66aaa8566e5c9c9e67b2ff].  Everything else looks good to me, +1.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
List Appends Are Not Linearizable,CASSANDRA-17177,13414585,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,benedict,benedict,benedict,30/Nov/21 16:21,27/May/22 19:25,13/Jul/23 08:40,10/Mar/22 20:27,4.1,4.1-alpha1,,,,,,Consistency/Coordination,,,,0,,,"List TimeUUID are issued using the wall clock of the coordinator, so that two coordinators with divergent clocks may invert their append order",,adelapena,benedict,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,benedict,,,,,,,,,,,,,Correctness -> Consistency,,,,,,,,Normal,Fuzz Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Mar 11 14:03:01 UTC 2022,,,,,,,All,,,,"0|z0x7sw:",9223372036854775807,,,,bdeggleston,benedict,,,Normal,,1.2.0,,"[8960b4d8513e22c4c11c181c520380342935aee7|https://github.com/apache/cassandra/commit/8960b4d8513e22c4c11c181c520380342935aee7]",,,,,,,,,Covered by CEP-14 Simulator improvements,,,,,"11/Mar/22 13:00;brandon.williams;Is there a CI run for this?;;;","11/Mar/22 13:06;benedict;It was committed as part of CASSANDRA-17164;;;","11/Mar/22 14:03;brandon.williams;I don't see any runs linked there either?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky GrantAndRevokeTest,CASSANDRA-17173,13414253,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,29/Nov/21 09:33,27/May/22 19:25,13/Jul/23 08:40,30/Nov/21 05:54,4.1,4.1-alpha1,,,,,,Test/unit,,,,0,,,"See [here|https://ci-cassandra.apache.org/job/Cassandra-trunk/869/testReport/junit/org.apache.cassandra.auth/GrantAndRevokeTest/testGrantedKeyspace_cdc/]

{noformat}
junit.framework.AssertionFailedError: Expected error message to contain 'User user has no MODIFY permission on <table cql_test_keyspace_alt.table_06> or any of its parents', but got 'You do not have access to this datacenter (datacenter1)'
	at org.apache.cassandra.cql3.CQLTester.assertMessageContains(CQLTester.java:1782)
	at org.apache.cassandra.cql3.CQLTester.assertInvalidThrowMessage(CQLTester.java:1721)
	at org.apache.cassandra.cql3.CQLTester.assertUnauthorizedQuery(CQLTester.java:1794)
	at org.apache.cassandra.auth.GrantAndRevokeTest.testGrantedKeyspace(GrantAndRevokeTest.java:64)
{noformat}
",,bereng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Nov 29 13:50:18 UTC 2021,,,,,,,All,,,,"0|z0x5r4:",9223372036854775807,,,,bereng,brandon.williams,,,Normal,,4.1,,https://github.com/apache/cassandra/commit/f47e4b294dd0512d8bec5f8cddd3142fa7c1867a,,,,,,,,,See PR,,,,,"29/Nov/21 11:27;bereng;I couldn't repro locally. But some modifications to wait for the auth changes to be effective pass 1K runs now.;;;","29/Nov/21 13:50;brandon.williams;CI looks good and the patch is straightforward, +1.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky CompactionsBytemanTest,CASSANDRA-17171,13413995,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,26/Nov/21 09:49,27/May/22 19:24,13/Jul/23 08:40,09/Dec/21 06:47,4.0.2,4.1,4.1-alpha1,,,,,Test/unit,,,,0,,,"See [here|https://ci-cassandra.apache.org/job/Cassandra-trunk/868/testReport/junit/org.apache.cassandra.db.compaction/CompactionsBytemanTest/testCompactingCFCounting/]

{noformat}
junit.framework.AssertionFailedError: expected:<0> but was:<1>
	at org.apache.cassandra.db.compaction.CompactionsBytemanTest.testCompactingCFCounting(CompactionsBytemanTest.java:130)
	at org.jboss.byteman.contrib.bmunit.BMUnitRunner$10.evaluate(BMUnitRunner.java:393)
	at org.jboss.byteman.contrib.bmunit.BMUnitRunner$6.evaluate(BMUnitRunner.java:263)
	at org.jboss.byteman.contrib.bmunit.BMUnitRunner$1.evaluate(BMUnitRunner.java:97)
{noformat}
",,adelapena,bereng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Dec 09 06:48:06 UTC 2021,,,,,,,All,,,,"0|z0x45s:",9223372036854775807,,,,adelapena,,,,Normal,,4.0.2,,https://github.com/apache/cassandra/commit/8cef32ae8376d23828a20b861161bd0d3845456f,,,,,,,,,See PR,,,,,"26/Nov/21 09:54;bereng;Can be repro'ed locally by adding a sleep to {{BackgroundCompactionCandidate.run()}};;;","26/Nov/21 12:03;bereng;A second bug was found running 1K in circle which has been fixed now. When we +1 trunk we can apply the same to 4.0.;;;","03/Dec/21 12:52;adelapena;Looks good to me, the patched test survives 5k runs ([j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1199/workflows/5272f762-e1b0-48e4-91ee-45de22bd294b], [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1200/workflows/3973ae47-2700-495c-b225-4715992eb2fd]).;;;","03/Dec/21 13:30;bereng;Adding 4.0 PR now + test run.;;;","03/Dec/21 14:03;adelapena;Sorry, my links to CI repeated runs above were for j8 in both [4.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/1199/workflows/5272f762-e1b0-48e4-91ee-45de22bd294b] and [trunk|https://app.circleci.com/pipelines/github/adelapena/cassandra/1200/workflows/3973ae47-2700-495c-b225-4715992eb2fd], not for trunk's j8 and j11. I didn't run them for j11.;;;","03/Dec/21 14:42;bereng;How did you run 4.0 if I hadn't put up the 4.0 PR yet?;;;","03/Dec/21 14:57;adelapena;I ran the {{CASSANDRA-17171-4.0}} branch in your repo, at [this|https://github.com/adelapena/cassandra/commits/17171-4.0-review] moment. However I didn't realize that the 4.0 branch didn't have the increased delay/timeout pair, although that would make the test less prone to fail, so if it has survived with a margin of 1s I guess it would also survive with 5s, as it does in trunk. Nevertheless we can wait for your run for 4.0 + review comments.;;;","03/Dec/21 15:01;bereng;Ok now we have 5K repeats on both trunk and 4.0. I think we're good to merge. Wdyt?;;;","03/Dec/21 15:05;adelapena;We are definitively ready to merge.;;;","09/Dec/21 06:48;bereng;Thx for the work!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky RecomputingSupplierTest,CASSANDRA-17169,13413577,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,24/Nov/21 11:05,27/May/22 19:25,13/Jul/23 08:40,03/Dec/21 10:41,4.0.2,4.1,4.1-alpha1,,,,,Test/unit,,,,0,,,"See https://ci-cassandra.apache.org/job/Cassandra-4.0/293/testReport/junit/org.apache.cassandra.utils/RecomputingSupplierTest/recomputingSupplierTest/

{noformat}
java.util.concurrent.TimeoutException
	at java.base/java.util.concurrent.CompletableFuture.timedGet(CompletableFuture.java:1886)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2021)
	at org.apache.cassandra.utils.RecomputingSupplier.get(RecomputingSupplier.java:110)
	at org.apache.cassandra.utils.RecomputingSupplierTest.recomputingSupplierTest(RecomputingSupplierTest.java:120)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{noformat}


",,adelapena,bereng,Gerrrr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Dec 02 11:04:05 UTC 2021,,,,,,,All,,,,"0|z0x1ko:",9223372036854775807,,,,adelapena,Gerrrr,,,Normal,,4.0.1,,https://github.com/apache/cassandra/commit/15eaa95f091749a7f4b8271a3fa10a13f854c448,,,,,,,,,See PR,,,,,"25/Nov/21 09:38;bereng;Can be repro'ed with the {{RepeatableRunner}} locally. The problem was the premature shutdown of a thread pool as {{RecomputingSupplier}} might needed it. I amended a few other nits in the test as well. Now it survives 10K local runs and 1K runs in circle. If we +1 4.0 I'll push the trunk PR.;;;","02/Dec/21 08:25;bereng;Added trunk PR which also passes 4K repetitions. Shall we merge?;;;","02/Dec/21 10:22;Gerrrr;The patch makes sense to me and seems to fix the test. +1 to merge it.;;;","02/Dec/21 11:04;adelapena;Looks good to me too, +1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Don't block gossip when clearing snapshots for failing repairs,CASSANDRA-17168,13413541,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,24/Nov/21 08:08,27/May/22 19:25,13/Jul/23 08:40,17/Jan/22 08:21,4.0.2,4.1,4.1-alpha1,,,,,Consistency/Repair,,,,0,,,"We clear snapshots in the GossipTasks thread when a repair session fails due to a replica shutting down. If there are many tables/repair sessions ongoing this can take a long time. With enough tables being repaired at the same time even checking if the snapshots exists can take long enough to mark nodes down.

We should clear snapshots in a separate thread and add a flag to tell us whether this repair session can have snapshots to avoid checking if the directory exists.",,dcapwell,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Availability -> Unavailable,,,,,,,,Normal,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Jan 10 15:34:34 UTC 2022,,,,,,,All,,,,"0|z0x1co:",9223372036854775807,,,,dcapwell,,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/98e798f567368f826fc3a57ddb6cdc464e741fe3,,,,,,,,,tests,,,,,"24/Nov/21 08:20;marcuse;trunk:
https://github.com/apache/cassandra/pull/1340
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F17168-trunk
4.0:
https://github.com/apache/cassandra/pull/1341 
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F17168

note that the trunk version includes a change to the PREPARE message to include repair parallelism instead of setting a flag on ParentRepairSession;;;","30/Nov/21 23:34;dcapwell;Overall +1 (assuming repair tests are passing).  I am not a fan of breaking change in the protocol, though I do know we say repair isn't supported in mixed-mode... ;;;","10/Jan/22 15:34;marcuse;updated the trunk patch to not change the protocol, feels unnecessary to break compatibility for something this small ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ViewTests flaky on timeouts,CASSANDRA-17167,13413115,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,22/Nov/21 09:50,27/May/22 19:25,13/Jul/23 08:40,26/Nov/21 06:20,4.0.2,4.1,4.1-alpha1,,,,,Test/unit,,,,0,,,"Recently, specially on trunk, View*Test have stared timing out. This is bad for CI credibility when submitting a patch so it's worth splitting them yet again.

Despite trunk being the main offender the patch will be also applied to 4.0 to be defensive about it.

As we can see [here|https://ci-cassandra.apache.org/job/Cassandra-trunk/861/testReport/junit/org.apache.cassandra.cql3/] the candidates are: ViewComplexLivenessTest, ViewComplexDeletionsTest, ViewComplexTest, ViewFilteringPKTest, ViewFilteringTest",,adelapena,bereng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Nov 25 13:38:20 UTC 2021,,,,,,,All,,,,"0|z0wyq8:",9223372036854775807,,,,adelapena,,,,Normal,,4.0.2,,https://github.com/apache/cassandra/commit/0764273608f501036f1f68e51185067856b934db,,,,,,,,,See PR,,,,,"22/Nov/21 11:24;bereng;Note for the reviewer:

[~adelapena] probably a quick review for you as we've both been working on these tests.

I split the tests that according to jenkins history have suffered the timeouts recently. It's just a plain split of test files.;;;","22/Nov/21 20:02;adelapena;Sure, I'll take a look;;;","23/Nov/21 11:50;adelapena;+1 to splitting those tests. Not sure however about applying the changes to 4.0 if we are only finding the failures in trunk. 4.0 misses the refactoring done by CASSANDRA-1712, which was done to avoid the code duplication introduced by the previous splitting of view tests done by CASSANDRA-16670. Thus, this new test splitting is introducing even more core duplication in 4.0. I think I'd prefer to either leave 4.0 unchanged or port back the changes introduced by CASSANDRA-17122 and then split, wdyt?

It's interesting that we are seeing those timeouts only in trunk. CASSANDRA-17122 introduced changes to always wait for  MV builds and updates even when it's not strictly required so we prevent accidental races. This however might make the tests slightly slower and thereof more prone to produce JUnit timeouts. That might explain the difference, although I'm not sure the impact of those additional waits is noticeable. At least, I don't see a lot of difference locally.

Do we have a PR for trunk with CI runs?;;;","23/Nov/21 12:09;bereng;I reached similar conclusions to you.

I did the 4.0 branch bc looking at jenkins test reports, despite being difficult to track, I was under the impression the same tests were close to timing out as well. Hence I thought doing 4.0 would be a good defensive move. I think porting 17122 would be a big effort with diminishing returns in 4.0. Trunk is a different story. So big refactor vs some minor code dup vs risk of timing out. I chose n2 for the best balance and return in my eyes. Would you prefer we leave 4.0 alone?

I did not push a trunk branch yet bc I wanted to have feedback on a first pass on 4.0. I'll do a trunk PR now then.;;;","23/Nov/21 13:16;adelapena;> So big refactor vs some minor code dup vs risk of timing out. I chose n2 for the best balance and return in my eyes. Would you prefer we leave 4.0 alone?

Indeed porting the refactor is quite involved and it could be done to prevent a timeout problem that we might not have. However keep duplicating code in 4.0 doesn't sound good either, especially considering that the duplication doesn't look so minor to me. I we leave 4.0 alone we could always go back and split the tests if we see them failing, but I don't have a strong opinion on this and I'd be ok splitting 4.0 if you think they are close to time out. If we go that way we should at least remove the duplications of {{{}createView{}}}/{{{}updateView{}}}/{{{}dropView{}}} in the new {{ViewFiltering2Test}} by calling the version of those methods in {{{}ViewFilteringTest{}}}, as it's done by the other {{ViewFiltering*}} tests.;;;","24/Nov/21 08:44;bereng;Ah that dup code in {{ViewFiltering2Test}} is an oversight, my bad. Yes that has to go and I did in the latest push. I left the split in 4.0 bc jenkins shows for some a failure but only in a blue moon. So as it is already there + removing that dup code I'd leave it as it is now.

I also pushed trunk. The only thing worth mentioning is again on {{ViewFiltering2Test}} where I call {{ViewFilteringTest}} enc setup/teardown methods rather than doing some parent common class which sounds like an overkill.;;;","24/Nov/21 15:45;adelapena;{quote}I also pushed trunk. The only thing worth mentioning is again on ViewFiltering2Test where I call ViewFilteringTest enc setup/teardown methods rather than doing some parent common class which sounds like an overkill.
{quote}
Thanks, I also think that a common superclass in the trunk case is an overkill. The patch for trunk looks good to me, I have left a couple of trivial suggestions on the PR.

As for 4.0, I agree to splitting the tests if they are also timing out, and it seems they are. We don't need to port back the refactoring done in CASSANDRA-1712, but we could still try to reduce duplications a bit by extracting a common superclass for {{ViewFiltering*}} tests, like we did with {{ViewComplexTester}} in CASSANDRA-17070, [this way|https://github.com/adelapena/cassandra/commit/e5b0937f80e6d7e8640b3ae1be99487bf895c642]. That's a 5min refactor and gets rid of the duplications within the six flavours of {{{}ViewFiltering*Test{}}}.

I have run the split tests and all seem to finish in very reasonable and well balanced times, hopefully we won't need to split them again :). Could we have some repeated runs of {{{}View*Test{}}}, just to be sure that at least they aren't flaky on CircleCI?;;;","25/Nov/21 11:32;bereng;[~adelapena] latest review comments addressed. The only downside is that I tried a 100 runs of {{View*Test}} and circle timed out as you can see on the CI links. I don't think it makes much sense to try 50, 25, etc runs. I would go for the merge but lmk wdyt.;;;","25/Nov/21 12:16;adelapena;Both PRs look good to me. With the common superclass {{ViewFilteringTester}} we don't solve the problem of duplications in 4.0 but at least we don't contribute to it with this new splitting, which is nice.
{quote}The only downside is that I tried a 100 runs of View*Test and circle timed out as you can see on the CI links. I don't think it makes much sense to try 50, 25, etc runs. I would go for the merge but lmk wdyt.
{quote}
I was writing about this on the PR, we can run those tests with MIDRES to prevent the timeouts:
{code:java}
.circleci/generate.sh -m \
  -e REPEATED_UTEST_TARGET=test \
  -e REPEATED_UTEST_COUNT=100 \
  -e REPEATED_UTEST_CLASS=View*Test
{code}
That's the config we used for CASSANDRA-17122. IIR both unit tests and repeated unit tests use the same resource class in LOWRES and MIDRES, and the only difference is parallelism. I'm running them here:
 * [4.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/1171/workflows/4be538d8-6695-4f06-8fe5-b9e7149a6800]
 * [trunk|https://app.circleci.com/pipelines/github/adelapena/cassandra/1172/workflows/e27a399a-9076-4b5f-bd1e-7fa59444f9cb];;;","25/Nov/21 12:58;bereng;Ah sorry I was out for lunch otherwise I would have done it myself. I intentionally went for low-res to get a constrained env bc on MID is like 100/24 ~= 4 runs per node. But it's better than nothing so sgtm.;;;","25/Nov/21 13:38;adelapena;No worries :). `View*Test` contains a bunch of slowish tests, it has taken around one hour even with the 25 parallel runners, but it has happily succeeded. I think we are ready to merge.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix test org.apache.cassandra.distributed.test.SecondaryIndexTest#test_only_coordinator_chooses_index_for_query,CASSANDRA-17165,13412676,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,maedhroz,dcapwell,dcapwell,19/Nov/21 01:34,27/May/22 19:25,13/Jul/23 08:40,19/Nov/21 20:39,4.1,4.1-alpha1,,,,,,Test/dtest/java,,,,0,,,"https://app.circleci.com/pipelines/github/dcapwell/cassandra/1140/workflows/3dff9cae-32e7-4e70-874e-6c672c563275/jobs/8355/tests

This test fails some times on j11

{code}
junit.framework.AssertionFailedError: expected:<[/127.0.0.1]> but was:<[]>
	at org.apache.cassandra.distributed.test.SecondaryIndexTest.test_only_coordinator_chooses_index_for_query(SecondaryIndexTest.java:104)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{code}",,dcapwell,maedhroz,,,,,,,,,,,,,,"maedhroz commented on a change in pull request #1334:
URL: https://github.com/apache/cassandra/pull/1334#discussion_r753448433



##########
File path: test/distributed/org/apache/cassandra/distributed/test/SecondaryIndexTest.java
##########
@@ -43,9 +45,10 @@
     private static final int NUM_NODES = 3;
     private static final int REPLICATION_FACTOR = 1;
     private static final String CREATE_TABLE = ""CREATE TABLE %s(k int, v int, PRIMARY KEY (k))"";
-    private static final String CREATE_INDEX = ""CREATE INDEX v_index ON %s(v)"";
+    private static final String CREATE_INDEX = ""CREATE INDEX v_index_%d ON %s(v)"";

Review comment:
       Note: It didn't matter for the correctness of the test, but it seemed good hygiene to suffix the index names, which I think are global to the keyspace.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 19:06;githubbot;600","maedhroz commented on a change in pull request #1334:
URL: https://github.com/apache/cassandra/pull/1334#discussion_r753449233



##########
File path: test/distributed/org/apache/cassandra/distributed/test/SecondaryIndexTest.java
##########
@@ -78,31 +80,45 @@ public void after()
     }
 
     @Test
-    public void test_only_coordinator_chooses_index_for_query() throws InterruptedException, UnknownHostException
+    public void test_only_coordinator_chooses_index_for_query()
     {
         for (int i = 0 ; i < 99 ; ++i)
             cluster.coordinator(1).execute(String.format(""INSERT INTO %s (k, v) VALUES (?, ?)"", tableName), ConsistencyLevel.ALL, i, i/3);
         cluster.forEach(i -> i.flush(KEYSPACE));
 
-        for (int i = 0 ; i < 33 ; ++i)
+        Pattern indexScanningPattern =
+                Pattern.compile(String.format(""Index mean cardinalities are v_index_%d:[0-9]+. Scanning with v_index_%d."", seq.get(), seq.get()));
+
+        for (int i = 0 ; i < 33; ++i)
         {
             UUID trace = UUID.randomUUID();
             Object[][] result = cluster.coordinator(1).executeWithTracing(trace, String.format(""SELECT * FROM %s WHERE v = ?"", tableName), ConsistencyLevel.ALL, i);
-            Assert.assertEquals(3, result.length);
-            Thread.sleep(100L);
-            Object[][] traces = cluster.coordinator(1).execute(String.format(""SELECT source, activity FROM system_traces.events WHERE session_id = ?"", tableName), ConsistencyLevel.ALL, trace);
-            List<InetAddress> scanning = Arrays.stream(traces)
-                                               .filter(t -> t[1].toString().matches(""Index mean cardinalities are v_index:[0-9]+. Scanning with v_index.""))
-                                               .map(t -> (InetAddress) t[0])
-                                               .distinct().collect(Collectors.toList());
-
-            List<InetAddress> executing = Arrays.stream(traces)
-                                                .filter(t -> t[1].toString().equals(""Executing read on "" + tableName + "" using index v_index""))
-                                                .map(t -> (InetAddress) t[0])
-                                                .distinct().collect(Collectors.toList());
-
-            Assert.assertEquals(Collections.singletonList(cluster.get(1).broadcastAddress().getAddress()), scanning);
-            Assert.assertEquals(3, executing.size());
+            Assert.assertEquals(""Failed on iteration "" + i, 3, result.length);
+
+            Awaitility.await(""For all events in the tracing session to persist"")
+                    .pollInterval(100, TimeUnit.MILLISECONDS)
+                    .atMost(10, TimeUnit.SECONDS)
+                    .untilAsserted(() -> 
+                                   {
+                                       Object[][] traces = cluster.coordinator(1)
+                                                                  .execute(""SELECT source, activity FROM system_traces.events WHERE session_id = ?"", 
+                                                                           ConsistencyLevel.ALL, trace);
+
+                                       List<InetAddress> scanning =
+                                               Arrays.stream(traces)
+                                                     .filter(t -> indexScanningPattern.matcher(t[1].toString()).matches())
+                                                     .map(t -> (InetAddress) t[0])
+                                                     .distinct().collect(Collectors.toList());
+
+                                       List<InetAddress> executing =
+                                               Arrays.stream(traces)
+                                                     .filter(t -> t[1].toString().equals(String.format(""Executing read on "" + tableName + "" using index v_index_%d"", seq.get())))
+                                                     .map(t -> (InetAddress) t[0])
+                                                     .distinct().collect(Collectors.toList());
+
+                                       Assert.assertEquals(Collections.singletonList(cluster.get(1).broadcastAddress().getAddress()), scanning);
+                                       Assert.assertEquals(3, executing.size());
+                                   });

Review comment:
       It might also have been possible to make some changes to the actual Tracing implementation to force pending events to persist, but it seemed cleaner to just keep changes isolated to the test.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 19:08;githubbot;600","maedhroz commented on pull request #1334:
URL: https://github.com/apache/cassandra/pull/1334#issuecomment-974445908


   Committed as https://github.com/apache/cassandra/commit/c15f530b63a1cd4d5b2835bb418197145beb7bb6


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 20:39;githubbot;600","maedhroz closed pull request #1334:
URL: https://github.com/apache/cassandra/pull/1334


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 20:39;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,2400,,,0,2400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,maedhroz,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Nov 19 20:52:22 UTC 2021,,,,,,,All,,,,"0|z0ww0o:",9223372036854775807,,,,dcapwell,,,,Normal,,4.1,,https://github.com/apache/cassandra/commit/c15f530b63a1cd4d5b2835bb418197145beb7bb6,,,,,,,,,n/a (patch is a test-only change),,,,,"19/Nov/21 15:46;maedhroz;I think this test was introduced in CASSANDRA-16925. I'll be out most of next week, but I'll start looking around today...

CC [~benedict] [~samt];;;","19/Nov/21 19:04;maedhroz;It looks like this was just a very rare consequence of a smaller-than-necessary wait for tracing events to persist. I've made that a little more robust...

patch: https://github.com/apache/cassandra/pull/1334
CircleCI repeater: https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-17165-trunk

UPDATE: repeat jobs are clean;;;","19/Nov/21 20:39;maedhroz;Committed as https://github.com/apache/cassandra/commit/c15f530b63a1cd4d5b2835bb418197145beb7bb6;;;","19/Nov/21 20:52;dcapwell;I +1ed in PR;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix test distributed.test.trackwarnings.TombstoneWarningTest,CASSANDRA-17156,13412114,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,16/Nov/21 19:19,16/Nov/21 22:44,13/Jul/23 08:40,16/Nov/21 22:44,NA,,,,,,,Test/dtest/java,,,,0,,,"https://app.circleci.com/pipelines/github/dcapwell/cassandra/1103/workflows/9a6767c7-fadf-4d86-9296-e8973167c6fe/jobs/7897

Passed on jdk8 but failed on jdk11.

Failures

{code}
junit.framework.AssertionFailedError: expected:<...7.0.0.1=1, /127.0.0.[2=1, /127.0.0.]3=1}> but was:<...7.0.0.1=1, /127.0.0.[]3=1}>
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at org.apache.cassandra.distributed.test.trackwarnings.TombstoneWarningTest.failThreshold(TombstoneWarningTest.java:233)
	at org.apache.cassandra.distributed.test.trackwarnings.TombstoneWarningTest.failThresholdScan(TombstoneWarningTest.java:189)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{code}

and

{code}
junit.framework.AssertionFailedError: [global aborts] expected:<[2]L> but was:<[3]L>
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at org.apache.cassandra.distributed.test.trackwarnings.TombstoneWarningTest.assertWarnAborts(TombstoneWarningTest.java:294)
	at org.apache.cassandra.distributed.test.trackwarnings.TombstoneWarningTest.failThreshold(TombstoneWarningTest.java:219)
	at org.apache.cassandra.distributed.test.trackwarnings.TombstoneWarningTest.failThresholdSinglePartition(TombstoneWarningTest.java:183)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{code}",,dcapwell,maedhroz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Nov 16 20:41:34 UTC 2021,,,,,,,All,,,,"0|z0wsjs:",9223372036854775807,,,,maedhroz,,,,Low,,NA,,https://github.com/apache/cassandra/commit/aa8bb2792adb7dffc1cf0c172814bae9096a06d9,,,,,,,,,copied previous test,,,,,"16/Nov/21 19:23;dcapwell;Looking at the first one I fixed this in the other tests but not tombstone:

Tombstone:

{code}
Assertions.assertThat(e.getFailuresMap())
                      .isEqualTo(ImmutableMap.of(
                      InetAddress.getByAddress(new byte[] {127, 0, 0, 1}), RequestFailureReason.READ_TOO_MANY_TOMBSTONES.code,
                      InetAddress.getByAddress(new byte[] {127, 0, 0, 2}), RequestFailureReason.READ_TOO_MANY_TOMBSTONES.code,
                      InetAddress.getByAddress(new byte[] {127, 0, 0, 3}), RequestFailureReason.READ_TOO_MANY_TOMBSTONES.code));
{code}

Others

{code}
ImmutableSet<InetAddress> expectedKeys = ImmutableSet.of(InetAddress.getByAddress(new byte[]{ 127, 0, 0, 1 }), InetAddress.getByAddress(new byte[]{ 127, 0, 0, 2 }), InetAddress.getByAddress(new byte[]{ 127, 0, 0, 3 }));
            assertThat(e.getFailuresMap())
            .hasSizeBetween(1, 3)
            // coordinator changes from run to run, so can't assert map as the key is dynamic... so assert the domain of keys and the single value expect
            .containsValue(RequestFailureReason.READ_SIZE.code)
            .hasKeySatisfying(new Condition<InetAddress>() {
                public boolean matches(InetAddress value)
                {
                    return expectedKeys.contains(value);
                }
            });
{code}

Looking at the second test now.;;;","16/Nov/21 19:30;dcapwell;The second issue looks to be caused by the fact the first test failed earlier before the call to assertWarnAborts (has to track global state by updating a counter), so the next test fails as the global state doesn't match what the test thinks.

For this reason, only need to fix the first assert.;;;","16/Nov/21 19:52;dcapwell;The test now matches org.apache.cassandra.distributed.test.trackwarnings.AbstractClientSizeWarning, which specifically handled this problem before; but guess I forgot to fix before merge.;;;","16/Nov/21 20:23;maedhroz;+1 (with a couple of nits in the PR);;;","16/Nov/21 20:41;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17156-trunk-219C00A0-3E3D-4512-8906-002126FB10EB]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17156-trunk-219C00A0-3E3D-4512-8906-002126FB10EB]|[build|unknown]|
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Increase the buckets count for timer histogram,CASSANDRA-17155,13411918,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,yifanc,yifanc,yifanc,15/Nov/21 23:42,27/May/22 19:25,13/Jul/23 08:40,19/Nov/21 17:40,4.1,4.1-alpha1,,,,,,Observability/Metrics,,,,0,,,"EstimatedHistograms used in timers are allocated with 90 buckets, as part of CASSANDRA-16760. It can represent the highest value of 25 seconds. The setting is not free from hitting overflow error when calculating the mean value from the histogram. We can increase the buckets count to 127 to increase the upper limit to 21,356 seconds, which just covers the range of 164 buckets prior CASSANDRA-16760.",,maedhroz,yifanc,,,,,,,,,,,,,,"maedhroz commented on a change in pull request #1323:
URL: https://github.com/apache/cassandra/pull/1323#discussion_r750466232



##########
File path: src/java/org/apache/cassandra/metrics/DecayingEstimatedHistogramReservoir.java
##########
@@ -83,6 +83,7 @@
      * The default number of decayingBuckets. Use this bucket count to reduce memory allocation for bucket offsets.
      */
     public static final int DEFAULT_BUCKET_COUNT = 164;
+    public static final int FEWER_BUCKET_COUNT = 127;

Review comment:
       This is a fun naming problem. (Completely non-binding) alternatives could be `LOW_BUCKET_COUNT` or `MICRO_LATENCY_BUCKET_COUNT`. I'm fine with whatever you think sounds best though.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Nov/21 16:43;githubbot;600","yifan-c commented on a change in pull request #1323:
URL: https://github.com/apache/cassandra/pull/1323#discussion_r750724365



##########
File path: src/java/org/apache/cassandra/metrics/DecayingEstimatedHistogramReservoir.java
##########
@@ -83,6 +83,7 @@
      * The default number of decayingBuckets. Use this bucket count to reduce memory allocation for bucket offsets.
      */
     public static final int DEFAULT_BUCKET_COUNT = 164;
+    public static final int FEWER_BUCKET_COUNT = 127;

Review comment:
       OK. Let's do `LOW_BUCKET_COUNT`




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Nov/21 22:49;githubbot;600","smiklosovic closed pull request #1323:
URL: https://github.com/apache/cassandra/pull/1323


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 08:46;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,yifanc,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Nov 19 17:40:54 UTC 2021,,,,,,,All,,,,"0|z0wrcw:",9223372036854775807,,,,maedhroz,,,,Low,,4.1,,https://github.com/apache/cassandra/commit/4aab2c79b9539e8d8cfe90e4dd700b8da2f9e8a0,,,,,,,,,n/a,,,,,"16/Nov/21 00:18;yifanc;PR: https://github.com/apache/cassandra/pull/1323
CI: https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=CASSANDRA-17155%2Ftrunk

The PR increases the bucket count. ;;;","16/Nov/21 16:51;maedhroz;+1 (some minor fixes to a couple Python dtests notwithstanding);;;","16/Nov/21 22:54;yifanc;Thanks! The dtest PR: https://github.com/apache/cassandra-dtest/pull/168;;;","17/Nov/21 16:51;maedhroz;+1 on the dtest PR;;;","19/Nov/21 17:38;yifanc;The [test result|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=CASSANDRA-17155%2Ftrunk] is green. ;;;","19/Nov/21 17:40;yifanc;Committed into trunk as [4aab2c7|https://github.com/apache/cassandra/commit/4aab2c79b9539e8d8cfe90e4dd700b8da2f9e8a0];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix test TestHintedHandoff#test_hintedhandoff_window,CASSANDRA-17144,13411572,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,smiklosovic,dcapwell,dcapwell,13/Nov/21 01:02,07/Mar/23 10:38,13/Jul/23 08:40,08/Jun/22 09:13,4.1.x,4.1-beta1,5.0,,,,,Test/dtest/python,,,,0,,,"This test fails from time to time (see butler https://butler.cassandra.apache.org/#/ci/upstream/workflow/Cassandra-trunk/failure/hintedhandoff_test/TestHintedHandoff/test_hintedhandoff_window)

Example: https://app.circleci.com/pipelines/github/dcapwell/cassandra/1101/workflows/7afb1c7e-8330-4ac6-963d-d7864282f2f3/jobs/7877

{code}
        # Ensure second and third datasets are not present
        for x in range(100, 300):
>           query_c1c2(session, x, ConsistencyLevel.ONE, tolerate_missing=True, must_be_missing=True)

hintedhandoff_test.py:264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tools/data.py:44: in query_c1c2
    assertions.assert_length_equal(rows, 0)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

object_with_length = [Row(c1='value1', c2='value2')], expected_length = 0

    def assert_length_equal(object_with_length, expected_length):
        """"""
        Assert an object has a specific length.
        @param object_with_length The object whose length will be checked
        @param expected_length The expected length of the object
    
        Examples:
        assert_length_equal(res, nb_counter)
        """"""
        assert len(object_with_length) == expected_length, \
            ""Expected {} to have length {}, but instead is of length {}""\
>           .format(object_with_length, expected_length, len(object_with_length))
E       AssertionError: Expected [Row(c1='value1', c2='value2')] to have length 0, but instead is of length 1

tools/assertions.py:269: AssertionError
{code}",,adelapena,dcapwell,e.dimitrova,maedhroz,smiklosovic,,,,,,,,,,,"smiklosovic closed pull request #197: CASSANDRA-17144
URL: https://github.com/apache/cassandra-dtest/pull/197


;08/Jun/22 09:16;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,CASSANDRA-17891,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,smiklosovic,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Sep 14 15:02:20 UTC 2022,,,,,,,All,,,,"0|z0wp80:",9223372036854775807,,,,brandon.williams,maedhroz,,,Normal,,4.1-alpha1,,https://github.com/apache/cassandra-dtest/commit/eb4c12f2ade07ab8beaa12a4d70bec99dd1a6ebb,,,,,,,,,updated dtest,,,,,"16/Nov/21 03:01;e.dimitrova;One more example:

https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1200/workflows/cfd02666-56aa-4081-ad7a-09c463978d89/jobs/7198/tests#failed-test-0;;;","17/Dec/21 14:50;e.dimitrova;Java 8, with and without vnodes: 

 

[https://app.circleci.com/pipelines/github/adelapena/cassandra/1221/workflows/1ab46212-639d-40ba-a16e-05e0e3244fda/jobs/11269]

https://app.circleci.com/pipelines/github/adelapena/cassandra/1221/workflows/1ab46212-639d-40ba-a16e-05e0e3244fda/jobs/11285;;;","03/Mar/22 22:51;maedhroz;[~stefan.miklosovic] Any chance this is related to the CASSANDRA-14309 changes?;;;","18/Mar/22 19:36;e.dimitrova;Still saw It failing today: 
[https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1480/workflows/b51909eb-633e-45f1-8dcc-eb43eb48fa38/jobs/9659]

 

I didn't find in in Butler, so I guess it is more common with the midres in CircleCI;;;","02/Jun/22 20:53;e.dimitrova;Another example - [https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1686/workflows/0fd9eb9f-3074-4b21-8ba2-d8c8b83613b8/jobs/11848/tests#failed-test-0]

(I know artifacts expire in time so that's why I am posting so people have fresh examples);;;","02/Jun/22 21:01;smiklosovic;yeah I know about this one ... I ll try to take a look.;;;","03/Jun/22 14:03;smiklosovic;https://github.com/apache/cassandra-dtest/pull/197

enabledgossip / disablegossip takes some time, the commands are non-blocking but it takes time to fully enable / disable. The test fails sometimes because gossip was not shut down in a timely manner before another set of inserts in executed so there will be hints done for that as well and then it fails the asserts that such set of inserts is not there.

I have tested this in circle 100x and it was consistently not failing.

https://app.circleci.com/pipelines/github/instaclustr/cassandra/1034/workflows/e36b3ba0-adea-46e6-931f-fd88b4509576/jobs/4323;;;","03/Jun/22 14:18;brandon.williams;can we watch the log for a message instead of blindly sleeping?;;;","03/Jun/22 16:54;smiklosovic;[~brandon.williams] this is the best I can do https://github.com/apache/cassandra-dtest/pull/197/files

I put there more waiting to be sure and all but without that one 30s sleep it is flaky. I dont think there is anything specific logged I could wait for even though I am waiting for gossip to  stop and so on. I guess there is something going on in the background still.;;;","03/Jun/22 19:53;brandon.williams;bq. I guess there is something going on in the background still.

I think we need to understand what that is to know how to handle this properly.;;;","03/Jun/22 19:58;smiklosovic;I am looking more into it, there needs to be some way / log to wait for. The problem is that when StorageService asks if it should hint a mutation to the node we just turned off the gossip for, it answers ""yes"" because stuff from TokenMetadata was not removed yet. It is removed later down the road after node turns off the gossip. Indeed, it announces that it did so, but there is additional logic happening, tokens are moved around and so on and eventually it is removed from TokenMetadata. I need to find a way to somehow hook into this process.;;;","03/Jun/22 20:35;smiklosovic;I think the best solution is to not hint for nodes which have ApplicationState of ""shutdown"".

;;;","03/Jun/22 20:44;brandon.williams;That will break hints anytime a node is stopped by an operator.  ""shutdown"" just means it was done cleanly.;;;","03/Jun/22 21:06;smiklosovic;Ah interesting, I need to sleep on this. Not sure what to do here.;;;","04/Jun/22 21:31;smiklosovic;PR: https://github.com/apache/cassandra-dtest/pull/197/files
100x circle: https://app.circleci.com/pipelines/github/instaclustr/cassandra/1048/workflows/6ea00f7d-da4c-429c-b86e-fb19b865095b/jobs/4357

I am reading from Gossiper via JMX how long the node is reported to be down - in order to trigger the feature 14309 implemented. I need to wait less than max_hint_window. The hint will not be delivered, because there is already earlier hint to be delivered yet.;;;","06/Jun/22 14:56;brandon.williams;That makes sense, and this looks good. +1;;;","08/Jun/22 09:13;smiklosovic;https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1773
https://app.circleci.com/pipelines/github/instaclustr/cassandra/1050/workflows/717b6627-6f3b-49fa-8be7-1b71c573544d/jobs/4361;;;","26/Aug/22 13:48;brandon.williams;There was another failure here: https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/265/workflows/dae08562-c56e-4f25-895a-f41157c614a8/jobs/1903/tests so this may need follow up.;;;","26/Aug/22 14:03;smiklosovic;Thanks Brandon, I take a look again. Seems like 100x circle was not enough huh.;;;","26/Aug/22 14:04;e.dimitrova;I confirm I also saw it the other day and I was about to open/reopen a ticket;;;","26/Aug/22 14:05;e.dimitrova;{quote}Thanks Brandon, I take a look again. Seems like 100x circle was not enough huh.
{quote}
I normally do 500 tbh, 100 is too often not enough from my experience the past year :( ;;;","14/Sep/22 14:53;adelapena;Just seen in a run for CASSANDRA-17819: https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/285/workflows/600dcc96-5d47-48ab-bc24-e4617decff1f/jobs/2291/tests;;;","14/Sep/22 15:02;e.dimitrova;CASSANDRA-17891 opened;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix test NetstatsBootstrapWithEntireSSTablesCompressionStreamingTest#testWithStreamingEntireSSTablesWithoutCompressionWithoutThrottling,CASSANDRA-17143,13411566,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,12/Nov/21 22:55,15/Nov/21 17:33,13/Jul/23 08:40,15/Nov/21 17:33,NA,,,,,,,Test/dtest/java,,,,0,,,"https://app.circleci.com/pipelines/github/dcapwell/cassandra/1099/workflows/2f08ff99-9ea5-4023-b027-84150efbd2e9/jobs/7850

Found in CASSANDRA-17069.

What I see is that there is a race condition, which is easier to hit when we disable throttling.  If zero-copy-streaming starts and completes within the gap between nodetool calls, then the test fails with a timeout as the expected condition is not seen (waits to see streaming).  We can avoid this by detecting that streaming completed by grepping the logs.",,dcapwell,smiklosovic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Nov 15 16:54:44 UTC 2021,,,,,,,All,,,,"0|z0wp6o:",9223372036854775807,,,,dcapwell,smiklosovic,,,Normal,,NA,,https://github.com/apache/cassandra/commit/6b7166a7a12fde3c3f786608ee9a731c41a87acb,,,,,,,,,ran tests in a loop,,,,,"12/Nov/21 23:38;dcapwell;[~stefan.miklosovic] would you mind reviewing?;;;","13/Nov/21 10:01;smiklosovic;+1, fairly simple change. Thanks for taking care of that.;;;","15/Nov/21 16:53;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17143-trunk-D95E13F6-1BF2-489C-A543-64A960E26D9D]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17143-trunk-D95E13F6-1BF2-489C-A543-64A960E26D9D]|[build|unknown]|
;;;","15/Nov/21 16:54;dcapwell;I didn't run tests in Jenkins as I think it is still in bad shape; since this is just a jvm-dtest failure based off a race condition, I felt Jenkins didn't matter.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
internode_send_buff_size_in_bytes and internode_recv_buff_size_in_bytes from cassandra.yaml ,CASSANDRA-17141,13411369,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,12/Nov/21 00:35,27/May/22 19:25,13/Jul/23 08:40,16/Nov/21 20:11,4.0.2,4.1,4.1-alpha1,,,,,Build,,,,0,,,"While working on CASSANDRA-17132 I found that in 4.0 _internode_send_buff_size_in_bytes_ and _internode_recv_buff_size_in_bytes_ were renamed to 

_internode_socket_send_buffer_size_in_bytes_ and _internode_socket_receive_buffer_size_in_bytes_

but only internally, not in cassandra.yaml. In cassandra.yaml we still have the old names. 

Options I see:
 - we decide that there is difference to be acknowledged so we just rename and announce the new parameters in NEWS.txt

 - it is confirmed that just a rename was needed. Then do we want to add backward compatibility so that anyone who is still looking to start upgrade from 3 or 3.11 can directly go smoothly to 4.0.2 without breaking change? 

CC [~benedict] , [~ifesdjeen] and [~aleksey] for your opinion what will be the right way to handle this issue.

 ",,dcapwell,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17132,CASSANDRA-17160,,,CASSANDRA-15234,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Nov 16 20:11:35 UTC 2021,,,,,,,All,,,,"0|z0wnyw:",9223372036854775807,,,,dcapwell,e.dimitrova,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/44ace88585f2aefc322465ed6b6f6ad5bfd5bb34,,,,,,,,,"||[Patch 4.0|https://github.com/ekaterinadimitrova2/cassandra/tree/C17141-4.0]|[CI J8|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1199/workflows/a3f3cb0f-d341-4f01-986e-ead713fd7587/jobs/7168]|[CI J11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1199/workflows/5a5f5ec1-31f9-4af4-9ad2-d80c1e54674c]|
||[Patch trunk|https://github.com/ekaterinadimitrova2/cassandra/tree/C17141-trunk]|[CI J8|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1200/workflows/cfd02666-56aa-4081-ad7a-09c463978d89]|[CI J11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1200/workflows/70f9725d-fc27-4e8c-b6ca-39319cb68e6a]|",,,,,"12/Nov/21 14:35;e.dimitrova;As per offline discussion, the best option is to maintain both names for some time.

I will port the backward compatibility for name change from CASSANDRA-15234 to 4.0;;;","16/Nov/21 04:29;e.dimitrova;[~dcapwell] :
||[Patch 4.0|https://github.com/ekaterinadimitrova2/cassandra/tree/C17141-4.0]|[CI J8|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1199/workflows/a3f3cb0f-d341-4f01-986e-ead713fd7587/jobs/7168]|[CI J11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1199/workflows/5a5f5ec1-31f9-4af4-9ad2-d80c1e54674c]|
||[Patch trunk|https://github.com/ekaterinadimitrova2/cassandra/tree/C17141-trunk]|[CI J8|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1200/workflows/cfd02666-56aa-4081-ad7a-09c463978d89]|[CI J11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1200/workflows/70f9725d-fc27-4e8c-b6ca-39319cb68e6a]|

There are only a few failures - two failures with java 8 which are the well known bootstrap tests and the python upgrade tests for which we also have a ticket already. 

*4.0 failures:*

_readWriteDuringBootstrapTest_ - CASSANDRA-17139

_bootstrapTest_ - CASSANDRA-17076

_Python upgrade tests_ - CASSANDRA-17086, CASSANDRA-17140, CASSANDRA-17080

 

*trunk failures:*

_TestHintedHandoff#test_hintedhandoff_window_ - CASSANDRA-17144
_testWithoutStreamingEntireSSTablesWithCompression_ - fix for this one was just committed when I pushed the patch

 ;;;","16/Nov/21 16:41;dcapwell;overall LGTM, small comments in the 4.0 patch (trunk has the same feedback, just make sure trunk gets the same changes);;;","16/Nov/21 18:04;e.dimitrova;Comments addressed, please, check. As long as you like the outcome, I will propagate them to trunk too. ;;;","16/Nov/21 18:18;dcapwell;+1 (the diff is https://github.com/apache/cassandra/compare/cassandra-4.0...ekaterinadimitrova2:C17141-4.0, this still links to commit);;;","16/Nov/21 18:20;e.dimitrova;No, it doesn't :D Seems I changed the links to branches while you were typing after you made a valid point :) Thanks. 

I will propagate to trunk and commit. ;;;","16/Nov/21 20:11;e.dimitrova;Committed to https://github.com/apache/cassandra.git

   b6f61e850c..44ace88585  cassandra-4.0 -> cassandra-4.0

   be9db0980b..670bcff596  trunk -> trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Broken test_rolling_upgrade - upgrade_tests.upgrade_through_versions_test.TestUpgrade_indev_3_0_x_To_indev_4_0_x,CASSANDRA-17140,13411366,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,yifanc,yifanc,12/Nov/21 00:04,09/Aug/22 08:42,13/Jul/23 08:40,11/Apr/22 05:09,3.0.27,3.11.13,4.0.4,4.1,4.1-alpha1,,,CI,,,,0,,,"The tests ""test_rolling_upgrade"" fail with the below error. 
 
[https://app.circleci.com/pipelines/github/yifan-c/cassandra/279/workflows/6340cd42-0b27-42c2-8418-9f8b56c57bea/jobs/1990]
 
I am able to alway produce it by running the test locally too. 
{{$ pytest --execute-upgrade-tests-only --upgrade-target-version-only --upgrade-version-selection all --cassandra-version=4.0 upgrade_tests/upgrade_through_versions_test.py::TestUpgrade_indev_3_11_x_To_indev_4_0_x::test_rolling_upgrade}}
 
{code:java}
self = <upgrade_tests.upgrade_through_versions_test.TestUpgrade_indev_3_0_x_To_indev_4_0_x object at 0x7ffba4242fd0>
subprocs = [<Process(Process-1, stopped[SIGKILL] daemon)>, <Process(Process-2, stopped[1] daemon)>]

    def _check_on_subprocs(self, subprocs):
        """"""
            Check on given subprocesses.
    
            If any are not alive, we'll go ahead and terminate any remaining alive subprocesses since this test is going to fail.
            """"""
        subproc_statuses = [s.is_alive() for s in subprocs]
        if not all(subproc_statuses):
            message = ""A subprocess has terminated early. Subprocess statuses: ""
            for s in subprocs:
                message += ""{name} (is_alive: {aliveness}), "".format(name=s.name, aliveness=s.is_alive())
            message += ""attempting to terminate remaining subprocesses now.""
            self._terminate_subprocs()
>           raise RuntimeError(message)
E           RuntimeError: A subprocess has terminated early. Subprocess statuses: Process-1 (is_alive: True), Process-2 (is_alive: False), attempting to terminate remaining subprocesses now.{code}",,bereng,blerer,brandon.williams,e.dimitrova,ifesdjeen,jmckenzie,maedhroz,yifanc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17806,,,,CASSANDRA-16262,CASSANDRA-17290,,,,,,,,,CASSANDRA-17086,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Aug 09 06:35:10 UTC 2022,,,,,,,All,,,,"0|z0wny8:",9223372036854775807,,,,jmckenzie,,,,Normal,,4.0,,https://github.com/apache/cassandra-dtest/commit/bcd094b19f8c771ea8fa4aad73fbfda72621eb4c,,,,,,,,,See PR,,,,,"08/Dec/21 01:22;e.dimitrova;[~Bereng] , as mentioned on CASSANDRA-15252 I didn't know you are looking already into this ticket so I was also bisecting today.

Now rolling upgrades are failing on 3.0, 3.11, 4.0 and trunk. 

While I agree on the date - 1st October when they started failing, I don't think it is because of CASSANDRA-15252.

I was not able to run the tests locally, getting different error, something with my python that I am not able to fix yet...

But I was digging into Jenkins, as I mentioned on the other ticket, and I found rolling upgrades not failing on 3.0 with CASSANDRA-16795, but failing with 

CASSANDRA-17014 on both 3.0 and 3.11. Please check [here|https://ci-cassandra.apache.org/job/Cassandra-3.0/204/].  for 3.0 and also failing in Jenkins for 3.11 [here|https://jenkins-cm4.apache.org/job/Cassandra-3.11/265/#showFailuresLink]

If it is not CASSANDRA-17014, then there are only two other options possible after CASSANDRA-16795 - 

CASSANDRA-16959 or CASSANDRA-14612.

Unfortunately, there is no more history in Jenkins and I can't run them locally

 ;;;","08/Dec/21 06:27;bereng;I'd rather wait you can repro locally to confirm than rely on jenkins history given the back & forth, restarts, etc that jenkins gets every now and then. Local repro seems more reliable?;;;","08/Dec/21 14:21;e.dimitrova;[~bereng] , we have two runs on the same commit showing the same failure. Hope you saw the links I posted.

I saw the good commit you had in your bisect was a commit presented only on newer branches. Can you, please, run the tests on the three commits I pointed to? Thank you in advance;;;","09/Dec/21 07:37;bereng;||Ticket||SHA||Result||command||
|CASSANDRA-17014|0c4653110d80f411d2c50445d48478967bcaa095|Pass|pytest -vv --log-cli-level=DEBUG --junit-xml=nosetests.xml --junit-prefix=dtest-upgrade -s --cassandra-dir=/tmp/cberengtrunk --execute-upgrade-tests-only --upgrade-target-version-only --upgrade-version-selection all upgrade_tests/upgrade_through_versions_test.py::TestUpgrade_current_2_2_x_To_indev_3_0_x::test_rolling_upgrade_with_internode_ssl|
|CASSANDRA-16959|4f8afe85bfb2633d98beed39e665463bf19b8789|Pass|same|
|CASSANDRA-14612|225a4c8faf7a2a67a1a8a360bc4efb70b36f6ae7|Pass|same|
|CASSANDRA-15252|13632e9a99e8256a565bd6919d2d11b3e476e973|Fail|same|

We're back to CASSANDRA-15252 imo;;;","10/Dec/21 03:11;e.dimitrova;As we talked, I tested also in CircleCI:
 * [https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1242/workflows/2aa40aad-f174-413c-8c9e-2cb4ba9790ea/jobs/7457] - this is CASSANDRA-15252 --> fail
 * [https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1243/workflows/9004656f-9d9d-4457-9e31-143fee8ed167/jobs/7461] - this is CASSANDRA-14612 --> fail
 * [https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1244/workflows/800e27c1-941e-4cf5-b1b2-76b4b1ad6b2b/jobs/7466] - this is CASSANDRA-17014 --> fail
 * this is CASSANDRA-16959 --> haven't finished yet, will revise it tomorrow;;;","10/Dec/21 06:17;bereng;Aha that's sthg new... and weird it doesn't match local repro.;;;","10/Dec/21 10:15;bereng;Ok so this is a bit crazy. I went as far as April in 3.0 and {{upgrade_tests/upgrade_through_versions_test.py::TestProtoV3Upgrade_AllVersions_EndsAt_3_11_X::test_rolling_upgrade}} will fail locally. Whereas other tests like the ones above start failing on 15252. So some tests will start failing sooner or later depending on which one you run.

Maybe my initial intuition that this is sthg to do with dtests was not wrong. Maybe we need to bisect matching java and dtest at that time. Other than that I can only think of deep-diving into 15252 4.0 for that test that reliably switches from pass to fail at that commit. Maybe that will reveal more info as that is the only pass -> fail transition we know atm.;;;","26/Jan/22 20:11;jmckenzie;[~bereng] / [~e.dimitrova] either of you have any concerns w/me taking this on? Was unassigned but want to make sure neither of you are active on it.;;;","26/Jan/22 20:22;e.dimitrova;Hey [~jmckenzie] , thanks for checking. I am not looking into it on my end. Normally if I do I assign tickets to myself if I actively work on them or plan to work on them soon.;;;","27/Jan/22 06:07;bereng;Fell free to take it. I was taking a break due to excessive hair pulling lol. Happy to have sbdy else help give it a go. It is an important one as it's almost the last one towards a mostly green CI.;;;","31/Jan/22 16:43;jmckenzie;Reviewed the code here and spoke with Alex Petrov. I'm going to wait for CASSANDRA-16262 to land and then rewrite this test and remove the python dtest.

I have about 1.5 pages of notes of what I'd need to change in order to have confidence in the quality and value of this test suite (removing significant duplicated code, removing runtime class creation, expanding the type of CQL generation and validation performed, improving logging on all fronts, etc), so at this point I expect rewriting it to be perhaps 50% more effort in time on calendar for significantly more value than that.;;;","01/Feb/22 05:54;bereng;[~jmckenzie] bear in mind we have a java SHA that reliably passes the test and the next one that reliably fails it. So regardless of the python test issues imo there is sthg on the java side that can trigger this failure. In other words, you might rewrite this into a jvm-dtest and still have it fail in the same way. Wdyt?;;;","01/Feb/22 13:34;jmckenzie;bq. you might rewrite this into a jvm-dtest and still have it fail in the same way. Wdyt?
I think this test is very brittle, overly complex, and hard enough to debug failures on as to be essentially not worth doing. I'm fine with it failing on a rewrite; I'll be able to debug it significantly faster and with much less cognitive burden.;;;","14/Mar/22 19:16;maedhroz;Just for visibility (as I'm not sure it would directly affect this Jira), I have some cleanup to the dtest upgrade manifest pending in CASSANDRA-17362.;;;","15/Mar/22 13:19;jmckenzie;Thanks for the heads up; planning on circling back to this hopefully later this week.;;;","16/Mar/22 06:00;bereng;This would be a release blocker. If you don't get anywhere let me know and I'll give another go.;;;","17/Mar/22 15:53;jmckenzie;{quote}This would be a release blocker.
{quote}
Every failing test is a release blocker now. :);;;","18/Mar/22 05:33;bereng;Didn't we introduce a wording such as 'except well known offenders we've tried for years to fix without success'?;;;","18/Mar/22 17:55;jmckenzie;Regardless, I've been swamped. If you want to swap [~bereng] (you take assignee I'll take review) on this one I'm happy to hand it off.;;;","25/Mar/22 10:33;bereng;This is what I've found so far:
- Dirty reverting 15252 on 4.0 [fixes|https://app.circleci.com/pipelines/github/bereng/cassandra/628/workflows/59274d2f-8346-4d53-8e69-c7d4cf2a5080] 50% of these tests. The other non-upgrade failures seem related to the revert itself and I don't think it adds any new significant failures.
- The other upgrade 50% failures seems to pass locally if I also dirty revert 3.11. That makes sense as being an upgrade test both versions need to be on the same page regarding pstmnts UUIDS.
- Seems like a dirty revert would fix these and not introduce new failures but would obviously resuscitate 15252's original bug.

This means we have an option to dirty revert, which I am not fully aware of the consequences and it's also quite involved. The other option is to deep dive into 15252 and try to fix it properly. I'll let this simmer during the weekend but I guess the best would be to revert until sbdy has bandwidth to tackle a fix for 15252. I would ask first to the 15252's authors if they see a problem with this or if they want to try a fix first.

Who'd be willing to be a reviewer here?;;;","25/Mar/22 11:10;brandon.williams;Just to round out the branches here, we also know that 15252 has broken two tests on 3.0: CASSANDRA-17349, CASSANDRA-17328.;;;","25/Mar/22 15:47;jmckenzie;Ping [~ifesdjeen] and [~marcuse] - have an opinion on how to proceed?;;;","28/Mar/22 07:43;bereng;Brandon pointed me that as this has already been released reverting is not an option. Hence a fix is needed, thx Josh for pinging them, you were faster :-);;;","30/Mar/22 08:09;bereng;Just adding a note to myself here and to whoever else it might be useful

{noformat}
Error:
ID mismatch while trying to reprepare (expected b'6adce641dda5efd3e3c427f94a11e358', got b'eac9d72796ebeeb41ba1bbb906493a91'). This prepared statement won't work anymore. This usually happens when you run a 'USE...' query after the statement was prepared.

4.0 repro
pytest -vv --log-cli-level=DEBUG --junit-xml=nosetests.xml --junit-prefix=dtest-upgrade -s --cassandra-dir=../17140 --execute-upgrade-tests-only --upgrade-target-version-only --upgrade-version-selection all upgrade_tests/upgrade_through_versions_test.py::TestUpgrade_current_3_0_x_To_indev_4_0_x::test_rolling_upgrade_with_internode_ssl

3.11 + 4.0 repro
pytest -vv --log-cli-level=DEBUG --junit-xml=nosetests.xml --junit-prefix=dtest-upgrade -s --cassandra-dir=../17140 --execute-upgrade-tests-only --upgrade-target-version-only --upgrade-version-selection all upgrade_tests/upgrade_through_versions_test.py::TestProtoV3Upgrade_AllVersions_RandomPartitioner_EndsAt_3_11_X_HEAD::test_rolling_upgrade_with_internode_ssl
{noformat}
;;;","31/Mar/22 07:28;bereng;[~ifesdjeen] or [~marcuse] do you think you'll have a gap to look into this?;;;","31/Mar/22 08:56;ifesdjeen;Just for my understanding - what are the exact versions we're upgrading through? All versions participating in the upgrade have to have 15252 + 17248 applied.  Besides, all of these tests can be fixed relatively easily by just not using `USE`. ;;;","31/Mar/22 09:18;bereng;[~ifesdjeen] thx for replying. These failures I can see currently in ci jenkins for 3.0, 3.11, 4.0 and trunk branches so they have both 15252 and 17248 applied. The question here is whether this is a legit bug that needs fixing? At face value and me not having been involved in those tickets it looks like so, rather than making the tests pass by removing the usage of {{USE}} (if that were the fix). That would also mean in mixed clusters we shouldn't use {{USE}}?;;;","04/Apr/22 10:45;ifesdjeen;We did mixed-mode testing, but could not commit the mixed mode test because the version of driver we have in-tree does not support binding to a specific node via setting host in statement. This testing has shown no persistent errors. What you're showing is a transient exception. When the driver get updated, we can run test again. For now, I'm fairly confident in this patch. If you want to dig deeper - please feel free. 

I personally think python upgrade dtests should go away and it's best to spend time migrating them than fixing them.

UPDATE: inserted missing [s] letters ;;;","04/Apr/22 11:42;blerer;{quote} I personally think python upgrade dtests should go away and it's best to spend time migrating them than fixing them.{quote}

Unfortunately it is not the same amount of work on both side. As we have less than a month before the freeze throwing away the python upgrade tests is not an option that we can consider at this point. Those test have catched real problems that other tests missed.

[~ifesdjeen] from what I understood of the patch it was supposed to handle those mix version cluster so I do not understand why the tests are suddenly failing. What did I miss?;;;","04/Apr/22 13:09;ifesdjeen;bq. Unfortunately it is not the same amount of work on both side. 

I think it may be less work to write a new test that does more than to keep fixing this one. I'm not suggesting everyone to do this, I'm saying I think it's just a more productive thing to do. In other words, next dtest I'll be fixing, I'll just port right away. I realise my wording did not reflect that precisely. Sorry for not being specific.

bq. What did I miss? 

I've mentioned above that this error should be transient. In other words, even though there's a chance of asynchronously switching to new hash version between the nodes because there's no single moment when all nodes agree on the version, but every node [flips behaviour|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/cql3/QueryProcessor.java#L636] at its own time. In other words, we switch and star returning a new hash. First query with old hash (for example, immediately after bounce), will fail with digest mismatch. However, while failing, it will also [prepare both hashes|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/cql3/QueryProcessor.java#L680-L683], and subsequent query will ""just"" succeed. I think we've also explained this [while working on the patch|https://github.com/apache/cassandra/commit/242f7f9b18db77bce36c9bba00b2acda4ff3209e#diff-3ce9f6c4626262d6a4be26ecf3a57ef11fdb55537448def0c736115417487115R438].

So I can see two ways out of this: 
1. *Avoid mismatches.* Because [this case|https://github.com/apache/cassandra/commit/242f7f9b18db77bce36c9bba00b2acda4ff3209e#diff-3ce9f6c4626262d6a4be26ecf3a57ef11fdb55537448def0c736115417487115R487] is the only one where we won't change the hash, I was suggesting removing `USE` (this would mean that during prepare and after upgrade {{qualifiedWithKeyspace}} will be null, and we'll return {{qualifiedWithoutKeyspace}} in both cases) and add keyspace to the executed statements.
2. *Retry on mismatches.* Simply add a retry that would tolerate failures during diverged gossip state, and retry failed query.

In other words, I believe there's no bug in the code and we did validate this behaviour and made sure it's transitory. It's just that at that particular moment I can not allocate time to fix this dtest, for which I'm sorry and hope you'll understand. Hope you find this explanation satisfactory.;;;","05/Apr/22 08:35;bereng;[~ifesdjeen] thx a lot for the feedback!

The root problem is that coming to the ticket with a blank sheet of paper it is just a cross-roads where every road looks just like the other bc lack of context: Is it a legit bug? is it ok to revert? what would reverting break? Is it reasonable avoiding the usage of {{USE}}? Is a retry a valid option?... It's a lot of work (and duplication) having to find out all that by oneself, whereas sbdy that has worked on the ticket can probably answer which path to investigate and which one to not look into. I was seeing the trees but not the forest.

Having said that now I have sthg to work with which is looking good locally. Fingers crossed and thx again!;;;","05/Apr/22 14:14;ifesdjeen;Glad this helped. Thank you very much for looking into it and sorry we didn't catch this during the review/test run.
;;;","08/Apr/22 15:36;jmckenzie;+1 [~bereng]. Thanks for taking this on!;;;","11/Apr/22 05:09;bereng;Yesssss. Done. Thanks all for the help :-);;;","27/Jul/22 20:30;maedhroz;Is this failing again (the same way) on 4.1?

https://ci-cassandra.apache.org/job/Cassandra-4.1/115/testReport/dtest-upgrade.upgrade_tests.upgrade_through_versions_test/TestProtoV3Upgrade_AllVersions_RandomPartitioner_EndsAt_3_11_X_HEAD/test_rolling_upgrade/;;;","08/Aug/22 10:35;bereng;The failure was the test spawning 4 (iirc) processes that would fail unexpectedly. I covered 2 of those processes where I thought the action was but I might as well have to extend the fix to the other 2... Will check soon.;;;","09/Aug/22 06:35;bereng;I really dislike creating a new ticket CASSANDRA-17806 for this, I should reopen and fix, but given the span in time, we have a new trunk, etc I thought it would be easier to follow history with a new ticket and not entangle this one further.

Edit: new ticket ready for a quick review as it's the same fix as here #justfyi;;;",,,,,,,,,,,,,,,,
utests_system_keyspace_directory - more than 500 tests failing on trunk,CASSANDRA-17137,13411181,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,e.dimitrova,e.dimitrova,11/Nov/21 03:21,27/May/22 19:25,13/Jul/23 08:40,19/Nov/21 10:45,4.1,4.1-alpha1,,,,,,CI,,,,0,,,"I have more than 500 tests failing on trunk [with the new|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1194/workflows/5fb2b193-d99a-4168-b10d-f7a3a05a3abf/jobs/7136] and [with the old image|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1189/workflows/416dcd5e-720e-4eca-b3d5-61767906457b/jobs/6984/tests#failed-test-1] - please check under {_}utests_system_keyspace_directory{_}. ",,bereng,e.dimitrova,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17134,CASSANDRA-17145,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Nov 19 10:40:52 UTC 2021,,,,,,,All,,,,"0|z0wmt4:",9223372036854775807,,,,samt,,,,Normal,,4.1,,https://github.com/apache/cassandra/commit/8d3fd3a97c5e277c80c846d3aa7b679018e8fab5,,,,,,,,,See PR,,,,,"12/Nov/21 07:08;bereng;Mmmm they pass locally on a quick test...;;;","18/Nov/21 05:57;bereng;[~blerer] investigating CASSANDRA-17145 I ended up starting to fix this one. Had you already started here? do you mind I take over?;;;","19/Nov/21 08:31;bereng;Stolen from Benjamin as agreed on Slack.

Please see comments [here|https://issues.apache.org/jira/browse/CASSANDRA-17145?focusedCommentId=17445100&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17445100] and [here|https://issues.apache.org/jira/browse/CASSANDRA-17145?focusedCommentId=17445151&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17445151]

[~samt] This is just the same issue you reviewed on CASSANDRA-17145 but it needed to be fixed in this ticket instead. If you get gap maybe you could be the reviewer as you already know the story.;;;","19/Nov/21 10:01;samt;lgtm, thanks [~bereng]. (one request: do you mind linking the CI from a Jira comment? It's not essential and no great hardship to click through to the PR, but I think it's useful to have it linked directly from here)  ;;;","19/Nov/21 10:40;bereng;Thx for the review [~samt]!

I _always_ try to avoid linking CI in a comment bc that makes it very difficult (at least for me) to match CI runs comments to actual commits. Whereas putting everything in a PR serves as a timeline. The CI for a SHA is immediately there and If there is no CI after the last SHA you forgot about it! lol Anyway personal preference but I can add it for you:

CI system KS [tests|https://app.circleci.com/pipelines/github/bereng/cassandra/505/workflows/b44c9b93-c2cc-44a3-9594-52d28d228893/jobs/4576] lgtm now
CI [j8|https://app.circleci.com/pipelines/github/bereng/cassandra/505/workflows/787aecda-702d-443c-a3da-e8feb630d41f] lgtm
CI [j11|https://app.circleci.com/pipelines/github/bereng/cassandra/505/workflows/13231d78-c732-49d9-bbb7-178db95ce8f8] lgtm;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FQL: Enabling via nodetool can trigger disk_failure_mode,CASSANDRA-17136,13411163,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,bcicchi,bcicchi,11/Nov/21 01:06,09/Dec/21 22:10,13/Jul/23 08:40,09/Dec/21 22:10,4.0.2,,,,,,,Tool/fql,,,,0,,,"When enabling fullquerylog via nodetool, if there is a non empty directory present under the location specified via --path which would trigger an java.nio.file.AccessDeniedException during cleaning, the node will trigger the disk_failure_policy which by default is stop. This is a fairly easy way to offline a cluster if someone executes this in parallel. I don't that think the behavior is desirable for enabling via nodetool.

 

Repro (1 node cluster already up):
{code:bash}
mkdir /some/path/dir
touch /some/path/dir/file
chown -R user: /some/path/dir # Non Cassandra process user
chmod 700 /some/path/dir
nodetool enablefullquerylog --path /some/path
{code}
Nodetool will give back this error:
{code:java}
error: /some/path/dir/file
-- StackTrace --
java.nio.file.AccessDeniedException: /some/path/dir/file
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:244)
	at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)
	at java.nio.file.Files.delete(Files.java:1126)
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:250)
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:237)
	at org.apache.cassandra.utils.binlog.BinLog.deleteRecursively(BinLog.java:492)
	at org.apache.cassandra.utils.binlog.BinLog.cleanDirectory(BinLog.java:477)
	at org.apache.cassandra.utils.binlog.BinLog$Builder.build(BinLog.java:436)
	at org.apache.cassandra.fql.FullQueryLogger.enable(FullQueryLogger.java:106)
	at org.apache.cassandra.service.StorageService.enableFullQueryLogger(StorageService.java:5915)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)
	at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:252)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:819)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:801)
	at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1468)
	at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:76)
	at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1309)
	at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1401)
	at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:829)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:357)
	at sun.rmi.transport.Transport$1.run(Transport.java:200)
	at sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:573)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:834)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:688)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:687)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}
On the Cassandra side, we see the following:
{code:java}
INFO  [RMI TCP Connection(2)-10.101.33.87] 2021-11-11 00:55:40,716 BinLog.java:420 - Attempting to configure bin log: Path: /some/path Roll cycle: HOURLY Blocking: true Max queue weight: 268435456 Max log size:17179869184 Archive command:
INFO  [RMI TCP Connection(2)-10.101.33.87] 2021-11-11 00:55:40,720 BinLog.java:433 - Cleaning directory: /some/path as requested
ERROR [RMI TCP Connection(2)-10.101.33.87] 2021-11-11 00:55:40,724 DefaultFSErrorHandler.java:64 - Stopping transports as disk_failure_policy is stop
ERROR [RMI TCP Connection(2)-10.101.33.87] 2021-11-11 00:55:40,725 StorageService.java:453 - Stopping native transport
INFO  [RMI TCP Connection(2)-10.101.33.87] 2021-11-11 00:55:40,730 Server.java:171 - Stop listening for CQL clients
ERROR [RMI TCP Connection(2)-10.101.33.87] 2021-11-11 00:55:40,730 StorageService.java:458 - Stopping gossiper
WARN  [RMI TCP Connection(2)-10.101.33.87] 2021-11-11 00:55:40,731 StorageService.java:357 - Stopping gossip by operator request
INFO  [RMI TCP Connection(2)-10.101.33.87] 2021-11-11 00:55:40,731 Gossiper.java:1984 - Announcing shutdown
{code}",,bcicchi,bereng,e.dimitrova,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Availability -> Response Crash,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Dec 09 22:10:29 UTC 2021,,,,,,,All,,,,"0|z0wmp4:",9223372036854775807,,,,bereng,,,,Critical,,4.0.0,,https://github.com/apache/cassandra/commit/aa82e3e4277397dbf630c7b805c5aaca22d660ad,,,,,,,,,Run CI,,,,,"11/Nov/21 02:54;brandon.williams;This sounds fairly serious from the description, setting the severity accordingly.;;;","11/Nov/21 20:25;brandon.williams;Hmm, it seems there is some other element to this, as I can't repro with the steps provided:

{noformat}
$ bin/nodetool  enablefullquerylog --path /tmp/test
error: null
-- StackTrace --
java.lang.NullPointerException
        at org.apache.cassandra.utils.binlog.BinLog.deleteRecursively(BinLog.java:490)
        at org.apache.cassandra.utils.binlog.BinLog.cleanDirectory(BinLog.java:477)
        at org.apache.cassandra.utils.binlog.BinLog$Builder.build(BinLog.java:436)
        at org.apache.cassandra.fql.FullQueryLogger.enable(FullQueryLogger.java:106)
        at org.apache.cassandra.service.StorageService.enableFullQueryLogger(StorageService.java:5929)
{noformat}

But the solution is likely the same: [branch|https://github.com/driftx/cassandra/tree/CASSANDRA-17136], [CI|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17136].  I'd still like to reproduce and also check the audit log for the same issue.;;;","12/Nov/21 14:20;bcicchi;Okay here are the exact commands that repro the issue for me on 4.0.1 (checked centos and ubuntu just in case). All commands run as root:
{code:java}
mkdir -p /tmp/dir/
chown cassandra:cassandra /tmp/dir
mkdir /tmp/dir/sub
touch /tmp/dir/sub/file
nodetool enablefullquerylog --path /tmp/dir {code}
Let me know if that does not work. Here are the permissions:
{code:java}
/tmp/dir:
total 12
drwxr-xr-x  3 cassandra cassandra 4096 Nov 12 14:18 .
drwxrwxrwt 16 root      root      4096 Nov 12 14:18 ..
drwxr-xr-x  2 root      root      4096 Nov 12 14:18 sub

/tmp/dir/sub:
total 8
drwxr-xr-x 2 root      root      4096 Nov 12 14:18 .
drwxr-xr-x 3 cassandra cassandra 4096 Nov 12 14:18 ..
-rw-r--r-- 1 root      root         0 Nov 12 14:18 file {code};;;","16/Nov/21 16:44;brandon.williams;Thanks, that works.  This is a fairly rare and specific set of circumstances, and the policy is triggered by deleteWithConfirm, which I assume was chosen intentionally in this situation, so I'm not sure we should fix this, though it would be nice to not have it triggered via JMX. [~marcuse] wdyt?;;;","17/Nov/21 02:38;bcicchi;So the thing that got me to uncover this was that {{fqltool dump}} command can very conveniently create a directory layout just like the one above. So an example scenario would only have to be this:
{code:java}
mkdir /tmp/dir
chown cassandra:cassandra /tmp/dir
cd /tmp/dir
fqltool dump # ... whoops, that was accidental (copy paste, bash history line, or just general badness, etc..)
nodetool enablefullquerylog --path /tmp/dir # Node is now down{code}
Directory structure:
{code:java}
/tmp/dir:
total 12
drwxr-xr-x  3 cassandra cassandra 4096 Nov 17 02:18 .
drwxrwxrwt 15 root      root      4096 Nov 17 02:18 ..
drwxr-xr-x  2 root      root      4096 Nov 17 02:18 cassandra.logdir_IS_UNDEFINED/tmp/dir/cassandra.logdir_IS_UNDEFINED:
total 8
drwxr-xr-x 2 root      root      4096 Nov 17 02:18 .
drwxr-xr-x 3 cassandra cassandra 4096 Nov 17 02:18 ..
-rw-r--r-- 1 root      root         0 Nov 17 02:18 debug.log
-rw-r--r-- 1 root      root         0 Nov 17 02:18 system.log {code}
I personally don't think the path to hit this is all that difficult to do for an operator.;;;","17/Nov/21 07:13;marcuse;This sounds like a bug to me, looks like we only {{cleanDirectory}} when enabling FQL via JMX, so we can probably just catch the exception and let the user know.

[~brandon.williams] feel free to reassign this to me

;;;","17/Nov/21 17:58;brandon.williams;bq. So the thing that got me to uncover this was that fqltool dump command can very conveniently create a directory layout just like the one above.

Aha, I see.

bq. looks like we only cleanDirectory when enabling FQL via JMX, so we can probably just catch the exception and let the user know.

cleanDirectory is what calls the JVMStabilityInspector, so instead I disabled it when called via JMX.

||Branch||CI||
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-17136]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17136], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1285/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1285/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-17136]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17136-trunk], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1285/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1286/pipeline]|
;;;","17/Nov/21 22:21;brandon.williams;This broke some FullQueryLoggerTests I'll look into.;;;","18/Nov/21 17:13;brandon.williams;I created an enableWithoutClean method for JMX to use.

||Branch||CI||
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-17136]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17136], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1287/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1287/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-17136]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17136-trunk], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1288/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1288/pipeline]|;;;","22/Nov/21 08:39;bereng;Couldn't we add a quick test at least checking the folder was/wasn't cleaned?;;;","06/Dec/21 19:23;brandon.williams;We can't reproduce exactly the same error without being able to become another unix user, but I added a dtest [here|https://github.com/driftx/cassandra-dtest/tree/CASSANDRA-17136] that reproduces the NPE by reducing permissions.

[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1309/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1309/pipeline]
;;;","09/Dec/21 06:56;bereng;^ lgtm. I would add a comment in the test explaining why the file and permissions change, otherwise it's difficult to grasp without the context of the ticket. ^This is only the 4.0 CI run so +1 conditioned to a successful trunk CI.;;;","09/Dec/21 15:21;brandon.williams;[circle for trunk|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17136-trunk]. I'll check back later to commit if that's good.;;;","09/Dec/21 17:33;brandon.williams;Heh, circle fails the teardown with this test:

bq. PermissionError: [Errno 13] Permission denied: 'baddir'

I've updated the test to change the permissions back afterward, circle is [running|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17136-trunk] again.;;;","09/Dec/21 22:10;brandon.williams;Test run looks good now, committed.  Thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Broken test_timeuuid - upgrade_tests.cql_tests,CASSANDRA-17133,13411117,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,frankgh,yifanc,yifanc,10/Nov/21 17:38,27/May/22 19:24,13/Jul/23 08:40,19/Jan/22 22:34,4.1,4.1-alpha1,,,,,,CQL/Semantics,,,,0,,,"Both CircleCI and Jenkins build failed at test_timeuuid with the following error.

{quote}cassandra.InvalidRequest: Error from server: code=2200 [Invalid query] message=""Ambiguous call to function maxtimeuuid (can be matched by following signatures: system.maxtimeuuid : (bigint) -> timeuuid, system.maxtimeuuid : (timestamp) -> timeuuid): use type casts to disambiguate""{quote}

https://app.circleci.com/pipelines/github/yifan-c/cassandra/273/workflows/7a855174-823a-4553-ad09-25623747a58e/jobs/1884/tests#failed-test-0

https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1272/tests/

The change was added in CASSANDRA-17029. ",,bereng,blerer,brandon.williams,frankgh,subkanthi,yifanc,,,,,,,,,,"frankgh opened a new pull request #1409:
URL: https://github.com/apache/cassandra/pull/1409


   There are two commits to this PR:
   1. Reverts commit 8ddcd43 
   2. Preserve tests from 8ddcd43 that use biting numbers


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jan/22 19:45;githubbot;600","smiklosovic closed pull request #1409:
URL: https://github.com/apache/cassandra/pull/1409


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 08:30;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,CASSANDRA-17029,,,,,,,,,,,,,,,,,,,,,,,,,0.0,frankgh,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jan 20 06:31:25 UTC 2022,,,,,,,All,,,,"0|z0wmew:",9223372036854775807,,,,brandon.williams,ycai,,,Normal,,NA,,https://github.com/apache/cassandra/commit/0dc5a289e8dd586150253d951e6e229480c0ffc8,,,,,,,,,"Created PR here.

https://github.com/apache/cassandra-dtest/pull/171/files",,,,,"10/Nov/21 17:45;yifanc;[~kanthis], would you like to take a look?;;;","10/Nov/21 17:46;brandon.williams;Strangely it didn't fail when it was tested [here|https://app.circleci.com/pipelines/github/blerer/cassandra/239/workflows/32b4bc10-685a-4719-ac6c-950e76cd9533].;;;","10/Nov/21 17:49;yifanc;The linked [run|https://app.circleci.com/pipelines/github/blerer/cassandra/239/workflows/32b4bc10-685a-4719-ac6c-950e76cd9533] did not run j8_upgradetests-no-vnodes;;;","21/Nov/21 04:26;subkanthi;[~yifanc] will take a look, sorry for some reason Im not notified by email when tagged.;;;","21/Nov/21 04:32;brandon.williams;Email notifications were actually not working during this time due to INFRA-22514, so don't feel bad.
;;;","27/Nov/21 01:07;subkanthi;[~yifanc] , [~brandon.williams] , cannot find this test in cassandra codebase, can you please let me know where I can find the tests and how to run it locally.
{code:java}
// code placeholder
def test_timeuuid(self):
        cursor = self.prepare()
    
        cursor.execute(""""""
                CREATE TABLE test (
                    k int,
                    t timeuuid,
                    PRIMARY KEY (k, t)
                )
            """""") {code};;;","29/Nov/21 13:48;brandon.williams;It is a python dtest, so in this repo: https://github.com/apache/cassandra-dtest/blob/trunk/upgrade_tests/cql_tests.py#L2620;;;","09/Dec/21 17:28;brandon.williams;[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17133] running.;;;","09/Dec/21 20:38;brandon.williams;Changing the test isn't the answer here, we should still be able to create timeuuids from ints.;;;","10/Dec/21 01:12;subkanthi;[~brandon.williams] , I made the same change in the unit tests too, please see here, because support for bigint was added to maxTimeuuid, the logic of picking the right function throws the ambiguous error. 

Its quite possible the user will encounter this, but I assumed its fine because the other functions work the same way.

[https://github.com/apache/cassandra/pull/1275/files]
{code:java}
-- assertEmpty(execute(""SELECT t FROM %s WHERE k = 0 AND t > maxTimeuuid(1234567) AND t < minTimeuuid('2012-11-07 18:18:22-0800')""));        

++ assertEmpty(execute(""SELECT t FROM %s WHERE k = 0 AND t > maxTimeuuid(1564830182000) AND t < minTimeuuid('2012-11-07 18:18:22-0800')"")); {code}
 

It obviously works when the number is bigint.
{code:java}
select maxTimeuuid(1564830182000) from emp; system.maxtimeuuid(1564830182000)
--------------------------------------
 42d31e0f-b5de-11e9-7f7f-7f7f7f7f7f7f
 {code}
The reason is this logic here, 
Because bigint and timestamp gets the WEAKLY_ASSIGNABLE when the parameter is integer.

https://issues.apache.org/jira/browse/CASSANDRA-17029
 
{code:java}
case INTEGER:
// code placeholdercase INTEGER:
    switch (nt)
    {
        case BIGINT:
        case COUNTER:
        case DATE:
        case DECIMAL:
        case DOUBLE:
        case DURATION:
        case FLOAT:
        case INT:
        case SMALLINT:
        case TIME:
        case TIMESTAMP:
        case TINYINT:
        case VARINT:
            return AssignmentTestable.TestResult.WEAKLY_ASSIGNABLE;
{code}
The tounixtimestamp function which wasnt changed as part of this PR also has the same problem.
{code:java}
// code placeholder
select toUnixTimestamp(123) from emp;
InvalidRequest: Error from server: code=2200 [Invalid query] message=""Ambiguous call to function tounixtimestamp (can be matched by following signatures: system.tounixtimestamp : (timestamp) -> bigint, system.tounixtimestamp : (date) -> bigint): use type casts to disambiguate""
 {code}
It will definitely be great if we can check for int and cast to bigint, but not sure where it can be done because the testAssignment function is first called.;;;","10/Dec/21 01:36;brandon.williams;I agree, and I'm sorry this was missed during review.  I think we're probably already handling this with similar cases somewhere but I'll have to look later. /cc [~blerer];;;","10/Dec/21 13:08;blerer;I had a look at the code and it seems that the mistake is mine. We did not need to add those new functions in CASSANDRA-17029 as the functionality was already there.
We had the following functions:
* toDate(timestamp)
* toTimestamp(date)
* mintimeuuid(timestamp)
* maxtimeuuid(timestamp)

Those functions were not overloaded so they will be the ones being picked up but the code allow deserialization from integer to the timestampt type or the date type.
by consequence adding new function was not needed and in fact lead to a slightly different behavior. What I would suggest it to remove the methods added by CASSANDRA-17029 and modify the tests to verify the behavior with int an long inputs.
Sorry for not realizing that sooner. :-( 


  ;;;","10/Dec/21 18:17;subkanthi;Thanks [~blerer] and [~brandon.williams]  for reviewing it again, should I be creating a PR to remove the functions and tests or is there anyway u can revert the commit. Please let me know.

 ;;;","10/Jan/22 06:25;bereng;Hi [~subkanthi], I was wondering if you are ok here and still planning on completing this or do you need some help?;;;","11/Jan/22 15:11;subkanthi;Hi [~bereng] , As suggested by [~blerer] , the plan is to rollback the change. I wanted to check if there is a way to revert it or I can create a PR that removes those changes, please let me know.;;;","11/Jan/22 15:30;brandon.williams;Whoever commits can revert CASSANDRA-17029, that is simple.  I think all we need here is the second part of what Benjamin said, ""modify the tests to verify the behavior with int and long inputs."";;;","19/Jan/22 08:09;bereng;[~subkanthi] if I were you I would put the revert of 17029 into it's own commit in the PR, then complete the PR with what Benjamin and Brandon mention it's missing. But feel free to take whatever route fits you best. Let me know if it's not clear and I can give it a go if you don't mind.;;;","19/Jan/22 18:32;frankgh;[~bereng], [~subkanthi] I have a patch on my local with two commits, one reverts 17029, and the other one modifies the tests to verify the behavior with int and long inputs (basically preserving the tests with long values introduced in 17029).

Let me know if you'd like me to contribute that patch.;;;","19/Jan/22 19:16;brandon.williams;[~frankgh] please go ahead and post it!;;;","19/Jan/22 19:48;frankgh;PR: https://github.com/apache/cassandra/pull/1409
CI: https://app.circleci.com/pipelines/github/frankgh/cassandra?branch=CASSANDRA-17133&filter=all;;;","19/Jan/22 21:05;brandon.williams;Failures are known or incidental timeouts, +1.;;;","19/Jan/22 22:21;yifanc;+1;;;","19/Jan/22 22:34;brandon.williams;Committed (w/revert on its own commit), thanks!;;;","20/Jan/22 06:31;bereng;Yes! Thx all :-);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix startup issue with internode_application_timeout_in_ms,CASSANDRA-17132,13410922,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,09/Nov/21 21:16,27/May/22 19:25,13/Jul/23 08:40,16/Nov/21 15:46,4.0.2,4.1,4.1-alpha1,,,,,Build,,,,0,,,"While testing my patch for CASSANDRA-17131 I found that there is a problem with _internode_application_timeout_in_ms_ in 4.0 and trunk.

Seems to me that we can just safely remove it for now?",,benedict,bereng,e.dimitrova,jjirsa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-15234,,,,CASSANDRA-17135,CASSANDRA-17141,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Feb 11 23:32:15 UTC 2022,,,,,,,All,,,,"0|z0wl7k:",9223372036854775807,,,,bereng,,,,Low,,4.0,,https://github.com/apache/cassandra/commit/b6f61e850c8cfb1f0763e0f15721cde8893814b5,,,,,,,,,"[4.0 patch |https://github.com/ekaterinadimitrova2/cassandra/pull/new/17132-4.0]| [J8 CI |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1188/workflows/06afaf5b-6951-4b3d-8fbf-6ef2aef04e52]| [J11 CI |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1188/workflows/8b8d24bc-b24e-439a-92e3-d6f4541ef9fb]

[trunk patch |https://github.com/ekaterinadimitrova2/cassandra/pull/new/17132-trunk]| [J8 CI |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1189/workflows/416dcd5e-720e-4eca-b3d5-61767906457b]| [J11 CI|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1189/workflows/40cb1de6-299d-4c6a-a162-d878d79beb67]",,,,,"09/Nov/21 21:18;e.dimitrova;I suspect this one was added with the idea to add some internals later but this never happened so we can probably just remove it for now from cassandra.yaml and the docs.

[~benedict] , can you, please, confirm? I can submit a patch;;;","10/Nov/21 03:11;e.dimitrova;I believe we also need to rename _internode_send_buff_size_in_bytes_ and _internode_recv_buff_size_in_bytes_ to 

_internode_socket_send_buffer_size_in_bytes_ and \{_}internode_socket_recv_buffer_size_in_bytes{_}.

They were refactored again as per the messaging subsystem rewrite. CC [~benedict] for confirmation;;;","10/Nov/21 03:29;e.dimitrova;I believe we also don't need {_}otc_backlog_expiration_interval_ms, otc_coalescing_strategy, otc_coalescing_window_us_default{_}, 

{_}otc_coalescing_window_us{_}. The last three are also not removed from _Config.java_ but they are not used. Sorry [~benedict], can you confirm also those, please? I believe those were the last ones with issues.;;;","10/Nov/21 11:29;benedict;Thanks [~e.dimitrova], agreed with all of the above.;;;","10/Nov/21 23:26;e.dimitrova;Thank you for confirming [~benedict] .

I just realized we also don't need _otc_coalescing_enough_coalesced_messages._

It is only used to check whether it is between 0 and 128 in the _DatabaseDescriptor_ and nothing else. I removed that check and the parameter too.

[4.0 patch |https://github.com/ekaterinadimitrova2/cassandra/pull/new/17132-4.0] | [J8 CI |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1188/workflows/06afaf5b-6951-4b3d-8fbf-6ef2aef04e52] | [J11 CI |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1188/workflows/8b8d24bc-b24e-439a-92e3-d6f4541ef9fb]

[trunk patch |https://github.com/ekaterinadimitrova2/cassandra/pull/new/17132-trunk] | [J8 CI |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1189/workflows/416dcd5e-720e-4eca-b3d5-61767906457b] | [J11 CI|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1189/workflows/40cb1de6-299d-4c6a-a162-d878d79beb67]

The docs are still in transition so I will open a followup ticket to update them in ascidoc. ;;;","10/Nov/21 23:38;e.dimitrova;Follow up ticket for the docs opened - CASSANDRA-17135;;;","11/Nov/21 21:02;e.dimitrova;I reran the java 11 python no-vnodes DTests as they were failing with ""UnavailableSocketError"", typical when lacking CircleCI resources but just in case!
[This|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1188/workflows/8b8d24bc-b24e-439a-92e3-d6f4541ef9fb/jobs/7143/tests] is the new run which confirms my theory and doesn't show any new issues except the one failure which fix is about to be merged later today.


There are already tickets opened for - {_}test_speculative_data_request - read_repair_test.TestSpeculativeReadRepair{_}, I opened CASSANDRA-17139 for {_}org.apache.cassandra.distributed.test.ring.BootstrapTest{_}. There are already tickets for the python _upgrade dtests, testNoTreesRetainedAfterDifference, replaceAliveHost - org.apache.cassandra.distributed.test.hostreplacement.HostReplacementTest, utests_system_keyspace_directory_ tests


Different bootstrap tests are failing, it seems to me bootstrapping is unstable lately. I am wondering whether not to open an umbrella ticket. What do you think?
CompactStorage tests OOM from time to time. That seems more like CircleCI config needs to be polished? [~benedict], [~dcapwell], anyone of you up for a review?;;;","12/Nov/21 00:00;e.dimitrova;[~dcapwell] made a valid comment that the rename was breaking change in 4.0.

I am pulling the rename in a separate ticket to decide on backward compatibilities, etc as I don't see a reason to delay the rest of the cleaning pending on those. 

CI stands, I can revert the rename on commit if the rest is fine.

 

 ;;;","15/Nov/21 09:23;bereng;[~e.dimitrova] your '4.0 patch' link point to a compare between _trunk_ and your 4.0 PR instead of 4.0 and your 4.0 PR #justfyi

Just a couple comments:
- I _think_ [~dcapwell] was on top of the bootstrap failures and there is some umbrella ticket somewhere already?
- The dtest failures on an address already being used I concur they are probably infra problems. I have seen than before and it sounds like a bad ccm env cleanup imo.
- Which rename is a breaking change in 4.0? {{internode_socket_send_buffer_size_in_bytes}} was changed in the code long ago and here we're only fixing the yml. it's like we're fixing a bug rather than introducing a rename right?

Otherwise lgtm.;;;","15/Nov/21 14:21;e.dimitrova;{quote}[~e.dimitrova] your '4.0 patch' link point to a compare between _trunk_ and your 4.0 PR instead of 4.0 and your 4.0 PR #justfyi
{quote}
I grabbed the link on commit but I didn't open a PR, it is just the comparison so it requires to get the 4.0 from the drop-down menu. Works perfect with trunk, but I had to open a PR for 4.0. 
{quote} - Which rename is a breaking change in 4.0? {{internode_socket_send_buffer_size_in_bytes}} was changed in the code long ago and here we're only fixing the yml. it's like we're fixing a bug rather than introducing a rename right?{quote}
The thing is that we have on one side a bug(the name not changed in cassandra.yaml), on the other one a breaking change so it is good to have the backward compatibility with the old name for people who upgrade, similar to what we did with metrics. I already pulled a ticket and agreed on the details with Benedict, Alex and Aleksey.

Thank you for the review [~bereng] ;;;","15/Nov/21 14:36;bereng;You can have a link with the right compare base as in [here|https://github.com/apache/cassandra/compare/cassandra-4.0...ekaterinadimitrova2:17132-4.0?expand=1] #justyi

Ok so iiuc that name change is seen as a bug, you've opened a ticket to address that (can you link it please?) and you'll remove that from the commits in here. Is that correct?;;;","15/Nov/21 15:00;e.dimitrova;CASSANDRA-17141 linked. True, I will remove those two renames from the current patch and handle the properties in the other ticket.;;;","16/Nov/21 06:40;bereng;Ok moved to suggest changes just for my benefit on tracking stuff until the PR gets those renames removed.;;;","16/Nov/21 11:48;bereng;Spoke on Slack that pending change will be done on commit. +1.;;;","16/Nov/21 15:46;e.dimitrova;Commit done:

03e83f2070..b6f61e850c  cassandra-4.0 -> cassandra-4.0

ad4d2b3a26..f61d817cb5  trunk -> trunk

The renaming of the two commented parameters was reverted and deferred to CASSANDRA-17141.

Thank you!;;;","11/Feb/22 22:42;jjirsa;This commit broke users upgrading from 4.0.1 to 4.0.2.

We should NOT be making breaking changes in minor versions.
We also missed the {{NEWS.txt}} entry that notifies customers of breaking changes.

;;;","11/Feb/22 23:32;e.dimitrova;CASSANDRA-17377 opened to fix this;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix formatting in  cassandra.yaml,CASSANDRA-17131,13410918,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,09/Nov/21 20:32,27/May/22 19:24,13/Jul/23 08:40,10/Nov/21 21:48,4.0.2,4.1,4.1-alpha1,,,,,Build,,,,0,,,"We have a few parameters with small formatting issues in cassandra.yaml which are not caught because by default they are commented out.

Cassandra 4.0:
 * a few parameters are added with _parameter *=* value_ instead of _parameter *:* value_

trunk:
 * same issue as in 4.0
 * few parameters added with _;_ after the value

 

 ",,e.dimitrova,jmckenzie,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-15234,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Nov 10 21:47:55 UTC 2021,,,,,,,All,,,,"0|z0wl6o:",9223372036854775807,,,,e.dimitrova,jmckenzie,,,Low,,,,https://github.com/apache/cassandra/commit/4bb6f411d8c7620aa330fd97a7d0af5973936893,,,,,,,,,"Patches:  [Cassandra 4.0|https://github.com/ekaterinadimitrova2/cassandra/pull/new/17131-4.0] | [trunk|https://github.com/ekaterinadimitrova2/cassandra/pull/new/17131-trunk]

No CI run, way to test is manually by uncommenting the parameters and trying to start Cassandra, except _internode_application_timeout_in_ms -_ seems to me that this one is an orphan. I will follow up on that separately. (CC [~benedict])",,,,,"09/Nov/21 20:51;e.dimitrova;Patches:  [Cassandra 4.0|https://github.com/ekaterinadimitrova2/cassandra/pull/new/17131-4.0] | [trunk|https://github.com/ekaterinadimitrova2/cassandra/pull/new/17131-trunk]

No CI run, way to test is manually by uncommenting the parameters and trying to start Cassandra, except _internode_application_timeout_in_ms -_ seems to me that this one is an orphan. I will follow up on that separately. (CC [~benedict])

 [~jmckenzie], can you, please, review? Thanks in advance :) ;;;","09/Nov/21 21:21;e.dimitrova;I already opened a follow up ticket for _internode_application_timeout_in_ms -_ CASSANDRA-17132

Safe removal or any other actions, we need to handle it as now uncommented, it fails Cassandra to start by saying it is unneeded.;;;","10/Nov/21 17:44;jmckenzie;+1 to both the 4.0 and trunk patches;;;","10/Nov/21 21:47;e.dimitrova;Thank you for the review.

Patch committed:

07b908c78c..4bb6f411d8  cassandra-4.0 -> cassandra-4.0

e0954fa1a8..4f112af615  trunk -> trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Classpath can be broken when multiple artifacts are present in build dir,CASSANDRA-17129,13410768,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,09/Nov/21 07:41,27/May/22 19:25,13/Jul/23 08:40,21/Nov/21 19:59,4.0.2,4.1,4.1-alpha1,,,,,Build,,,,0,,,"{noformat}
$ ant artifacts

$ ls -1 build/apache-cassandra-*.jar
build/apache-cassandra-4.1-SNAPSHOT-javadoc.jar
build/apache-cassandra-4.1-SNAPSHOT-sources.jar
build/apache-cassandra-4.1-SNAPSHOT.jar

$ bin/cassandra -f
...
Error: Could not find or load main class org.apache.cassandra.service.CassandraDaemon
{noformat}

Classpath is something like:
{noformat}
...bin/../conf:bin/../build/apache-cassandra-4.1-SNAPSHOT-javadoc.jar bin/../build/apache-cassandra-4.1-SNAPSHOT-sources.jar bin/../build/apache-cassandra-4.1-SNAPSHOT.jar:bin/../lib/HdrHistogram-2.1.9.jar:bin/../lib/ST4-4.0.8.jar:bin/../lib/airline-0.8.jar:bin/../lib/antlr-runtime-3.5.2.jar:bin/../lib/asm-7.1.jar:bin/../lib/caffeine-2.9.2.jar:bin...
{noformat}

notice that:
- javadoc and sources jars are on the classpath
- classpath is broken because javadoc, sources and main jar are separated by blankspaces instead of colons

The problem is in {{cassandra.in.sh}} where the main jar gets added to the classpath:

{noformat}
cassandra_bin=`ls -1 $CASSANDRA_HOME/build/apache-cassandra*.jar`
{noformat}

",,brandon.williams,jlewandowski,mck,,,,,,,,,,,,,"jacek-lewandowski closed pull request #1308:
URL: https://github.com/apache/cassandra/pull/1308


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Nov/21 10:02;githubbot;600","jacek-lewandowski closed pull request #1332:
URL: https://github.com/apache/cassandra/pull/1332


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Nov/21 10:02;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jlewandowski,,,,,,,,,,,,,Packaging,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sun Nov 21 19:59:27 UTC 2021,,,,,,,All,,,,"0|z0wk9c:",9223372036854775807,,,,brandon.williams,mck,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/aaffb3b53ef85b1d06c3e4371230208d46effad6,,,,,,,,,Manual testing,,,,,"09/Nov/21 09:33;mck;PR at https://github.com/apache/cassandra/pull/1308;;;","09/Nov/21 10:34;mck;+1;;;","09/Nov/21 15:55;brandon.williams;+1;;;","09/Nov/21 23:22;mck;CI
- 4.0 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1291/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1291/];;;","18/Nov/21 12:21;jlewandowski;||PR||j11||
|[4.0|https://github.com/apache/cassandra/pull/1308]|[(/)|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/136/workflows/768cd34d-2612-4cc5-b247-fc8910ac5a91]
|[trunk|https://github.com/apache/cassandra/pull/1332]|[(/)|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/137/workflows/c39c7a28-5102-4801-93b6-4860ca17437a]|;;;","21/Nov/21 19:59;mck;Committed as [aaffb3b53ef85b1d06c3e4371230208d46effad6|https://github.com/apache/cassandra/commit/aaffb3b53ef85b1d06c3e4371230208d46effad6].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky test - org.apache.cassandra.serializers.TimestampSerializerTest,CASSANDRA-17120,13410080,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,04/Nov/21 15:09,27/May/22 19:25,13/Jul/23 08:40,08/Nov/21 17:12,4.1,4.1-alpha1,,,,,,Test/unit,,,,0,,,"As seen here: https://app.circleci.com/pipelines/github/blerer/cassandra/239/workflows/32b4bc10-685a-4719-ac6c-950e76cd9533/jobs/2144

{noformat}
junit.framework.AssertionFailedError: 'now' timestamp not within expected tolerance.
	at org.apache.cassandra.serializers.TimestampSerializerTest.testNow(TimestampSerializerTest.java:227)
{noformat}",,blerer,e.dimitrova,subkanthi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Nov 08 17:25:30 UTC 2021,,,,,,,All,,,,"0|z0wg5c:",9223372036854775807,,,,e.dimitrova,,,,Normal,,NA,,https://github.com/apache/cassandra/commit/d37e256f2ed0105f65ce1753765d3a712be45032,,,,,,,,,run CI,,,,,"04/Nov/21 16:15;subkanthi;Looks like the condition that fails is *parsed <= now + threshold*

_assertTrue_(""'now' timestamp not within expected tolerance."", now <= parsed && parsed <= now + threshold);
 

INFO [main] 2021-11-04 12:12:43,816 SubstituteLogger.java:169 - now1636042363752
INFO [main] 2021-11-04 12:12:43,819 SubstituteLogger.java:169 - parsed1636042363765;;;","08/Nov/21 14:37;blerer;The issue is that the comparison is done between the output of {{System.currentTimeMillis}} and the output of the {{Clock}} used by the function. The test need to use the output of the {{Clock}} for computing the expected value. ;;;","08/Nov/21 16:31;brandon.williams;Linked a branch and 100 repeated runs in Circle.;;;","08/Nov/21 16:36;e.dimitrova;+1 on this patch. Just wanted to mention that quick grep showed me we might have similar issue with other unit tests too. (even if they are not failing)

Not sure whether we want to address this as part of this ticket or another one. ;;;","08/Nov/21 17:10;brandon.williams;bq. Not sure whether we want to address this as part of this ticket or another one. 

I noticed the same, but there are over 300 instances, so  I made CASSANDRA-17123 for that.;;;","08/Nov/21 17:12;brandon.williams;Committed.;;;","08/Nov/21 17:25;e.dimitrova;{quote}I noticed the same, but there are over 300 instances, so I made CASSANDRA-17123 for that.
{quote}
Thanks!

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Broken test_speculative_data_request,CASSANDRA-17119,13410005,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,04/Nov/21 09:26,27/May/22 19:25,13/Jul/23 08:40,15/Nov/21 08:46,4.0.2,4.1,4.1-alpha1,,,,,Test/dtest/python,,,,0,,,"This has been failing consistently lately


{noformat}
Error Message

KeyError: '127.0.0.3'

Stacktrace

self = <read_repair_test.TestSpeculativeReadRepair object at 0x7f979a965850>

    @since('4.0')
    def test_speculative_data_request(self):
        """""" If one node doesn't respond to a full data request, it should query the other """"""
        node1, node2, node3 = self.cluster.nodelist()
        assert isinstance(node1, Node)
        assert isinstance(node2, Node)
        assert isinstance(node3, Node)
        session = self.get_cql_connection(node1, timeout=2)
    
        session.execute(quorum(""INSERT INTO ks.tbl (k, c, v) VALUES (1, 0, 1)""))
    
        node2.byteman_submit(['./byteman/read_repair/stop_writes.btm'])
        node3.byteman_submit(['./byteman/read_repair/stop_writes.btm'])
    
        session.execute(""INSERT INTO ks.tbl (k, c, v) VALUES (1, 1, 2)"")
    
        # re-enable writes
        node2.byteman_submit(['-u', './byteman/read_repair/stop_writes.btm'])
    
        node1.byteman_submit(['./byteman/read_repair/sorted_live_endpoints.btm'])
        node1.byteman_submit(['./byteman/request_verb_timing.btm'])
    
        with StorageProxy(node1) as storage_proxy:
            assert storage_proxy.blocking_read_repair == 0
            assert storage_proxy.speculated_rr_read == 0
            assert storage_proxy.speculated_rr_write == 0
    
            session = self.get_cql_connection(node1)
            node2.byteman_submit(['./byteman/read_repair/stop_data_reads.btm'])
            results = session.execute(quorum(""SELECT * FROM ks.tbl WHERE k=1""))
    
            timing = request_verb_timing(node1)
>           repair_req_node3 = timing[node3.ip_addr].get('READ_REPAIR_REQ')
E           KeyError: '127.0.0.3'

read_repair_test.py:621: KeyError
{noformat}
",,benedict,bereng,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16928,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Nov 11 16:51:08 UTC 2021,,,,,,,All,,,,"0|z0wfoo:",9223372036854775807,,,,brandon.williams,,,,Normal,,4.1,,https://github.com/apache/cassandra-dtest/commit/01a647f4a1ec42d42198fe4c49fe654a7705d7d7,,,,,,,,,See PR,,,,,"04/Nov/21 10:32;bereng;This test passes on cassandra dtest c2256c72ea9851a259df79d76239d2df80cd97b8 but fails on [6016da3b696481dd7c948cbb65f211461e4e6047|https://github.com/apache/cassandra-dtest/commit/6016da3b696481dd7c948cbb65f211461e4e6047] related to CASSANDRA-16928.

Copying over the previous {{byteman/request_verb_timing.btm}} fixes the test. Mainly imo bc {{InetAddressAndPort}} is missing a {{getAddress()}} method from {{InetSocketAddress}} in older java branches <=4.0?

Given the 16928 is a big PR and seems to be part of an even bigger stream of merges I lack the context to guess which is the best fix here: add the {{InetSocketAddress}} inheritance to the older branches, create a different btm for <=4.0 branches, sthg else? Some guidance would be appreciated thx.

cc/ [~samt] [~benedict];;;","04/Nov/21 10:37;benedict;Ah, an obvious error with the byte man script in retrospect. Sorry about that. I’d say the best option is the simplest, which is probably to copy the byte man script.;;;","08/Nov/21 15:43;brandon.williams;Maybe we should go ahead and create a 'post-4.0' or similar directory under byteman as we do for pre-4.0 and 4.0.  Patch and CI lgtm to me though, +1.;;;","10/Nov/21 06:34;bereng;We're not in a hurry, let's make it pretty. I moved it into a new post4.0 folder and fired a new run for trunk. If that is ok I'll merge tomorrow unless you object.;;;","11/Nov/21 07:09;bereng;Seems CI has a million runs now and there are image and other changes going in. I don't want to add to the noise so holding off merging for the moment.;;;","11/Nov/21 08:17;bereng;Oh I forgot to ask are you ok we merge [~edimitrova]?;;;","11/Nov/21 16:51;e.dimitrova;Ha...seems I was marked as a reviewer when I updated the ticket status for [~brandon.williams]
I will remove myself. [~benedict] and [~brandon.williams] already confirmed the issue.  Let me know if you still want me to review :-) ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
coordinator_large_read should be actually  coordinator_read_size in cassandra.yaml,CASSANDRA-17118,13409945,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,03/Nov/21 22:05,10/Nov/21 00:55,13/Jul/23 08:40,03/Nov/21 22:35,NA,,,,,,,Local/Config,,,,0,,,"coordinator_large_read should be actually called coordinator_read_size in cassandra.yaml

After refactoring the name was changed in the test config but not in the default file.

The issue was not caught because track_warnings is currently disabled and commented out.",,dcapwell,e.dimitrova,,,,,,,,,,,,,,"dcapwell merged pull request #1302:
URL: https://github.com/apache/cassandra/pull/1302


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Nov/21 22:32;githubbot;600","dcapwell merged pull request #1302:
URL: https://github.com/apache/cassandra/pull/1302






-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Nov/21 00:50;githubbot;600","dcapwell merged pull request #1302:
URL: https://github.com/apache/cassandra/pull/1302


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Nov/21 01:37;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,CASSANDRA-15234,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Nov 03 22:29:04 UTC 2021,,,,,,,All,,,,"0|z0wfbk:",9223372036854775807,,,,dcapwell,,,,Low,,NA,,https://github.com/apache/cassandra/commit/5b4d3692664172546b25c765f89c94e61400d873,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-17118?focusedCommentId=17438319&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17438319,,,,,"03/Nov/21 22:24;e.dimitrova;I think this change requires only manual testing. CI cannot catch it as it uses the test/conf file instead where the parameter has already the correct name.

Patch posted [here|https://github.com/ekaterinadimitrova2/cassandra/pull/new/CASSANDRA-17118-trunk]

[~dcapwell], can you review, please?;;;","03/Nov/21 22:29;dcapwell;PR is https://github.com/apache/cassandra/pull/1302;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CQLSSTableWriter backwards compatibility fix for Date fields,CASSANDRA-17117,13409875,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,drohrer,drohrer,drohrer,03/Nov/21 13:53,27/May/22 19:25,13/Jul/23 08:40,05/Nov/21 08:27,4.0.2,4.1,4.1-alpha1,,,,,Local/SSTable,,,,0,,,"{{cassandra-all}} library consumers of the CQLSSTableWriter class cannot easily create an appropriate instance of the {{LocalDate}} class in order to write SSTables including dates, and the current implementation no longer accepts a {{int}} value as a valid input as previous versions of the class would - we used to use {{((AbstractType)columnSpecification.type).decompose(value);}} in order to serialize the value, but now we use the type codec's .serialize method. Unfortunately, this doesn't work when the consumer can't easily create the type needed (serialize, in the case of dates, takes a {{LocalDate}} instance which is not easy to construct outside of Cassandra internal code).

This can be worked around by catching the resulting {{ClassCastException}} thrown from the {{serialize}} call and falling back to the older {{decompose}} implementation, which would maintain backwards-compatibility with other users of the CQLSSTableWriter in cases where they are passing integers for date fields, which used to work.",,drohrer,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Nov/21 17:41;drohrer;CASSANDRA-17117-4.0.patch;https://issues.apache.org/jira/secure/attachment/13035660/CASSANDRA-17117-4.0.patch","03/Nov/21 20:30;drohrer;CASSANDRA-17117-trunk.patch;https://issues.apache.org/jira/secure/attachment/13035665/CASSANDRA-17117-trunk.patch",,,,2.0,drohrer,,,,,,,,,,,,,Code,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Nov 05 08:27:21 UTC 2021,,,,,,,All,,,,"0|z0wew0:",9223372036854775807,,,,brandon.williams,samt,,,Low,,4.0.0,,https://github.com/apache/cassandra/commit/c96131035b309dcc8d716fb0a57ff9d46a8c5042,,,,,,,,,Patches for 4.0 and trunk are attached - added an additional unit test to cover the backward-compatible and current cases to make sure both are still supported.,,,,,"03/Nov/21 21:01;brandon.williams;Not sure if you planned to add circle results, but I broke the circle config out into another commit and started jenkins CI:

||Branch||CI||
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-17117-4.0]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1265/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1265/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-17117-trunk]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1264/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1264/pipeline]|
;;;","03/Nov/21 21:18;drohrer;Brandon:

Thanks for doing that - I do have some Circle runs with just unit tests run at the moment (4.0 passed unit tests, trunk had a few unrelated failures). It looks like your 4.0 branch just didn't even start running unfortunately.

* 4.0/jdk8 - https://app.circleci.com/pipelines/github/JeetKunDoug/cassandra/2/workflows/8ef3122d-1901-4099-a2cb-4ba56acd26b7/jobs/303
4.0 jdk11 - https://app.circleci.com/pipelines/github/JeetKunDoug/cassandra/2/workflows/e8061097-7f5c-4f12-a483-db4945d2c87c/jobs/301

Trunk/jdk8 - https://app.circleci.com/pipelines/github/JeetKunDoug/cassandra/3/workflows/3c6d730f-c72d-4343-bcf5-d97f3ddd3196/jobs/308
Trunk/jdk11 - https://app.circleci.com/pipelines/github/JeetKunDoug/cassandra/3/workflows/eb8566a6-0136-4f4e-b2c3-cd5d0bd6f0cb/jobs/307

I can kick off the complete pre-commit Circle CI builds if that's useful at this point - just let me know.;;;","03/Nov/21 21:23;brandon.williams;bq. It looks like your 4.0 branch just didn't even start

I ninja-fixed that right before you commented. :)

bq. I can kick off the complete pre-commit Circle CI builds if that's useful at this point - just let me know.

Yes please, more CI never hurts but things are a bit delicate right now so it's especially good to have.;;;","03/Nov/21 21:37;drohrer;Here are all the workflows in Circle CI - I've approved all of the pre-commit ones - will take time to work through the queue I'm sure.

Trunk 
JDK11 - https://app.circleci.com/pipelines/github/JeetKunDoug/cassandra/3/workflows/581de388-4488-4789-8880-95d7faab7877
JDK8 - https://app.circleci.com/pipelines/github/JeetKunDoug/cassandra/3/workflows/475b6807-199c-4cf0-a9e6-e2b63fc4e65d

4.0
JDK11 - https://app.circleci.com/pipelines/github/JeetKunDoug/cassandra/2/workflows/3efa087e-75e8-4794-99be-64c6475e3cab
JDK8 - https://app.circleci.com/pipelines/github/JeetKunDoug/cassandra/2/workflows/81e8a3ac-96ff-46a6-9c4c-0f5e68bdb276;;;","04/Nov/21 12:59;brandon.williams;With the exception of the FullRepairCoordinatorTimeoutTest which is obviously not related, all the other failures appear known to me, so I think we're good. +1.;;;","05/Nov/21 08:27;samt;+1 LGTM too, thanks [~drohrer];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
When streaming sees a ClosedChannelException this triggers the disk failure policy,CASSANDRA-17116,13409763,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,02/Nov/21 23:38,27/May/22 19:25,13/Jul/23 08:40,04/Feb/22 19:53,4.1,4.1-alpha1,,,,,,Consistency/Streaming,,,,0,,,"Found in CASSANDRA-17085.

https://app.circleci.com/pipelines/github/dcapwell/cassandra/1069/workflows/26b7b83a-686f-4516-a56a-0709d428d4f2/jobs/7264
https://app.circleci.com/pipelines/github/dcapwell/cassandra/1069/workflows/26b7b83a-686f-4516-a56a-0709d428d4f2/jobs/7256

{code}
ERROR [Stream-Deserializer-/127.0.0.1:7000-f2eb1a15] 2021-11-02 21:35:40,983 DefaultFSErrorHandler.java:104 - Exiting forcefully due to file system exception on startup, disk failure policy ""stop""
org.apache.cassandra.io.FSWriteError: java.nio.channels.ClosedChannelException
	at org.apache.cassandra.io.sstable.format.big.BigTableZeroCopyWriter.write(BigTableZeroCopyWriter.java:227)
	at org.apache.cassandra.io.sstable.format.big.BigTableZeroCopyWriter.writeComponent(BigTableZeroCopyWriter.java:206)
	at org.apache.cassandra.db.streaming.CassandraEntireSSTableStreamReader.read(CassandraEntireSSTableStreamReader.java:125)
	at org.apache.cassandra.db.streaming.CassandraIncomingFile.read(CassandraIncomingFile.java:84)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:51)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:37)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:50)
	at org.apache.cassandra.streaming.StreamDeserializingTask.run(StreamDeserializingTask.java:62)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException: null
	at org.apache.cassandra.net.AsyncStreamingInputPlus.reBuffer(AsyncStreamingInputPlus.java:136)
	at org.apache.cassandra.net.AsyncStreamingInputPlus.consume(AsyncStreamingInputPlus.java:155)
	at org.apache.cassandra.io.sstable.format.big.BigTableZeroCopyWriter.write(BigTableZeroCopyWriter.java:217)
	... 9 common frames omitted
{code}


When bootstrap fails and streaming is closed, this triggers the disk failure policy which causes the JVM to halt by default (if this happens outside of bootstrap, then we stop transports and keep the JVM up).

org.apache.cassandra.streaming.StreamDeserializingTask attempts to handle this by ignoring this exception, but the call to org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize
 Does try/catch and inspects exception; triggering this condition.",,dcapwell,djoshi,e.dimitrova,frankgh,jasonstack,jjordan,maedhroz,,,,,,,,,"frankgh opened a new pull request #172:
URL: https://github.com/apache/cassandra-dtest/pull/172


   For the resumable rebuild test, we now are seeing additional log messages that
   can be safely ignored when a failure is injected during streaming. The errors
   are coming from the node 1 where the log entry reads ""stream operation from
   /127.0.0.1:.* failed"". These are expected log entries when the failure is
   injected. Also, added an optionall forward slash in the ""Remote peer
   127.0.0.3:7000 failed stream session"" expected log entry, which was being
   called out when executing the test locally.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Jan/22 20:30;githubbot;600","dcapwell closed pull request #172:
URL: https://github.com/apache/cassandra-dtest/pull/172


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Feb/22 19:57;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,CASSANDRA-17085,CASSANDRA-17081,CASSANDRA-17076,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,frankgh,,,,,,,,,,,,Availability -> Process Crash,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Feb 04 18:19:23 UTC 2022,,,,,,,All,,,,"0|z0we74:",9223372036854775807,,,,djoshi,maedhroz,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/0859b3c4cfa690dd270030c4bc7ff93eadf6a732,,,,,,,,,tests added,,,,,"02/Nov/21 23:40;dcapwell;if this is impacting 4.0 as well we should add 4.0.x to fix version; not confirmed though;;;","03/Nov/21 17:28;dcapwell;have a patch which replicates the problem and found several other issues as well.  This issue only triggers disk policy for zero-copy-streaming but the error handling in streaming also was causing issues as it wouldn't properly close the session; leaving it hanging...;;;","03/Nov/21 23:48;dcapwell;To show that the test actually detects the issue, remove the core of the patch which fixes the issue

{code}
git checkout trunk src/java/org/apache/cassandra/db/streaming test/unit/org/apache/cassandra/io/sstable/format/big/BigTableZeroCopyWriterTest.java src/java/org/apache/cassandra/io/sstable/format/big/BigTableZeroCopyWriter.java
{code};;;","04/Nov/21 03:27;dcapwell;patch breaks streaming in python dtest; nice!;;;","09/Nov/21 20:02;dcapwell;trying to debug why org.apache.cassandra.distributed.test.ring.BootstrapTest is flaky.  It seems that it times out on Cluster.close, and only happens for a single test sometimes... trying to look to see if I can get more insights into why this happens.;;;","10/Nov/21 00:07;dcapwell;now that I don't try to hide channel close, it seems that python dtest is failing as the logs show the exception.  What is weird to me is that this happens in the happy path as well, so not sure how things were ""success"" if the session fails due to channel close... ;;;","16/Nov/21 20:12;dcapwell;I am trying to look closer at the streaming code, and I think there is a race condition

{code}
// only part of the code which sends COMPLETE
channel.sendControlMessage(new CompleteMessage());
closeSession(State.COMPLETE);
{code}

There is a concept of a control message, which is its own channel.  This means we have 2 channels: control, data (don't know better name); we close data after sending COMPLETE on control, but there is nothing in place to make sure the followers don't see the channel closed BEFORE seeing COMPLETE...;;;","16/Nov/21 23:58;dcapwell;cool, by trying to write CompleteMessage on the outbound channel (to avoid the race condition issue) LegacySSTableTest starts to fail with 

{code}
ERROR [Reference-Reaper] 2021-11-16 15:55:07,656 LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@637953b7) to class org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier@1459220591:/Users/davidcapwell/src/github/apache/cassandra/trunk/test/data/legacy-sstables/nb/legacy_tables/legacy_nb_simple/nb-1-big was not released b
efore the reference was garbage collected
ERROR [Reference-Reaper] 2021-11-16 15:55:07,657 Allocate trace org.apache.cassandra.utils.concurrent.Ref$State@637953b7:
Thread[main,5,main]
        at java.lang.Thread.getStackTrace(Thread.java:1559)
        at org.apache.cassandra.utils.concurrent.Ref$Debug.<init>(Ref.java:248)
        at org.apache.cassandra.utils.concurrent.Ref$State.<init>(Ref.java:178)
        at org.apache.cassandra.utils.concurrent.Ref.<init>(Ref.java:100)
        at org.apache.cassandra.io.sstable.format.SSTableReader.<init>(SSTableReader.java:679)
        at org.apache.cassandra.io.sstable.format.SSTableReader.<init>(SSTableReader.java:643)
        at org.apache.cassandra.io.sstable.format.big.BigTableReader.<init>(BigTableReader.java:57)
        at org.apache.cassandra.io.sstable.format.big.BigFormat$ReaderFactory.open(BigFormat.java:103)
        at org.apache.cassandra.io.sstable.format.SSTableReaderBuilder$ForRead.build(SSTableReaderBuilder.java:370)
        at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:510)
        at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:381)
        at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:376)
        at org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:371)
        at org.apache.cassandra.io.sstable.LegacySSTableTest.streamLegacyTable(LegacySSTableTest.java:425)
        at org.apache.cassandra.io.sstable.LegacySSTableTest.streamLegacyTables(LegacySSTableTest.java:416)
        at org.apache.cassandra.io.sstable.LegacySSTableTest.testStreamLegacyCqlTables(LegacySSTableTest.java:301)
{code}

and

{code}
DEBUG [main] 2021-11-16 15:55:14,453 Got exception trying to acquire sstables
org.apache.cassandra.db.repair.PendingAntiCompaction$SSTableAcquisitionException: Prepare phase failed because it encountered legacy sstables that don't support pending repair, run upgradesstables before starting incremental repairs, repair session (a4751540-4738-11ec-8f0a-09f160ae1e48)
        at org.apache.cassandra.db.repair.PendingAntiCompaction$AntiCompactionPredicate.apply(PendingAntiCompaction.java:132)
        at org.apache.cassandra.db.repair.PendingAntiCompaction$AntiCompactionPredicate.apply(PendingAntiCompaction.java:104)
        at com.google.common.base.Predicate.test(Predicate.java:79)
        at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:174)
        at java.util.Iterator.forEachRemaining(Iterator.java:116)
        at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
        at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)
        at org.apache.cassandra.db.repair.PendingAntiCompaction$AcquisitionCallable.acquireTuple(PendingAntiCompaction.java:198)
        at org.apache.cassandra.db.ColumnFamilyStore.runWithCompactionsDisabled(ColumnFamilyStore.java:2447)
        at org.apache.cassandra.db.repair.PendingAntiCompaction$AcquisitionCallable.call(PendingAntiCompaction.java:234)
        at org.apache.cassandra.io.sstable.LegacySSTableTest.testPendingAntiCompactionOldSSTables(LegacySSTableTest.java:373)
{code}

I don't grasp how this patch breaks it o_O;;;","17/Nov/21 22:11;dcapwell;In talking with [~djoshi] this is the following feedback

* from an API point of view we do not know if the FileChannel or the SocketChannel is closed; FileChannel implies race condition bug where as socket channel may be just ""network hates us"".  Based off stack trace we know this case is network close.
* when we send COMPLETE we also shutdown the channels, this doesn't give the followers enough time to consistently handle this; the feedback was to extend the state machine to have a COMPLETE_ACK (to attempt backwards compatibility, if we timeout and the channel is closed, assume the closed channel is an ACK (current behavior))
* ""streaming doesn't support backwards compatibility"" - me: ""I have been called into prod to support repair in mixed mode... so lets try ^_^"";;;","17/Nov/21 23:06;djoshi;I think with the introduction of {{COMPLETE_ACK}}, we would need to also introduce a timeout after the {{COMPLETE}} message is transmitted but before the sender closes the Channel. This would give the receiving peer time to consume all the data and the {{COMPLETE}} message. This would not only solve the issue but also be backward compatible as we could send {{COMPLETE_ACK}} to peers that support the message and not to other peers.;;;","18/Nov/21 02:10;dcapwell;Also didn't bother debugging but feel the bootstrap timeout tests (see https://app.circleci.com/pipelines/github/dcapwell/cassandra/1129/workflows/43d3d109-58a5-42ac-846a-1eca0e9233ed/jobs/8175) are caused by this bug.  when the streams are in limbo jvm-dtest waits for them;;;","18/Nov/21 17:06;dcapwell;did the POC, possible I messed everything up, but it doesn't solve anything; fails the same way...  going to do something simpler and see about just delaying close and see what happens.;;;","18/Nov/21 21:22;dcapwell;delaying the close base off stream timeout seems to be more stable...

[~jasonstack] [~sbtourist] would love your feedback on how to deal with this.  Started down this rabbit hole trying to fix a flaky test, but do not know streaming well enough.;;;","19/Nov/21 13:52;jjordan;I wonder if the answer here is to instead set some state such that the ZCS code can catch the exception and check ""was this streaming op canceled?"" and if so not trigger the disk failure?;;;","19/Nov/21 17:12;dcapwell;bq. ZCS code can catch the exception and check ""was this streaming op canceled?""

We do this right now in the patch.   I moved the closed exception to no longer be re-thrown as a FSWriteError, this bubbles up to the top which notifies the session.onError method; I updated this method to special case this the same way EOF was special cased.  This works fine if we do not hit the COMPLETE/close race condition, if we see COMPLETE first we log a debug message, if we see close first we fail the stream.;;;","06/Dec/21 23:53;frankgh;I took a look at this as well, and it seems that the follower keeps track of the number of {{RECEIVED}} messages it expects and the number of received messages it has seen. Only when the follower has seen all the {{RECEIVED}} messages it expects to see, will the follower initiate the {{COMPLETE}} message, and close the connections.

It looks like the initiator is sending back the received message before actually receiving the stream. The code sits in {{org.apache.cassandra.streaming.StreamSesssion.receive(IncomingStreamMessage)}}. We can see that the control message is being sent and then the receiver receives the stream.

A potential solution to the race is delaying the sending of the {{RECEIVED}} message right after the stream has been consumed (maybe in the finally block of the {{receive}} method).

Unfortunately, I have not found a good way to reproduce the issue, so I don't know if that will be sufficient to resolve the race issue. Maybe if [~dcapwell] can try it, or give me some guidance on how to repro the issue, I can take a look into it further. ;;;","23/Dec/21 00:05;frankgh;[~djoshi] and I took another look at this, it seems that the race is happening in {{org.apache.cassandra.streaming.StreamSession#maybeCompleted()}}. 

The race is most likely happening in the code block below.

{code:java}
    channel.sendControlMessage(new CompleteMessage());
    closeSession(State.COMPLETE);
{code}

The {{channel.sendControlMessage}} call returns a future and we immediately close the session without waiting for the future to execute. In the majority of cases, the message will be delivered on time,
Network delays/system load/thread scheduling can cause the {{CompleteMessage}} to be sent/received after the session has been closed triggering the {{java.nio.channels.ClosedChannelException}}.

A potential solution is to add a listener for the future, and only then close the session.

{code:java}
    Future<?> messageFuture = channel.sendControlMessage(new CompleteMessage());
    messageFuture.addListener(f -> closeSession(State.COMPLETE));
{code};;;","05/Jan/22 19:36;dcapwell;I like the listener way... seems clean if it works

{code}
Future<?> messageFuture = channel.sendControlMessage(new CompleteMessage());
messageFuture.addListener(f -> closeSession(State.COMPLETE));
{code};;;","05/Jan/22 19:40;dcapwell;I can try adding the listener to my patch and run through CI to see if anything keeps failing... can keep triggering python dtests;;;","05/Jan/22 19:42;frankgh;Great, let me know when you trigger CI. I can take a look and hopefully it solves the race condition.;;;","05/Jan/22 23:06;dcapwell;rebased and push the change to my branch;;;","06/Jan/22 02:52;dcapwell;heh. https://app.circleci.com/pipelines/github/dcapwell/cassandra/1150/workflows/e1f0b429-c024-4b3e-8e97-07669f60996a/jobs/8438

test_preview - repair_tests.preview_repair_test.TestPreviewRepair

{code}
test teardown failure
Unexpected error found in node logs (see stdout for full details). Errors: [ERROR [Stream-Deserializer-/127.0.0.1:7000-e3a2ecc2] 2022-01-06 02:26:28,485 StreamSession.java:650 - [Stream #0d9ed480-6e98-11ec-91be-5f7fa67bb742] Socket closed before session completion, peer 127.0.0.1:7000 is probably down.
java.nio.channels.ClosedChannelException: null
	at org.apache.cassandra.net.AsyncStreamingInputPlus.reBuffer(AsyncStreamingInputPlus.java:136)
	at org.apache.cassandra.io.util.RebufferingInputStream.readByte(RebufferingInputStream.java:178)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:49)
	at org.apache.cassandra.streaming.StreamDeserializingTask.run(StreamDeserializingTask.java:59)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834), ERROR [Stream-Deserializer-/127.0.0.1:7000-e3a2ecc2] 2022-01-06 02:26:28,485 StreamSession.java:650 - [Stream #0d9ed480-6e98-11ec-91be-5f7fa67bb742] Socket closed before session completion, peer 127.0.0.1:7000 is probably down.
java.nio.channels.ClosedChannelException: null
	at org.apache.cassandra.net.AsyncStreamingInputPlus.reBuffer(AsyncStreamingInputPlus.java:136)
	at org.apache.cassandra.io.util.RebufferingInputStream.readByte(RebufferingInputStream.java:178)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:49)
	at org.apache.cassandra.streaming.StreamDeserializingTask.run(StreamDeserializingTask.java:59)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)]
{code}

{code}
boolean isEofException = e instanceof EOFException || e instanceof ClosedChannelException;
        if (isEofException)
        {
            if (state.finalState)
            {
                logger.debug(""[Stream #{}] Socket closed after session completed with state {}"", planId(), state);

                return null;
            }
            else
            {
                logger.error(""[Stream #{}] Socket closed before session completion, peer {} is probably down."",
                             planId(),
                             peer.getHostAddressAndPort(),
                             e);

                return closeSession(State.FAILED);
            }
        }
{code}

so closing after the write future notifies, we still see the issue.  [~djoshi] [~frankgh];;;","11/Jan/22 20:07;dcapwell;after looking closer with [~frankgh] it looks like this is a race condition issue in how we close connections, trying to figure out where.

I see that adding a 10s sleep causes us to give enough time for the follower to send COMPLETE and close, and without that it some times works and some times doesn't; the fun behavior is we see COMPLETE isn't sent from the follower, yet the initiator closes the session as complete!;;;","11/Jan/22 20:56;dcapwell;I think we finally found the issue!  When the follower sends the last msg, there is a race condition as we do the following

{code}
send(lastMessage);
// with bad OS scheduling issues, this may happen AFTER the initiator closes the socket
closeSession(COMPLETE);
{code}

if the OS scheduler runs the closeSession(COMPLETE) logic AFTER getting the socket close msg from initiator, then the socket will be closed and cause the ClosedChannelException, and since the state isn't final we fail the session...

To fix this, moved end messages to the following pattern

{code}
setState(WAIT_COMPLETE);
setState(COMPLETE);
send(lastMessage);
closeSession(COMPLETE);
{code};;;","13/Jan/22 19:12;dcapwell;Relative to trunk, it looks like CI is finally green!  

Trunk: https://app.circleci.com/pipelines/github/dcapwell/cassandra/1163/workflows/17e71cd2-1e9c-48db-bde4-63a290a90499
Patch: https://app.circleci.com/pipelines/github/dcapwell/cassandra/1162/workflows/c22e4720-bbd0-4a0a-bc9b-2e99d7b0c5b6

Going to do one more round of cleanup, but think ready for review;;;","13/Jan/22 20:32;frankgh;I have a small commit for {{cassandra-dtest}} for new expected output in the logs of one of the tests:

https://github.com/apache/cassandra-dtest/pull/172;;;","01/Feb/22 05:21;maedhroz;Made a first pass at the [trunk PR|https://github.com/apache/cassandra/pull/1301] and left some minor comments. I still want to look at the new {{StreamCloseInMiddleTest}} one more time though...;;;","02/Feb/22 00:06;maedhroz;+1;;;","03/Feb/22 19:54;dcapwell;[~djoshi] approved in GH, so 2 +1s;;;","03/Feb/22 21:13;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17116-trunk-9F17D44F-1990-4FA1-B04B-B908D0533DF7]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17116-trunk-9F17D44F-1990-4FA1-B04B-B908D0533DF7]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1398/]|
;;;","04/Feb/22 01:52;dcapwell;Aborted commit due to change in AbstractCluster breaking a few upgrade tests.  Also found out that some upgrade tests don't actually test against trunk... so fixing...;;;","04/Feb/22 02:01;dcapwell;pushed changes to fix the upgrade test issues

{code}
commit 1a43be88a433307c47521e3d890687bf784f4e1f (HEAD -> CASSANDRA-17116, origin/CASSANDRA-17116)
Author: David Capwell <dcapwell@apache.org>
Date:   Thu Feb 3 17:58:08 2022 -0800

    fixed it so singleUpgrade no longer takes to, as that allows us to not test against CURRENT

test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeGossipTest.java
test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeReadTest.java
test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeRepairTest.java
test/distributed/org/apache/cassandra/distributed/upgrade/Pre40MessageFilterTest.java
test/distributed/org/apache/cassandra/distributed/upgrade/UpgradeTestBase.java

commit 9dcdb1448284f4bd259b144a49e4b9e37408bda3
Author: David Capwell <dcapwell@apache.org>
Date:   Thu Feb 3 17:51:04 2022 -0800

    only clear delegate if it shutdown or if address changed, no other reason

test/distributed/org/apache/cassandra/distributed/impl/AbstractCluster.java
{code};;;","04/Feb/22 17:25;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17116-trunk-04BC233C-9090-4A35-8909-4BC19A3667EF]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17116-trunk-04BC233C-9090-4A35-8909-4BC19A3667EF]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1404/]|
;;;","04/Feb/22 18:19;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17116-trunk-D65E87A1-597B-4BC8-A340-DA5754F5625C]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17116-trunk-D65E87A1-597B-4BC8-A340-DA5754F5625C]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1405/]|
;;;",,,,,,,,,,,,,,,,,,,
Fix test org.apache.cassandra.net.MessagingServiceTest,CASSANDRA-17088,13409182,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,dcapwell,dcapwell,29/Oct/21 19:10,27/May/22 19:25,13/Jul/23 08:40,29/Oct/21 19:15,4.1,4.1-alpha1,,,,,,Test/unit,,,,0,,,"https://app.circleci.com/pipelines/github/dcapwell/cassandra/1062/workflows/3642831f-81d0-4c4f-8bb7-9444e11b58b4/jobs/7084

{code}
junit.framework.AssertionFailedError
	at org.apache.cassandra.net.MessagingServiceTest.listen(MessagingServiceTest.java:343)
	at org.apache.cassandra.net.MessagingServiceTest.listenRequiredSecureConnection(MessagingServiceTest.java:277)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{code}

And

{code}
junit.framework.AssertionFailedError
	at org.apache.cassandra.net.MessagingServiceTest.listen(MessagingServiceTest.java:343)
	at org.apache.cassandra.net.MessagingServiceTest.listenOptionalSecureConnection(MessagingServiceTest.java:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{code}",,dcapwell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17033,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,2021-10-29 19:10:27.0,,,,,,,All,,,,"0|z0wam8:",9223372036854775807,,,,,,,,Normal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"commit log was switched from non-daemon to daemon threads, which causes the JVM to exit in some case as no non-daemon threads are active",CASSANDRA-17085,13409179,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,29/Oct/21 19:08,27/May/22 19:25,13/Jul/23 08:40,03/Nov/21 20:08,4.1,4.1-alpha1,,,,,,Test/dtest/python,,,,0,,,"Right now bootstrap tests are failing every time we run, this work is to debug and fix the underling issue.

Examples:

https://app.circleci.com/pipelines/github/dcapwell/cassandra/1062/workflows/ba3e6395-ef22-4724-8424-0549e65d8cff/jobs/7089

{code}
>       node3.nodetool('bootstrap resume')

bootstrap_test.py:1014: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../env3.6/lib/python3.6/site-packages/ccmlib/node.py:1005: in nodetool
    return handle_external_tool_process(p, ['nodetool', '-h', 'localhost', '-p', str(self.jmx_port)] + shlex.split(cmd))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

process = <subprocess.Popen object at 0x7fb071a03940>
cmd_args = ['nodetool', '-h', 'localhost', '-p', '7300', 'bootstrap', ...]

    def handle_external_tool_process(process, cmd_args):
        out, err = process.communicate()
        if (out is not None) and isinstance(out, bytes):
            out = out.decode()
        if (err is not None) and isinstance(err, bytes):
            err = err.decode()
        rc = process.returncode
    
        if rc != 0:
>           raise ToolError(cmd_args, rc, out, err)
E           ccmlib.node.ToolError: Subprocess ['nodetool', '-h', 'localhost', '-p', '7300', 'bootstrap', 'resume'] exited with non-zero status; exit status: 1; 
E           stderr: nodetool: Failed to connect to 'localhost:7300' - EOFException: 'null'.

../env3.6/lib/python3.6/site-packages/ccmlib/node.py:2305: ToolError
{code}

https://app.circleci.com/pipelines/github/dcapwell/cassandra/1062/workflows/ba3e6395-ef22-4724-8424-0549e65d8cff/jobs/7087

{code}
>       node1.start()

bootstrap_test.py:483: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../env3.6/lib/python3.6/site-packages/ccmlib/node.py:895: in start
    node.watch_log_for_alive(self, from_mark=mark)
../env3.6/lib/python3.6/site-packages/ccmlib/node.py:664: in watch_log_for_alive
    self.watch_log_for(tofind, from_mark=from_mark, timeout=timeout, filename=filename)
../env3.6/lib/python3.6/site-packages/ccmlib/node.py:592: in watch_log_for
    head=reads[:50], tail=""...""+reads[len(reads)-150:]))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

start = 1635453190.3118386, timeout = 120
msg = ""Missing: ['127.0.0.1:7000.* is now UP'] not found in system.log:\n Head: \n Tail: ...""
node = 'node3'

    @staticmethod
    def raise_if_passed(start, timeout, msg, node=None):
        if start + timeout < time.time():
>           raise TimeoutError.create(start, timeout, msg, node)
E           ccmlib.node.TimeoutError: 28 Oct 2021 20:35:10 [node3] after 120.12/120 seconds Missing: ['127.0.0.1:7000.* is now UP'] not found in system.log:
E            Head: 
E            Tail: ...
{code}",,dcapwell,e.dimitrova,samt,,,,,,,,,,,,,"smiklosovic closed pull request #1298:
URL: https://github.com/apache/cassandra/pull/1298


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 18:14;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,CASSANDRA-17081,,,,,,,CASSANDRA-17116,,,,,,,,,,,,,,,,,,,0.0,dcapwell,samt,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Nov 03 18:59:52 UTC 2021,,,,,,,All,,,,"0|z0walk:",9223372036854775807,,,,samt,,,,Normal,,NA,,https://github.com/apache/cassandra/commit/a540afd12ae4c29f15c54330242efdf1cf61354c,,,,,,,,,local and ci dtest,,,,,"01/Nov/21 19:31;dcapwell;Here is what I am seeing in bootstrap_test.py::TestBootstrap::test_bootstrap_with_reset_bootstrap_state

{code}
      node3 = new_node(cluster)
        try:
            node3.start()
        except NodeError:
            pass  # node doesn't start as expected
        t.join()
        node1.start()
{code}

node1.start checks all the alive nodes (according to ccm) to see if node1 is seen as up in the logs.  node3 is dead (or dying), so it should not be included in the watch set

I was able to repro the issue when I limit the environment to 2 cores; trying a patch where we force shutdown node3 before starting node1 to avoid ccm checking node3's logs;;;","01/Nov/21 21:36;dcapwell;bootstrap_test.py::TestBootstrap::test_bootstrap_binary_disabled also fails with the following

{code}
        try:
            node3.nodetool('join')
            pytest.fail('nodetool should have errored and failed to join ring')
        except ToolError as t:
>           assert ""Cannot join the ring until bootstrap completes"" in t.stdout
E           assert 'Cannot join the ring until bootstrap completes' in ''
E            +  where '' = ToolError(""Subprocess ['nodetool', '-h', 'localhost', '-p', '7300', 'join'] exited with non-zero status; exit status: 1; \nstderr: nodetool: Failed to connect to 'localhost:7300' - SocketException: 'Connection reset'.\n"",).stdout
{code}

In both cases it looks like issue connecting to JMX.  Logs for node3 don't show the process going down during the test so not sure what's up yet.  This is localhost networking so shouldn't have random connection close events, so not sure what leads to this flaky behavior yet.;;;","01/Nov/21 23:19;dcapwell;bootstrap_test.py::TestBootstrap::test_bootstrap_binary_disabled  is more complex it seems, something is causing the JVM to do a graceful shutdown; is see the following in the node3 logs

{code}
WARN  [main] 2021-11-01 22:43:33,212 CassandraDaemon.java:663 - Not starting client transports in write_survey mode as it's bootstrapping or auth is enabled
INFO  [main] 2021-11-01 22:43:33,212 CassandraDaemon.java:764 - Startup complete
INFO  [StorageServiceShutdownHook] 2021-11-01 22:43:33,219 HintsService.java:233 - Paused hints dispatch
{code}

I enhanced the test to log where it is out, so I can correlate test and server logs

{code}
22:43:35,415 bootstrap_test INFO Attempting to resume bootstrap on node3
{code}


So, I see that we start a graceful shutdown at 22:43:33,219, and the test tries to resume bootstrap at 22:43:35,415; 2 seconds AFTER we started shutdown.  I don't see us doing a shutdown in the test; and this fails 100% of the time for me, so we always seem to do a graceful shutdown for some reason...;;;","01/Nov/21 23:41;dcapwell;Added the following to CassandraDaemon to detect if System.exit is getting called; it doesn't look to be

{code}
System.setSecurityManager(new SecurityManager()
        {
            public void checkExit(int status)
            {
                System.err.println(""System.exit(""+status+"")) callled"");
                new Throwable(""System.exit(""+status+"")) callled"").printStackTrace();
            }
        });
{code}

So something else looks to be causing the JVM to halt.;;;","01/Nov/21 23:56;dcapwell;Ok I think I figured out the issue; we have no daemon threads running..

updated drain to log threads

{code}
protected synchronized void drain(boolean isFinalShutdown) throws IOException, InterruptedException, ExecutionException
    {
        logger.info(""drain({})"", isFinalShutdown);
        if (isFinalShutdown)
        {
            Map<Thread, StackTraceElement[]> traces = Thread.getAllStackTraces();
            List<String> nonDaemonThreads = new ArrayList<>();
            for (Entry<Thread, StackTraceElement[]> e : traces.entrySet())
            {
                if (e.getKey().isDaemon())
                    continue;
                nonDaemonThreads.add(e.getKey().getName());
            }
            logger.info(""Non-daemon threads: {}"", nonDaemonThreads);
        }
{code}

This produces

{code}
INFO  [StorageServiceShutdownHook] 2021-11-01 23:54:50,181 StorageService.java:5003 - Non-daemon threads: [DestroyJavaVM, StorageServiceShutdownHook]
{code};;;","02/Nov/21 16:10;dcapwell;Here is what I see different than 4.0

{code}
$ diff 40.txt trunk.txt
4,5c4
< COMMIT-LOG-ALLOCATOR    false
< CacheCleanupExecutor:1    true
---
> COMMIT-LOG-ALLOCATOR    true
10d8
< GossipStage:1    true
12,14d9
< HintsDispatcher:1    true
< HintsDispatcher:2    true
< HintsWriteExecutor:1    true
23d17
< MigrationStage:1    true
27c21
< PERIODIC-COMMIT-LOG-SYNCER    false
---
> PERIODIC-COMMIT-LOG-SYNCER    true
37d30
< SecondaryIndexManagement:1    true
40,42c33
< ValidationExecutor:1    true
< ValidationExecutor:2    true
< ViewBuildExecutor:1    true
---
> SnapshotCleanup:1    true
45a37
> read-hotness-tracker:1    true
{code}

This was collected as the last step in main, so just scans every thread and checks if daemon or not

the non-daemon threads in 40 are: nioEventLoopGroup-5-1, PERIODIC-COMMIT-LOG-SYNCER, and COMMIT-LOG-ALLOCATOR

but in trunk it is only: nioEventLoopGroup-5-1

seems PERIODIC-COMMIT-LOG-SYNCER and COMMIT-LOG-ALLOCATOR went daemon; will try to track down where.

PeriodicCommitLogService:
40: NamedThreadFactory.createThread(new SyncRunnable(MonotonicClock.preciseTime), name) // daemon=false
trunk: executorFactory().infiniteLoop(name, new SyncRunnable(MonotonicClock.preciseTime), true); // daemon=true in org.apache.cassandra.concurrent.ExecutorFactory.Default#startThread

AbstractCommitLogSegmentManager
40: NamedThreadFactory.createThread(runnable, ""COMMIT-LOG-ALLOCATOR""); // daemon=false
trunk: executorFactory().infiniteLoop(""COMMIT-LOG-ALLOCATOR"", runnable, true, interruptHandler); // daemon=true

These two were changed in CASSANDRA-16925;;;","02/Nov/21 17:02;e.dimitrova;Is it only me or there is no CI run accompanying CASSANDRA-16925, maybe they just forgot to publish the link...? I don't know. ;;;","02/Nov/21 18:34;dcapwell;[~samt] was working on another issue with commit log which is another race condition bug; will ninja that patch into this one as it touches the same code and rewriting the same interface twice is annoying...

Error is

{code}
ERROR [COMMIT-LOG-WRITER] 2021-10-25 14:51:13,985 Exiting due to error while processing commit log during initialization.
org.apache.cassandra.io.FSWriteError: java.nio.channels.ClosedByInterruptException
	at org.apache.cassandra.db.commitlog.CompressedSegment.write(CompressedSegment.java:86)
	at org.apache.cassandra.db.commitlog.CommitLogSegment.sync(CommitLogSegment.java:360)
	at org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager.sync(AbstractCommitLogSegmentManager.java:555)
	at org.apache.cassandra.db.commitlog.CommitLog.sync(CommitLog.java:253)
	at org.apache.cassandra.db.commitlog.AbstractCommitLogService$SyncRunnable.run(AbstractCommitLogService.java:178)
	at org.apache.cassandra.concurrent.InfiniteLoopExecutor.loop(InfiniteLoopExecutor.java:86)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedByInterruptException: null
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.FileChannelImpl.position(FileChannelImpl.java:269)
	at org.apache.cassandra.db.commitlog.CompressedSegment.write(CompressedSegment.java:78)
	... 7 common frames omitted
{code};;;","02/Nov/21 22:08;dcapwell;I was hopeful that https://app.circleci.com/pipelines/github/dcapwell/cassandra/1069/workflows/26b7b83a-686f-4516-a56a-0709d428d4f2/jobs/7256/tests#failed-test-1 would pass as it looks like the same pattern; but it didn't... 

{code}
node3 = new_node(cluster)
        try:
            node3.start()
        except NodeError:
            pass  # node doesn't start as expected
        t.join()
>       node1.start()
{code}

{code}
ccmlib.node.TimeoutError: 02 Nov 2021 21:41:45 [node3] after 120.11/120 seconds Missing: ['127.0.0.1:7000.* is now UP'] not found in system.log:
{code}

Looking at node3's logs

https://circle-production-customer-artifacts.s3.amazonaws.com/picard/5d8cf450ac092b7198121061/6181a8080bc8444c0cfb3495-7-build/artifacts/dtest_j8_upgradetests_without_vnodes_logs/1635889075100_test_bootstrap_with_reset_bootstrap_state/node3.log?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20211102T220735Z&X-Amz-SignedHeaders=host&X-Amz-Expires=60&X-Amz-Credential=AKIAJR3Q6CR467H7Z55A%2F20211102%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=8a0b070e2db9d3e2bed74754d6f34d13171ab5ce1cc7236ec7792003ea14808f

{code}
ERROR [Stream-Deserializer-/127.0.0.1:7000-f2eb1a15] 2021-11-02 21:35:40,983 DefaultFSErrorHandler.java:104 - Exiting forcefully due to file system exception on startup, disk failure policy ""stop""
org.apache.cassandra.io.FSWriteError: java.nio.channels.ClosedChannelException
	at org.apache.cassandra.io.sstable.format.big.BigTableZeroCopyWriter.write(BigTableZeroCopyWriter.java:227)
	at org.apache.cassandra.io.sstable.format.big.BigTableZeroCopyWriter.writeComponent(BigTableZeroCopyWriter.java:206)
	at org.apache.cassandra.db.streaming.CassandraEntireSSTableStreamReader.read(CassandraEntireSSTableStreamReader.java:125)
	at org.apache.cassandra.db.streaming.CassandraIncomingFile.read(CassandraIncomingFile.java:84)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:51)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:37)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:50)
	at org.apache.cassandra.streaming.StreamDeserializingTask.run(StreamDeserializingTask.java:62)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException: null
	at org.apache.cassandra.net.AsyncStreamingInputPlus.reBuffer(AsyncStreamingInputPlus.java:136)
	at org.apache.cassandra.net.AsyncStreamingInputPlus.consume(AsyncStreamingInputPlus.java:155)
	at org.apache.cassandra.io.sstable.format.big.BigTableZeroCopyWriter.write(BigTableZeroCopyWriter.java:217)
	... 9 common frames omitted
{code};;;","02/Nov/21 23:00;dcapwell;tested on 3.0 and see we do not stop node3

{code}
WARN  [main] 2021-11-02T22:57:12,390 : - Node is not yet bootstrapped completely. Use nodetool to check bootstrap state and resume. For more, see `nodetool help bootstrap`
INFO  [main] 2021-11-02T22:57:12,390 : - Startup complete
{code}

I am in the container and see the JVM is still up;  and tailing the logs shows the following every few seconds

{code}
INFO  [OptionalTasks:1] 2021-11-02T22:59:32,211 : - Setup task failed with error, rescheduling
WARN  [OptionalTasks:1] 2021-11-02T22:59:42,178 : - CassandraRoleManager skipped default role setup: some nodes were not ready
INFO  [OptionalTasks:1] 2021-11-02T22:59:42,178 : - Setup task failed with error, rescheduling
{code}

so looks like this 1 test hit 2 bugs... nice;;;","02/Nov/21 23:14;dcapwell;I will file a new JIRA for zero-copy-streaming channel close causes node to shutdown.;;;","03/Nov/21 16:54;samt;+1 LGTM;;;","03/Nov/21 18:59;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17085-trunk-E65F2954-175A-46A4-B954-FC6A91109F61]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17085-trunk-E65F2954-175A-46A4-B954-FC6A91109F61]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1262/]|
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
startup fails if directories do not exist,CASSANDRA-17084,13409140,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,29/Oct/21 15:24,27/May/22 19:24,13/Jul/23 08:40,14/Jan/22 17:56,4.1,4.1-alpha1,,,,,,Local/Startup and Shutdown,,,,0,,,"Prior to CASSANDRA-16926, having commitlog and data dirs defined that did not exist would be created on startup, but now we throw:

{noformat}
Exception (org.apache.cassandra.exceptions.ConfigurationException) encountered during startup: Unable check disk space in 'bin/../data/commitlog'. Perhaps the Cassandra user does not have the necessary permissions
org.apache.cassandra.exceptions.ConfigurationException: Unable check disk space in 'bin/../data/commitlog'. Perhaps the Cassandra user does not have the necessary permissions
        at org.apache.cassandra.config.DatabaseDescriptor.lambda$tryGetSpace$3(DatabaseDescriptor.java:1188)
        at org.apache.cassandra.io.util.PathUtils.tryOnFileStore(PathUtils.java:639)
        at org.apache.cassandra.io.util.PathUtils.tryGetSpace(PathUtils.java:665)
        at org.apache.cassandra.config.DatabaseDescriptor.tryGetSpace(DatabaseDescriptor.java:1188)
        at org.apache.cassandra.config.DatabaseDescriptor.applySimpleConfig(DatabaseDescriptor.java:553)
        at org.apache.cassandra.config.DatabaseDescriptor.applyAll(DatabaseDescriptor.java:350)
        at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:178)
        at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:162)
        at org.apache.cassandra.service.CassandraDaemon.applyConfig(CassandraDaemon.java:800)
        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:736)
        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:871)
{noformat}

This was at least convenient for development, but also may be relied upon by some tooling/automation.",,bereng,e.dimitrova,jeromatron,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17115,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Availability,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jan 14 17:56:54 UTC 2022,,,,,,,All,,,,"0|z0wacw:",9223372036854775807,,,,bereng,,,,Normal,,NA,,https://github.com/apache/cassandra/commit/76f8333e9b9c89f029dd586273d5d42fdaf676dd,,,,,,,,,Added test,,,,,"29/Oct/21 18:52;brandon.williams;Previously we could get past DD.daemonInitialization and then in setup() when initializing the commitlog it ends up calling DD.createAllDirectories, but this is now too late.  I don't think calling createAllDirectories sooner now is the solution though, since we use daemonInitialization extensively in tests, and probably don't want the side effect of it creating directories.;;;","07/Dec/21 22:47;brandon.williams;PathUtils.tryOnFileStore was already attempting to copy the previous behavior, but was using relative paths so they never existed. [Branch|https://github.com/driftx/cassandra/tree/CASSANDRA-17084], [circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17084], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1314/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1314/pipeline] with this [dtest branch|https://github.com/driftx/cassandra-dtest/tree/CASSANDRA-17084].;;;","10/Jan/22 09:37;bereng;They seem to be failing [~brandon.williams]?;;;","11/Jan/22 14:47;brandon.williams;They only fail on circle, and it's just the test I wrote for this issue (where the fix is quite obviously correct.)  They fail in the teardown:

{quote}
test teardown failure
Unexpected error found in node logs (see stdout for full details). Errors: [ERROR [COMMIT-LOG-ALLOCATOR] 2022-01-10 17:56:48,793 JVMStabilityInspector.java:185 - Exiting due to error while processing commit log during initialization.
java.lang.ExceptionInInitializerError: null
	at org.apache.cassandra.db.commitlog.CommitLogSegmentManagerStandard.createSegment(CommitLogSegmentManagerStandard.java:64)
	at org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager$AllocatorRunnable.run(AbstractCommitLogSegmentManager.java:153)
	at org.apache.cassandra.concurrent.InfiniteLoopExecutor.loop(InfiniteLoopExecutor.java:114)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.lang.NullPointerException: null
	at org.apache.cassandra.db.commitlog.CommitLogSegment.<clinit>(CommitLogSegment.java:79)
	... 5 common frames omitted, ERROR [COMMIT-LOG-ALLOCATOR] 2022-01-10 17:56:48,793 JVMStabilityInspector.java:185 - Exiting due to error while processing commit log during initialization.
{quote}

But that sure doesn't _seem_ like teardown to me, but initialization.  I'm not really sure how to attack this problem except for trial and error since it is localized to circle.;;;","11/Jan/22 18:07;brandon.williams;The stacktrace seems to imply that `commitlog_directory` is null, but it's being explicitly set in the test and works everywhere else I run it.;;;","13/Jan/22 09:52;bereng;Hi [~brandon.williams],

While looking into the failures I've been playing with {{commitlog_directory}} and I can't get it to fail locally. Paths being relative or not it always creates the folder for me. There is a note in the javadoc that all these methods are implementation dependent. Hence I can only think there is some code there behaving differently depending on where it gets executed. I can only think to add a few debug statements and run it on circle to narrow the problem down. I am afraid I don't have a better suggestion here... :thinking:...;;;","13/Jan/22 19:30;brandon.williams;Thanks for looking.  I think the issue is that circle's current working directory when running the tests isn't the cassandra directory (and in retrospect that was probably a bad assumption to begin with) so the directories it's looking for actually do not exist at the base level, hence the NPE.  I updated the dtest to create its [own temp directory|https://github.com/driftx/cassandra-dtest/commit/2c28040113e95bb277050e35fe60b3da2fd8edfa] and point to relative (nonexistent) paths within that, and that fails without my patch, and [passes on circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17084&filter=all] with it.;;;","14/Jan/22 05:55;bereng;Yes. Good thinking. I went over everything and the random failures pass locally. Also the rest are just GH timeouts. +1;;;","14/Jan/22 17:56;brandon.williams;Committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testsome target doesn't work with wildcards,CASSANDRA-17083,13409068,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bernardo.botella,bereng,bereng,29/Oct/21 08:10,22/Oct/22 11:35,13/Jul/23 08:40,22/Jun/22 05:16,5.0,,,,,,,Build,,,,0,low-hanging-fruit,,"Running {{ant test -Dtest.name=PasswordObfuscator*Test}} runs the test correctly. But {{ant testsome -Dtest.name=PasswordObfuscator*Test}} will make it fail like

{noformat}
[junit-timeout] Testsuite: org.apache.cassandra.cql3.PasswordObfuscatorTest
[junit-timeout] Testsuite: org.apache.cassandra.cql3.PasswordObfuscatorTest Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.038 sec
[junit-timeout] 
[junit-timeout] Testsuite: PasswordObfuscator*Test
[junit-timeout] Testsuite: PasswordObfuscator*Test Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0 sec
[junit-timeout] 
[junit-timeout] Null Test: 	Caused an ERROR
[junit-timeout] PasswordObfuscator*Test
[junit-timeout] java.lang.ClassNotFoundException: PasswordObfuscator*Test
[junit-timeout] 	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
[junit-timeout] 	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
[junit-timeout] 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
[junit-timeout] 	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
[junit-timeout] 	at java.lang.Class.forName0(Native Method)
[junit-timeout] 	at java.lang.Class.forName(Class.java:348)
[junit-timeout] 
[junit-timeout] 
[junit-timeout] Test PasswordObfuscator*Test FAILED
{noformat}

We should fix testsome as this is a useful feature for 'families' of tests such as {{ViewComplex*Test}}",,adelapena,bereng,bernardo.botella,brandon.williams,Gerrrr,yifanc,,,,,,,,,,"bbotella opened a new pull request, #1608:
URL: https://github.com/apache/cassandra/pull/1608

   Fix testsome target to prevent double test execution when not using FQDN names.


;06/May/22 16:03;githubbot;600","bbotella opened a new pull request, #1609:
URL: https://github.com/apache/cassandra/pull/1609

   Fix testsome target to prevent double test execution when not using FQDN names.


;06/May/22 16:03;githubbot;600","bbotella opened a new pull request, #1610:
URL: https://github.com/apache/cassandra/pull/1610

   Fix testsome target to prevent double test execution when not using FQDN names.


;06/May/22 16:03;githubbot;600","bereng closed pull request #1665: CASSANDRA-17083 testsome target doesn't work with wildcards
URL: https://github.com/apache/cassandra/pull/1665


;23/Jun/22 06:08;githubbot;600","smiklosovic closed pull request #1610: CASSANDRA-17083 - Fix testsome target to prevent double test execution
URL: https://github.com/apache/cassandra/pull/1610


;22/Oct/22 11:34;githubbot;600","smiklosovic closed pull request #1608: CASSANDRA-17083 - Fix testsome target to prevent double test execution
URL: https://github.com/apache/cassandra/pull/1608


;22/Oct/22 11:35;githubbot;600","smiklosovic closed pull request #1609: CASSANDRA-17083 - Fix testsome target to prevent double test execution
URL: https://github.com/apache/cassandra/pull/1609


;22/Oct/22 11:35;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,4200,,,0,4200,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17070,,,,,,,,,,0.0,bereng,bernardo.botella,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jun 22 05:16:50 UTC 2022,,,,,,,All,,,,"0|z0w9ww:",9223372036854775807,,,,brandon.williams,,,,Low,,4.0,,https://github.com/apache/cassandra/commit/92069ec0932774357f5a7babaf3ec28ca1255286,,,,,,,,,See PR,,,,,"05/May/22 23:45;bernardo.botella;I don't think what we are trying to accomplish here is possible with current ant version. Right now, the ant JUnit task we are using provides two different attributes:
 * test -> it has a required field called name, and which represents the FQDN of the test class. It has an optional methods parameter that can be used to define a list of methods to be run. We are using this attribute in the [testsome target|https://github.com/apache/cassandra/blob/trunk/build.xml#L1658-L1668]. Name field does not support wildcards, and that is the reason the testsome target fails as described in the ticket.
 * batchtest -> it receives a series of filters that are used to determine which test classes will be run, and doesn't accept any concept of methods. We are using this attribute in the [test target|https://github.com/apache/cassandra/blob/trunk/build.xml#L1925-L1931], you'll see that if you follow the macros definitions. Those filters support wildcards, and that is the reason the test target works as described in the ticket.

Full documentation of these two attributes can be found [here|https://ant.apache.org/manual/Tasks/junit.html].

Now, as I understand this ticket, we would need to be able to filter by two different dimensions on the batchtest approach (the goal is to perform several test), class name AND methods. As we have just seen, this is not supported at this point as batchtest only supports class names.

Hence, in my opinion, the correct path forward would be:
 # [Create an enhancement report|https://issues.apache.org/bugzilla/enter_bug.cgi?product=Ant&bug_severity=enhancement] for Ant. This should mention the need to modify the [batchtest logic|https://github.com/apache/ant/blob/master/src/main/org/apache/tools/ant/taskdefs/optional/junit/JUnitTask.java#L604-L609] in order to support filter by method names.
 # Work with Ant team members to have this implemented and released.
 # Update the version Cassandra is using to have support for this.

The alternative of extending the [JUnitTask class|https://github.com/apache/ant/blob/master/src/main/org/apache/tools/ant/taskdefs/optional/junit/JUnitTask.java] in our own project to add support to that seems hardly maintainable on the long run, and I would definitely discourage it.;;;","06/May/22 01:44;yifanc;Thank you Bernardo for the detailed explanation! It makes sense to me. 

[~bereng], is the goal of this ticket to make `testsome` to be able to filter with both class name and method names? If so, it feels a bit unclear semantically, when running the command. The method names may or may not be the same across test classes. If the goal is to run all tests from different test classes, `test` is able to do it and the CI config is able to point to a different target. Looks like it is applied during the work on CASSANDRA-17070. ;;;","06/May/22 06:55;bereng;Hi all,

Thanks for looking into this. This is only about {{testsome}} not failing the build when using wildcards. Not about test methods, shared method names across test classes, workarounds with {{test}} etc. Don't look so much into it.

It's just a plain fix of the above bug so you don't get failed runs with {{testsome}} bc of that nonsense error.;;;","06/May/22 10:25;brandon.williams;[~bernardo.botella] thanks for your analysis.  I recall when I first added the testsome target I was trying to allow wildcards and not require the FQDN for the class, but wasn't able to figure either one out.

bq. This is only about testsome not failing the build when using wildcards.

It looks like it does fail when you do this?;;;","06/May/22 11:34;bereng;Yes, it fails when you do use {{testsome}} and succeeds when you do {{test}}

{noformat}
testsome:
    [mkdir] Created dir: /home/bereng/work/repos/bdpWS/17605/build/test/cassandra
    [mkdir] Created dir: /home/bereng/work/repos/bdpWS/17605/build/test/output
[junit-timeout] Testsuite: org.apache.cassandra.cql3.PasswordObfuscatorTest
[junit-timeout] Testsuite: org.apache.cassandra.cql3.PasswordObfuscatorTest Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.045 sec
[junit-timeout] 
[junit-timeout] Testsuite: PasswordObfuscator*Test
[junit-timeout] Testsuite: PasswordObfuscator*Test Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0 sec
[junit-timeout] 
[junit-timeout] Null Test: 	Caused an ERROR
[junit-timeout] PasswordObfuscator*Test
[junit-timeout] java.lang.ClassNotFoundException: PasswordObfuscator*Test
[junit-timeout] 	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
[junit-timeout] 	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
[junit-timeout] 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
[junit-timeout] 	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
[junit-timeout] 	at java.lang.Class.forName0(Native Method)
[junit-timeout] 	at java.lang.Class.forName(Class.java:348)
[junit-timeout] 
[junit-timeout] 
[junit-timeout] Test PasswordObfuscator*Test FAILED

BUILD FAILED
/home/bereng/work/repos/bdpWS/17605/build.xml:1659: The following error occurred while executing this line:
/home/bereng/work/repos/bdpWS/17605/build.xml:1912: Some test(s) failed.

Total time: 20 seconds

{noformat}
;;;","06/May/22 11:41;brandon.williams;I don't think that's surprising given it does not work.  I don't think the effort required here is worth investing, shall we close?;;;","06/May/22 11:56;bereng;It sort of _does_ work. It picks up all the test classes and runs them, see the output. Only it tries to run the class with a wildcard as well. The only job to do here is to see if adding that exclusion is low cost. Which, finger in the air, I would presume it's doable? So I wouldn't close without looking into it. It's probably just adding an {{<exclude>}} somewhere. I can take a look when I get a gap, I'd rather have a look than just closing.;;;","06/May/22 15:12;bernardo.botella;[~bereng] you will see the same output if you run the same command without the wildcard. Something like:
{noformat}
testsome:
[junit-timeout] OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
[junit-timeout] Testsuite: org.apache.cassandra.cql3.PasswordObfuscatorTest
[junit-timeout] Testsuite: org.apache.cassandra.cql3.PasswordObfuscatorTest Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.269 sec
[junit-timeout]
[junit-timeout] OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
[junit-timeout] Testsuite: PasswordObfuscatorTest
[junit-timeout] Testsuite: PasswordObfuscatorTest Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0 sec
[junit-timeout]
[junit-timeout] Null Test: 	Caused an ERROR
[junit-timeout] PasswordObfuscatorTest
[junit-timeout] java.lang.ClassNotFoundException: PasswordObfuscatorTest
[junit-timeout] 	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)
[junit-timeout] 	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)
[junit-timeout] 	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)
[junit-timeout] 	at java.base/java.lang.Class.forName0(Native Method)
[junit-timeout] 	at java.base/java.lang.Class.forName(Class.java:398)
[junit-timeout]
[junit-timeout]
[junit-timeout] Test PasswordObfuscatorTest FAILED

BUILD FAILED
 {noformat}
The reason for that, I believe, is that whenever you try to run testsome not using the FQDN name of the class it runs both batchtest and test. You can see this following the [used macro definition|https://github.com/apache/cassandra/blob/trunk/build.xml#L1659] brings us to this other [macro definition|https://github.com/apache/cassandra/blob/trunk/build.xml#L1906] which in turn [uses batchtest|https://github.com/apache/cassandra/blob/trunk/build.xml#L1538-L1541].

Now, if we want to fix that, we need a way to not execute the batchtest and just stick to the test lines of testsome to prevent that double execution, and fail fast. To do so, we need to modify the default filter on [this line|https://github.com/apache/cassandra/blob/trunk/build.xml#L1659] for the batchtest defined on the macro to ignore the run. I can post the PRs for that. Thanks for the clarification!;;;","06/May/22 16:06;bernardo.botella;I posted the 3 PRs



||PR||
|[3.11|https://github.com/apache/cassandra/pull/1609]|
|[4.0|https://github.com/apache/cassandra/pull/1608]|
|[trunk|https://github.com/apache/cassandra/pull/1610]|

;;;","09/May/22 04:58;bereng;Hi [~bernardo.botella],

thanks for looking into this. But it seems to still be failing:

{noformat}
ant testsome -Dtest.name=PasswordObfuscator*Test

...

testsome:
    [mkdir] Created dir: /tmp/cassandra-CASSANDRA-17083-4.0/build/test/cassandra
    [mkdir] Created dir: /tmp/cassandra-CASSANDRA-17083-4.0/build/test/output
[junit-timeout] Testsuite: PasswordObfuscator*Test
[junit-timeout] Testsuite: PasswordObfuscator*Test Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0 sec
[junit-timeout] 
[junit-timeout] Null Test: 	Caused an ERROR
[junit-timeout] PasswordObfuscator*Test
[junit-timeout] java.lang.ClassNotFoundException: PasswordObfuscator*Test
[junit-timeout] 	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
[junit-timeout] 	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
[junit-timeout] 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
[junit-timeout] 	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
[junit-timeout] 	at java.lang.Class.forName0(Native Method)
[junit-timeout] 	at java.lang.Class.forName(Class.java:348)
[junit-timeout] 
[junit-timeout] 
[junit-timeout] Test PasswordObfuscator*Test FAILED
{noformat}

We'd also need a 4.1 branch.;;;","09/May/22 15:26;bernardo.botella;Hi [~bereng],

Thanks for following up!

 

Yes, it fails as expected (as I mentioned before, the testsome target will need the FQDN passed on the test.name parameter to work). My change is just preventing the double execution that was happening before which is, the batchtest part of the macro AND the test part of the testsome target. With my change, only the test part of the testsome target is executed, and fails because the wildcard is not a valid FQDN. If you still want to execute tests with a wildcard, you can always use the test target instead.

 

I will post the new change for the 4.1 branch.;;;","10/May/22 06:43;bereng;Ok icwym. But wdyt about this?

{noformat}
diff --git a/build.xml b/build.xml
index 343f7e87a0..b32f5b45b7 100644
--- a/build.xml
+++ b/build.xml
@@ -1656,9 +1656,27 @@
     ant testsome -Dtest.name=org.apache.cassandra.service.StorageServiceServerTest -Dtest.methods=testRegularMode,testGetAllRangesEmpty
   -->
   <target name=""testsome"" depends=""build-test"" description=""Execute specific unit tests"" >
+    <condition property=""withoutMethods"">
+      <and>
+        <equals arg1=""${test.methods}"" arg2=""""/>
+        <not>
+          <contains string=""${test.name}"" substring=""*""/>
+        </not>
+      </and>
+    </condition>
+    <condition property=""withMethods"">
+      <and>
+        <not>
+         <equals arg1=""${test.methods}"" arg2=""""/>
+        </not>
+        <not>
+          <contains string=""${test.name}"" substring=""*""/>
+        </not>
+      </and>
+    </condition>
     <testmacro inputdir=""${test.unit.src}"" timeout=""${test.timeout}"">
-      <test unless:blank=""${test.methods}"" name=""${test.name}"" methods=""${test.methods}"" outfile=""build/test/output/TEST-${test.name}-${test.methods}""/>
-      <test if:blank=""${test.methods}"" name=""${test.name}"" outfile=""build/test/output/TEST-${test.name}""/>
+         <test if=""withMethods"" name=""${test.name}"" methods=""${test.methods}"" outfile=""build/test/output/TEST-${test.name}-${test.methods}""/>
+      <test if=""withoutMethods"" name=""${test.name}"" outfile=""build/test/output/TEST-${test.name}""/>
       <jvmarg value=""-Dlegacy-sstable-root=${test.data}/legacy-sstables""/>
       <jvmarg value=""-Dinvalid-legacy-sstable-root=${test.data}/invalid-legacy-sstables""/>
       <jvmarg value=""-Dcassandra.ring_delay_ms=1000""/>
{noformat}

Takes a FQDN and doesn't fail, takes a wildcard running all matching tests and doesn't fail, also doesn't do double execution. If I didn't miss anything this has all the advantages and none of the limitations?;;;","10/May/22 15:34;bernardo.botella;I like the idea of the flexibility that provides, but it comes with a cost. For example, as is, if you pass both a wildcard on the test.name and some test.methods, it will silently ignore the test.methods and may lead to confusion on whoever is trying to run that command. That of course can be checked with yet another set of conditions in the target definition (IF we have have a wildcard AND some test methods, then fail). 

My issue with this is that the target becomes somehow harder to understand by adding so many conditions and alternative flows, therefore, harder to maintain. Given that we have the alternative of using ""ant test"" what do you think about just failing fast if someone tries to use testsome with a wildcard? Something like:

{code:java}
diff --git a/build.xml b/build.xml
index d0466578ac..e65909fe67 100644
--- a/build.xml
+++ b/build.xml
@@ -1656,7 +1656,12 @@
     ant testsome -Dtest.name=org.apache.cassandra.service.StorageServiceServerTest -Dtest.methods=testRegularMode,testGetAllRangesEmpty
   -->
   <target name=""testsome"" depends=""build-test"" description=""Execute specific unit tests"" >
-    <testmacro inputdir=""${test.unit.src}"" timeout=""${test.timeout}"">
+    <fail message=""testsome target does not support the use of wildcards. To use wildcards, please use 'ant test'."">
+      <condition>
+        <contains string=""${test.name}"" substring=""*""/>
+      </condition>
+    </fail>
+    <testmacro inputdir=""${test.unit.src}"" timeout=""${test.timeout}"" filter=""${test.name}"">
       <test unless:blank=""${test.methods}"" name=""${test.name}"" methods=""${test.methods}"" outfile=""build/test/output/TEST-${test.name}-${test.methods}""/>
       <test if:blank=""${test.methods}"" name=""${test.name}"" outfile=""build/test/output/TEST-${test.name}""/>
       <jvmarg value=""-Dlegacy-sstable-root=${test.data}/legacy-sstables""/>
{code}

I guess it is just a matter of preference at this point, but I find this ""fail fast use this alternative instead"" approach simple enough and easier to maintain in the long run. In any case, happy to hear your thoughts on this.;;;","11/May/22 05:12;bereng;Hi [~bernardo.botella],

thanks for looking. My preference would be to support wildcards in the test name which is why I opened the ticket in the first place and what I needed at the time. That comes from working on some features like the {{View*Test}} family. Going back & forth test/testsome was a pain, I've never hit the need to use wildcards in methods and imo 2 simple conditions don't hit readability, it's just ant's syntax being very verbose.

Let me know if you want to try to put up a PR for trunk, probably my quick & dirty draft can be written more elegantly , or if you prefer me to take over?

On second thoughts I am going to constrain this to trunk only as it doesn't seem severe/critical enough/worth it to go disturb branches being released atm :thinking:;;;","16/May/22 07:15;bereng;Hi [~bernardo.botella],

just double checking if you need anything from me here?;;;","17/May/22 00:25;bernardo.botella;Nope, I've got everything I need. Sorry for the delay, I've been just busy this last week. Will take a shot at it hopefully by tomorrow.;;;","17/May/22 05:46;bereng;[~bernardo.botella] please take the time you need, no hurries. I was doing my sort of weekly check on tickets to make sure I wasn't blocking anything :-) Take all the time you need.;;;","03/Jun/22 09:49;bereng;[~bernardo.botella] I was going around trying to close loose ends I had on my list. I created a PR [here|https://github.com/apache/cassandra/pull/1665] with the suggested changes. Again feel free to disagree or suggest changes. But if we're not against these going in we could merge them and then open a new ticket for any improvements you have in your mind. These are always welcomed :-) Wdyt?;;;","14/Jun/22 05:22;bereng;Hi, moving this to review for the small original fix just to close loose ends. We can always open a new ticket for any further improvements which are always welcomed :-);;;","21/Jun/22 13:29;brandon.williams;+1;;;","22/Jun/22 05:16;bereng;Thx [~bernardo.botella] and [~brandon.williams] for your help here :-);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix test: dtest-upgrade.upgrade_tests.drop_compact_storage_upgrade_test.TestDropCompactStorage.test_drop_compact_storage_mixed_cluster,CASSANDRA-17080,13408963,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,jmckenzie,jmckenzie,28/Oct/21 17:50,27/May/22 19:25,13/Jul/23 08:40,02/Dec/21 23:27,3.0.26,4.0.2,4.1,4.1-alpha1,,,,Test/dtest/python,,,,0,,,"!https://ci-cassandra.apache.org/static/a177fe56/images/32x32/health-80plus.png! Failed 28 times in the last 28 runs. Flakiness: 0%, Stability: 0%
  
 Example of failure: [https://ci-cassandra.apache.org/job/Cassandra-trunk/801/testReport/junit/dtest-upgrade.upgrade_tests.drop_compact_storage_upgrade_test/TestDropCompactStorage/test_drop_compact_storage_mixed_cluster/]
   
{code:java}
upgrade_tests/drop_compact_storage_upgrade_test.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <upgrade_tests.drop_compact_storage_upgrade_test.TestDropCompactStorage object at 0x7fa0e7f1ceb0>
session = <cassandra.cluster.Session object at 0x7fa0e7c56d30>
assert_msg = 'Cannot DROP COMPACT STORAGE as some nodes in the cluster ([/127.0.0.2:7000, /127.0.0.1:7000]) are not on 4.0+ yet. Please upgrade those nodes and run `upgradesstables` before retrying.'

    def drop_compact_storage(self, session, assert_msg):
        try:
            session.execute(""ALTER TABLE drop_compact_storage_test.test DROP COMPACT STORAGE"")
            pytest.fail(""No exception has been thrown"")
        except InvalidRequest as e:
>           assert assert_msg in str(e)
E           assert 'Cannot DROP COMPACT STORAGE as some nodes in the cluster ([/127.0.0.2:7000, /127.0.0.1:7000]) are not on 4.0+ yet. Please upgrade those nodes and run `upgradesstables` before retrying.' in 'Error from server: code=2200 [Invalid query] message=""Cannot DROP COMPACT STORAGE as some nodes in the cluster ([/127....1:7000, /127.0.0.2:7000]) are not on 4.0+ yet. Please upgrade those nodes and run `upgradesstables` before retrying.""'
E            +  where 'Error from server: code=2200 [Invalid query] message=""Cannot DROP COMPACT STORAGE as some nodes in the cluster ([/127....1:7000, /127.0.0.2:7000]) are not on 4.0+ yet. Please upgrade those nodes and run `upgradesstables` before retrying.""' = str(InvalidRequest('Error from server: code=2200 [Invalid query] message=""Cannot DROP COMPACT STORAGE as some nodes in the...1:7000, /127.0.0.2:7000]) are not on 4.0+ yet. Please upgrade those nodes and run `upgradesstables` before retrying.""'))

upgrade_tests/drop_compact_storage_upgrade_test.py:45: AssertionError
{code}",,bereng,e.dimitrova,jmckenzie,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Dec 02 23:26:58 UTC 2021,,,,,,,All,,,,"0|z0w99k:",9223372036854775807,,,,bereng,,,,Normal,,4.0.1,,https://github.com/apache/cassandra-dtest/commit/e215a72e646d40eb8ae28c4b4020e26447034384,,,,,,,,,"[Python DTest patch|https://github.com/apache/cassandra-dtest/compare/trunk...ekaterinadimitrova2:C17080?expand=1]

It's a test issue, no new tests needed, the one in hand was fixed",,,,,"22/Nov/21 22:23;e.dimitrova;It seems locally and in Jenkins - the error message appears to have ordered the IPs in one order, now I ran it 100 times in Circle and it was always different order.

I made the test checking just that all the IPs we want appear in the exception and order won't matter.

[Python DTest patch|https://github.com/apache/cassandra-dtest/compare/trunk...ekaterinadimitrova2:C17080?expand=1];;;","01/Dec/21 05:38;bereng;PR lgtm but we still need a CI runs?;;;","01/Dec/21 20:34;e.dimitrova;Well, I mentioned that it doesn't fail in Circle but I reproduce it locally so I was testing locally. I was thinking that probably we can skip the full for local run proof but considering you asked and our CI is funky, I pushed only the upgrade tests in Jenkins for 3.0, 4.0 and trunk as I am using the updated method also with the test for 3.0. Everything looks good to me:
[3.0|https://jenkins-cm4.apache.org/job/Cassandra-devbranch-dtest-upgrade/735/#showFailuresLink], [4.0|https://jenkins-cm4.apache.org/job/Cassandra-devbranch-dtest-upgrade/734/#showFailuresLink], [trunk|https://jenkins-cm4.apache.org/job/Cassandra-devbranch-dtest-upgrade/733/#showFailuresLink]

 

Side note: I don't see timeouts and these are rebased. ;;;","02/Dec/21 05:45;bereng;Right. As the original link to the failure is on trunk and afaik CI is weird on 4.0 a CI link was worth it imo. Did you notice how the 4.0 here has 10 failures instead of 40-ish? There is sthg going on in 4.0... Anyway regarding this ticket +1. Thx for the work!;;;","02/Dec/21 23:26;e.dimitrova;Committed [here|https://github.com/apache/cassandra-dtest/commit/e215a72e646d40eb8ae28c4b4020e26447034384], thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix failing test: SSTableReaderTest.testPersistentStatistics,CASSANDRA-17078,13408959,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jmckenzie,jmckenzie,jmckenzie,28/Oct/21 17:43,27/May/22 19:25,13/Jul/23 08:40,07/Feb/22 17:58,4.0.3,4.1,4.1-alpha1,,,,,Test/unit,,,,0,,,"JDK8 unit test failure

See it on CircleCI but not on Jenkins ASF infra right now.
{code:java}
java.lang.RuntimeException: Failed importing sstables
	at org.apache.cassandra.db.SSTableImporter.importNewSSTables(SSTableImporter.java:164)
	at org.apache.cassandra.db.ColumnFamilyStore.loadNewSSTables(ColumnFamilyStore.java:734)
	at org.apache.cassandra.io.sstable.SSTableReaderTest.clearAndLoad(SSTableReaderTest.java:222)
	at org.apache.cassandra.io.sstable.SSTableReaderTest.testPersistentStatistics(SSTableReaderTest.java:215)
Caused by: java.lang.RuntimeException: Failed to rename /tmp/cassandra/build/test/cassandra/data/SSTableReaderTest/Standard1-da581e50380611ecaad41173773221f9/nb-9-big-Digest.crc32 to /tmp/cassandra/build/test/cassandra/data/SSTableReaderTest/Standard1-da581e50380611ecaad41173773221f9/nb-13-big-Digest.crc32
	at org.apache.cassandra.io.util.PathUtils.rename(PathUtils.java:385)
	at org.apache.cassandra.io.util.File.move(File.java:227)
	at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:704)
	at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:698)
	at org.apache.cassandra.io.sstable.format.SSTableWriter.rename(SSTableWriter.java:337)
	at org.apache.cassandra.io.sstable.format.SSTableReader.moveAndOpenSSTable(SSTableReader.java:2339)
	at org.apache.cassandra.db.SSTableImporter.importNewSSTables(SSTableImporter.java:139)
Caused by: java.nio.file.NoSuchFileException: /tmp/cassandra/build/test/cassandra/data/SSTableReaderTest/Standard1-da581e50380611ecaad41173773221f9/nb-9-big-Digest.crc32 -> /tmp/cassandra/build/test/cassandra/data/SSTableReaderTest/Standard1-da581e50380611ecaad41173773221f9/nb-13-big-Digest.crc32
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixCopyFile.move(UnixCopyFile.java:396)
	at sun.nio.fs.UnixFileSystemProvider.move(UnixFileSystemProvider.java:262)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.cassandra.io.util.PathUtils.atomicMoveWithFallback(PathUtils.java:396)
	at org.apache.cassandra.io.util.PathUtils.rename(PathUtils.java:377)
{code}
 

 ",,azotcsit,jjordan,jmckenzie,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jmckenzie,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Feb 07 17:58:21 UTC 2022,,,,,,,All,,,,"0|z0w98o:",9223372036854775807,,,,azotcsit,jjordan,,,Low,,4.0,,"https://git-wip-us.apache.org/repos/asf?p=cassandra.git;a=commit;h=f2816f5a7cd0e0416870bb21b8cec8f26c05d1f7",,,,,,,,,Change to flaky test,,,,,"03/Feb/22 19:41;jmckenzie;Got a prelim branch [here|https://github.com/apache/cassandra/compare/trunk...josh-mckenzie:cassandra-17078?expand=1] that does a few things in SSTableReaderTest:
1. Removes duplication on the CF SSTable discarding at the start of many tests
2. Isolates the test w/the intermittent failure in circle to its own CF instead of sharing w/other tests
3. Isolates the test that has a couple potentially troublesome calls (.deleteOnExit, etc) that may be leading to ordering and timing issues between tests.

A lot of these tests are mucking around directly with SSTable files, deleting things, moving things, deleting directories and files with hooks, you name it. A lot of stuff that's risky when it comes to consistency if the parallelization of your test running infra doesn't have deterministic test ordering. 

Not sure if I can repro the original problem locally; going to give it a solid soak and if it doesn't repro try it on circle for a multiplex run as well.;;;","07/Feb/22 15:56;jmckenzie;|Item|Link|
|Branch|[Link|https://github.com/apache/cassandra/compare/trunk...josh-mckenzie:cassandra-17078?expand=1]|
|JDK8 repeat|[Link|https://app.circleci.com/pipelines/github/josh-mckenzie/cassandra/173/workflows/61a47fee-6514-41ab-a180-31534801b8ec]|
|JDK11 repeat|[Link|https://app.circleci.com/pipelines/github/josh-mckenzie/cassandra/173/workflows/0ec1e264-c0db-41aa-b5a7-01678d7237b2]|;;;","07/Feb/22 16:49;azotcsit;The changes LGTM, +1

Should we backport them to 4.0 and 3.x branches? ;;;","07/Feb/22 16:58;jjordan;{{You missed removing store.discardSSTables(System.currentTimeMillis()); in }}{{{}testGetPositionsForRanges{}}}.  Otherwise LGTM.;;;","07/Feb/22 17:18;jmckenzie;{quote}Should we backport them to 4.0 and 3.x branches?
{quote}
I'll take a look; if the tests isn't flaking out there I'd say we hold off and I'll just keep an eye on it and backport if it starts to misbehave later. edit: shows up on 4.0. I'll target 4.0.x and 4.x with this.
{quote}You missed removing store.discardSSTables(System.currentTimeMillis()); in testGetPositionsForRanges
{quote}
Good catch.;;;","07/Feb/22 17:58;jmckenzie;Committed to 4.0 and trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DebuggableThreadPoolExecutor does not propagate client warnings,CASSANDRA-17072,13408860,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,28/Oct/21 09:25,27/May/22 19:25,13/Jul/23 08:40,19/Nov/21 01:33,4.0.2,4.1,4.1-alpha1,,,,,Local/Other,,,,0,,,"Extracted this as a separate ticket per discussion on CASSANDRA-17044

The problem is in {{DebuggableThreadPoolExecutor}} - it does not propagate executor locals to the thread when tracing is disabled. It is probably expected that we propagate the state if at least one executor local is defined, but we only check for tracing and completely ignore client warnings.

The attached PR fixes the problem, adds some tests and reverts a workaround for client warnings in some schema alteration statements implemented in CASSANDRA-16296 (described below).

----

h4. Old description - still valid, but this is just a manifestation of the problem rather than the problem itself
This seemed to be screwed a bit. In just two schema alteration statements we collect client warnings which are captured during the transformation into a local collection. 

I guess it is done that way because the transformation is being executed in a different stage (migration) and client warnings collected in that stage are not present in the stage where the query is executed. 

Then, the client warnings are retrieved using {{clientWarnings}} method and added to the captured client warnings in the stage which is executing the query. 

This mechanism was implemented only in two schema alteration statements. It is possible that for other ones the client warnings can simply get lost.


",,adelapena,bereng,dcapwell,e.dimitrova,jlewandowski,,,,,,,,,,,"dcapwell commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r746766909



##########
File path: test/unit/org/apache/cassandra/concurrent/DebuggableThreadPoolExecutorTest.java
##########
@@ -78,6 +82,34 @@ public void runMayThrow() throws InterruptedException
         assert delta >= 9 * 50 : delta;
     }
 
+    @Test
+    public void testExecuteFutureTaskWhileCapturingClientWarnings() throws InterruptedException
+    {
+        testClientWarnings(executor -> executor.execute(() -> ClientWarn.instance.warn(""msg"")));
+        testClientWarnings(executor -> executor.submit(() -> ClientWarn.instance.warn(""msg"")));
+        testClientWarnings(executor -> executor.submit(() -> ClientWarn.instance.warn(""msg""), null));
+        testClientWarnings(executor -> executor.submit((Callable<Void>) () -> {
+            ClientWarn.instance.warn(""msg"");
+            return null;
+        }));
+    }
+
+    private void testClientWarnings(Consumer<DebuggableThreadPoolExecutor> schedulingTask) throws InterruptedException
+    {
+        LinkedBlockingQueue<Runnable> q = new LinkedBlockingQueue<Runnable>(1);
+        DebuggableThreadPoolExecutor executor = new DebuggableThreadPoolExecutor(1,

Review comment:
       nit: can reuse the executor rather than start/stop for each test case

##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/CreateKeyspaceStatement.java
##########
@@ -87,10 +83,6 @@ public Keyspaces apply(Keyspaces schema)
         keyspace.params.validate(keyspaceName);
         Keyspaces keyspaces = schema.withAddedOrUpdated(keyspace);
 
-        int newNumWarnings = ClientWarn.instance.numWarnings();
-        if (newNumWarnings > previousNumWarnings)
-            clientWarnings.addAll(ClientWarn.instance.getWarnings().subList(previousNumWarnings, newNumWarnings));
-

Review comment:
       I know you are removing but I am trying to figure out the justification for ignoring previous warnings...  Tried reading CASSANDRA-16296 and this comes off as a work around to a bug rather than fix the bug...  https://issues.apache.org/jira/browse/CASSANDRA-16296?focusedCommentId=17277213&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17277213
   
   @adelapena can I get your eyes here?

##########
File path: test/unit/org/apache/cassandra/schema/SchemaTest.java
##########
@@ -78,4 +92,81 @@ public void testTransKsMigration() throws IOException
         }
     }
 
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE KeyspaceParams.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)"")})
+    public void testClientWarningsOnCreateKeyspace() throws Throwable
+    {
+        ClientWarn.instance.captureWarnings();
+        injectedWarnings.clear();
+        createKeyspace(""CREATE KEYSPACE %s WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}"");
+
+        Assertions.assertThat(injectedWarnings).contains(msg1, msg2); // failure here means the bm rules need to be updated
+        Assertions.assertThat(ClientWarn.instance.getWarnings()).containsExactlyInAnyOrder(msg1, msg2);
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE TableMetadata.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),

Review comment:
       missing case for `alter`

##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/AlterKeyspaceStatement.java
##########
@@ -84,10 +81,6 @@ public Keyspaces apply(Keyspaces schema)
 
         Keyspaces res = schema.withAddedOrUpdated(newKeyspace);
 
-        int newNumWarnings = ClientWarn.instance.numWarnings();

Review comment:
       I know you are removing but I am trying to figure out the justification for ignoring previous warnings...  Tried reading CASSANDRA-16296 and this comes off as a work around to a bug rather than fix the bug...  https://issues.apache.org/jira/browse/CASSANDRA-16296?focusedCommentId=17277213&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17277213
   
   @adelapena can I get your eyes here?

##########
File path: src/java/org/apache/cassandra/service/ClientWarn.java
##########
@@ -74,6 +74,11 @@ public void resetWarnings()
         warnLocal.remove();
     }
 
+    public static boolean isCapturingClientWarnings()

Review comment:
       dead code?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 17:18;githubbot;600","jacek-lewandowski commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r746895619



##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/CreateKeyspaceStatement.java
##########
@@ -87,10 +83,6 @@ public Keyspaces apply(Keyspaces schema)
         keyspace.params.validate(keyspaceName);
         Keyspaces keyspaces = schema.withAddedOrUpdated(keyspace);
 
-        int newNumWarnings = ClientWarn.instance.numWarnings();
-        if (newNumWarnings > previousNumWarnings)
-            clientWarnings.addAll(ClientWarn.instance.getWarnings().subList(previousNumWarnings, newNumWarnings));
-

Review comment:
       I don't think we are ignoring anything. AFAIR client warning works in the way that once we start processing a query, client warnings state is initialized and since that time whenever we do `ClientWarn.instance.warn` it is added to the client warnings internal state which is for this particular client request. The workaround here was because state of client warnings was not passed from the initial thread which processed the request to the subtasks processed in different threads (in this case, the task was executed in migration stage).




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 18:58;githubbot;600","jacek-lewandowski commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r746896423



##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/CreateKeyspaceStatement.java
##########
@@ -87,10 +83,6 @@ public Keyspaces apply(Keyspaces schema)
         keyspace.params.validate(keyspaceName);
         Keyspaces keyspaces = schema.withAddedOrUpdated(keyspace);
 
-        int newNumWarnings = ClientWarn.instance.numWarnings();
-        if (newNumWarnings > previousNumWarnings)
-            clientWarnings.addAll(ClientWarn.instance.getWarnings().subList(previousNumWarnings, newNumWarnings));
-

Review comment:
       btw. I can add an initial warning by byteman, before we get into the apply method and check if it is not cleared

##########
File path: src/java/org/apache/cassandra/service/ClientWarn.java
##########
@@ -74,6 +74,11 @@ public void resetWarnings()
         warnLocal.remove();
     }
 
+    public static boolean isCapturingClientWarnings()

Review comment:
       yes, sorry




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 18:59;githubbot;600","jacek-lewandowski commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r746899081



##########
File path: test/unit/org/apache/cassandra/schema/SchemaTest.java
##########
@@ -78,4 +92,81 @@ public void testTransKsMigration() throws IOException
         }
     }
 
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE KeyspaceParams.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)"")})
+    public void testClientWarningsOnCreateKeyspace() throws Throwable
+    {
+        ClientWarn.instance.captureWarnings();
+        injectedWarnings.clear();
+        createKeyspace(""CREATE KEYSPACE %s WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}"");
+
+        Assertions.assertThat(injectedWarnings).contains(msg1, msg2); // failure here means the bm rules need to be updated
+        Assertions.assertThat(ClientWarn.instance.getWarnings()).containsExactlyInAnyOrder(msg1, msg2);
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE TableMetadata.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),

Review comment:
       yup, I can added alter as well, but I don't think it makes much sense - this way we should add for each single schema alteration statement. I added ""create table"" because for this case the code was actually failing the tests - if the warning was added inside `apply`, it was not returned to the client (it was because the workaround was applied only to create and alter keyspace)
   




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 19:01;githubbot;600","bereng commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r747267457



##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/CreateKeyspaceStatement.java
##########
@@ -87,10 +83,6 @@ public Keyspaces apply(Keyspaces schema)
         keyspace.params.validate(keyspaceName);
         Keyspaces keyspaces = schema.withAddedOrUpdated(keyspace);
 
-        int newNumWarnings = ClientWarn.instance.numWarnings();
-        if (newNumWarnings > previousNumWarnings)
-            clientWarnings.addAll(ClientWarn.instance.getWarnings().subList(previousNumWarnings, newNumWarnings));
-

Review comment:
       We're not ignoring warnings, but adding just the _newly generated ones_. Otherwise they would accumulate and duplicate depending on how state and multi-threading played at each particular scenario.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Nov/21 07:40;githubbot;600","bereng commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r747267457



##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/CreateKeyspaceStatement.java
##########
@@ -87,10 +83,6 @@ public Keyspaces apply(Keyspaces schema)
         keyspace.params.validate(keyspaceName);
         Keyspaces keyspaces = schema.withAddedOrUpdated(keyspace);
 
-        int newNumWarnings = ClientWarn.instance.numWarnings();
-        if (newNumWarnings > previousNumWarnings)
-            clientWarnings.addAll(ClientWarn.instance.getWarnings().subList(previousNumWarnings, newNumWarnings));
-

Review comment:
       We're not ignoring warnings, but adding just the _newly generated ones_. Otherwise they were accumulating and duplicating depending on how state and multi-threading played at each particular scenario.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Nov/21 07:41;githubbot;600","adelapena commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r747695652



##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/CreateKeyspaceStatement.java
##########
@@ -87,10 +83,6 @@ public Keyspaces apply(Keyspaces schema)
         keyspace.params.validate(keyspaceName);
         Keyspaces keyspaces = schema.withAddedOrUpdated(keyspace);
 
-        int newNumWarnings = ClientWarn.instance.numWarnings();
-        if (newNumWarnings > previousNumWarnings)
-            clientWarnings.addAll(ClientWarn.instance.getWarnings().subList(previousNumWarnings, newNumWarnings));
-

Review comment:
       Indeed that was a workaround to avoid accumulating warnings from previous queries. With the proposed changes we still get the proper warnings without needing that code to remove repetitions. This can be verified for example by running these two queries in a single node cluster:
   ```
   CREATE KEYSPACE k1 WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 2}; # warns
   CREATE KEYSPACE k2 WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}; # doesn't warn
   ```
   We also have some tests to verify that this works as expected.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Nov/21 17:38;githubbot;600","dcapwell commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r748662178



##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/CreateKeyspaceStatement.java
##########
@@ -87,10 +83,6 @@ public Keyspaces apply(Keyspaces schema)
         keyspace.params.validate(keyspaceName);
         Keyspaces keyspaces = schema.withAddedOrUpdated(keyspace);
 
-        int newNumWarnings = ClientWarn.instance.numWarnings();
-        if (newNumWarnings > previousNumWarnings)
-            clientWarnings.addAll(ClientWarn.instance.getWarnings().subList(previousNumWarnings, newNumWarnings));
-

Review comment:
       > avoid accumulating warnings from previous queries
   
   might not understand what you are saying, but if ClientWarn contains state from a different request, then that is a bug (which I would assume is fixed by this PR?).
   
   > We also have some tests to verify that this works as expected.
   
   so if they pass that means this PR fixes the root cause?  Works for me =)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Nov/21 01:20;githubbot;600","dcapwell commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r748662570



##########
File path: test/unit/org/apache/cassandra/schema/SchemaTest.java
##########
@@ -78,4 +92,81 @@ public void testTransKsMigration() throws IOException
         }
     }
 
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE KeyspaceParams.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)"")})
+    public void testClientWarningsOnCreateKeyspace() throws Throwable
+    {
+        ClientWarn.instance.captureWarnings();
+        injectedWarnings.clear();
+        createKeyspace(""CREATE KEYSPACE %s WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}"");
+
+        Assertions.assertThat(injectedWarnings).contains(msg1, msg2); // failure here means the bm rules need to be updated
+        Assertions.assertThat(ClientWarn.instance.getWarnings()).containsExactlyInAnyOrder(msg1, msg2);
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE TableMetadata.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),

Review comment:
       given this patch/tests are showing that executors are doing the right thing; I am cool not testing every DDL, but if its dead code then should remove




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Nov/21 01:23;githubbot;600","jacek-lewandowski commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r748695279



##########
File path: test/unit/org/apache/cassandra/schema/SchemaTest.java
##########
@@ -78,4 +92,81 @@ public void testTransKsMigration() throws IOException
         }
     }
 
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE KeyspaceParams.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)"")})
+    public void testClientWarningsOnCreateKeyspace() throws Throwable
+    {
+        ClientWarn.instance.captureWarnings();
+        injectedWarnings.clear();
+        createKeyspace(""CREATE KEYSPACE %s WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}"");
+
+        Assertions.assertThat(injectedWarnings).contains(msg1, msg2); // failure here means the bm rules need to be updated
+        Assertions.assertThat(ClientWarn.instance.getWarnings()).containsExactlyInAnyOrder(msg1, msg2);
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE TableMetadata.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaTest.addWarnToList($!)""),

Review comment:
       yes, I'll remove it, just was off for the last two days




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Nov/21 07:52;githubbot;600","bereng commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r749029765



##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/CreateKeyspaceStatement.java
##########
@@ -87,10 +83,6 @@ public Keyspaces apply(Keyspaces schema)
         keyspace.params.validate(keyspaceName);
         Keyspaces keyspaces = schema.withAddedOrUpdated(keyspace);
 
-        int newNumWarnings = ClientWarn.instance.numWarnings();
-        if (newNumWarnings > previousNumWarnings)
-            clientWarnings.addAll(ClientWarn.instance.getWarnings().subList(previousNumWarnings, newNumWarnings));
-

Review comment:
       It is not from other queries but from the same. You want
   
   > Your warning 1
   > Your warning 2
   
   instead of
   
   > Your warning 1
   > Your warning 1
   > Your warning 2
   
   Makes sense? But I'm terrible at explaining things lol




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Nov/21 06:14;githubbot;600","bereng commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r749232770



##########
File path: test/unit/org/apache/cassandra/schema/SchemaStatementWarningsTest.java
##########
@@ -0,0 +1,126 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.schema;
+
+import java.util.HashSet;
+import java.util.Queue;
+import java.util.Set;
+import java.util.UUID;
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.service.ClientWarn;
+import org.assertj.core.api.Assertions;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMRules;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
+
+@RunWith(BMUnitRunner.class)
+public class SchemaStatementWarningsTest extends CQLTester
+{
+    @BeforeClass
+    public static void setupDatabaseDescriptor()
+    {
+        DatabaseDescriptor.daemonInitialization();
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE KeyspaceParams.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",

Review comment:
       Weren't you intending to remove this one iiuc?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Nov/21 11:24;githubbot;600","jacek-lewandowski commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r749236499



##########
File path: test/unit/org/apache/cassandra/schema/SchemaStatementWarningsTest.java
##########
@@ -0,0 +1,126 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.schema;
+
+import java.util.HashSet;
+import java.util.Queue;
+import java.util.Set;
+import java.util.UUID;
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.service.ClientWarn;
+import org.assertj.core.api.Assertions;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMRules;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
+
+@RunWith(BMUnitRunner.class)
+public class SchemaStatementWarningsTest extends CQLTester
+{
+    @BeforeClass
+    public static void setupDatabaseDescriptor()
+    {
+        DatabaseDescriptor.daemonInitialization();
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE KeyspaceParams.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",

Review comment:
       actually not, it is not harmful and it makes the rules set applicable for both statements which override `clientWarnings` and those which do not




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Nov/21 11:29;githubbot;600","adelapena commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r747738526



##########
File path: test/unit/org/apache/cassandra/schema/SchemaTest.java
##########
@@ -19,21 +19,35 @@
 package org.apache.cassandra.schema;
 
 import java.io.IOException;
+import java.util.HashSet;
+import java.util.Queue;
+import java.util.Set;
+import java.util.UUID;
+import java.util.concurrent.ConcurrentLinkedQueue;
 
+import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
+import org.junit.runner.RunWith;
 
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
 import org.apache.cassandra.db.Keyspace;
 import org.apache.cassandra.db.commitlog.CommitLog;
 import org.apache.cassandra.gms.Gossiper;
+import org.apache.cassandra.service.ClientWarn;
+import org.assertj.core.api.Assertions;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMRules;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
 
-import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 
-public class SchemaTest
+//@RunWith(BMUnitRunner.class)

Review comment:
       Why is this commented?

##########
File path: test/unit/org/apache/cassandra/schema/SchemaStatementWarningsTest.java
##########
@@ -0,0 +1,126 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.schema;
+
+import java.util.HashSet;
+import java.util.Queue;
+import java.util.Set;
+import java.util.UUID;
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.service.ClientWarn;
+import org.assertj.core.api.Assertions;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMRules;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
+
+@RunWith(BMUnitRunner.class)
+public class SchemaStatementWarningsTest extends CQLTester
+{
+    @BeforeClass
+    public static void setupDatabaseDescriptor()
+    {
+        DatabaseDescriptor.daemonInitialization();
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE KeyspaceParams.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)"") })
+    public void testClientWarningsOnCreateKeyspace() throws Throwable
+    {
+        ClientWarn.instance.captureWarnings();
+        injectedWarnings.clear();
+        createKeyspace(""CREATE KEYSPACE %s WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}"");
+
+        Assertions.assertThat(injectedWarnings).contains(msg1, msg2); // failure here means the bm rules need to be updated
+        Assertions.assertThat(ClientWarn.instance.getWarnings()).containsExactlyInAnyOrder(msg1, msg2);
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE TableMetadata.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+    })
+    public void testClientWarningsOnCreateTable() throws Throwable
+    {
+        ClientWarn.instance.captureWarnings();
+        injectedWarnings.clear();
+        createTable(""CREATE TABLE %s (k int primary key, v int)"");
+
+        Assertions.assertThat(injectedWarnings).contains(msg1, msg2); // failure here means the bm rules need to be updated
+        Assertions.assertThat(ClientWarn.instance.getWarnings()).containsExactlyInAnyOrder(msg1, msg2);
+    }
+
+    static volatile String msg1, msg2;

Review comment:
       This can be `private`. Also we could place it at the beginning of the class, before methods.

##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/AlterKeyspaceStatement.java
##########
@@ -63,9 +63,6 @@ public AlterKeyspaceStatement(String keyspaceName, KeyspaceAttributes attrs)
 
     public Keyspaces apply(Keyspaces schema)
     {
-        if (ClientWarn.instance.get() == null)

Review comment:
       Nit: unused import of `ClientWarn`

##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/CreateKeyspaceStatement.java
##########
@@ -87,10 +83,6 @@ public Keyspaces apply(Keyspaces schema)
         keyspace.params.validate(keyspaceName);
         Keyspaces keyspaces = schema.withAddedOrUpdated(keyspace);

Review comment:
       Nit: now we can directly return `schema.withAddedOrUpdated(keyspace)` without putting it in the `keyspaces` var.

##########
File path: test/unit/org/apache/cassandra/schema/SchemaStatementWarningsTest.java
##########
@@ -0,0 +1,126 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.schema;
+
+import java.util.HashSet;
+import java.util.Queue;
+import java.util.Set;
+import java.util.UUID;
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.service.ClientWarn;
+import org.assertj.core.api.Assertions;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMRules;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
+
+@RunWith(BMUnitRunner.class)
+public class SchemaStatementWarningsTest extends CQLTester
+{
+    @BeforeClass
+    public static void setupDatabaseDescriptor()
+    {
+        DatabaseDescriptor.daemonInitialization();
+    }

Review comment:
       I think we don't need this in a `CQLTester`

##########
File path: test/unit/org/apache/cassandra/schema/SchemaStatementWarningsTest.java
##########
@@ -0,0 +1,126 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.schema;
+
+import java.util.HashSet;
+import java.util.Queue;
+import java.util.Set;
+import java.util.UUID;
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.service.ClientWarn;
+import org.assertj.core.api.Assertions;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMRules;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
+
+@RunWith(BMUnitRunner.class)
+public class SchemaStatementWarningsTest extends CQLTester
+{
+    @BeforeClass
+    public static void setupDatabaseDescriptor()
+    {
+        DatabaseDescriptor.daemonInitialization();
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE KeyspaceParams.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)"") })
+    public void testClientWarningsOnCreateKeyspace() throws Throwable

Review comment:
       Nit: we don't need the `throws Throwable`

##########
File path: test/unit/org/apache/cassandra/concurrent/DebuggableThreadPoolExecutorTest.java
##########
@@ -78,6 +86,74 @@ public void runMayThrow() throws InterruptedException
         assert delta >= 9 * 50 : delta;
     }
 
+    @Test
+    public void testLocalStatePropagation() throws InterruptedException

Review comment:
       Nit: this header doesn't need the `throws InterruptedException` part

##########
File path: test/unit/org/apache/cassandra/concurrent/DebuggableThreadPoolExecutorTest.java
##########
@@ -78,6 +82,34 @@ public void runMayThrow() throws InterruptedException
         assert delta >= 9 * 50 : delta;
     }
 
+    @Test
+    public void testExecuteFutureTaskWhileCapturingClientWarnings() throws InterruptedException
+    {
+        testClientWarnings(executor -> executor.execute(() -> ClientWarn.instance.warn(""msg"")));
+        testClientWarnings(executor -> executor.submit(() -> ClientWarn.instance.warn(""msg"")));
+        testClientWarnings(executor -> executor.submit(() -> ClientWarn.instance.warn(""msg""), null));
+        testClientWarnings(executor -> executor.submit((Callable<Void>) () -> {
+            ClientWarn.instance.warn(""msg"");
+            return null;
+        }));
+    }
+
+    private void testClientWarnings(Consumer<DebuggableThreadPoolExecutor> schedulingTask) throws InterruptedException
+    {
+        LinkedBlockingQueue<Runnable> q = new LinkedBlockingQueue<Runnable>(1);
+        DebuggableThreadPoolExecutor executor = new DebuggableThreadPoolExecutor(1,

Review comment:
       +1, we can do that for most tests except maybe for `testExecuteFutureTaskWhileCapturingClientWarnings`

##########
File path: src/java/org/apache/cassandra/cql3/statements/schema/CreateKeyspaceStatement.java
##########
@@ -62,10 +62,6 @@ public CreateKeyspaceStatement(String keyspaceName, KeyspaceAttributes attrs, bo
 
     public Keyspaces apply(Keyspaces schema)
     {
-        if (ClientWarn.instance.get() == null)

Review comment:
       Nit: unused import of `ClientWarn`

##########
File path: test/unit/org/apache/cassandra/schema/SchemaStatementWarningsTest.java
##########
@@ -0,0 +1,126 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.schema;
+
+import java.util.HashSet;
+import java.util.Queue;
+import java.util.Set;
+import java.util.UUID;
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.service.ClientWarn;
+import org.assertj.core.api.Assertions;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMRules;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
+
+@RunWith(BMUnitRunner.class)
+public class SchemaStatementWarningsTest extends CQLTester
+{
+    @BeforeClass
+    public static void setupDatabaseDescriptor()
+    {
+        DatabaseDescriptor.daemonInitialization();
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE KeyspaceParams.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)"") })
+    public void testClientWarningsOnCreateKeyspace() throws Throwable
+    {
+        ClientWarn.instance.captureWarnings();
+        injectedWarnings.clear();
+        createKeyspace(""CREATE KEYSPACE %s WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}"");
+
+        Assertions.assertThat(injectedWarnings).contains(msg1, msg2); // failure here means the bm rules need to be updated
+        Assertions.assertThat(ClientWarn.instance.getWarnings()).containsExactlyInAnyOrder(msg1, msg2);
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE TableMetadata.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+    })
+    public void testClientWarningsOnCreateTable() throws Throwable

Review comment:
       Nit: we don't need the `throws Throwable`

##########
File path: test/unit/org/apache/cassandra/schema/SchemaStatementWarningsTest.java
##########
@@ -0,0 +1,126 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.schema;
+
+import java.util.HashSet;
+import java.util.Queue;
+import java.util.Set;
+import java.util.UUID;
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.service.ClientWarn;
+import org.assertj.core.api.Assertions;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMRules;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
+
+@RunWith(BMUnitRunner.class)
+public class SchemaStatementWarningsTest extends CQLTester
+{
+    @BeforeClass
+    public static void setupDatabaseDescriptor()
+    {
+        DatabaseDescriptor.daemonInitialization();
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE KeyspaceParams.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)"") })
+    public void testClientWarningsOnCreateKeyspace() throws Throwable
+    {
+        ClientWarn.instance.captureWarnings();
+        injectedWarnings.clear();
+        createKeyspace(""CREATE KEYSPACE %s WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}"");
+
+        Assertions.assertThat(injectedWarnings).contains(msg1, msg2); // failure here means the bm rules need to be updated
+        Assertions.assertThat(ClientWarn.instance.getWarnings()).containsExactlyInAnyOrder(msg1, msg2);
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE TableMetadata.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+    })
+    public void testClientWarningsOnCreateTable() throws Throwable
+    {
+        ClientWarn.instance.captureWarnings();
+        injectedWarnings.clear();
+        createTable(""CREATE TABLE %s (k int primary key, v int)"");
+
+        Assertions.assertThat(injectedWarnings).contains(msg1, msg2); // failure here means the bm rules need to be updated
+        Assertions.assertThat(ClientWarn.instance.getWarnings()).containsExactlyInAnyOrder(msg1, msg2);
+    }
+
+    static volatile String msg1, msg2;
+
+    @Before
+    public void before()
+    {
+        msg1 = UUID.randomUUID().toString();
+        msg2 = UUID.randomUUID().toString();
+    }
+
+    static Queue<String> injectedWarnings = new ConcurrentLinkedQueue<String>();

Review comment:
       This can be `private`. Also we could place it at the beginning of the class, before methods. We don't need the second `<String>`, so it can be:
   ```java
   private static final Queue<String> injectedWarnings = new ConcurrentLinkedQueue<>();
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Nov/21 11:55;githubbot;600","adelapena commented on a change in pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314#discussion_r750199406



##########
File path: test/unit/org/apache/cassandra/schema/SchemaStatementWarningsTest.java
##########
@@ -0,0 +1,126 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.schema;
+
+import java.util.HashSet;
+import java.util.Queue;
+import java.util.Set;
+import java.util.UUID;
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.service.ClientWarn;
+import org.assertj.core.api.Assertions;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMRules;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
+
+@RunWith(BMUnitRunner.class)
+public class SchemaStatementWarningsTest extends CQLTester
+{
+    @BeforeClass
+    public static void setupDatabaseDescriptor()
+    {
+        DatabaseDescriptor.daemonInitialization();
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE KeyspaceParams.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateKeyspaceStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)"") })
+    public void testClientWarningsOnCreateKeyspace() throws Throwable
+    {
+        ClientWarn.instance.captureWarnings();
+        injectedWarnings.clear();
+        createKeyspace(""CREATE KEYSPACE %s WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}"");
+
+        Assertions.assertThat(injectedWarnings).contains(msg1, msg2); // failure here means the bm rules need to be updated
+        Assertions.assertThat(ClientWarn.instance.getWarnings()).containsExactlyInAnyOrder(msg1, msg2);
+    }
+
+    @Test
+    @BMRules(rules = { @BMRule(name = ""client warning 1"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""apply"",
+                               targetLocation = ""AT INVOKE TableMetadata.validate"",
+                               action = ""org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarn()""),
+                       @BMRule(name = ""client warning 2"",
+                               targetClass = ""CreateTableStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+                       @BMRule(name = ""client warning 3"",
+                               targetClass = ""AlterSchemaStatement"",
+                               targetMethod = ""clientWarnings"",
+                               targetLocation = ""AT EXIT"",
+                               action = ""return org.apache.cassandra.schema.SchemaStatementWarningsTest.addWarnToList($!)""),
+    })
+    public void testClientWarningsOnCreateTable() throws Throwable
+    {
+        ClientWarn.instance.captureWarnings();
+        injectedWarnings.clear();
+        createTable(""CREATE TABLE %s (k int primary key, v int)"");
+
+        Assertions.assertThat(injectedWarnings).contains(msg1, msg2); // failure here means the bm rules need to be updated
+        Assertions.assertThat(ClientWarn.instance.getWarnings()).containsExactlyInAnyOrder(msg1, msg2);
+    }
+
+    static volatile String msg1, msg2;
+
+    @Before
+    public void before()

Review comment:
       Can we place this method at the beginning of the class?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Nov/21 11:59;githubbot;600","jacek-lewandowski closed pull request #1314:
URL: https://github.com/apache/cassandra/pull/1314


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 06:46;githubbot;600","jacek-lewandowski closed pull request #1320:
URL: https://github.com/apache/cassandra/pull/1320


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 06:46;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,10200,,,0,10200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jlewandowski,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Nov 19 01:22:13 UTC 2021,,,,,,,All,,,,"0|z0w8mo:",9223372036854775807,,,,adelapena,bereng,dcapwell,,Low,,3.0.0,,https://github.com/apache/cassandra/commit/1bcfa087f4521135ef101c694f5e6ada8347827c,,,,,,,,,Run regressions,,,,,"10/Nov/21 13:10;jlewandowski;PR: https://github.com/apache/cassandra/pull/1314;;;","10/Nov/21 17:18;dcapwell;Can you also work on a trunk patch?  Executors were completely rewritten;;;","11/Nov/21 19:03;adelapena;Indeed we'd need a patch for trunk.

CI runs:
||PR||CI||
|[4.0|https://github.com/apache/cassandra/pull/1314]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1138/workflows/ffd098b1-abbf-4be4-bb59-617b7c3a1793] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1138/workflows/1607ab4f-9308-41aa-9f78-1bc19341b348]|

It seems that all three tests in {{SchemaTest}} are failing, dtests are still running.;;;","13/Nov/21 01:25;dcapwell;patch mostly LGTM, holding off +1 until tests are green; will do final review at that point.  Thanks Andres for running them =);;;","15/Nov/21 06:18;bereng;The dtests failures are my CASSANDRA-17119 so you're good there. But the junit warn failures are probably legit?;;;","15/Nov/21 06:39;jlewandowski;Thanks for running tests; I'll look into the failures today;;;","15/Nov/21 07:34;jlewandowski;The reason for failing unit tests was my mistake that I forgot to uncomment byteman runner.

For the trunk, there is a question, perhaps to [~benedict] - I noticed that migration stage is not local aware while it was in 4.0 - is there any particular reason why it should not be a local aware? I've changed it to local aware in the PR for this ticket because migration stage is used during execution of schema statements and thus should propagate both tracing and client warnings - is it ok?

PR for trunk: https://github.com/apache/cassandra/pull/1320
;;;","15/Nov/21 10:20;jlewandowski;The review remarks regarding dead code and testing were addressed. I refactored the tests and added more (also for tracing). 

Also, the same problem was in {{SEPExecutor}} (plus one more nit where the {{ExecutorLocals}} instance was passed as a result rather than as locals due to overloading confusion).

For trunk there are only tests.;;;","15/Nov/21 20:06;dcapwell;4.0: https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=pr%2F1314
trunk: https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=pr%2F1320;;;","16/Nov/21 00:54;dcapwell;test results look clean (need to rebase to fix most tests); will review tomorrow.;;;","16/Nov/21 07:07;jlewandowski;I'll rebase and squash;;;","16/Nov/21 07:23;jlewandowski;I rebased both PRs and squashed - I'd really appreciate if somebody confirm this https://github.com/apache/cassandra/pull/1320/files#diff-884063e4549a5202588049240e62b219f7d14f75d4e983416a61815d84674444R173 changes is ok in trunk - although it seems obvious for me, I might have missed something
;;;","16/Nov/21 07:46;bereng;[~jlewandowski] did you trigger CI as well?;;;","16/Nov/21 08:19;jlewandowski;[trunk|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/125/workflows/0b30c7cf-29a0-47f3-ac39-70a275850979]

[4.0|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/126/workflows/d563afaf-fef3-4323-bee4-55bcf729a7a9];;;","16/Nov/21 12:25;adelapena;Changes look good to me, I have left a few mostly cosmetic suggestions on the 4.0 PR that also apply to trunk.

Here are some repeated runs for the changed/new tests, just in case:
||Test||CI||
|{{SchemaStatementWarningsTest}}|[4.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/1146/workflows/c66af191-cda2-409d-a466-a9d5514ab9b4] [trunk|https://app.circleci.com/pipelines/github/adelapena/cassandra/1147/workflows/7f84c1d9-de24-4e6a-9f81-183512b42ed8]|
|{{DebuggableThreadPoolExecutorTest}}|[4.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/1149/workflows/9c582316-2f57-445d-96cf-b22d1ae8eca4] [trunk|https://app.circleci.com/pipelines/github/adelapena/cassandra/1148/workflows/de9fff30-5f0e-4db2-9a14-4a23cb211126]|
|{{SEPExecutorTest}}|[4.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/1151/workflows/50eca6a3-710a-49e4-a998-60f7287db98b] [trunk|https://app.circleci.com/pipelines/github/adelapena/cassandra/1150/workflows/fe98bcea-7b2a-4c83-8f83-077be14d80e5]|;;;","16/Nov/21 14:08;jlewandowski;thank you [~adelapena], I've applied your comments;;;","16/Nov/21 18:49;dcapwell;bq.  I'd really appreciate if somebody confirm this

I have reported other issues after the refactor, so its very possible this is a regression; if 4.0 was localAware, then trunk is supposed to be as well.

Looking at the migration stage on 3.0 I see it was JMXEnabledSingleThreadExecutor -> JMXEnabledThreadPoolExecutor -> DebuggableThreadPoolExecutor -> LocalAwareExecutorService;;;","16/Nov/21 19:17;dcapwell;Overall LGTM, +1 assuming still stable after latest changes.;;;","17/Nov/21 07:17;bereng;Right we seem to be missing CI for the latest commit.;;;","17/Nov/21 08:55;jlewandowski;[4.0|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/128/workflows/8e465b6f-c8fe-4031-88ab-e44021260914]
[trunk|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/130/workflows/e2e5536d-01b8-4944-b3c8-70575b34068d]
;;;","17/Nov/21 11:42;jlewandowski;trunk tests passed, I could not reproduce locally two failures on 4.0
;;;","17/Nov/21 14:54;adelapena;CI looks good, so I guess we are ready to commit.;;;","17/Nov/21 17:22;jlewandowski;Yup, so can we move forward?;;;","17/Nov/21 18:57;dcapwell;I don't see a +1 from [~bereng] so holding off merge until he has the time to finish his review (think this has 2 +1s, Andres and I).  If [~bereng] wants to merge I am cool with that, else I can merge;;;","18/Nov/21 06:06;bereng;[~jlewandowski] I can see you only ran CI for j11 but not for j8? I tried to start them but it doesn't allow me... :-(;;;","18/Nov/21 06:38;jlewandowski;[trunk|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/130/workflows/e79f362e-ca0a-4542-a117-5fb9223463d1]
[4.0|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/128/workflows/166706de-6847-4159-b177-664d11295f35]
;;;","18/Nov/21 07:33;jlewandowski;||PR||j8||j11||
|[4.0|https://github.com/apache/cassandra/pull/1314]|[4.0|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/128/workflows/166706de-6847-4159-b177-664d11295f35]|[4.0|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/128/workflows/8e465b6f-c8fe-4031-88ab-e44021260914]
|[trunk|https://github.com/apache/cassandra/pull/1320]|[trunk|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/130/workflows/e79f362e-ca0a-4542-a117-5fb9223463d1]|[trunk|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/130/workflows/e2e5536d-01b8-4944-b3c8-70575b34068d]|;;;","18/Nov/21 07:34;bereng;The CI runs SHAs don't match the SHAs on the PRs?

Edit: Sorry for being a pain lol! just trying to connect all the dots;;;","18/Nov/21 07:36;jlewandowski;Indeed, I created separate branches with that extra commit that changes circle configuration;;;","18/Nov/21 07:40;jlewandowski;wait, i need to verify;;;","18/Nov/21 07:43;jlewandowski;:facepalm I must have confused something :(;;;","18/Nov/21 07:45;bereng;We usually make the circle config change in a separate commit in the same branch. I think it keeps things a bit easier and it's also what _I think_ everybody else does.;;;","18/Nov/21 09:33;jlewandowski;||PR||j8||j11||
|[4.0|https://github.com/apache/cassandra/pull/1314]|[4.0|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/133/workflows/92089846-2367-44c3-979e-6935b16492ad]|[4.0|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/133/workflows/8a22f82e-b232-43a8-adaf-06ce6e8114ae]
|[trunk|https://github.com/apache/cassandra/pull/1320]|[trunk|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/134/workflows/8a044775-3f00-4aaf-9eab-e6ab6b752bbf]|[trunk|https://app.circleci.com/pipelines/github/jacek-lewandowski/cassandra/134/workflows/cf4afedf-11fb-4b87-82d6-e5919433d394]|

;;;","18/Nov/21 10:29;jlewandowski;[~bereng] new test runs finished;;;","18/Nov/21 11:42;bereng;The runs hadn't finished and in fact there's one still running which seems stuck in some concurrency limit. The failure it reports looks unrelated to me as the rest of the CI. Happy to +1 but I'll let a day go by to let [~adelapena] and [~dcapwell] a last pass and I'll merge tomorrow unless sbdy beats me to it.;;;","18/Nov/21 21:10;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|cassandra-4.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17072-cassandra-4.0-082C4D96-51F3-4E70-BCE8-0DE9100DB8CB]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17072-cassandra-4.0-082C4D96-51F3-4E70-BCE8-0DE9100DB8CB]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1289/]|
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17072-trunk-082C4D96-51F3-4E70-BCE8-0DE9100DB8CB]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17072-trunk-082C4D96-51F3-4E70-BCE8-0DE9100DB8CB]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1290/]|
;;;","19/Nov/21 01:11;dcapwell;4.0: j8 looks normal, j11 I don't think we paid attention to so don't know what is normal here.
trunk: j8 looks normal, j11 had org.apache.cassandra.distributed.test.SecondaryIndexTest failed and not seen it before (and don't see any JIRA for it https://issues.apache.org/jira/issues/?jql=project%20%3D%20CASSANDRA%20AND%20text%20~%20SecondaryIndexTest%20ORDER%20BY%20status%20DESC)

The only thing that worried me is org.apache.cassandra.distributed.test.SecondaryIndexTest so going to run that on repeat to see if I can see anything;;;","19/Nov/21 01:13;dcapwell;Trunk: https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=ci%2Ftrunk.
Trunk PR: https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=pr%2F1320;;;","19/Nov/21 01:22;dcapwell;failed on trunk as well, so will create a ticket and not block this merge.;;;",,,,,,,,,,,,,,
ViewComplexTest hardening,CASSANDRA-17070,13408819,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,28/Oct/21 05:24,27/May/22 19:25,13/Jul/23 08:40,04/Nov/21 07:26,4.0.2,4.1,4.1-alpha1,,,,,Test/unit,,,,1,,,I have seen a number of times already the {{ViewComplexTest}} family timeout on test method teardown. This leaves a dirty env behind triggering the following test methods to fail on it. This ticket aims at hardening them.,,adelapena,bereng,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17083,,,,,,,,,0.0,adelapena,bereng,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Nov 04 07:25:36 UTC 2021,,,,,,,All,,,,"0|z0w8dk:",9223372036854775807,,,,adelapena,,,,Low,,4.0,,https://github.com/apache/cassandra/commit/8ba8f0b841ba772dcdaf8b5109b7d3fda87b6888,,,,,,,,,See PR,,,,,"28/Oct/21 06:16;bereng;Hardening by trying to rerun the cleanup logic on any leftovers in case the first attempt failed. Trunk PR will be identical.;;;","28/Oct/21 16:43;adelapena;I'm not sure I understand why the MV cleanup can fail. Would the second round of cleanup guarantee that the MV cleanups succeed, or would it reduce the chances of having leftovers because it's unlikely to have the same error twice? Maybe it's just giving more time for the first async cleanup to happen?

In any case, here are 500 runs of each ViewComplex test:
 * [ViewComplexDeletionsTest|https://app.circleci.com/pipelines/github/adelapena/cassandra/1090/workflows/4362eefe-a13a-4a8c-a8eb-9e543a74623a/jobs/10187]
 * [ViewComplexLivenessTest|https://app.circleci.com/pipelines/github/adelapena/cassandra/1091/workflows/a9185c89-ceff-4ddd-90c0-960281233fe3/jobs/10189]
 * [ViewComplexTTLTest|https://app.circleci.com/pipelines/github/adelapena/cassandra/1092/workflows/1f74edb4-3a41-47fd-b95c-0edc1d514a20/jobs/10191]
 * [ViewComplexTest|https://app.circleci.com/pipelines/github/adelapena/cassandra/1093/workflows/f2e69851-19ea-4ab6-9315-5af9d721ec3d/jobs/10193]
 * [ViewComplexUpdatesTest|https://app.circleci.com/pipelines/github/adelapena/cassandra/1094/workflows/0d25bf72-7c90-4287-92d6-21a751082e21/jobs/10196]

From these runs only a test runner for {{ViewComplexTest}} is failing due to timeouts.

It's not strictly related to the fix, but it seems that there is some repeated code among the five tests in which {{ViewComplexTest}} was split by CASSANDRA-16670. Probably we should do the same thing that we did with {{ViewTest}} in CASSANDRA-16777 and extract a superclass to avoid code duplication. This would make changes like this one a bit easier to do. I gave it a go in [this commit|https://github.com/adelapena/cassandra/commit/204f3bbe69aae9165c0570224bfd811c8bbd4d07], and it saves us some 176 lines of code, which I think is always nice.

Here are some repeated runs for the tests using a common superclass, with no failures so far:
 * [ViewComplexDeletionsTest|https://app.circleci.com/pipelines/github/adelapena/cassandra/1096/workflows/ded0dfe1-e736-468a-babb-0c007a6bf3c9/jobs/10201]
 * [ViewComplexLivenessTest|https://app.circleci.com/pipelines/github/adelapena/cassandra/1097/workflows/544b429d-b712-428c-b97d-edd50076992a/jobs/10203]
 * [ViewComplexTTLTest|https://app.circleci.com/pipelines/github/adelapena/cassandra/1098/workflows/c062d815-2e26-4a75-aa64-656bfc48c8cc/jobs/10205]
 * [ViewComplexTest|https://app.circleci.com/pipelines/github/adelapena/cassandra/1099/workflows/1f834191-b30b-4380-87ce-da257fac731e/jobs/10207]
 * [ViewComplexUpdatesTest|https://app.circleci.com/pipelines/github/adelapena/cassandra/1095/workflows/3df8138d-1d7b-4283-be3c-a23cb2c0bc40]

An alternative/complementary approach to avoid problems with leftovers from previous runs is making sure that all MVs are created with a new, unique name. This way the tests don't collide with any surviving MVs if the cleanup has failed or if it hasn't finished. {{CQLTester}} does this with keyspace, table, function and aggregate names.

I gave a go to this generation of unique names [here|https://github.com/adelapena/cassandra/commit/e1928447e4139f1ad4126d9ed34e3de9d3bceb10]. It is just for {{ViewComplexTest}}, but we may consider having a more generic and reusable solution for creating/cleaning MVs in {{CQLTester}}, although I think we don't have to do it here. wdyt?;;;","28/Oct/21 17:01;adelapena;I forgot to mention that I found an unrelated mistake [here|https://github.com/apache/cassandra/blob/trunk/test/unit/org/apache/cassandra/cql3/ViewComplexTest.java#L142-L148], where two tests are supposed to run a scenario with and without flushing the table, but both of them run the scenario with flush. It's fixed in the commit extracting a superclass, [here|https://github.com/adelapena/cassandra/blob/204f3bbe69aae9165c0570224bfd811c8bbd4d07/test/unit/org/apache/cassandra/cql3/ViewComplexTest.java#L55-L61].;;;","28/Oct/21 19:05;e.dimitrova;+1 on the proposed change to use a super class similar to #16777, it was on my list for some time but it was a lower priority. Honestly, we should have done it at first place like that. Thanks [~adelapena]!;;;","29/Oct/21 08:07;bereng;[~adelapena] the reason to run that code twice was that the test keeps a list of the views. So if a cleanup failed the next one would pick up from the failing point

But +1 to the abstract class and unique MV name. I ported your changes to my PR but: I deleted the extra cleanup which is not needed anymore, I changed the config to run {{ViewComplex*Test}} instead of having one commit per repeat test and I attached results to the PR with 100 repeats and 0 failures (CASSANDRA-17083).

I am only on the fence about the cleanup logic, which we could remove now there are unique MV names, but on the other hand it's nice to have it. I think I am +1 on how things are right now. Wdyt?;;;","29/Oct/21 10:24;adelapena;It seems that the multiplexer runs in the PR have failed due to the wildcard. I think it would work if we use {{ant test}} instead of {{ant testsome}}, with the unqualified class name:
{code:java}
.circleci/generate.sh -m \
  -e REPEATED_UTEST_TARGET=test \
  -e REPEATED_UTEST_COUNT=500 \
  -e REPEATED_UTEST_CLASS=ViewComplex*Test
{code}
The wildcard is a great idea, it would have saved me time with the above runs :)

I think we can try some more runs without the duplicated cleanup logic and see how it goes, wdyt?;;;","29/Oct/21 10:45;bereng;They didn't fail sort to speak... They show the 13200 passed tests with no _test_ failures. It failed the run bc of the wilcard. It is easy to remove the noise by switching to {{test}} instead of {{testsome}}.

Removing the cleanup logic breaks the {{CQLTester}} teardown when it tries to drop tables that have attached MVs. So I want to give that a thought...;;;","29/Oct/21 14:55;adelapena;[Here|https://app.circleci.com/pipelines/github/adelapena/cassandra/1101/workflows/c335ffa0-1513-40a1-b925-292e0d03cee3/jobs/10214] are other 500 rounds of the tests without the duplicated cleanup. There is a single error in {{ViewComplexUpdatesTest.testUpdateWithColumnTimestampSmallerThanPk}}, apparently due to a query timeout (see the bottom of the [stdout|https://circle-production-customer-artifacts.s3.amazonaws.com/picard/52e11c3bf7d0f78c41388745/617bdf2aa30bc2444e1c8dda-15-build/artifacts/stdout/fails/05/test-ViewComplex%2ATest.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20211029T144933Z&X-Amz-SignedHeaders=host&X-Amz-Expires=60&X-Amz-Credential=AKIAJR3Q6CR467H7Z55A%2F20211029%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=033813c3f1bc4bd9485bd06dad36099d61616fc505b8ae03d71cba4e41cf7844] file).;;;","02/Nov/21 08:53;bereng;Right. But it's on view creation, not the cleanup logic. Seems like a legit timeout. I've had the feeling timeouts have to be raised for some time. I still think we're good to merge. Or are you suggesting we put the cleanup back in?

{noformat}
[junit-timeout] Testcase: testUpdateWithColumnTimestampSmallerThanPkWithFlush[3](org.apache.cassandra.cql3.ViewComplexUpdatesTest):	Caused an ERROR
[junit-timeout] [localhost/127.0.0.1:43739] Timed out waiting for server response
[junit-timeout] com.datastax.driver.core.exceptions.OperationTimedOutException: [localhost/127.0.0.1:43739] Timed out waiting for server response
[junit-timeout] 	at com.datastax.driver.core.exceptions.OperationTimedOutException.copy(OperationTimedOutException.java:43)
[junit-timeout] 	at com.datastax.driver.core.exceptions.OperationTimedOutException.copy(OperationTimedOutException.java:25)
[junit-timeout] 	at com.datastax.driver.core.DriverThrowables.propagateCause(DriverThrowables.java:35)
[junit-timeout] 	at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:293)
[junit-timeout] 	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:58)
[junit-timeout] 	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:45)
[junit-timeout] 	at org.apache.cassandra.cql3.CQLTester.executeNet(CQLTester.java:972)
[junit-timeout] 	at org.apache.cassandra.cql3.ViewComplexTester.createView(ViewComplexTester.java:83)
[junit-timeout] 	at org.apache.cassandra.cql3.ViewComplexUpdatesTest.testUpdateWithColumnTimestampSmallerThanPk(ViewComplexUpdatesTest.java:224)
[junit-timeout] 	at org.apache.cassandra.cql3.ViewComplexUpdatesTest.testUpdateWithColumnTimestampSmallerThanPkWithFlush(ViewComplexUpdatesTest.java:207)
[junit-timeout] Caused by: com.datastax.driver.core.exceptions.OperationTimedOutException: [localhost/127.0.0.1:43739] Timed out waiting for server response
[junit-timeout] 	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onTimeout(RequestHandler.java:979)
[junit-timeout] 	at com.datastax.driver.core.Connection$ResponseHandler$1.run(Connection.java:1636)
[junit-timeout] 	at com.datastax.shaded.netty.util.HashedWheelTimer$HashedWheelTimeout.expire(HashedWheelTimer.java:663)
[junit-timeout] 	at com.datastax.shaded.netty.util.HashedWheelTimer$HashedWheelBucket.expireTimeouts(HashedWheelTimer.java:738)
[junit-timeout] 	at com.datastax.shaded.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:466)
[junit-timeout] 	at com.datastax.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[junit-timeout] 	at java.lang.Thread.run(Thread.java:748)
{noformat}
;;;","02/Nov/21 14:55;adelapena;I don't think we should put the duplicated cleanup logic back, in principle not reusing MV names should be enough.

I mentioned the query timeout to indicate that the failure is not related to what we are addressing here, so I think the run can be considered successful. By the way, [here|https://app.circleci.com/pipelines/github/adelapena/cassandra/1101/workflows/63014008-3d52-4d07-a5aa-748fad389ec7] is the repeated run for j11, all green. I think we are ready to merge.;;;","03/Nov/21 11:56;bereng;I added the trunk PR with CI. There's no rush so this will give you time to take a look at it. Let me know if you're still ok I merge. ;;;","03/Nov/21 17:11;adelapena;The PR for trunk looks good to me. Here are 200 runs of {{ViewComplex*Test}} in the PR for trunk:
 * [j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1114/workflows/2a6ea982-7109-4cf2-b5af-7f06188f2d4f]
 * [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1114/workflows/12ab59cb-24d5-4795-a309-21b7eb6b187c]

If those succeed I think we'll be definitively ready to merge.;;;","04/Nov/21 07:25;bereng;Yep wall of green :-);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"v4+ protocol did not clean up client warnings, which caused leaking the state",CASSANDRA-17054,13407816,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,21/Oct/21 18:15,27/May/22 19:24,13/Jul/23 08:40,25/Oct/21 15:44,4.1,4.1-alpha1,,,,,,Messaging/Client,,,,0,,,"If you perform a query in v5, this will cause the STARTUP message to be handled in the netty thread, but the way this is done is by calling an internal API to dispatcher which requires the caller to clean up; but we do not clean up; at this point the netty thread will have a ClientWarn state populated.  If you now perform the same query again, but with the v3 protocol, this will pick up the state and try to serialize it, causing a client error (in java as java rejects the output from the server) saying that v3 may not have client warnings.",,dcapwell,e.dimitrova,jonmeredith,maedhroz,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Transient Incorrect Response,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Oct 25 15:43:19 UTC 2021,,,,,,,All,,,,"0|z0w26o:",9223372036854775807,,,,jmeredithco,maedhroz,samt,,Normal,,4.0.0,,https://github.com/apache/cassandra/commit/d8fff9b2d0e79fa8d945a8cdc1295fda3deae77c,,,,,,,,,jvm-dtest,,,,,"21/Oct/21 18:51;dcapwell;To validate the test does fail without the patch, revert

{code}
src/java/org/apache/cassandra/transport/Dispatcher.java
src/java/org/apache/cassandra/transport/InitialConnectionHandler.java
{code};;;","22/Oct/21 03:29;maedhroz;+1 (assuming clean tests);;;","22/Oct/21 15:22;samt;+1, left a couple of tiny nits, nothing important;;;","25/Oct/21 13:52;jonmeredith;+1;;;","25/Oct/21 14:32;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17054-trunk-D0BB41D6-69AC-42C7-B884-2B22CE33E742]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17054-trunk-D0BB41D6-69AC-42C7-B884-2B22CE33E742]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1247/]|
;;;","25/Oct/21 15:43;dcapwell;a lot of tests are failing, but they are also failing on trunk (reported in slack as well), so merging even though there are many test failures...;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Queries performed with NODE_LOCAL consistency level do not update request metrics,CASSANDRA-17052,13407553,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aleksey,aleksey,aleksey,20/Oct/21 14:24,27/May/22 19:25,13/Jul/23 08:40,12/Nov/21 11:44,4.0.2,4.1,4.1-alpha1,,,,,Observability/Metrics,,,,0,,,"Currently, queries performed with {{NODE_LOCAL}} consistency level are not reflected in request metrics. The suggested patch addresses that, and also allows modification and batch statements to be used with {{NODE_LOCAL}} consistency level.",,aleksey,ifesdjeen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,aleksey,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Normal,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Nov 12 11:42:48 UTC 2021,,,,,,,All,,,,"0|z0w0k8:",9223372036854775807,,,,ifesdjeen,,,,Low,,4.0,,"[dd6242037b6c78eed0994638c20ec82ecf78c43c|https://github.com/apache/cassandra/commit/dd6242037b6c78eed0994638c20ec82ecf78c43c]",,,,,,,,,Unit tests included,,,,,"28/Oct/21 13:52;aleksey;Code: https://github.com/iamaleksey/cassandra/commits/17052-4.0
CI: https://app.circleci.com/pipelines/github/iamaleksey/cassandra?branch=17052-4.0;;;","08/Nov/21 15:24;ifesdjeen;+1; minor comments on the patch;;;","10/Nov/21 17:15;ifesdjeen;+1 with latest additions;;;","12/Nov/21 11:42;aleksey;Cheers, committed as [dd6242037b6c78eed0994638c20ec82ecf78c43c|https://github.com/apache/cassandra/commit/dd6242037b6c78eed0994638c20ec82ecf78c43c] to cassandra-4.0 and merged into trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade tests fail with InvocationTargetException,CASSANDRA-17050,13407366,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,benedict,benedict,benedict,19/Oct/21 19:10,27/May/22 19:25,13/Jul/23 08:40,10/Nov/21 11:16,2.2.20,3.0.26,4.0.2,4.1,4.1-alpha1,,,Test/dtest/java,,,,0,,,Upgrade tests are currently failing due to the new dtest-api changes and their integration with trunk.,,benedict,brandon.williams,e.dimitrova,maedhroz,mck,sumanth.pasupuleti,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,benedict,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Nov 09 10:15:29 UTC 2021,,,,,,,All,,,,"0|z0vzeo:",9223372036854775807,,,,mck,,,,Critical,,NA,,"[cedde3d991da48039caee2afb421c737777267f0|https://github.com/apache/cassandra/commit/cedde3d991da48039caee2afb421c737777267f0]",,,,,,,,,Test fix,,,,,"20/Oct/21 15:55;benedict;[17050-trunk|https://github.com/belliottsmith/cassandra/tree/17050-trunk]
[17050-4.0|https://github.com/belliottsmith/cassandra/tree/17050-4.0]
[17050-3.11|https://github.com/belliottsmith/cassandra/tree/17050-3.11]
[17050-3.0|https://github.com/belliottsmith/cassandra/tree/17050-3.0]
[17050-2.2|https://github.com/belliottsmith/cassandra/tree/17050-2.2]

The {{trunk}} patch addresses the issue referenced by this ticket, however another problem also arose due to a bug in the past usage of the dtest-api. Specifically, all prior versions cast {{IInstanceConfig}} to the concrete {{InstanceConfig}} inside of {{Instance.loadConfig}} - which is of course unsafe if this class is modified by the later version (and fundamentally breaks the encapsulation offered by the dtest-api).

I have therefore had to upgrade all versions to the latest dtest-api, except for 2.2 which I have cheated by simply grabbing the {{getParams}} method by reflection.;;;","25/Oct/21 07:48;mck;Raising priority as CI is trashed until this gets out.;;;","25/Oct/21 07:57;mck;The patches don't build, because they don't pass the `ant dependency-check` which now fail on all branches because of a new CVE in netty-all-4.0.44.Final.jar

;;;","25/Oct/21 09:46;benedict;That isn't related to this patch.;;;","25/Oct/21 09:52;benedict;FWIW, the dependency check fails locally for unrelated reasons, seemingly unable to connect to nist.gov, though I am able to connect to nist.gov just fine and download the file it is looking for. So perhaps this check has some kinks to work out before we depend upon it. I'm also unconvinced of the sense of downloading an arbitrary binary direct from somebody's personal GitHub to execute on the local machine.

I'm not convinced of the sense of breaking builds that previously worked for this check, it should at most be a pre-release check rather than a pre-merge check. Perhaps it could also be pre-merge if build.xml modified as part of the patch.;;;","25/Oct/21 10:17;mck;That discussion (which is out of scope) is ongoing. 

pre-release check is no good, we want a faster feedback on such CVE breakages.

part of the problem is the check can fail for one of three reasons:
# a new dependency is introduced in the patch, and that should be caught (not merged)
# a new CVE is listed, and that breaks all our CI
# the nist.gov becomes unavailable, and that breaks all our CI.

We want (1) as part of CI. We want (2) as feedback as fast as possible, but not breaking CI. We want to ignore (workaround) (3).
;;;","25/Oct/21 12:19;mck;CI
- trunk [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1243/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1243/]
- 4.0 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1241/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1241/]
- 3.11 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1240/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1240/]
- 3.0 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1239/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1239/]
- 2.2 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1238/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1238/];;;","25/Oct/21 12:33;benedict;It looks like there's another [unrelated issue|https://app.circleci.com/pipelines/github/belliottsmith/cassandra/113/workflows/1f672000-5432-44d7-a691-b1d397c40932/jobs/3866/tests#failed-test-5]

This might require an update to dtest-api, I'm investigating;;;","28/Oct/21 15:15;benedict;Additional necessary changes to [dtest-api|https://github.com/belliottsmith/cassandra-in-jvm-dtest-api/tree/17050]

It looks like Jenkins CI has its own issues, as I don't think CQLSHLIB tests have been affected by this or earlier work, and 2.2 has failing python dtests that are definitely unrelated.

CircleCI is now showing upgrade dtests as clean, and I have the other jvm dtests for confirmation. However we will need to release a new dtest-api (preferably to include CASSANDRA-17064) before we merge this.

I wonder if we should aim to reduce the friction for internal dependencies by using the apache snapshots repository for non-release builds. Not sure if somebody has a better idea, but today it is more than a little annoying to have to release the dtest-api before merging any change that uses it. The problem may become more common as we accumulate more sub-projects.;;;","28/Oct/21 21:15;mck;bq. I wonder if we should aim to reduce the friction for internal dependencies by using the apache snapshots repository for non-release builds. Not sure if somebody has a better idea, but today it is more than a little annoying to have to release the dtest-api before merging any change that uses it. The problem may become more common as we accumulate more sub-projects.

Yes. This was discussed a little [here|https://issues.apache.org/jira/browse/CASSANDRA-16649?focusedCommentId=17341901&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17341901] and the comment after it. I'm not confident yet of any other approach but the ""throwaway"" commits introducing the snapshot repository in patches (which are akin to the circle ""throwaway"" commits).;;;","28/Oct/21 21:36;mck;bq. Additional necessary changes to dtest-api

+1 

And i reckon the ""update SNAPSHOT"" commit should be ninja'd to trunk. That was supposed to have happened in [2139b4c85e319b17afbdea2f653152d1e1895fc6|https://github.com/apache/cassandra-in-jvm-dtest-api/commit/2139b4c85e319b17afbdea2f653152d1e1895fc6].

;;;","29/Oct/21 11:10;benedict;So is the idea that we'll merge with a SNAPSHOT dependency, or that we'll first release dtest-api?

I can look into modifying build.xml to use different dependencies for release, though we end up in a weird release chain where we cannot release cassandra without first releasing dtest-api (and any other dependencies).

I'll merge dtest-api changes for now anyway, thanks.;;;","29/Oct/21 11:15;mck;bq. So is the idea that we'll merge with a SNAPSHOT dependency, or that we'll first release dtest-api?

That we'll first release dtest-api. I know it's not ideal, we can revisit this, though one can say it fits into a stable trunk practice, but it is overhead…;;;","29/Oct/21 11:21;benedict;I just wonder if we should consider nested git repositories containing the library code, or some other approach to reduce the friction. This will become more acute over time as Accord will want to use the utilities from Cassandra (so that it's consistent with it), so we might end up with three or more projects that are dependencies for building Cassandra, so it feels like we should aim to support them all within the same IDE and commit flow.

I guess I should raise a DISCUSS thread about it.;;;","30/Oct/21 09:48;mck;CI
- trunk [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1257/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1257/]
- 4.0 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1255/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1255/] (10 more failures, 28 vs 18)
- 3.11 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1254/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1254/] (7 more failures than 3.11, 48 vs 41)
- 3.0 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1253/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1253/] (28 more failures than 3.0, 54 vs 26)
- 2.2 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/885/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/885/]
;;;","30/Oct/21 19:27;mck;[~benedict], I'm not seeing those fixes in ci-cassandra yet, to the contrary more failures. Am I doing something wrong here…?;;;","30/Oct/21 19:31;benedict;None of the failures I'm seeing are related to in-jvm upgrade tests anymore?

It's possible we've somehow broken normal dtests, or that they've been broken by some other issue. I'll take a look at the output.;;;","30/Oct/21 19:32;benedict;Can we get the test logs on Jenkins?

FWIW, it looks like a significant portion are: python auth dtests, python upgrade dtests.;;;","30/Oct/21 20:19;mck;Happy to ignore if they are not jvm-dtest* related.

Logs are available. See the Console Output first (if from the pipeline you need to click on one of the links to the inner stage job's Console Output), then at the bottom (or search for 'For test report and logs') there's a link to nightlies.a.o where test logs are uploaded.;;;","31/Oct/21 14:04;benedict;Something is very badly wrong with CI, I see several hundred python dtest failures in CircleCI for [17050-4.0|https://app.circleci.com/pipelines/github/belliottsmith/cassandra/124/workflows/4bcc17bb-01e8-4cb3-81f1-e64a3e0e323e]. I can't imagine how this patch could have caused these, as the 4.0 branch literally only changes the java dtests, but I will run a baseline test for each of the branches for comparison to be sure.
;;;","31/Oct/21 21:14;mck;Something broke python dtests on the 11th October. It wasn't this ticket, nor does it look like CASSANDRA-16839 or its [commit|https://github.com/apache/cassandra-dtest/commit/7c3333958e2b2bd53018a50ab1f529e1a2cca173]. And it's not flakies, a ton definitely broke for good :( ;;;","09/Nov/21 10:15;mck;dtest-api-0.0.11 has passed vote and been published.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix rare NPE caused by batchlog replay / node decomission races,CASSANDRA-17049,13407319,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,aleksey,aleksey,aleksey,19/Oct/21 14:47,27/May/22 19:24,13/Jul/23 08:40,12/Nov/21 14:46,3.0.26,3.11.12,4.0.2,4.1,4.1-alpha1,,,Consistency/Batch Log,Consistency/Hints,,,0,,,"Batchlog replay process collects addresses of the hosts that have been hinted to, so it can flush hints for them to disk before confirming deletion of the replayed batches. If a node has been decommissioned during replay, however, when the time comes to flush the hints at the very end of replay, {{StorageService.getHostIdForEndpoint()}} will return {{null}} for its address, which will, down the line, cause {{HintsCatalog::get()}} to be invoked with a {{null}} host id argument, causing an NPE.

The simple fix is to check returned host ids for addresses for nulls, and collect hinted host ids instead of hinted addresses.",,aleksey,ifesdjeen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,aleksey,,,,,,,,,,,,,Degradation -> Other Exception,,,,,,,,Normal,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Nov 12 14:45:02 UTC 2021,,,,,,,All,,,,"0|z0vz48:",9223372036854775807,,,,ifesdjeen,,,,Low,,3.0.0,,"[58c878e3e0356286ac1418e5e52e6f5cadd22ddb|https://github.com/apache/cassandra/commit/58c878e3e0356286ac1418e5e52e6f5cadd22ddb] ",,,,,,,,,Covered by existing unit tests,,,,,"20/Oct/21 12:24;aleksey;3.0: [code|https://github.com/iamaleksey/cassandra/commits/17049-3.0], [ci|https://app.circleci.com/pipelines/github/iamaleksey/cassandra?branch=17049-3.0]
3.11: [code|https://github.com/iamaleksey/cassandra/commits/17049-3.11], [ci|https://app.circleci.com/pipelines/github/iamaleksey/cassandra?branch=17049-3.11]
4.0: [code|https://github.com/iamaleksey/cassandra/commits/17049-4.0], [ci|https://app.circleci.com/pipelines/github/iamaleksey/cassandra?branch=17049-4.0]
trunk: [code|https://github.com/iamaleksey/cassandra/commits/17049-trunk], [ci|https://app.circleci.com/pipelines/github/iamaleksey/cassandra?branch=17049-trunk]

Changes are covered by existing batch log testes.;;;","12/Nov/21 13:53;aleksey;This is a very rare one. An example stack trace of an NPE:

{code}
ERROR 2021-10-19T08:30:16,692 [HintsWriteExecutor:1] org.apache.cassandra.service.CassandraDaemon:599 - Exception in thread Thread[HintsWriteExecutor:1,5,main]
java.lang.NullPointerException: null
        at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936) ~[?:?]
        at org.apache.cassandra.hints.HintsCatalog.get(HintsCatalog.java:102) ~[cie-cassandra-4.0.0.35.jar:4.0.0.35]
        at com.google.common.collect.Iterables$5.lambda$forEach$0(Iterables.java:704) ~[guava-27.0-jre.jar:?]
        at com.google.common.collect.Iterables$5.lambda$forEach$0(Iterables.java:704) ~[guava-27.0-jre.jar:?]
        at java.lang.Iterable.forEach(Iterable.java:75) ~[?:?]
        at com.google.common.collect.Iterables$5.forEach(Iterables.java:704) ~[guava-27.0-jre.jar:?]
        at com.google.common.collect.Iterables$5.forEach(Iterables.java:704) ~[guava-27.0-jre.jar:?]
        at org.apache.cassandra.hints.HintsWriteExecutor$PartiallyFlushBufferPoolTask.run(HintsWriteExecutor.java:188) ~[cie-cassandra-4.0.0.35.jar:4.0.0.35]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[?:?]
        at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-all-4.1.58.Final.jar:4.1.58.Final]
        at java.lang.Thread.run(Thread.java:834) [?:?]
{code}
;;;","12/Nov/21 14:01;ifesdjeen;+1. The only comments I have is that there's no test (but since it's straightforward yet rare and is difficult to reproduce, I'd say it's fine), and that [here|https://github.com/iamaleksey/cassandra/commit/05f379b812a9967b192347a341ae9270a35c27b4#diff-03e0ee2c01f2ca4d3b15d3a1fc4917d8737861c15d8c83cb73b352fe9da22d1aR410] we may additionally check for emptiness of the {NodesToHint} (but since it would work just fine even without it, please feel free to omit). ;;;","12/Nov/21 14:45;aleksey;Cheers, committed with the suggested change as [58c878e3e0356286ac1418e5e52e6f5cadd22ddb|https://github.com/apache/cassandra/commit/58c878e3e0356286ac1418e5e52e6f5cadd22ddb] and merged up. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RepairJobTest.testNoTreesRetainedAfterDifference fails consistently on Java 11,CASSANDRA-17039,13406429,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,maedhroz,brandon.williams,brandon.williams,13/Oct/21 19:53,27/May/22 19:25,13/Jul/23 08:40,13/Nov/21 00:01,4.1,4.1-alpha1,,,,,,Consistency/Repair,,,,0,,,"Sometimes fails an assertion:

{noformat}
Expecting:
 <10000L>
to be less than:
 <10000L> 
{noformat}

https://app.circleci.com/pipelines/github/driftx/cassandra/269/workflows/f2b0a738-0785-4011-9ac1-071837dc9170/jobs/2049/tests#failed-test-1",,dcapwell,e.dimitrova,maedhroz,,,,,,,,,,,,,"maedhroz closed pull request #1310:
URL: https://github.com/apache/cassandra/pull/1310


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Nov/21 18:31;githubbot;600","maedhroz commented on a change in pull request #1309:
URL: https://github.com/apache/cassandra/pull/1309#discussion_r748525029



##########
File path: test/unit/org/apache/cassandra/repair/RepairJobTest.java
##########
@@ -274,9 +277,9 @@ public void testNoTreesRetainedAfterDifference() throws Throwable
         long millisUntilFreed;
         for (millisUntilFreed = 0; millisUntilFreed < TEST_TIMEOUT_S * 1000; millisUntilFreed += THREAD_TIMEOUT_MILLIS)
         {
-            // The measured size of the syncingTasks, and result of the computation should be much smaller
+            // Once the threads die, the size of the session should return to nearly pre-execution levels.
             TimeUnit.MILLISECONDS.sleep(THREAD_TIMEOUT_MILLIS);
-            if (ObjectSizes.measureDeep(session) < 0.8 * singleTreeSize)
+            if (ObjectSizes.measureDeep(session) <= (sizeBeforeTasks * 1.05))

Review comment:
       The starting size of the session (before a single task is submitted) is much higher in Java 11 than Java 8 for some reason, but the amount of memory freed by the dying threads is almost exactly the same. The idea here is that we simply remember the starting size and make sure we revert to nearly that once the workers expire.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Nov/21 19:08;githubbot;600","dcapwell commented on a change in pull request #1309:
URL: https://github.com/apache/cassandra/pull/1309#discussion_r748594438



##########
File path: test/unit/org/apache/cassandra/repair/RepairJobTest.java
##########
@@ -274,9 +277,9 @@ public void testNoTreesRetainedAfterDifference() throws Throwable
         long millisUntilFreed;
         for (millisUntilFreed = 0; millisUntilFreed < TEST_TIMEOUT_S * 1000; millisUntilFreed += THREAD_TIMEOUT_MILLIS)
         {
-            // The measured size of the syncingTasks, and result of the computation should be much smaller
+            // Once the threads die, the size of the session should return to nearly pre-execution levels.
             TimeUnit.MILLISECONDS.sleep(THREAD_TIMEOUT_MILLIS);
-            if (ObjectSizes.measureDeep(session) < 0.8 * singleTreeSize)
+            if (ObjectSizes.measureDeep(session) <= (sizeBeforeTasks * 1.05))

Review comment:
       to help maintenance it would be good to document this

##########
File path: test/unit/org/apache/cassandra/repair/RepairJobTest.java
##########
@@ -274,9 +277,9 @@ public void testNoTreesRetainedAfterDifference() throws Throwable
         long millisUntilFreed;
         for (millisUntilFreed = 0; millisUntilFreed < TEST_TIMEOUT_S * 1000; millisUntilFreed += THREAD_TIMEOUT_MILLIS)
         {
-            // The measured size of the syncingTasks, and result of the computation should be much smaller
+            // Once the threads die, the size of the session should return to nearly pre-execution levels.
             TimeUnit.MILLISECONDS.sleep(THREAD_TIMEOUT_MILLIS);
-            if (ObjectSizes.measureDeep(session) < 0.8 * singleTreeSize)
+            if (ObjectSizes.measureDeep(session) <= (sizeBeforeTasks * 1.05))

Review comment:
       >  revert to nearly that once the workers expire.
   what is the extra 5% for?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Nov/21 21:29;githubbot;600","dcapwell commented on a change in pull request #1309:
URL: https://github.com/apache/cassandra/pull/1309#discussion_r748596049



##########
File path: test/unit/org/apache/cassandra/repair/RepairJobTest.java
##########
@@ -274,9 +277,9 @@ public void testNoTreesRetainedAfterDifference() throws Throwable
         long millisUntilFreed;
         for (millisUntilFreed = 0; millisUntilFreed < TEST_TIMEOUT_S * 1000; millisUntilFreed += THREAD_TIMEOUT_MILLIS)
         {
-            // The measured size of the syncingTasks, and result of the computation should be much smaller
+            // Once the threads die, the size of the session should return to nearly pre-execution levels.
             TimeUnit.MILLISECONDS.sleep(THREAD_TIMEOUT_MILLIS);
-            if (ObjectSizes.measureDeep(session) < 0.8 * singleTreeSize)
+            if (ObjectSizes.measureDeep(session) <= (sizeBeforeTasks * 1.05))

Review comment:
       >  revert to nearly that once the workers expire.
   
   what is the extra 5% for?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Nov/21 21:33;githubbot;600","dcapwell commented on a change in pull request #1309:
URL: https://github.com/apache/cassandra/pull/1309#discussion_r748598090



##########
File path: test/unit/org/apache/cassandra/repair/RepairJobTest.java
##########
@@ -274,9 +277,9 @@ public void testNoTreesRetainedAfterDifference() throws Throwable
         long millisUntilFreed;
         for (millisUntilFreed = 0; millisUntilFreed < TEST_TIMEOUT_S * 1000; millisUntilFreed += THREAD_TIMEOUT_MILLIS)
         {
-            // The measured size of the syncingTasks, and result of the computation should be much smaller
+            // Once the threads die, the size of the session should return to nearly pre-execution levels.
             TimeUnit.MILLISECONDS.sleep(THREAD_TIMEOUT_MILLIS);
-            if (ObjectSizes.measureDeep(session) < 0.8 * singleTreeSize)
+            if (ObjectSizes.measureDeep(session) <= (sizeBeforeTasks * 1.05))

Review comment:
       given how I read the test, this patch looks fine to me; just making sure we revert to where we were before starting; which is mostly what this test is checking....
   
   +1 for that, but would still be nice to know what got larger.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Nov/21 21:33;githubbot;600","maedhroz commented on a change in pull request #1309:
URL: https://github.com/apache/cassandra/pull/1309#discussion_r748617174



##########
File path: test/unit/org/apache/cassandra/repair/RepairJobTest.java
##########
@@ -274,9 +277,9 @@ public void testNoTreesRetainedAfterDifference() throws Throwable
         long millisUntilFreed;
         for (millisUntilFreed = 0; millisUntilFreed < TEST_TIMEOUT_S * 1000; millisUntilFreed += THREAD_TIMEOUT_MILLIS)
         {
-            // The measured size of the syncingTasks, and result of the computation should be much smaller
+            // Once the threads die, the size of the session should return to nearly pre-execution levels.
             TimeUnit.MILLISECONDS.sleep(THREAD_TIMEOUT_MILLIS);
-            if (ObjectSizes.measureDeep(session) < 0.8 * singleTreeSize)
+            if (ObjectSizes.measureDeep(session) <= (sizeBeforeTasks * 1.05))

Review comment:
       I'll make a note around this in the Jira and expand the comment inline here as well.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Nov/21 22:19;githubbot;600","maedhroz closed pull request #1309:
URL: https://github.com/apache/cassandra/pull/1309


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Nov/21 00:01;githubbot;600","maedhroz commented on pull request #1309:
URL: https://github.com/apache/cassandra/pull/1309#issuecomment-967735262


   Committed as https://github.com/apache/cassandra/commit/092bb60ba413b8ef0eb9e0de86ce394a2f939084


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Nov/21 00:01;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,4800,,,0,4800,,,,,,,,,,CASSANDRA-17087,,,,,,,,,,,,,,,,,,,,,,,"12/Nov/21 22:56;maedhroz;j11-threadfactory;https://issues.apache.org/jira/secure/attachment/13036051/j11-threadfactory","12/Nov/21 22:56;maedhroz;j8-threadfactory;https://issues.apache.org/jira/secure/attachment/13036050/j8-threadfactory",,,,2.0,maedhroz,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sat Nov 13 00:01:35 UTC 2021,,,,,,,All,,,,"0|z0vtmo:",9223372036854775807,,,,dcapwell,,,,Normal,,4.1,,https://github.com/apache/cassandra/commit/092bb60ba413b8ef0eb9e0de86ce394a2f939084,,,,,,,,,This patch is a small fix to an existing unit test.,,,,,"10/Nov/21 02:01;maedhroz;I've been able to reproduce this locally, but only on Java 11 for some reason. That actually squares w/ the CircleCi runs, where it doesn't seem to have failed on 8...;;;","10/Nov/21 02:21;maedhroz;The memory meter reports completely different numbers between J8 and J11 for the retained size of {{MeasureableRepairSession}} across the same exact C* codebase:

J8
{noformat}
INFO  [main] 2021-11-09 20:13:02,767 RepairJob.java:268 - Created 2 sync tasks based on 3 merkle tree responses for 6e524549-dbfd-4143-83b6-8a9920594f9e (took: 13ms)
INFO  [RepairJobTask:1] 2021-11-09 20:13:02,876 SyncTask.java:89 - [repair #bba3e650-41cb-11ec-86cb-e76f756cd20a] Endpoints /127.0.0.1:7012 and /127.0.0.2:7012 have 1 range(s) out of sync for Standard1
INFO  [RepairJobTask:2] 2021-11-09 20:13:02,876 SyncTask.java:89 - [repair #bba3e650-41cb-11ec-86cb-e76f756cd20a] Endpoints /127.0.0.1:7012 and /127.0.0.3:7012 have 1 range(s) out of sync for Standard1
INFO  [RepairJobTask:2] 2021-11-09 20:13:02,878 SymmetricRemoteSyncTask.java:68 - [repair #bba3e650-41cb-11ec-86cb-e76f756cd20a] Forwarding streaming repair of 1 ranges to /127.0.0.1:7012 (to be streamed with /127.0.0.3:7012)
INFO  [RepairJobTask:1] 2021-11-09 20:13:02,878 SymmetricRemoteSyncTask.java:68 - [repair #bba3e650-41cb-11ec-86cb-e76f756cd20a] Forwarding streaming repair of 1 ranges to /127.0.0.1:7012 (to be streamed with /127.0.0.2:7012)
ERROR [main] 2021-11-09 20:13:03,123 SubstituteLogger.java:265 - Size with trees: 9574096
DEBUG [RepairJobTask:2] 2021-11-09 20:13:03,125 RepairSession.java:241 - [repair #bba3e650-41cb-11ec-86cb-e76f756cd20a] Repair completed between /127.0.0.1:7012 and /127.0.0.3:7012 on Standard1
DEBUG [RepairJobTask:1] 2021-11-09 20:13:03,125 RepairSession.java:241 - [repair #bba3e650-41cb-11ec-86cb-e76f756cd20a] Repair completed between /127.0.0.1:7012 and /127.0.0.2:7012 on Standard1
ERROR [main] 2021-11-09 20:13:03,275 SubstituteLogger.java:265 - Size without trees: 1863000
{noformat}

J11
{noformat}
INFO  [main] 2021-11-09 20:13:26,155 RepairJob.java:268 - Created 2 sync tasks based on 3 merkle tree responses for f9e90e8c-6ae6-4ca9-ba24-f40750d8b0f8 (took: 11ms)
INFO  [RepairJobTask:1] 2021-11-09 20:13:26,204 SyncTask.java:89 - [repair #c9a25bb0-41cb-11ec-bba2-f9bd30f7271a] Endpoints /127.0.0.1:7012 and /127.0.0.2:7012 have 1 range(s) out of sync for Standard1
INFO  [RepairJobTask:2] 2021-11-09 20:13:26,204 SyncTask.java:89 - [repair #c9a25bb0-41cb-11ec-bba2-f9bd30f7271a] Endpoints /127.0.0.1:7012 and /127.0.0.3:7012 have 1 range(s) out of sync for Standard1
INFO  [RepairJobTask:2] 2021-11-09 20:13:26,205 SymmetricRemoteSyncTask.java:68 - [repair #c9a25bb0-41cb-11ec-bba2-f9bd30f7271a] Forwarding streaming repair of 1 ranges to /127.0.0.1:7012 (to be streamed with /127.0.0.3:7012)
INFO  [RepairJobTask:1] 2021-11-09 20:13:26,205 SymmetricRemoteSyncTask.java:68 - [repair #c9a25bb0-41cb-11ec-bba2-f9bd30f7271a] Forwarding streaming repair of 1 ranges to /127.0.0.1:7012 (to be streamed with /127.0.0.2:7012)
ERROR [main] 2021-11-09 20:13:26,641 SubstituteLogger.java:265 - Size with trees: 16202960
DEBUG [RepairJobTask:1] 2021-11-09 20:13:26,643 RepairSession.java:241 - [repair #c9a25bb0-41cb-11ec-bba2-f9bd30f7271a] Repair completed between /127.0.0.1:7012 and /127.0.0.2:7012 on Standard1
DEBUG [RepairJobTask:2] 2021-11-09 20:13:26,643 RepairSession.java:241 - [repair #c9a25bb0-41cb-11ec-bba2-f9bd30f7271a] Repair completed between /127.0.0.1:7012 and /127.0.0.3:7012 on Standard1
ERROR [main] 2021-11-09 20:13:48,363 SubstituteLogger.java:265 - Size without trees: 8447392
{noformat}

One comment from the test indicates...

{noformat}
// The session retains memory in the contained executor until the threads expire, so we wait for the threads
// that ran the Tree -> SyncTask conversions to die and release the memory
{noformat}

In both cases above, the executor has two worker threads in its collection of workers before and zero after. Jamm should only be following live references, so still have some digging to do. I might make the executor itself volatile and null it out before the second inspection...;;;","12/Nov/21 21:04;maedhroz;As I've noted [here|https://github.com/apache/cassandra/pull/1309#discussion_r748525029], the starting size (according to {{jamm}}) of the {{RepairSession}} is much higher in Java 11 than Java 8, solely due to its {{taskExecutor}} field. Its type was recently changed to {{ThreadPoolExecutorPlus}} in CASSANDRA-16925, so this problem doesn't manifest in 4.0, but it's not clear to me why {{jamm}} interprets it differently on Java 11. ([~samt] [~benedict] I can dig a bit more into the jamm accounting if either of you is interested.)

In terms of this Jira, I went the direction of making the existing assertion in {{RepairJobTest.testNoTreesRetainedAfterDifference}} (i.e. that expired worker threads release tree memory) less brittle. Our expectations are now grounded to the starting size of the session before any tasks are submitted.;;;","12/Nov/21 21:08;maedhroz;PR: https://github.com/apache/cassandra/pull/1309
CircleCI: https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-17039

Note...there are some failures outside the unit tests, but as this is a small change to a single existing unit test, those are surely unrelated. Also note I've not used the multiplexer here, since the failure was stable on Java 11 prior to the fix.;;;","12/Nov/21 21:49;dcapwell;+1.  The test is marking sure we free memory, so I am cool making sure we are at least <= previous memory.

nit: can you add documentation in the code explaining the change?;;;","12/Nov/21 22:58;maedhroz;It looks like the differences in jamm's measurements between J8 and J11 are all around the {{ClassLoader}} reference {{contextClassLoader}} in {{NamedThreadFactory}}. That object graph appears to have expanded in J11.

 [^j8-threadfactory]  [^j11-threadfactory] ;;;","12/Nov/21 23:49;maedhroz;Alright, so I did run it through the multiplexer just in case :)

https://app.circleci.com/pipelines/github/maedhroz/cassandra/364/workflows/1ad887d0-c457-4a8b-b1ec-2d7da2e6e5e3;;;","13/Nov/21 00:01;maedhroz;Committed to trunk in https://github.com/apache/cassandra/commit/092bb60ba413b8ef0eb9e0de86ce394a2f939084;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MessagingServiceTest listenOptionalSecureConnection and listenRequiredSecureConnection fail sporadically,CASSANDRA-17033,13405990,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,maedhroz,maedhroz,11/Oct/21 17:34,27/May/22 19:25,13/Jul/23 08:40,09/Nov/21 17:02,4.1,4.1-alpha1,,,,,,Messaging/Internode,,,,1,test-failure,test-failures,"This popped up in a recent CircleCI run: https://app.circleci.com/pipelines/github/maedhroz/cassandra/351/workflows/f8dbf599-df72-4982-8a12-a72a5b8ddd3b/jobs/2195

I was able to reproduce it locally on trunk as well in a single run, although it happens perhaps once per 3-4 runs of the MessagingServiceTest suite. It looks like we open the sockets in an InboundSockets container, await on the future that returns, and then assert that all those sockets are open. It’s not clear to me yet why this assertion fails sporadically, or what state changes exactly are racing.",,benedict,dcapwell,e.dimitrova,maedhroz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17088,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Nov 09 16:01:04 UTC 2021,,,,,,,All,,,,"0|z0vqy0:",9223372036854775807,,,,benedict,maedhroz,,,Normal,,NA,,https://github.com/apache/cassandra/commit/59aab691ea22653e395c62c6c38ab547e59de63a,,,,,,,,,tests,,,,,"04/Nov/21 23:07;dcapwell;found the issue; 2 bugs

1) test doesn't wait on the future...
2) future combiner isn't working, need to use the non-netty methods and works just fine then.;;;","04/Nov/21 23:08;dcapwell;the issue looks localized to trunk as the future refactor is what looks to have caused this;;;","08/Nov/21 23:45;dcapwell;the issue was that the future returned from open would return and call a callback async; this callback sets the state that isOpen depends on (causing the flaky behavior). The patch fixes this so that all state is updated before the future open returns gets completed.;;;","09/Nov/21 03:40;maedhroz;+1;;;","09/Nov/21 09:14;benedict;+1;;;","09/Nov/21 16:01;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-17033-trunk-55120AA3-A9C0-46B7-A831-0B7249750D7E]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-17033-trunk-55120AA3-A9C0-46B7-A831-0B7249750D7E]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1270/]|
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Backport snakeyaml 1.26 upgrade,CASSANDRA-17028,13405646,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,08/Oct/21 15:34,15/Oct/21 15:08,13/Jul/23 08:40,15/Oct/21 15:08,3.11.12,,,,,,,Dependencies,,,,0,,,"In CASSANDRA-16150 snakeyaml was upgraded, but only in the 4.0 line.  We should backport this to 3.11 and 3.0 as well.",,bereng,tsteinmaurer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Security,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Oct 15 15:08:59 UTC 2021,,,,,,,All,,,,"0|z0votc:",9223372036854775807,,,,bereng,,,,Normal,,NA,,https://github.com/apache/cassandra/commit/5c7603c2aed261380e364f5f50933db11038dbb0,,,,,,,,,Run CI,,,,,"08/Oct/21 17:21;brandon.williams;||Branch||CI||
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-17028-3.11]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17028-3.11], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1205/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1205/pipeline]|

4.0 had an easier time since it already had some minor changes to compile against 1.23, which I've backported here for 3.11, but will skip for 3.0.
;;;","15/Oct/21 04:33;bereng;Code lgtm, only left a nit. Circle passes. Jenkins has around 40 failures which aligns to what I see in the nightly CI. I would not bother 3.0 with non critical updates. +1;;;","15/Oct/21 15:08;brandon.williams;Committed w/nits fixed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
UnableToParseClientMessageFromBlockedSubnetTest.badMessageCausesProtocolExceptionFromExcludeList failing on extra log entries,CASSANDRA-17026,13405500,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,maedhroz,maedhroz,maedhroz,07/Oct/21 21:18,27/May/22 19:25,13/Jul/23 08:40,09/Oct/21 06:02,4.1,4.1-alpha1,,,,,,Observability/Logging,Test/dtest/java,,,0,,,"This test, while parameterized and run more than once, expects a single log entry describing the reporting exclusion for the single query made with each parameter combination.

However, we’re seeing this:

{noformat}
junit.framework.AssertionFailedError: 
Expected size:<1>  but was:<2>  in:
<[""DEBUG [nioEventLoopGroup-5-2] {instance:id} 2021-10-07T09:49:42,974 Excluding client exception for /127.0.0.1:56628; address contained in client_error_reporting_exclusions"",
    ""DEBUG [nioEventLoopGroup-5-3] {instance:id} 2021-10-07T09:49:42,984 Excluding client exception for /127.0.0.1:56634; address contained in client_error_reporting_exclusions""]>
	at org.apache.cassandra.distributed.test.UnableToParseClientMessageFromBlockedSubnetTest.badMessageCausesProtocolExceptionFromExcludeList(UnableToParseClientMessageFromBlockedSubnetTest.java:114)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{noformat}

Looking at the logs more deeply, the V3 and V4 protocol cases are actually logging twice, once on initially processing the message, and again on channel closure. There should be a way to eliminate the double logging...",,jonmeredith,maedhroz,,,,,,,,,,,,,,"maedhroz closed pull request #1257:
URL: https://github.com/apache/cassandra/pull/1257


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Oct/21 06:01;githubbot;600","maedhroz commented on pull request #1257:
URL: https://github.com/apache/cassandra/pull/1257#issuecomment-939235112


   Committed as https://github.com/apache/cassandra/commit/4f09733d28398207bc16ace92cda6e1ffeb99644


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Oct/21 06:02;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,CASSANDRA-16859,,,,,,,,,,,,,,,,,,,,,,,,,0.0,maedhroz,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sat Oct 09 06:02:31 UTC 2021,,,,,,,All,,,,"0|z0vnww:",9223372036854775807,,,,jmeredithco,,,,Low,,4.1,,https://github.com/apache/cassandra/commit/4f09733d28398207bc16ace92cda6e1ffeb99644,,,,,,,,,This is a fix for a flakey test (although the fix isn't in the test itself).,,,,,"08/Oct/21 20:43;maedhroz;To summarize, when protocol version decoding fails in the pre-V5 message handling code, we don't consume/skip the remaining {{Envelope}} bytes. So, we log on the initial decoding attempt, but then log again when the channel closure logic tries to decode again, which leads to all sorts of possible racy behavior in the test, which assumes a single log message per request.

PR: https://github.com/apache/cassandra/pull/1257
CircleCI: https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-17026;;;","08/Oct/21 21:33;jonmeredith;+1 once you get a clean CI run.;;;","08/Oct/21 23:21;maedhroz;I've been able to reproduce the failures in {{MessagingServiceTest}} locally on trunk, so those are clearly not related. I'll move to commit this, but will create a test flake Jira as well...;;;","09/Oct/21 06:02;maedhroz;Committed as https://github.com/apache/cassandra/commit/4f09733d28398207bc16ace92cda6e1ffeb99644;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use com.google.common.collect.Lists instead of com.google.monitoring.runtime.instrumentation.common.collect.Lists in RowUtil.,CASSANDRA-17022,13404738,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,ifesdjeen,ifesdjeen,ifesdjeen,04/Oct/21 08:06,27/May/22 19:25,13/Jul/23 08:40,12/Nov/21 06:25,4.0.2,4.1,4.1-alpha1,,,,,Test/dtest/java,,,,0,,,Use com.google.common.collect.Lists instead of com.google.monitoring.runtime.instrumentation.common.collect.Lists in RowUtil.,,blerer,ifesdjeen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,ifesdjeen,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Low Hanging Fruit,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Nov 12 06:24:30 UTC 2021,,,,,,,All,,,,"0|z0vj80:",9223372036854775807,,,,blerer,,,,Low,,4.0,,https://github.com/apache/cassandra/commit/ddf5c581b8aba355262ecfd7499af18362af8e9f,,,,,,,,,Exercised during fuzz test ,,,,,"04/Oct/21 08:20;ifesdjeen;Patch: https://github.com/apache/cassandra/compare/trunk...ifesdjeen:CASSANDRA-17022-4.0?expand=1

Cleanly merges to trunk.;;;","04/Oct/21 08:27;blerer;The patch looks good to me.;;;","12/Nov/21 06:24;ifesdjeen;Thank you [~blerer]! Committed to 4.0 with [ddf5c581b8aba355262ecfd7499af18362af8e9f|https://github.com/apache/cassandra/commit/ddf5c581b8aba355262ecfd7499af18362af8e9f] and merged up to trunk (no-op).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cqlshlib failure,CASSANDRA-17020,13404504,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandonwilliams,e.dimitrova,e.dimitrova,01/Oct/21 13:55,27/May/22 19:25,13/Jul/23 08:40,05/Oct/21 14:48,4.0.2,4.1,4.1-alpha1,,,,,CI,,,,0,,,"Failing for 4.0 and trunk - [https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1135/workflows/3e76993a-8ff0-442b-ae19-e3c6abf09ee6/jobs/6670] 

Also 3.11 here - https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1152/#showFailuresLink
 

/CC [~brandon.williams]",,e.dimitrova,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandonwilliams,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Oct 05 14:48:03 UTC 2021,,,,,,,All,,,,"0|z0vhs0:",9223372036854775807,,,,e.dimitrova,,,,Normal,,,,https://github.com/apache/cassandra/commit/b22749bbb2c5f5dc91312c7e0f7107e9a301b8eb,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-17020?focusedCommentId=17423326&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17423326,,,,,"01/Oct/21 14:04;brandon.williams;setuptools deprecated 'use_2to3': https://github.com/pypa/setuptools/issues/2086 which the thrift 0.9.3 package sets to True.  When we began pulling in setuptools 0.58.1, this broke the build.;;;","01/Oct/21 14:07;brandon.williams;Also, I believe this will fail all builds, not just 4.0 and trunk, since they all use thrift and the setuptools version is pulled automagically.  For 4.0 and trunk we can just [remove thrift|https://github.com/apache/cassandra/blob/trunk/pylib/requirements.txt#L21].;;;","01/Oct/21 14:42;brandon.williams;Removing thrift works: https://ci-cassandra.apache.org/job/Cassandra-devbranch-cqlsh-tests/1072/;;;","01/Oct/21 14:58;e.dimitrova;+1 on the fix for 4.0 and trunk, we need to look at the previous branches. I confirm, we use cached base image and it seems when the new image was pushed the new version was pulled. 
I can try to fix this now for the previous branches too or as an intermediate solution we can point to the old image until it's fixed. Circle CI should be working fine though as it still points on all branches to the old cached image where we use the older version. ;;;","01/Oct/21 15:03;brandon.williams;[Removed|https://github.com/apache/cassandra/commit/b22749bbb2c5f5dc91312c7e0f7107e9a301b8eb] thrift from 4.0 and trunk.;;;","01/Oct/21 15:12;e.dimitrova;Thanks! Looking into 3.11 now;;;","01/Oct/21 16:03;e.dimitrova;It seems like a different issue.

I am waiting for [this build|https://jenkins-cm4.apache.org/job/Cassandra-3.0/204/console] to finish soon.

What I found from [this build |https://jenkins-cm4.apache.org/job/Cassandra-devbranch-cqlsh-tests/1068/] and in [this log |https://jenkins-cm4.apache.org/job/Cassandra-devbranch-cqlsh-tests/1068/cython=yes,jdk=jdk_1.8_latest,label=cassandra/console] is:

{code:java}
21:16:55 ./cassandra-builds/build-scripts/cassandra-test-docker.sh: line 134: 30217 Terminated              tail -F build/test/logs/docker_attach_$(( $i + 1 )).log
21:16:55 Error: No such container:path: 090399aa7b6d41f4516812432ae9fdc27447b1ff0fce2584031d0d1e615f5eec:/home/cassandra/cassandra/build/test/output/.
21:16:55 Error: No such container:path: 
{code}

The cqlsh tests are running but logs are not saved it seems. I don't have immediate answer to what happened. Keep on digging...;;;","01/Oct/21 22:54;e.dimitrova;I found that the same issue with the paths is appearing from time to time - like I found logs for it on the 3.0 branch from a week ago. Eventually the next builds were fine. Maybe [~mck] will know already something about that. 
I pushed 3.0, 3.11, 4.0, trunk tests as I had to test also one patch I have.
3.0 cqlsh finished [ok| https://ci-cassandra.apache.org/job/Cassandra-devbranch-cqlsh-tests/1074/], 3.11 [also finished fine |https://jenkins-cm4.apache.org/job/Cassandra-devbranch-cqlsh-tests/1073/#showFailuresLink] in the sense the logs look fine, there are some failing tests that we already know from before. 

;;;","05/Oct/21 14:20;brandon.williams;It looks like all the builds are working now, is there anything else that needs to be done on this ticket?;;;","05/Oct/21 14:48;e.dimitrova;Yeah, I was monitoring and I also don't think there is anything more to be done. Closing it. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JNA 5.6.0 does not support arm64,CASSANDRA-17019,13404456,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,yqGu,igmar,igmar,01/Oct/21 09:39,16/Nov/22 22:34,13/Jul/23 08:40,07/Jan/22 19:07,4.1,4.1-alpha1,,,,,,Dependencies,,,,0,,,"Cassandra depends on net.java.dev.jna.jna version 5.6.0 to do the native binding into the C library.

JNA 5.6.0 does not support arm64 architecture (Apple M1 devices), causing cassandra to fail on bootstrap.
 Bumping the dependency to 5.9.0 adds arm64 support. Will a PR to bump the dependency be acceptable ?",,brandon.williams,djoshi,e.dimitrova,flightc,ganeshraju,igmar,stefan.miklosovic,tsteinmaurer,v_ganeshraju,yifanc,yqGu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17040,,,,,,,,CASSANDRA-18050,,,,,,,,,,,,,,,,,,"14/Oct/21 04:26;yqGu;UTs_snappy_upgrading.txt;https://issues.apache.org/jira/secure/attachment/13034940/UTs_snappy_upgrading.txt","13/Oct/21 05:29;yqGu;cassandra_UTs.txt;https://issues.apache.org/jira/secure/attachment/13034891/cassandra_UTs.txt",,,,2.0,yqGu,,,,,,,,,,,,,Availability -> Unavailable,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sat Jan 08 20:53:07 UTC 2022,,,,,,,ARM,,,,"0|z0vhhc:",9223372036854775807,,,,djoshi,stefan.miklosovic,,,Normal,,4.1,,https://github.com/apache/cassandra/commit/2043cb9fb6b25ff34afb90467b9476a09acc3933,,,,,,,,,Jenkins build and manual testing,,,,,"08/Oct/21 06:43;stefan.miklosovic;Hi [~igmar], we are building ARM here as part of our pipeline (1).

Are  you sure it does not work on arm64?

We are building that, for example, on this node (3)

(1) https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-artifacts/
(2) https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-artifacts-arm64/
(3) https://ci-cassandra.apache.org/computer/cassandra-arm2/;;;","08/Oct/21 07:42;flightc;FWIW I believe [PR#1238|https://github.com/java-native-access/jna/pull/1238] was the fix for Apple M1 {{darwin}} in [JNA 5.7.0|https://github.com/java-native-access/jna/blob/master/CHANGES.md#release-570].;;;","08/Oct/21 09:34;stefan.miklosovic;I upgraded this to 5.9.0.

4.0 https://github.com/apache/cassandra/pull/1255
trunk https://github.com/apache/cassandra/pull/1256
build: https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1192/

I have manually verified 5.9.0 works on 4.0 on Debian Buster 10 on m6g.xlarge in AWS  (aarm64). I do not have any Apple M1 devices available to test this on.

[~igmar] [~flightc] could you verify the patch on Apple M1 if you happen to have that machine? ;;;","08/Oct/21 10:05;stefan.miklosovic;I would preferably do this for trunk only, not for 4.0.x. I do no think that it is a good idea to drop architecture (like 32 bit Darwin as they said in release notes for 5.7.0) in a patch release.;;;","08/Oct/21 10:06;igmar;It doesn't work with 5.6.0. Building isn't the issue, its a runtime thing. Replacing 5.6.0 with 5.9.0 makes it work for me.;;;","08/Oct/21 10:15;stefan.miklosovic;Yeah I get that, part of the build are tests which are running just built Cassandra and we have different archs for that, arm64 is one of these but as you say it just doesnt work on Apple stuff with 5.6.0.;;;","12/Oct/21 03:20;yqGu;[~stefan.miklosovic]

We have Apple M1 device and would like to help verify it based on trunk ( [https://github.com/apache/cassandra/pull/1256).|https://github.com/apache/cassandra/pull/1256]

I'll post the related result here soon.;;;","12/Oct/21 06:41;yqGu;Successfully built on Apple M1 by replacing 5.6.0 with 5.9.0([https://github.com/apache/cassandra/pull/1256]):

 

Environment:
{code:java}
Hardware Overview: 
Model Name: Mac mini 
Model Identifier: Macmini9,1 
Chip: Apple M1 
Total Number of Cores: 8 (4 performance and 4 efficiency) 
Memory: 16 GB
 
JDK11:
openjdk 11.0.12 2021-07-20
OpenJDK Runtime Environment Homebrew (build 11.0.12+0)
OpenJDK 64-Bit Server VM Homebrew (build 11.0.12+0, mixed mode)
 
{code}
 
{code:java}
$ ant -Duse.jdk11=true

Buildfile: /Users/linux/yuqi/cassandra/build.xml
   [script] Warning: Nashorn engine is planned to be removed from a future JDK releasevalidate-build-conf:init:
    [mkdir] Created dir: /Users/linux/yuqi/cassandra/build/classes/main
    [mkdir] Created dir: /Users/linux/yuqi/cassandra/build/test/lib
    [mkdir] Created dir: /Users/linux/yuqi/cassandra/build/test/classes
    [mkdir] Created dir: /Users/linux/yuqi/cassandra/build/test/stress-classes
    [mkdir] Created dir: /Users/linux/yuqi/cassandra/build/test/fqltool-classes
    [mkdir] Created dir: /Users/linux/yuqi/cassandra/src/gen-java
    [mkdir] Created dir: /Users/linux/yuqi/cassandra/build/lib
    [mkdir] Created dir: /Users/linux/yuqi/cassandra/build/jacoco
    [mkdir] Created dir: /Users/linux/yuqi/cassandra/build/jacoco/partials
............
.........
.....
...
..
.
    [mkdir] Created dir: /Users/linux/yuqi/cassandra/build/tools/lib
      [jar] Building jar: /Users/linux/yuqi/cassandra/build/tools/lib/stress.jar
    [mkdir] Created dir: /Users/linux/yuqi/cassandra/build/classes/fqltool/META-INF
      [jar] Building jar: /Users/linux/yuqi/cassandra/build/tools/lib/fqltool.jar
BUILD SUCCESSFUL
Total time: 4 minutes 22 seconds
{code}
 ;;;","12/Oct/21 08:28;stefan.miklosovic;Hi [~yqGu], could you please run all tests? I was reported that build is not a problem but tests are.;;;","12/Oct/21 09:07;yqGu;Sure, I'll post the result of Unit tests late.;;;","12/Oct/21 09:18;stefan.miklosovic;It would be awesome if you had a capacity to run dtests too.;;;","12/Oct/21 17:57;brandon.williams;[Here|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-17019] is a circle run on trunk too.;;;","13/Oct/21 05:33;yqGu;The log of unit tests was attached.

It seems 19 test cases were failed, which are related to ""snappy"".

 ;;;","13/Oct/21 07:11;stefan.miklosovic;Interesting, that has to be some kind of a glitch I guess ... can you doblecheck you have that lib on the classpath? It fails on ""ClassNotFoundException"";;;","13/Oct/21 10:10;yqGu;The snappy-java-1.1.2.6.jar could be found in:
{code:java}
cassandra/build/lib/jars{code}
I add this path to CLASS_PATH  and add flag: 

{{-Dorg.xerial.snappy.lib.name=libsnappyjava.jnilib -Dorg.xerial.snappy.tempdir=/tmp}}

But also failed in test case for ""SnappyCompressor.create() threw an error: java.lang.NoClassDefFoundError...."".

 

 

 

 

 ;;;","14/Oct/21 01:30;djoshi;It looks like snappy lacks support for M1 Mac. However, it is expected to fall back on a pure Java implementation.;;;","14/Oct/21 03:00;yqGu;[~djoshi] Yes, snappy-java didn't support Apple M1 until 1.1.8.2 release.


[~stefan.miklosovic] 
I upgraded snappy to the latest verison 1.1.8.4 to support M1: https://github.com/apache/cassandra/pull/1268
The releated unit tests were passed and the logs will be attached to CASSANDRA-17040 soon.
;;;","14/Oct/21 04:25;yqGu;After upgrading snappy to latest version, all unit tests are passed except one:
{code:java}
org.apache.cassandra.net.MessagingServiceTest
{code}


{code:java}
[junit-timeout] Testsuite: org.apache.cassandra.net.MessagingServiceTest
[junit-timeout] Testsuite: org.apache.cassandra.net.MessagingServiceTest Tests run: 14, Failures: 2, Errors: 4, Skipped: 0, Time elapsed: 1.502 sec
[junit-timeout]
[junit-timeout] Testcase: listenRequiredSecureConnectionWithBroadcastAddrAndLegacyPort(org.apache.cassandra.net.MessagingServiceTest):  Caused an ERROR
[junit-timeout] failed to bind to: /127.0.0.2:17012
[junit-timeout] org.apache.cassandra.exceptions.ConfigurationException: failed to bind to: /127.0.0.2:17012
[junit-timeout]         at org.apache.cassandra.net.InboundConnectionInitiator.bind(InboundConnectionInitiator.java:189)
[junit-timeout]         at org.apache.cassandra.net.InboundConnectionInitiator.bind(InboundConnectionInitiator.java:199)
[junit-timeout]         at org.apache.cassandra.net.InboundSockets$InboundSocket.open(InboundSockets.java:100)
[junit-timeout]         at org.apache.cassandra.net.InboundSockets$InboundSocket.open(InboundSockets.java:87)
[junit-timeout]         at org.apache.cassandra.net.InboundSockets.open(InboundSockets.java:236)
[junit-timeout]         at org.apache.cassandra.net.MessagingServiceTest.listen(MessagingServiceTest.java:342)
[junit-timeout]         at org.apache.cassandra.net.MessagingServiceTest.listenRequiredSecureConnectionWithBroadcastAddrAndLegacyPort(MessagingServiceTest.java:307)
[junit-timeout]         at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[junit-timeout]         at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[junit-timeout]         at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[junit-timeout] Caused by: java.net.BindException: Can't assign requested address
[junit-timeout]         at java.base/sun.nio.ch.Net.bind0(Native Method)
[junit-timeout]         at java.base/sun.nio.ch.Net.bind(Net.java:455)
[junit-timeout]         at java.base/sun.nio.ch.Net.bind(Net.java:447)
[junit-timeout]         at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
[junit-timeout]         at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:134)
[junit-timeout]         at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:550)
[junit-timeout]         at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1334)
[junit-timeout]         at io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:506)
[junit-timeout]         at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:491)
[junit-timeout]         at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
[junit-timeout]         at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:248)
[junit-timeout]         at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
[junit-timeout]         at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
[junit-timeout]         at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
[junit-timeout]         at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
[junit-timeout]         at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
[junit-timeout]         at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[junit-timeout]         at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[junit-timeout]         at java.base/java.lang.Thread.run(Thread.java:829)
[junit-timeout]
[junit-timeout]
{code}
;;;","14/Oct/21 06:05;djoshi;[~yqGu] this is expected in macOS. You'll need to manually create aliases for 127.0.0.1 to fix this failing unit test like this:
{code:java}
sudo ifconfig lo0 alias 127.0.0.2 up
sudo ifconfig lo0 alias 127.0.0.3 up
...
{code}

You may need to create more than just 3.

As part of this patch, please update Cassandra's README to reflect these instructions.;;;","19/Oct/21 23:04;djoshi;I am not sure if we need two different tickets (CASSANDRA-17040 and this) here as I don't think we can run the tests successfully without both Snappy and JNA being upgraded.;;;","14/Dec/21 17:57;djoshi;+1 lgtm;;;","05/Jan/22 22:09;yifanc;+1 on the patch. ;;;","08/Jan/22 20:53;e.dimitrova;I am wondering, is there a particular reason this was not bumped to 5.10, the latest version from November? (context - I was thinking of updating JNA considering the Java 17 upgrades, but delayed it as it seems they haven't tested yet, only with Java 16 from what I found);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky test - TokenMetadataTest.testRingIteratorIncludeMin,CASSANDRA-17007,13403845,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,28/Sep/21 12:42,27/May/22 19:25,13/Jul/23 08:40,28/Sep/21 20:17,4.1,4.1-alpha1,,,,,,Test/unit,,,,0,,,"As Berenguer noted on CASSANDRA-15290.

https://ci-cassandra.apache.org/job/Cassandra-trunk/733/testReport/junit/org.apache.cassandra.locator/TokenMetadataTest/testRingIteratorIncludeMin_2/",,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Sep 28 20:17:04 UTC 2021,,,,,,,All,,,,"0|z0vdpk:",9223372036854775807,,,,e.dimitrova,,,,Normal,,NA,,https://github.com/apache/cassandra/commit/021842312794a7fc24d49144f9aa7f22bb74a1f9,,,,,,,,,Run the multiplexer.,,,,,"28/Sep/21 17:16;brandon.williams;This test only fails when run in the suite, so here's a branch that moves the initialization of tmd from before the class init, to before each method.  This [passes|https://app.circleci.com/pipelines/github/driftx/cassandra/244/workflows/0842d9b5-b423-4b12-8d23-21a6b600d14b/jobs/1885] 100 runs in circle.;;;","28/Sep/21 19:48;e.dimitrova;+1, thank you! ;;;","28/Sep/21 20:17;brandon.williams;Commited, thank you for the review!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix test dtest.repair_tests.incremental_repair_test.TestIncRepair.test_multiple_repair,CASSANDRA-17005,13403653,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,e.dimitrova,e.dimitrova,27/Sep/21 19:18,22/Nov/22 15:42,13/Jul/23 08:40,04/Oct/22 23:32,4.0.7,4.1,4.1-rc1,5.0,,,,Test/dtest/python,,,,0,,,"[dtest.repair_tests.incremental_repair_test.TestIncRepair.test_multiple_repair|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1143/testReport/junit/dtest.repair_tests.incremental_repair_test/TestIncRepair/test_multiple_repair/] is flaky:
h3.  
{code:java}
Error Message
cassandra.OperationTimedOut: errors={'127.0.0.2:9042': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.2:9042

Stacktrace
self = <repair_tests.incremental_repair_test.TestIncRepair object at 0x7ff52f4f4fd0> def test_multiple_repair(self): """""" * Launch a three node cluster * Create a keyspace with RF 3 and a table * Insert 49 rows * Stop node3 * Insert 50 more rows * Restart node3 * Issue an incremental repair on node3 * Stop node2 * Insert a final50 rows * Restart node2 * Issue an incremental repair on node2 * Replace node3 with a new node * Verify data integrity # TODO: Several more verifications of data need to be interspersed throughout the test. The final assertion is insufficient. @jira_ticket CASSANDRA-10644 """""" cluster = self.cluster cluster.populate(3).start() node1, node2, node3 = cluster.nodelist() session = self.patient_cql_connection(node1) create_ks(session, 'ks', 3) if cluster.version() < '4.0': create_cf(session, 'cf', read_repair=0.0, columns={'c1': 'text', 'c2': 'text'}) else: create_cf(session, 'cf', columns={'c1': 'text', 'c2': 'text'}) logger.debug(""insert data"") insert_c1c2(session, keys=list(range(1, 50)), consistency=ConsistencyLevel.ALL) node1.flush() logger.debug(""bringing down node 3"") node3.flush() node3.stop(gently=False) logger.debug(""inserting additional data into node 1 and 2"") insert_c1c2(session, keys=list(range(50, 100)), consistency=ConsistencyLevel.TWO) node1.flush() node2.flush() logger.debug(""restarting and repairing node 3"") node3.start(wait_for_binary_proto=True) if cluster.version() >= ""2.2"": node3.repair() else: node3.nodetool(""repair -par -inc"") # wait stream handlers to be closed on windows # after session is finished (See CASSANDRA-10644) if is_win: time.sleep(2) logger.debug(""stopping node 2"") node2.stop(gently=False) logger.debug(""inserting data in nodes 1 and 3"") insert_c1c2(session, keys=list(range(100, 150)), consistency=ConsistencyLevel.TWO) node1.flush() node3.flush() logger.debug(""start and repair node 2"") node2.start(wait_for_binary_proto=True) if cluster.version() >= ""2.2"": node2.repair() else: node2.nodetool(""repair -par -inc"") logger.debug(""replace node and check data integrity"") node3.stop(gently=False) node5 = Node('node5', cluster, True, ('127.0.0.5', 9160), ('127.0.0.5', 7000), '7500', '0', None, ('127.0.0.5', 9042)) cluster.add(node5, False, data_center=""dc1"") node5.start(replace_address='127.0.0.3') > assert_one(session, ""SELECT COUNT(*) FROM ks.cf LIMIT 200"", [149]) repair_tests/incremental_repair_test.py:300: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ tools/assertions.py:130: in assert_one res = session.execute(simple_query) ../venv/src/cassandra-driver/cassandra/cluster.py:2618: in execute return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile, paging_state, host, execute_as).result() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = <ResponseFuture: query='<SimpleStatement query=""SELECT COUNT(*) FROM ks.cf LIMIT 200"", consistency=Not Set>' request_i...9042': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.2:9042 coordinator_host=None> def result(self): """""" Return the final result or raise an Exception if errors were encountered. If the final result or error has not been set yet, this method will block until it is set, or the timeout set for the request expires. Timeout is specified in the Session request execution functions. If the timeout is exceeded, an :exc:`cassandra.OperationTimedOut` will be raised. This is a client-side timeout. For more information about server-side coordinator timeouts, see :class:`.policies.RetryPolicy`. Example usage:: >>> future = session.execute_async(""SELECT * FROM mycf"") >>> # do other stuff... >>> try: ... rows = future.result() ... for row in rows: ... ... # process results ... except Exception: ... log.exception(""Operation failed:"") """""" self._event.wait() if self._final_result is not _NOT_SET: return ResultSet(self, self._final_result) else: > raise self._final_exception E cassandra.OperationTimedOut: errors={'127.0.0.2:9042': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.2:9042 ../venv/src/cassandra-driver/cassandra/cluster.py:4894: OperationTimedOut
{code}",,bereng,e.dimitrova,smiklosovic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Oct 04 23:32:38 UTC 2022,,,,,,,All,,,,"0|z0vciw:",9223372036854775807,,,,e.dimitrova,,,,Low,,NA,,https://github.com/apache/cassandra-dtest/commit/682060ab747d851343fa950be323cbf5404614ef,,,,,,,,,run CI,,,,,"18/Feb/22 13:01;brandon.williams;I think this must have been fixed somewhere along the way.  I can't get it to fail after many runs, I don't see it [in butler|https://butler.cassandra.apache.org/#/ci/upstream/compare/Cassandra-4.0/cassandra-4.0], and it passes repeated runs [in circle|https://app.circleci.com/pipelines/github/driftx/cassandra/371/workflows/d462e8b9-1fe7-4159-ac41-404246eb47ea/jobs/4219].  I suggest we close.;;;","18/Feb/22 14:53;e.dimitrova;I think I actually saw it on some branch the other day, let me double check. Anyway I have to check how is butler doing today :) ;;;","18/Feb/22 14:54;e.dimitrova;Yes, it seems it is flaky on 4.0 https://butler.cassandra.apache.org/#/ci/upstream/workflow/Cassandra-4.0/failure/repair_tests.incremental_repair_test/TestIncRepair/test_multiple_repair;;;","18/Feb/22 15:02;brandon.williams;I'm not sure why that doesn't show on the main page, but the few occurrences there are timeouts, and circle passes so I'm not sure there's any surface left to attack.;;;","24/Feb/22 10:45;bereng;Agreed. All failures I see on jenkins and are timeouts, which is a well known jenkins issue CASSANDRA-17321. I would close and see if one day we can keep jenkins clean and stable enough these timeouts are actually sthg we can look into. Otherwise whenever I looked they would always be just plain timeouts on an overloaded node.;;;","12/May/22 08:00;bereng;Checked trunk jenkins history and all is clean. Butler is all green except for a couple occurrences which are all the same as the above: client request timeouts. Which seem prefectly legit on jenkins given it's state and problems. Closing to clear the board for the release.;;;","30/Aug/22 17:21;smiklosovic;I still see it in circle

https://app.circleci.com/pipelines/github/instaclustr/cassandra/1232/workflows/0ee2b67a-28d3-496e-a372-da234292ec41/jobs/5002/tests#failed-test-0;;;","02/Sep/22 14:18;e.dimitrova;I also saw it today on 4.1

Maybe worth it to be checked at some point as it seems those timeouts consistently pop up here and there only for this test?

https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1880/workflows/85df925c-da13-430e-99d1-1203f6440c41/jobs/14862/tests#failed-test-0

 ;;;","19/Sep/22 21:43;e.dimitrova;One more on trunk: https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1929/workflows/f70dd874-0b32-4028-9e9e-40e4f739b436/jobs/15245;;;","26/Sep/22 15:41;e.dimitrova;And one more time:

https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1948/workflows/24fc5596-0685-48e6-86ce-45a7b05ca944/jobs/15444;;;","27/Sep/22 05:16;bereng;Added to the CASSANDRA-17321 bucket list for starters. Do you guys think we should reopen it or is that 'enough'?;;;","03/Oct/22 23:23;e.dimitrova;I think this one fails pretty consistently in CircleCI, like almost every other time, and the other ticket seems to me to be focused on the Jenkins endless timeouts.

I would advocate to just reopen this one.

In other news, just saw it again, trunk:

https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1975/workflows/9dfad996-8e8f-497e-b01a-4d9212540646/jobs/15657

 ;;;","04/Oct/22 23:07;brandon.williams;[Unpatched failures inside 500x|https://app.circleci.com/pipelines/github/driftx/cassandra/660/workflows/2e6ed4ea-715a-41f8-ab7c-de77ee01ae14/jobs/7399] and [clean 500x|https://app.circleci.com/pipelines/github/driftx/cassandra/659/workflows/031f2a18-dd3b-4cdf-9f5b-045b906d6951/jobs/7401] after [this patch|https://github.com/driftx/cassandra-dtest/commit/534c6c6784411fe38656b168bb656eab9d13632e].;;;","04/Oct/22 23:28;e.dimitrova;+1, thanks;;;","04/Oct/22 23:32;brandon.williams;Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Handle timestamp wraparound for internode messages,CASSANDRA-16997,13403451,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,27/Sep/21 08:29,27/May/22 19:25,13/Jul/23 08:40,30/Sep/21 09:29,4.0.2,4.1,4.1-alpha1,,,,,Messaging/Internode,,,,0,,,"In internode messaging we send the lower 4 bytes of the timestamp and then correct on receiving side if the local time has wrapped (every 50 days), but we currently don't correct the time if the sending side wrapped before us. 

This can cause us to use the wrong timestamp for the message and if the local System.nanoTime is < 50 days, we get a negative creation time which causes an AssertionError in MonitorableImpl",,jonmeredith,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Availability -> Response Crash,,,,,,,,Normal,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Sep 30 09:29:28 UTC 2021,,,,,,,All,,,,"0|z0vba0:",9223372036854775807,,,,jonmeredith,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/84ec1dc97d6358bd569d5467cb150abd0fc8939b,,,,,,,,,new test + cci run,,,,,"27/Sep/21 08:33;marcuse;https://github.com/krummas/cassandra/commits/marcuse/16997
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16997 (cci seems broken, but should appear there soon);;;","27/Sep/21 16:05;jonmeredith;+1 ;;;","30/Sep/21 09:29;marcuse;and committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prevent broken concurrent schema read/writes,CASSANDRA-16996,13403427,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,27/Sep/21 06:39,27/May/22 19:24,13/Jul/23 08:40,26/Oct/21 05:49,3.11.12,4.0,4.1,4.1-alpha1,,,,Cluster/Schema,,,,0,,,See CASSANDRA-16856 where the concurrent read/write path was left out,,benedict,bereng,jlewandowski,maedhroz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16856,,,,,,,,,,,,,,,,CASSANDRA-17044,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Oct 26 05:50:02 UTC 2021,,,,,,,All,,,,"0|z0vb4o:",9223372036854775807,,,,jlewandowski,maedhroz,,,Normal,,3.11.0,,https://github.com/apache/cassandra/commit/fa532a61f810b428ccfdf4964684794a7fc0e885,,,,,,,,,Patch adds fuzz testing around local schema change atomicity.,,,,,"27/Sep/21 08:00;bereng;CI is down. Will trigger a run when it's back up again.;;;","27/Sep/21 22:57;maedhroz;Linking my comments from [here|https://issues.apache.org/jira/browse/CASSANDRA-16856?focusedCommentId=17420953&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17420953].

To expand on that a bit, I think we need at least 2 and possibly 3 things here, if it's clear that the problem identified in CASSANDRA-16856 is legitimate (and I think it is) and we want to make schema modifications atomic for {{SchemaKeyspace}}:

1.) To protect {{saveSystemKeyspacesSchema()}}, {{truncate()}}, {{calculateSchemaDigest()}}, {{convertSchemaToMutations()}}, and {{applyChanges()}}, given those are the places we deal with the contents of the entire schema keyspace.

2.) JavaDoc for {{SchemaKeyspace}} that explicitly lays out the class's synchronization policy and why it is that way. (This might need to mention in passing how this interacts w/ {{Schema}}, which also has its own synchronization that sort of incompletely overlaps w/ {{SchemaKeyspace}}.)

3.) (perhaps optional, but really nice and maybe not optional) A fuzz test like the one I mentioned [here|https://issues.apache.org/jira/browse/CASSANDRA-16856?focusedCommentId=17420953&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17420953] to simulate the case we're worried about at a reasonable level. In this case, it probably means hitting {{convertSchemaToMutations()}}, which is a good proxy for {{SchemaPullVerbHandler#doVerb()}}, concurrent to schema changes and/or truncations (possibly from {{Schema#transform()}}).

There is another way we might be able to solve this problem, and that's delegating more of our schema manipulation to {{Schema}}, where we're already synchronizing some of the codepaths that hit {{SchemaKeyspace}}. In that case, we could just annotate the latter as being explicitly not thread-safe.;;;","28/Sep/21 08:06;bereng;Pre CI run is done now [j11|https://app.circleci.com/pipelines/github/bereng/cassandra/438/workflows/edcb3e2e-a6f1-416b-8587-a6e82c387cb1] and [j8|https://app.circleci.com/pipelines/github/bereng/cassandra/438/workflows/4f56dcf3-e467-445e-a34c-cfce0b196ae2] which I was worried about.

1.) Yes these are some of the holes. But other 'multi-step' methods such as {{fetchKeyspace}} i.e. are not atomic. We could have changes get in-between each method it calls iiuc etc.
2.) Yes adding a javadoc along a note on each method as Josh mentioned is a good idea.
3.) The fuzz test I really dislike here an I am not entirely sure why. Overloading the class and making sure the syncs work would be my preference, short of that the junit we have now does the trick imo. At the end of the day is making sure the contract (API) won't be broken by accident in a deterministic way.;;;","28/Sep/21 09:50;bereng;The latest push seems ok test wise [j11|https://app.circleci.com/pipelines/github/bereng/cassandra/443/workflows/0f2e1f0b-4a48-41b2-8fb1-8b8c9ed5b840] [j8|https://app.circleci.com/pipelines/github/bereng/cassandra/443/workflows/b55a6248-4197-4246-88dd-a8cafc879288] besides the related junit failure fix I just pushed. I still want to give this one more thought before moving into review...;;;","28/Sep/21 11:42;benedict;Tests should verify that the behaviour we care about is correct, not that some specific artefact of the implementation is maintained.

I haven't looked carefully at this patch, but if we are to solve this using {{synchronized}} we should consider that currently the {{Schema}} class controls mutually exclusivity on {{applyChanges}} and perhaps this class should be the public API for these other two API methods. It seems these are the _only_ two public methods in {{SchemaKeyspace}} and so it would be easy to migrate public accessors to {{Schema}}, and perhaps even make {{SchemaKeyspace}} package private by migrating its public fields as well.;;;","28/Sep/21 16:02;maedhroz;bq. we should consider that currently the Schema class controls mutually exclusivity on applyChanges and perhaps this class should be the public API for these other two API methods

Yes, this is exactly what I meant by...

bq. There is another way we might be able to solve this problem, and that's delegating more of our schema manipulation to Schema, where we're already synchronizing some of the codepaths that hit SchemaKeyspace. In that case, we could just annotate the latter as being explicitly not thread-safe. 

In terms of what level of abstraction at which we would like to test, there is some prior art between {{SchemaDisagreementTest}}, {{SchemaTest}} (in-JVM), and {{SchemaTest}} (unit), and {{DigestResolverTest}} that could be a starting point. Fuzzing on the thread-safety guarantees (or lack thereof) of {{Schema}} directly (assuming the structure above) to reproduce this seems valuable. (If I had to argue against myself, I'd say that this doesn't add much value over simply the properly reviewed and documented fix, but in that case, a test checking for the {{synchronized}} modifier doesn't either.)

Are there any other details around the original Fallout test that spawned this that might be helpful?;;;","29/Sep/21 07:41;bereng;{quote}we should consider that currently the Schema class controls mutually exclusivity on applyChanges and perhaps this class should be the public API for these other two API methods{quote}

That resonates with me, right, which is what Caleb was saying and it is growing on me now.;;;","30/Sep/21 09:18;bereng;In the latest push I created sync public methods on {{Schema}} and made {{SchemaKeyspace}} package private. If we agree we are ok with how it looks now I can go for the test and the rest of PRs next. CI [j11|https://app.circleci.com/pipelines/github/bereng/cassandra/452/workflows/2baaca08-623d-4d45-846c-aa61744f7879] and [j8|https://app.circleci.com/pipelines/github/bereng/cassandra/452/workflows/fa80b38c-d726-417b-90de-2df583cd1575] have known flakies and 1 failure I overlooked so it lgtm.;;;","01/Oct/21 22:43;maedhroz;Just made a pass at the PR, and dropped some comments. Looks like it's headed in the right direction.;;;","15/Oct/21 16:41;maedhroz;With the discussion over how to test this in a better place, I've thrown my +1 (and one more non-controversial nit) on the PR.

I'm still in favor of removing {{testSchemaPullSynchoricity()}}, but I'm fine leaving a second reviewer ([~jlewandowski]?), which we should probably grab, given there is concurrency involved here, to break that tie ;);;;","18/Oct/21 05:23;bereng;Removing that test wins you nothing and it gives some level of protection imo.;;;","18/Oct/21 05:52;jlewandowski;btw. you can fix the typo in the test name;;;","18/Oct/21 07:32;bereng;Done :-) good eye;;;","19/Oct/21 06:52;bereng;[~jlewandowski] did you get a chance to look at the PR? Are you +1 on it?;;;","19/Oct/21 08:31;jlewandowski;+1;;;","20/Oct/21 10:51;bereng;Rebased and pushed the other PRs. The only problem being 3.11 with the new test I have to look a bit deeper as I can't get it to fail.;;;","22/Oct/21 14:29;maedhroz;Except for the [one remaining issue|https://github.com/apache/cassandra/pull/1278/files?authenticity_token=mRk1HCiqlaBpW%2BQQMMaRRuV4n68Frlnv1PNIOF18a5nAZYUHAZrX8pHh2DQ1pg4EjptTTct%2FyZbhCDRLSg3xhg%3D%3D&file-filters%5B%5D=.java#r734593004] we need to fix, I'm +1 on all 3 PRs at this point, assuming clean tests.;;;","25/Oct/21 07:57;bereng;All rebased, fixed, squahsed + new CI for a final check otherwise I'll merge.;;;","25/Oct/21 16:06;maedhroz;CASSANDRA-17050 will make it noisy unfortunately, but +1 if we don't make it worse.;;;","26/Oct/21 05:25;bereng;As agreed on Slack CI seems good so we're good to merge.;;;","26/Oct/21 05:50;bereng;Committed thx for the patience where we talking past each other :-);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
repair prepare message would produce a wrong error message if network timeout happened rather than reply wait timeout,CASSANDRA-16992,13403172,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,jmckenzie,jmckenzie,24/Sep/21 14:42,27/May/22 19:25,13/Jul/23 08:40,19/Nov/21 22:33,4.1,4.1-alpha1,,,,,,Consistency/Repair,Test/dtest/java,,,0,,,"Showed up on CASSANDRA-12988 test runs; can't reproduce locally.

 {quote}
junit.framework.AssertionFailedError: nodetool command [repair, distributed_test_keyspace, preparerpctimeout_full_parallel_false, --full] Error message 'Got negative replies from endpoints [/127.0.0.2:7012]' does not contain any of [Did not get replies from all endpoints.]
stdout:
[2021-09-22 17:37:02,187] After waiting for poll interval of 1 seconds queried for parent session status and discovered repair failed.
[2021-09-22 17:37:02,187] Got negative replies from endpoints [/127.0.0.2:7012]
[2021-09-22 17:37:02,187] Repair command #4 finished with error

stderr:
error: Got negative replies from endpoints [/127.0.0.2:7012]
-- StackTrace --
java.io.IOException: Got negative replies from endpoints [/127.0.0.2:7012]
	at org.apache.cassandra.tools.RepairRunner.queryForCompletedRepair(RepairRunner.java:167)
	at org.apache.cassandra.tools.RepairRunner.run(RepairRunner.java:72)
	at org.apache.cassandra.tools.NodeProbe.repairAsync(NodeProbe.java:461)
	at org.apache.cassandra.tools.nodetool.Repair.execute(Repair.java:171)
	at org.apache.cassandra.tools.NodeTool$NodeToolCmd.runInternal(NodeTool.java:363)
	at org.apache.cassandra.tools.NodeTool$NodeToolCmd.run(NodeTool.java:348)
	at org.apache.cassandra.tools.NodeTool.execute(NodeTool.java:251)
	at org.apache.cassandra.distributed.impl.Instance$DTestNodeTool.execute(Instance.java:895)
	at org.apache.cassandra.distributed.impl.Instance.lambda$nodetoolResult$39(Instance.java:805)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
{quote}",,bereng,dcapwell,jmckenzie,maedhroz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Apr 11 16:31:26 UTC 2022,,,,,,,All,,,,"0|z0v9k8:",9223372036854775807,,,,bereng,,,,Normal,,3.0.0,,https://github.com/apache/cassandra/commit/bebe20d2a7b4939158169990d7a9a856e086d532,,,,,,,,,repeat jobs,,,,,"17/Nov/21 16:00;brandon.williams;There is also the same failure in org.apache.cassandra.distributed.test.IncrementalRepairCoordinatorTimeoutTest:

https://app.circleci.com/pipelines/github/bereng/cassandra/501/workflows/735504ab-58ad-4a27-9a69-6d3094caa1ad/jobs/4483;;;","17/Nov/21 19:05;dcapwell;I am the test author, will try to take a look today;;;","17/Nov/21 19:47;dcapwell;here is the logging code

{code}
try
        {
            if (!prepareLatch.await(getRpcTimeout(MILLISECONDS), MILLISECONDS))
                failRepair(parentRepairSession, ""Did not get replies from all endpoints."");
        }
        catch (InterruptedException e)
        {
            failRepair(parentRepairSession, ""Interrupted while waiting for prepare repair response."");
        }

        if (!status.get())
        {
            failRepair(parentRepairSession, ""Got negative replies from endpoints "" + failedNodes);
        }
{code}

The test is trying to make sure we see the timeout, but the log is saying we didn't and instead saw failed status

{code}
public void onFailure(InetAddressAndPort from, RequestFailureReason failureReason)
            {
                status.set(false);
{code};;;","17/Nov/21 20:55;dcapwell;not replicated yet, but added logging to show caller... I have a feeling that org.apache.cassandra.net.RequestCallbacks#onExpired(org.apache.cassandra.net.RequestCallbacks.CallbackInfo) is what is doing this

{code}
if (info.invokeOnFailure())
            INTERNAL_RESPONSE.submit(() -> info.callback.onFailure(info.peer, RequestFailureReason.TIMEOUT));
{code}

if we fail with a timeout, then we don't get a timeout but instead get a negative reply?;;;","17/Nov/21 22:16;dcapwell;after 27 attempts I was finally able to replicate!

{code}
INFO  [node1_Repair-Task:1] node1 2021-11-17 21:53:21,355 [repair #c1f82130-47f0-11ec-a719-b9714b384415]Repair command #6 finished with error
ERROR [node1_InternalResponseStage:2] node1 2021-11-17 21:53:22,055 Failing prepare caused by /127.0.0.2:7012 and reason TIMEOUT
java.lang.Throwable: null
        at org.apache.cassandra.service.ActiveRepairService$2.onFailure(ActiveRepairService.java:540)
        at org.apache.cassandra.net.RequestCallbacks.lambda$onExpired$0(RequestCallbacks.java:173)
        at org.apache.cassandra.concurrent.FutureTask$1.call(FutureTask.java:81)
        at org.apache.cassandra.concurrent.FutureTask.call(FutureTask.java:47)
        at org.apache.cassandra.concurrent.FutureTask.run(FutureTask.java:57)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
{code}

so having 2 different definitions of timeout causes this bug!;;;","18/Nov/21 00:36;dcapwell;ran repeat job with HIGHER; green.  Testing with LOWER now;;;","18/Nov/21 02:14;dcapwell;lower was green as well; CI is running normal CI now;;;","18/Nov/21 09:06;bereng;Code lgtm, repeat tests lgtm +1

Btw [~dcapwell] I see you mentioned 27 attempts and I was wondering if you had done those manually. There is {{RepeatbleRunner}} #justfyi

 {code}
@RunWith(RepeatableRunner.class)
@RepeatableRunnerConfiguration(iterations = 50, runner = Parameterized.class)
 {code};;;","18/Nov/21 17:52;dcapwell;I ran manually.  Created a docker container with 2 cpu and ran the test in a loop;;;","18/Nov/21 17:54;dcapwell;[~bereng] how well does the RepeatbleRunner work for jvm-dtests?  We start/stop instances often which tends to lead to the JVM crashing if we do it ""too much"";;;","19/Nov/21 07:02;bereng;I haven't used it extensively on jvm-dtests but I did this time with a few iterations.

On junits I've done 10K and crazy things like that for some very hard repros which would be impossible looping at shell level. And on dtests you have a flag to run a test N times also. Again #justfyi bc I also used to do all sort of things to loop tests chasing repros but now we have some helpers around.;;;","19/Nov/21 20:57;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16992-trunk-C80A9035-99AE-4B70-B59B-0CD99E928624]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16992-trunk-C80A9035-99AE-4B70-B59B-0CD99E928624]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1292/]|
;;;","11/Apr/22 16:31;maedhroz;[~dcapwell] Should we fix this for 4.0 as well? I just saw https://ci-cassandra.apache.org/job/Cassandra-4.0/376/testReport/org.apache.cassandra.distributed.test/IncrementalRepairCoordinatorTimeoutTest/prepareRPCTimeout_DATACENTER_AWARE_false_/;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ArrayIndexOutOfBoundsException in FunctionResource#fromName,CASSANDRA-16977,13402132,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,20/Sep/21 08:12,27/May/22 19:25,13/Jul/23 08:40,24/Sep/21 06:40,3.0.26,3.11.12,4.0.2,4.1,4.1-alpha1,,,Feature/Authorization,,,,0,,,"{{FunctionResource}} can't handle functions with 0 args where it throws:

{noformat}
2021-04-08 10:45:40,984 ErrorMessage.java:387 - Unexpected exception during request
java.lang.ArrayIndexOutOfBoundsException: 1
at org.apache.cassandra.auth.FunctionResource.fromName(FunctionResource.java:178)
{noformat}


",,azotcsit,bereng,e.dimitrova,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16995,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Sep 28 10:26:20 UTC 2021,,,,,,,All,,,,"0|z0v35c:",9223372036854775807,,,,azotcsit,,,,Normal,,3.11.0,,https://github.com/apache/cassandra/commit/1aa7fb172f7f107f7b3a252721c501a20ee6e8aa,,,,,,,,,See PR,,,,,"20/Sep/21 18:31;azotcsit;I checked 3.11 PR and posted a question on the function format without square brackets:
{code:java}
functions/ks1/foo
{code}
I'm not sure whether it needs to be supported. In either case, a corresponding test needs to be added.

 ;;;","21/Sep/21 05:17;bereng;Thx [~azotcsit] for the review!;;;","21/Sep/21 06:39;azotcsit;I checked the latest changes on the PR, they look good to me. Assuming functions without square brackets are supposed to be supported, +1 (non-binding).;;;","21/Sep/21 07:08;azotcsit;[~samt] any concerns on functions without square brackets? Asking you because you are the person who wrote that code originally.;;;","21/Sep/21 07:34;bereng;When dropping a function i.e. you reference it without any square brackets so it was my assumption that is ok but Sam will now better agreed.;;;","21/Sep/21 09:32;samt;{{DropFunctionStatement}} does accept a function without parens, but this is really because it's only constructing a {{FunctionName}}, which does not have parameters. Wherever a {{FunctionResource}} is required, the brackets are used. IMO, {{fromName}} and {{getName}} ought to be symmetrical, otherwise we're at risk of running into problems where something is serialized in one format but read in another. i.e. entries in the permissions tables use {{getName}} and so always include brackets.;;;","23/Sep/21 10:28;azotcsit;The updated code in 3.11 branch LGTM, +1.;;;","23/Sep/21 10:44;bereng;The other PRs are the same. So I will assume good to commit?;;;","23/Sep/21 11:34;azotcsit;The CI issues do not seem to be related to this change. I think we're good to merge. ;;;","24/Sep/21 06:33;bereng;[~edimitrova] I removed you as a reviewer as Aleksei became a committer already and didn't see any comments in the review as you're probably busy? I hope that is correct otherwise feel free to slap me in the hand! lol;;;","24/Sep/21 13:46;e.dimitrova;You didn't wait a few hours for me to respond to your question. Slap :D (joking)

Not a big deal as it is not some fat patch but IMHO  ideally reviewers should remove themselves from the list if they see that they won't be returning to provide such a +1.
{quote}didn't see any comments in the review
{quote}
I was following actually. GH has that option to add comments without submitting them and only when you are ready to submit a review. That's what I normally do, most often with the big patches where I might do more than one pass. :) ;;;","24/Sep/21 14:23;bereng;1 day. I merged 1 day later.;;;","24/Sep/21 14:37;e.dimitrova;Different time zones :D Anyway, no biggie :D ;;;","28/Sep/21 10:26;azotcsit;This change has been additionally backported to 3.0 as a part of CASSANDRA-16995 ticket.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CompactionTask#runMayThrow should not release new SSTables for offline transactions,CASSANDRA-16975,13402008,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,Gerrrr,Gerrrr,Gerrrr,18/Sep/21 16:03,27/May/22 19:24,13/Jul/23 08:40,30/Sep/21 12:19,3.0.26,3.11.12,4.0.2,4.1,4.1-alpha1,,,Local/Compaction,,,,0,,,"Right now, {{CompactionTask#runMayThrow}} releases new SSTables for offline transactions ([code|https://github.com/apache/cassandra/blob/f7c71f65c000c2c3ef7df1b034b8fdd822a396d8/src/java/org/apache/cassandra/db/compaction/CompactionTask.java#L227-L230]). This change was added in CASSANDRA-8962, prior to the introduction of lifecycle transactions in CASSANDRA-8568. I suspect that this behavior might be undesired and could have just fallen through the cracks.

To my knowledge, this code does not cause any known bugs solely because in-tree tools do not access the SSTables they produce before exiting. However, if someone is to write, say, offline compaction daemon, it might break on subsequent compactions because newly created SSTables will be released.",,adelapena,blambov,Gerrrr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,Gerrrr,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Sep 30 12:19:13 UTC 2021,,,,,,,All,,,,"0|z0v2ds:",9223372036854775807,,,,adelapena,blambov,,,Low,,NA,,https://github.com/apache/cassandra/commit/3e6faca572a5ca1de5906b39b8c0a6bf4deb40e9,,,,,,,,,I added a test to {{CompactionTaskTest}} that ensures that SSTables produced by offline CompactionTasks are not released.,,,,,"19/Sep/21 12:28;Gerrrr;||Branch||CI||
|[3.0|https://github.com/apache/cassandra/compare/cassandra-3.0...Gerrrr:16975-3.0?expand=1]|[j8|https://app.circleci.com/pipelines/github/Gerrrr/cassandra/208/workflows/ed8ff9b7-f126-477b-8191-b39efd61345d]|
|[3.11|https://github.com/apache/cassandra/compare/cassandra-3.11...Gerrrr:16975-3.11?expand=1]|[j8|https://app.circleci.com/pipelines/github/Gerrrr/cassandra/207/workflows/12bf105b-60b2-4fec-b98e-ab08ef6d33bc]|
|[4.0|https://github.com/apache/cassandra/compare/trunk...Gerrrr:CASSANDRA-16975?expand=1] |[j8|https://app.circleci.com/pipelines/github/Gerrrr/cassandra/200/workflows/9f0978f7-b363-440d-aa88-1a8a2b4b6316] [j11|https://app.circleci.com/pipelines/github/Gerrrr/cassandra/200/workflows/6fbd5910-0e98-457f-8d1a-0b1f2048052c]|

 ;;;","21/Sep/21 08:18;blambov;Within compaction itself clearly isn't the right place to clear these references, but don't we still want to do this in the tools?;;;","21/Sep/21 08:39;blambov;On second thought, clearing the reference will bring it to 0, which might trigger some obsoletion we really don't want to happen to the outputs. In other words, it's best if the tools exit with a reference to their outputs.

Patch LGTM.;;;","23/Sep/21 10:24;adelapena;Looks good to me. Should we apply this to 3.0/3.11?

Nit: the {{throws Exception}} in the test is not needed.;;;","23/Sep/21 11:24;Gerrrr;I removed {{throws Exception}} from the test and added patches + CI for 3.0 and 3.11 to the table in the previous comment.;;;","27/Sep/21 16:54;adelapena;Great, +1;;;","30/Sep/21 08:10;Gerrrr;[~adelapena] As this patch has two +1s, should I move it to {{READY TO COMMIT}}?;;;","30/Sep/21 09:27;adelapena;Sure, I'll commit it in a bit.;;;","30/Sep/21 09:47;Gerrrr;Thank you!;;;","30/Sep/21 10:13;adelapena;[~Gerrrr] I understand that the patch should also be applied to trunk, is this right? I have prepared a patch for trunk [here|https://github.com/apache/cassandra/compare/trunk...adelapena:16975-trunk-review], with CI runs for [j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/936/workflows/0d59df0e-ac26-4c88-afc5-404bf767c033] and [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/936/workflows/2f4fd070-4fd2-4753-a4e6-2137379f8997]. The runs contain 100 rounds of the new test, just in case.;;;","30/Sep/21 10:22;Gerrrr;Ah, you are right! I am still not used to the fact that 4.0 is not trunk :);;;","30/Sep/21 12:19;adelapena;No worries, too many branches :)

Committed to 3.0 as [3e6faca572a5ca1de5906b39b8c0a6bf4deb40e9|https://github.com/apache/cassandra/commit/3e6faca572a5ca1de5906b39b8c0a6bf4deb40e9] and merged to [3.11|https://github.com/apache/cassandra/commit/dcc95492e9b05e1b8ceb3af332d5c0989c7272b0], [4.0|https://github.com/apache/cassandra/commit/c0916d67be25c700e5de93242afa7244c7fbbb02] and [trunk|https://github.com/apache/cassandra/commit/b6e400d0c3c3f74d17261caaa6388e6c70df322f].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution,CASSANDRA-16973,13401929,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,17/Sep/21 21:47,24/Sep/21 17:16,13/Jul/23 08:40,24/Sep/21 17:10,3.0.26,3.11.12,,,,,,Test/unit,,,,0,,,"org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution fails in [3.11|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1119/testReport/junit/org.apache.cassandra.concurrent/LongSharedExecutorPoolTest/testPromptnessOfExecution/]
h3.  
{code:java}
Stacktrace
junit.framework.AssertionFailedError at org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution(LongSharedExecutorPoolTest.java:169) at org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution(LongSharedExecutorPoolTest.java:102)

Standard Output
Completed 0K batches with 0.0M events Running for 120s with load multiplier 0.5

Standard Error
SLF4J: The following set of substitute loggers may have been accessed SLF4J: during the initialization phase. Logging calls during this SLF4J: phase were not honored. However, subsequent logging calls to these SLF4J: loggers will work as normally expected. SLF4J: See also
http://www.slf4j.org/codes.html#substituteLogger
SLF4J: org.apache.cassandra.LogbackStatusListener
{code}
 ",,e.dimitrova,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Sep 24 17:16:41 UTC 2021,,,,,,,All,,,,"0|z0v1w8:",9223372036854775807,,,,brandon.williams,e.dimitrova,,,Normal,,3.0.25,,https://github.com/apache/cassandra/commit/bd406c7ca9650ab724a938ee6471af788c55a38e,,,,,,,,,"No new tests needed, we just ignore one test. Tested locally",,,,,"18/Sep/21 06:11;mck;See https://issues.apache.org/jira/issues/?jql=text%20~%20LongSharedExecutorPoolTest%20ORDER%20BY%20key%20DESC

The test was ignored in 4.0.
I suggest we remove it from all older branches.;;;","22/Sep/21 21:34;e.dimitrova;Short memory, I don't remember anymore the details :(  

I am +1 to remove it but shall we open a ticket for new jmh test, etc? Post-4.0 revisit as suggested on that ticket?

 Should I remove it from old branches and leave it ignored on 4.0 as a reference for whoever works on the revisit?

 ;;;","22/Sep/21 22:54;brandon.williams;According to the comments from Jacek on CASSANDRA-16497, this may be solvable.;;;","22/Sep/21 23:59;e.dimitrova;I just tried that patch cherry-picked on 4.0 and running it locally it fails again:
{code:java}
Exception in thread ""main"" java.lang.AssertionErrorException in thread ""main"" java.lang.AssertionError at org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution(LongSharedExecutorPoolTest.java:180) at org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.main(LongSharedExecutorPoolTest.java:234){code}
It was long time ago but I guess we saw it doesn't completely fix the test and that's why it wasn't committed.;;;","23/Sep/21 00:04;brandon.williams;Welp, +1 to either removing or ignoring on the other branches, the latter if we ever want to revisit this. Again.;;;","24/Sep/21 15:18;e.dimitrova;I would like to suggest to add the @Ignore and open a follow up ticket for writing a new test and whoever has appetite can look into that? WDYT?;;;","24/Sep/21 15:23;brandon.williams;+1;;;","24/Sep/21 17:08;e.dimitrova;Committed to 3.0 and 3.11, empty commit to 4.0 and trunk where we already ignored the test.

To https://github.com/apache/cassandra.git

   af85e7ad49..bd406c7ca9  cassandra-3.0 -> cassandra-3.0

   6a3440bd61..91077975df  cassandra-3.11 -> cassandra-3.11

   77144aa472..89f35a49a0  cassandra-4.0 -> cassandra-4.0

   9f15ec6de1..01ca6057c0  trunk -> trunk;;;","24/Sep/21 17:16;e.dimitrova;CASSANDRA-16993 opened;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix org.apache.cassandra.cql3.ViewTest.testTruncateWhileBuilding ,CASSANDRA-16972,13401928,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,e.dimitrova,e.dimitrova,17/Sep/21 21:46,24/Sep/21 10:52,13/Jul/23 08:40,24/Sep/21 10:52,3.0.26,3.11.12,,,,,,Test/unit,,,,0,,,"[org.apache.cassandra.cql3.ViewTest.testTruncateWhileBuilding|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1119/testReport/junit/org.apache.cassandra.cql3/ViewTest/testTruncateWhileBuilding/]  fails in 3.11

 
{code:java}
Error Message
expected:<0> but was:<1>

Stacktrace
junit.framework.AssertionFailedError: expected:<0> but was:<1> at org.apache.cassandra.Util.spinAssertEquals(Util.java:575) at org.apache.cassandra.cql3.ViewTest.testTruncateWhileBuilding(ViewTest.java:1656) at org.jboss.byteman.contrib.bmunit.BMUnitRunner$9.evaluate(BMUnitRunner.java:342) at org.jboss.byteman.contrib.bmunit.BMUnitRunner$6.evaluate(BMUnitRunner.java:241) at org.jboss.byteman.contrib.bmunit.BMUnitRunner$1.evaluate(BMUnitRunner.java:75)
{code}
 ",,adelapena,bereng,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16567,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Sep 24 10:50:48 UTC 2021,,,,,,,All,,,,"0|z0v1w0:",9223372036854775807,,,,bereng,,,,Normal,,3.0.25,,https://github.com/apache/cassandra/commit/af85e7ad49beec3c6831e000a44802c0dac1afa5,,,,,,,,,Multiplexed CircleCI runs are included.,,,,,"23/Sep/21 09:35;adelapena;I think that the check for the completion of the MV build completion [here|https://github.com/apache/cassandra/blob/ea3cca04eba8844a685142d7d3093b1aa58bb4eb/test/unit/org/apache/cassandra/cql3/ViewTest.java#L1486] is not reliable in 3.0 and 3.11 because in those branches the views are built on the same executor that is used for compaction and the number of pending compaction tasks is estimated. That's not a problem in 4.0 and trunk because in those branches the MVs are built on their own dedicated executor.

The proposed patch just removes the wait for the running compactions and instead waits for the MV to be marked as built. That seems to survive 5000 runs of the {{ViewTest#testTruncateWhileBuilding}} method and 2000 of for the entire {{ViewTest}} suite:

||branch||Multiplexed method||Multiplexed suite||
|[3.0|https://github.com/adelapena/cassandra/tree/16972-3.0]  |[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/872/workflows/08c3abc8-a7cc-41b7-adbe-4eb4ba5b3cfc/jobs/8379]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/883/workflows/d81e1df6-deb4-491e-883b-f22648246a44/jobs/8423]|
|[3.11|https://github.com/adelapena/cassandra/tree/16972-3.11] |[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/873/workflows/e918e933-af1c-44ee-bdc1-48ed04430f92/jobs/8370]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/881/workflows/105061d6-4f79-4e9e-ae6e-0568303b8096/jobs/8434]|
|[4.0|https://github.com/adelapena/cassandra/tree/16972-4.0]  |[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/875/workflows/58df4965-420e-4dc0-a53d-fdfc4cd6a931/jobs/8372] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/875/workflows/209aaa16-bcc0-48c6-ac41-a887f8853a4d/jobs/8375]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/882/workflows/94fb2e42-06b2-49a3-a68b-147cd531a0ba/jobs/8426] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/882/workflows/b6286f56-9589-4660-96f8-3b24773d00f0/jobs/8417]|
|[trunk|https://github.com/adelapena/cassandra/tree/16972-trunk]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/874/workflows/cb9da1da-95c6-4b32-b49f-4001efe41914/jobs/8376] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/874/workflows/07e5be80-2a8b-45d6-ab1c-81601dcf0110/jobs/8377]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/880/workflows/eba4b419-ecfa-4224-bc83-15936b3e2f8f/jobs/8428] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/880/workflows/8654441a-31d2-4d73-bc2b-b877602f22b1/jobs/8436]|

;;;","23/Sep/21 10:12;bereng;[~adelapena] Am I reading correctly in the multiplexed suite you forgot to remove the method name so it is in fact again a 2K run of the method alone?;;;","23/Sep/21 10:47;adelapena;Oh, you are totally right, I forgot to remove the method. Good catch. Here are the multiplexed suites, this time with 1000 runs instead of 2000 because I suspect it's going to take ages:
||branch||Multiplexed suite||
|[3.0|https://github.com/adelapena/cassandra/tree/16972-3.0]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/895/workflows/d74cce99-ede6-490a-9370-e9238570f204/jobs/8486]|
|[3.11|https://github.com/adelapena/cassandra/tree/16972-3.11]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/894/workflows/222c2994-374e-4bb9-98e2-d37657a170d4/jobs/8490]|
|[4.0|https://github.com/adelapena/cassandra/tree/16972-4.0]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/887/workflows/7c9520d2-8450-4530-bab7-2171d387386c/jobs/8459] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/887/workflows/08e7bf7a-6be4-4846-a1ed-16fcfa3e6346/jobs/8449]|
|[trunk|https://github.com/adelapena/cassandra/tree/16972-trunk]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/886/workflows/bb0998e5-a2d2-4742-82ae-eccb379b83b2/jobs/8460] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/886/workflows/a789cae4-4069-4478-ad80-25047171702f/jobs/8456]|

Edit: I keep forgetting that for 3.0 and 3.11 the Ant objective for entire test suites has to be {{test}} instead of {{testsome}}, even though it implies running other classes named {{ViewTest}} in other packages. I have updated the CI links above.;;;","24/Sep/21 06:22;bereng;+1;;;","24/Sep/21 09:17;adelapena;Thanks for the review!

Just for reference, the single failure in the 1000 full suite runs for 3.11 is caused by {{testRangeTombstone}}:
{code:xml}
<testcase classname=""org.apache.cassandra.cql3.ViewTest"" name=""testRangeTombstone"" time=""3.093"">
  <failure message=""expected:&lt;100&gt; but was:&lt;0&gt;"" type=""junit.framework.AssertionFailedError"">junit.framework.AssertionFailedError: expected:&lt;100&gt; but was:&lt;0&gt;
at org.apache.cassandra.cql3.ViewTest.testRangeTombstone(ViewTest.java:673)
at org.jboss.byteman.contrib.bmunit.BMUnitRunner$6.evaluate(BMUnitRunner.java:241)
at org.jboss.byteman.contrib.bmunit.BMUnitRunner$1.evaluate(BMUnitRunner.java:75)
failure>
</testcase>
{code}
I think that this failure is not related with {{testTruncateWhileBuilding}}, and it's something that we will probably need to investigate separately.;;;","24/Sep/21 09:44;bereng;^Agreed;;;","24/Sep/21 10:50;adelapena;Committed to 3.0 as [af85e7ad49beec3c6831e000a44802c0dac1afa5|https://github.com/apache/cassandra/commit/af85e7ad49beec3c6831e000a44802c0dac1afa5] and merged up to [3.11|https://github.com/apache/cassandra/commit/6a3440bd6174948461a33e274f675bd8d26688a0], [4.0|https://github.com/apache/cassandra/commit/77144aa472df87ac9d79012f097c5b1a868d8803] and [trunk|https://github.com/apache/cassandra/commit/81e5abfc3d4976abc26de420206de7595552ab55]. The merge commits for 3.11 and trunk are empty because these branches are not affected.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix org.apache.cassandra.distributed.test.OptimiseStreamsRepairTest.randomTest,CASSANDRA-16971,13401926,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,e.dimitrova,e.dimitrova,17/Sep/21 21:44,27/May/22 19:25,13/Jul/23 08:40,23/Sep/21 09:44,4.0.2,4.1,4.1-alpha1,,,,,Test/dtest/java,,,,0,,,"org.apache.cassandra.distributed.test.OptimiseStreamsRepairTest.randomTest is [failing|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1120/testReport/junit/org.apache.cassandra.distributed.test/OptimiseStreamsRepairTest/randomTest/] on 4.0  
h3.  
{code:java}
Error Message
nodetool command [repair, distributed_test_keyspace, -vd] was not successful stdout: [2021-09-15 16:45:34,539] Starting repair command #2 (58d1e2a0-1644-11ec-8c42-ef15a225544a), repairing keyspace distributed_test_keyspace with repair options (parallelism: parallel, primary range: false, incremental: true, job threads: 1, ColumnFamilies: [], dataCenters: [], hosts: [], previewKind: REPAIRED, # of ranges: 3, pull repair: false, force repair: false, optimise streams: false, ignore unreplicated keyspaces: false) [2021-09-15 16:45:34,552] Repair command #2 failed with error Repair session 58d2cd00-1644-11ec-8c42-ef15a225544a for range [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]] failed with error An incremental repair with session id 560ecb00-1644-11ec-8c42-ef15a225544a finished during this preview repair runtime [2021-09-15 16:45:34,552] Repair command #2 finished with error
{code}
 

 ",,e.dimitrova,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Sep 23 09:44:44 UTC 2021,,,,,,,All,,,,"0|z0v1vk:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/50e0b40184145ce9d5c72de80dd5e5995206a3fb,,,,,,,,,"https://issues.apache.org/jira/browse/CASSANDRA-16971?focusedCommentId=17418224&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17418224

 

No additional tests needed",,,,,"19/Sep/21 18:22;e.dimitrova;Similar to CASSANDRA-15685, IR and Preview repair can't run concurrently.  ;;;","21/Sep/21 16:54;e.dimitrova;Hey [~marcuse], may I ask you for a quick sanity check, please? I believe you added these tests some time ago. 

While I can't reproduce the mentioned issue neither locally, nor in the CircleCI multiplexer, I am fairly confident that we just need to add similar to CASSANDRA-15685 *Thread.sleep(1000)* after [this assert|https://github.com/apache/cassandra/blob/trunk/test/distributed/org/apache/cassandra/distributed/test/OptimiseStreamsRepairTest.java#L184] which does not guarantee that the job has completed. This should be enough to clear the flakiness and the Jenkins noise.

I think we can also add *Thread.sleep(1000)*  [here|https://github.com/apache/cassandra/blob/trunk/test/distributed/org/apache/cassandra/distributed/test/OptimiseStreamsRepairTest.java#L91] to prevent also _testBasic()_ from being flaky. If you agree, I can take care to commit a quick patch for 4.0 and trunk where the tests exist.

 

 ;;;","22/Sep/21 06:04;marcuse;https://github.com/krummas/cassandra/commits/marcuse/16971 fixes this by checking the logs to make sure the previous repair is fully finished before starting the next one

https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16971;;;","22/Sep/21 20:56;e.dimitrova;Thanks [~marcuse]

+1, I also pushed it to trunk and tested [here|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1125/workflows/fa67f6e4-7da0-46ca-9e48-ae5cb4ce262d], just to be sure there are no weird surprises later :) ;;;","23/Sep/21 09:44;marcuse;committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Scrub does not detect invalid partition keys,CASSANDRA-16969,13401921,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,17/Sep/21 20:35,27/May/22 19:24,13/Jul/23 08:40,27/Sep/21 14:14,3.11.12,4.0.2,4.1,4.1-alpha1,,,,Tool/sstable,,,,0,,,"The standalone scrubber [gets the key|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/compaction/Scrubber.java#L202] from the file but never validates it, and this will propagate to the new sstable so it will be corrupted when read later.",,bereng,blerer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16991,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Sep 27 14:14:02 UTC 2021,,,,,,,All,,,,"0|z0v1ug:",9223372036854775807,,,,bereng,blerer,,,Normal,,NA,,https://github.com/apache/cassandra/commit/ec1195bed76b17a150371810c78413e6cb9c7049,,,,,,,,,Run CI,,,,,"17/Sep/21 21:59;brandon.williams;For now, [here|https://github.com/driftx/cassandra/tree/CASSANDRA-16969] is a branch against 3.11.
;;;","20/Sep/21 17:30;brandon.williams;||Branch||CI||
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16969]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16969], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1126/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1126/pipeline]|
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16969-4.0]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16969-4.0], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1127/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1127/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16969-trunk]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16969-trunk], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1128/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1128/pipeline]|;;;","22/Sep/21 08:13;blerer;+1;;;","22/Sep/21 16:29;brandon.williams;Committed, thank you!;;;","23/Sep/21 07:37;blerer;I have seen following failure of {{test_scrub_collections_table - scrub_test.TestScrubIndexes}} from {{scrub_test.py}} and wonder if it is not related to this patch.

{code}
test teardown failure
Unexpected error found in node logs (see stdout for full details). Errors: [ERROR [CompactionExecutor:1] 2021-09-22 17:50:31,020 CassandraDaemon.java:581 - Exception in thread Thread[CompactionExecutor:1,1,main]
java.io.IOError: java.lang.IllegalArgumentException
	at org.apache.cassandra.db.compaction.Scrubber.throwIfCannotContinue(Scrubber.java:449)
	at org.apache.cassandra.db.compaction.Scrubber.scrub(Scrubber.java:272)
	at org.apache.cassandra.db.compaction.CompactionManager.scrubOne(CompactionManager.java:1159)
	at org.apache.cassandra.db.compaction.CompactionManager$3.execute(CompactionManager.java:459)
	at org.apache.cassandra.db.compaction.CompactionManager$2.call(CompactionManager.java:379)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: null
	at java.nio.Buffer.limit(Buffer.java:275)
	at org.apache.cassandra.db.marshal.ByteBufferAccessor.slice(ByteBufferAccessor.java:107)
	at org.apache.cassandra.db.marshal.ByteBufferAccessor.slice(ByteBufferAccessor.java:39)
	at org.apache.cassandra.serializers.CollectionSerializer.readValue(CollectionSerializer.java:127)
	at org.apache.cassandra.serializers.ListSerializer.validateForNativeProtocol(ListSerializer.java:76)
	at org.apache.cassandra.serializers.CollectionSerializer.validate(CollectionSerializer.java:66)
	at org.apache.cassandra.db.marshal.AbstractType.validate(AbstractType.java:193)
	at org.apache.cassandra.db.marshal.AbstractType.validate(AbstractType.java:188)
	at org.apache.cassandra.db.compaction.Scrubber.scrub(Scrubber.java:263)
	... 8 common frames omitted, WARN  [RMI TCP Connection(8)-127.0.0.1] 2021-09-22 17:50:31,037 ColumnFamilyStore.java:1560 - Rebuilding index for users.user_uuids_idx because of 
{code};;;","23/Sep/21 11:49;brandon.williams;Yes, this broke that :(

I've pushed updates to my branches that skip key validation for indexes; I'm not sure how to validate those, and it seems a little disingenuous of the api to give me the parent's validator without any indication.  We can go with this for now and tackle indexes later and still be better off than before.;;;","24/Sep/21 07:01;bereng;Are there any jenkins CI links to see if this helps clear CI failures?;;;","24/Sep/21 12:42;brandon.williams;The circle links [above|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16969] updated.;;;","27/Sep/21 06:10;bereng;I fired a [jenkins|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1147/] one to be on the safe side as I've seen sometimes differences across the diff CIs and I have a suspicion it might be the case.;;;","27/Sep/21 12:54;bereng;Jenkins lgtm so +1 from me.;;;","27/Sep/21 14:14;brandon.williams;Committed the index fix in 02840c9006d;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Avoid rewriting all sstables during nodetool cleanup,CASSANDRA-16966,13401898,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,17/Sep/21 15:49,27/May/22 19:25,13/Jul/23 08:40,30/Sep/21 09:28,4.0.2,4.1,4.1-alpha1,,,,,Local/SSTable,,,,0,,,{{nodetool cleanup}} does not skip repaired sstables if transient replication is disabled,,ifesdjeen,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Degradation -> Slow Use Case,,,,,,,,Low Hanging Fruit,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Sep 30 09:28:27 UTC 2021,,,,,,,All,,,,"0|z0v1pc:",9223372036854775807,,,,ifesdjeen,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/41b43a46c13680168b45181e904a170717cd2514,,,,,,,,,updated jvm dtest + cci run,,,,,"17/Sep/21 15:51;marcuse;https://github.com/krummas/cassandra/commits/marcuse/16966
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16966;;;","27/Sep/21 12:31;ifesdjeen;Thank you for the patch! +1, LGTM.;;;","30/Sep/21 09:28;marcuse;and committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Avoid returning null in RangesAtEndpoint,CASSANDRA-16965,13401896,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,17/Sep/21 15:44,17/Feb/22 08:17,13/Jul/23 08:40,30/Sep/21 09:30,4.0.2,,,,,,,Local/Other,,,,0,,,A race in RangesAtEndpoint can cause us to return null,,jonmeredith,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Degradation -> Other Exception,,,,,,,,Low Hanging Fruit,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Sep 30 09:30:11 UTC 2021,,,,,,,All,,,,"0|z0v1ow:",9223372036854775807,,,,jmeredithco,,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/aaf72a7decf6964f00adb871333571de66c166a3,,,,,,,,,cci run,,,,,"17/Sep/21 15:47;marcuse;https://github.com/krummas/cassandra/commits/marcuse/16965
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16965;;;","27/Sep/21 16:08;jonmeredith;+1 great find on that nasty little race;;;","30/Sep/21 09:30;marcuse;and committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky test: repair_tests/repair_test.py::TestRepair::test_local_dc_repair,CASSANDRA-16963,13401695,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,ifesdjeen,ifesdjeen,ifesdjeen,16/Sep/21 16:03,11/Jan/22 18:41,13/Jul/23 08:40,11/Jan/22 18:41,,,,,,,,Test/dtest/python,,,,0,,,"Sometimes we get “ID mismatch while trying to reprepare” after node restart on write workload in dtests, which we can avoid by using fully qualified cf names.",,ifesdjeen,maedhroz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,ifesdjeen,,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Jan 11 18:41:53 UTC 2022,,,,,,,All,,,,"0|z0v0g8:",9223372036854775807,,,,maedhroz,,,,,,,,,,,,,,,,,,,,,,"16/Sep/21 17:25;maedhroz;Made one comment in the PR and ran the tests locally. Seeing {{test_simple_sequential_repair}}, {{test_simple_parallel_repair}}, and a few others fail with an error that looks something like this:

{noformat}
test_simple_sequential_repair failed and was not selected for rerun.
	<class 'KeyError'>
	'fully_qualified_cf'
	[<TracebackEntry /Users/maedhroz/Projects/Apache/cassandra-dtest/repair_tests/repair_test.py:363>, <TracebackEntry /Users/maedhroz/Projects/Apache/cassandra-dtest/repair_tests/repair_test.py:453>, <TracebackEntry /Users/maedhroz/Projects/Apache/cassandra-dtest/repair_tests/repair_test.py:112>, <TracebackEntry /Users/maedhroz/Projects/Apache/cassandra-dtest/tools/data.py:30>]
{noformat};;;","16/Sep/21 21:00;ifesdjeen;[~maedhroz] sorry about that, I've done it the right way first, but then somehow thought that Python string interpolation works slightly differently. Maybe it was another language that allowed string interpolation right from variable names. I've fixed it now.;;;","17/Sep/21 15:32;maedhroz;+1

(I do have a local trunk run of {{repair_tests/repair_test.py}} in flight, but I assume it'll be fine now. I'll post if it isn't.);;;","11/Jan/22 18:41;ifesdjeen;Committed to [trunk|https://github.com/apache/cassandra-dtest/commit/27c6d022c2d7c197be03c7d6ebe22861ca66a04d];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix dtest-novnode.materialized_views_test.TestMaterializedViews.test_drop_with_stopped_build,CASSANDRA-16962,13401693,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,e.dimitrova,e.dimitrova,16/Sep/21 16:02,24/Feb/22 10:48,13/Jul/23 08:40,23/Feb/22 08:25,4.0.4,,,,,,,Test/dtest/python,,,,0,,,"Failed in Jenkins 4.0:

[https://jenkins-cm4.apache.org/job/Cassandra-4.0/213/testReport/junit/dtest-novnode.materialized_views_test/TestMaterializedViews/test_drop_with_stopped_build/]

 

 
{code:java}
dtest-novnode.materialized_views_test.TestMaterializedViews.test_drop_with_stopped_build (from Cassandra dtests)

Failing for the past 1 build (Since #213 ) Took 1 min 33 sec.    Failed 1 times in the last 30 runs. Flakiness: 3%, Stability: 96% Error Message
AssertionError: Expected [[5000]] from SELECT COUNT(*) FROM t_by_v, but got [[4991]]

{code}
 ",,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17216,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Feb 18 12:48:00 UTC 2022,,,,,,,All,,,,"0|z0v0fs:",9223372036854775807,,,,bereng,brandon.williams,,,Normal,,4.0.3,,https://github.com/apache/cassandra-dtest/commit/8396b643b5303d4d849030bb81bb986068e1bd92,,,,,,,,,See PR,,,,,"18/Feb/22 12:48;brandon.williams;+1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve MV TTL error message,CASSANDRA-16960,13401532,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,16/Sep/21 06:28,27/May/22 19:25,13/Jul/23 08:40,20/Sep/21 07:52,3.11.12,4.0.2,4.1,4.1-alpha1,,,,Feature/Materialized Views,,,,0,,,"Old MVs could have been created with a {{default_time_to_live}} before the time of CASSANDRA-12868.

A few years forward customers altering that MV for other reasons might get a very confusing message which can benefit from some clarification.

{code}
ALTER MATERIALIZED VIEW XXXXX_view WITH gc_grace_seconds = 10800;

Cannot set or alter default_time_to_live for a materialized view. Data in a materialized view always expire at the same time than the corresponding data in the parent table.
{code}
",,azotcsit,bereng,blerer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Sep 17 11:41:11 UTC 2021,,,,,,,All,,,,"0|z0uzg0:",9223372036854775807,,,,azotcsit,blerer,brandon.williams,,Normal,,3.11.0,,https://github.com/apache/cassandra/commit/8f4ae7d825d90a18327c5555386f3cdaf414d836,,,,,,,,,See PR,,,,,"16/Sep/21 11:53;brandon.williams;+1;;;","17/Sep/21 06:50;bereng;[~brandon.williams] the other PRs are up with CI that lgtm with some unrelated failures. All ok for me to commit?;;;","17/Sep/21 08:30;blerer;Do we have a test for that validation ? If we have one it is clearly not checking the content of the error message. If we do not have one we shoud add one.;;;","17/Sep/21 09:03;bereng;No being just an error message improvement I didn't add one but I can.;;;","17/Sep/21 10:05;bereng;Wow so I was seeing little value in testing the wording of the error message itself. But upon adding the test I found a bug in the already existing test where it was failing but for the wrong reason. Nice suggestion! Test added to PRs;;;","17/Sep/21 11:28;brandon.williams;bq. I found a bug in the already existing test where it was failing but for the wrong reason

Nice! Some kind of weird serendipity.  +1 on all the PRs.;;;","17/Sep/21 11:41;azotcsit;+1 (non-binding);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nodetool setstreamthroughput accepts invalid arguments that are not immediately applied,CASSANDRA-16959,13401411,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,adelapena,adelapena,15/Sep/21 14:27,27/May/22 19:25,13/Jul/23 08:40,01/Oct/21 11:03,3.0.26,3.11.12,4.0.2,4.1,4.1-alpha1,,,Tool/nodetool,,,,0,,,"Both {{nodetool setstreamthroughput}} and {{nodetool setinterdcstreamthroughput}} accept a negative throughput. The throughput value is not immediately applied to the corresponding rate limiters. Instead, the value is [set in the {{Config}}|https://github.com/apache/cassandra/blob/09c89e5f5f8604301c233130dfb6e82a36ae30f3/src/java/org/apache/cassandra/service/StorageService.java#L1488] and it's only applied to the singleton rate limiter when new sstable stream writer are created (see [here|https://github.com/apache/cassandra/blob/09c89e5f5f8604301c233130dfb6e82a36ae30f3/src/java/org/apache/cassandra/streaming/StreamManager.java#L66-L76]). This could happen much later than the definition of the new throughput, and by then the setting of the new rate in the rate limiter will fail with an {{IllegalArgumentException}} due to the negative value.

I think we should either immediately reject negative throughputs or consider them unlimited, as we do with zero. Also we should probably apply the new throughput to the rate limiter immediately, since I don't see why we should wait to start using the new throughput.",,adelapena,azotcsit,bereng,,,,,,,,,,,,,"bereng commented on a change in pull request #1202:
URL: https://github.com/apache/cassandra/pull/1202#discussion_r714485672



##########
File path: src/java/org/apache/cassandra/streaming/StreamManager.java
##########
@@ -62,41 +63,62 @@ public static StreamRateLimiter getRateLimiter(InetAddressAndPort peer)
 
     public static class StreamRateLimiter
     {
-        private static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
-        private static final RateLimiter limiter = RateLimiter.create(Double.MAX_VALUE);
-        private static final RateLimiter interDCLimiter = RateLimiter.create(Double.MAX_VALUE);
+        public static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
+        private static final RateLimiter limiter = RateLimiter.create(calculateRateInBytes());
+        private static final RateLimiter interDCLimiter = RateLimiter.create(calculateInterDCRateInBytes());
         private final boolean isLocalDC;
 
         public StreamRateLimiter(InetAddressAndPort peer)
         {
-            double throughput = DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(throughput, limiter);
-
-            double interDCThroughput = DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(interDCThroughput, interDCLimiter);
-
             if (DatabaseDescriptor.getLocalDataCenter() != null && DatabaseDescriptor.getEndpointSnitch() != null)
                 isLocalDC = DatabaseDescriptor.getLocalDataCenter().equals(
                             DatabaseDescriptor.getEndpointSnitch().getDatacenter(peer));
             else
                 isLocalDC = true;
         }
 
-        private void mayUpdateThroughput(double limit, RateLimiter rateLimiter)
-        {
-            // if throughput is set to 0, throttling is disabled
-            if (limit == 0)
-                limit = Double.MAX_VALUE;
-            if (rateLimiter.getRate() != limit)
-                rateLimiter.setRate(limit);
-        }
-
         public void acquire(int toTransfer)
         {
             limiter.acquire(toTransfer);
             if (!isLocalDC)
                 interDCLimiter.acquire(toTransfer);
         }
+
+        public static synchronized void updateThroughput()
+        {
+            limiter.setRate(calculateRateInBytes());
+        }
+
+        public static synchronized void updateInterDCThroughput()
+        {
+            interDCLimiter.setRate(calculateInterDCRateInBytes());
+        }
+
+        private static double calculateRateInBytes()
+        {
+            return DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0
+                   ? DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT
+                   : Double.MAX_VALUE; // if throughput is set to 0, throttling is disabled
+        }
+
+        private static double calculateInterDCRateInBytes()
+        {
+            return DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0

Review comment:
       `* BYTES_PER_MEGABIT` will never be zero so I guess you could simplify the conditional for readability and sparing an operation?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Sep/21 05:44;githubbot;600","bereng commented on a change in pull request #1202:
URL: https://github.com/apache/cassandra/pull/1202#discussion_r714485672



##########
File path: src/java/org/apache/cassandra/streaming/StreamManager.java
##########
@@ -62,41 +63,62 @@ public static StreamRateLimiter getRateLimiter(InetAddressAndPort peer)
 
     public static class StreamRateLimiter
     {
-        private static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
-        private static final RateLimiter limiter = RateLimiter.create(Double.MAX_VALUE);
-        private static final RateLimiter interDCLimiter = RateLimiter.create(Double.MAX_VALUE);
+        public static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
+        private static final RateLimiter limiter = RateLimiter.create(calculateRateInBytes());
+        private static final RateLimiter interDCLimiter = RateLimiter.create(calculateInterDCRateInBytes());
         private final boolean isLocalDC;
 
         public StreamRateLimiter(InetAddressAndPort peer)
         {
-            double throughput = DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(throughput, limiter);
-
-            double interDCThroughput = DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(interDCThroughput, interDCLimiter);
-
             if (DatabaseDescriptor.getLocalDataCenter() != null && DatabaseDescriptor.getEndpointSnitch() != null)
                 isLocalDC = DatabaseDescriptor.getLocalDataCenter().equals(
                             DatabaseDescriptor.getEndpointSnitch().getDatacenter(peer));
             else
                 isLocalDC = true;
         }
 
-        private void mayUpdateThroughput(double limit, RateLimiter rateLimiter)
-        {
-            // if throughput is set to 0, throttling is disabled
-            if (limit == 0)
-                limit = Double.MAX_VALUE;
-            if (rateLimiter.getRate() != limit)
-                rateLimiter.setRate(limit);
-        }
-
         public void acquire(int toTransfer)
         {
             limiter.acquire(toTransfer);
             if (!isLocalDC)
                 interDCLimiter.acquire(toTransfer);
         }
+
+        public static synchronized void updateThroughput()
+        {
+            limiter.setRate(calculateRateInBytes());
+        }
+
+        public static synchronized void updateInterDCThroughput()
+        {
+            interDCLimiter.setRate(calculateInterDCRateInBytes());
+        }
+
+        private static double calculateRateInBytes()
+        {
+            return DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0
+                   ? DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT
+                   : Double.MAX_VALUE; // if throughput is set to 0, throttling is disabled
+        }
+
+        private static double calculateInterDCRateInBytes()
+        {
+            return DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0

Review comment:
       `* BYTES_PER_MEGABIT` will never be zero so I guess you could simplify the conditional for readability and sparing an operation?
   
   `return DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0 ?`
   ->
   `return DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() > 0 ?`




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Sep/21 05:46;githubbot;600","bereng commented on a change in pull request #1202:
URL: https://github.com/apache/cassandra/pull/1202#discussion_r714485672



##########
File path: src/java/org/apache/cassandra/streaming/StreamManager.java
##########
@@ -62,41 +63,62 @@ public static StreamRateLimiter getRateLimiter(InetAddressAndPort peer)
 
     public static class StreamRateLimiter
     {
-        private static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
-        private static final RateLimiter limiter = RateLimiter.create(Double.MAX_VALUE);
-        private static final RateLimiter interDCLimiter = RateLimiter.create(Double.MAX_VALUE);
+        public static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
+        private static final RateLimiter limiter = RateLimiter.create(calculateRateInBytes());
+        private static final RateLimiter interDCLimiter = RateLimiter.create(calculateInterDCRateInBytes());
         private final boolean isLocalDC;
 
         public StreamRateLimiter(InetAddressAndPort peer)
         {
-            double throughput = DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(throughput, limiter);
-
-            double interDCThroughput = DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(interDCThroughput, interDCLimiter);
-
             if (DatabaseDescriptor.getLocalDataCenter() != null && DatabaseDescriptor.getEndpointSnitch() != null)
                 isLocalDC = DatabaseDescriptor.getLocalDataCenter().equals(
                             DatabaseDescriptor.getEndpointSnitch().getDatacenter(peer));
             else
                 isLocalDC = true;
         }
 
-        private void mayUpdateThroughput(double limit, RateLimiter rateLimiter)
-        {
-            // if throughput is set to 0, throttling is disabled
-            if (limit == 0)
-                limit = Double.MAX_VALUE;
-            if (rateLimiter.getRate() != limit)
-                rateLimiter.setRate(limit);
-        }
-
         public void acquire(int toTransfer)
         {
             limiter.acquire(toTransfer);
             if (!isLocalDC)
                 interDCLimiter.acquire(toTransfer);
         }
+
+        public static synchronized void updateThroughput()
+        {
+            limiter.setRate(calculateRateInBytes());
+        }
+
+        public static synchronized void updateInterDCThroughput()
+        {
+            interDCLimiter.setRate(calculateInterDCRateInBytes());
+        }
+
+        private static double calculateRateInBytes()
+        {
+            return DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0
+                   ? DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT
+                   : Double.MAX_VALUE; // if throughput is set to 0, throttling is disabled
+        }
+
+        private static double calculateInterDCRateInBytes()
+        {
+            return DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0

Review comment:
       `* BYTES_PER_MEGABIT` will never be zero or negative so I guess you could simplify the conditional for readability and sparing an operation?
   
   `return DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0 ?`
   ->
   `return DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() > 0 ?`




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Sep/21 05:49;githubbot;600","azotcsit commented on a change in pull request #1202:
URL: https://github.com/apache/cassandra/pull/1202#discussion_r714591264



##########
File path: src/java/org/apache/cassandra/streaming/StreamManager.java
##########
@@ -62,41 +63,62 @@ public static StreamRateLimiter getRateLimiter(InetAddressAndPort peer)
 
     public static class StreamRateLimiter
     {
-        private static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
-        private static final RateLimiter limiter = RateLimiter.create(Double.MAX_VALUE);
-        private static final RateLimiter interDCLimiter = RateLimiter.create(Double.MAX_VALUE);
+        public static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
+        private static final RateLimiter limiter = RateLimiter.create(calculateRateInBytes());
+        private static final RateLimiter interDCLimiter = RateLimiter.create(calculateInterDCRateInBytes());
         private final boolean isLocalDC;
 
         public StreamRateLimiter(InetAddressAndPort peer)
         {
-            double throughput = DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(throughput, limiter);
-
-            double interDCThroughput = DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(interDCThroughput, interDCLimiter);
-
             if (DatabaseDescriptor.getLocalDataCenter() != null && DatabaseDescriptor.getEndpointSnitch() != null)
                 isLocalDC = DatabaseDescriptor.getLocalDataCenter().equals(
                             DatabaseDescriptor.getEndpointSnitch().getDatacenter(peer));
             else
                 isLocalDC = true;
         }
 
-        private void mayUpdateThroughput(double limit, RateLimiter rateLimiter)
-        {
-            // if throughput is set to 0, throttling is disabled
-            if (limit == 0)
-                limit = Double.MAX_VALUE;
-            if (rateLimiter.getRate() != limit)
-                rateLimiter.setRate(limit);
-        }
-
         public void acquire(int toTransfer)
         {
             limiter.acquire(toTransfer);
             if (!isLocalDC)
                 interDCLimiter.acquire(toTransfer);
         }
+
+        public static synchronized void updateThroughput()
+        {
+            limiter.setRate(calculateRateInBytes());

Review comment:
       `setRate` seems to be thread-safe (see https://github.com/google/guava/blob/v27.0/guava/src/com/google/common/util/concurrent/RateLimiter.java#L227), so I'm not sure we need `synchronized` here. WDYT?

##########
File path: src/java/org/apache/cassandra/streaming/StreamManager.java
##########
@@ -62,41 +63,62 @@ public static StreamRateLimiter getRateLimiter(InetAddressAndPort peer)
 
     public static class StreamRateLimiter
     {
-        private static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
-        private static final RateLimiter limiter = RateLimiter.create(Double.MAX_VALUE);
-        private static final RateLimiter interDCLimiter = RateLimiter.create(Double.MAX_VALUE);
+        public static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
+        private static final RateLimiter limiter = RateLimiter.create(calculateRateInBytes());
+        private static final RateLimiter interDCLimiter = RateLimiter.create(calculateInterDCRateInBytes());
         private final boolean isLocalDC;
 
         public StreamRateLimiter(InetAddressAndPort peer)
         {
-            double throughput = DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(throughput, limiter);
-
-            double interDCThroughput = DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(interDCThroughput, interDCLimiter);
-
             if (DatabaseDescriptor.getLocalDataCenter() != null && DatabaseDescriptor.getEndpointSnitch() != null)
                 isLocalDC = DatabaseDescriptor.getLocalDataCenter().equals(
                             DatabaseDescriptor.getEndpointSnitch().getDatacenter(peer));
             else
                 isLocalDC = true;
         }
 
-        private void mayUpdateThroughput(double limit, RateLimiter rateLimiter)
-        {
-            // if throughput is set to 0, throttling is disabled
-            if (limit == 0)
-                limit = Double.MAX_VALUE;
-            if (rateLimiter.getRate() != limit)
-                rateLimiter.setRate(limit);
-        }
-
         public void acquire(int toTransfer)
         {
             limiter.acquire(toTransfer);
             if (!isLocalDC)
                 interDCLimiter.acquire(toTransfer);
         }
+
+        public static synchronized void updateThroughput()
+        {
+            limiter.setRate(calculateRateInBytes());
+        }
+
+        public static synchronized void updateInterDCThroughput()
+        {
+            interDCLimiter.setRate(calculateInterDCRateInBytes());
+        }
+
+        private static double calculateRateInBytes()
+        {
+            return DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0
+                   ? DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT
+                   : Double.MAX_VALUE; // if throughput is set to 0, throttling is disabled

Review comment:
       nit: ""if throughput is set to 0"" -> ""if throughput is set to 0 or negative value""




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Sep/21 09:04;githubbot;600","adelapena commented on a change in pull request #1202:
URL: https://github.com/apache/cassandra/pull/1202#discussion_r718575379



##########
File path: src/java/org/apache/cassandra/streaming/StreamManager.java
##########
@@ -62,41 +63,62 @@ public static StreamRateLimiter getRateLimiter(InetAddressAndPort peer)
 
     public static class StreamRateLimiter
     {
-        private static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
-        private static final RateLimiter limiter = RateLimiter.create(Double.MAX_VALUE);
-        private static final RateLimiter interDCLimiter = RateLimiter.create(Double.MAX_VALUE);
+        public static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
+        private static final RateLimiter limiter = RateLimiter.create(calculateRateInBytes());
+        private static final RateLimiter interDCLimiter = RateLimiter.create(calculateInterDCRateInBytes());
         private final boolean isLocalDC;
 
         public StreamRateLimiter(InetAddressAndPort peer)
         {
-            double throughput = DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(throughput, limiter);
-
-            double interDCThroughput = DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(interDCThroughput, interDCLimiter);
-
             if (DatabaseDescriptor.getLocalDataCenter() != null && DatabaseDescriptor.getEndpointSnitch() != null)
                 isLocalDC = DatabaseDescriptor.getLocalDataCenter().equals(
                             DatabaseDescriptor.getEndpointSnitch().getDatacenter(peer));
             else
                 isLocalDC = true;
         }
 
-        private void mayUpdateThroughput(double limit, RateLimiter rateLimiter)
-        {
-            // if throughput is set to 0, throttling is disabled
-            if (limit == 0)
-                limit = Double.MAX_VALUE;
-            if (rateLimiter.getRate() != limit)
-                rateLimiter.setRate(limit);
-        }
-
         public void acquire(int toTransfer)
         {
             limiter.acquire(toTransfer);
             if (!isLocalDC)
                 interDCLimiter.acquire(toTransfer);
         }
+
+        public static synchronized void updateThroughput()
+        {
+            limiter.setRate(calculateRateInBytes());
+        }
+
+        public static synchronized void updateInterDCThroughput()
+        {
+            interDCLimiter.setRate(calculateInterDCRateInBytes());
+        }
+
+        private static double calculateRateInBytes()
+        {
+            return DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0
+                   ? DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT
+                   : Double.MAX_VALUE; // if throughput is set to 0, throttling is disabled
+        }
+
+        private static double calculateInterDCRateInBytes()
+        {
+            return DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0

Review comment:
       Good idea, done.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Sep/21 14:27;githubbot;600","adelapena commented on a change in pull request #1202:
URL: https://github.com/apache/cassandra/pull/1202#discussion_r718590487



##########
File path: src/java/org/apache/cassandra/streaming/StreamManager.java
##########
@@ -62,41 +63,62 @@ public static StreamRateLimiter getRateLimiter(InetAddressAndPort peer)
 
     public static class StreamRateLimiter
     {
-        private static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
-        private static final RateLimiter limiter = RateLimiter.create(Double.MAX_VALUE);
-        private static final RateLimiter interDCLimiter = RateLimiter.create(Double.MAX_VALUE);
+        public static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
+        private static final RateLimiter limiter = RateLimiter.create(calculateRateInBytes());
+        private static final RateLimiter interDCLimiter = RateLimiter.create(calculateInterDCRateInBytes());
         private final boolean isLocalDC;
 
         public StreamRateLimiter(InetAddressAndPort peer)
         {
-            double throughput = DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(throughput, limiter);
-
-            double interDCThroughput = DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(interDCThroughput, interDCLimiter);
-
             if (DatabaseDescriptor.getLocalDataCenter() != null && DatabaseDescriptor.getEndpointSnitch() != null)
                 isLocalDC = DatabaseDescriptor.getLocalDataCenter().equals(
                             DatabaseDescriptor.getEndpointSnitch().getDatacenter(peer));
             else
                 isLocalDC = true;
         }
 
-        private void mayUpdateThroughput(double limit, RateLimiter rateLimiter)
-        {
-            // if throughput is set to 0, throttling is disabled
-            if (limit == 0)
-                limit = Double.MAX_VALUE;
-            if (rateLimiter.getRate() != limit)
-                rateLimiter.setRate(limit);
-        }
-
         public void acquire(int toTransfer)
         {
             limiter.acquire(toTransfer);
             if (!isLocalDC)
                 interDCLimiter.acquire(toTransfer);
         }
+
+        public static synchronized void updateThroughput()
+        {
+            limiter.setRate(calculateRateInBytes());

Review comment:
       Right, we don't need synchronized here




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Sep/21 14:41;githubbot;600","adelapena commented on a change in pull request #1202:
URL: https://github.com/apache/cassandra/pull/1202#discussion_r718575379



##########
File path: src/java/org/apache/cassandra/streaming/StreamManager.java
##########
@@ -62,41 +63,62 @@ public static StreamRateLimiter getRateLimiter(InetAddressAndPort peer)
 
     public static class StreamRateLimiter
     {
-        private static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
-        private static final RateLimiter limiter = RateLimiter.create(Double.MAX_VALUE);
-        private static final RateLimiter interDCLimiter = RateLimiter.create(Double.MAX_VALUE);
+        public static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
+        private static final RateLimiter limiter = RateLimiter.create(calculateRateInBytes());
+        private static final RateLimiter interDCLimiter = RateLimiter.create(calculateInterDCRateInBytes());
         private final boolean isLocalDC;
 
         public StreamRateLimiter(InetAddressAndPort peer)
         {
-            double throughput = DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(throughput, limiter);
-
-            double interDCThroughput = DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(interDCThroughput, interDCLimiter);
-
             if (DatabaseDescriptor.getLocalDataCenter() != null && DatabaseDescriptor.getEndpointSnitch() != null)
                 isLocalDC = DatabaseDescriptor.getLocalDataCenter().equals(
                             DatabaseDescriptor.getEndpointSnitch().getDatacenter(peer));
             else
                 isLocalDC = true;
         }
 
-        private void mayUpdateThroughput(double limit, RateLimiter rateLimiter)
-        {
-            // if throughput is set to 0, throttling is disabled
-            if (limit == 0)
-                limit = Double.MAX_VALUE;
-            if (rateLimiter.getRate() != limit)
-                rateLimiter.setRate(limit);
-        }
-
         public void acquire(int toTransfer)
         {
             limiter.acquire(toTransfer);
             if (!isLocalDC)
                 interDCLimiter.acquire(toTransfer);
         }
+
+        public static synchronized void updateThroughput()
+        {
+            limiter.setRate(calculateRateInBytes());
+        }
+
+        public static synchronized void updateInterDCThroughput()
+        {
+            interDCLimiter.setRate(calculateInterDCRateInBytes());
+        }
+
+        private static double calculateRateInBytes()
+        {
+            return DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0
+                   ? DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT
+                   : Double.MAX_VALUE; // if throughput is set to 0, throttling is disabled
+        }
+
+        private static double calculateInterDCRateInBytes()
+        {
+            return DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT > 0

Review comment:
       Good idea, done.

##########
File path: src/java/org/apache/cassandra/streaming/StreamManager.java
##########
@@ -62,41 +63,62 @@ public static StreamRateLimiter getRateLimiter(InetAddressAndPort peer)
 
     public static class StreamRateLimiter
     {
-        private static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
-        private static final RateLimiter limiter = RateLimiter.create(Double.MAX_VALUE);
-        private static final RateLimiter interDCLimiter = RateLimiter.create(Double.MAX_VALUE);
+        public static final double BYTES_PER_MEGABIT = (1024 * 1024) / 8; // from bits
+        private static final RateLimiter limiter = RateLimiter.create(calculateRateInBytes());
+        private static final RateLimiter interDCLimiter = RateLimiter.create(calculateInterDCRateInBytes());
         private final boolean isLocalDC;
 
         public StreamRateLimiter(InetAddressAndPort peer)
         {
-            double throughput = DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(throughput, limiter);
-
-            double interDCThroughput = DatabaseDescriptor.getInterDCStreamThroughputOutboundMegabitsPerSec() * BYTES_PER_MEGABIT;
-            mayUpdateThroughput(interDCThroughput, interDCLimiter);
-
             if (DatabaseDescriptor.getLocalDataCenter() != null && DatabaseDescriptor.getEndpointSnitch() != null)
                 isLocalDC = DatabaseDescriptor.getLocalDataCenter().equals(
                             DatabaseDescriptor.getEndpointSnitch().getDatacenter(peer));
             else
                 isLocalDC = true;
         }
 
-        private void mayUpdateThroughput(double limit, RateLimiter rateLimiter)
-        {
-            // if throughput is set to 0, throttling is disabled
-            if (limit == 0)
-                limit = Double.MAX_VALUE;
-            if (rateLimiter.getRate() != limit)
-                rateLimiter.setRate(limit);
-        }
-
         public void acquire(int toTransfer)
         {
             limiter.acquire(toTransfer);
             if (!isLocalDC)
                 interDCLimiter.acquire(toTransfer);
         }
+
+        public static synchronized void updateThroughput()
+        {
+            limiter.setRate(calculateRateInBytes());

Review comment:
       Right, we don't need synchronized here




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;30/Sep/21 00:42;githubbot;600","adelapena closed pull request #1238:
URL: https://github.com/apache/cassandra/pull/1238


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:42;githubbot;600","adelapena closed pull request #1237:
URL: https://github.com/apache/cassandra/pull/1237


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:42;githubbot;600","adelapena closed pull request #1236:
URL: https://github.com/apache/cassandra/pull/1236


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:42;githubbot;600","adelapena closed pull request #1202:
URL: https://github.com/apache/cassandra/pull/1202


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:44;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,6600,,,0,6600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Code,,,,,,,,Normal,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Oct 01 11:02:29 UTC 2021,,,,,,,All,,,,"0|z0uyp4:",9223372036854775807,,,,azotcsit,bereng,brandon.williams,,Normal,,NA,,https://github.com/apache/cassandra/commit/4f8afe85bfb2633d98beed39e665463bf19b8789,,,,,,,,,Some unit tests are included.,,,,,"15/Sep/21 14:51;adelapena;The proposed patch immediately applies the rate and considers negative values as unlimited:
||PR||CI||
|[trunk|https://github.com/apache/cassandra/pull/1202]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/842/workflows/2f8cbef4-0e93-4079-ac77-ba7223c1ecff] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/842/workflows/41966994-0d46-4b57-a747-06a70b13f238]|

I've opted for accepting negative values for simplicity, just to not repeat the validation for the value in the configuration and in the two nodetool commands. We can easily reject negative values if we prefer so.

Also I wonder whether we should improve [the log message|https://github.com/apache/cassandra/blob/09c89e5f5f8604301c233130dfb6e82a36ae30f3/src/java/org/apache/cassandra/service/StorageService.java#L1489] to include things like the unit of measurement, the previous rate or if the value is considered unlimited. My only concern about this is compatibility, in case some tooling out there depends on these log messages.

All praise to Niteshwar Kumar, who originally wrote the patch. The tiny tests for {{nodetool setstreamthroughput/setinterdcstreamthroughput}} are mine.;;;","22/Sep/21 18:55;brandon.williams;The patch looks good, +1.  I do think we should improve [both|https://github.com/apache/cassandra/blob/09c89e5f5f8604301c233130dfb6e82a36ae30f3/src/java/org/apache/cassandra/service/StorageService.java#L1500] log messages, as that not only provides needed context, but these messages appear to be outliers for not displaying a unit where applicable.  If some tooling out there depends on this output, adding a unit will be an easy fix, or it can grow up and use JMX directly so that's not necessary.;;;","23/Sep/21 05:51;bereng;Adding me back as I had already started reviewing this one but I was OOO yesterday, I only had a minor comment I dropped.;;;","23/Sep/21 09:05;azotcsit;[~adelapena]

I put a couple of minor comments to the PR. A quick question: what versions are you going to apply the fix to? I can see many versions mentioned in ""fix version"" field, however, the patch is for _trunk_ only.
{quote}The tiny tests for {{nodetool setstreamthroughput/setinterdcstreamthroughput}} are mine.
{quote}
The tests are great actually!;;;","29/Sep/21 16:05;adelapena;Thanks for the feedback, I have tried to address all the review comments.
{quote}I do think we should improve both log messages, as that not only provides needed context, but these messages appear to be outliers for not displaying a unit where applicable. If some tooling out there depends on this output, adding a unit will be an easy fix, or it can grow up and use JMX directly so that's not necessary.
{quote}
Makes sense, I have updated both messages to say {{throttle set to {} Mb/s (was {} Mb/s)}}.
{quote}A quick question: what versions are you going to apply the fix to? I can see many versions mentioned in ""fix version"" field, however, the patch is for trunk only.
{quote}
Here are all the PRs for the other branches:
||PR||CI||
|[3.0|https://github.com/apache/cassandra/pull/1236]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/925/workflows/d968e026-24a9-49f0-8fa7-69632ed5293d]|
|[3.11|https://github.com/apache/cassandra/pull/1237]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/923/workflows/7908af36-0777-4964-a34c-b2e15d270046]|
|[4.0|https://github.com/apache/cassandra/pull/1238]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/924/workflows/0568f57e-8824-42be-9648-586f7da8c78d] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/924/workflows/0d2f7db6-ea04-48bf-8aee-b05841623bac]|
|[trunk|https://github.com/apache/cassandra/pull/1202]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/922/workflows/99aa78a6-e631-40df-af64-09b8ceda6f69] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/922/workflows/c2aa41b5-c15c-484a-a30f-d7f2185c7dd9]|

Unfortunately, in the case of 3.0 and 3.11 we don't have [{{ToolRunner}}|https://github.com/apache/cassandra/blob/trunk/test/unit/org/apache/cassandra/tools/ToolRunner.java] available so the tests for the nodetool commands can't be backported as they are. In those branches we still have {{StreamManagerTest}} doing something quite similar, but I can add some dtests with a {{@since}} annotation if you think it is worth it.;;;","29/Sep/21 16:22;azotcsit;LGTM, +1;;;","30/Sep/21 05:14;bereng;LGTM +1;;;","01/Oct/21 11:02;adelapena;Thanks for the reviews, committed to 3.0 as [4f8afe85bfb2633d98beed39e665463bf19b8789|https://github.com/apache/cassandra/commit/4f8afe85bfb2633d98beed39e665463bf19b8789] and merged to [3.11|https://github.com/apache/cassandra/commit/c6e897d2d43bd8c2dff9553cee466231247b9840], [4.0|https://github.com/apache/cassandra/commit/339e8b74bff715f112e4b5947645c9e6cd00de7f] and [trunk|https://github.com/apache/cassandra/commit/0ccca8dab21719cc9248a87542a504cc057700e1].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky tests due to teardown failure,CASSANDRA-16954,13400979,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,k-rus,k-rus,14/Sep/21 10:25,27/May/22 19:25,13/Jul/23 08:40,20/Oct/21 16:05,3.0.26,3.11.12,4.0.2,4.1,4.1-alpha1,,,Test/dtest/python,,,,0,flaky-test,,"Different dtests in several CircleCI builds failed with teardown failure due to network failure with the error:
{code}
test teardown failure
Unexpected error found in node logs (see stdout for full details). Errors: [WARN  [epollEventLoopGroup-5-4] 2021-09-14 09:35:15,897 ExceptionHandlers.java:134 - Unknown exception in client networking
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer, WARN  [epollEventLoopGroup-5-4] 2021-09-14 09:35:15,897 ExceptionHandlers.java:134 - Unknown exception in client networking
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer]
{code}

For example, {{test_view_metadata_cleanup}} from {{materialized_views_test.TestMaterializedViews}} failed in [this build|https://app.circleci.com/pipelines/github/k-rus/cassandra/18/workflows/0cb193f3-ffe8-41c1-a376-43c91634579e/jobs/185/tests#failed-test-0] or {{test_expiration_overflow_policy_reject}} from {{ttl_test.TestTTL}} failed in [this build|https://app.circleci.com/pipelines/github/k-rus/cassandra/8/workflows/da99468d-c513-4a4f-9fd3-48b67482ce3e/jobs/67/tests#failed-test-0]",,bereng,k-rus,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Oct 20 16:05:18 UTC 2021,,,,,,,All,,,,"0|z0uw1c:",9223372036854775807,,,,bereng,,,,Normal,,3.0.25,,https://github.com/apache/cassandra/commit/f71dfdc37569398e282158e188be946eb1d5de01,,,,,,,,,Run CI,,,,,"18/Oct/21 17:19;brandon.williams;I think before CASSANDRA-16581 these exceptions were just ignored since they weren't ProtocolExceptions but now the catchall is logging this warning and causing the teardown failures. Patch to log native IO errors like these at trace instead.

||Branch||CI||
|[3.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16954-3.0]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16954-3.0], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1222/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1222/pipeline]|
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16954-3.11]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16954-3.11], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1220/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1220/pipeline]|
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16954-4.0]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16954-4.0], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1219/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1219/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16954-trunk]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16954-trunk], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1218/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1218/pipeline]|

;;;","20/Oct/21 06:49;bereng;Yes, I was just hitting this one on node reusage and was about to start looking into it. Thx fo fixing it. LGTM +1. But I would suggest running jvm dtests on 4.0 and trunk to be on the safe side.;;;","20/Oct/21 16:05;brandon.williams;The jvm dtests were run above by circle and jenkins.  They're broken on trunk by CASSANDRA-17050, but look good on 4.0.

Committed, appreciate your review!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
offline_tools_test.py::TestOfflineTools::test_sstableverify fails on 3.11,CASSANDRA-16948,13400795,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,13/Sep/21 13:27,27/May/22 19:25,13/Jul/23 08:40,27/Sep/21 21:52,3.11.12,4.0.2,4.1,4.1-alpha1,,,,Test/dtest/python,,,,0,,,"As noted by [~stefan.miklosovic]:

===Flaky Test Report===

test_sstableverify failed and was not selected for rerun.
        <class 'AssertionError'>
        assert None
 +  where None = <function search at 0x7fef074b5550>(('WARNING: Corrupted SSTable : ' + '/tmp/dtest-z6njep37/test/node1/data2/keyspace1/standard1-9b45a1f0149411ecbc69f72e6826361e/me-12-big-Data.db'), ""Subprocess sstableverify on keyspace1 : standard1 with options: ['-v'] exited with non-zero status; exit status: 1; \...p/dtest-z6njep37/test/node1/cdc_raw; setting cdc_total_space_in_mb to 3831.  You can override this in cassandra.yaml\n"")
 +    where <function search at 0x7fef074b5550> = re.search
        [<TracebackEntry /home/ubuntu/cassandra-dtest/offline_tools_test.py:303>]
",,bereng,maedhroz,stefan.miklosovic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Sep 27 21:52:18 UTC 2021,,,,,,,All,,,,"0|z0uuwg:",9223372036854775807,,,,maedhroz,,,,Normal,,NA,,https://github.com/apache/cassandra-dtest/commit/c2256c72ea9851a259df79d76239d2df80cd97b8,,,,,,,,,"Fix a test, run CI.",,,,,"13/Sep/21 16:49;stefan.miklosovic;That is only part of that ... yes, this is an issue as well. Especially when you are running locally, so you do not have enough disk space available and it emits these warnings and test expects something else.

 

But if you get through this, the error itself is in StandaloneVerifier (or so), it just logs the exception / errors differently from version to version I think and it seems to be flaky in general. Line 303 I think.;;;","13/Sep/21 16:50;stefan.miklosovic;[~dcapwell] this second part of this as I wrote above is more interesting.;;;","21/Sep/21 05:02;bereng;#justfyi there is some history to this guy see CASSANDRA-12519 ie. Reading about it might help as it has been historically speaking always flaky-ish;;;","22/Sep/21 17:04;brandon.williams;Linked branch fixes the test on 3.11.  I didn't run into any other problems you mentioned Stefan, but I noticed this was using a 3 node cluster and rf=3 for no reason, so I dropped it to a single node which may assuage your issues.

[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1132/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1132/pipeline]
;;;","22/Sep/21 20:02;stefan.miklosovic;[~brandon.williams]
test_sstableverify - offline_tools_test.TestOfflineTools failure here [https://app.circleci.com/pipelines/github/instaclustr/cassandra/461/workflows/c81c0b93-640a-4046-89c2-7eae17535513/jobs/2238/tests#failed-test-2];;;","22/Sep/21 20:07;brandon.williams;Hmm, well that's a problem in the 4.0 code.  I'll take a look though.;;;","22/Sep/21 20:12;stefan.miklosovic;I think I was messing with that test in order to fix what I saw and that build does not necessarily repeats the exact behavior rather my attempt to fix it. Basically, the regexp on the line 303 fails:

assert re.search(""Corrupted: "" + sstable1, error) - this does not match anything. Try to run it in a loop against 3.11 / 4.0.0.;;;","22/Sep/21 21:00;brandon.williams;bq.  that build does not necessarily repeats the exact behavior

Indeed, since the test randomizes the spot where it corrupts the table, sometimes 4.0 throws a slightly different error about the sstable being invalid.  I thought the 4.0 test was ok so I left it alone, but I've updated my branch to use my approach for all versions.;;;","27/Sep/21 21:44;maedhroz;Added a little fix to make sure the path comparisons work on MacOS: [https://github.com/maedhroz/cassandra-dtest/commits/CASSANDRA-16948-macos]

otherwise, LGTM;;;","27/Sep/21 21:52;brandon.williams;Committed with your mac fix added, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
 Multiple full sources can be select unexpectedly for bootstrap streaming,CASSANDRA-16945,13400504,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,yifanc,yifanc,yifanc,10/Sep/21 16:06,16/Mar/22 16:41,13/Jul/23 08:40,12/Nov/21 00:30,4.0.2,,,,,,,Consistency/Bootstrap and Decommission,,,,0,,,"With CASSANDRA-14404, the RangeStreamer selects all endpoints as sources when using strict consistency and RF > endpoints count. In such case, the bootstrapping node is almost guaranteed to fail in the validation later. 

It is a change of behavior. Before the patch, in such case (i.e., higher RF) the bootstrapping node just pick one endpoint as source, since consistent range movement cannot be established. I'd propose to restore the old behavior.",,yifanc,,,,,,,,,,,,,,,"smiklosovic closed pull request #1196:
URL: https://github.com/apache/cassandra/pull/1196


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:41;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,CASSANDRA-14404,,,,,,,,,,,,,,,,,,,,,,,,,0.0,yifanc,,,,,,,,,,,,,Availability -> Process Crash,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Nov 12 00:30:00 UTC 2021,,,,,,,All,,,,"0|z0ut3s:",9223372036854775807,,,,brandon.williams,,,,Low,,4.0.0,,https://github.com/apache/cassandra/commit/79bbb7dac5ad62f3bc725028ca7ea2be351d1999,,,,,,,,,circle ci,,,,,"10/Sep/21 16:10;brandon.williams;With TR marked experimental we should definitely restore the old behavior, +1 to that.;;;","10/Sep/21 16:30;yifanc;PR: [https://github.com/apache/cassandra/pull/1196]

CI: [https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=CASSANDRA-16945%2F4.0]

Basically, disable strict consistency when having a higher RF.;;;","21/Oct/21 21:13;yifanc;Rebased the patch. Sorry I was distracted from it for so long. 

[~brandon.williams], would you like to take another look? ;;;","21/Oct/21 21:19;brandon.williams;Sure, will do.;;;","22/Oct/21 15:20;brandon.williams;The patch looks good, +1.;;;","10/Nov/21 21:36;yifanc;Starting commit

CI Results:
||Branch||Source||Circle CI||Jenkins||
|cassandra-4.0|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16945-cassandra-4.0-47DB5D41-3965-4063-965F-7771F62E0576]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16945-cassandra-4.0-47DB5D41-3965-4063-965F-7771F62E0576]|[build|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1277/pipeline/]|
|trunk|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16945-trunk-47DB5D41-3965-4063-965F-7771F62E0576]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16945-trunk-47DB5D41-3965-4063-965F-7771F62E0576]| |

The build has unrelated test failures. {{test_rolling_upgrade}} failures can be reproduced by running the dtest using the upstream 3.11 and 4.0 branches. Filed the ticket CASSANDRA-17140;;;","12/Nov/21 00:30;yifanc;Committed into cassandra-4.0 as [79bbb7d
https://github.com/apache/cassandra/commit/79bbb7dac5ad62f3bc725028ca7ea2be351d1999] and merged to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Single partition reads can read more SSTables than required ,CASSANDRA-16944,13400470,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,blerer,blerer,10/Sep/21 13:08,16/Mar/22 17:02,13/Jul/23 08:40,28/Sep/21 16:14,3.0.26,3.11.12,4.0.2,,,,,Legacy/Local Write-Read Paths,,,,0,,,"For some scenarios involving row deletions, range deletions or static columns, the logic of {{SinglePartitionReadCommand.queryMemtableAndSSTablesInTimestampOrder}} might trigger more SSTables reads that expected. 

For row deletions and range deletions the reasons is that the logic do not take them into account. Once we hit a deleted row (caused by a row deletion or a range deletion) with a timestamp higher than the one of the next SStable we know that we can stop reading more SSTables.

For static columns the problems seems to have been introduced by the changes in CASSANDRA-16671.      ",,blerer,e.dimitrova,maedhroz,,,,,,,,,,,,,"maedhroz commented on a change in pull request #1200:
URL: https://github.com/apache/cassandra/pull/1200#discussion_r708577099



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -1047,10 +1048,21 @@ private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filte
      */
     private boolean isRowComplete(Row row, Columns requestedColumns, long sstableTimestamp)
     {
+        // Static rows do not have row deletion or primary key liveness info
+        if (!row.isStatic())
+        {
+            // If the row has been delete or is part of a range deletion we know that we have enough information and can

Review comment:
       ```suggestion
               // If the row has been deleted or is part of a range deletion we know that we have enough information and can
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Sep/21 19:40;githubbot;600","maedhroz commented on a change in pull request #1200:
URL: https://github.com/apache/cassandra/pull/1200#discussion_r708582291



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -1047,10 +1048,21 @@ private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filte
      */
     private boolean isRowComplete(Row row, Columns requestedColumns, long sstableTimestamp)
     {
+        // Static rows do not have row deletion or primary key liveness info
+        if (!row.isStatic())
+        {
+            // If the row has been delete or is part of a range deletion we know that we have enough information and can
+            // stop at this point.
+            // Note that deleted rows in compact table (non static) do not have a row deletion. Instead there single column

Review comment:
       ```suggestion
               // Note that deleted rows in compact tables (non static) do not have a row deletion. Single column cells are
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Sep/21 19:49;githubbot;600","maedhroz commented on a change in pull request #1200:
URL: https://github.com/apache/cassandra/pull/1200#discussion_r708582657



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -1047,10 +1048,21 @@ private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filte
      */
     private boolean isRowComplete(Row row, Columns requestedColumns, long sstableTimestamp)
     {
+        // Static rows do not have row deletion or primary key liveness info
+        if (!row.isStatic())
+        {
+            // If the row has been delete or is part of a range deletion we know that we have enough information and can
+            // stop at this point.
+            // Note that deleted rows in compact table (non static) do not have a row deletion. Instead there single column
+            // cell is deleted. By consequence this check will not work for those but the row will appears as complete later on

Review comment:
       ```suggestion
               // deleted instead. By consequence this check will not work for those, but the row will appear as complete later on
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Sep/21 19:49;githubbot;600","maedhroz commented on a change in pull request #1200:
URL: https://github.com/apache/cassandra/pull/1200#discussion_r708628793



##########
File path: test/unit/org/apache/cassandra/cql3/validation/miscellaneous/SSTablesIteratedTest.java
##########
@@ -983,4 +988,129 @@ public void testCompactTableWithMultipleRegularColumnsAndColumnDeletion() throws
         executeAndCheck(""SELECT v1, v2 FROM %s WHERE pk = 4"", 3, row(3, null));
         executeAndCheck(""SELECT v2 FROM %s WHERE pk = 4"", 3, row((Integer) null));
     }
+
+    @Test
+    public void testNonCompactTableWithStaticColumnAndRowDeletion() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (pk int, c int, s int static, v int, PRIMARY KEY(pk, c))"");
+
+        execute(""INSERT INTO %s (pk, c, s, v) VALUES (?, ?, ?, ?) USING TIMESTAMP 1000"", 1, 1, 1, 1);
+        execute(""INSERT INTO %s (pk, s) VALUES (?, ?) USING TIMESTAMP 1001"", 2, 2);
+        execute(""INSERT INTO %s (pk, c, v) VALUES (?, ?, ?) USING TIMESTAMP 1002"", 3, 1, 1);
+        flush();
+        execute(""UPDATE %s USING TIMESTAMP 2000 SET v = ? WHERE pk = ? AND c = ?"", 2, 1, 1);
+        execute(""INSERT INTO %s (pk, c, v) VALUES (?, ?, ?) USING TIMESTAMP 2001"", 2, 1, 2);
+        execute(""DELETE FROM %s USING TIMESTAMP 2001 WHERE pk = ? AND c = ?"", 3, 1);
+        flush();
+        execute(""DELETE FROM %s USING TIMESTAMP 3000 WHERE pk = ? AND c = ?"", 1, 1);
+        execute(""DELETE FROM %s USING TIMESTAMP 3001 WHERE pk = ? AND c = ?"", 2, 1);
+        execute(""INSERT INTO %s (pk, s) VALUES (?, ?) USING TIMESTAMP 3002"", 3, 3);
+        flush();
+
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 1"", 3, row(1, null, 1, null));
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 1 AND c = 1"", 3);
+        // In 3.0 the SinglePartitionReadCommand is looking for all the fetching columns which always includes the
+        // static ones so it needs to go through all the SSTables.
+        executeAndCheck(""SELECT v FROM %s WHERE pk = 1 AND c = 1"", 3);
+
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 2"", 3, row(2, null, 2, null));
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 2 AND c = 1"", 3);
+        executeAndCheck(""SELECT v FROM %s WHERE pk = 2 AND c = 1"", 3);
+
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 3"", 3, row(3, null, 3, null));
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 3 AND c = 1"", 2);
+        executeAndCheck(""SELECT v FROM %s WHERE pk = 3 AND c = 1"", 2);
+    }
+
+    @Test
+    public void testNonCompactTableWithStaticColumnAndRangeDeletion() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (pk int, c int, s int static, v int, PRIMARY KEY(pk, c))"");
+
+        execute(""INSERT INTO %s (pk, c, s, v) VALUES (?, ?, ?, ?) USING TIMESTAMP 1000"", 1, 1, 1, 1);
+        execute(""INSERT INTO %s (pk, s) VALUES (?, ?) USING TIMESTAMP 1001"", 2, 2);
+        execute(""INSERT INTO %s (pk, c, v) VALUES (?, ?, ?) USING TIMESTAMP 1002"", 3, 1, 1);
+        flush();
+        execute(""UPDATE %s USING TIMESTAMP 2000 SET v = ? WHERE pk = ? AND c = ?"", 2, 1, 1);
+        execute(""INSERT INTO %s (pk, c, v) VALUES (?, ?, ?) USING TIMESTAMP 2001"", 2, 1, 2);
+        execute(""DELETE FROM %s USING TIMESTAMP 2001 WHERE pk = ? AND c >= ?"", 3, 0);
+        flush();
+        execute(""DELETE FROM %s USING TIMESTAMP 3000 WHERE pk = ? AND c > ?"", 1, 0);
+        execute(""DELETE FROM %s USING TIMESTAMP 3001 WHERE pk = ? AND c > ?"", 2, 0);
+        execute(""INSERT INTO %s (pk, s) VALUES (?, ?) USING TIMESTAMP 3002"", 3, 3);
+        flush();
+
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 1"", 3, row(1, null, 1, null));
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 1 AND c = 1"", 3);
+        // In 3.0 the SinglePartitionReadCommand is looking for all the fetching columns which always includes the
+        // static ones so it needs to go through all the SSTables.
+        executeAndCheck(""SELECT v FROM %s WHERE pk = 1 AND c = 1"", 3);
+
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 2"", 3, row(2, null, 2, null));
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 2 AND c = 1"", 3);
+        executeAndCheck(""SELECT v FROM %s WHERE pk = 2 AND c = 1"", 3);
+
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 3"", 3, row(3, null, 3, null));
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 3 AND c = 1"", 2);
+        executeAndCheck(""SELECT v FROM %s WHERE pk = 3 AND c = 1"", 2);
+    }
+
+    @Test
+    public void testNonCompactTableWithStaticColumn() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (pk int, c int, s int static, v int, PRIMARY KEY(pk, c))"");
+
+        execute(""INSERT INTO %s (pk, c, s, v) VALUES (?, ?, ?, ?) USING TIMESTAMP 1000"", 1, 1, 1, 1);
+        execute(""INSERT INTO %s (pk, c, v) VALUES (?, ?, ?) USING TIMESTAMP 1001"", 2, 1, 1);
+        execute(""INSERT INTO %s (pk, c, v) VALUES (?, ?, ?) USING TIMESTAMP 1002"", 3, 1, 1);
+        flush();
+        execute(""UPDATE %s USING TIMESTAMP 2000 SET v = ? WHERE pk = ? AND c = ?"", 2, 1, 1);
+        execute(""UPDATE %s USING TIMESTAMP 2001 SET v = ? WHERE pk = ? AND c = ?"", 2, 2, 1);
+        execute(""INSERT INTO %s (pk, c, v) VALUES (?, ?, ?) USING TIMESTAMP 2002"", 3, 1, 2);
+        flush();
+        execute(""UPDATE %s USING TIMESTAMP 3000 SET s = ? WHERE pk = ?"", 2, 1);
+        execute(""INSERT INTO %s (pk, s) VALUES (?, ?) USING TIMESTAMP 3001"", 2, 1);
+        execute(""INSERT INTO %s (pk, c, s, v) VALUES (?, ?, ?, ?) USING TIMESTAMP 3002"", 3, 1, 1, 3);
+        flush();
+
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 1"", 3, row(1, 1, 2, 2));
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 1 AND c = 1"", 3, row(1, 1, 2, 2));
+        executeAndCheck(""SELECT v FROM %s WHERE pk = 1 AND c = 1"", 3, row(2));
+        executeAndCheck(""SELECT s FROM %s WHERE pk = 1"", 3, row(2));
+        executeAndCheck(""SELECT DISTINCT s FROM %s WHERE pk = 1"", 3, row(2));
+
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 2"", 3, row(2, 1, 1, 2));
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 2 AND c = 1"", 3, row(2, 1, 1, 2));
+        executeAndCheck(""SELECT v FROM %s WHERE pk = 2 AND c = 1"", 3, row(2));
+        executeAndCheck(""SELECT s FROM %s WHERE pk = 2"", 3, row(1));
+        executeAndCheck(""SELECT DISTINCT s FROM %s WHERE pk = 2"", 3, row(1));
+
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 3"", 3, row(3, 1, 1, 3));
+        executeAndCheck(""SELECT * FROM %s WHERE pk = 3 AND c = 1"", 1, row(3, 1, 1, 3));
+        executeAndCheck(""SELECT v FROM %s WHERE pk = 3 AND c = 1"", 1, row(3));
+        executeAndCheck(""SELECT s FROM %s WHERE pk = 3"", 3, row(1));
+        executeAndCheck(""SELECT DISTINCT s FROM %s WHERE pk = 3"", 3, row(1));
+    }
+
+    @Test
+    public void testCompactStaticTable() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (pk int PRIMARY KEY, v int) WITH COMPACT STORAGE"");

Review comment:
       The case where we have a compact table but more than one non-key column might be interesting, although scouring this class, it seems like `testCompactAndNonCompactTableWithPartitionTombstones()` sort of already hits it. WDYT?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Sep/21 21:00;githubbot;600","maedhroz commented on a change in pull request #1199:
URL: https://github.com/apache/cassandra/pull/1199#discussion_r708678259



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -957,6 +958,23 @@ private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filte
         }
 
         NavigableSet<Clustering<?>> toRemove = null;
+
+        DeletionInfo deletionInfo = result.deletionInfo();

Review comment:
       nit: I think all actual implementations of `Partition` would support it, so you could just add `result.deletionInfo()`to the interface and avoid referring to `ImmutableBTreePartition` directly.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Sep/21 22:04;githubbot;600","maedhroz commented on a change in pull request #1199:
URL: https://github.com/apache/cassandra/pull/1199#discussion_r708713985



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -957,6 +958,23 @@ private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filte
         }
 
         NavigableSet<Clustering<?>> toRemove = null;
+
+        DeletionInfo deletionInfo = result.deletionInfo();
+
+        if (deletionInfo.hasRanges())
+        {
+            for (Clustering<?> clustering : clusterings)
+            {
+                RangeTombstone rt = deletionInfo.rangeCovering(clustering);
+                if (rt != null && rt.deletionTime().deletes(sstableTimestamp))
+                {
+                    if (toRemove == null)
+                        toRemove = new TreeSet<>(result.metadata().comparator);
+                    toRemove.add(clustering);
+                }
+            } 
+        }

Review comment:
       This is required because there are row deletions that were converted to range tombstones in CASSANDRA-15369, and therefore aren't picked up by the logic in `isRowComplete()`?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Sep/21 22:51;githubbot;600","smiklosovic closed pull request #1199:
URL: https://github.com/apache/cassandra/pull/1199


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:43;githubbot;600","smiklosovic closed pull request #1200:
URL: https://github.com/apache/cassandra/pull/1200


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:47;githubbot;600","smiklosovic closed pull request #1198:
URL: https://github.com/apache/cassandra/pull/1198


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 17:02;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,5400,,,0,5400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Code,,,,,,,,Normal,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Sep 28 16:14:40 UTC 2021,,,,,,,All,,,,"0|z0usw8:",9223372036854775807,,,,maedhroz,,,,Low,,3.0.0,,https://github.com/apache/cassandra/commit/9f492844d5401d4d856c3bf5b908ba84d1b92a0c,,,,,,,,,The patches add new unit tests and distributed tests. It also update existing unit tests.,,,,,"13/Sep/21 13:54;blerer;|| Branche || CI ||
| [3.0|https://github.com/apache/cassandra/pull/1200] | [j8|https://app.circleci.com/pipelines/github/blerer/cassandra?branch=CASSANDRA-16944-3.0] |
| [3.11|https://github.com/apache/cassandra/pull/1198] | [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/207/workflows/cc17987b-b70f-433b-b005-3a9bb2705363] |
| [4.0|https://github.com/apache/cassandra/pull/1199] |[j8|https://app.circleci.com/pipelines/github/blerer/cassandra/208/workflows/c2224be7-d0ab-4b4a-af9e-48c25cb1849b], [j11|https://app.circleci.com/pipelines/github/blerer/cassandra/208/workflows/d3a6c41c-152f-4a4b-8327-7ffe7e12e71e] |

The 3.0 patch unit tests slightly differ from the other branches as the 3.0 require the static columns to always be read even if they are not queried.
The 4.0 patch logic handle range deletion in a different way than the other branches due to CASSANDRA-15369 that modified the logic in the 4.0 branch. ;;;","13/Sep/21 13:55;blerer;[~maedhroz] Would you have some time to review those patches?;;;","14/Sep/21 21:00;maedhroz;Approved the 3.0 and 3.11 patches w/ some nits. Moving to 4.0...;;;","14/Sep/21 22:54;maedhroz;+1 on all patches (although I've left a few minor nits across the PRs)

The test failures I do see are all preexisting issues.

This will merge up to trunk as well, correct?;;;","15/Sep/21 07:38;blerer;Thanks [~maedhroz]. I will go through all your feedback and changes things accordingly.

Yes, it will be merged to trunk. I expect the patch to be the same as the 4.0 one. I will run CI for it too once I have addressed the feedbacks. :-);;;","24/Sep/21 19:50;maedhroz;Latest feedback commits LGTM;;;","28/Sep/21 16:14;blerer;Committed into 3.0 at 9f492844d5401d4d856c3bf5b908ba84d1b92a0c and merged into 3.11, 4.0 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove OrderedJUnit4ClassRunner,CASSANDRA-16942,13400385,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,10/Sep/21 06:58,27/May/22 19:25,13/Jul/23 08:40,20/Sep/21 12:27,4.0.2,4.1,4.1-alpha1,,,,,Test/unit,,,,0,,,"Tests in a class should not depend on the order they are run in, remove {{OrderedJUnit4ClassRunner}} and fix any tests that depend on it",,bereng,e.dimitrova,maedhroz,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Sep 21 10:29:46 UTC 2021,,,,,,,All,,,,"0|z0usdc:",9223372036854775807,,,,bereng,maedhroz,,,Low,,2.1 beta1,,https://github.com/apache/cassandra/commit/9e9dffb70439e3e09e3da5515b7687b449b5ea76,,,,,,,,,This patch is itself a raft of text fixes.,,,,,"10/Sep/21 07:01;marcuse;https://github.com/krummas/cassandra/commits/marcuse/16942
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16942;;;","13/Sep/21 21:49;maedhroz;Finished a pass at review. There are some nits (we're cleaning up, so why not), which you can take or leave as you please, and some interesting results from running the tests locally, which I'll describe here first (and then investigate a bit if I have time today).

*Nits*

_Unused Imports_
 - {{import static org.junit.Assert.assertNotEquals}} in {{CompactionsTest}}

 - {{import java.util.ArrayList}} in {{ScrubTest}}

 - {{import org.junit.runner.RunWith}} and {{import org.junit.runners.Parameterized}} in {{QueryPagerTest}}

 - {{import static org.junit.Assert.fail}} in {{BulkLoaderTest}}

_Miscellaneous_
 - {{TestEventType}} has an unnecessary semicolon in

 - {{testBulkLoader_NoArgs}} doesn't need the {{throws Exception}} in {{DiagnosticEventServiceTest}}

 - {{testFromatArg()}} doesn't need the {{throws Throwable}} in {{NodeToolTPStatsTest}}

 - Should we do the second {{setPartitionerUnsafe()}} in a {{finally}} block in {{ScrubTest#testFilterOutDuplicates}}?

*Failures*

(Note that these are failures I encountered when running from IDEA.)
 - {{testCleanupArg}}, {{testTypeArg}}, {{testDefaultCall}}, and {{testListFilesArgs}} fail in {{StandaloneSSTableUtilTest}}, in that order.

 - {{testFlagArgs}} and {{testDefaultCall}} fail in that order in {{StandaloneUpgraderTest}};;;","13/Sep/21 22:03;maedhroz;UPDATE: I think the failures above only happened because a {{system_schema}} keyspace persisted in {{build/test/data}} when it shouldn't have. The {{OfflineToolUtils}} sub-classes might consider cleaning up the data directory in a {{@BeforeClass}}...

+1 on the patch, assuming the above are resolved;;;","14/Sep/21 08:05;marcuse;Pushed fixes for the above

Regarding the failures - assuming I understand what you were doing here (marking several test classes in idea and running them) - our configuration when running tests in idea is to not fork between classes, so these tests run in the same JVM which makes the tests fail. I pushed a config change to enable forking between classes (this is the same way we run from {{ant}}). These tests failed the same way before removing {{OrderedJUnit4ClassRunner}};;;","20/Sep/21 12:27;marcuse;and committed, thanks!;;;","21/Sep/21 08:07;bereng;Hi, there is big number of {{SSTableExportTest}} failures just on this commit. I haven't dug deep but it might be related. Would you be so kind to confirm please you that know the details inside out :-) Thx;;;","21/Sep/21 09:03;marcuse;hi, thanks for letting me know, split that test in two, one handles tests where we expect schema to be loaded and one where we don't

https://github.com/krummas/cassandra/commit/7bb2710da526dbe977ef84fca15f3f849bc2cbe2
https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-test/810/;;;","21/Sep/21 09:36;bereng;Agreed and reviewed on Slack +1;;;","21/Sep/21 10:29;marcuse;thanks, committed as https://github.com/apache/cassandra/commit/86aaf22f15290fac1b5f94843c9a2c9d1c6d56fd;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missed wait latencies in the output of `nodetool tpstats -F`,CASSANDRA-16938,13400261,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,adelapena,adelapena,09/Sep/21 14:53,27/May/22 19:25,13/Jul/23 08:40,10/Sep/21 12:34,4.0.2,4.1,4.1-alpha1,,,,,Tool/nodetool,,,,0,,,"The output of {{nodetool tpstats -F json}} always prints an empty map for {{WaitLatencies}}:
{code:java}
$ nodetool tpstats -F json
(...)""WaitLatencies"":{},(...)
{code}
The same happens with yaml output:
{code:java}
$ nodetool tpstats -F yaml
(...)
WaitLatencies: {}
(...)
{code}
This happens because [this cast|https://github.com/apache/cassandra/blob/cassandra-4.0.1/src/java/org/apache/cassandra/tools/nodetool/stats/TpStatsHolder.java#L61-L63] silently fails inside a try-catch with an empty catch block:
{code:java}
String[] strValues = (String[]) Arrays.stream(probe.metricPercentilesAsArray(probe.getMessagingQueueWaitMetrics(entry.getKey())))
                                      .map(D -> D.toString())
                                      .toArray();
{code}
When we would need something like:
{code:java}
String[] strValues = Arrays.stream(probe.metricPercentilesAsArray(probe.getMessagingQueueWaitMetrics(entry.getKey())))
                           .map(Object::toString)
                           .toArray(String[]::new);
{code}
This conversion from {{Double[]}} to {{String[]}} was introduced during CASSANDRA-16230. My guess is that the conversion was done trying to work around a malformed JSON output detected in [the new tests|https://github.com/apache/cassandra/blob/cassandra-4.0.1/test/unit/org/apache/cassandra/tools/NodeToolTPStatsTest.java#L158] added by that ticket. Without the conversion the output would be something like:
{code:java}
$ nodetool tpstats -F json
(...)""WaitLatencies"":{""READ_RSP"":[Ljava.lang.Double;@398dada8,(...)
{code}
That's because {{json-simple}} doesn't handle well arrays. I think that instead of converting the array of doubles to an array of strings we can simply use {{jackson-mapper-asl}} to print the proper array.",,adelapena,e.dimitrova,mck,,,,,,,,,,,,,"adelapena closed pull request #1191:
URL: https://github.com/apache/cassandra/pull/1191


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:44;githubbot;600","adelapena closed pull request #1190:
URL: https://github.com/apache/cassandra/pull/1190


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:44;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Sep/21 15:21;adelapena;json-after.txt;https://issues.apache.org/jira/secure/attachment/13033275/json-after.txt","09/Sep/21 15:21;adelapena;json-before.txt;https://issues.apache.org/jira/secure/attachment/13033274/json-before.txt",,,,2.0,adelapena,,,,,,,,,,,,,Correctness -> Transient Incorrect Response,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Sep 10 12:32:22 UTC 2021,,,,,,,All,,,,"0|z0urls:",9223372036854775807,,,,e.dimitrova,,,,Low,,4.0-beta3,,https://github.com/apache/cassandra/commit/636ab42bd5b2d2e55d37ce653daf23955f869a38,,,,,,,,,Some extra tests are included in the PRs,,,,,"09/Sep/21 15:06;adelapena;The proposed patch reverts the conversion from {{Double[]}} to {{String[]}} in {{TpStatsHolder}} and uses {{jackson-mapper-asl}} instead of {{json-simple}} to generate the json output:
||PR||CI||
|[4.0|https://github.com/apache/cassandra/pull/1190]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/837/workflows/494afd37-92b7-4127-9626-40cbc279a90c] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/837/workflows/b8fee35e-5b60-4590-80b6-ffa53858b741]​|
|[trunk|https://github.com/apache/cassandra/pull/1191]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra?branch=16938-trunk] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/838/workflows/1ec0b51b-eb8d-4f55-b9d6-7b6d06dcce45]​|

All praise to [~dimitarndimitrov] who originally found the problem with {{json-simple}} and wrote the changes for {{StatsPrinter}}. The changes in {{TpStatsHolder}} and the new tests are mine.;;;","09/Sep/21 15:36;adelapena;Please note that the change to {{jackson-mapper-asl}} will produce some formatting differences in the output. The original output didn't have any pretty-printing:
{code:json}
{""ThreadPools"":{""ReadStage"":{""TotalBlockedTasks"":0,""ActiveTasks"":0,""PendingTasks"":0,""CurrentlyBlockedTasks"":0,""CompletedTasks"":1},""CompactionExecutor"":(...)}
{code}
While the new output does use pretty-printing:
{code:json}
{
  ""ThreadPools"" : {
    ""CompactionExecutor"" : {
      ""TotalBlockedTasks"" : 0,
      ""ActiveTasks"" : 0,
      ""PendingTasks"" : 0,
      ""CurrentlyBlockedTasks"" : 0,
      ""CompletedTasks"" : 41
    },
    ""MemtableReclaimMemory"" : {
(...)
}
{code}
Also the order of the attributes is different. I have attached examples of the output after and before the changes. Of course the old output doesn't contain the wait latency metrics.

These formatting differences shouldn't be a problem for anyone parsing the output as proper json, but it might be an issue if someone is trying to parse the output as regular text. If we think that that can be a problem we can always keep using the old, ugly compact format.;;;","09/Sep/21 16:04;e.dimitrova;Thank you [~adelapena] and [~ddimitrov].

The patch looks great but I think changes of output probably can be introduced only in minor/major version. I wouldn't do it in a patch version probably. (even if the old one is ugly, indeed :) )

I think [~brandon.williams] and [~mck] might have some thoughts to share here.;;;","09/Sep/21 16:08;brandon.williams;I don't see how it matters in a serialized format like json. If people are trying to read it themselves and specifically chose json output to do so...well, this is still valid json, heh.;;;","09/Sep/21 16:36;adelapena;{quote}
I don't see how it matters in a serialized format like json. If people are trying to read it themselves and specifically chose json output to do so...well, this is still valid json, heh.
{quote}
I agree, the new rearranged json is equivalent to the previous one and any parser should produce the same output as before. 

By the way, at some point we should probably try to get rid of other usages of the venerable {{json-simple}}. We are using version 1.1 which was released in 2009. The only newer version is 1.1.1, which is from 2012 and doesn't solve the bug with numeric arrays.;;;","09/Sep/21 16:40;brandon.williams;bq. at some point we should probably try to get rid of other usages of the venerable json-simple

I believe that's CASSANDRA-16855;;;","09/Sep/21 16:53;e.dimitrova;Agreed with all said, the question was I guess about something weird someone might do but I guess we can't support every weird customization in the world. +1 on green CI (some tests were still running);;;","09/Sep/21 21:02;mck;bq. I don't see how it matters in a serialized format like json. If people are trying to read it themselves and specifically chose json output to do so...well, this is still valid json, heh.

Agreed.;;;","10/Sep/21 11:50;adelapena;I'd say CI looks good, the only two failing tests for 4.0 are known flakies.;;;","10/Sep/21 12:32;adelapena;Thanks for the feedback and the quick review.

Committed to {{cassandra-4.0}} as [636ab42bd5b2d2e55d37ce653daf23955f869a38|https://github.com/apache/cassandra/commit/636ab42bd5b2d2e55d37ce653daf23955f869a38] and merged to [{{trunk}}|https://github.com/apache/cassandra/commit/0516aa1be2b30dfe25c213c5ccfed44c9220cccc].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gossip Fixes,CASSANDRA-16932,13400070,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,benedict,benedict,benedict,08/Sep/21 17:53,27/May/22 19:25,13/Jul/23 08:40,07/Oct/21 15:31,4.1,4.1-alpha1,,,,,,Cluster/Gossip,,,,0,,,"Testing with CEP-10 discovered faults with gossip where status updates may be processed in an order that invalidates their application. These fixes are necessary for simulation to run correctly, but also potentially affect gossip time to settle.",,benedict,brandon.williams,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16929,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,benedict,,,,,,,,,,,,,Degradation -> Other Exception,,,,,,,,Low Hanging Fruit,Fuzz Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Sep 28 11:13:27 UTC 2021,,,,,,,All,,,,"0|z0uqfc:",9223372036854775807,,,,benedict,samt,,,Low,,4.0,,"[ce2a0a28bc9ca21e1fae29f2a38448a877db06c3|https://github.com/apache/cassandra/commit/ce2a0a28bc9ca21e1fae29f2a38448a877db06c3]",,,,,,,,,"Simulator discovered this flaw, and is being provided in a follow-up ticket",,,,,"28/Sep/21 11:13;benedict;Patch [here|https://github.com/belliottsmith/cassandra/tree/16932-trunk];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make creation timestamp consistent for all tables of a snapshot,CASSANDRA-16920,13400001,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stefan.miklosovic,stefan.miklosovic,stefan.miklosovic,08/Sep/21 13:38,07/Mar/23 11:52,13/Jul/23 08:40,16/Sep/21 20:28,4.1,4.1-alpha1,,,,,,Local/Snapshots,,,,0,,,"This mostly affects listsnapshots command as well as removal of a snapshot when it is on TTL.

Currently, there is not the same timestamp for ""created_at"" field in listsnapshots output so what might happen when TTL deletion kicks in is that only part of tables might be removed because other tables do not have to make it into that TTL threshold but they will be removed on the next SnapshotManager's removal round.",,azotcsit,paulo,stefan.miklosovic,,,,,,,,,,,,,"alex-ninja commented on a change in pull request #1189:
URL: https://github.com/apache/cassandra/pull/1189#discussion_r708662164



##########
File path: test/distributed/org/apache/cassandra/distributed/test/SnapshotsTest.java
##########
@@ -180,10 +184,25 @@ public void testSecondaryIndexCleanup() throws Exception {
         listSnapshotsResult.stdoutNotContains(""first"");
     }
 
-    private void populate(Cluster cluster) {
-        for (int i = 0; i < 100; i++) {
-            cluster.coordinator(1).execute(""INSERT INTO default.tbl (key, value) VALUES (?, 'txt')"", ConsistencyLevel.ONE, i);
-        }
+    @Test
+    public void testSameTimestampOnEachTableOfSnaphot()
+    {
+        cluster.get(1).nodetoolResult(""snapshot"", ""-t"", ""sametimestamp"").asserts().success();
+        NodeToolResult result = cluster.get(1).nodetoolResult(""listsnapshots"");
+
+        int distinctDates = Arrays.stream(result.getStdout().split(""\n""))
+                                  .filter(line -> line.startsWith(""sametimestamp""))
+                                  .map(line -> line.replaceAll("" +"", "" "").split("" "")[7])
+                                  .collect(Collectors.toSet())

Review comment:
       nit: probably it would be a bit clearer:
   ```
   .distinct()
   .count()
   ```

##########
File path: src/java/org/apache/cassandra/service/snapshot/SnapshotManifest.java
##########
@@ -60,13 +60,18 @@ private SnapshotManifest() {
         this.expiresAt = null;
     }
 
-    public SnapshotManifest(List<String> files, Duration ttl)
+    public SnapshotManifest(List<String> files, Duration ttl, long timestamp)
     {
         this.files = files;
-        this.createdAt = Instant.now();
+        this.createdAt = Instant.ofEpochMilli(timestamp);
         this.expiresAt = ttl == null ? null : createdAt.plusMillis(ttl.toMilliseconds());
     }
 
+    public SnapshotManifest(List<String> files, Duration ttl)

Review comment:
       Here is a conceptual question - do we still need to have this constructor? It is only used in tests. We can update tests to use the new one. If we remove this constructor we will enforce developers to always pass a timestamp, in turn that will not let them introduce the same issue as you're fixing now.
   
   The same is applicable to a few other methods you've updated.

##########
File path: src/java/org/apache/cassandra/db/ColumnFamilyStore.java
##########
@@ -1839,13 +1843,13 @@ public ClusteringComparator getComparator()
 
     public TableSnapshot snapshotWithoutFlush(String snapshotName)

Review comment:
       There is another usage of this method in `ConpactionTask`:
   ```
   if (DatabaseDescriptor.isSnapshotBeforeCompaction())
       cfs.snapshotWithoutFlush(System.currentTimeMillis() + ""-compact-"" + cfs.name);
   ```
   
   Looks like it has a timestamp in the name as well. Should we fix this one too? If yes, probably, I'd just change the signature of this method and add `timestamp` argument.

##########
File path: test/distributed/org/apache/cassandra/distributed/test/SnapshotsTest.java
##########
@@ -180,10 +184,25 @@ public void testSecondaryIndexCleanup() throws Exception {
         listSnapshotsResult.stdoutNotContains(""first"");
     }
 
-    private void populate(Cluster cluster) {
-        for (int i = 0; i < 100; i++) {
-            cluster.coordinator(1).execute(""INSERT INTO default.tbl (key, value) VALUES (?, 'txt')"", ConsistencyLevel.ONE, i);
-        }
+    @Test
+    public void testSameTimestampOnEachTableOfSnaphot()
+    {
+        cluster.get(1).nodetoolResult(""snapshot"", ""-t"", ""sametimestamp"").asserts().success();
+        NodeToolResult result = cluster.get(1).nodetoolResult(""listsnapshots"");
+
+        int distinctDates = Arrays.stream(result.getStdout().split(""\n""))

Review comment:
       nit: `distinctDates` -> `distinctTimestamps`?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Sep/21 21:57;githubbot;600","smiklosovic commented on a change in pull request #1189:
URL: https://github.com/apache/cassandra/pull/1189#discussion_r709351484



##########
File path: src/java/org/apache/cassandra/service/snapshot/SnapshotManifest.java
##########
@@ -60,13 +60,18 @@ private SnapshotManifest() {
         this.expiresAt = null;
     }
 
-    public SnapshotManifest(List<String> files, Duration ttl)
+    public SnapshotManifest(List<String> files, Duration ttl, long timestamp)
     {
         this.files = files;
-        this.createdAt = Instant.now();
+        this.createdAt = Instant.ofEpochMilli(timestamp);
         this.expiresAt = ttl == null ? null : createdAt.plusMillis(ttl.toMilliseconds());
     }
 
+    public SnapshotManifest(List<String> files, Duration ttl)

Review comment:
       thanks for review @alex-ninja , 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Sep/21 16:26;githubbot;600","smiklosovic commented on a change in pull request #1189:
URL: https://github.com/apache/cassandra/pull/1189#discussion_r710142863



##########
File path: src/java/org/apache/cassandra/db/ColumnFamilyStore.java
##########
@@ -1839,13 +1843,13 @@ public ClusteringComparator getComparator()
 
     public TableSnapshot snapshotWithoutFlush(String snapshotName)

Review comment:
       I introduced the method you suggested but I have also left there timestamp-less version of it which just takes snapshotName and which calls the new method with generated timestamp.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Sep/21 13:55;githubbot;600","alex-ninja commented on a change in pull request #1189:
URL: https://github.com/apache/cassandra/pull/1189#discussion_r710216945



##########
File path: src/java/org/apache/cassandra/db/ColumnFamilyStore.java
##########
@@ -1524,7 +1524,11 @@ public SSTableReader getMaxSizeFile(Iterable<SSTableReader> sstables)
     {
         // skip snapshot creation during scrub, SEE JIRA 5891
         if(!disableSnapshot)
-            snapshotWithoutFlush(""pre-scrub-"" + System.currentTimeMillis());
+        {
+            long timestamp = System.currentTimeMillis();
+            String snapshotName = ""pre-scrub-"" + timestamp;
+            snapshotWithoutFlush(snapshotName, null, false, null, null, timestamp);

Review comment:
       I think now we can re-use the newly created method:
   ```
   snapshotWithoutFlush(snapshotName, timestamp);
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Sep/21 15:14;githubbot;600","smiklosovic commented on a change in pull request #1189:
URL: https://github.com/apache/cassandra/pull/1189#discussion_r710334878



##########
File path: src/java/org/apache/cassandra/db/ColumnFamilyStore.java
##########
@@ -1524,7 +1524,11 @@ public SSTableReader getMaxSizeFile(Iterable<SSTableReader> sstables)
     {
         // skip snapshot creation during scrub, SEE JIRA 5891
         if(!disableSnapshot)
-            snapshotWithoutFlush(""pre-scrub-"" + System.currentTimeMillis());
+        {
+            long timestamp = System.currentTimeMillis();
+            String snapshotName = ""pre-scrub-"" + timestamp;
+            snapshotWithoutFlush(snapshotName, null, false, null, null, timestamp);

Review comment:
       good catch, thanks




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Sep/21 17:33;githubbot;600","smiklosovic closed pull request #1189:
URL: https://github.com/apache/cassandra/pull/1189


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Sep/21 20:29;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,3600,,,0,3600,,CASSANDRA-16860,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,stefan.miklosovic,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Sep 16 20:08:00 UTC 2021,,,,,,,All,,,,"0|z0uq00:",9223372036854775807,,,,azotcsit,paulo,,,Low,,5.0,,https://github.com/apache/cassandra/commit/e86ae7fbe52c95747d69f7d78b6da6fbd34bd48d,,,,,,,,,unit test / dtest,,,,,"08/Sep/21 13:42;stefan.miklosovic;https://github.com/apache/cassandra/pull/1189;;;","14/Sep/21 21:57;azotcsit;[~stefan.miklosovic]

I put a few minor comments to your PR. Please, take a look when you have some time.;;;","16/Sep/21 14:17;stefan.miklosovic;Thanks [~azotcsit], could you do the second pass and eventually +1 me here? (I trully do not know if you are a committer or not).;;;","16/Sep/21 16:57;azotcsit;I left one more minor comment. But in general the code LGTM. I'm just a contributor (not a committer), so +1 non-binding.;;;","16/Sep/21 20:01;stefan.miklosovic;I rewrote timestamps on longs from System.currentTimeMillis to Instant.now()

CI build https://app.circleci.com/pipelines/github/instaclustr/cassandra/474/workflows/ad4b84d9-d6aa-4512-a09c-f0e8754d6110;;;","16/Sep/21 20:08;paulo;LGTM, good job! +1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A user should be able to view permissions of role they created,CASSANDRA-16902,13398456,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,adelapena,adelapena,31/Aug/21 12:28,27/May/22 19:24,13/Jul/23 08:40,27/Oct/21 17:30,3.0.26,3.11.12,4.0.2,4.1,4.1-alpha1,,,Feature/Authorization,,,,0,,,"Currently users are denied to view permissions to see a role they created:
{code}
CREATE ROLE parent WITH PASSWORD = 'x' AND LOGIN = true;
GRANT CREATE ON ALL ROLES TO parent;
LOGIN parent;
CREATE ROLE child WITH PASSWORD = 'x' AND LOGIN = true;
LIST ALL PERMISSIONS OF 'child'; -- You are not authorized to view child's permissions
{code}
When a user creates a role they should get the {{DESCRIBE}} permission on that role by default.",,adelapena,azotcsit,blerer,,,,,,,,,,,,,"blerer commented on pull request #1179:
URL: https://github.com/apache/cassandra/pull/1179#issuecomment-909311765


   Sorry, I missed the fact that there was some DTest changes.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Aug/21 15:28;githubbot;600","blerer commented on pull request #1179:
URL: https://github.com/apache/cassandra/pull/1179#issuecomment-909311765


   Sorry, I missed the fact that there was some DTest changes.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Sep/21 09:22;githubbot;600","azotcsit commented on a change in pull request #1179:
URL: https://github.com/apache/cassandra/pull/1179#discussion_r715141670



##########
File path: src/java/org/apache/cassandra/service/ClientState.java
##########
@@ -404,6 +404,19 @@ public void ensurePermission(Permission perm, IResource resource)
         ensurePermissionOnResourceChain(perm, resource);
     }
 
+    public boolean hasPermission(Permission required, RoleResource resource) throws UnauthorizedException

Review comment:
       It does not throw `UnauthorizedException`

##########
File path: src/java/org/apache/cassandra/cql3/statements/ListPermissionsStatement.java
##########
@@ -78,6 +79,17 @@ public void validate(ClientState state) throws RequestValidationException
 
         if ((grantee != null) && !DatabaseDescriptor.getRoleManager().isExistingRole(grantee))
             throw new InvalidRequestException(String.format(""%s doesn't exist"", grantee));
+
+        // If the user requesting 'LIST PERMISSIONS' is not a superuser OR their username doesn't match 'grantee' OR
+        // has no DESCRIBE permission on the role or all roles, we throw UnauthorizedException.
+        // So only a superuser, system user can view everybody's permissions. Regular users are only
+        // allowed to see their own permissions and those of roles for which they have DESCRIBE permission.
+        if (!state.getUser().isSuper()

Review comment:
       I guess the right place to this logic is `authorize` method.

##########
File path: src/java/org/apache/cassandra/cql3/statements/ListPermissionsStatement.java
##########
@@ -78,6 +79,17 @@ public void validate(ClientState state) throws RequestValidationException
 
         if ((grantee != null) && !DatabaseDescriptor.getRoleManager().isExistingRole(grantee))
             throw new InvalidRequestException(String.format(""%s doesn't exist"", grantee));
+
+        // If the user requesting 'LIST PERMISSIONS' is not a superuser OR their username doesn't match 'grantee' OR
+        // has no DESCRIBE permission on the role or all roles, we throw UnauthorizedException.
+        // So only a superuser, system user can view everybody's permissions. Regular users are only
+        // allowed to see their own permissions and those of roles for which they have DESCRIBE permission.
+        if (!state.getUser().isSuper()
+            && !state.getUser().isSystem()
+            && !state.getUser().getRoles().contains(grantee)
+            && !state.hasPermission(Permission.DESCRIBE, grantee == null ? RoleResource.root() : grantee))

Review comment:
       Would it be easier to not create a `hasPermission` method and just check everything right here?
   ```
   && !state.getUser().getPermissions(RoleResource.root()).contains(Permission.DESCRIBE)
   && !(grantee != null && state.getUser().getPermissions(grantee).contains(Permission.DESCRIBE)))
   ```
   
   `hasPermission` is slightly ""non-concise"" to `ClientState` class because everything there is ""ensured"" (meaning throwing exceptions).

##########
File path: src/java/org/apache/cassandra/auth/RoleResource.java
##########
@@ -49,7 +49,8 @@
     // permissions which may be granted on role level resources
     private static final Set<Permission> ROLE_LEVEL_PERMISSIONS = Sets.immutableEnumSet(Permission.ALTER,
                                                                                         Permission.DROP,
-                                                                                        Permission.AUTHORIZE);
+                                                                                        Permission.AUTHORIZE,
+                                                                                        Permission.DESCRIBE);

Review comment:
       Please, update `CreateRoleStatement`, see https://github.com/azotcsit/cassandra/commit/4ee78c216c1f4e03f55174c9f2d7b86385bbbd3d#diff-6fa1c95412982ddb8451f332084d0d8d59a38d3a4c3c4b8bd8d955f71d55554aR98

##########
File path: src/java/org/apache/cassandra/auth/CassandraAuthorizer.java
##########
@@ -240,19 +240,12 @@ private void addLookupEntry(IResource resource, RoleResource role) throws Reques
     }
 
     // 'of' can be null - in that case everyone's permissions have been requested. Otherwise only single user's.
-    // If the user requesting 'LIST PERMISSIONS' is not a superuser OR their username doesn't match 'of', we
-    // throw UnauthorizedException. So only a superuser can view everybody's permissions. Regular users are only
-    // allowed to see their own permissions.
     public Set<PermissionDetails> list(AuthenticatedUser performer,
                                        Set<Permission> permissions,
                                        IResource resource,
                                        RoleResource grantee)
     throws RequestValidationException, RequestExecutionException
     {
-        if (!(performer.isSuper() || performer.isSystem()) && !performer.getRoles().contains(grantee))

Review comment:
       Basically we could achieve everything we need right here. Please, check a prototype code I wrote: https://github.com/azotcsit/cassandra/commit/4ee78c216c1f4e03f55174c9f2d7b86385bbbd3d#diff-a7b54023248dbee7fbdcb09e9336fabeddeede6276dd226850cb29e79eb5e7f2R252

##########
File path: src/java/org/apache/cassandra/cql3/statements/ListPermissionsStatement.java
##########
@@ -78,6 +79,17 @@ public void validate(ClientState state) throws RequestValidationException
 
         if ((grantee != null) && !DatabaseDescriptor.getRoleManager().isExistingRole(grantee))
             throw new InvalidRequestException(String.format(""%s doesn't exist"", grantee));
+
+        // If the user requesting 'LIST PERMISSIONS' is not a superuser OR their username doesn't match 'grantee' OR
+        // has no DESCRIBE permission on the role or all roles, we throw UnauthorizedException.
+        // So only a superuser, system user can view everybody's permissions. Regular users are only
+        // allowed to see their own permissions and those of roles for which they have DESCRIBE permission.
+        if (!state.getUser().isSuper()
+            && !state.getUser().isSystem()
+            && !state.getUser().getRoles().contains(grantee)
+            && !state.hasPermission(Permission.DESCRIBE, grantee == null ? RoleResource.root() : grantee))

Review comment:
       Actually we can even write it like this:
   ```
   AuthenticatedUser performer = state.getUser();
   if (performer.isSuper() || performer.isSystem() || performer.getRoles().contains(grantee))
       return;
   
   state.ensurePermission(Permission.DESCRIBE, grantee == null ? RoleResource.root() : grantee);
   ```
   
   I feel this logic is even more clear. However, the downside is that it slightly changes error message. From:
   ```
   ""You are not authorized to view %s's permissions"", grantee == null ? ""everyone"" : grantee.getRoleName()
   ```
   To:
   ```
   ""User %s has no %s permission on %s or any of its parents"", user.getName(), perm, resource)
   ```
   that does not seem to be a problem.
   
   Please, share your thoughts.

##########
File path: src/java/org/apache/cassandra/service/ClientState.java
##########
@@ -404,6 +404,19 @@ public void ensurePermission(Permission perm, IResource resource)
         ensurePermissionOnResourceChain(perm, resource);
     }
 
+    public boolean hasPermission(Permission required, RoleResource resource) throws UnauthorizedException

Review comment:
       In general I'm not sure we really need to introduce this methods, please, check another comment and let me know your thoughts.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Sep/21 12:14;githubbot;600","azotcsit commented on a change in pull request #1179:
URL: https://github.com/apache/cassandra/pull/1179#discussion_r717816774



##########
File path: test/unit/org/apache/cassandra/auth/CassandraAuthorizerTest.java
##########
@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.auth;
+
+import java.util.Collections;
+
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.apache.cassandra.SchemaLoader;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.cql3.QueryProcessor;
+import org.apache.cassandra.cql3.UntypedResultSet;
+import org.apache.cassandra.cql3.statements.CreateRoleStatement;
+import org.apache.cassandra.cql3.statements.ListPermissionsStatement;
+import org.apache.cassandra.exceptions.UnauthorizedException;
+import org.apache.cassandra.service.ClientState;
+import org.apache.cassandra.transport.messages.ResultMessage;
+
+import static org.apache.cassandra.auth.AuthenticatedUser.SYSTEM_USER;
+
+public class CassandraAuthorizerTest extends CQLTester
+{
+    public static final RoleResource PARENT_ROLE = RoleResource.role(""parent"");
+    public static final RoleResource CHILD_ROLE = RoleResource.role(""child"");
+    public static final RoleResource OTHER_ROLE = RoleResource.role(""other"");
+
+    @BeforeClass
+    public static void setupClass()
+    {
+        CQLTester.setUpClass();
+        SchemaLoader.setupAuth(new AuthTestUtils.LocalCassandraRoleManager(),
+                               new AuthTestUtils.LocalPasswordAuthenticator(),
+                               new AuthTestUtils.LocalCassandraAuthorizer(),
+                               new AuthTestUtils.LocalCassandraNetworkAuthorizer());
+    }
+
+    @Test
+    public void testListPermissionsOfChildByParent()
+    {
+        // create parent role by system user
+        DatabaseDescriptor.getRoleManager()
+                          .createRole(SYSTEM_USER, PARENT_ROLE, AuthTestUtils.getLoginRoleOptions());
+
+        // create child role by parent
+        String createRoleQuery = String.format(""CREATE ROLE %s"", CHILD_ROLE.getRoleName());
+        CreateRoleStatement createRoleStatement = (CreateRoleStatement) QueryProcessor.parseStatement(createRoleQuery)
+                                                                                      .prepare(ClientState.forInternalCalls());
+        createRoleStatement.execute(getClientState(PARENT_ROLE.getRoleName()));
+
+        // grant SELECT permission on ALL KEYSPACES to child
+        DatabaseDescriptor.getAuthorizer()
+                          .grant(SYSTEM_USER,
+                                 Collections.singleton(Permission.SELECT),
+                                 DataResource.root(),
+                                 CHILD_ROLE);
+
+        // list child permissions by parent
+        String listPermissionsQuery = String.format(""LIST ALL PERMISSIONS OF %s"", CHILD_ROLE.getRoleName());
+        ListPermissionsStatement listPermissionsStatement = (ListPermissionsStatement) QueryProcessor.parseStatement(listPermissionsQuery)
+                                                                                                     .prepare(ClientState.forInternalCalls());
+        ResultMessage message = listPermissionsStatement.execute(getClientState(PARENT_ROLE.getRoleName()));
+        assertRows(UntypedResultSet.create(((ResultMessage.Rows) message).result),
+                   row(""child"", ""child"", ""<all keyspaces>"", ""SELECT""));
+
+        // list child permissions by other user that is not their parent
+        DatabaseDescriptor.getRoleManager().createRole(SYSTEM_USER, OTHER_ROLE, AuthTestUtils.getLoginRoleOptions());
+        try

Review comment:
       nit: stylistically I prefer `assertThatThrownBy`, but it's up to you.

##########
File path: test/unit/org/apache/cassandra/auth/CassandraAuthorizerTest.java
##########
@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.auth;
+
+import java.util.Collections;
+
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.apache.cassandra.SchemaLoader;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.cql3.QueryProcessor;
+import org.apache.cassandra.cql3.UntypedResultSet;
+import org.apache.cassandra.cql3.statements.CreateRoleStatement;
+import org.apache.cassandra.cql3.statements.ListPermissionsStatement;
+import org.apache.cassandra.exceptions.UnauthorizedException;
+import org.apache.cassandra.service.ClientState;
+import org.apache.cassandra.transport.messages.ResultMessage;
+
+import static org.apache.cassandra.auth.AuthenticatedUser.SYSTEM_USER;
+
+public class CassandraAuthorizerTest extends CQLTester
+{
+    public static final RoleResource PARENT_ROLE = RoleResource.role(""parent"");

Review comment:
       nit: I missed that the variables are public (can be private), but again it is not a reason to fix unless some other changes are made

##########
File path: test/unit/org/apache/cassandra/auth/AuthTestUtils.java
##########
@@ -139,7 +139,7 @@ public static long getRolesReadCount()
         return rolesTable.metric.readLatency.latency.getCount();
     }
 
-    public static RoleOptions getLoginRoleOprions()
+    public static RoleOptions getLoginRoleOptions()

Review comment:
       Thanks for fixing it here. I was going to do that in https://github.com/apache/cassandra/pull/1208.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Sep/21 17:38;githubbot;600","azotcsit commented on a change in pull request #1179:
URL: https://github.com/apache/cassandra/pull/1179#discussion_r717816774



##########
File path: test/unit/org/apache/cassandra/auth/CassandraAuthorizerTest.java
##########
@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.auth;
+
+import java.util.Collections;
+
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.apache.cassandra.SchemaLoader;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.cql3.QueryProcessor;
+import org.apache.cassandra.cql3.UntypedResultSet;
+import org.apache.cassandra.cql3.statements.CreateRoleStatement;
+import org.apache.cassandra.cql3.statements.ListPermissionsStatement;
+import org.apache.cassandra.exceptions.UnauthorizedException;
+import org.apache.cassandra.service.ClientState;
+import org.apache.cassandra.transport.messages.ResultMessage;
+
+import static org.apache.cassandra.auth.AuthenticatedUser.SYSTEM_USER;
+
+public class CassandraAuthorizerTest extends CQLTester
+{
+    public static final RoleResource PARENT_ROLE = RoleResource.role(""parent"");
+    public static final RoleResource CHILD_ROLE = RoleResource.role(""child"");
+    public static final RoleResource OTHER_ROLE = RoleResource.role(""other"");
+
+    @BeforeClass
+    public static void setupClass()
+    {
+        CQLTester.setUpClass();
+        SchemaLoader.setupAuth(new AuthTestUtils.LocalCassandraRoleManager(),
+                               new AuthTestUtils.LocalPasswordAuthenticator(),
+                               new AuthTestUtils.LocalCassandraAuthorizer(),
+                               new AuthTestUtils.LocalCassandraNetworkAuthorizer());
+    }
+
+    @Test
+    public void testListPermissionsOfChildByParent()
+    {
+        // create parent role by system user
+        DatabaseDescriptor.getRoleManager()
+                          .createRole(SYSTEM_USER, PARENT_ROLE, AuthTestUtils.getLoginRoleOptions());
+
+        // create child role by parent
+        String createRoleQuery = String.format(""CREATE ROLE %s"", CHILD_ROLE.getRoleName());
+        CreateRoleStatement createRoleStatement = (CreateRoleStatement) QueryProcessor.parseStatement(createRoleQuery)
+                                                                                      .prepare(ClientState.forInternalCalls());
+        createRoleStatement.execute(getClientState(PARENT_ROLE.getRoleName()));
+
+        // grant SELECT permission on ALL KEYSPACES to child
+        DatabaseDescriptor.getAuthorizer()
+                          .grant(SYSTEM_USER,
+                                 Collections.singleton(Permission.SELECT),
+                                 DataResource.root(),
+                                 CHILD_ROLE);
+
+        // list child permissions by parent
+        String listPermissionsQuery = String.format(""LIST ALL PERMISSIONS OF %s"", CHILD_ROLE.getRoleName());
+        ListPermissionsStatement listPermissionsStatement = (ListPermissionsStatement) QueryProcessor.parseStatement(listPermissionsQuery)
+                                                                                                     .prepare(ClientState.forInternalCalls());
+        ResultMessage message = listPermissionsStatement.execute(getClientState(PARENT_ROLE.getRoleName()));
+        assertRows(UntypedResultSet.create(((ResultMessage.Rows) message).result),
+                   row(""child"", ""child"", ""<all keyspaces>"", ""SELECT""));
+
+        // list child permissions by other user that is not their parent
+        DatabaseDescriptor.getRoleManager().createRole(SYSTEM_USER, OTHER_ROLE, AuthTestUtils.getLoginRoleOptions());
+        try

Review comment:
       nit: stylistically I prefer `assertThatThrownBy`, but it's up to you.

##########
File path: test/unit/org/apache/cassandra/auth/CassandraAuthorizerTest.java
##########
@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.auth;
+
+import java.util.Collections;
+
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.apache.cassandra.SchemaLoader;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.cql3.QueryProcessor;
+import org.apache.cassandra.cql3.UntypedResultSet;
+import org.apache.cassandra.cql3.statements.CreateRoleStatement;
+import org.apache.cassandra.cql3.statements.ListPermissionsStatement;
+import org.apache.cassandra.exceptions.UnauthorizedException;
+import org.apache.cassandra.service.ClientState;
+import org.apache.cassandra.transport.messages.ResultMessage;
+
+import static org.apache.cassandra.auth.AuthenticatedUser.SYSTEM_USER;
+
+public class CassandraAuthorizerTest extends CQLTester
+{
+    public static final RoleResource PARENT_ROLE = RoleResource.role(""parent"");

Review comment:
       nit: I missed that the variables are public (can be private), but again it is not a reason to fix unless some other changes are made

##########
File path: test/unit/org/apache/cassandra/auth/AuthTestUtils.java
##########
@@ -139,7 +139,7 @@ public static long getRolesReadCount()
         return rolesTable.metric.readLatency.latency.getCount();
     }
 
-    public static RoleOptions getLoginRoleOprions()
+    public static RoleOptions getLoginRoleOptions()

Review comment:
       Thanks for fixing it here. I was going to do that in https://github.com/apache/cassandra/pull/1208.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Sep/21 20:07;githubbot;600","adelapena closed pull request #1179:
URL: https://github.com/apache/cassandra/pull/1179


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:44;githubbot;600","adelapena closed pull request #1234:
URL: https://github.com/apache/cassandra/pull/1234


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:44;githubbot;600","adelapena closed pull request #1233:
URL: https://github.com/apache/cassandra/pull/1233


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:44;githubbot;600","adelapena closed pull request #1235:
URL: https://github.com/apache/cassandra/pull/1235


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:44;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,5400,,,0,5400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Oct 27 17:29:35 UTC 2021,,,,,,,All,,,,"0|z0uggw:",9223372036854775807,,,,azotcsit,blerer,,,Low,,NA,,https://github.com/apache/cassandra/commit/969531a113530eb87d5ea350aa005abc946a5152,,,,,,,,,Dtests are modified to reflect the changes in permissions,,,,,"31/Aug/21 12:45;adelapena;The proposed patch adds {{DESCRIBE}} permissions to roles:
||PR||CI||
|[trunk|https://github.com/apache/cassandra/pull/1179]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/812/workflows/8727c0e0-2b78-4320-9e71-b2e93eee695d] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/812/workflows/37bc1376-00af-4822-82f7-0e09b45765cd]|
|[dtest|https://github.com/apache/cassandra-dtest/pull/157]|

Probably we should apply this fix to older branches.

All praise to [~snazy], who is the original author of the patch.;;;","24/Sep/21 12:14;azotcsit;[~adelapena]

I put some comment to the PR, please, check them out and let me know your thoughts.

The main points:
 # do we want to keep authorization logic in {{CassandraAuthorizer}} or move to {{ListPermissionsStatement}}? I feel moving makes sense, but I'd move it to {{authorize}} method then. 
 # I wrote a unit test (while trying to figure out what is going on), could you, please, check it and incorporate to the PR if it looks good to you.

You can find the unit test and other changes I'm referring to in the PR comments here: https://github.com/azotcsit/cassandra/commit/4ee78c216c1f4e03f55174c9f2d7b86385bbbd3d;;;","28/Sep/21 15:37;adelapena;[~azotcsit] thanks for the review. Keeping the authorization logic in {{CassandraAuthorizer}} makes sense to me, and the new unit test looks nice. I have incorporated you changes to the PR with minimal modifications. I have also extended the test to exercise the authorization exception.

||PR||CI||
|[trunk|https://github.com/apache/cassandra/pull/1179]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/913/workflows/24c1e434-08a3-45d0-95f7-7182f34d80cf] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/913/workflows/40bf1a55-0ee1-4f15-939a-7072f7c0b3f3]|
|[dtest|https://github.com/apache/cassandra-dtest/pull/157]|;;;","28/Sep/21 17:43;azotcsit;[~adelapena]  I put a couple of nits to the PR, but it's up to you whether address them or not. _trunk_ branch LGTM.

The question is: are we going to fix this issue in other branches? I feel it makes sense to do it starting from 3.0, but I'm not totally sure. Probably [~blerer] can help to determine that.;;;","29/Sep/21 12:23;adelapena;[~azotcsit] I have addressed your nits on the PR.

Not sure about whether we want to apply the patch to the other branches, since this fix is almost a new feature. The patch applies quite cleanly to older branches, the only problem is when applying the new unit test to 3.0 and 3.11. Those branches don't have some of the testing improvements that were done during the 4.0 quality testing epic, so I think that for those branches we could live with the dtest only:
||PR||CI||
|[3.0|https://github.com/apache/cassandra/pull/1233]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/919/workflows/7c734732-e092-4ed5-bf52-d13d3a82a9a0]|
|[3.11|https://github.com/apache/cassandra/pull/1234]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/920/workflows/18199018-3dea-4aed-b2a9-e5007ab5c32d]|
|[4.0|https://github.com/apache/cassandra/pull/1235]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/918/workflows/753e6a1a-1c82-4227-9c25-2828d807462e], [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/918/workflows/35b7b4af-ef75-45f3-8d0f-b81058c8b580]|
|[trunk|https://github.com/apache/cassandra/pull/1179]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/921/workflows/f516822e-8494-4e4e-b23e-6246cd70a85d], [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/921/workflows/127aad17-35cd-4454-9964-f8489999214f]|
|[dtest|https://github.com/apache/cassandra-dtest/pull/157]|

[~blerer] what do you think?;;;","29/Sep/21 16:34;azotcsit;All branches LGTM, +1.;;;","13/Oct/21 05:56;azotcsit;[~blerer] [~jmckenzie]

Would you mind reviewing this change? I'd like to get it merged to prevent conflicts with CASSANDRA-16914.;;;","13/Oct/21 13:07;blerer;[~azotcsit] Sorry, I am the one blocking that issue. I had a discussion with [~adelapena] about simplifying the unit tests but those simplification would require the changes that are part of CASSANDRA-17027.;;;","13/Oct/21 14:03;azotcsit;[~blerer]

Oh ok, got it. I did not know it is blocked by something else. Sorry for disturbing!  ;;;","26/Oct/21 13:25;adelapena;I have just updated the test for trunk for using the new authentication utils added to {{CQLTester}} by CASSANDRA-17027 ([this commit|https://github.com/apache/cassandra/pull/1179/commits/18fd301e916bc8b40a5c13e2eb8d4a6a2500413e]). Those utils are only present in trunk, I wonder if we should port them back to older branches.;;;","26/Oct/21 14:49;blerer;The patch looks good to me.

{quote}Those utils are only present in trunk, I wonder if we should port them back to older branches.{quote} 

I do not feel a real need for it but I am also not against it if you believe that it makes sense.;;;","26/Oct/21 16:55;adelapena;I also think that we don't need to port back those test improvements. Besides CASSANDRA-17027, we would also need some stuff from CASSANDRA-16918, CASSANDRA-16404 and CASSANDRA-14497, and I'm not sure that is a good idea to apply so many changes to the relatively stable older branches for a mainly cosmetic improvement.

Here is a final CI round after rebase, including repeated runs of the new/modified tests:
||PR||CI||
|[3.0|https://github.com/apache/cassandra/pull/1233]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1085/workflows/299084af-60a7-4637-9448-6eb62e7b36ba]|
|[3.11|https://github.com/apache/cassandra/pull/1234]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1086/workflows/935b5a9c-b2da-42b1-a224-573f6d387c31]|
|[4.0|https://github.com/apache/cassandra/pull/1235]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1088/workflows/1f421ce7-f6ad-41e8-8ee4-4726b716e279] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1088/workflows/a1de585a-aa03-4d1b-a9ca-07e660f86ea9]|
|[trunk|https://github.com/apache/cassandra/pull/1179]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1087/workflows/af2ce406-b50e-4e67-828f-5bc96ed12eb8] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1087/workflows/3a6f102a-1827-42b3-978c-8fc12b221033]|
|[dtest|https://github.com/apache/cassandra-dtest/pull/157]|;;;","26/Oct/21 18:58;azotcsit;The updated patch LGTM, +1.;;;","27/Oct/21 17:29;adelapena;Committed to 3.0 as [969531a113530eb87d5ea350aa005abc946a5152|https://github.com/apache/cassandra/commit/969531a113530eb87d5ea350aa005abc946a5152] and merged to [3.11|https://github.com/apache/cassandra/commit/3d74cad35f94eaa2003c51e9755d5c71adb093f6], [4.0|https://github.com/apache/cassandra/commit/6c9d5abbc56c043b8d89232bbc2d145482e297c3] and [trunk|https://github.com/apache/cassandra/commit/d21e0dd8461e7ab9ce41ad4ee58e75134dc918ab].

Dtest changes committed as [027eb0dbc6b71f547f156c05fad0b418939e4d92|https://github.com/apache/cassandra-dtest/commit/027eb0dbc6b71f547f156c05fad0b418939e4d92].

Thanks for the reviews.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
org.apache.cassandra.db.rows.ArrayCell#unsharedHeapSizeExcludingData includes data twice,CASSANDRA-16900,13398276,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,30/Aug/21 17:14,27/May/22 19:25,13/Jul/23 08:40,31/Aug/21 15:40,4.0.2,4.1,4.1-alpha1,,,,,Legacy/Local Write-Read Paths,,,,0,,,"org.apache.cassandra.db.rows.ArrayCell#unsharedHeapSizeExcludingData includes data and adds the length; so includes data twice",,dcapwell,maedhroz,,,,,,,,,,,,,,"dcapwell commented on a change in pull request #1176:
URL: https://github.com/apache/cassandra/pull/1176#discussion_r698685191



##########
File path: src/java/org/apache/cassandra/db/rows/BufferCell.java
##########
@@ -43,7 +45,7 @@ public BufferCell(ColumnMetadata column, long timestamp, int ttl, int localDelet
     {
         super(column);
         assert !column.isPrimaryKeyColumn();
-        assert column.isComplex() == (path != null);
+        assert column.isComplex() == (path != null) : format(""Column %s.%s(%s: %s) isComplex: %b with cellpath: %s"", column.ksName, column.cfName, column.name, column.type.toString(), column.isComplex(), path);

Review comment:
       this is a nit from me; asserts should have messages to help (not needed for the patch, but is useful)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;30/Aug/21 17:48;githubbot;600","dcapwell commented on a change in pull request #1176:
URL: https://github.com/apache/cassandra/pull/1176#discussion_r698685491



##########
File path: src/java/org/apache/cassandra/db/rows/NativeCell.java
##########
@@ -78,7 +78,7 @@ public NativeCell(NativeAllocator allocator,
         assert column.isComplex() == (path != null);
         if (path != null)
         {
-            assert path.size() == 1;
+            assert path.size() == 1 : String.format(""Expected path size to be 1 but was not; %s"", path);

Review comment:
       this is a nit from me; asserts should have messages to help (not needed for the patch, but is useful)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;30/Aug/21 17:48;githubbot;600","maedhroz commented on a change in pull request #1176:
URL: https://github.com/apache/cassandra/pull/1176#discussion_r698707701



##########
File path: test/unit/org/apache/cassandra/db/CellSpecTest.java
##########
@@ -0,0 +1,120 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.db;
+
+import java.nio.ByteBuffer;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+import java.util.concurrent.CompletableFuture;
+import java.util.function.BiConsumer;
+import java.util.stream.Collectors;
+
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+
+import org.apache.cassandra.db.marshal.BytesType;
+import org.apache.cassandra.db.marshal.ListType;
+import org.apache.cassandra.db.rows.ArrayCell;
+import org.apache.cassandra.db.rows.BufferCell;
+import org.apache.cassandra.db.rows.Cell;
+import org.apache.cassandra.db.rows.CellPath;
+import org.apache.cassandra.db.rows.NativeCell;
+import org.apache.cassandra.schema.ColumnMetadata;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.utils.ObjectSizes;
+import org.apache.cassandra.utils.UUIDGen;
+import org.apache.cassandra.utils.concurrent.OpOrder;
+import org.apache.cassandra.utils.memory.NativeAllocator;
+import org.apache.cassandra.utils.memory.NativePool;
+import org.assertj.core.api.Assertions;
+
+import static org.apache.cassandra.utils.ByteBufferUtil.bytes;
+
+@RunWith(Parameterized.class)
+public class CellSpecTest
+{
+    private final Cell<?> cell;
+
+    public CellSpecTest(String ignoreOnlyUsedForBetterTestName, Cell<?> cell)

Review comment:
       nit: could always throw a `@SuppressWarnings(""unused"")` in there




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;30/Aug/21 18:23;githubbot;600","maedhroz commented on a change in pull request #1176:
URL: https://github.com/apache/cassandra/pull/1176#discussion_r698767494



##########
File path: src/java/org/apache/cassandra/utils/ObjectSizes.java
##########
@@ -133,6 +134,16 @@ public static long sizeOnHeapExcludingData(ByteBuffer buffer)
         return BUFFER_EMPTY_SIZE;
     }
 
+    public static long sizeOfEmptyHeapByteBuffer()
+    {
+        return BUFFER_EMPTY_SIZE;
+    }

Review comment:
       Not directly related to your patch, but it seems a bit misleading that `sizeOnHeapExcludingData()` takes an argument. Perhaps it would be better to be explicit and just remove it, replacing current usages w/ your new `sizeOfEmptyHeapByteBuffer()` method.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;30/Aug/21 19:58;githubbot;600","dcapwell commented on a change in pull request #1176:
URL: https://github.com/apache/cassandra/pull/1176#discussion_r698685191



##########
File path: src/java/org/apache/cassandra/db/rows/BufferCell.java
##########
@@ -43,7 +45,7 @@ public BufferCell(ColumnMetadata column, long timestamp, int ttl, int localDelet
     {
         super(column);
         assert !column.isPrimaryKeyColumn();
-        assert column.isComplex() == (path != null);
+        assert column.isComplex() == (path != null) : format(""Column %s.%s(%s: %s) isComplex: %b with cellpath: %s"", column.ksName, column.cfName, column.name, column.type.toString(), column.isComplex(), path);

Review comment:
       this is a nit from me; asserts should have messages to help (not needed for the patch, but is useful)

##########
File path: src/java/org/apache/cassandra/db/rows/NativeCell.java
##########
@@ -78,7 +78,7 @@ public NativeCell(NativeAllocator allocator,
         assert column.isComplex() == (path != null);
         if (path != null)
         {
-            assert path.size() == 1;
+            assert path.size() == 1 : String.format(""Expected path size to be 1 but was not; %s"", path);

Review comment:
       this is a nit from me; asserts should have messages to help (not needed for the patch, but is useful)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Aug/21 15:13;githubbot;600","maedhroz commented on a change in pull request #1176:
URL: https://github.com/apache/cassandra/pull/1176#discussion_r698707701



##########
File path: test/unit/org/apache/cassandra/db/CellSpecTest.java
##########
@@ -0,0 +1,120 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.db;
+
+import java.nio.ByteBuffer;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+import java.util.concurrent.CompletableFuture;
+import java.util.function.BiConsumer;
+import java.util.stream.Collectors;
+
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+
+import org.apache.cassandra.db.marshal.BytesType;
+import org.apache.cassandra.db.marshal.ListType;
+import org.apache.cassandra.db.rows.ArrayCell;
+import org.apache.cassandra.db.rows.BufferCell;
+import org.apache.cassandra.db.rows.Cell;
+import org.apache.cassandra.db.rows.CellPath;
+import org.apache.cassandra.db.rows.NativeCell;
+import org.apache.cassandra.schema.ColumnMetadata;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.utils.ObjectSizes;
+import org.apache.cassandra.utils.UUIDGen;
+import org.apache.cassandra.utils.concurrent.OpOrder;
+import org.apache.cassandra.utils.memory.NativeAllocator;
+import org.apache.cassandra.utils.memory.NativePool;
+import org.assertj.core.api.Assertions;
+
+import static org.apache.cassandra.utils.ByteBufferUtil.bytes;
+
+@RunWith(Parameterized.class)
+public class CellSpecTest
+{
+    private final Cell<?> cell;
+
+    public CellSpecTest(String ignoreOnlyUsedForBetterTestName, Cell<?> cell)

Review comment:
       nit: could always throw a `@SuppressWarnings(""unused"")` in there

##########
File path: src/java/org/apache/cassandra/utils/ObjectSizes.java
##########
@@ -133,6 +134,16 @@ public static long sizeOnHeapExcludingData(ByteBuffer buffer)
         return BUFFER_EMPTY_SIZE;
     }
 
+    public static long sizeOfEmptyHeapByteBuffer()
+    {
+        return BUFFER_EMPTY_SIZE;
+    }

Review comment:
       Not directly related to your patch, but it seems a bit misleading that `sizeOnHeapExcludingData()` takes an argument. Perhaps it would be better to be explicit and just remove it, replacing current usages w/ your new `sizeOfEmptyHeapByteBuffer()` method.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Aug/21 15:14;githubbot;600","smiklosovic closed pull request #1176:
URL: https://github.com/apache/cassandra/pull/1176


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:39;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,4200,,,0,4200,,,,,,,,,,,,,,CASSANDRA-17402,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> API / Semantic Implementation,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Aug 30 23:44:22 UTC 2021,,,,,,,All,,,,"0|z0ufcw:",9223372036854775807,,,,maedhroz,,,,Normal,,4.0.0,,https://github.com/apache/cassandra/commit/39a3054950c16f6ca9bdaf45a3a74e4267541df0,,,,,,,,,added tests,,,,,"30/Aug/21 21:00;maedhroz;[~dcapwell] I'm about ready to just say LGTM on this, but there is one thing that might be worth clarifying...

If the behavior we want from the {{unsharedHeapSizeExcludingData()}} methods of {{ArrayCell}} and {{BufferCell}} is that they take nothing from the {{value}} field other than the size of its reference, things are fine as they are. The only thing we might want to do is remove the {{ObjectSizes#sizeOnHeapExcludingData()}} method and use your new {{sizeOfEmptyHeapByteBuffer()}} instead.

On the other hand, if that isn't what was originally intended (and the {{ByteBuffer}} argument on {{sizeOnHeapExcludingData()}} makes me wonder), then we'd have to figure out what's going on. I think the argument is just an oversight from a refactoring.;;;","30/Aug/21 21:02;maedhroz;Yeah, the {{ByteBuffer}} argument looks like it was just not cleaned up in CASSANDRA-5549.

+1;;;","30/Aug/21 23:44;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|cassandra-4.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16900-cassandra-4.0-C57B47CC-812C-45A3-8CDE-0D458BAF7BF0]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16900-cassandra-4.0-C57B47CC-812C-45A3-8CDE-0D458BAF7BF0]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1084/]|
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16900-trunk-C57B47CC-812C-45A3-8CDE-0D458BAF7BF0]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16900-trunk-C57B47CC-812C-45A3-8CDE-0D458BAF7BF0]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1085/]|
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The clustering order logic in Materialized view creation changed in 4.0,CASSANDRA-16898,13398226,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,blerer,blerer,30/Aug/21 13:19,16/Mar/22 16:42,13/Jul/23 08:40,31/Aug/21 15:05,4.0.2,,,,,,,Feature/Materialized Views,,,,0,,,"Before 4.0, when a Materialized view was created with no {{CLUSTERING ORDER}} specified the clustering order was based on the base table clustering order (see [3.11 code|https://github.com/apache/cassandra/blob/cassandra-3.11/src/java/org/apache/cassandra/cql3/statements/CreateViewStatement.java#L108]). In 4.0 this behaviour changed and the clustering order was defaulted to ASC for all columns. ",,blerer,jasonstack,,,,,,,,,,,,,,"smiklosovic closed pull request #1175:
URL: https://github.com/apache/cassandra/pull/1175


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:42;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,CASSANDRA-12734,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Aug 31 15:05:49 UTC 2021,,,,,,,All,,,,"0|z0uf1s:",9223372036854775807,,,,jasonstack,,,,Low,,4.0-rc1,,https://github.com/apache/cassandra/commit/af17f136e58910fa23f1b8c6b8f13de62787e823,,,,,,,,,The patch add additional unit tests,,,,,"30/Aug/21 14:59;blerer;|| Branch || CI ||
| [PR|https://github.com/apache/cassandra/pull/1175] | [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/190/workflows/e5f4d1a7-4c7c-43ff-a20b-111ca209e3cb] [j11|https://app.circleci.com/pipelines/github/blerer/cassandra/190/workflows/9c18ded2-e9fe-497c-acb2-bc565e45dc5e] |;;;","31/Aug/21 02:55;jasonstack;LGTM, thanks for the fix;;;","31/Aug/21 15:05;blerer;Committed into cassandra-4.0 at af17f136e58910fa23f1b8c6b8f13de62787e823 and merged into trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove duplicate 'lib.download.sha' entries in build-resolver.xml,CASSANDRA-16897,13398225,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mck,mck,mck,30/Aug/21 13:18,30/Aug/21 19:49,13/Jul/23 08:40,30/Aug/21 19:49,3.11.12,,,,,,,Build,,,,0,,,"As reported by [~jasonstack] [here|https://the-asf.slack.com/archives/CK23JSY2K/p1630325518017000].",,jasonstack,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,mck,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Aug 30 19:49:59 UTC 2021,,,,,,,All,,,,"0|z0uf1k:",9223372036854775807,,,,jasonstack,,,,Normal,,3.11.12,,https://github.com/apache/cassandra/commit/1038f4489a141d0660f114fdfa632b627ae73678,,,,,,,,,CI,,,,,"30/Aug/21 13:23;mck;patch: https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/16897/3.11

[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1080/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1080/];;;","30/Aug/21 13:35;jasonstack;thanks for the fix;;;","30/Aug/21 19:49;mck;Committed as [1038f4489a141d0660f114fdfa632b627ae73678|https://github.com/apache/cassandra/commit/1038f4489a141d0660f114fdfa632b627ae73678].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flakiness in upgrade_tests/thrift_upgrade_test.py in dtests,CASSANDRA-16892,13397781,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stefan.miklosovic,stefan.miklosovic,stefan.miklosovic,27/Aug/21 10:59,01/Jun/23 14:36,13/Jul/23 08:40,06/Sep/21 07:12,NA,,,,,,,Test/dtest/python,,,,0,,,"I noticed that tests for dtest in upgrade_tests/thrift_upgrade_test.py are flaky.

The reason this flakiness happens is that we are stopping and starting a node too fast without waiting for its full initialisation and then next attempt to connect to rpc port fails and whole test fails.

The fix is rather easy, we just need to wait until it is full started.",,blerer,stefan.miklosovic,,,,,,,,,,,,,,"smiklosovic closed pull request #156: CASSANDRA-16892 wait for node to be available in upgrade tests for Thrift for dense and sparse supercolumn tests
URL: https://github.com/apache/cassandra-dtest/pull/156


;01/Jun/23 14:36;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,stefan.miklosovic,,,,,,,,,,,,,Code,,,,,,,,Low Hanging Fruit,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Sep 03 15:49:42 UTC 2021,,,,,,,All,,,,"0|z0ucaw:",9223372036854775807,,,,blerer,,,,Low,,NA,,https://github.com/apache/cassandra-dtest/commit/2ed526a43d3a37b00ada500a0354955fecf1e61c,,,,,,,,,https://github.com/apache/cassandra-dtest/pull/156,,,,,"03/Sep/21 15:49;blerer;I ran the patched {{upgrade_tests/thrift_upgrade_test.py}} using the repeated_upgrade_dtest runner 100 times and did not get any failure. Results are [here|https://app.circleci.com/pipelines/github/blerer/cassandra/195/workflows/a9c26e1f-01e6-4af5-84c3-a0314c08ed59].

The fix looks good. +1

Thanks for the patch [~stefan.miklosovic];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SSTableReaderTest#testGetPositionsKeyCacheStats failing sporadically on unexpected key cache hit for non-cached key,CASSANDRA-16888,13397652,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,maedhroz,maedhroz,maedhroz,26/Aug/21 21:08,27/May/22 19:25,13/Jul/23 08:40,09/Sep/21 19:14,4.0.2,4.1,4.1-alpha1,,,,,Local/Caching,,,,0,,,"This has started to pop up on 4.0.x and trunk builds in both CircleCI and Apache CI:

[https://app.circleci.com/pipelines/github/josh-mckenzie/cassandra/60/workflows/15e09ea4-4d35-4035-9afc-ff0d1089041e/jobs/382]

[https://app.circleci.com/pipelines/github/maedhroz/cassandra/332/workflows/3bd588d9-717f-4877-8e78-7a127180dfee/jobs/2093/tests#failed-test-0]


https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1067/testReport/junit/org.apache.cassandra.io.sstable/SSTableReaderTest/testGetPositionsKeyCacheStats_cdc/
 
It passes consistently in local runs, although I have seen one failure in about 10 runs.",,adelapena,brandon.williams,maedhroz,marcuse,,,,,,,,,,,,"maedhroz opened a new pull request #1192:
URL: https://github.com/apache/cassandra/pull/1192


   patch by Caleb Rackliffe; reviewed by XXX for CASSANDRA-16888


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Sep/21 16:58;githubbot;600","maedhroz opened a new pull request #1193:
URL: https://github.com/apache/cassandra/pull/1193


   patch by Caleb Rackliffe; reviewed by Marcus Eriksson for CASSANDRA-16888


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Sep/21 18:30;githubbot;600","maedhroz closed pull request #1192:
URL: https://github.com/apache/cassandra/pull/1192


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Sep/21 16:02;githubbot;600","maedhroz closed pull request #1193:
URL: https://github.com/apache/cassandra/pull/1193


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Sep/21 16:02;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,2400,,,0,2400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,maedhroz,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Sep 09 19:14:03 UTC 2021,,,,,,,All,,,,"0|z0ubig:",9223372036854775807,,,,marcuse,,,,Normal,,4.0.1,,https://github.com/apache/cassandra/commit/bc052fa68f525155246de498cc86bb192f2d479a,,,,,,,,,This patch fixes an existing test class.,,,,,"26/Aug/21 21:15;maedhroz;[~brandon.williams] No idea if it's related yet, but I think the most recent changes around this were for CASSANDRA-12922. I'll try to track this down in the next few days...;;;","26/Aug/21 21:19;brandon.williams;Hmm, I was mostly facilitating the commit there, ping [~blerer].;;;","26/Aug/21 23:36;adelapena;25 hits in 200 runs of the full test class with j8: [https://app.circleci.com/pipelines/github/adelapena/cassandra/807/workflows/67d4e4bf-a599-4fbb-a445-d600e10b10f5/jobs/7830]

 ;;;","09/Sep/21 16:07;maedhroz;What's interesting is that this test only seems to have been running since CASSANDRA-12922. There's also {{OrderedJUnit4ClassRunner}} in play here, so there might be some test state leakage that was papering over that's now a problem...;;;","09/Sep/21 17:16;maedhroz;patch (4.0): https://github.com/apache/cassandra/pull/1192
CircleCI: https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16888-4.0
trunk multiplexer run: https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=16888-trunk-with-fix;;;","09/Sep/21 17:21;maedhroz;The long story short here is that many of the tests in {{SSTableReaderTest}} share the same table(s), but there was not consistent removal of the SSTables from previous tests. That combined with partition key reuse, doomed the test in question here, since it could view an SSTable from {{testGetPositionsForRangesWithKeyCache()}}. Doing this also happens to remove the need to use {{OrderedJUnit4ClassRunner}}.;;;","09/Sep/21 17:24;marcuse;+1;;;","09/Sep/21 18:19;maedhroz;The multiplexer [likes is|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=16888-trunk-with-fix], so I think we're all set. Starting commit...;;;","09/Sep/21 19:14;maedhroz;4.0: https://github.com/apache/cassandra/commit/bc052fa68f525155246de498cc86bb192f2d479a
trunk: https://github.com/apache/cassandra/commit/b6b3be6d8aa79c5e74b0c0f197075fdc48e38287;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Weak visibility guarantees of Accumulator can lead to failure to recognize digest mismatches,CASSANDRA-16883,13397316,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,maedhroz,maedhroz,maedhroz,25/Aug/21 17:51,01/Sep/21 09:35,13/Jul/23 08:40,31/Aug/21 21:43,3.0.26,3.11.12,,,,,,Consistency/Coordination,,,,0,,,"The context for this problem is largely the same as CASSANDRA-16807. The difference is that for 4.0+, CASSANDRA-16097 added an assertion to {{DigestResolver#responseMatch()}} that ensures the responses snapshot has at least one visible element (although of course only one element trivially cannot generate a mismatch and short-circuits immediately). In 3.0 and 3.11, this assertion does not exist, and when the underlying problem occurs (i.e. zero responses are visible on {{Accumulator}} when there should be 2), we can silently avoid the digest matching entirely. This seems like it would make it both impossible to do a potentially necessary full data read to resolve the correct response and prevent repair.

The fix here should be similar to the one in CASSANDRA-16807, although there might be some test infrastructure that needs porting in order to make that work.",,jmeredithco,maedhroz,,,,,,,,,,,,,,"maedhroz commented on a change in pull request #1173:
URL: https://github.com/apache/cassandra/pull/1173#discussion_r697740846



##########
File path: src/java/org/apache/cassandra/service/ReadCallback.java
##########
@@ -158,7 +158,14 @@ public void response(MessageIn<ReadResponse> message)
         int n = waitingFor(message.from)
               ? recievedUpdater.incrementAndGet(this)
               : received;
-        if (n >= blockfor && resolver.isDataPresent())
+
+        /*
+         * Ensure that data is present and the response accumulator has properly published the
+         * responses it has received. This may result in not signaling immediately when we receive
+         * the minimum number of required results, but it guarantees at least the minimum will
+         * be accessible when we do signal. (see rdar://77320313)
+         */
+        if (n >= blockfor && resolver.responses.size() >= blockfor && resolver.isDataPresent())

Review comment:
       For reviewers: remove this line and run the attached test. You should eventually get an assertion error.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/Aug/21 22:01;githubbot;600","maedhroz closed pull request #1173:
URL: https://github.com/apache/cassandra/pull/1173


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Aug/21 21:41;githubbot;600","maedhroz commented on pull request #1173:
URL: https://github.com/apache/cassandra/pull/1173#issuecomment-909663475


   Committed as https://github.com/apache/cassandra/commit/f9d41ff83655ead37ac6083d7ee43f2c35a346da


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Aug/21 21:41;githubbot;600","maedhroz commented on pull request #1181:
URL: https://github.com/apache/cassandra/pull/1181#issuecomment-909663795


   Committed as https://github.com/apache/cassandra/commit/e5621184d86ac0c8d0c9870786c44baaadfb446a


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Aug/21 21:42;githubbot;600","maedhroz closed pull request #1181:
URL: https://github.com/apache/cassandra/pull/1181


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Aug/21 21:42;githubbot;600","maedhroz commented on pull request #1173:
URL: https://github.com/apache/cassandra/pull/1173#issuecomment-909663475


   Committed as https://github.com/apache/cassandra/commit/f9d41ff83655ead37ac6083d7ee43f2c35a346da


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Sep/21 09:13;githubbot;600","maedhroz closed pull request #1181:
URL: https://github.com/apache/cassandra/pull/1181


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Sep/21 09:27;githubbot;600","maedhroz closed pull request #1173:
URL: https://github.com/apache/cassandra/pull/1173


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Sep/21 09:33;githubbot;600","maedhroz commented on pull request #1181:
URL: https://github.com/apache/cassandra/pull/1181#issuecomment-909663795


   Committed as https://github.com/apache/cassandra/commit/e5621184d86ac0c8d0c9870786c44baaadfb446a


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Sep/21 09:35;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,5400,,,0,5400,,,,,,,,,,,,,,,CASSANDRA-16807,,,,,,,,,,,,,,,,,,,,,,,0.0,maedhroz,,,,,,,,,,,,,Correctness -> Consistency,,,,,,,,Normal,Fuzz Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Aug 31 21:43:03 UTC 2021,,,,,,,All,,,,"0|z0u9g0:",9223372036854775807,,,,jmeredithco,,,,Critical,,3.0.0,,https://github.com/apache/cassandra/commit/f9d41ff83655ead37ac6083d7ee43f2c35a346da,,,,,,,,,new unit test in {{DigestResolverTest}} covers the changes here,,,,,"27/Aug/21 21:17;maedhroz;Note that this will only merge up to 3.11, given CASSANDRA-16807 already solves the problem in 4.0+.;;;","27/Aug/21 21:58;maedhroz;||branch||Circle CI||Apache CI|
|[3.0|https://github.com/apache/cassandra/pull/1173]|[J8|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16883-3.0]|[1078|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1078/]|
|[3.11|https://github.com/apache/cassandra/pull/1181]|[J8|https://app.circleci.com/pipelines/github/maedhroz/cassandra/342/workflows/d6850818-6c5f-4427-9e63-f29a6bf17bd3]|[1088|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1088/]|

(This should be a pretty clean merge up to 3.11, and won't be necessary in 4.0.);;;","30/Aug/21 17:37;jmeredithco;+1 patch looks good, failures look unrelated.;;;","31/Aug/21 21:43;maedhroz;Committed as https://github.com/apache/cassandra/commit/f9d41ff83655ead37ac6083d7ee43f2c35a346da to {{cassandra-3.0}}.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
High priority internode messages which exceed the large message threshold are dropped,CASSANDRA-16877,13396738,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,samt,samt,samt,23/Aug/21 17:05,25/Aug/21 16:47,13/Jul/23 08:40,25/Aug/21 16:47,4.0.1,,,,,,,Cluster/Gossip,,,,0,,,"Currently, there is an assumption that internode messages whose verb has priority P0 will always fit within a single messaging frame. While this is usually the case, on occasion it is possible that this assumption does not hold. One example is gossip messages during the startup shadow round, where in very large clusters the digest ack can contain all states for every peer. In this scenario, the respondent fails to send the ack which may lead to the shadow round and, ultimately, the startup failing.
 
We could tweak the shadow round acks to minimise the message size, but a more robust solution would be to permit high priority messages to be sent on the large messages connection when necessary.",,e.dimitrova,jaid,maedhroz,mck,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,samt,,,,,,,,,,,,,Availability -> Process Crash,,,,,,,,Normal,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Aug 25 16:47:14 UTC 2021,,,,,,,All,,,,"0|z0u5vk:",9223372036854775807,,,,maedhroz,,,,Critical,,4.0-alpha1,,https://github.com/apache/cassandra/commit/b8242730918c2e8edec83aeafeeae8255378125d,,,,,,,,,New unit test in patch,,,,,"23/Aug/21 17:54;samt;This can be a fairly serious problem when cluster sizes run into hundreds of nodes. Following a restart, the shadow round can begin to fail as the respondants can't serialize the {{GossipDigestAck}}, leaving the sender unable to start. Even if the shadow round is skipped, the same problem often occurs when the starting node first sends a regular {{GossipDygestSyn}}. This may be an even worse scenario from an availability perspective as the restarted node will not establish contact with peers and will see the rest of the ring as down. 

The reason I didn't add more detail to the nospam log message is that doing so always feels to be of limited utility to me.  With nospam you're probably only seeing a tiny portion of the actual events, so you really need to enable the trace/debug logging anyway. If people have a strong opinion to the contrary though, I can always change this. 

||branch||Circle CI||Apache CI||
|[16877-4.0|https://github.com/beobal/cassandra/tree/16877-4.0]|[circle|https://circleci.com/gh/beobal/cassandra?branch=16877-4.0]|[apache|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1058]|
;;;","24/Aug/21 17:28;maedhroz;+1 w/ minor nits [here|https://github.com/beobal/cassandra/commit/045844bab6a175fe6c02d1398c3a33a81a0a2a9d#r55367210] and [here|https://github.com/beobal/cassandra/commit/045844bab6a175fe6c02d1398c3a33a81a0a2a9d#r55367841].

The couple test failures I see don't look related/appear in other live 4.0 branches.;;;","25/Aug/21 16:47;samt;Thanks. Agreed about the tests, so committed (with one nit addressed and one swerved) to 4.0 in {{b8242730918c2e8edec83aeafeeae8255378125d}} and merged up to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Handle empty TOC file when taking snapshots,CASSANDRA-16872,13396349,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,20/Aug/21 11:53,27/May/22 19:25,13/Jul/23 08:40,20/Sep/21 12:37,4.0.2,4.1,4.1-alpha1,,,,,Local/Snapshots,Local/Startup and Shutdown,,,0,,,"In some situations we can end up with empty TOC files during unclean shutdown, then, on startup we get an exception when trying to acquire 0 permits from the rate limiter",,ifesdjeen,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17604,,,,,,,,,CASSANDRA-10709,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Degradation -> Other Exception,,,,,,,,Low Hanging Fruit,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Sep 20 12:37:56 UTC 2021,,,,,,,All,,,,"0|z0u3h4:",9223372036854775807,,,,ifesdjeen,,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/b9d8700355bf0ecabe1ca7e3f139d0ad52c4bdc4,,,,,,,,,Test included in the patch,,,,,"20/Aug/21 12:25;marcuse;https://github.com/krummas/cassandra/commits/marcuse/16872
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16872;;;","10/Sep/21 13:23;ifesdjeen;+1, thank you for the patch

RateLimiter was a 4.0 addition, so this only applies to 4.0 and trunk.;;;","20/Sep/21 12:37;marcuse;and committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Secondary indexes on primary key columns can miss some writes,CASSANDRA-16868,13396094,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,adelapena,adelapena,19/Aug/21 11:17,27/May/22 19:25,13/Jul/23 08:40,24/Aug/21 17:22,3.0.26,3.11.12,4.0.1,4.1,4.1-alpha1,,,Feature/2i Index,,,,0,,,"Secondary indexes on primary key columns can miss some writes. For example, an update after a deletion won't create an index entry:
{code:java}
CREATE TABLE t (pk int, ck int, v int, PRIMARY KEY (pk, ck));
CREATE INDEX ON t(ck);
INSERT INTO t(pk, ck, v) VALUES (1, 2, 3); -- creates an index entry (right)
DELETE FROM t WHERE pk = 1 AND ck = 2; -- deletes the previous index entry (right)
UPDATE t SET v = 3 WHERE pk = 1 AND ck = 2; -- doesn't create a new index entry (wrong)
SELECT * FROM t WHERE ck = 2; -- doesn't find the row (wrong)
{code}
This happens because the update uses the {{LivenssInfo}} of the previously deleted row (see [here|https://github.com/apache/cassandra/blob/cassandra-3.0.25/src/java/org/apache/cassandra/index/internal/CassandraIndex.java#L439]). The same happens when updating an expired row:
{code:java}
CREATE TABLE t (pk int, ck int, v int, PRIMARY KEY (pk, ck));
CREATE INDEX ON t(ck);
UPDATE t USING TTL 1 SET v = 3 WHERE pk = 1 AND ck = 2; -- creates a non-expiring index entry (right)
-- wait for the expiration of the above row
SELECT * FROM t WHERE ck = 2; -- deletes the index entry (right)
UPDATE t SET v = 3 WHERE pk = 1 AND ck = 2; -- doesn't create an index entry (wrong)
SELECT * FROM t WHERE ck = 2; -- doesn't find the row (wrong)
{code}
I think that the fix for this is just using the {{getPrimaryKeyIndexLiveness}} in {{updateRow}}, as it's used in {{insertRow}}.

Another related problem is that {{getPrimaryKeyIndexLiveness}} uses [the most recent TTL in the columns contained on the indexed row fragment|https://github.com/apache/cassandra/blob/cassandra-3.0.25/src/java/org/apache/cassandra/index/internal/CassandraIndex.java#L519] as the TTL of the index entry, producing an expiring index entry that ignores the columns without TTL that are already present in flushed sstables. So we can find this other error when setting a TTL over flushed indexed data:
{code:java}
CREATE TABLE t(k1 int, k2 int, v int, PRIMARY KEY ((k1, k2)));
CREATE INDEX idx ON t(k1);
INSERT INTO t (k1, k2, v) VALUES (1, 2, 3);
-- flush
UPDATE t USING TTL 1 SET v=0 WHERE k1=1 AND k2=2; -- creates an index entry with TTL (wrong)
-- wait for TTL expiration
SELECT TTL(v) FROM t WHERE k1=1; -- doesn't find the row (wrong)
{code}
The straightforward fix is just ignoring the TTL of the columns for indexes on primary key components, so we don't produce expiring index entries in that case. The index entries will be eventually deleted during index reads, when we are sure that they are not pointing to any live data.
  ",,adelapena,blerer,,,,,,,,,,,,,,"adelapena closed pull request #1157:
URL: https://github.com/apache/cassandra/pull/1157


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:47;githubbot;600","adelapena closed pull request #1156:
URL: https://github.com/apache/cassandra/pull/1156


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:47;githubbot;600","adelapena closed pull request #1155:
URL: https://github.com/apache/cassandra/pull/1155


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:47;githubbot;600","adelapena closed pull request #1158:
URL: https://github.com/apache/cassandra/pull/1158


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:48;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,2400,,,0,2400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Correctness -> Recoverable Corruption / Loss,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Aug 24 17:19:15 UTC 2021,,,,,,,All,,,,"0|z0u1wg:",9223372036854775807,,,,blerer,,,,Normal,,3.0 alpha 1,,https://github.com/apache/cassandra/commit/c76ff1ba14487d521c49d4b830b2d718d170b2e1,,,,,,,,,The PR contains unit tests for the problematic use cases,,,,,"19/Aug/21 12:06;adelapena;||PR||CI||
|[3.0|https://github.com/apache/cassandra/pull/1155]​|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/783/workflows/954778ef-199d-451b-adeb-cd4c03e0d922]​|
|[3.11|https://github.com/apache/cassandra/pull/1157]​|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/784/workflows/abcc7cef-3cdb-419d-940c-df745f8fa66f]​|
|[4.0|https://github.com/apache/cassandra/pull/1156]​|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/785/workflows/299ead54-3f33-4dca-a2a0-851cb33c7755] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/785/workflows/38cc77a3-9a76-4392-98c7-1bccb04bcd33]​|
|[trunk|https://github.com/apache/cassandra/pull/1158]​|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/786/workflows/cce0fcd3-fb70-444a-9965-7cf015e8a9b8] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/786/workflows/b218de99-b598-4f2d-bbf1-c8c21476e6f8]​|;;;","20/Aug/21 14:16;blerer;Thanks for all the extra testing :-). The patches look good. ;;;","24/Aug/21 17:19;adelapena;Thanks for the review :)

Committed to 3.0 as [c76ff1ba14487d521c49d4b830b2d718d170b2e1|https://github.com/apache/cassandra/commit/c76ff1ba14487d521c49d4b830b2d718d170b2e1] and merged into [3.11|https://github.com/apache/cassandra/commit/0c38f9dfb8d66d2de2cbde2aadbd03105f411a0d], [4.0|https://github.com/apache/cassandra/commit/31ce794d588618a62b2cf1ed222e13bd62dcd2c3] and [trunk|https://github.com/apache/cassandra/commit/5dd472e943f237fa86a06d077a27d704c09996db].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky test DatabaseDescriptorRefTest,CASSANDRA-16862,13395766,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,azotcsit,e.dimitrova,e.dimitrova,17/Aug/21 22:07,27/May/22 19:25,13/Jul/23 08:40,20/Sep/21 21:18,3.11.12,4.0.2,4.1,4.1-alpha1,,,,CI,,,,0,,,"While working on another ticket I found out that DatabaseDescriptorRefTest is failing consistently locally for me and one more community member on 3.11, 4.0 and trunk.


{code:java}
 java.lang.AssertionError: thread started in clientInitialization 
Expected :5
Actual   :8
<Click to see difference>


	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.apache.cassandra.config.DatabaseDescriptorRefTest.testDatabaseDescriptorRef(DatabaseDescriptorRefTest.java:285)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:221)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54)
{code}
",,azotcsit,e.dimitrova,jmeredithco,sumanth.pasupuleti,,,,,,,,,,,,"ekaterinadimitrova2 commented on a change in pull request #1212:
URL: https://github.com/apache/cassandra/pull/1212#discussion_r712211212



##########
File path: test/unit/org/apache/cassandra/config/DatabaseDescriptorRefTest.java
##########
@@ -176,13 +177,15 @@
     static final Set<String> checkedClasses = new HashSet<>(Arrays.asList(validClasses));
 
     @Test
+    @SuppressWarnings({""DynamicRegexReplaceableByCompiledPattern"", ""UseOfSystemOutOrSystemErr""})
     public void testDatabaseDescriptorRef() throws Throwable
     {
         PrintStream out = System.out;
         PrintStream err = System.err;
 
         ThreadMXBean threads = ManagementFactory.getThreadMXBean();
         int threadCount = threads.getThreadCount();
+        List<Long> existingThreadids = Arrays.stream(threads.getAllThreadIds()).boxed().collect(Collectors.toList());

Review comment:
       nit: `existingThreadIds` or `existingThreadIDs`




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Sep/21 14:43;githubbot;600","alex-ninja closed pull request #1212:
URL: https://github.com/apache/cassandra/pull/1212


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Sep/21 21:20;githubbot;600","alex-ninja commented on pull request #1212:
URL: https://github.com/apache/cassandra/pull/1212#issuecomment-923320051


   Merged as https://github.com/apache/cassandra/commit/e9645cc7a4e189b58eb0ba20269dfaec9b46da29.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Sep/21 21:21;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,azotcsit,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Sep 20 21:17:20 UTC 2021,,,,,,,All,,,,"0|z0tzvk:",9223372036854775807,,,,e.dimitrova,jonmeredith,,,Low,,,,https://github.com/apache/cassandra/commit/876f7b05914a68ae314e5e420667272cf4415cf9,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16862?focusedCommentId=17416550&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17416550,,,,,"17/Aug/21 23:07;jmeredithco;It might behave differently when run inside an IDE rather than with {{ant}}. I think I've hit that before.  Does this pass for you?

{noformat}
ant testclasslist -Dtest.classlistprefix=unit -Dtest.classlistfile=<(echo org/apache/cassandra/config/DatabaseDescriptorRefTest.java)

{noformat}
;;;","18/Aug/21 00:27;e.dimitrova;Yes, that works actually. I am surprised because I am 100% sure that some time ago I was working on that class and everything was passing(in the IDE). Also, it was failing for two of us but not for [~brandon.williams]. [~brandonwilliams], did you actually run it from IDE or the command line?

Do you know what is the reason so I can add a comment in the test for example? For others so they don't troubleshoot and raise tickets :D And thank you for the quick response, appreciate it :) ;;;","18/Aug/21 00:29;brandon.williams;I never run from the IDE. :) I guess I should have clarified that before.;;;","18/Aug/21 15:05;jmeredithco;It fails for me from inside IDEA

{noformat}
java.lang.AssertionError: thread started in clientInitialization 
Expected :6
Actual   :9

{noformat}

however this also passes for me

{code}
ant testsome -Dtest.name=org.apache.cassandra.config.DatabaseDescriptorRefTest -Dtest.method=testDatabaseDescriptorRef
{code}

I suspect the issue is test runner setup for the fancy IDE.  I wonder if it's possible to detect running outside of the regular ant runner and just skip the test in that case, though I'm interested if others can reproduce [~brandon.williams]'s failure.;;;","18/Aug/21 16:07;brandon.williams;bq. reproduce Brandon Williams's failure.

I think you misunderstood, I'm the one who doesn't run it in an IDE and it doesn't fail for me. :);;;","23/Aug/21 09:37;sumanth.pasupuleti;fwiw, the test passes successfully for me, when I try it both from my IDE (idea) and from command line.;;;","15/Sep/21 10:30;azotcsit;JFYI.

The test passed via {{ant}}, however, failed in IDE:
{code:java}
java.lang.AssertionError: thread started in clientInitialization 
Expected :5
Actual   :8
{code}
Environment:
 * Intellij Idea 2021.2.2
 * JDK 8u281
 * Ant 1.10.10
 * Ubuntu 20.04;;;","17/Sep/21 08:47;azotcsit;[~e.dimitrova] [~brandon.williams] [~sumanth.pasupuleti]

I've taken a look to the test a bit closer and here is what I can see:
 # it sometimes (once per ~15 runs) passes in Intellij in ""run"" mode
 # it always passes in Intellij in ""debug"" mode
 # the problem is caused by ""Attach Listener"" which is related to [Dynamic Attach|http://openjdk.java.net/groups/hotspot/docs/Serviceability.html] feature of JVM
 # if I add {{-XX:+DisableAttachMechanism}} parameter then the test always pass in Intellij in ""run"" mode

Conclusion:
 # the test works in ""debug"" mode because Intellij attaches to JVM though an agentlib, not through ""Dynamic Attach"":
{code:java}-agentlib:jdwp=transport=dt_socket,address=127.0.0.1:59053,suspend=y,server=n{code}
This is parameter is the only difference between ""run"" and ""debug"" configuration
 # the issue is caused by IDE (Intellij in my case) which tries to attach to the JVM. I found no details on how to disable such a behavior in Intellij for ""run"" mode.
 # {{ant}} works fine because no process tries to attach to JVM

I came up with a fix and here is the summary of changes:
 # started ignoring ""Attach Listener"" thread
 # started ignoring Logback-related threads by names instead of having assumption that two additional threads are always Logback-related
 # started filtering out multiple Logback basic threads (while debugging the problem I mentioned that sometimes two threads _logback-1_ and _logback-2_ are spawned)
 # fixed warnings

Here are the patches:
 * [3.11|https://github.com/alex-ninja/cassandra/commit/5bf8f1debfd547b5c8e613b294b50ea8f56a3367]
 * [4.0|https://github.com/alex-ninja/cassandra/commit/c7de42d70dd28bbc9049286f9db7f8b3fb2f6b7d]
 * [trunk|https://github.com/alex-ninja/cassandra/commit/683fea50002694bce27b3b687194f5db3ef11fd1]

Could you please review them and try out on your local machines. ;;;","17/Sep/21 13:33;brandon.williams;Nice detective work!  On the surface this all makes sense to me, but I will leave review to someone who has experienced this issue.;;;","17/Sep/21 13:48;e.dimitrova;Moved it to Patch available, I will look at it later. Thanks!!;;;","17/Sep/21 18:09;e.dimitrova;I'll look at it and test. Marking as ""NEEDS COMMITTER"" in the meantime as we need second reviewer committer. ;;;","20/Sep/21 14:55;e.dimitrova;Tested the latest trunk version and it looks good. Good catch!
CircleCI didn't show issues, also I tested manually:
- once and multiple times run in Intellij
- once and multiple times run in debug mode Intellij
- once and multiple times with code coverage in Intellij
- also nothing changed around ant 
I think we need the patch on all other branches and a second committer. Thank you!;;;","20/Sep/21 15:02;azotcsit;Thanks for testing the changes [~e.dimitrova]! I updated all the branches:
 * [https://github.com/apache/cassandra/compare/trunk...alex-ninja:cassandra-16862_db_descriptor_test-3.11]
 * [https://github.com/apache/cassandra/compare/trunk...alex-ninja:cassandra-16862_db_descriptor_test-4.0]
 * [https://github.com/apache/cassandra/compare/trunk...alex-ninja:cassandra-16862_db_descriptor_test-trunk]

 ;;;","20/Sep/21 17:21;e.dimitrova;Tested all branches, +1
[~jmeredithco], do you think you can check this one too? Should be quick, I promise :D ;;;","20/Sep/21 17:54;jmeredithco;Sure, I'll take a look.;;;","20/Sep/21 19:03;jmeredithco;Also tested 3.11, 4.0 and trunk under IDEA and on the command line with ant.

+1;;;","20/Sep/21 20:57;e.dimitrova;Thank you [~psynix@t-online.de] and [~azotcsit], I am going to commit the patch soon. ;;;","20/Sep/21 21:17;e.dimitrova;Committed:
To https://github.com/apache/cassandra.git
   8f4ae7d825..876f7b0591  cassandra-3.11 -> cassandra-3.11
   b9d8700355..4018084bf7  cassandra-4.0 -> cassandra-4.0
   bc348c9985..e9645cc7a4  trunk -> trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CircleCI MIDRES might be missing some changes in 3.11,CASSANDRA-16858,13395518,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,adelapena,adelapena,16/Aug/21 17:34,17/Aug/21 14:24,13/Jul/23 08:40,17/Aug/21 14:24,3.11.12,,,,,,,CI,,,,0,,,"I've noticed that when we run {{.circleci/generate.sh}} in 3.11 the file {{config.yml.MIDRES}} is modified, when I'd say it shouldn't be changed. If I'm right running that script should be noop when there hasn't been changes in {{config-2_1.yml}}, and indeed the file isn't modified in the other branches.

Not sure yet, but I think that this might be the result of not having generated a new {{config.yml.MIDRES}} with the script when merging 3.0 into 3.11 during CASSANDRA-16804.",,adelapena,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16804,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Aug 17 14:23:43 UTC 2021,,,,,,,All,,,,"0|z0tycg:",9223372036854775807,,,,e.dimitrova,,,,Low,,3.11.11,,https://github.com/apache/cassandra/commit/770dee5a57da96696b3df64384326786c0506762,,,,,,,,,"Running {{.circleci/generate.sh}} should not modify any file, and CircleCI should pass with MIDRES using the expected resources.",,,,,"16/Aug/21 17:39;adelapena;If I'm not missing something the fix should be as easy as regenerating {{config.yml.MIDRES}} with {{generate.sh}}, as it's done [here|https://github.com/apache/cassandra/blob/trunk/.circleci/config.yml.MIDRES].

[~edimitrova], wdyt?;;;","16/Aug/21 21:30;e.dimitrova;I don't recall whether I merged or regenerated the file as part of CASSANDRA-16804 but a quick test makes me think the same as you.

Seems like regenerating the file should do the magic. Thanks a lot, good catch!;;;","17/Aug/21 11:27;adelapena;Thanks for checking this. I assume we are ready to commit, or do you want to test anything else?;;;","17/Aug/21 13:08;e.dimitrova;I just pushed a Circle CI run with the regenerated file. It seems things are [going well|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1080/workflows/11fe255f-1ff1-4959-baf9-1e57ca546c6e] and I think we are more than ready to commit. Thank you!;;;","17/Aug/21 14:23;adelapena;Thanks for confirming it, committed to 3.11 as [770dee5a57da96696b3df64384326786c0506762|https://github.com/apache/cassandra/commit/770dee5a57da96696b3df64384326786c0506762].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prevent broken concurrent schema pulls,CASSANDRA-16856,13395388,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,16/Aug/21 05:27,27/May/22 19:25,13/Jul/23 08:40,19/Aug/21 05:45,3.11.12,4.0.1,4.1,4.1-alpha1,,,,Cluster/Gossip,,,,0,,,"There's a race condition around pulling schema changes, that can occur in case the schema changes push/propagation mechanism is not immediately effective (e.g. because of network delay, or because of the pulling node being down, etc.).

If schema changes happen on node 1, these changes do not reach node 2 immediately through the SCHEMA.PUSH mechanism, and are first recognized during gossiping, the corresponding SCHEMA.PULL request from node 2 can catch the node 1 schema in the middle of it being modified by another schema change request. This can easily lead to problems (e.g. if a new table is being added, and the node 2 request reads the changes that need to be applied to  system_schema.tables, but not the ones that need to be applied to system_schema.columns).

This PR addresses that by synchronizing the SCHEMA.PULL ""RPC call"" executed in node 1 by a request from node 2 with the method for applying schema changes in node 1.",,azotcsit,bereng,jmckenzie,maedhroz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16996,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Sep 28 05:29:15 UTC 2021,,,,,,,All,,,,"0|z0txjk:",9223372036854775807,,,,brandon.williams,,,,Normal,,3.11.x,,https://github.com/apache/cassandra/commit/23b61a5fa1de17cc6b8a1d7c300053160bfc728a,,,,,,,,,See PR,,,,,"18/Aug/21 12:38;brandon.williams;+1;;;","24/Sep/21 05:51;maedhroz;I've been looking at the 4.0 & trunk versions of this patch, and I'm having a hard time putting things together in my head. Reading the description above, it seems like the approach was going to be a.) synchronize {{SchemaKeyspace.convertSchemaToMutations()}}, effectively serializing requests handled by {{SchemaPullVerbHandler}} and b.) synchronize {{SchemaKeyspace.applyChanges()}} (I'm guessing?), which is where mutations to the schema keyspace are actually applied. In other words, the idea was to not allow concurrent reads and writes on the state protected by {{SchemaKeyspace}}. (Would we also need to synchronize {{truncate()}} and {{saveSystemKeyspacesSchema()}}?)

It seems like only ""a"" was done here and not ""b"", and the attached test is sort of just a trip-wire for if anyone ever tries to remove the monitor lock.

CC [~bereng] [~brandon.williams];;;","25/Sep/21 08:34;azotcsit;{{applyChanges}} is used from synchronized sections in {{Schema}} and that helps to prevent issues related to concurrent schema updates, but does not seem to handle ""read during write"" use case as [~maedhroz] correctly pointed. I'm not really well familiar with this codebase, but what Caleb suggested (including {{truncate}} and {{saveSystemKeyspacesSchema}}) makes sense to me.;;;","27/Sep/21 06:38;bereng;What you mention makes sense. The concurrent read/write path is not protected. I am going to open a ticket for these modification as this is not a part of the code I know inside out, where we'll be able to run tests. Let's cross fingers there are no exotic scenarios leading to some deadlock.

As per the junit this is the best we could came up with without going into a multinode/byteman craze that might end up not testing the actual path. It's better than nothing but suggestions welcomed.;;;","27/Sep/21 15:23;jmckenzie;bq. As per the junit this is the best we could came up with without going into a multinode/byteman craze that might end up not testing the actual path. It's better than nothing but suggestions welcomed.
I'd house the comment as to why the method is synchronized plus the link to the JIRA together rather than having the documentation of the reason only existing in the unit test. Seems like we'd have better cohesion on the ""this is here for a reason, understand that reason before modifying"" effort by doing so.;;;","27/Sep/21 18:23;maedhroz;Assuming the scenario in the description is something we arrived at simply via inspection...

{quote}
If schema changes happen on node 1, these changes do not reach node 2 immediately through the SCHEMA.PUSH mechanism, and are first recognized during gossiping, the corresponding SCHEMA.PULL request from node 2 can catch the node 1 schema in the middle of it being modified by another schema change request.
{quote}

...the goal of making access to schema via {{SchemaKeyspace}} atomic (in the sense that we won't expose partial schema changes) is reasonable. In terms of testing, I'd probably just start w/ a time-boxed fuzz test of {{SchemaKeyspace}} itself to reproduce atomicity violations, using that to verify the fix. (ex. {{DigestResolverTest#multiThreadedNoRepairNeededReadCallback()}})

(Even if there wasn't a catastrophic consequence to not changing this, having {{SchemaKeyspace}} expose some serial ordering of complete schema changes certainly reduces the possible states of the system to reason about other problems. Deadlock due to something like lock acquisition order doesn't seem like a worry here...);;;","28/Sep/21 05:29;bereng;[~maedhroz][~jmckenzie] the origin of this ticket is a multi-node fallout test that was failing to start some node bc of this reason.

[~jmckenzie] good point I can add the comment + ticket ref to all the places for clarity.

[~maedhroz] Brandon and I had a discussion on how to better test this. Besides the one you point out there was another dtest I played with that was also very re-usable. But in the end we had a worry: look at {{applyChanges()}} where the method itself is not synched but the paths that call it are. The worry being we'd be testing the call paths being synched but not the method itself being synched. Instantiating the class itself and mocking everything is 'not doable' within reason, the class is final and can't be extended, etc. So that junit is what I could come up with. And tbh I dislike both approaches: the one I did and going for a dtest. But I couldn't think of anything else. Maybe I am thinking too much about it.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testsome fails in the CircleCI multiplexer because the class JStackJUnitTask can't be found,CASSANDRA-16852,13394971,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,e.dimitrova,e.dimitrova,12/Aug/21 21:49,10/Nov/21 15:47,13/Jul/23 08:40,16/Aug/21 17:03,3.0.26,3.11.12,,,,,,CI,,,,0,,,"As [~adelapena] explained on [CASSANDRA-16827|https://issues.apache.org/jira/browse/CASSANDRA-16827?focusedCommentId=17398060&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17398060], the problem might be in the flag _-Dno-build-test=true_ that the multiplexer uses to not run _build-test_ in every iteration, relying on that this has already been  done by the build task. This is a performance optimisation that can be especially effective in fast tests.
It would be ideal to have the initial multiplexer behavior restored, but we can always run _ant build-test_ at the beginning of every multiplexer runner while still not running it on every iteration. This seems enough to keep the multiplexer working but it requires some extra builds and therefore higher costs.

The goal of this ticket is to find the root of this failure and fix the multiplexer either by restoring its initial flow or adding _ant build-test_ at the beginning of every multiplexer runner, if there is no more effective solution. ",,adelapena,e.dimitrova,,,,,,,,,,,,,,"adelapena closed pull request #1138:
URL: https://github.com/apache/cassandra/pull/1138


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:47;githubbot;600","adelapena closed pull request #1139:
URL: https://github.com/apache/cassandra/pull/1139


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:47;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16836,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Aug 16 17:02:32 UTC 2021,,,,,,,All,,,,"0|z0tuyw:",9223372036854775807,,,,e.dimitrova,,,,Low,,3.0.25,,https://github.com/apache/cassandra/commit/07706662104fd7d471379a5ba1155c7e4fb71618,,,,,,,,,We can test this by getting a successful utest multiplexer run,,,,,"12/Aug/21 22:51;e.dimitrova;For the record, there was a suggestion that this issue might be caused by CASSANDRA-16827 but testing shows that it existed before that. ;;;","13/Aug/21 00:41;e.dimitrova;Aaaand....ticket stolen :D I can do a review when you are done as I was already checking some stuff around too :-) ;;;","13/Aug/21 00:46;adelapena;I see that since CASSANDRA-16557 {{build-test}} is not a dependency of {{ant jar}} in neither 3.0 or 3.11, while it's still a dependency on 4.0 and trunk, where the multiplexer works smoothly.

The multiplexer relies on the CircleCI {{build}} job building the tests with a call to {{ant clean jar}}, so the runners can skip the {{build-test}} target. I haven't checked yet why {{build-test}} was removed from the {{jar}} dependencies, but my initial guess is that we can either restore it or run {{ant build-test}} in the CircleCI workflow. The later can be done either in the {{build}} job or in the {{run_repeated_utest}} job.;;;","13/Aug/21 00:49;adelapena;bq. Aaaand....ticket stolen  I can do a review when you are done as I was already checking some stuff around too 
Oh, I wrote my last comment without reading yours. ;;;","13/Aug/21 00:58;adelapena;I think the problem can be reproduced locally by running something like:
{code:java}
ant realclean jar
ant  testsome -Dtest.name=org.apache.cassandra.cql3.ViewTest -Dtest.methods=testNonExistingOnes -Dno-build-test=true
{code}
That reproduces the action of the {{build}} and {{run_repeated_utest}} CircleCI jobs, and it only works if {{build-test}} is a dependency of {{jar}}, as it is in 4.0 and trunk but not in 3.0 and 3.11 since, I think, CASSANDRA-16557.;;;","13/Aug/21 13:31;adelapena;It seems we can't easily add {{build-test}} to {{jar}}, since it would produce a circular dependency. Instead, I have simply added {{build-test}} as a target of the Ant command in the {{build}} CircleCI job:
||PR||CI||
|[3.0|https://github.com/apache/cassandra/pull/1138]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/776/workflows/466c5fec-2fcf-4282-bd51-4320bda6a680]|
|[3.11|https://github.com/apache/cassandra/pull/1139]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/775/workflows/f1e4e4ae-8819-42eb-8027-4b4d23f2a780]|

That seems enough to get the multiplexer back into shape. Note that the failure in {{j8_repeated_utest}} for 3.0 is a timeout not related to our build problem.

By the way, independently to this fix we might at some point consider using {{-Dno-build-test=true}} with other test jobs to save some resources, even if it doesn't have as much impact as in the multiplexer.;;;","13/Aug/21 22:19;e.dimitrova;LGTM,  thank you!;;;","13/Aug/21 22:21;e.dimitrova;{quote}By the way, independently to this fix we might at some point consider using -Dno-build-test=true with other test jobs to save some resources, even if it doesn't have as much impact as in the multiplexer.
{quote}
SGTM, let's open another ticket, thanks;;;","16/Aug/21 17:02;adelapena;Thanks for the review, committed to 3.0 as [07706662104fd7d471379a5ba1155c7e4fb71618|https://github.com/apache/cassandra/commit/07706662104fd7d471379a5ba1155c7e4fb71618] and merged to [3.11|https://github.com/apache/cassandra/commit/1482ead465a651f6ed7d694f081a128613d2dfd0].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Latest docker testing image (20210809) does not default support TLSv1 and TLSv1.1,CASSANDRA-16848,13394888,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mck,mck,mck,12/Aug/21 11:51,27/May/22 19:25,13/Jul/23 08:40,13/Aug/21 21:46,4.0.1,4.1,4.1-alpha1,,,,,CI,Test/dtest/java,,,0,,,"Since deployment of the latest docker testing image (20210809), ci-cassandra.a.o is failing a few [tests|https://ci-cassandra.apache.org/job/Cassandra-trunk-jvm-dtest/833], e.g.:

* SSTableLoaderEncryptionOptionsTest.bulkLoaderCannotAgreeOnClientTLSProtocol
* NativeTransportEncryptionOptionsTest.negotiatedProtocolMustBeAcceptedProtocolTest
* InternodeEncryptionOptionsTest.negotiatedProtocolMustBeAcceptedProtocolTest


Looking at the [logs|https://ci-cassandra.apache.org/job/Cassandra-trunk-jvm-dtest/lastSuccessfulBuild/jdk=jdk_1.8_latest,label=cassandra,split=8/testReport/junit/org.apache.cassandra.distributed.test/SSTableLoaderEncryptionOptionsTest/bulkLoaderCannotAgreeOnClientTLSProtocol/], the in-jvm node is starting up with
{noformat}
JdkSslContext.java:97 - Default protocols (JDK): [TLSv1.2] 
{noformat}

Running the test locally works, and the matching line is
{noformat}
JdkSslContext.java:97 - Default protocols (JDK): [TLSv1.2, TLSv1.1, TLSv1]
{noformat}

The docker image is using {{openjdk version ""1.8.0_282""}}.

Upgrading and using {{1.8.0_302}} locally reproduces the failure.",,bereng,brandon.williams,e.dimitrova,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,mck,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Aug 16 05:15:55 UTC 2021,,,,,,,All,,,,"0|z0tugg:",9223372036854775807,,,,brandon.williams,,,,Normal,,4.0.0,,https://github.com/apache/cassandra-builds/commit/d1a3a0c59b3c5c17697d6a6656cd5d4f3a1cdbe9,,,,,,,,,CI,,,,,"12/Aug/21 11:54;mck;https://senthilnayagan.medium.com/tlsv1-and-tlsv1-1-protocols-disabled-by-default-in-javas-latest-patch-released-on-april-20-2021-52c309f6b16d;;;","12/Aug/21 13:00;brandon.williams;Do we know what the problem is here?  On the surface it seems like everything should just use 1.2, and the [sstableloader test requires it.|https://github.com/apache/cassandra/blob/trunk/test/distributed/org/apache/cassandra/distributed/test/SSTableLoaderEncryptionOptionsTest.java#L60];;;","12/Aug/21 13:12;mck;At least for the two other failures, if we are to continue testing TLSv1 and TLSv1.1, then we need to update the java.security configuration file in the docker image. Given that users can still use TLSv1 and TLSv1.1 (older JDKs or adjusting the java.security file), I would think it makes sense to keep the tests for now.;;;","12/Aug/21 13:19;brandon.williams;That all makes sense. I am still not sure how the loader test is failing since it only uses 1.2 though.;;;","13/Aug/21 19:32;mck;Patch at https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:mck/16848

[!https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-mck/4/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-mck/4/];;;","13/Aug/21 19:34;brandon.williams;+1;;;","13/Aug/21 21:46;mck;Committed as [d1a3a0c59b3c5c17697d6a6656cd5d4f3a1cdbe9|https://github.com/apache/cassandra-builds/commit/d1a3a0c59b3c5c17697d6a6656cd5d4f3a1cdbe9].;;;","16/Aug/21 05:15;bereng;The fix looks good on 4.0 but trunk now is OOM'ing on a few of these tests. How weird... #justfyi;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nodetool assassinate of a node that failed bootstrap may lead to IndexOutOfBoundsException,CASSANDRA-16847,13394811,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,flightc,flightc,12/Aug/21 03:40,08/Sep/21 16:56,13/Jul/23 08:40,08/Sep/21 16:56,3.11.12,4.0.2,,,,,,Cluster/Gossip,Cluster/Membership,Consistency/Bootstrap and Decommission,,0,,,"User [Yorick|https://the-asf.slack.com/team/U026YMYS2QN] reported on ASF Slack that a node which failed to bootstrap is stuck in {{hibernate}} status and persists in {{gossipinfo}}:
{noformat}
/10.x.x.108
  generation:1625493756
  heartbeat:86
  STATUS:2:hibernate,true
  LOAD:79:96124.0
  SCHEMA:14:59adb24e-f3cd-3e02-97f0-5b395827453f
  DC:10:DC1
  RACK:12:RAC3
  RELEASE_VERSION:6:3.11.10
  INTERNAL_IP:8:10.x.x.108
  RPC_ADDRESS:5:10.x.x.108
  NET_VERSION:3:11
  HOST_ID:4:5b254d51-fc58-4ca2-856f-fe7878752131
  TOKENS:1:<hidden> {noformat}
Attempts to assassinate the node returns {{IndexOutOfBoundsException}}:
{noformat}
ERROR [GossipStage:1] 2021-08-11 09:10:03,440 CassandraDaemon.java:244 - Exception in thread Thread[GossipStage:1,5,main]
java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
        at java.util.ArrayList.rangeCheck(ArrayList.java:659) ~[na:1.8.0_292]
        at java.util.ArrayList.get(ArrayList.java:435) ~[na:1.8.0_292]
        at com.google.common.collect.Iterables.get(Iterables.java:728) ~[guava-18.0.jar:na]
        at org.apache.cassandra.gms.VersionedValue$VersionedValueFactory.makeTokenString(VersionedValue.java:156) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.gms.VersionedValue$VersionedValueFactory.left(VersionedValue.java:178) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.gms.Gossiper.lambda$assassinateEndpoint$1(Gossiper.java:695) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_292]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_292]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_292]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_292]
        at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:84) [apache-cassandra-3.11.10.jar:3.11.10]
        at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_292] {noformat}",,adelapena,flightc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness -> Consistency,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Sep 08 16:56:26 UTC 2021,,,,,,,All,,,,"0|z0ttzc:",9223372036854775807,,,,adelapena,,,,Normal,,NA,,https://github.com/apache/cassandra/commit/5cdddcf393145b4fb794cc4a73391fad78f58bac,,,,,,,,,run CI,,,,,"12/Aug/21 16:24;brandon.williams;||Branch||Circle||Jenkins||
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16847]||[j8|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16847]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1015/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1015/pipeline]|
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16847-4.0]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16847-4.0], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16847-4.0]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1016/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1016/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16847-trunk]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16847-trunk], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16847-trunk]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1017/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1017/pipeline]|

This patch is originally by Robert Stupp and I've ported it here.
;;;","08/Sep/21 12:03;adelapena;Looks good to me, +1;;;","08/Sep/21 16:56;brandon.williams;Thanks.  Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ArrayClustering.unsharedHeapSize does not include the data so undercounts the heap size,CASSANDRA-16845,13394741,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,11/Aug/21 18:21,27/May/22 19:25,13/Jul/23 08:40,11/Aug/21 20:26,4.0.1,4.1,4.1-alpha1,,,,,Local/Memtable,,,,0,,,"We have two methods: unsharedHeapSize and unsharedHeapSizeExcludingData; for ArrayClustering they are basically the same as unsharedHeapSize does not include the data, which is a regression.",,bdeggleston,dcapwell,,,,,,,,,,,,,,"smiklosovic closed pull request #1134:
URL: https://github.com/apache/cassandra/pull/1134


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:31;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> API / Semantic Implementation,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Aug 11 19:40:23 UTC 2021,,,,,,,All,,,,"0|z0ttjs:",9223372036854775807,,,,bdeggleston,,,,Normal,,4.0.0,,https://github.com/apache/cassandra/commit/979ab72f4f2afe4a23654572cd804184fc0e2089,,,,,,,,,unit tests,,,,,"11/Aug/21 18:32;bdeggleston;+1;;;","11/Aug/21 19:40;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|cassandra-4.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16845-cassandra-4.0-08C68782-5D52-4F60-8B2D-812DB26F43E6]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16845-cassandra-4.0-08C68782-5D52-4F60-8B2D-812DB26F43E6]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/1009/]|
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
List snapshots of dropped tables,CASSANDRA-16843,13394563,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,paulo,jbrownEP,jbrownEP,11/Aug/21 06:21,27/May/22 19:25,13/Jul/23 08:40,29/Apr/22 22:03,4.1,4.1-alpha1,,,,,,Local/Snapshots,,,,0,,,"Auto snapshots from dropped tables don't seem to show up in {{nodetool listsnapshots}} (even though they do get cleared by {{nodetool clearsnapshot}}). This makes them kind of annoying to clean up, since you need to muck about in the data directory to find them.

Erick on the mailing list said that this seems to be an oversight and that clearsnapshot was fixed by [CASSANDRA-6418|https://issues.apache.org/jira/browse/CASSANDRA-6418].

I reproduced this both on 3.11.11 and 4.0.0.",,e.dimitrova,flightc,jbrownEP,manmagic3,paulo,smiklosovic,stefan.miklosovic,,,,,,,,,"pauloricardomg closed pull request #1305: CASSANDRA-16843: List snapshots of dropped tables
URL: https://github.com/apache/cassandra/pull/1305


;25/Apr/22 21:26;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861721986


##########
src/java/org/apache/cassandra/db/ColumnFamilyStore.java:
##########
@@ -2974,6 +2974,7 @@ public double getDroppableTombstoneRatio()
 
     public long trueSnapshotsSize()
     {
+

Review Comment:
   nit: this line can be deleted.



;29/Apr/22 11:36;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861726735


##########
src/java/org/apache/cassandra/db/Directories.java:
##########
@@ -1244,9 +1249,8 @@ private static String join(String... s)
     private class SSTableSizeSummer extends DirectorySizeCalculator
     {
         private final Set<String> toSkip;
-        SSTableSizeSummer(File path, List<File> files)
+        SSTableSizeSummer(List<File> files)
         {
-            super(path);
             toSkip = files.stream().map(f -> f.name()).collect(Collectors.toSet());

Review Comment:
   can be simplified by `map(File::name)`



;29/Apr/22 11:44;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861728211


##########
src/java/org/apache/cassandra/db/commitlog/CommitLogSegmentManagerCDC.java:
##########
@@ -274,9 +274,12 @@ private static class CDCSizeTracker extends DirectorySizeCalculator
         // track the total size between two dictionary size calculations
         private final AtomicLong sizeInProgress;
 
+        private final File path;
+
         CDCSizeTracker(CommitLogSegmentManagerCDC segmentManager, File path)
         {
-            super(path);
+            super();

Review Comment:
   why do we need this `super()` here to be called explicitly?



;29/Apr/22 11:47;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861729102


##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());

Review Comment:
   can be all simplified to `this.dataDirectories = Arrays.stream(dataDirs).map(Paths::get).collect(Collectors.toList());`



;29/Apr/22 11:48;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861729730


##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        if (!walked) {
+            for (Path dataDir : dataDirectories)
+            {
+                try
+                {
+                    Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+                }
+                catch (IOException e)
+                {
+                    throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+                }
+            }
+            walked = true;
+        }
+        return snapshots.values().stream().map(s -> s.build()).collect(Collectors.toSet());

Review Comment:
   I prefer method referencies here like ""TableSnapshot.Builder::build"" instead of `s -> s.build()`



;29/Apr/22 11:49;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861730307


##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        if (!walked) {
+            for (Path dataDir : dataDirectories)
+            {
+                try
+                {
+                    Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+                }
+                catch (IOException e)
+                {
+                    throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+                }
+            }
+            walked = true;
+        }
+        return snapshots.values().stream().map(s -> s.build()).collect(Collectors.toSet());
+    }
+
+    public FileVisitResult preVisitDirectory(Path subdir, BasicFileAttributes attrs)
+    {
+        if (subdir.getParent().getFileName().toString().equals(SNAPSHOT_SUBDIR))
+        {
+            logger.trace(""Processing directory "" + subdir);
+            Matcher snapshotDirMatcher = SNAPSHOT_DIR_PATTERN.matcher(subdir.toString());
+            if (snapshotDirMatcher.find())
+            {
+                try
+                {
+                    loadSnapshotFromDir(snapshotDirMatcher, subdir);
+                } catch (Throwable e)
+                {
+                    logger.warn(""Could not load snapshot from %s."", subdir, e);

Review Comment:
   IDEA says: ""More arguments provided (1) than placeholders specified (0) "". I think you forgot to String.format it.



;29/Apr/22 11:50;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861730641


##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        if (!walked) {
+            for (Path dataDir : dataDirectories)
+            {
+                try
+                {
+                    Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+                }
+                catch (IOException e)
+                {
+                    throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+                }
+            }
+            walked = true;
+        }
+        return snapshots.values().stream().map(s -> s.build()).collect(Collectors.toSet());
+    }
+
+    public FileVisitResult preVisitDirectory(Path subdir, BasicFileAttributes attrs)
+    {
+        if (subdir.getParent().getFileName().toString().equals(SNAPSHOT_SUBDIR))
+        {
+            logger.trace(""Processing directory "" + subdir);
+            Matcher snapshotDirMatcher = SNAPSHOT_DIR_PATTERN.matcher(subdir.toString());
+            if (snapshotDirMatcher.find())
+            {
+                try
+                {
+                    loadSnapshotFromDir(snapshotDirMatcher, subdir);
+                } catch (Throwable e)
+                {
+                    logger.warn(""Could not load snapshot from %s."", subdir, e);
+                }
+            }
+            return FileVisitResult.SKIP_SUBTREE;
+        }
+
+        return subdir.equals(Directories.BACKUPS_SUBDIR)

Review Comment:
   you are comparing Path with String here.



;29/Apr/22 11:51;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861731907


##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        if (!walked) {
+            for (Path dataDir : dataDirectories)
+            {
+                try
+                {
+                    Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+                }
+                catch (IOException e)
+                {
+                    throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+                }
+            }
+            walked = true;
+        }
+        return snapshots.values().stream().map(s -> s.build()).collect(Collectors.toSet());
+    }
+
+    public FileVisitResult preVisitDirectory(Path subdir, BasicFileAttributes attrs)
+    {
+        if (subdir.getParent().getFileName().toString().equals(SNAPSHOT_SUBDIR))
+        {
+            logger.trace(""Processing directory "" + subdir);
+            Matcher snapshotDirMatcher = SNAPSHOT_DIR_PATTERN.matcher(subdir.toString());
+            if (snapshotDirMatcher.find())
+            {
+                try
+                {
+                    loadSnapshotFromDir(snapshotDirMatcher, subdir);
+                } catch (Throwable e)
+                {
+                    logger.warn(""Could not load snapshot from %s."", subdir, e);
+                }
+            }
+            return FileVisitResult.SKIP_SUBTREE;
+        }
+
+        return subdir.equals(Directories.BACKUPS_SUBDIR)
+               ? FileVisitResult.SKIP_SUBTREE
+               : FileVisitResult.CONTINUE;
+    }
+
+    private void loadSnapshotFromDir(Matcher snapshotDirMatcher, Path snapshotDir)
+    {
+        String keyspaceName = snapshotDirMatcher.group(""keyspace"");
+        String tableName = snapshotDirMatcher.group(""tableName"");
+        UUID tableId = parseUUID(snapshotDirMatcher.group(""tableId""));
+        String tag = snapshotDirMatcher.group(""tag"");
+        String snapshotId = buildSnapshotId(keyspaceName, tableName, tableId, tag);
+        TableSnapshot.Builder builder = snapshots.computeIfAbsent(snapshotId, k -> new TableSnapshot.Builder(keyspaceName, tableName, tableId, tag));
+        builder.addSnapshotDir(new File(snapshotDir));
+    }
+
+    /**
+     * Given an UUID string without dashes (ie. c7e513243f0711ec9bbc0242ac130002)
+     * return an UUID object (ie. c7e51324-3f07-11ec-9bbc-0242ac130002)
+     */
+    protected static UUID parseUUID(String uuidWithoutDashes) throws IllegalArgumentException
+    {
+        assert uuidWithoutDashes.length() == 32 && !uuidWithoutDashes.contains(""-"");
+        String dashedUUID = uuidWithoutDashes.replaceFirst(""([0-9a-f]{8})([0-9a-f]{4})([0-9a-f]{4})([0-9a-f]{4})([0-9a-f]+)"", ""$1-$2-$3-$4-$5"");

Review Comment:
   you might replace this by compiled Pattern



;29/Apr/22 11:53;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861732939


##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -17,50 +17,76 @@
  */
 package org.apache.cassandra.service.snapshot;
 
+import java.io.IOException;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
 import java.time.Instant;
 import java.util.Collection;
+import java.util.HashSet;
 import java.util.Map;

Review Comment:
   you have few unused imports here



;29/Apr/22 11:55;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861733478


##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +139,171 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}. {}"", snapshotDir, e);
+            }
+        }
+
+        return visitor.getAllocatedSize();
     }
 
     public Collection<File> getDirectories()
     {
         return snapshotDirs;
     }
 
-    @Override
-    public String toString()
+    public Optional<File> getManifestFile()
     {
-        return ""TableSnapshot{"" +
-               ""keyspace='"" + keyspace + '\'' +
-               "", table='"" + table + '\'' +
-               "", tag='"" + tag + '\'' +
-               "", createdAt="" + createdAt +
-               "", expiresAt="" + expiresAt +
-               "", snapshotDirs="" + snapshotDirs +
-               '}';
+        for (File snapshotDir : snapshotDirs)
+        {
+            File manifestFile = Directories.getSnapshotManifestFile(snapshotDir);
+            if (manifestFile.exists())
+            {
+                return Optional.of(manifestFile);
+            }
+        }
+        return Optional.empty();
+    }
+
+    public Optional<File> getSchemaFile()
+    {
+        for (File snapshotDir : snapshotDirs)
+        {
+            File schemaFile = Directories.getSnapshotSchemaFile(snapshotDir);
+            if (schemaFile.exists())
+            {
+                return Optional.of(schemaFile);
+            }
+        }
+        return Optional.empty();
     }
 
     @Override
     public boolean equals(Object o)
     {
         if (this == o) return true;
         if (o == null || getClass() != o.getClass()) return false;
-        TableSnapshot that = (TableSnapshot) o;
-        return Objects.equals(keyspace, that.keyspace) && Objects.equals(table, that.table)
-               && Objects.equals(tag, that.tag) && Objects.equals(createdAt, that.createdAt)
-               && Objects.equals(expiresAt, that.expiresAt) && Objects.equals(snapshotDirs, that.snapshotDirs);
+        TableSnapshot snapshot = (TableSnapshot) o;
+        return Objects.equals(keyspaceName, snapshot.keyspaceName) && Objects.equals(tableName, snapshot.tableName) && Objects.equals(tableId, snapshot.tableId) && Objects.equals(tag, snapshot.tag) && Objects.equals(createdAt, snapshot.createdAt) && Objects.equals(expiresAt, snapshot.expiresAt) && Objects.equals(snapshotDirs, snapshot.snapshotDirs);

Review Comment:
   could you please make this line shorter?



;29/Apr/22 11:55;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861735858


##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +139,171 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}. {}"", snapshotDir, e);

Review Comment:
   Should not this be replaced by `error(String msg, Throwable t)`? I do not think that this version of the method is the one we want. Sorry if I am wrong. 



;29/Apr/22 11:59;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861738167


##########
src/java/org/apache/cassandra/utils/DirectorySizeCalculator.java:
##########
@@ -49,12 +45,14 @@ public boolean isAcceptable(Path file)
     public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException
     {
         if (isAcceptable(file))
+        {

Review Comment:
   I think that if there is just one statement in the body of `if`, the parenthesis might be left out completely.



;29/Apr/22 12:03;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861738973


##########
test/unit/org/apache/cassandra/service/snapshot/TableSnapshotTest.java:
##########
@@ -216,25 +210,41 @@ public void testGetCreatedAt() throws IOException
         TableSnapshot withCreatedAt = new TableSnapshot(
         ""ks"",
         ""tbl"",
+        UUID.randomUUID(),
         ""some1"",
         createdAt,
         null,
-        folders,
-        (File file) -> 0L
-        );
+        folders);
         assertThat(withCreatedAt.getCreatedAt()).isEqualTo(createdAt);
 
         // When createdAt is  null, it should return the snapshot folder minimum update time
         TableSnapshot withoutCreatedAt = new TableSnapshot(
         ""ks"",
         ""tbl"",
+        UUID.randomUUID(),
         ""some1"",
         null,
         null,
-        folders,
-        (File file) -> 0L
-        );
+        folders);
         assertThat(withoutCreatedAt.getCreatedAt()).isEqualTo(Instant.ofEpochMilli(folders.stream().mapToLong(f -> f.lastModified()).min().getAsLong()));
     }
 
+    @Test
+    public void testGetLiveFileFromSnapshotFile()
+    {
+        testGetLiveFileFromSnapshotFile(""~/.ccm/test/node1/data0/test_ks/tbl-e03faca0813211eca100c705ea09b5ef/snapshots/1643481737850/me-1-big-Data.db"",

Review Comment:
   are these .ccm methods really something we are interested in? I think this is the leftover from your local testing.



;29/Apr/22 12:04;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861739581


##########
test/unit/org/apache/cassandra/service/snapshot/TableSnapshotTest.java:
##########
@@ -216,25 +210,41 @@ public void testGetCreatedAt() throws IOException
         TableSnapshot withCreatedAt = new TableSnapshot(
         ""ks"",
         ""tbl"",
+        UUID.randomUUID(),
         ""some1"",
         createdAt,
         null,
-        folders,
-        (File file) -> 0L
-        );
+        folders);
         assertThat(withCreatedAt.getCreatedAt()).isEqualTo(createdAt);
 
         // When createdAt is  null, it should return the snapshot folder minimum update time
         TableSnapshot withoutCreatedAt = new TableSnapshot(
         ""ks"",
         ""tbl"",
+        UUID.randomUUID(),
         ""some1"",
         null,
         null,
-        folders,
-        (File file) -> 0L
-        );
+        folders);
         assertThat(withoutCreatedAt.getCreatedAt()).isEqualTo(Instant.ofEpochMilli(folders.stream().mapToLong(f -> f.lastModified()).min().getAsLong()));
     }
 
+    @Test
+    public void testGetLiveFileFromSnapshotFile()
+    {
+        testGetLiveFileFromSnapshotFile(""~/.ccm/test/node1/data0/test_ks/tbl-e03faca0813211eca100c705ea09b5ef/snapshots/1643481737850/me-1-big-Data.db"",

Review Comment:
   ah no sorry, I see what you did there now. Forget it.



;29/Apr/22 12:05;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861740574


##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());

Review Comment:
   could not be `this.dataDirectories` renamed to `this.dataDirs` as you are putting `dataDirs` into the constructor? I just dont like this minor discrepancy.



;29/Apr/22 12:07;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861743227


##########
src/java/org/apache/cassandra/service/StorageService.java:
##########
@@ -4129,24 +4130,26 @@ public void clearSnapshot(String tag, String... keyspaceNames) throws IOExceptio
 
     public Map<String, TabularData> getSnapshotDetails(Map<String, String> options)
     {
+        boolean skipExpiring = options != null && Boolean.parseBoolean(options.getOrDefault(""no_ttl"", ""false""));
+
+        SnapshotLoader loader = new SnapshotLoader();
         Map<String, TabularData> snapshotMap = new HashMap<>();
-        for (Keyspace keyspace : Keyspace.all())
+
+        for (TableSnapshot snapshot : loader.loadSnapshots())

Review Comment:
   I see you have 'walked' variable in loadSnapshots method, I guess it is for not needing to go over whole data structure multiple times. However, is it really used in this method? This is called from JMX when I am not mistaken, plus you create new instance of SnapshotLoader every time we use nodetool, so it will parse all data dirs anyway. Maybe we should cache this? I think it would be better to do this via SnapshotManager and I believe you have this in mind, just the proximity of the release is blocking you from doing it ""properly"".



;29/Apr/22 12:11;githubbot;600","pauloricardomg commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r861834427


##########
src/java/org/apache/cassandra/db/ColumnFamilyStore.java:
##########
@@ -2974,6 +2974,7 @@ public double getDroppableTombstoneRatio()
 
     public long trueSnapshotsSize()
     {
+

Review Comment:
   👍 



##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        if (!walked) {
+            for (Path dataDir : dataDirectories)
+            {
+                try
+                {
+                    Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+                }
+                catch (IOException e)
+                {
+                    throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+                }
+            }
+            walked = true;
+        }
+        return snapshots.values().stream().map(s -> s.build()).collect(Collectors.toSet());
+    }
+
+    public FileVisitResult preVisitDirectory(Path subdir, BasicFileAttributes attrs)
+    {
+        if (subdir.getParent().getFileName().toString().equals(SNAPSHOT_SUBDIR))
+        {
+            logger.trace(""Processing directory "" + subdir);
+            Matcher snapshotDirMatcher = SNAPSHOT_DIR_PATTERN.matcher(subdir.toString());
+            if (snapshotDirMatcher.find())
+            {
+                try
+                {
+                    loadSnapshotFromDir(snapshotDirMatcher, subdir);
+                } catch (Throwable e)
+                {
+                    logger.warn(""Could not load snapshot from %s."", subdir, e);
+                }
+            }
+            return FileVisitResult.SKIP_SUBTREE;
+        }
+
+        return subdir.equals(Directories.BACKUPS_SUBDIR)

Review Comment:
   good catch, fixed.



##########
src/java/org/apache/cassandra/db/commitlog/CommitLogSegmentManagerCDC.java:
##########
@@ -274,9 +274,12 @@ private static class CDCSizeTracker extends DirectorySizeCalculator
         // track the total size between two dictionary size calculations
         private final AtomicLong sizeInProgress;
 
+        private final File path;
+
         CDCSizeTracker(CommitLogSegmentManagerCDC segmentManager, File path)
         {
-            super(path);
+            super();

Review Comment:
   Good catch. Removed it.



##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());

Review Comment:
   👍 



##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        if (!walked) {
+            for (Path dataDir : dataDirectories)
+            {
+                try
+                {
+                    Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+                }
+                catch (IOException e)
+                {
+                    throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+                }
+            }
+            walked = true;
+        }
+        return snapshots.values().stream().map(s -> s.build()).collect(Collectors.toSet());
+    }
+
+    public FileVisitResult preVisitDirectory(Path subdir, BasicFileAttributes attrs)
+    {
+        if (subdir.getParent().getFileName().toString().equals(SNAPSHOT_SUBDIR))
+        {
+            logger.trace(""Processing directory "" + subdir);
+            Matcher snapshotDirMatcher = SNAPSHOT_DIR_PATTERN.matcher(subdir.toString());
+            if (snapshotDirMatcher.find())
+            {
+                try
+                {
+                    loadSnapshotFromDir(snapshotDirMatcher, subdir);
+                } catch (Throwable e)
+                {
+                    logger.warn(""Could not load snapshot from %s."", subdir, e);

Review Comment:
   good catch, fixed.



##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +139,171 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}. {}"", snapshotDir, e);

Review Comment:
   Good catch, fixed it.



##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        if (!walked) {
+            for (Path dataDir : dataDirectories)
+            {
+                try
+                {
+                    Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+                }
+                catch (IOException e)
+                {
+                    throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+                }
+            }
+            walked = true;
+        }
+        return snapshots.values().stream().map(s -> s.build()).collect(Collectors.toSet());

Review Comment:
   👍 



##########
src/java/org/apache/cassandra/service/StorageService.java:
##########
@@ -4129,24 +4130,26 @@ public void clearSnapshot(String tag, String... keyspaceNames) throws IOExceptio
 
     public Map<String, TabularData> getSnapshotDetails(Map<String, String> options)
     {
+        boolean skipExpiring = options != null && Boolean.parseBoolean(options.getOrDefault(""no_ttl"", ""false""));
+
+        SnapshotLoader loader = new SnapshotLoader();
         Map<String, TabularData> snapshotMap = new HashMap<>();
-        for (Keyspace keyspace : Keyspace.all())
+
+        for (TableSnapshot snapshot : loader.loadSnapshots())

Review Comment:
   > I see you have 'walked' variable in loadSnapshots method, I guess it is for not needing to go over whole data structure multiple times. However, is it really used in this method?
   
   Removed `walked` variable from `SnapshotLoader` since it's no longer neeeded. This is a leftover from a previous implementation.
   
   
   > Maybe we should cache this? I think it would be better to do this via SnapshotManager and I believe you have this in mind, just the proximity of the release is blocking you from doing it ""properly"".
   
   Yes, I have a longer version of this patch where loaded snapshots are cached in the `SnapshotManager` ([here](https://github.com/apache/cassandra/compare/trunk...pauloricardomg:CASSANDRA-16843-final?expand=1#diff-17b12c3f18d24601e8d6dcdf288f6583624ebf1b5cd1b135cfe1ed5abd6d349dR71)). However in order to cache this properly we need to move snapshot cleanup logic to `SnapshotManager`, which makes this patch bigger than it should be and riskier for 4.1. I plan to create follow-up patches based on the longer patch above centralizing snapshot logic on `SnapshotManager` for 4.2.



##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +139,171 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}. {}"", snapshotDir, e);
+            }
+        }
+
+        return visitor.getAllocatedSize();
     }
 
     public Collection<File> getDirectories()
     {
         return snapshotDirs;
     }
 
-    @Override
-    public String toString()
+    public Optional<File> getManifestFile()
     {
-        return ""TableSnapshot{"" +
-               ""keyspace='"" + keyspace + '\'' +
-               "", table='"" + table + '\'' +
-               "", tag='"" + tag + '\'' +
-               "", createdAt="" + createdAt +
-               "", expiresAt="" + expiresAt +
-               "", snapshotDirs="" + snapshotDirs +
-               '}';
+        for (File snapshotDir : snapshotDirs)
+        {
+            File manifestFile = Directories.getSnapshotManifestFile(snapshotDir);
+            if (manifestFile.exists())
+            {
+                return Optional.of(manifestFile);
+            }
+        }
+        return Optional.empty();
+    }
+
+    public Optional<File> getSchemaFile()
+    {
+        for (File snapshotDir : snapshotDirs)
+        {
+            File schemaFile = Directories.getSnapshotSchemaFile(snapshotDir);
+            if (schemaFile.exists())
+            {
+                return Optional.of(schemaFile);
+            }
+        }
+        return Optional.empty();
     }
 
     @Override
     public boolean equals(Object o)
     {
         if (this == o) return true;
         if (o == null || getClass() != o.getClass()) return false;
-        TableSnapshot that = (TableSnapshot) o;
-        return Objects.equals(keyspace, that.keyspace) && Objects.equals(table, that.table)
-               && Objects.equals(tag, that.tag) && Objects.equals(createdAt, that.createdAt)
-               && Objects.equals(expiresAt, that.expiresAt) && Objects.equals(snapshotDirs, that.snapshotDirs);
+        TableSnapshot snapshot = (TableSnapshot) o;
+        return Objects.equals(keyspaceName, snapshot.keyspaceName) && Objects.equals(tableName, snapshot.tableName) && Objects.equals(tableId, snapshot.tableId) && Objects.equals(tag, snapshot.tag) && Objects.equals(createdAt, snapshot.createdAt) && Objects.equals(expiresAt, snapshot.expiresAt) && Objects.equals(snapshotDirs, snapshot.snapshotDirs);

Review Comment:
   Done.



##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        if (!walked) {
+            for (Path dataDir : dataDirectories)
+            {
+                try
+                {
+                    Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+                }
+                catch (IOException e)
+                {
+                    throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+                }
+            }
+            walked = true;
+        }
+        return snapshots.values().stream().map(s -> s.build()).collect(Collectors.toSet());
+    }
+
+    public FileVisitResult preVisitDirectory(Path subdir, BasicFileAttributes attrs)
+    {
+        if (subdir.getParent().getFileName().toString().equals(SNAPSHOT_SUBDIR))
+        {
+            logger.trace(""Processing directory "" + subdir);
+            Matcher snapshotDirMatcher = SNAPSHOT_DIR_PATTERN.matcher(subdir.toString());
+            if (snapshotDirMatcher.find())
+            {
+                try
+                {
+                    loadSnapshotFromDir(snapshotDirMatcher, subdir);
+                } catch (Throwable e)
+                {
+                    logger.warn(""Could not load snapshot from %s."", subdir, e);
+                }
+            }
+            return FileVisitResult.SKIP_SUBTREE;
+        }
+
+        return subdir.equals(Directories.BACKUPS_SUBDIR)
+               ? FileVisitResult.SKIP_SUBTREE
+               : FileVisitResult.CONTINUE;
+    }
+
+    private void loadSnapshotFromDir(Matcher snapshotDirMatcher, Path snapshotDir)
+    {
+        String keyspaceName = snapshotDirMatcher.group(""keyspace"");
+        String tableName = snapshotDirMatcher.group(""tableName"");
+        UUID tableId = parseUUID(snapshotDirMatcher.group(""tableId""));
+        String tag = snapshotDirMatcher.group(""tag"");
+        String snapshotId = buildSnapshotId(keyspaceName, tableName, tableId, tag);
+        TableSnapshot.Builder builder = snapshots.computeIfAbsent(snapshotId, k -> new TableSnapshot.Builder(keyspaceName, tableName, tableId, tag));
+        builder.addSnapshotDir(new File(snapshotDir));
+    }
+
+    /**
+     * Given an UUID string without dashes (ie. c7e513243f0711ec9bbc0242ac130002)
+     * return an UUID object (ie. c7e51324-3f07-11ec-9bbc-0242ac130002)
+     */
+    protected static UUID parseUUID(String uuidWithoutDashes) throws IllegalArgumentException
+    {
+        assert uuidWithoutDashes.length() == 32 && !uuidWithoutDashes.contains(""-"");
+        String dashedUUID = uuidWithoutDashes.replaceFirst(""([0-9a-f]{8})([0-9a-f]{4})([0-9a-f]{4})([0-9a-f]{4})([0-9a-f]+)"", ""$1-$2-$3-$4-$5"");

Review Comment:
   I could, but I prefer not to touch this right now as I'm not really sure how to use `Pattern` here and this is working as expected. Feel free to offer a suggestion on how to improve this.



##########
src/java/org/apache/cassandra/utils/DirectorySizeCalculator.java:
##########
@@ -49,12 +45,14 @@ public boolean isAcceptable(Path file)
     public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException
     {
         if (isAcceptable(file))
+        {

Review Comment:
   fixed



##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -17,50 +17,76 @@
  */
 package org.apache.cassandra.service.snapshot;
 
+import java.io.IOException;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
 import java.time.Instant;
 import java.util.Collection;
+import java.util.HashSet;
 import java.util.Map;

Review Comment:
   Fixed.



##########
test/unit/org/apache/cassandra/service/snapshot/TableSnapshotTest.java:
##########
@@ -216,25 +210,41 @@ public void testGetCreatedAt() throws IOException
         TableSnapshot withCreatedAt = new TableSnapshot(
         ""ks"",
         ""tbl"",
+        UUID.randomUUID(),
         ""some1"",
         createdAt,
         null,
-        folders,
-        (File file) -> 0L
-        );
+        folders);
         assertThat(withCreatedAt.getCreatedAt()).isEqualTo(createdAt);
 
         // When createdAt is  null, it should return the snapshot folder minimum update time
         TableSnapshot withoutCreatedAt = new TableSnapshot(
         ""ks"",
         ""tbl"",
+        UUID.randomUUID(),
         ""some1"",
         null,
         null,
-        folders,
-        (File file) -> 0L
-        );
+        folders);
         assertThat(withoutCreatedAt.getCreatedAt()).isEqualTo(Instant.ofEpochMilli(folders.stream().mapToLong(f -> f.lastModified()).min().getAsLong()));
     }
 
+    @Test
+    public void testGetLiveFileFromSnapshotFile()
+    {
+        testGetLiveFileFromSnapshotFile(""~/.ccm/test/node1/data0/test_ks/tbl-e03faca0813211eca100c705ea09b5ef/snapshots/1643481737850/me-1-big-Data.db"",

Review Comment:
   👍 



##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,141 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+    private boolean walked = false;
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirs)
+    {
+        this.dataDirectories = Arrays.asList(dataDirs).stream().map(d -> Paths.get(d)).collect(Collectors.toList());

Review Comment:
   updated constructor to match `dataDirectories`



##########
src/java/org/apache/cassandra/db/Directories.java:
##########
@@ -1244,9 +1249,8 @@ private static String join(String... s)
     private class SSTableSizeSummer extends DirectorySizeCalculator
     {
         private final Set<String> toSkip;
-        SSTableSizeSummer(File path, List<File> files)
+        SSTableSizeSummer(List<File> files)
         {
-            super(path);
             toSkip = files.stream().map(f -> f.name()).collect(Collectors.toSet());

Review Comment:
   👍 



;29/Apr/22 14:36;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862120170


##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,137 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirectories)
+    {
+        this.dataDirectories = Arrays.stream(dataDirectories).map(Paths::get).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        for (Path dataDir : dataDirectories)
+        {
+            try
+            {
+                Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+            }
+            catch (IOException e)
+            {
+                throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+            }
+        }
+        return snapshots.values().stream().map(TableSnapshot.Builder::build).collect(Collectors.toSet());
+    }
+
+    public FileVisitResult preVisitDirectory(Path subdir, BasicFileAttributes attrs)
+    {
+        if (subdir.getParent().getFileName().toString().equals(SNAPSHOT_SUBDIR))
+        {
+            logger.trace(""Processing directory "" + subdir);
+            Matcher snapshotDirMatcher = SNAPSHOT_DIR_PATTERN.matcher(subdir.toString());
+            if (snapshotDirMatcher.find())
+            {
+                try
+                {
+                    loadSnapshotFromDir(snapshotDirMatcher, subdir);
+                } catch (Throwable e)
+                {
+                    logger.warn(""Could not load snapshot from {}."", subdir, e);

Review Comment:
   I think this is still not fixed, is it? this will call warn(String, Object, Object). It is different from warn(String,Throwable). And there are not two {} anyway.



;29/Apr/22 20:18;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862121092


##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +136,174 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}."", snapshotDir, e);

Review Comment:
   same as above.



;29/Apr/22 20:19;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862124191


##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +136,174 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}."", snapshotDir, e);
+            }
+        }
+
+        return visitor.getAllocatedSize();
     }
 
     public Collection<File> getDirectories()
     {
         return snapshotDirs;
     }
 
-    @Override
-    public String toString()
+    public Optional<File> getManifestFile()
     {
-        return ""TableSnapshot{"" +
-               ""keyspace='"" + keyspace + '\'' +
-               "", table='"" + table + '\'' +
-               "", tag='"" + tag + '\'' +
-               "", createdAt="" + createdAt +
-               "", expiresAt="" + expiresAt +
-               "", snapshotDirs="" + snapshotDirs +
-               '}';
+        for (File snapshotDir : snapshotDirs)
+        {
+            File manifestFile = Directories.getSnapshotManifestFile(snapshotDir);
+            if (manifestFile.exists())
+            {
+                return Optional.of(manifestFile);
+            }
+        }
+        return Optional.empty();
+    }
+
+    public Optional<File> getSchemaFile()
+    {
+        for (File snapshotDir : snapshotDirs)
+        {
+            File schemaFile = Directories.getSnapshotSchemaFile(snapshotDir);
+            if (schemaFile.exists())
+            {
+                return Optional.of(schemaFile);
+            }
+        }
+        return Optional.empty();
     }
 
     @Override
     public boolean equals(Object o)
     {
         if (this == o) return true;
         if (o == null || getClass() != o.getClass()) return false;
-        TableSnapshot that = (TableSnapshot) o;
-        return Objects.equals(keyspace, that.keyspace) && Objects.equals(table, that.table)
-               && Objects.equals(tag, that.tag) && Objects.equals(createdAt, that.createdAt)
-               && Objects.equals(expiresAt, that.expiresAt) && Objects.equals(snapshotDirs, that.snapshotDirs);
+        TableSnapshot snapshot = (TableSnapshot) o;
+        return Objects.equals(keyspaceName, snapshot.keyspaceName) && Objects.equals(tableName, snapshot.tableName) &&
+               Objects.equals(tableId, snapshot.tableId) && Objects.equals(tag, snapshot.tag) &&
+               Objects.equals(createdAt, snapshot.createdAt) && Objects.equals(expiresAt, snapshot.expiresAt) &&
+               Objects.equals(snapshotDirs, snapshot.snapshotDirs);
     }
 
     @Override
     public int hashCode()
     {
-        return Objects.hash(keyspace, table, tag, createdAt, expiresAt, snapshotDirs);
+        return Objects.hash(keyspaceName, tableName, tableId, tag, createdAt, expiresAt, snapshotDirs);
+    }
+
+    @Override
+    public String toString()
+    {
+        return ""TableSnapshot{"" +
+               ""keyspaceName='"" + keyspaceName + '\'' +
+               "", tableName='"" + tableName + '\'' +
+               "", tableId="" + tableId +
+               "", tag='"" + tag + '\'' +
+               "", createdAt="" + createdAt +
+               "", expiresAt="" + expiresAt +
+               "", snapshotDirs="" + snapshotDirs +
+               '}';
+    }
+
+    static class Builder {
+        private final String keyspaceName;
+        private final String tableName;
+        private final UUID tableId;
+        private final String tag;
+
+        private Instant createdAt = null;
+        private Instant expiresAt = null;
+
+        private final Set<File> snapshotDirs = new HashSet<>();
+
+        Builder(String keyspaceName, String tableName, UUID tableId, String tag)
+        {
+            this.keyspaceName = keyspaceName;
+            this.tableName = tableName;
+            this.tag = tag;
+            this.tableId = tableId;
+        }
+
+        void addSnapshotDir(File snapshotDir)
+        {
+            snapshotDirs.add(snapshotDir);
+            File manifestFile = new File(snapshotDir, ""manifest.json"");
+            if (manifestFile.exists() && createdAt == null && expiresAt == null) {
+                loadTimestampsFromManifest(manifestFile);
+            }
+        }
+
+        private void loadTimestampsFromManifest(File manifestFile)
+        {
+            try
+            {
+                logger.debug(""Loading snapshot manifest from {}"", manifestFile);
+                SnapshotManifest manifest = SnapshotManifest.deserializeFromJsonFile(manifestFile);
+                createdAt = manifest.createdAt;
+                expiresAt = manifest.expiresAt;
+            }
+            catch (IOException e)
+            {
+                logger.warn(""Cannot read manifest file {} of snapshot {}."", manifestFile, tag, e);

Review Comment:
   same ... I live with the opinion that this API expects Object's, two objects and Throwable. There are other methods for logging throwables. This does not work I think or I am completely wrong here.



;29/Apr/22 20:20;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862124191


##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +136,174 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}."", snapshotDir, e);
+            }
+        }
+
+        return visitor.getAllocatedSize();
     }
 
     public Collection<File> getDirectories()
     {
         return snapshotDirs;
     }
 
-    @Override
-    public String toString()
+    public Optional<File> getManifestFile()
     {
-        return ""TableSnapshot{"" +
-               ""keyspace='"" + keyspace + '\'' +
-               "", table='"" + table + '\'' +
-               "", tag='"" + tag + '\'' +
-               "", createdAt="" + createdAt +
-               "", expiresAt="" + expiresAt +
-               "", snapshotDirs="" + snapshotDirs +
-               '}';
+        for (File snapshotDir : snapshotDirs)
+        {
+            File manifestFile = Directories.getSnapshotManifestFile(snapshotDir);
+            if (manifestFile.exists())
+            {
+                return Optional.of(manifestFile);
+            }
+        }
+        return Optional.empty();
+    }
+
+    public Optional<File> getSchemaFile()
+    {
+        for (File snapshotDir : snapshotDirs)
+        {
+            File schemaFile = Directories.getSnapshotSchemaFile(snapshotDir);
+            if (schemaFile.exists())
+            {
+                return Optional.of(schemaFile);
+            }
+        }
+        return Optional.empty();
     }
 
     @Override
     public boolean equals(Object o)
     {
         if (this == o) return true;
         if (o == null || getClass() != o.getClass()) return false;
-        TableSnapshot that = (TableSnapshot) o;
-        return Objects.equals(keyspace, that.keyspace) && Objects.equals(table, that.table)
-               && Objects.equals(tag, that.tag) && Objects.equals(createdAt, that.createdAt)
-               && Objects.equals(expiresAt, that.expiresAt) && Objects.equals(snapshotDirs, that.snapshotDirs);
+        TableSnapshot snapshot = (TableSnapshot) o;
+        return Objects.equals(keyspaceName, snapshot.keyspaceName) && Objects.equals(tableName, snapshot.tableName) &&
+               Objects.equals(tableId, snapshot.tableId) && Objects.equals(tag, snapshot.tag) &&
+               Objects.equals(createdAt, snapshot.createdAt) && Objects.equals(expiresAt, snapshot.expiresAt) &&
+               Objects.equals(snapshotDirs, snapshot.snapshotDirs);
     }
 
     @Override
     public int hashCode()
     {
-        return Objects.hash(keyspace, table, tag, createdAt, expiresAt, snapshotDirs);
+        return Objects.hash(keyspaceName, tableName, tableId, tag, createdAt, expiresAt, snapshotDirs);
+    }
+
+    @Override
+    public String toString()
+    {
+        return ""TableSnapshot{"" +
+               ""keyspaceName='"" + keyspaceName + '\'' +
+               "", tableName='"" + tableName + '\'' +
+               "", tableId="" + tableId +
+               "", tag='"" + tag + '\'' +
+               "", createdAt="" + createdAt +
+               "", expiresAt="" + expiresAt +
+               "", snapshotDirs="" + snapshotDirs +
+               '}';
+    }
+
+    static class Builder {
+        private final String keyspaceName;
+        private final String tableName;
+        private final UUID tableId;
+        private final String tag;
+
+        private Instant createdAt = null;
+        private Instant expiresAt = null;
+
+        private final Set<File> snapshotDirs = new HashSet<>();
+
+        Builder(String keyspaceName, String tableName, UUID tableId, String tag)
+        {
+            this.keyspaceName = keyspaceName;
+            this.tableName = tableName;
+            this.tag = tag;
+            this.tableId = tableId;
+        }
+
+        void addSnapshotDir(File snapshotDir)
+        {
+            snapshotDirs.add(snapshotDir);
+            File manifestFile = new File(snapshotDir, ""manifest.json"");
+            if (manifestFile.exists() && createdAt == null && expiresAt == null) {
+                loadTimestampsFromManifest(manifestFile);
+            }
+        }
+
+        private void loadTimestampsFromManifest(File manifestFile)
+        {
+            try
+            {
+                logger.debug(""Loading snapshot manifest from {}"", manifestFile);
+                SnapshotManifest manifest = SnapshotManifest.deserializeFromJsonFile(manifestFile);
+                createdAt = manifest.createdAt;
+                expiresAt = manifest.expiresAt;
+            }
+            catch (IOException e)
+            {
+                logger.warn(""Cannot read manifest file {} of snapshot {}."", manifestFile, tag, e);

Review Comment:
   same ... I live with the opinion that this API expects Object's, not two objects and Throwable. There are other methods for logging throwables. This does not work I think or I am completely wrong here.



;29/Apr/22 20:21;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862124191


##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +136,174 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}."", snapshotDir, e);
+            }
+        }
+
+        return visitor.getAllocatedSize();
     }
 
     public Collection<File> getDirectories()
     {
         return snapshotDirs;
     }
 
-    @Override
-    public String toString()
+    public Optional<File> getManifestFile()
     {
-        return ""TableSnapshot{"" +
-               ""keyspace='"" + keyspace + '\'' +
-               "", table='"" + table + '\'' +
-               "", tag='"" + tag + '\'' +
-               "", createdAt="" + createdAt +
-               "", expiresAt="" + expiresAt +
-               "", snapshotDirs="" + snapshotDirs +
-               '}';
+        for (File snapshotDir : snapshotDirs)
+        {
+            File manifestFile = Directories.getSnapshotManifestFile(snapshotDir);
+            if (manifestFile.exists())
+            {
+                return Optional.of(manifestFile);
+            }
+        }
+        return Optional.empty();
+    }
+
+    public Optional<File> getSchemaFile()
+    {
+        for (File snapshotDir : snapshotDirs)
+        {
+            File schemaFile = Directories.getSnapshotSchemaFile(snapshotDir);
+            if (schemaFile.exists())
+            {
+                return Optional.of(schemaFile);
+            }
+        }
+        return Optional.empty();
     }
 
     @Override
     public boolean equals(Object o)
     {
         if (this == o) return true;
         if (o == null || getClass() != o.getClass()) return false;
-        TableSnapshot that = (TableSnapshot) o;
-        return Objects.equals(keyspace, that.keyspace) && Objects.equals(table, that.table)
-               && Objects.equals(tag, that.tag) && Objects.equals(createdAt, that.createdAt)
-               && Objects.equals(expiresAt, that.expiresAt) && Objects.equals(snapshotDirs, that.snapshotDirs);
+        TableSnapshot snapshot = (TableSnapshot) o;
+        return Objects.equals(keyspaceName, snapshot.keyspaceName) && Objects.equals(tableName, snapshot.tableName) &&
+               Objects.equals(tableId, snapshot.tableId) && Objects.equals(tag, snapshot.tag) &&
+               Objects.equals(createdAt, snapshot.createdAt) && Objects.equals(expiresAt, snapshot.expiresAt) &&
+               Objects.equals(snapshotDirs, snapshot.snapshotDirs);
     }
 
     @Override
     public int hashCode()
     {
-        return Objects.hash(keyspace, table, tag, createdAt, expiresAt, snapshotDirs);
+        return Objects.hash(keyspaceName, tableName, tableId, tag, createdAt, expiresAt, snapshotDirs);
+    }
+
+    @Override
+    public String toString()
+    {
+        return ""TableSnapshot{"" +
+               ""keyspaceName='"" + keyspaceName + '\'' +
+               "", tableName='"" + tableName + '\'' +
+               "", tableId="" + tableId +
+               "", tag='"" + tag + '\'' +
+               "", createdAt="" + createdAt +
+               "", expiresAt="" + expiresAt +
+               "", snapshotDirs="" + snapshotDirs +
+               '}';
+    }
+
+    static class Builder {
+        private final String keyspaceName;
+        private final String tableName;
+        private final UUID tableId;
+        private final String tag;
+
+        private Instant createdAt = null;
+        private Instant expiresAt = null;
+
+        private final Set<File> snapshotDirs = new HashSet<>();
+
+        Builder(String keyspaceName, String tableName, UUID tableId, String tag)
+        {
+            this.keyspaceName = keyspaceName;
+            this.tableName = tableName;
+            this.tag = tag;
+            this.tableId = tableId;
+        }
+
+        void addSnapshotDir(File snapshotDir)
+        {
+            snapshotDirs.add(snapshotDir);
+            File manifestFile = new File(snapshotDir, ""manifest.json"");
+            if (manifestFile.exists() && createdAt == null && expiresAt == null) {
+                loadTimestampsFromManifest(manifestFile);
+            }
+        }
+
+        private void loadTimestampsFromManifest(File manifestFile)
+        {
+            try
+            {
+                logger.debug(""Loading snapshot manifest from {}"", manifestFile);
+                SnapshotManifest manifest = SnapshotManifest.deserializeFromJsonFile(manifestFile);
+                createdAt = manifest.createdAt;
+                expiresAt = manifest.expiresAt;
+            }
+            catch (IOException e)
+            {
+                logger.warn(""Cannot read manifest file {} of snapshot {}."", manifestFile, tag, e);

Review Comment:
   same ... I live with the opinion that this API expects Object's, not two objects and Throwable. There are other methods for logging throwables. This does not work I think or I am completely wrong here.
   I am used to do it like logger.warn(String.format(""%s %s"", a, b), e); so it calls warn(String,Throwable). If there is warn(Objects...) I can indeed do warn(""{} {} {}"", a, b, c) but I would not put Throwable into it.



;29/Apr/22 20:22;githubbot;600","pauloricardomg commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862127861


##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,137 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirectories)
+    {
+        this.dataDirectories = Arrays.stream(dataDirectories).map(Paths::get).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        for (Path dataDir : dataDirectories)
+        {
+            try
+            {
+                Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+            }
+            catch (IOException e)
+            {
+                throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+            }
+        }
+        return snapshots.values().stream().map(TableSnapshot.Builder::build).collect(Collectors.toSet());
+    }
+
+    public FileVisitResult preVisitDirectory(Path subdir, BasicFileAttributes attrs)
+    {
+        if (subdir.getParent().getFileName().toString().equals(SNAPSHOT_SUBDIR))
+        {
+            logger.trace(""Processing directory "" + subdir);
+            Matcher snapshotDirMatcher = SNAPSHOT_DIR_PATTERN.matcher(subdir.toString());
+            if (snapshotDirMatcher.find())
+            {
+                try
+                {
+                    loadSnapshotFromDir(snapshotDirMatcher, subdir);
+                } catch (Throwable e)
+                {
+                    logger.warn(""Could not load snapshot from {}."", subdir, e);

Review Comment:
   Yes this is fixed.



;29/Apr/22 20:27;githubbot;600","pauloricardomg commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862127861


##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,137 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirectories)
+    {
+        this.dataDirectories = Arrays.stream(dataDirectories).map(Paths::get).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        for (Path dataDir : dataDirectories)
+        {
+            try
+            {
+                Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+            }
+            catch (IOException e)
+            {
+                throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+            }
+        }
+        return snapshots.values().stream().map(TableSnapshot.Builder::build).collect(Collectors.toSet());
+    }
+
+    public FileVisitResult preVisitDirectory(Path subdir, BasicFileAttributes attrs)
+    {
+        if (subdir.getParent().getFileName().toString().equals(SNAPSHOT_SUBDIR))
+        {
+            logger.trace(""Processing directory "" + subdir);
+            Matcher snapshotDirMatcher = SNAPSHOT_DIR_PATTERN.matcher(subdir.toString());
+            if (snapshotDirMatcher.find())
+            {
+                try
+                {
+                    loadSnapshotFromDir(snapshotDirMatcher, subdir);
+                } catch (Throwable e)
+                {
+                    logger.warn(""Could not load snapshot from {}."", subdir, e);

Review Comment:
   Yes this is fixed - check this: https://www.slf4j.org/faq.html#paramException



;29/Apr/22 20:29;githubbot;600","pauloricardomg commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862129189


##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +136,174 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}."", snapshotDir, e);

Review Comment:
   This is working as expected: https://www.slf4j.org/faq.html#paramException
   
   The first parameter will be added to the message, and the exception trace will be print.



;29/Apr/22 20:30;githubbot;600","pauloricardomg commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862129447


##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +136,174 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}."", snapshotDir, e);
+            }
+        }
+
+        return visitor.getAllocatedSize();
     }
 
     public Collection<File> getDirectories()
     {
         return snapshotDirs;
     }
 
-    @Override
-    public String toString()
+    public Optional<File> getManifestFile()
     {
-        return ""TableSnapshot{"" +
-               ""keyspace='"" + keyspace + '\'' +
-               "", table='"" + table + '\'' +
-               "", tag='"" + tag + '\'' +
-               "", createdAt="" + createdAt +
-               "", expiresAt="" + expiresAt +
-               "", snapshotDirs="" + snapshotDirs +
-               '}';
+        for (File snapshotDir : snapshotDirs)
+        {
+            File manifestFile = Directories.getSnapshotManifestFile(snapshotDir);
+            if (manifestFile.exists())
+            {
+                return Optional.of(manifestFile);
+            }
+        }
+        return Optional.empty();
+    }
+
+    public Optional<File> getSchemaFile()
+    {
+        for (File snapshotDir : snapshotDirs)
+        {
+            File schemaFile = Directories.getSnapshotSchemaFile(snapshotDir);
+            if (schemaFile.exists())
+            {
+                return Optional.of(schemaFile);
+            }
+        }
+        return Optional.empty();
     }
 
     @Override
     public boolean equals(Object o)
     {
         if (this == o) return true;
         if (o == null || getClass() != o.getClass()) return false;
-        TableSnapshot that = (TableSnapshot) o;
-        return Objects.equals(keyspace, that.keyspace) && Objects.equals(table, that.table)
-               && Objects.equals(tag, that.tag) && Objects.equals(createdAt, that.createdAt)
-               && Objects.equals(expiresAt, that.expiresAt) && Objects.equals(snapshotDirs, that.snapshotDirs);
+        TableSnapshot snapshot = (TableSnapshot) o;
+        return Objects.equals(keyspaceName, snapshot.keyspaceName) && Objects.equals(tableName, snapshot.tableName) &&
+               Objects.equals(tableId, snapshot.tableId) && Objects.equals(tag, snapshot.tag) &&
+               Objects.equals(createdAt, snapshot.createdAt) && Objects.equals(expiresAt, snapshot.expiresAt) &&
+               Objects.equals(snapshotDirs, snapshot.snapshotDirs);
     }
 
     @Override
     public int hashCode()
     {
-        return Objects.hash(keyspace, table, tag, createdAt, expiresAt, snapshotDirs);
+        return Objects.hash(keyspaceName, tableName, tableId, tag, createdAt, expiresAt, snapshotDirs);
+    }
+
+    @Override
+    public String toString()
+    {
+        return ""TableSnapshot{"" +
+               ""keyspaceName='"" + keyspaceName + '\'' +
+               "", tableName='"" + tableName + '\'' +
+               "", tableId="" + tableId +
+               "", tag='"" + tag + '\'' +
+               "", createdAt="" + createdAt +
+               "", expiresAt="" + expiresAt +
+               "", snapshotDirs="" + snapshotDirs +
+               '}';
+    }
+
+    static class Builder {
+        private final String keyspaceName;
+        private final String tableName;
+        private final UUID tableId;
+        private final String tag;
+
+        private Instant createdAt = null;
+        private Instant expiresAt = null;
+
+        private final Set<File> snapshotDirs = new HashSet<>();
+
+        Builder(String keyspaceName, String tableName, UUID tableId, String tag)
+        {
+            this.keyspaceName = keyspaceName;
+            this.tableName = tableName;
+            this.tag = tag;
+            this.tableId = tableId;
+        }
+
+        void addSnapshotDir(File snapshotDir)
+        {
+            snapshotDirs.add(snapshotDir);
+            File manifestFile = new File(snapshotDir, ""manifest.json"");
+            if (manifestFile.exists() && createdAt == null && expiresAt == null) {
+                loadTimestampsFromManifest(manifestFile);
+            }
+        }
+
+        private void loadTimestampsFromManifest(File manifestFile)
+        {
+            try
+            {
+                logger.debug(""Loading snapshot manifest from {}"", manifestFile);
+                SnapshotManifest manifest = SnapshotManifest.deserializeFromJsonFile(manifestFile);
+                createdAt = manifest.createdAt;
+                expiresAt = manifest.expiresAt;
+            }
+            catch (IOException e)
+            {
+                logger.warn(""Cannot read manifest file {} of snapshot {}."", manifestFile, tag, e);

Review Comment:
   Read this: https://www.slf4j.org/faq.html#paramException



;29/Apr/22 20:30;githubbot;600","pauloricardomg commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862133566


##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +136,174 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}."", snapshotDir, e);
+            }
+        }
+
+        return visitor.getAllocatedSize();
     }
 
     public Collection<File> getDirectories()
     {
         return snapshotDirs;
     }
 
-    @Override
-    public String toString()
+    public Optional<File> getManifestFile()
     {
-        return ""TableSnapshot{"" +
-               ""keyspace='"" + keyspace + '\'' +
-               "", table='"" + table + '\'' +
-               "", tag='"" + tag + '\'' +
-               "", createdAt="" + createdAt +
-               "", expiresAt="" + expiresAt +
-               "", snapshotDirs="" + snapshotDirs +
-               '}';
+        for (File snapshotDir : snapshotDirs)
+        {
+            File manifestFile = Directories.getSnapshotManifestFile(snapshotDir);
+            if (manifestFile.exists())
+            {
+                return Optional.of(manifestFile);
+            }
+        }
+        return Optional.empty();
+    }
+
+    public Optional<File> getSchemaFile()
+    {
+        for (File snapshotDir : snapshotDirs)
+        {
+            File schemaFile = Directories.getSnapshotSchemaFile(snapshotDir);
+            if (schemaFile.exists())
+            {
+                return Optional.of(schemaFile);
+            }
+        }
+        return Optional.empty();
     }
 
     @Override
     public boolean equals(Object o)
     {
         if (this == o) return true;
         if (o == null || getClass() != o.getClass()) return false;
-        TableSnapshot that = (TableSnapshot) o;
-        return Objects.equals(keyspace, that.keyspace) && Objects.equals(table, that.table)
-               && Objects.equals(tag, that.tag) && Objects.equals(createdAt, that.createdAt)
-               && Objects.equals(expiresAt, that.expiresAt) && Objects.equals(snapshotDirs, that.snapshotDirs);
+        TableSnapshot snapshot = (TableSnapshot) o;
+        return Objects.equals(keyspaceName, snapshot.keyspaceName) && Objects.equals(tableName, snapshot.tableName) &&
+               Objects.equals(tableId, snapshot.tableId) && Objects.equals(tag, snapshot.tag) &&
+               Objects.equals(createdAt, snapshot.createdAt) && Objects.equals(expiresAt, snapshot.expiresAt) &&
+               Objects.equals(snapshotDirs, snapshot.snapshotDirs);
     }
 
     @Override
     public int hashCode()
     {
-        return Objects.hash(keyspace, table, tag, createdAt, expiresAt, snapshotDirs);
+        return Objects.hash(keyspaceName, tableName, tableId, tag, createdAt, expiresAt, snapshotDirs);
+    }
+
+    @Override
+    public String toString()
+    {
+        return ""TableSnapshot{"" +
+               ""keyspaceName='"" + keyspaceName + '\'' +
+               "", tableName='"" + tableName + '\'' +
+               "", tableId="" + tableId +
+               "", tag='"" + tag + '\'' +
+               "", createdAt="" + createdAt +
+               "", expiresAt="" + expiresAt +
+               "", snapshotDirs="" + snapshotDirs +
+               '}';
+    }
+
+    static class Builder {
+        private final String keyspaceName;
+        private final String tableName;
+        private final UUID tableId;
+        private final String tag;
+
+        private Instant createdAt = null;
+        private Instant expiresAt = null;
+
+        private final Set<File> snapshotDirs = new HashSet<>();
+
+        Builder(String keyspaceName, String tableName, UUID tableId, String tag)
+        {
+            this.keyspaceName = keyspaceName;
+            this.tableName = tableName;
+            this.tag = tag;
+            this.tableId = tableId;
+        }
+
+        void addSnapshotDir(File snapshotDir)
+        {
+            snapshotDirs.add(snapshotDir);
+            File manifestFile = new File(snapshotDir, ""manifest.json"");
+            if (manifestFile.exists() && createdAt == null && expiresAt == null) {
+                loadTimestampsFromManifest(manifestFile);
+            }
+        }
+
+        private void loadTimestampsFromManifest(File manifestFile)
+        {
+            try
+            {
+                logger.debug(""Loading snapshot manifest from {}"", manifestFile);
+                SnapshotManifest manifest = SnapshotManifest.deserializeFromJsonFile(manifestFile);
+                createdAt = manifest.createdAt;
+                expiresAt = manifest.expiresAt;
+            }
+            catch (IOException e)
+            {
+                logger.warn(""Cannot read manifest file {} of snapshot {}."", manifestFile, tag, e);

Review Comment:
   ```
   The SLF4J API supports parametrization in the presence of an exception, assuming the exception is the last parameter. Thus, 
   ```
   
   I've been using this for a while and it's the recommended way to log exception traces, and no longer use the previous workaround `logger.warn(String.format(""%s %s"", a, b), e)` which is required for `SLF4J < 1.6.0`.



;29/Apr/22 20:35;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862146828


##########
src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java:
##########
@@ -0,0 +1,137 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.service.snapshot;
+
+import java.io.IOException;
+import java.nio.file.FileVisitResult;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.SimpleFileVisitor;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Directories;
+import org.apache.cassandra.io.util.File;
+
+import static org.apache.cassandra.db.Directories.SNAPSHOT_SUBDIR;
+import static org.apache.cassandra.service.snapshot.TableSnapshot.buildSnapshotId;
+
+/**
+ * Loads snapshot metadata from data directories
+ */
+public class SnapshotLoader extends SimpleFileVisitor<Path>
+{
+    private static final Logger logger = LoggerFactory.getLogger(SnapshotLoader.class);
+
+    static final Pattern SNAPSHOT_DIR_PATTERN = Pattern.compile(""(?<keyspace>\\w+)/(?<tableName>\\w+)\\-(?<tableId>[0-9a-f]{32})/snapshots/(?<tag>[\\w-]+)$"");
+
+    private final Collection<Path> dataDirectories;
+    private final Map<String, TableSnapshot.Builder> snapshots = new HashMap<>();
+
+    public SnapshotLoader()
+    {
+        this(DatabaseDescriptor.getAllDataFileLocations());
+    }
+
+    public SnapshotLoader(String[] dataDirectories)
+    {
+        this.dataDirectories = Arrays.stream(dataDirectories).map(Paths::get).collect(Collectors.toList());
+    }
+
+    public SnapshotLoader(Collection<Path> dataDirs)
+    {
+        this.dataDirectories = dataDirs;
+    }
+
+    public Set<TableSnapshot> loadSnapshots()
+    {
+        for (Path dataDir : dataDirectories)
+        {
+            try
+            {
+                Files.walkFileTree(dataDir, Collections.EMPTY_SET, 5, this);
+            }
+            catch (IOException e)
+            {
+                throw new RuntimeException(String.format(""Error while loading snapshots from %s"", dataDir));
+            }
+        }
+        return snapshots.values().stream().map(TableSnapshot.Builder::build).collect(Collectors.toSet());
+    }
+
+    public FileVisitResult preVisitDirectory(Path subdir, BasicFileAttributes attrs)
+    {
+        if (subdir.getParent().getFileName().toString().equals(SNAPSHOT_SUBDIR))
+        {
+            logger.trace(""Processing directory "" + subdir);
+            Matcher snapshotDirMatcher = SNAPSHOT_DIR_PATTERN.matcher(subdir.toString());
+            if (snapshotDirMatcher.find())
+            {
+                try
+                {
+                    loadSnapshotFromDir(snapshotDirMatcher, subdir);
+                } catch (Throwable e)
+                {
+                    logger.warn(""Could not load snapshot from {}."", subdir, e);

Review Comment:
   Oh wow, that is very nice. So resolved.



;29/Apr/22 20:57;githubbot;600","smiklosovic commented on code in PR #1595:
URL: https://github.com/apache/cassandra/pull/1595#discussion_r862147350


##########
src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java:
##########
@@ -113,54 +136,174 @@ public long computeSizeOnDiskBytes()
 
     public long computeTrueSizeBytes()
     {
-        return snapshotDirs.stream().mapToLong(trueDiskSizeComputer::apply).sum();
+        DirectorySizeCalculator visitor = new SnapshotTrueSizeCalculator();
+
+        for (File snapshotDir : snapshotDirs)
+        {
+            try
+            {
+                Files.walkFileTree(snapshotDir.toPath(), visitor);
+            }
+            catch (IOException e)
+            {
+                logger.error(""Could not calculate the size of {}."", snapshotDir, e);
+            }
+        }
+
+        return visitor.getAllocatedSize();
     }
 
     public Collection<File> getDirectories()
     {
         return snapshotDirs;
     }
 
-    @Override
-    public String toString()
+    public Optional<File> getManifestFile()
     {
-        return ""TableSnapshot{"" +
-               ""keyspace='"" + keyspace + '\'' +
-               "", table='"" + table + '\'' +
-               "", tag='"" + tag + '\'' +
-               "", createdAt="" + createdAt +
-               "", expiresAt="" + expiresAt +
-               "", snapshotDirs="" + snapshotDirs +
-               '}';
+        for (File snapshotDir : snapshotDirs)
+        {
+            File manifestFile = Directories.getSnapshotManifestFile(snapshotDir);
+            if (manifestFile.exists())
+            {
+                return Optional.of(manifestFile);
+            }
+        }
+        return Optional.empty();
+    }
+
+    public Optional<File> getSchemaFile()
+    {
+        for (File snapshotDir : snapshotDirs)
+        {
+            File schemaFile = Directories.getSnapshotSchemaFile(snapshotDir);
+            if (schemaFile.exists())
+            {
+                return Optional.of(schemaFile);
+            }
+        }
+        return Optional.empty();
     }
 
     @Override
     public boolean equals(Object o)
     {
         if (this == o) return true;
         if (o == null || getClass() != o.getClass()) return false;
-        TableSnapshot that = (TableSnapshot) o;
-        return Objects.equals(keyspace, that.keyspace) && Objects.equals(table, that.table)
-               && Objects.equals(tag, that.tag) && Objects.equals(createdAt, that.createdAt)
-               && Objects.equals(expiresAt, that.expiresAt) && Objects.equals(snapshotDirs, that.snapshotDirs);
+        TableSnapshot snapshot = (TableSnapshot) o;
+        return Objects.equals(keyspaceName, snapshot.keyspaceName) && Objects.equals(tableName, snapshot.tableName) &&
+               Objects.equals(tableId, snapshot.tableId) && Objects.equals(tag, snapshot.tag) &&
+               Objects.equals(createdAt, snapshot.createdAt) && Objects.equals(expiresAt, snapshot.expiresAt) &&
+               Objects.equals(snapshotDirs, snapshot.snapshotDirs);
     }
 
     @Override
     public int hashCode()
     {
-        return Objects.hash(keyspace, table, tag, createdAt, expiresAt, snapshotDirs);
+        return Objects.hash(keyspaceName, tableName, tableId, tag, createdAt, expiresAt, snapshotDirs);
+    }
+
+    @Override
+    public String toString()
+    {
+        return ""TableSnapshot{"" +
+               ""keyspaceName='"" + keyspaceName + '\'' +
+               "", tableName='"" + tableName + '\'' +
+               "", tableId="" + tableId +
+               "", tag='"" + tag + '\'' +
+               "", createdAt="" + createdAt +
+               "", expiresAt="" + expiresAt +
+               "", snapshotDirs="" + snapshotDirs +
+               '}';
+    }
+
+    static class Builder {
+        private final String keyspaceName;
+        private final String tableName;
+        private final UUID tableId;
+        private final String tag;
+
+        private Instant createdAt = null;
+        private Instant expiresAt = null;
+
+        private final Set<File> snapshotDirs = new HashSet<>();
+
+        Builder(String keyspaceName, String tableName, UUID tableId, String tag)
+        {
+            this.keyspaceName = keyspaceName;
+            this.tableName = tableName;
+            this.tag = tag;
+            this.tableId = tableId;
+        }
+
+        void addSnapshotDir(File snapshotDir)
+        {
+            snapshotDirs.add(snapshotDir);
+            File manifestFile = new File(snapshotDir, ""manifest.json"");
+            if (manifestFile.exists() && createdAt == null && expiresAt == null) {
+                loadTimestampsFromManifest(manifestFile);
+            }
+        }
+
+        private void loadTimestampsFromManifest(File manifestFile)
+        {
+            try
+            {
+                logger.debug(""Loading snapshot manifest from {}"", manifestFile);
+                SnapshotManifest manifest = SnapshotManifest.deserializeFromJsonFile(manifestFile);
+                createdAt = manifest.createdAt;
+                expiresAt = manifest.expiresAt;
+            }
+            catch (IOException e)
+            {
+                logger.warn(""Cannot read manifest file {} of snapshot {}."", manifestFile, tag, e);

Review Comment:
   great.



;29/Apr/22 20:57;githubbot;600","smiklosovic closed pull request #1595: CASSANDRA-16843: List snapshots of dropped tables
URL: https://github.com/apache/cassandra/pull/1595


;30/Apr/22 09:23;githubbot;600","smiklosovic closed pull request #1590: CASSANDRA-16843: List snapshots of dropped tables
URL: https://github.com/apache/cassandra/pull/1590


;30/Apr/22 09:23;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,0,19200,,,0,19200,,CASSANDRA-16790,,,,,,CASSANDRA-17357,,,,,,,CASSANDRA-17357,CASSANDRA-6418,CASSANDRA-6821,CASSANDRA-13096,CASSANDRA-17568,CASSANDRA-13338,,,,,,,,CASSANDRA-17588,CASSANDRA-17267,,,CASSANDRA-16451,,,,,,0.0,paulo,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Apr 29 22:02:24 UTC 2022,,,,,,,All,,,,"0|z0tsg8:",9223372036854775807,,,,brandon.williams,smiklosovic,,,Low,,4.1,,https://github.com/apache/cassandra/commit/31aa17a2a3b18bdda723123cad811f075287807d,,,,,,,,,added in-jvm dtests and unit tests - documentation will be release notes,,,,,"11/Aug/21 06:29;flightc;I don't have any insight on why {{listsnapshots}} doesn't mirror what {{clearsnapshot}} does but it makes total sense to me that it should. (y);;;","11/Aug/21 06:42;manmagic3;Looks okay to me. List snapshot should only show snapshot of live tables. As per clearsnapshot, once table is dropped no point in keeping its backup. Any use case which requires clearsnapshot to not clear snapshot of dropped tables. For example if I have dropped a table x, then its old snapshot does not come in list snapshot which is correct in my opinion. For clearsnapshot if old snapshots are getting cleared, I dont find any reason not to clear them (Space gets created and old snapshots are not of any use as such). I think functionality is correct.;;;","11/Aug/21 07:09;flightc;{quote}As per clearsnapshot, once table is dropped no point in keeping its backup.
{quote}
 That's the point – {{clearsnapshot}} correctly identifies that there's are snapshots for dropped tables and are deleting them off the disk.

But I don't understand what you mean by this:
{quote}Any usecase which requires clearsnapshot to not clear snapshot of dropped tables.
{quote}
Could you please elaborate? :);;;","11/Aug/21 07:31;flightc;{quote}For example if I have dropped a table x, then its old snapshot does not come in list snapshot which is correct in my opinion.
{quote}
Personally, I think that kind of behaviour is confusing for an ordinary operator. Most would expect that {{listsnapshot}} would list all snapshots regardless of whether they're for existing or dropped tables. To me it's more intuitive. :);;;","11/Aug/21 13:19;brandon.williams;I agree this is a bug, it doesn't make sense to have some snapshots listed and others not, regardless of their creation method.;;;","11/Aug/21 20:27;brandon.williams;This is actually a regression from CASSANDRA-6821.;;;","17/Aug/21 13:40;brandon.williams;This unfortunately is not a simple thing to fix in an elegant manner.  We have a habit of assuming the lifetimes of snapshots will always be contained by their respective CFs.  It is that assumption that got us into both CASSANDRA-6418 and CASSANDRA-6821, and now this ticket as well.  Most of the code that handles snapshots is in instance methods of Directories.java, which is instantiated with CFMetatadata, and ultimately StorageService is accessing information through them from the ColumnFamilyStore... which won't exist for dropped tables.

For trunk I think we should probably refactor snapshot handling altogether to dissolve the marriage between CFs and snapshots a bit, but for existing versions I'm not sure what the least invasive way of reworking this is yet. ;;;","17/Aug/21 13:49;stefan.miklosovic;FYI we are working on this https://github.com/apache/cassandra/pull/1046/files

We plan to merge it basically this week (right [~paulo]?) We might try to get back to this afterwards to see if anything changed in that regard.;;;","17/Aug/21 13:51;brandon.williams;I'm aware of it.  It's another wrinkle to this problem that can't really be dealt with before the existing issues, but I'll take another look when it lands.;;;","17/Aug/21 13:52;stefan.miklosovic;We plan to overhaul snapshots a lot in a forseeable future so one might expect improvements and refactoring which would enable what you need.;;;","17/Aug/21 13:53;paulo;bq.  For trunk I think we should probably refactor snapshot handling altogether to dissolve the marriage between CFs and snapshots a bit, but for existing versions I'm not sure what the least invasive way of reworking this is yet.

We've been going towards this direction on CASSANDRA-16451 by centralizing snapshot management on a `SnapshotManager` module decoupled from CFS, but so far restricted to snapshots created with TTL. Myself and [~stefan.miklosovic] plan to extend this to ""legacy"" snapshots after that work is finished which will make it easier to solve this issue on trunk/4.1. ;;;","17/Aug/21 14:00;brandon.williams;bq. centralizing snapshot management on a `SnapshotManager` module decoupled from CFS

You have read my mind on where I'd like to see things go!  If only that didn't seem a bit too heavy handed for point releases...;;;","07/Nov/21 21:01;paulo;Added an initial trunk patch [on this PR|https://github.com/apache/cassandra/pull/1305] decoupling snapshot loading logic from {{ColumnFamilyStore}} which enables listing snapshots of dropped tables.

The basic idea is to search all data file locations for snapshot directories matching {{{}${data_dir}/${ks_name}/${table_name}-${table_uuid}/snapshots/{tag{}}}}, optionally with a json manifest ({{{}manifest.json{}}}) and feed these to {{SnapshotManager}} which will keep track of live snapshots listed by {{{}nodetool listsnapshots{}}}.

One potential issue is handling legacy data directories (2.x series iirc) which do not contain the UUID part. I'm not sure if these are still supported, if so we may need to handle these.

The snapshot searching logic is done by {{SnapshotFinder}} on [this commit|https://github.com/pauloricardomg/cassandra/commit/6b104afed5cd190ab43e97bad622feda5db5d2df] (with a few tests).

[This commit|https://github.com/pauloricardomg/cassandra/commit/ec53e8a5cec9dd58f574663c4ab48780de7feb4a] updates {{SnapshotManager}} initialization logic to use {{SnapshotFinder}} instead of {{Keyspace/ColumnFamilyStore}} to load snapshots into memory during startup.

The {{SnapshotManager}} class originally stored only expiring snapshots (added by CASSANDRA-16789), but after this patch it keeps an in-memory view of all live snapshots (expiring and non-expiring). As new snapshots are created they are registered on this class by {{ColumnFamilyStore}} via {{{}SnapshotManager.addSnapshot{}}}. In the future I want move snapshot creation logic completely out of {{ColumnFamilyStore}} leaving there only sstable hardlinking logic.

[This commit|https://github.com/pauloricardomg/cassandra/commit/c614f88b817145e83237f61975e0e8a1b4b71cff] makes snapshot listing use {{{}SnapshotManager.getSnapshots{}}}. This enables listing of dropped snapshots which is tested by the test [added on this commit|https://github.com/pauloricardomg/cassandra/commit/1fb024e6ab726da5c42f7937a8e97540d43fd7fd].

The previous change broke {{org.apache.cassandra.distributed.test.SnapshotsTest.testManualSnapshotCleanup}} because cleared snapshots were not removed from {{{}SnapshotManager{}}}. [This commit|https://github.com/pauloricardomg/cassandra/commit/2b1ec31885908b1199a93127668b2a4fd422a2c6] fixes this by moving snapshot cleanup logic to {{{}SnapshotManager{}}}.

Finally [this commit|https://github.com/pauloricardomg/cassandra/commit/6edb90ac025690566a7a1ebc138a6198bb8a9c28] fixes an NPE when computing the true size disk bytes of snapshots since these are not currently computed for snapshots loaded via {{{}SnapshotFinder{}}}. I will create a fix to this by moving this logic which is dependent of {{ColumnFamilyStore}} out of the {{TableSnapshot}} class.

I wanted to hear your initial feedback on the approach before addressing todos, working on edge cases (ie. secondary indexes, dropped tables with same names, snapshot tag uniqueness) and cleanup (ie. remove dead snapshot handling code).

Can you take a look [~brandon.williams], [~stefan.miklosovic] ?;;;","10/Nov/21 17:13;brandon.williams;This all makes sense and looks good so far to me.

bq. One potential issue is handling legacy data directories (2.x series iirc) which do not contain the UUID part. I'm not sure if these are still supported, if so we may need to handle these.

I don't think this should be an issue, at least not in trunk.;;;","05/Jan/22 17:10;brandon.williams;bq. I will create a fix to this by moving this logic which is dependent of ColumnFamilyStore out of the TableSnapshot class.

I'm +1 on this especially, as I recall it being problematic when I looked at this earlier.;;;","26/Apr/22 14:31;paulo;Submitted CI with intermediate patch to gather initial results: https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1631/;;;","27/Apr/22 20:22;smiklosovic;Is this ready to be reviewed? I am not sure if this is still indeed in ""in progress"".;;;","27/Apr/22 20:27;paulo;It's in progress, not ready for review yet.;;;","28/Apr/22 19:41;paulo;To provide some contextualization and recap before going into the implementation details, please find a little summary of what end-user changes will be made visible by this patch.

This is the current output of {{nodetool listsnapshots}} before this patch:
{noformat}
Snapshot Details:
Snapshot name Keyspace name Column family name True size Size on disk Creation time            Expiration time
test          ks            indexed_table      9.83 KiB  21.22 KiB    2022-04-26T19:13:20.102Z
test          ks            my_table           9.83 KiB  10.76 KiB    2022-04-26T19:13:20.102Z

Total TrueDiskSpaceUsed: 19.65 KiB
{noformat}
*The main problem being solved by this patch is that snapshots from dropped tables are omitted from this output.*

In addition to this, there are 2 additional issues with the previous output:
1) Snapshot ""true size"" column does not include {{manifest.json}} and {{schema.cql}} file sizes. This can be observed by the mismatching numbers in the ""true size"" (9.83 KiB) and ""size on disk"" (10.76 KiB) columns of {{my_table}}.
2) Snapshot ""true size"" of table with secondary index ({{indexed_table}}) does not include secondary index files (CASSANDRA-17357). This can be observed by the ""true size"" being 9.83 KiB while the ""size on disk"" is 21.22 KiB.

After this patch, the following output is displayed for the same data:
{noformat}
Snapshot Details:
Snapshot name                  Keyspace name Column family name True size Size on disk Creation time            Expiration time
test                           ks            indexed_table      21.22 KiB 21.22 KiB    2022-04-26T19:13:20.102Z
test                           ks            my_table           10.76 KiB 10.76 KiB    2022-04-26T19:13:20.102Z
dropped-1650997415751-my_table ks            my_table           989 bytes 989 bytes    2022-04-26T18:23:35.751Z

Total TrueDiskSpaceUsed: 32.95 KiB
{noformat}
The new output after this patch shows the snapshot ""true size"" equal to the ""size on disk"" when there are no live sstables.

(will follow-up with implementation details on next comment);;;","28/Apr/22 22:45;paulo;The reason why snapshots of ""dropped tables"" are omitted from the ""nodetool listsnapshots"" output above is because the prior implementation relied on the mechanics of [ColumnFamilyStore|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java#L2240=] and [Directories|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/Directories.java#L964=] to list snapshots.

Since dropped tables no longer have an associated {{ColumnFamilyStore}} object, it's not possible to list snapshots of dropped tables in the current implementation.

[This patch|https://github.com/apache/cassandra/pull/1595] re-architects the snapshot listing logic to be fully decoupled from {{{}ColumnFamilyStore{}}}/{{{}Directories{}}} and rely solely on the snapshot directory structure, which currently has this format:
 * {{$data_dir/$ks_name/$table_name-$table_uuid/snapshots/$tag}}

The new snapshot discovery logic is mostly contained in the [SnapshotLoader|https://github.com/apache/cassandra/blob/993190ada5b65b79c5b7ca707d436a6ceff7abcf/src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java] class, which traverses the data directory [looking for snapshot directories matching the pattern above|https://github.com/apache/cassandra/blob/993190ada5b65b79c5b7ca707d436a6ceff7abcf/src/java/org/apache/cassandra/service/snapshot/SnapshotLoader.java#L102=].

I updated [StorageService.getSnapshotDetails|https://github.com/apache/cassandra/pull/1595/files#diff-9bf2c26bc294ef9085e16bf287490223665eaa2eb8ec24bcf5bd8653c713644bR4131] which is used by {{nodetool listsnapshots}} to use new {{SnapshotLoader}} class to list snapshots.

The snapshot true size computation was previously dependent on logic from [Directories|https://github.com/apache/cassandra/blob/bb3749f2bb8282f67375c67712d8e3ca1f085879/src/java/org/apache/cassandra/db/Directories.java#L1153], so in order to fully decouple snapshot listing from {{Directories}}, I [simplified the computation of snapshot true size|https://github.com/apache/cassandra/blob/993190ada5b65b79c5b7ca707d436a6ceff7abcf/src/java/org/apache/cassandra/service/snapshot/TableSnapshot.java#L282] to only include files which do not have a corresponding ""live"" file on {{{}$data_dir/$ks_name/$table_name-$table_uuid{}}}.

This simplification to the snapshot true size computation fixed two additional issues with the previous implementation (illustrated with examples in the previous comment):
1) Snapshot true size did not include ""schema.cql"" and ""manifest.json"" sizes
2) Snapshot true size did not include secondary indexes (CASSANDRA-17357)

I performed other simplifications and refactorings along the way, but given the proximity to the 4.1 freeze, I prepared a leaner version of the original patch to facilitate review.

After this is merged I will prepare another set of follow-up patches (for next release) with refactorings and simplifications in the snapshot management module that will be enabled by this change.

Testing:
 - [dtest to check if snapshot of dropped tables are included on listsnapshots|https://github.com/apache/cassandra/blob/993190ada5b65b79c5b7ca707d436a6ceff7abcf/test/distributed/org/apache/cassandra/distributed/test/SnapshotsTest.java#L195=]
 - [SnapshotLoaderTest|https://github.com/apache/cassandra/blob/e3fd12ab2a112dad5cdba7cda226aab12f0c2c04/test/unit/org/apache/cassandra/service/snapshot/SnapshotLoaderTest.java]
 - [Test to check that manifest and schema file sizes are included in true size computation|https://github.com/apache/cassandra/blob/e3fd12ab2a112dad5cdba7cda226aab12f0c2c04/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java#L266=]
 - [Update DirectoriesTest.testSecondaryIndexDirectories to include 2i on true size computation|https://github.com/apache/cassandra/blob/e3fd12ab2a112dad5cdba7cda226aab12f0c2c04/test/unit/org/apache/cassandra/db/DirectoriesTest.java#L420=]
 - [testGetLiveFileFromSnapshotFile (used by new true size computation)|https://github.com/apache/cassandra/blob/993190ada5b65b79c5b7ca707d436a6ceff7abcf/test/unit/org/apache/cassandra/service/snapshot/TableSnapshotTest.java#L233=];;;","28/Apr/22 22:50;paulo;[~brandon.williams] [~smiklosovic] This is finally ready for a final round of review and I apologize for the delay. Please check the 2 previous comments for context.


Even though I'd like to get this in, I will understand if you're not able to get to this before the 4.1 freeze.


|[trunk|https://github.com/apache/cassandra/pull/1595]|[tests|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1645/]|;;;","29/Apr/22 12:16;smiklosovic;I reviewed it and put my comments there. I ll return to this in the late evening today CEST time to see if there was some progress. I do not mind if we merge this now but the proximity of the freeze makes me uncomfortable a bit. However, if we find there are some minor issues with this during freeze, we can still fix it there as well.;;;","29/Apr/22 14:45;paulo;bq. I do not mind if we merge this now but the proximity of the freeze makes me uncomfortable a bit.

This patch in its current state is fairly low risk, since it only updates the implementation of ""nodetool listsnapshots"" without touching other components. Furthermore this area is pretty well covered by unit tests and dtests.

I realized the original larger patch had a higher risk as it was also touching other areas like snapshot cleanup and ephemeral snapshots, so I decided to split the original patch to only contain the minimum viable set. I will create tickets for follow-up work for 4.2.

bq. I reviewed it and put my comments there. 

Thanks for the prompt review. Addressed comments [on this commit|https://github.com/apache/cassandra/pull/1595/commits/d1834c88c362f3804f9817e6d2cd80c6fd0e8d4b].

[CI failures|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1645/testReport/] look unrelated.

I will squash + rebase and re-submit CI shortly.;;;","29/Apr/22 15:07;paulo;Squashed and rebased patch after review comments, prepared for commit:
|[squashed commit|https://github.com/apache/cassandra/commit/01a7d1e1fcb63f1413e5e9dd96f3ca2bbb829f3d]|[tests|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1646/]|

Feel free to take a sanity check look if you have cycles [~brandon.williams].;;;","29/Apr/22 15:10;brandon.williams;Was just looking and it looks good to me after the latest commit. I'll check CI when it's complete but I'm +1 if that doesn't have any new failures.;;;","29/Apr/22 20:40;smiklosovic;I think I hit few bugs:

1) listsnapshots gives me ""Total TrueDiskSpaceUsed: 0 bytes"" irrelevant how many snapshots I have

2) Not sure if it is a bug but it is weird - when I list snapshots, it gives me some values in True Size / Size on Disk but when I drop that table and I list snapshots again, these sizes are different.

I am -1 on this as it is in the current state, unfortunately. We can still merge this if these problems are addressed before the freeze. I will be online occasionaly during weekend too.

EDIT: I was thinking I hit a bug with not deleting expired snapshots for dropped table but I think that I was wrong on my side, I just have not waited long enough.;;;","29/Apr/22 20:50;paulo;Can you paste the full output for the ""listsnapshots"" value that you're observing? this would help debug.

I remember testing before submitting and it was working as expected. Let me try again.;;;","29/Apr/22 20:52;paulo;{quote}Not sure if it is a bug but it is weird - when I list snapshots, it gives me some values in True Size / Size on Disk but when I drop that table and I list snapshots again, these sizes are different.
{quote}
This is not a bug. The true size should be very small when the table is live, because live sstables are skipped and the true size only accounts for the manifest and schema file sizes.

 

When the table is dropped the true size is equal to the size on disk because no sstables are live.;;;","29/Apr/22 20:58;paulo;{quote}listsnapshots gives me ""Total TrueDiskSpaceUsed: 0 bytes"" irrelevant how many snapshots I have
{quote}

*Total* true disk space (which is different from ""true disk space"" of individual snapshots) is zero because all sstables are live, so snapshots are not taking any extra space.

This is working as expected. It's the current behavior on trunk and it is not changed by this patch.

However there is another bug there, because ""Total TrueDiskSpaceUsed"" should include sizes of schema and manifest files.

I do not touch the code path that is responsible for computing ""{*}Total{*} TrueDiskSpaceUsed"" on this patch. The true disk space should also include manifest and schema files, but fixing that requires a reworking of how the *total* true size is computed, and is out of the scope of this patch.

I fixed this on the extended version of this patch that will be posted later.;;;","29/Apr/22 21:10;smiklosovic;_When the table is dropped the true size is equal to the size on disk because no sstables are live._ 

Right ... Ok I think this explains it.

_True disk space is zero because all sstables are live, so snapshots are not taking any extra space._

Ok, I compacted the table and took a snapshot again and it started to be non-zero.

Ok so it seems we are good after all, minus that bug you mentioned.

So what is your strategy, you want to merge this and in the freeze you take care of the bugs? In that case I think that might fly.;;;","29/Apr/22 21:12;paulo;In order to make things easier to understand, since this is indeed a bit confusing:

Each individual snapshot has two attributes:
* {*}Size on disk{*}: the amount of disk space used by a specific snapshot.
* *TrueDiskSpaceUsed:* the amount of *extra* disk space used by a snapshot (snapshot_size - live_sstables)

Before this patch, the *TrueDiskSpace* metric was incorrectly calculated, because:
a) It did not include the size of manifest and schema files.
b) It did not include the size of secondary indexes.

The behavior above was fixed by this patch.

This means that when you create a snapshot on ccm:
* *Size on disk* should be equal to the size of the snapshots
* *TrueDiskSpaceUsed* should only include the size of manifest+schema file, since there are live sstables, so the snapshot is not taking more space to store these sstables which are hard-linked.

When you drop the table, the snapshot no longer has live data so *Size on disk* = *TrueDiskSpaceUsed* (this was not the case before this patch, because *TrueDiskSpaceUsed* did not previously include the size of manifest and schema files, so *Size on disk* > *TrueDiskSpaceUsed.*

In addition to that, the *Total TrueDiskSpaceUsed* is computed by a different code path, and still has the following limitation:
a) It does not include the size of manifest and schema files.

Fixing the *Total TrueDiskSpaceUsed* metric is out of the scope of this patch because required additional changes. It will be fixed on a follow-up ticket.;;;","29/Apr/22 21:14;paulo;{quote}So what is your strategy, you want to merge this and in the freeze you take care of the bugs? In that case I think that might fly.
{quote}
The minor bug on the *Total TrueDiskSpaceUsed* computation was not introduced by this patch, it is like that on all versions below trunk. We can fix it whenever we want, but it probably shouldn't block this.;;;","29/Apr/22 21:20;smiklosovic;Yes, that's how I understood it, probably not communicated properly, ""take care of the bugs"" not like ""remaining bugs in this ticket"" but ""other bugs related to this subsystem we just stumbled upon while discussing this.""

Let's ship this then on a reasonably clean build.;;;","29/Apr/22 21:26;paulo;Created CASSANDRA-17588 to address *Total TrueDiskSpaceUsed* computation.

bq. Let's ship this then on a reasonably clean build.

CI looks [good|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1646/]. Can we merge?;;;","29/Apr/22 22:02;paulo;Since CI looks good, I merged this as [31aa17a2a3b18bdda723123cad811f075287807d|https://github.com/apache/cassandra/commit/31aa17a2a3b18bdda723123cad811f075287807d] to trunk.

Thanks all for the prompt reviews!;;;",,,,,,,,,,,,,,,,,,
Unexpectedly ignored dtests,CASSANDRA-16841,13394477,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,k-rus,k-rus,k-rus,10/Aug/21 15:37,27/May/22 19:25,13/Jul/23 08:40,14/Sep/21 11:21,3.0.26,3.11.12,4.0.2,4.1,4.1-alpha1,,,Test/dtest/python,,,,0,,,"An issue, which I was hit:

When one class in a dtest file is marked as resource intensive, then all tests in all classes are treated as resource intensive. For example, [repair_tests/repair_test.py|https://github.com/apache/cassandra-dtest/blob/trunk/repair_tests/repair_test.py] contains three classes and the last class is marked as resource intensive:
{code:java}
@pytest.mark.resource_intensive
class TestRepairDataSystemTable(Tester):
{code}
So if I try to run an unmarked class: 
{code:java}
pytest --cassandra-dir=../cassandra repair_tests/repair_test.py::TestRepair --collect-only --skip-resource-intensive-tests
{code}
then all tests are ignored
{code:java}
collected 36 items / 36 deselected 
{code}
This is because a test is treated to be marked if any class in the same file has the mark. This bug was introduced in the fix of CASS-16399. Before only upgrade tests had such behaviour, i.e., if a class is marked as upgrade test, then all tests are upgrade test in the file.

 

This bug, for example, means that if the same file contains one class marked with vnodes and another class with no_vnodes, then no tests will be executed in the file.

I also noticed another issue that If a test run is executed with the argument {{-only-resource-intensive-tests}} and there is no sufficient resources for resource intensive tests, then no tests were executed. Thus it was necessary to provide {{-force-resource-intensive-tests}} in addition.

Suggestions for the solutions:
 # Require to mark each class and remove the special case of upgrade tests. This will simplify the implementation and might be more obvious for new comers.
 # Treat {{-only-resource-intensive-tests}} in the same way as {{-force-resource-intensive-tests}}, so it will be enough to just specify it even with no sufficient resources.

*Update:* comments were provided to keep only the first suggestion and do not implement the second suggestion. 

 ",,adelapena,brandon.williams,e.dimitrova,k-rus,,,,,,,,,,,,"k-rus commented on pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#issuecomment-898456995


   [CircleCI build](https://app.circleci.com/pipelines/github/k-rus/cassandra?branch=CASS-16841-CI) is running


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Aug/21 13:26;githubbot;600","adelapena commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r702037038



##########
File path: conftest.py
##########
@@ -545,53 +544,46 @@ def cassandra_dir_and_version(config):
     return cassandra_dir, cassandra_version
 
 
-def has_mark(item, mark):
+def _is_skippable(item, mark, skip_marked, skip_non_marked):
     if item.get_closest_marker(mark) is not None:
-        return True
-    else:
-        for item_module in inspect.getmembers(item.module, inspect.isclass):
-            if hasattr(item_module[1], ""pytestmark""):
-                mark_names = [m.name for m in item_module[1].pytestmark]
-                if mark in mark_names:
-                    return True
-
-        return False
-
-
-def _is_skippable(item, mark, include_marked, include_other):
-    if has_mark(item, mark):
-        if include_marked:
-            return False
-        else:
-            logger.info(""SKIP: Skipping %s because it is marked with %s"" % (item, mark))
+        if skip_marked:
+            logger.info(
+                ""SKIP: Skipping %s because it is marked with %s"" % (item, mark))
             return True
-    else:
-        if include_other:
-            return False
         else:
-            logger.info(""SKIP: Skipping %s because it is not marked with %s"" % (item, mark))
+            return False
+    else:
+        if skip_non_marked:
+            logger.info(
+                ""SKIP: Skipping %s because it is not marked with %s"" % (item, mark))
             return True
+        else:
+            return False
 
 
-def is_skippable(item,
-                 include_upgrade_tests,
-                 include_non_upgrade_tests,
-                 include_resource_intensive_tests,
-                 include_non_resource_intensive_tests,
-                 include_vnodes_tests,
-                 include_no_vnodes_tests,
-                 include_no_offheap_memtables_tests):
-
-    skippable = False
+class SkipConditions:

Review comment:
       If we are going to pack these vars into a new class perhaps we could also place `_is_skippable` and `is_skippable` inside the class, for example [this way](https://github.com/adelapena/cassandra-dtest/commit/bb3b4382a59c453ccfcd8b85c5cbc70afe8b5cee).

##########
File path: conftest.py
##########
@@ -545,53 +544,46 @@ def cassandra_dir_and_version(config):
     return cassandra_dir, cassandra_version
 
 
-def has_mark(item, mark):
+def _is_skippable(item, mark, skip_marked, skip_non_marked):
     if item.get_closest_marker(mark) is not None:
-        return True
-    else:
-        for item_module in inspect.getmembers(item.module, inspect.isclass):
-            if hasattr(item_module[1], ""pytestmark""):
-                mark_names = [m.name for m in item_module[1].pytestmark]
-                if mark in mark_names:
-                    return True
-
-        return False
-
-
-def _is_skippable(item, mark, include_marked, include_other):
-    if has_mark(item, mark):
-        if include_marked:
-            return False
-        else:
-            logger.info(""SKIP: Skipping %s because it is marked with %s"" % (item, mark))
+        if skip_marked:
+            logger.info(
+                ""SKIP: Skipping %s because it is marked with %s"" % (item, mark))
             return True
-    else:
-        if include_other:
-            return False
         else:
-            logger.info(""SKIP: Skipping %s because it is not marked with %s"" % (item, mark))
+            return False
+    else:
+        if skip_non_marked:
+            logger.info(
+                ""SKIP: Skipping %s because it is not marked with %s"" % (item, mark))
             return True
+        else:
+            return False
 
 
-def is_skippable(item,
-                 include_upgrade_tests,
-                 include_non_upgrade_tests,
-                 include_resource_intensive_tests,
-                 include_non_resource_intensive_tests,
-                 include_vnodes_tests,
-                 include_no_vnodes_tests,
-                 include_no_offheap_memtables_tests):
-
-    skippable = False
+class SkipConditions:
+    def __init__(self, dtest_config, sufficient_resources):
+        self.skip_upgrade_tests = not dtest_config.execute_upgrade_tests and not dtest_config.execute_upgrade_tests_only
+        self.skip_non_upgrade_tests = dtest_config.execute_upgrade_tests_only
+        self.skip_resource_intensive_tests = (
+            not dtest_config.force_execution_of_resource_intensive_tests
+            and not dtest_config.only_resource_intensive_tests
+            and not sufficient_resources) or dtest_config.skip_resource_intensive_tests
+        self.skip_non_resource_intensive_tests = dtest_config.only_resource_intensive_tests
+        self.skip_vnodes_tests = not dtest_config.use_vnodes
+        self.skip_no_vnodes_tests = dtest_config.use_vnodes
+        self.skip_no_offheap_memtables_tests = dtest_config.use_off_heap_memtables
 
-    skippable = skippable or _is_skippable(item, ""upgrade_test"", include_upgrade_tests, include_non_upgrade_tests)
-    skippable = skippable or _is_skippable(item, ""resource_intensive"", include_resource_intensive_tests, include_non_resource_intensive_tests)
-    skippable = skippable or _is_skippable(item, ""vnodes"", include_vnodes_tests, True)
-    skippable = skippable or _is_skippable(item, ""no_vnodes"", include_no_vnodes_tests, True)
-    skippable = skippable or _is_skippable(item, ""no_offheap_memtables"", include_no_offheap_memtables_tests, True)
-    skippable = skippable or _is_skippable(item, ""depends_driver"", False, True)
 
-    return skippable
+def is_skippable(item, skip_cond):
+    return (_is_skippable(item, ""upgrade_test"",
+                          skip_cond.skip_upgrade_tests, skip_cond.skip_non_upgrade_tests)
+            or _is_skippable(item, ""resource_intensive"",
+                             skip_cond.skip_resource_intensive_tests, skip_cond.skip_non_resource_intensive_tests)
+            or _is_skippable(item, ""vnodes"", skip_cond.skip_vnodes_tests, skip_non_marked=False)
+            or _is_skippable(item, ""no_vnodes"", skip_cond.skip_no_vnodes_tests, skip_non_marked=False)
+            or _is_skippable(item, ""no_offheap_memtables"", skip_cond.skip_no_offheap_memtables_tests, skip_non_marked=False)
+            or _is_skippable(item, ""depends_driver"", skip_marked=True, skip_non_marked=False))

Review comment:
       Nit: maybe this block would be a bit easier to read if we always name the `skip_marked`/`skip_non_marked` parameters:
   ```suggestion
       return (self._is_skippable(item, ""upgrade_test"",
                                  skip_marked=self.skip_upgrade_tests,
                                  skip_non_marked=self.skip_non_upgrade_tests)
               or self._is_skippable(item, ""resource_intensive"",
                                     skip_marked=self.skip_resource_intensive_tests,
                                     skip_non_marked=self.skip_non_resource_intensive_tests)
               or self._is_skippable(item, ""vnodes"",
                                     skip_marked=self.skip_vnodes_tests,
                                     skip_non_marked=False)
               or self._is_skippable(item, ""no_vnodes"",
                                     skip_marked=self.skip_no_vnodes_tests,
                                     skip_non_marked=False)
               or self._is_skippable(item, ""no_offheap_memtables"",
                                     skip_marked=self.skip_no_offheap_memtables_tests,
                                     skip_non_marked=False)
               or self._is_skippable(item, ""depends_driver"",
                                     skip_marked=True,
                                     skip_non_marked=False))
   ```

##########
File path: upgrade_tests/paging_test.py
##########
@@ -188,6 +188,7 @@ def random_txt(text):
             assert_lists_equal_ignoring_order(pf.all_data(), expected_data, sort_key='value')
 
 
+@pytest.mark.upgrade_test

Review comment:
       Can we simply add the annotation to `BasePagingTester`, which is the parent of all the marked tests, [this way](https://github.com/adelapena/cassandra-dtest/commit/c3668b62654b0b5f11eccb9e2cfd74d1e164d990)?

##########
File path: conftest.py
##########
@@ -545,53 +544,46 @@ def cassandra_dir_and_version(config):
     return cassandra_dir, cassandra_version
 
 
-def has_mark(item, mark):
+def _is_skippable(item, mark, skip_marked, skip_non_marked):
     if item.get_closest_marker(mark) is not None:
-        return True
-    else:
-        for item_module in inspect.getmembers(item.module, inspect.isclass):
-            if hasattr(item_module[1], ""pytestmark""):
-                mark_names = [m.name for m in item_module[1].pytestmark]
-                if mark in mark_names:
-                    return True
-
-        return False
-
-
-def _is_skippable(item, mark, include_marked, include_other):
-    if has_mark(item, mark):
-        if include_marked:
-            return False
-        else:
-            logger.info(""SKIP: Skipping %s because it is marked with %s"" % (item, mark))
+        if skip_marked:
+            logger.info(
+                ""SKIP: Skipping %s because it is marked with %s"" % (item, mark))

Review comment:
       Nit: I think we don't need to break this line nor the other `loggger.info` call right below
   ```suggestion
               logger.info(""SKIP: Skipping %s because it is marked with %s"" % (item, mark))
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Sep/21 17:02;githubbot;600","adelapena commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r702050453



##########
File path: .gitignore
##########
@@ -10,3 +10,4 @@ last_test_dir
 upgrade
 html/
 doxygen/doxypy-0.4.2/
+.pytest_cache/

Review comment:
       +1000




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Sep/21 17:11;githubbot;600","adelapena commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r702065709



##########
File path: conftest.py
##########
@@ -605,28 +597,17 @@ def pytest_collection_modifyitems(items, config):
     selected_items = []
     deselected_items = []
 
-    can_run_resource_intensive_tests = dtest_config.force_execution_of_resource_intensive_tests or sufficient_system_resources_for_resource_intensive_tests()
-    if not can_run_resource_intensive_tests:
-        logger.info(""Resource intensive tests will be skipped because there is not enough system resource ""
-                    ""and --force-resource-intensive-tests was not specified"")
+    sufficient_resources = sufficient_system_resources_for_resource_intensive_tests()
+    skip_conditions = SkipConditions(dtest_config, sufficient_resources)
 
-    include_upgrade_tests = dtest_config.execute_upgrade_tests or dtest_config.execute_upgrade_tests_only
-    include_non_upgrade_tests = not dtest_config.execute_upgrade_tests_only
-    include_resource_intensive_tests = can_run_resource_intensive_tests and not dtest_config.skip_resource_intensive_tests
-    include_non_resource_intensive_tests = not dtest_config.only_resource_intensive_tests
-    include_vnodes_tests = dtest_config.use_vnodes
-    include_no_vnodes_tests = not dtest_config.use_vnodes
-    include_no_offheap_memtables_tests = not dtest_config.use_off_heap_memtables
+    if skip_conditions.skip_resource_intensive_tests:
+        logger.info(""Resource intensive tests will be skipped because ""
+                    ""it was requested to skip or there is not enough system resource ""
+                    ""and --force-resource-intensive-tests or --only-resource-intensive-tests ""
+                    ""were not specified"")

Review comment:
       I don't see why skipping resource intensive tests with not enough resources and `--only-resource-intensive-tests` is wrong. IMO it makes sense to require the `--force-resource-intensive-tests` in that case, since one flag controls the selection and the other one skips the resource check. Let's see what the second reviewer thinks about this. In any case if we are going the behaviour of the flags or we find them confusing we should probably extend their descriptions in `pytest_addoption` and `run_dtests.py`.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Sep/21 17:39;githubbot;600","adelapena commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r702065709



##########
File path: conftest.py
##########
@@ -605,28 +597,17 @@ def pytest_collection_modifyitems(items, config):
     selected_items = []
     deselected_items = []
 
-    can_run_resource_intensive_tests = dtest_config.force_execution_of_resource_intensive_tests or sufficient_system_resources_for_resource_intensive_tests()
-    if not can_run_resource_intensive_tests:
-        logger.info(""Resource intensive tests will be skipped because there is not enough system resource ""
-                    ""and --force-resource-intensive-tests was not specified"")
+    sufficient_resources = sufficient_system_resources_for_resource_intensive_tests()
+    skip_conditions = SkipConditions(dtest_config, sufficient_resources)
 
-    include_upgrade_tests = dtest_config.execute_upgrade_tests or dtest_config.execute_upgrade_tests_only
-    include_non_upgrade_tests = not dtest_config.execute_upgrade_tests_only
-    include_resource_intensive_tests = can_run_resource_intensive_tests and not dtest_config.skip_resource_intensive_tests
-    include_non_resource_intensive_tests = not dtest_config.only_resource_intensive_tests
-    include_vnodes_tests = dtest_config.use_vnodes
-    include_no_vnodes_tests = not dtest_config.use_vnodes
-    include_no_offheap_memtables_tests = not dtest_config.use_off_heap_memtables
+    if skip_conditions.skip_resource_intensive_tests:
+        logger.info(""Resource intensive tests will be skipped because ""
+                    ""it was requested to skip or there is not enough system resource ""
+                    ""and --force-resource-intensive-tests or --only-resource-intensive-tests ""
+                    ""were not specified"")

Review comment:
       I don't see why skipping resource intensive tests with not enough resources and `--only-resource-intensive-tests` is wrong. IMO it makes sense to require the `--force-resource-intensive-tests` flag in that case, since one flag controls the selection and the other one skips the resource check. Let's see what the second reviewer thinks about this. In any case if we are going to change the behaviour of the flags or we find them confusing we should probably extend their descriptions in `pytest_addoption` and `run_dtests.py`.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Sep/21 17:40;githubbot;600","k-rus commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r702677803



##########
File path: conftest.py
##########
@@ -545,53 +544,46 @@ def cassandra_dir_and_version(config):
     return cassandra_dir, cassandra_version
 
 
-def has_mark(item, mark):
+def _is_skippable(item, mark, skip_marked, skip_non_marked):
     if item.get_closest_marker(mark) is not None:
-        return True
-    else:
-        for item_module in inspect.getmembers(item.module, inspect.isclass):
-            if hasattr(item_module[1], ""pytestmark""):
-                mark_names = [m.name for m in item_module[1].pytestmark]
-                if mark in mark_names:
-                    return True
-
-        return False
-
-
-def _is_skippable(item, mark, include_marked, include_other):
-    if has_mark(item, mark):
-        if include_marked:
-            return False
-        else:
-            logger.info(""SKIP: Skipping %s because it is marked with %s"" % (item, mark))
+        if skip_marked:
+            logger.info(
+                ""SKIP: Skipping %s because it is marked with %s"" % (item, mark))

Review comment:
       It is not required. I guess I had default setting for autopep8. I will restore it back.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;06/Sep/21 07:45;githubbot;600","k-rus commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r702679052



##########
File path: conftest.py
##########
@@ -605,28 +597,17 @@ def pytest_collection_modifyitems(items, config):
     selected_items = []
     deselected_items = []
 
-    can_run_resource_intensive_tests = dtest_config.force_execution_of_resource_intensive_tests or sufficient_system_resources_for_resource_intensive_tests()
-    if not can_run_resource_intensive_tests:
-        logger.info(""Resource intensive tests will be skipped because there is not enough system resource ""
-                    ""and --force-resource-intensive-tests was not specified"")
+    sufficient_resources = sufficient_system_resources_for_resource_intensive_tests()
+    skip_conditions = SkipConditions(dtest_config, sufficient_resources)
 
-    include_upgrade_tests = dtest_config.execute_upgrade_tests or dtest_config.execute_upgrade_tests_only
-    include_non_upgrade_tests = not dtest_config.execute_upgrade_tests_only
-    include_resource_intensive_tests = can_run_resource_intensive_tests and not dtest_config.skip_resource_intensive_tests
-    include_non_resource_intensive_tests = not dtest_config.only_resource_intensive_tests
-    include_vnodes_tests = dtest_config.use_vnodes
-    include_no_vnodes_tests = not dtest_config.use_vnodes
-    include_no_offheap_memtables_tests = not dtest_config.use_off_heap_memtables
+    if skip_conditions.skip_resource_intensive_tests:
+        logger.info(""Resource intensive tests will be skipped because ""
+                    ""it was requested to skip or there is not enough system resource ""
+                    ""and --force-resource-intensive-tests or --only-resource-intensive-tests ""
+                    ""were not specified"")

Review comment:
       I explained my thoughts in the Jira ticket, so I guess we continue there and let's see what others think about it.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;06/Sep/21 07:47;githubbot;600","k-rus commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r702710177



##########
File path: upgrade_tests/paging_test.py
##########
@@ -188,6 +188,7 @@ def random_txt(text):
             assert_lists_equal_ignoring_order(pf.all_data(), expected_data, sort_key='value')
 
 
+@pytest.mark.upgrade_test

Review comment:
       Thank you for pointing it. Actually marking `BasePagingTester` is not needed, since it inherits form `UpgradeTester`, which is already marked. My main concern is that the marking becomes implicit. I don't know if it will be confusing or not, while  believe developers will have intention that all tests are marked as upgrade tests in this folder. I can try to clarify in `upgrade_tests/README.md` that using `UpgradeTester` is enough.
   
   I tested that it works in `pytest`, however the readme instructions use `nosetests` to run upgrade tests.
   




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;06/Sep/21 08:33;githubbot;600","k-rus commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r702710645



##########
File path: conftest.py
##########
@@ -545,53 +544,46 @@ def cassandra_dir_and_version(config):
     return cassandra_dir, cassandra_version
 
 
-def has_mark(item, mark):
+def _is_skippable(item, mark, skip_marked, skip_non_marked):
     if item.get_closest_marker(mark) is not None:
-        return True
-    else:
-        for item_module in inspect.getmembers(item.module, inspect.isclass):
-            if hasattr(item_module[1], ""pytestmark""):
-                mark_names = [m.name for m in item_module[1].pytestmark]
-                if mark in mark_names:
-                    return True
-
-        return False
-
-
-def _is_skippable(item, mark, include_marked, include_other):
-    if has_mark(item, mark):
-        if include_marked:
-            return False
-        else:
-            logger.info(""SKIP: Skipping %s because it is marked with %s"" % (item, mark))
+        if skip_marked:
+            logger.info(
+                ""SKIP: Skipping %s because it is marked with %s"" % (item, mark))
             return True
-    else:
-        if include_other:
-            return False
         else:
-            logger.info(""SKIP: Skipping %s because it is not marked with %s"" % (item, mark))
+            return False
+    else:
+        if skip_non_marked:
+            logger.info(
+                ""SKIP: Skipping %s because it is not marked with %s"" % (item, mark))
             return True
+        else:
+            return False
 
 
-def is_skippable(item,
-                 include_upgrade_tests,
-                 include_non_upgrade_tests,
-                 include_resource_intensive_tests,
-                 include_non_resource_intensive_tests,
-                 include_vnodes_tests,
-                 include_no_vnodes_tests,
-                 include_no_offheap_memtables_tests):
-
-    skippable = False
+class SkipConditions:

Review comment:
       Thank you for the suggestion with the patch. Looks nice. I plan to incorporate it into the patch.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;06/Sep/21 08:33;githubbot;600","k-rus commented on pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#issuecomment-913600173


   I addressed comments and started [new build in CircleCI](https://app.circleci.com/pipelines/github/k-rus/cassandra?branch=CASS-16841-CI).


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;06/Sep/21 12:12;githubbot;600","adelapena commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r702998318



##########
File path: upgrade_tests/paging_test.py
##########
@@ -188,6 +188,7 @@ def random_txt(text):
             assert_lists_equal_ignoring_order(pf.all_data(), expected_data, sort_key='value')
 
 
+@pytest.mark.upgrade_test

Review comment:
       I think that the note in the readme makes this clearer, thanks. At some point we will have to clear the references to nosetests, but I think there is no need to do it during this ticket.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;06/Sep/21 16:17;githubbot;600","k-rus commented on pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#issuecomment-916211330


   Addressed comment and run [j11_dtest build](https://app.circleci.com/pipelines/github/k-rus/cassandra/10/workflows/e56bdedd-45ba-466f-ae32-a003b9004063)


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Sep/21 15:36;githubbot;600","adelapena commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r705551579



##########
File path: conftest.py
##########
@@ -605,28 +603,16 @@ def pytest_collection_modifyitems(items, config):
     selected_items = []
     deselected_items = []
 
-    can_run_resource_intensive_tests = dtest_config.force_execution_of_resource_intensive_tests or sufficient_system_resources_for_resource_intensive_tests()
-    if not can_run_resource_intensive_tests:
-        logger.info(""Resource intensive tests will be skipped because there is not enough system resource ""
-                    ""and --force-resource-intensive-tests was not specified"")
+    sufficient_resources = sufficient_system_resources_for_resource_intensive_tests()
+    skip_conditions = SkipConditions(dtest_config, sufficient_resources)
 
-    include_upgrade_tests = dtest_config.execute_upgrade_tests or dtest_config.execute_upgrade_tests_only
-    include_non_upgrade_tests = not dtest_config.execute_upgrade_tests_only
-    include_resource_intensive_tests = can_run_resource_intensive_tests and not dtest_config.skip_resource_intensive_tests
-    include_non_resource_intensive_tests = not dtest_config.only_resource_intensive_tests
-    include_vnodes_tests = dtest_config.use_vnodes
-    include_no_vnodes_tests = not dtest_config.use_vnodes
-    include_no_offheap_memtables_tests = not dtest_config.use_off_heap_memtables
+    if skip_conditions.skip_resource_intensive_tests:
+        logger.info(""Resource intensive tests will be skipped because ""
+                    ""it was requested to skip or there is not enough system resource ""
+                    ""and --force-resource-intensive-tests were not specified"")

Review comment:
       ```suggestion
                       ""and --force-resource-intensive-tests was not specified"")
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Sep/21 17:27;githubbot;600","k-rus commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r705955561



##########
File path: conftest.py
##########
@@ -605,28 +603,16 @@ def pytest_collection_modifyitems(items, config):
     selected_items = []
     deselected_items = []
 
-    can_run_resource_intensive_tests = dtest_config.force_execution_of_resource_intensive_tests or sufficient_system_resources_for_resource_intensive_tests()
-    if not can_run_resource_intensive_tests:
-        logger.info(""Resource intensive tests will be skipped because there is not enough system resource ""
-                    ""and --force-resource-intensive-tests was not specified"")
+    sufficient_resources = sufficient_system_resources_for_resource_intensive_tests()
+    skip_conditions = SkipConditions(dtest_config, sufficient_resources)
 
-    include_upgrade_tests = dtest_config.execute_upgrade_tests or dtest_config.execute_upgrade_tests_only
-    include_non_upgrade_tests = not dtest_config.execute_upgrade_tests_only
-    include_resource_intensive_tests = can_run_resource_intensive_tests and not dtest_config.skip_resource_intensive_tests
-    include_non_resource_intensive_tests = not dtest_config.only_resource_intensive_tests
-    include_vnodes_tests = dtest_config.use_vnodes
-    include_no_vnodes_tests = not dtest_config.use_vnodes
-    include_no_offheap_memtables_tests = not dtest_config.use_off_heap_memtables
+    if skip_conditions.skip_resource_intensive_tests:
+        logger.info(""Resource intensive tests will be skipped because ""
+                    ""it was requested to skip or there is not enough system resource ""
+                    ""and --force-resource-intensive-tests were not specified"")

Review comment:
       Thank you for catching this!




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Sep/21 07:25;githubbot;600","adelapena commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r707367774



##########
File path: bootstrap_test.py
##########
@@ -1097,3 +1097,12 @@ def test_host_id_override(self):
         # 3. check host_id in other node's table
         session1 = self.patient_exclusive_cql_connection(node1)
         assert_one(session1, ""SELECT host_id FROM system.peers_v2 WHERE peer = {}"".format(address2), [uuid.UUID(host_id)])
+
+class TestBootstrap(BootstrapTester):

Review comment:
       Nit: missed additional blank line before the class declaration




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Sep/21 14:05;githubbot;600","k-rus commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r707396317



##########
File path: bootstrap_test.py
##########
@@ -1097,3 +1097,12 @@ def test_host_id_override(self):
         # 3. check host_id in other node's table
         session1 = self.patient_exclusive_cql_connection(node1)
         assert_one(session1, ""SELECT host_id FROM system.peers_v2 WHERE peer = {}"".format(address2), [uuid.UUID(host_id)])
+
+class TestBootstrap(BootstrapTester):

Review comment:
       Thank you for noting! I haven't set up automatic formatting on commits and there is nothing prepared in Cassandra to just reuse. I know that there is git commit hook, but it doesn't fix formatting, it is just erroring.
   
   And took almost a day to get Travis to run it.
   
   I will fix it soon.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Sep/21 14:35;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r707404684



##########
File path: bootstrap_test.py
##########
@@ -1097,3 +1097,12 @@ def test_host_id_override(self):
         # 3. check host_id in other node's table
         session1 = self.patient_exclusive_cql_connection(node1)
         assert_one(session1, ""SELECT host_id FROM system.peers_v2 WHERE peer = {}"".format(address2), [uuid.UUID(host_id)])
+
+class TestBootstrap(BootstrapTester):

Review comment:
       I use PyCharm and I get warnings for formatting, never had to do anything in addition to be able to see those. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Sep/21 14:43;githubbot;600","k-rus commented on a change in pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152#discussion_r707466267



##########
File path: bootstrap_test.py
##########
@@ -1097,3 +1097,12 @@ def test_host_id_override(self):
         # 3. check host_id in other node's table
         session1 = self.patient_exclusive_cql_connection(node1)
         assert_one(session1, ""SELECT host_id FROM system.peers_v2 WHERE peer = {}"".format(address2), [uuid.UUID(host_id)])
+
+class TestBootstrap(BootstrapTester):

Review comment:
       I use VS Code. My preferable approach is to be not dependent on IDE, thus I am looking into setting up a git commit hook.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Sep/21 15:50;githubbot;600","k-rus closed pull request #152:
URL: https://github.com/apache/cassandra-dtest/pull/152


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Sep/21 08:47;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,11400,,,0,11400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Sep/21 14:05;adelapena;collected-dtests-diffs-v2.txt;https://issues.apache.org/jira/secure/attachment/13033419/collected-dtests-diffs-v2.txt","10/Sep/21 11:16;adelapena;collected-dtests-diffs.txt;https://issues.apache.org/jira/secure/attachment/13033316/collected-dtests-diffs.txt",,,,2.0,k-rus,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Sep 14 11:17:28 UTC 2021,,,,,,,All,,,,"0|z0trx4:",9223372036854775807,,,,adelapena,e.dimitrova,,,Normal,,NA,,https://github.com/apache/cassandra-dtest/commit/6f3a4cb3c55323156c2b8686bea07a3362f3e861,,,,,,,,,run tests,,,,,"11/Aug/21 07:36;k-rus;PR is created: https://github.com/apache/cassandra-dtest/pull/152;;;","03/Sep/21 19:54;adelapena;Thanks for the patch. Finding those skipped tests is a very good catch. Overall the patch looks good to me, I have left some minor suggestions on the PR.
{quote}Treat --only-resource-intensive-tests in the same way as --force-resource-intensive-tests, so it will be enough to just specify it even with no sufficient resources.
{quote}
I'm not sure about this, IMO it makes sense the way it currently works. The flag {{\-\-only-resource-intensive-tests}} selects the tests to run and {{\-\-force-resource-intensive-tests}} disables the safety mechanism that prevents running the tests if there aren't enough resources available.

On one hand, I understand that current meaning of {{\-\-only-resource-intensive-tests}} without {{\-\-force-resource-intensive-tests}} is ""run the resource intensive tests but only if you have resources to do so"". I guess that a (convoluted) example use case for this could be having a CircleCI job for running resource intensive tests. This job would success in LOWRES and MIDRES without running any tests due to the lack of resources, and it would actually run the tests in HIGHRES.

On the other hand, I understand that in most cases when you use {{\-\-only-resource-intensive-tests}} probably you are going to want to run with or without the resources. I don't think that any of the approaches is wrong or much better than the other, so I'm more inclined to preserve the current behaviour. We can always add some more information in the description of the flags if we think that this is going to be confusing for users. What do you think? Am I missing something?;;;","06/Sep/21 07:18;k-rus;I suggested this change to not require {{\-\-force-resource-intensive-tests}} with {{\-\-only-resource-intensive-tests}}, since it feels odd: if you don't have sufficient resources and use  {{\-\-only-resource-intensive-tests}}, then no tests will be run at all. I.e., calling
{code:bash}
pytest --only-resource-intensive-tests --cassandra-dir=../cassandra/
...
collected 12345 items / 12345 deselected{code}
will lead to all tests are deselected.

However, since I don't develop or run much dtests, I don't have strong opinion.;;;","06/Sep/21 16:38;adelapena;Aside from the discussion about changes in {{\-\-only-resource-intensive-tests}}/{{\-\-force-resource-intensive-tests}}, where I also don't have a strong opinion, the changes look good to me. Here are some CI runs using the modified dtests:
||Branch||CircleCI||Jenkins||
|3.0|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/832/workflows/d20d69a8-a495-4d61-b881-b933525a5dc7]|
|3.11|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/830/workflows/39ba64ae-8ad0-4e70-9e7d-1c711b4fc296]|
|4.0|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/831/workflows/404ff71d-dff8-4f8b-b675-ad97a3327a15], [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/831/workflows/f3140558-c781-4293-8ecc-07a7e0448f96]|
|trunk|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/829/workflows/bc6b2e19-8fc8-43ef-8609-029f526ce94b], [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/829/workflows/a13907a2-bc02-45f8-a85b-6393fda0081b]|[link|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1101/pipeline]|;;;","07/Sep/21 16:47;e.dimitrova;I am inclined to not change the behavior as this will lead to a lot of noise in CI environments. I would say we need to have a warning why tests were skipped but then I think there is already an option that can be run in order to get the reason for skipping tests in pytest. Quick check showed me it is not used at least in Circle CI environment. 

I would suggest finding a way probably to add a warning why the tests didn't work in a separate ticket. For the record, I just did a quick check whether the pytest option _-rxXS_ will produce the warning but it didn't. It works nicely with the mark for cassandra version. For example:
{code:java}
pytest --cassandra-dir=../cassandra repair_tests/repair_test.py::TestRepair::test_parent_repair_session_cleanup  -rxXS
============================================================================================================ test session starts =============================================================================================================
platform darwin -- Python 3.8.10, pytest-3.6.4, py-1.10.0, pluggy-0.7.1
rootdir: ../cassandra-dtest-d, inifile: pytest.ini
plugins: timeout-1.4.2, repeat-0.9.1, flaky-3.7.0
timeout: 900.0s
timeout method: signal
timeout func_only: False
collected 1 item                                                                                                                                                                                                                             
 
repair_tests/repair_test.py s                                                                                                                                                                                                          [100%]
========================================================================================================== short test summary info ===========================================================================================================
SKIP [1] ../cassandra-dtest-d/conftest.py:461: 3.11.12 < 4.0
{code}
*Note:* I had to remove the _--collect-only_ flag to see the skip reason.

 ;;;","07/Sep/21 17:34;adelapena;We already have [a warning|https://github.com/apache/cassandra-dtest/blob/trunk/conftest.py#L610-L611] about the tests ignored due to the lack of resources, it's [slightly modified|https://github.com/apache/cassandra-dtest/blob/ccc663461727a363121e8937efe44db1d34fb843/conftest.py#L611-L614] in the PR. However the message is not printed on stdout with the default config. Maybe we can make it visible for example emitting it with {{logger.warning}} instead of {{logger.info}}.;;;","07/Sep/21 21:24;e.dimitrova;{quote}However the message is not printed on stdout with the default config.
{quote}
Yes, that's what I meant but as I said, we can always do it as a separate improvement if we want to. 

I am in for preserving the behavior around the two flags, the rest looks good and that was definitely a good catch that the tests are not running. Thanks!;;;","08/Sep/21 07:41;k-rus;[~e.dimitrova] Thank you for your comment and clarifying that the comment was only related to the resource intensive case.
[~e.dimitrova] [~adelapena] Your suggestion is to remove the change related to flags of the resource intensive only and the resource intensive force, so that the resource intensive force flag is always needed even with the resource intensive only flag. I will do this change to restore the original behaviour and will update the tests. The rest of the patch will be kept the same. Let me know if I missed or misunderstood anything.;;;","08/Sep/21 07:42;k-rus;Do I need to do any changes in the status of the ticket, while I am addressing this comment?;;;","08/Sep/21 22:53;e.dimitrova;Thank you [~k-rus], confirmed, we are on the same page. Thank you for your work. 

About the ticket status, staying in REVIEW IN PROGRESS is fine. You are addressing small review comment. 

If it was a big ticket with a lot of rewriting, someone might return it to work in progress but I don't think this is the case. Just ping us on the ticket when you are ready so we can do a final check and commit. Thanks again for all your work! :) ;;;","09/Sep/21 15:39;k-rus;[~adelapena] [~e.dimitrova] I addressed your comments and reverted the change about resource intensive tests, so force execution flag is always required if not sufficient resources even in the case to execute only resource intensive tests.
I run [j11_dtests in CircleCI|https://app.circleci.com/pipelines/github/k-rus/cassandra/10/workflows/e56bdedd-45ba-466f-ae32-a003b9004063] and [j8_dtests|https://app.circleci.com/pipelines/github/k-rus/cassandra/10/workflows/846bfcdc-b33e-4e57-9252-56ef445d115a];;;","09/Sep/21 17:25;adelapena;IIUC the change in the {{-only-resource-intensive-tests}}/{{-force-resource-intensive-tests}} flags is reverted but now the message is changed so it also appears when {{-skip-resource-intensive-tests}} is used, even if there are enough resources available. Without the patch the message was only emitted when there weren't enough resources and {{-force-resource-intensive-tests}} wasn't used, independently of other test selection flags. Is this correct? I think I would have preferred to separate this in two separate messages in a follow up ticket, but if you think it's clearer this way I'm fine with it.;;;","10/Sep/21 07:31;k-rus;I don't have a strong opinion about the message. I will split the check condition into two separate variables to be able to print the message in accordance with the suggestion.;;;","10/Sep/21 07:41;k-rus;I addressed latest comments from [~adelapena]
[java11 CircleCI build|https://app.circleci.com/pipelines/github/k-rus/cassandra/11/workflows/65abc408-edac-4c75-85dc-495f5c9af848]
[java8 CircleCI build|https://app.circleci.com/pipelines/github/k-rus/cassandra/11/workflows/fc3f33a1-3f56-486a-be8d-1c0b6ffa9507]
cc [~e.dimitrova] ;;;","10/Sep/21 11:32;adelapena;Thanks for the changes.

I have noticed that with the patch some tests are collected twice. Specifically, this happens with the tests in {{TestBootstrap}} and {{TestBaseSStableLoader}}. These classes are extended by upgrade tests classes in {{bootstrap_upgrade_test.py}} and {{storage_engine_upgrade_test.py}}, and they are collected both from their original class and from the upgrade test that extends them.

I am attaching a file with the differences in collected tests for different combinations of flags, excluding the changes in \{{conftest_test}} for clarity.;;;","10/Sep/21 11:38;k-rus;[~adelapena] Thank you for this finding! I confirm that these tests were not collected as non-upgrade tests previously.
{code:java}
pytest --cassandra-dir=../cassandra/ upgrade_tests --collect-only
{code}
on trunk gives:
{code}
collected 4081 items / 4081 deselected 
{code}
while on PR the same command gives:
{code}
collected 4081 items / 4043 deselected
{code}
I am investigating. 

 ;;;","13/Sep/21 08:41;k-rus;[~adelapena] It is actually an old issue, which became visible with my patch. Basically importing a class brings all the tests from the imported class to be part of this file. Inheriting the imported class also brings the same file but as part of the child class, which is marked as upgrade test. As result there are always two sets of test methods in such case. Here is an experiment, which confirms this:
{code}
pytest --cassandra-dir=../cassandra/ upgrade_tests/bootstrap_upgrade_test.py --collect-only --execute-upgrade-tests
...
collected 57 items                                                                                                                                                                             
<Module 'upgrade_tests/bootstrap_upgrade_test.py'>
  <Class 'TestBootstrap'>
    <Instance '()'>
      <Function 'test_simple_bootstrap_with_ssl'>
      <Function 'test_simple_bootstrap'>
      <Function 'test_bootstrap_on_write_survey'>
      <Function 'test_simple_bootstrap_small_keepalive_period'>
      <Function 'test_simple_bootstrap_nodata'>
      <Function 'test_schema_removed_nodes'>
      <Function 'test_read_from_bootstrapped_node'>
      <Function 'test_bootstrap_waits_for_streaming_to_finish'>
      <Function 'test_consistent_range_movement_true_with_replica_down_should_fail'>
      <Function 'test_consistent_range_movement_false_with_replica_down_should_succeed'>
      <Function 'test_consistent_range_movement_true_with_rf1_should_fail'>
      <Function 'test_consistent_range_movement_false_with_rf1_should_succeed'>
      <Function 'test_rf_gt_nodes_multidc_should_succeed'>
      <Function 'test_resumable_bootstrap'>
      <Function 'test_bootstrap_with_reset_bootstrap_state'>
      <Function 'test_manual_bootstrap'>
      <Function 'test_local_quorum_bootstrap'>
      <Function 'test_shutdown_wiped_node_cannot_join'>
      <Function 'test_killed_wiped_node_cannot_join'>
      <Function 'test_decommissioned_wiped_node_can_join'>
      <Function 'test_decommissioned_wiped_node_can_gossip_to_single_seed'>
      <Function 'test_failed_bootstrap_wiped_node_can_join'>
      <Function 'test_node_cannot_join_as_hibernating_node_without_replace_address'>
      <Function 'test_simultaneous_bootstrap'>
      <Function 'test_cleanup'>
      <Function 'test_bootstrap_binary_disabled'>
      <Function 'test_invalid_host_id'>
      <Function 'test_host_id_override'>
  <Class 'TestBootstrapUpgrade'>
    <Instance '()'>
      <Function 'test_simple_bootstrap_with_ssl'>
      <Function 'test_simple_bootstrap'>
      <Function 'test_bootstrap_on_write_survey'>
      <Function 'test_simple_bootstrap_small_keepalive_period'>
      <Function 'test_simple_bootstrap_nodata'>
      <Function 'test_schema_removed_nodes'>
      <Function 'test_read_from_bootstrapped_node'>
      <Function 'test_bootstrap_waits_for_streaming_to_finish'>
      <Function 'test_consistent_range_movement_true_with_replica_down_should_fail'>
      <Function 'test_consistent_range_movement_false_with_replica_down_should_succeed'>
      <Function 'test_consistent_range_movement_true_with_rf1_should_fail'>
      <Function 'test_consistent_range_movement_false_with_rf1_should_succeed'>
      <Function 'test_rf_gt_nodes_multidc_should_succeed'>
      <Function 'test_resumable_bootstrap'>
      <Function 'test_bootstrap_with_reset_bootstrap_state'>
      <Function 'test_manual_bootstrap'>
      <Function 'test_local_quorum_bootstrap'>
      <Function 'test_shutdown_wiped_node_cannot_join'>
      <Function 'test_killed_wiped_node_cannot_join'>
      <Function 'test_decommissioned_wiped_node_can_join'>
      <Function 'test_decommissioned_wiped_node_can_gossip_to_single_seed'>
      <Function 'test_failed_bootstrap_wiped_node_can_join'>
      <Function 'test_node_cannot_join_as_hibernating_node_without_replace_address'>
      <Function 'test_simultaneous_bootstrap'>
      <Function 'test_cleanup'>
      <Function 'test_bootstrap_binary_disabled'>
      <Function 'test_invalid_host_id'>
      <Function 'test_host_id_override'>
      <Function 'test_simple_bootstrap_mixed_versions'>
{code}
To my understanding this side effect of importing with the double execution of tests is not intentional. Before the change the same set of imported tests  were executed two time as upgrade tests and once as non-upgrade as part of the original file. After this patch the upgrade tests are executed once, while the non-upgrade tests are executed twice: one as part of the original file and one as imported.
-I currently have no good idea how to fix it and remove double execution.-;;;","13/Sep/21 08:50;k-rus;Suggested solution is to rename the base class to be not picked up by PyTest and then introduce dummy child class in the original file to inherit from the base class. I tested that it works.;;;","13/Sep/21 10:06;k-rus;I pushed a commit, which fixes the discovered duplication. It also removed one duplication unrelated to upgrade.
So now the above command gives:
{code}
pytest --cassandra-dir=../cassandra/ upgrade_tests/bootstrap_upgrade_test.py --collect-only --execute-upgrade-tests
collected 29 items                                                                                                                                                                             
<Module 'upgrade_tests/bootstrap_upgrade_test.py'>
  <Class 'TestBootstrapUpgrade'>
    <Instance '()'>
      <Function 'test_simple_bootstrap_with_ssl'>
      <Function 'test_simple_bootstrap'>
      <Function 'test_bootstrap_on_write_survey'>
      <Function 'test_simple_bootstrap_small_keepalive_period'>
      <Function 'test_simple_bootstrap_nodata'>
      <Function 'test_schema_removed_nodes'>
      <Function 'test_read_from_bootstrapped_node'>
      <Function 'test_bootstrap_waits_for_streaming_to_finish'>
      <Function 'test_consistent_range_movement_true_with_replica_down_should_fail'>
      <Function 'test_consistent_range_movement_false_with_replica_down_should_succeed'>
      <Function 'test_consistent_range_movement_true_with_rf1_should_fail'>
      <Function 'test_consistent_range_movement_false_with_rf1_should_succeed'>
      <Function 'test_rf_gt_nodes_multidc_should_succeed'>
      <Function 'test_resumable_bootstrap'>
      <Function 'test_bootstrap_with_reset_bootstrap_state'>
      <Function 'test_manual_bootstrap'>
      <Function 'test_local_quorum_bootstrap'>
      <Function 'test_shutdown_wiped_node_cannot_join'>
      <Function 'test_killed_wiped_node_cannot_join'>
      <Function 'test_decommissioned_wiped_node_can_join'>
      <Function 'test_decommissioned_wiped_node_can_gossip_to_single_seed'>
      <Function 'test_failed_bootstrap_wiped_node_can_join'>
      <Function 'test_node_cannot_join_as_hibernating_node_without_replace_address'>
      <Function 'test_simultaneous_bootstrap'>
      <Function 'test_cleanup'>
      <Function 'test_bootstrap_binary_disabled'>
      <Function 'test_invalid_host_id'>
      <Function 'test_host_id_override'>
      <Function 'test_simple_bootstrap_mixed_versions'>
{code}
Execution in the base test file is also correct:
{code}
pytest --cassandra-dir=../cassandra/ bootstrap_test.py --collect-only --execute-upgrade-tests
collected 28 items                                                                                                                                                                             
<Module 'bootstrap_test.py'>
  <Class 'TestBootstrap'>
    <Instance '()'>
      <Function 'test_simple_bootstrap_with_ssl'>
      <Function 'test_simple_bootstrap'>
      <Function 'test_bootstrap_on_write_survey'>
      <Function 'test_simple_bootstrap_small_keepalive_period'>
      <Function 'test_simple_bootstrap_nodata'>
      <Function 'test_schema_removed_nodes'>
      <Function 'test_read_from_bootstrapped_node'>
      <Function 'test_bootstrap_waits_for_streaming_to_finish'>
      <Function 'test_consistent_range_movement_true_with_replica_down_should_fail'>
      <Function 'test_consistent_range_movement_false_with_replica_down_should_succeed'>
      <Function 'test_consistent_range_movement_true_with_rf1_should_fail'>
      <Function 'test_consistent_range_movement_false_with_rf1_should_succeed'>
      <Function 'test_rf_gt_nodes_multidc_should_succeed'>
      <Function 'test_resumable_bootstrap'>
      <Function 'test_bootstrap_with_reset_bootstrap_state'>
      <Function 'test_manual_bootstrap'>
      <Function 'test_local_quorum_bootstrap'>
      <Function 'test_shutdown_wiped_node_cannot_join'>
      <Function 'test_killed_wiped_node_cannot_join'>
      <Function 'test_decommissioned_wiped_node_can_join'>
      <Function 'test_decommissioned_wiped_node_can_gossip_to_single_seed'>
      <Function 'test_failed_bootstrap_wiped_node_can_join'>
      <Function 'test_node_cannot_join_as_hibernating_node_without_replace_address'>
      <Function 'test_simultaneous_bootstrap'>
      <Function 'test_cleanup'>
      <Function 'test_bootstrap_binary_disabled'>
      <Function 'test_invalid_host_id'>
      <Function 'test_host_id_override'>
{code}
 Before the fix there was non-upgrade issue:
{code}
pytest --cassandra-dir=../cassandra/ sstable_generation_loading_test.py --collect-only --execute-upgrade-tests
collected 24 items                                                                                                                                                                             
<Module 'sstable_generation_loading_test.py'>
  <Class 'TestBaseSStableLoader'>
    <Instance '()'>
      <Function 'test_sstableloader_compression_none_to_none'>
      <Function 'test_sstableloader_compression_none_to_snappy'>
      <Function 'test_sstableloader_compression_none_to_deflate'>
      <Function 'test_sstableloader_compression_snappy_to_none'>
      <Function 'test_sstableloader_compression_snappy_to_snappy'>
      <Function 'test_sstableloader_compression_snappy_to_deflate'>
      <Function 'test_sstableloader_compression_deflate_to_none'>
      <Function 'test_sstableloader_compression_deflate_to_snappy'>
      <Function 'test_sstableloader_compression_deflate_to_deflate'>
      <Function 'test_sstableloader_with_mv'>
  <Class 'TestSSTableGenerationAndLoading'>
    <Instance '()'>
      <Function 'test_sstableloader_compression_none_to_none'>
      <Function 'test_sstableloader_compression_none_to_snappy'>
      <Function 'test_sstableloader_compression_none_to_deflate'>
      <Function 'test_sstableloader_compression_snappy_to_none'>
      <Function 'test_sstableloader_compression_snappy_to_snappy'>
      <Function 'test_sstableloader_compression_snappy_to_deflate'>
      <Function 'test_sstableloader_compression_deflate_to_none'>
      <Function 'test_sstableloader_compression_deflate_to_snappy'>
      <Function 'test_sstableloader_compression_deflate_to_deflate'>
      <Function 'test_sstableloader_uppercase_keyspace_name'>
      <Function 'test_incompressible_data_in_compressed_table'>
      <Function 'test_remove_index_file'>
      <Function 'test_sstableloader_with_mv'>
      <Function 'test_sstableloader_with_failing_2i'>
{code}
And after the fix:
{code}
pytest --cassandra-dir=../cassandra/ sstable_generation_loading_test.py --collect-only --execute-upgrade-tests
collected 14 items                                                                                                                                                                             
<Module 'sstable_generation_loading_test.py'>
  <Class 'TestSSTableGenerationAndLoading'>
    <Instance '()'>
      <Function 'test_sstableloader_compression_none_to_none'>
      <Function 'test_sstableloader_compression_none_to_snappy'>
      <Function 'test_sstableloader_compression_none_to_deflate'>
      <Function 'test_sstableloader_compression_snappy_to_none'>
      <Function 'test_sstableloader_compression_snappy_to_snappy'>
      <Function 'test_sstableloader_compression_snappy_to_deflate'>
      <Function 'test_sstableloader_compression_deflate_to_none'>
      <Function 'test_sstableloader_compression_deflate_to_snappy'>
      <Function 'test_sstableloader_compression_deflate_to_deflate'>
      <Function 'test_sstableloader_uppercase_keyspace_name'>
      <Function 'test_incompressible_data_in_compressed_table'>
      <Function 'test_remove_index_file'>
      <Function 'test_sstableloader_with_mv'>
      <Function 'test_sstableloader_with_failing_2i'>
{code}
;;;","13/Sep/21 12:13;k-rus;[~adelapena][~e.dimitrova] I fixed the issue identified by Andrès in a [separate commit|https://github.com/apache/cassandra-dtest/pull/152/commits/4952c6392a4cc5735a6c8488312defab930ac543].
[Java11 CircleCI build|https://app.circleci.com/pipelines/github/k-rus/cassandra/15/workflows/8f17c37d-dc46-4873-81f6-644ca6660044] is started
[Java8 CircleCI build|https://app.circleci.com/pipelines/github/k-rus/cassandra/15/workflows/8c03d4a9-6495-4d46-a99a-db3f02f92a30] is started;;;","13/Sep/21 14:31;adelapena;The solution makes sense to me, +1. 

It's great that you have also found the duplication in {{sstable_generation_loading_test.py}}. I have been looking for other duplications and I can't spot anything else.

I'm attaching a new set of diffs between tests collected before and after the patch, it seems correct to me.;;;","13/Sep/21 16:39;e.dimitrova;+1 

The failed test shouldn't be related to this patch. It is a good idea to follow up on It separately though.

Code wise looks good and I also looked at the attached by [~adelapena] diffs (thank you for saving me the time to run them on my own :) ), things look OK to me. 

Not running tests and running tests twice were all good catches. Thank you for all the work!

 

Btw I also checked for more duplications and I didn't find any at this point! :) ;;;","14/Sep/21 10:38;k-rus;Finally Travis build, which validates formatting, succeeded. So I guess I addressed all comments :);;;","14/Sep/21 11:17;adelapena;Committed to {{trunk}} as [6f3a4cb3c55323156c2b8686bea07a3362f3e861|https://github.com/apache/cassandra-dtest/commit/6f3a4cb3c55323156c2b8686bea07a3362f3e861], thanks for the patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Truncation snapshots unnecessarily created on node startup,CASSANDRA-16839,13394438,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,paulo,paulo,10/Aug/21 12:46,27/May/22 19:24,13/Jul/23 08:40,11/Oct/21 17:12,3.0.26,3.11.12,4.0.2,4.1,4.1-alpha1,,,Tool/nodetool,,,,1,,,"When testing cassandra 4.0 on ccm I noticed that everytime I restart a node, truncation snapshots are created for the tables {{system.table_estimates}} and {{system.size_estimates}}:

{noformat}
$ ccm create -n 1 test -s
$ ccm node1 stop
$ ccm node1 start
$ ccm node1 stop
$ ccm node1 start
$ ccm node1 nodetool listsnapshots

Snapshot Details:
Snapshot name                           Keyspace name Column family name True size Size on disk
truncated-1628599001857-table_estimates system        table_estimates    0 bytes   13 bytes
truncated-1628599099560-table_estimates system        table_estimates    0 bytes   13 bytes
truncated-1628599001736-size_estimates  system        size_estimates     0 bytes   13 bytes
truncated-1628599057438-table_estimates system        table_estimates    6.16 KiB  6.19 KiB
truncated-1628599099458-size_estimates  system        size_estimates     0 bytes   13 bytes
truncated-1628599057340-size_estimates  system        size_estimates     5.73 KiB  5.76 KiB

Total TrueDiskSpaceUsed: 0 bytes
{noformat}

Not sure if this is expected behavior, but feels like a bug to me.

Reproduced on 4.0, not sure if it reproduces on lower versions.",,adelapena,blerer,Bowen Song,e.dimitrova,paulo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Oct 11 17:12:48 UTC 2021,,,,,,,All,,,,"0|z0trog:",9223372036854775807,,,,adelapena,blerer,,,Normal,,2.2.0 beta 1,,https://github.com/apache/cassandra/commit/0e12b8d4fc9183cb8bb37cb461c3fe9e434ba9b8,,,,,,,,,Run CI,,,,,"25/Sep/21 16:55;Bowen Song;I can confirm that I'm experiencing the same issue on a Cassandra 4.0.1 cluster on production. New snapshot is created for those system tables when the server is rebooted or the Cassandra service is restarted. The size of the snapshot is small, but if left untreated, the filesystem may run out of free inodes eventually.;;;","06/Oct/21 16:21;brandon.williams;This is caused by CASSANDRA-15776 truncating these tables via CQL, which does not have a mechanism for truncation without snapshotting. I actually couldn't find a way to truncate without snapshotting, so this patch adds one, uses it instead, and additionally replaces the other two truncateBlocking instances that generate snapshots for prepared statements and available ranges.


||Branch||CI||
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16839-4.0]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16839-4.0], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1184/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1184/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16839-trunk]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16839-trunk], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1185/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1185/pipeline]|;;;","08/Oct/21 12:30;adelapena;The fix looks good to me. As for using the new {{truncateBlockingWithoutSnapshot}} method in {{resetAvailableRanges}} and {{resetPreparedStatements}} to prevent the unwanted snapshot, shouldn't we backport that to 3.0 and 3.11?;;;","08/Oct/21 12:33;blerer;The patch looks good to me.;;;","08/Oct/21 16:16;brandon.williams;bq. shouldn't we backport that to 3.0 and 3.11?

Good catch.  I've fixed the nits, backported this to 3.11 and 3.0 (which didn't have CASSANDRA-13641), and also renamed the variable for prepared statements correctly.

||Branch||CI||
|[3.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16839-3.0]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16839-3.0], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1197/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1197/pipeline]|
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16839-3.11]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16839-3.11], [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1198/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1198/pipeline]|
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16839-4.0]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16839-4.0]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16839-trunk]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16839-trunk]|
;;;","08/Oct/21 16:39;adelapena;Great, looks good to me, +1 if CI is ok. Nice catch on the var name.;;;","11/Oct/21 17:12;brandon.williams;I don't think there are any related failures, committed.  Thank you for the reviews.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Materialized views incorrect quoting of UDF,CASSANDRA-16836,13394374,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,10/Aug/21 07:52,27/May/22 19:24,13/Jul/23 08:40,13/Aug/21 06:51,3.11.12,4.1,4.1-alpha1,,,,,Feature/Materialized Views,,,,0,,,"Creating a MV with a UDF needing quotes will explode on inserts after restart

 
{code:sql}
create keyspace test WITH replication = {'class':'SimpleStrategy', 'replication_factor' : 3};

use test;

CREATE TABLE t (k int PRIMARY KEY, v int);

CREATE FUNCTION ""Double"" (input int) 

   CALLED ON NULL INPUT 

   RETURNS int 

   LANGUAGE java 

   AS 'return input*2;';

CREATE MATERIALIZED VIEW mv AS SELECT * FROM t 

   WHERE k < test.""Double""(2) 

   AND k IS NOT NULL 

   AND v IS NOT NULL 

   PRIMARY KEY (v, k);
 {code}

Now restart the node, run an insert and you get an error

{noformat}
INSERT INTO t(k, v) VALUES (3, 1);
ERROR [MutationStage-2] 2021-08-10 09:55:56,662 StorageProxy.java:1551 - Failed to apply mutation locally : 
org.apache.cassandra.exceptions.InvalidRequestException: Unknown function test.double called
	at org.apache.cassandra.cql3.statements.RequestValidations.invalidRequest(RequestValidations.java:217)
	at org.apache.cassandra.cql3.functions.FunctionCall$Raw.prepare(FunctionCall.java:155)
	at org.apache.cassandra.cql3.SingleColumnRelation.toTerm(SingleColumnRelation.java:123)
	at org.apache.cassandra.cql3.SingleColumnRelation.newSliceRestriction(SingleColumnRelation.java:231)
	at org.apache.cassandra.cql3.Relation.toRestriction(Relation.java:144)
	at org.apache.cassandra.cql3.restrictions.StatementRestrictions.<init>(StatementRestrictions.java:188)
	at org.apache.cassandra.cql3.restrictions.StatementRestrictions.<init>(StatementRestrictions.java:135)
	at org.apache.cassandra.cql3.statements.SelectStatement$RawStatement.prepareRestrictions(SelectStatement.java:1067)
	at org.apache.cassandra.cql3.statements.SelectStatement$RawStatement.prepare(SelectStatement.java:937)
	at org.apache.cassandra.db.view.View.getSelectStatement(View.java:180)
	at org.apache.cassandra.db.view.View.getReadQuery(View.java:204)
	at org.apache.cassandra.db.view.TableViews.updatedViews(TableViews.java:368)
	at org.apache.cassandra.db.view.ViewManager.updatesAffectView(ViewManager.java:85)
	at org.apache.cassandra.db.Keyspace.applyInternal(Keyspace.java:538)
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:513)
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:215)
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:220)
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:229)
	at org.apache.cassandra.service.StorageProxy$4.runMayThrow(StorageProxy.java:1545)
	at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:2324)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162)
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:134)
	at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:119)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
WriteFailure: Error from server: code=1500 [Replica(s) failed to execute write] message=""Operation failed - received 0 responses and 1 failures: UNKNOWN from localhost/127.0.0.1:7000"" info={'consistency': 'ONE', 'required_responses': 1, 'received_responses': 0, 'failures': 1, 'error_code_map': {'127.0.0.1': '0x0000'}}

{noformat}",,adelapena,bereng,e.dimitrova,jakubzytka,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16852,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Aug 12 21:54:36 UTC 2021,,,,,,,All,,,,"0|z0tra8:",9223372036854775807,,,,adelapena,,,,Normal,,3.11.x,,99e1fcc251bd498abab17a59a9fc9593d242671b,,,,,,,,,Unit tests are included. See PR for CI.,,,,,"10/Aug/21 08:44;bereng;[~adelapena] [~jakubzytka] can you please take a cursory look I didn't do anything silly before I jump into porting to 3.0, 3.11 and trunk?;;;","10/Aug/21 10:15;jakubzytka;LGTM;;;","10/Aug/21 12:35;adelapena;Looks good to me too. Can we run a few multiplexer rounds of {{ViewTest}}, just in case?;;;","11/Aug/21 06:28;bereng;100 runs [lgtm|https://app.circleci.com/pipelines/github/bereng/cassandra/385/workflows/8d80554e-2ffa-46f4-8c5f-e8580d7fbdbb/jobs/3568/steps];;;","11/Aug/21 09:03;bereng;The rest of the PRs are up for a formal review;;;","11/Aug/21 12:28;adelapena;The other PRs look good to me. I think that 3.0 is also affected, and the new {{testFunctionInWhereClause}} test can reproduce the failure in that branch. Shouldn't we fix that branch too?

Also, could we run the multiplexer for {{org.apache.cassandra.db.lifecycle.ViewTest}} in the other branches, at least for {{testFunctionInWhereClause}}?;;;","11/Aug/21 12:33;adelapena;{quote}I think that 3.0 is also affected, and the new testFunctionInWhereClause test can reproduce the failure in that branch. Shouldn't we fix that branch too?
{quote}
Please ignore me about 3.0, this isn't critical enough. I was still on a pre-4.0 GA mindset.;;;","12/Aug/21 05:22;bereng;Right I didn't do the 3.0 branch bc MV are experimental to start with, then the UDF issue can be workarounded, etc So I didn't go there.

[~adelapena] multiplexing all the branches sounds like an overkill to me? but feel free to correct me. Otherwise are we +1 and can I merge?;;;","12/Aug/21 11:53;adelapena;It seems that the multiplexer fails in 3.11, although I suspect that might be related to the ant-junit dependencies that we have recently had: had: https://app.circleci.com/pipelines/github/adelapena/cassandra/769/workflows/48bdd598-7631-43ba-baf7-3738db10e482/jobs/7661;;;","12/Aug/21 12:04;bereng;^Right icwym. I would argue it the test was directly broken it wouldn't have passed the first CI and maybe the multiplexer for 3.11 needs adjusting?;;;","12/Aug/21 12:32;adelapena;Yes, the test passes both locally and in regular non-multiplexed CI, the failure seems linked to recent dependency issues, and the other multiplexed runs pass (trunk [here|https://app.circleci.com/pipelines/github/adelapena/cassandra/767/workflows/3e7aed15-30fc-477e-841b-6b099a6e9ef2] and [here|https://app.circleci.com/pipelines/github/adelapena/cassandra/767/workflows/a0467ef7-2962-41ba-b208-19428c2be8d0]). So I'd say we're ready to merge this one, and we'll have to check those recent dependency problems for the multiplexer.;;;","12/Aug/21 21:54;e.dimitrova;For the record, the multiplexer issues are not related neither to this patch nor to ant-junit dependency issue that was solved recently - I reverted both patches and ran the test 5 times in a loop [here|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1059/workflows/69a26429-ac07-40bd-8ee5-9d48987532de/jobs/6235]. Separate ticket for the issue was opened - CASSANDRA-16852  ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Scrub still uses ""row"" to mean ""partitions"", and has broken code",CASSANDRA-16835,13394279,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,09/Aug/21 20:45,27/May/22 19:25,13/Jul/23 08:40,17/Aug/21 19:23,3.11.12,4.0.1,4.1,4.1-alpha1,,,,Tool/nodetool,,,,0,,,"2 issues in the scrub code:
 1) It still uses ""row"" to mean ""partition"". And not only in the code, but also in user messages. As we've fairly systematically remove such instances elsewhere in 3.0+, having it in scrub is going to confuse users which will almost surely misinterpret the results. If scrub says that it dropped 2 unreadable ""rows"" from your sstable, you might be ok with that when we're actually talking about CQL rows, but not if we talk of 2 full partitions.
 2) There is a branch at the end of scrub that is supposed to handle the case where scrubbing a sstable generates no output at all (the sstable is completely hosed usually), mostly providing a more user friendly message. The code is broken (and has been for a long time, since CASSANDRA-7066 I believe) however such that this branch can simply never be taken (even when it should). While admittedly pretty minor, no reason to leave it that way.",,brandon.williams,e.dimitrova,jmckenzie,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,slebresne,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Aug 17 19:22:17 UTC 2021,,,,,,,All,,,,"0|z0tqp4:",9223372036854775807,,,,brandon.williams,,,,Low,,,,https://github.com/apache/cassandra/commit/e581a85b93acff0fecef7d41d9a94a2f89f810ba,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16835?focusedCommentId=17396932&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17396932,,,,,"10/Aug/21 23:04;e.dimitrova;[3.11|https://github.com/apache/cassandra/compare/trunk...ekaterinadimitrova2:16835-3.11?expand=1], [4.0|https://github.com/apache/cassandra/compare/trunk...ekaterinadimitrova2:16835-4.0?expand=1] patches.
 The trunk patch will be identical with 4.0.
 I ran the respective tests locally for now. I didn't clean unrelated warnings as I didn't want to overwhelm the patch at this point with unrelated changes but if a reviewer insists, I can add that later too. 
 I will also run full CI pre-commit.;;;","11/Aug/21 16:20;brandon.williams;Looks good to me, +1.  The bug fixed was around completed/finished.isEmpty()?;;;","11/Aug/21 16:27;e.dimitrova;Thank you for the review. 
{quote}The bug fixed was around completed/finished.isEmpty()?
{quote}
Yes, that is the one, I guess I had to put it in a separate commit for clarity. Sorry.

I will propagate also to trunk and run full CI on all three branches for sanity check.;;;","11/Aug/21 16:52;e.dimitrova;||Patch||CI||
| [3.11| https://github.com/apache/cassandra/compare/trunk...ekaterinadimitrova2:16835-3.11?expand=1] | [Jenkins|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1006/] |
|[4.0|https://github.com/apache/cassandra/compare/trunk...ekaterinadimitrova2:16835-4.0?expand=1 ] | [Jenkins|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1007/] |
|[trunk|https://github.com/apache/cassandra/compare/trunk...ekaterinadimitrova2:16835-trunk?expand=1] | [Jenkins|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1008/] |;;;","11/Aug/21 16:53;e.dimitrova;I will commit on green CI ;;;","13/Aug/21 01:52;e.dimitrova;Unfortunately, _testRecoverOverflowedExpirationWithSSTableScrub_ is failing on 4.0. I will check it tomorrow, hopefully it is only test issue. ;;;","16/Aug/21 18:28;e.dimitrova;I think it is a test issue. [~brandon.williams], as you were also involved In CASSANDRA-16013 where [this assertion|https://github.com/ekaterinadimitrova2/cassandra/commit/06aca0e4a995f0fff4e4eac76d1d81d27d181239#diff-702da23770e443ad8b0ac0a4b94c6b9fbf1c3727fcab13b734389e49878ff175L430] (the fix will apply to 4.0 and trunk) was added, can you confirm It, please, that I am not missing anything? ;;;","16/Aug/21 18:58;brandon.williams;That looks like what we need, +1.;;;","16/Aug/21 21:21;e.dimitrova;Great, thanks. Then squash, rebase and then these are last(hopefully) CI runs:
||Patch||CI||
|[3.11|https://github.com/ekaterinadimitrova2/cassandra/commit/ed49d3edad9b9e86952808e7585f6dce69785e2b]|[CircleCI|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1073/workflows/5fb0b764-bfc0-4409-9d3b-b65fe07f13e0]|
|[4.0|https://github.com/ekaterinadimitrova2/cassandra/commit/af10a0c1f6f9824b4933fb65d42c860c0fc4766a]|[CircleCI j8|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1074/workflows/40500114-c53e-42b3-bee1-d48b0c1e3e20], [j11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1074/workflows/5e0527f6-a1d1-4be6-af1d-dc120395bdf7]|
|[trunk|https://github.com/ekaterinadimitrova2/cassandra/commit/6af63779aa6f4dab4b184a0e4ff612ec3c6c3536]|[CircleCI j8|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1075/workflows/8d4f1f0f-1e46-4e52-8064-ceaa02735a05], [j11| https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1075/workflows/a326d796-3350-4655-a2c9-80175f46a776]|;;;","17/Aug/21 13:52;e.dimitrova;All known errors.

Except [this one|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1082/workflows/8dacef5d-46f4-4b59-a8f7-08824bf1180f/jobs/6407/tests#failed-test-0] which is stable in Jenkins but shows as flaky in the multiplexer so I am going to open a separate ticket for it. 

Preparing to commit;;;","17/Aug/21 19:22;e.dimitrova;Committed, thanks.

To https://github.com/apache/cassandra.git

   770dee5a57..e581a85b93  cassandra-3.11 -> cassandra-3.11

   af6654cb06..cb19b39827  cassandra-4.0 -> cassandra-4.0

   dc77cb8729..5b325b8c51  trunk -> trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""java: package org.apache.tools.ant does not exist"" error ",CASSANDRA-16827,13393580,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,04/Aug/21 21:25,17/Feb/22 08:13,13/Jul/23 08:40,10/Aug/21 14:59,3.11.12,,,,,,,Build,Dependencies,,,0,,,"After CASSANDRA-16557 I am getting ""java: package org.apache.tools.ant does not exist"" error when I try to run unit tests in IntelliJ.

 ",,adelapena,e.dimitrova,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Aug 12 21:51:00 UTC 2021,,,,,,,All,,,,"0|z0tmds:",9223372036854775807,,,,mck,,,,Low,,,,https://github.com/apache/cassandra/commit/ca6bb2af02dc21a2625840985551003c9d2e2a5c,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16827?focusedCommentId=17394163&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17394163,,,,,"04/Aug/21 21:36;e.dimitrova;CC [~mck]

I was looking to remove the exclude of ant plus a few other things but that didn't work.

I can try to look at it more tomorrow.;;;","05/Aug/21 16:29;e.dimitrova; ant-junit issue in build.xml fixed. I tested locally and seems it works fine.  It seems as a separate thing which was uncovered after the commits in CASSANDRA-16557. This was not part of the original patch for 4.0.

Jenkins run submitted for sanity check.
||Patch||CI||

-|[3.0 |https://github.com/ekaterinadimitrova2/cassandra/pull/new/16827-3.0]|--[Jenkins|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/992/]|-
|[3.11 |https://github.com/ekaterinadimitrova2/cassandra/pull/new/16827-3.11]|[Jenkins|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/993/]|;;;","09/Aug/21 14:07;e.dimitrova;Thank you for the review [~mck]
3.0 was not affected, seems I was looking something wrong. 
I applied the additional suggestion to 3.11 [here|https://github.com/ekaterinadimitrova2/cassandra/commit/e172b2c5a7a3d86c36e642d773b31566693a8af1];;;","09/Aug/21 14:19;brandon.williams;Why would the ant-junit version need to be unpinned since it's the same one in 3.0?  It's pinned in 4.0 too, albeit to a newer version.;;;","09/Aug/21 15:44;e.dimitrova;Version should be added only in _parent-pom_ and it is already there. But it shouldn't be added to _build-deps-pom_. 
If you look at the other dependencies their version is also added only in the _parent-pom_. ;;;","10/Aug/21 09:56;mck;+1;;;","10/Aug/21 14:58;e.dimitrova;Committed to https://github.com/apache/cassandra.git

   7bab2da375..ca6bb2af02  cassandra-3.11 -> cassandra-3.11

   a9abccb28b..112513c72d  cassandra-4.0 -> cassandra-4.0 - empty 

   b26a4daf86..cd36926577  trunk -> trunk - empty;;;","12/Aug/21 13:15;adelapena;Could this be related to [this recent failure|https://app.circleci.com/pipelines/github/adelapena/cassandra/769/workflows/48bdd598-7631-43ba-baf7-3738db10e482/jobs/7661] in the CircleCI test multiplexer, where {{testsome}} fails because the class {{JStackJUnitTask}} can't be found?

I think that the problem might be in the flag {{-Dno-build-test=true}} that the multiplexer uses to not run {{build-test}} in every iteration, relying on that this has already done by the build task. This is a performance optimisation that can be especially effective in fast tests.

It would be ideal to have the previous behaviour, but we can always run {{ant build-test}} at the beginning of every multiplexer runner while still not running it on every iteration, as it's done [here|https://github.com/adelapena/cassandra/commit/1f736c7e1a71dbfd2028a0543da27519274c447d]. This seems enough to keep the multiplexer working, as [this run|https://app.circleci.com/pipelines/github/adelapena/cassandra/770/workflows/0fac2594-a1c6-4e2c-9070-f5f4dad0432a/jobs/7665] shows, although it requires some extra builds and therefore higher costs.;;;","12/Aug/21 15:44;e.dimitrova;Hey [~adelapena],
Thank you for raising this issue. My first thought is - why this is an issue only in 3.11 now? ant-junit is setup currently with identical entries in 3.11, 4.0 and trunk. I don't have immediate answer, I will take a deeper look and test.  ;;;","12/Aug/21 21:40;e.dimitrova;I didn't see a difference in the _ant-junit_ dependency management or how the CircleCI multiplexer is setup on 3.11 and 4.0 so I ran in a small loop (5 iterations) the same test as you on your branch with reverted this patch.
Confirmed the issue was there before this ticket/patch - https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1058/workflows/cc163a5f-06d4-4b8c-bad6-31de82d04a61/jobs/6233
I will open a separate ticket. ;;;","12/Aug/21 21:51;e.dimitrova;I just opened CASSANDRA-16852;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky test consistent_bootstrap_test.py::TestBootstrapConsistency::test_consistent_reads_after_move,CASSANDRA-16826,13393329,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,03/Aug/21 20:23,05/Oct/22 22:22,13/Jul/23 08:40,24/May/22 14:52,4.1,4.1-alpha1,4.1-beta1,,,,,Test/dtest/python,,,,0,,,"consistent_bootstrap_test.py::TestBootstrapConsistency::test_consistent_reads_after_move can be flaky from time to time on less powerful environments due to timeouts; this can be improved by having retries for queries

Here is the error I was seeing

{code}
self =  <consistent_bootstrap_test.TestBootstrapConsistency object at 0x7fad988790f0>
     @pytest.mark.no_vnodes
    def test_consistent_reads_after_move(self):
        logger.debug(""Creating a ring"")
        cluster = self.cluster
        cluster.set_configuration_options(values={'hinted_handoff_enabled': False,
                                                  'write_request_timeout_in_ms': 60000,
                                                  'read_request_timeout_in_ms': 60000,
                                                  'dynamic_snitch_badness_threshold': 0.0})
        cluster.set_batch_commitlog(enabled=True)
   
        cluster.populate(3, tokens=[0, 2**48, 2**62]).start()
        node1, node2, node3 = cluster.nodelist()
   
        logger.debug(""Set to talk to node 2"")
        n2session = self.patient_cql_connection(node2)
        create_ks(n2session, 'ks', 2)
        create_c1c2_table(self, n2session)
   
        logger.debug(""Generating some data for all nodes"")
        insert_c1c2(n2session, keys=list(range(10, 20)), consistency=ConsistencyLevel.ALL)
   
        node1.flush()
        logger.debug(""Taking down node1"")
        node1.stop(wait_other_notice=True)
   
        logger.debug(""Writing data to node2"")
        insert_c1c2(n2session, keys=list(range(30, 1000)), consistency=ConsistencyLevel.ONE)
        node2.flush()
   
        logger.debug(""Restart node1"")
        node1.start()
   
        logger.debug(""Move token on node3"")
        node3.move(2)
   
        logger.debug(""Checking that no data was lost"")
        for n in range(10, 20):
            query_c1c2(n2session, n, ConsistencyLevel.ALL)
   
        for n in range(30, 1000):
>            query_c1c2(n2session, n, ConsistencyLevel.ALL)
 consistent_bootstrap_test.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tools/data.py:34: in query_c1c2
    rows = list(session.execute(query))
cassandra/cluster.py:2618: in cassandra.cluster.Session.execute
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
 >    ???
E   cassandra.OperationTimedOut: errors={'127.0.0.1:9042': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.1:9042
 cassandra/cluster.py:4894: OperationTimedOut
{code}",,adelapena,aratnofsky,dcapwell,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue May 24 14:52:09 UTC 2022,,,,,,,All,,,,"0|z0tku0:",9223372036854775807,,,,aratnofsky,e.dimitrova,,,Low,,NA,,https://github.com/apache/cassandra-dtest/commit/230c66c9395fb339d08744d832279281928d3b9b,,,,,,,,,local testing,,,,,"03/Aug/21 22:05;e.dimitrova;I made a few suggestions in the PR around the _retry_ method as it is a bit confusing now.  

-Also, please, acknowledge the other usages of _query_c1c2_ method, out of  _consistent_bootstrap_test_.- 

EDIT: [~dcapwell] pointed I was wrong, apparently he did already add the needed change but I missed it. My bad, I am sorry for overseeing It. The other suggestion stands :)

Thank you :) ;;;","04/Aug/21 00:04;dcapwell;pushed feedback changes [~e.dimitrova];;;","04/Aug/21 00:14;e.dimitrova;Looks good to me.

Please also Green CI and loop it before commit to ensure there are no surprises, just in case. Thank you!;;;","04/Aug/21 00:36;dcapwell;CI https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=CASSANDRA-16826_ci;;;","05/Aug/21 12:19;adelapena;Here are some repeated runs of {{test_consistent_reads_after_move}} in the CircleCI test multiplexer, with MIDRES:
 * [j8-j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/748/workflows/0e17dc1d-7f16-4a11-90b0-0192b287bc9b/jobs/7533]
 * [j8-j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/748/workflows/0e17dc1d-7f16-4a11-90b0-0192b287bc9b/jobs/7534]
 * [j11-j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/748/workflows/2646028e-846c-4af9-bd16-b814f928d23a/jobs/7532]

It seems there are multiple failures.;;;","05/Aug/21 12:45;e.dimitrova;Thanks [~adelapena], I think David looped it only locally. Reopening the ticket for further investigation. ;;;","05/Aug/21 12:53;e.dimitrova;It seems the multiplexer failures are different, no client timeouts anymore. But still we need to fix those and not leave it flaky. ;;;","05/Aug/21 12:58;adelapena;I think that there are also some client request timeouts, eight in j8-j8;;;","05/Aug/21 13:13;e.dimitrova;You are right! It seems there are 4 of them I missed around the others. ;;;","17/Aug/21 00:43;dcapwell;removed myself.  If you look at the test failures in circle there are several things going on; each may need to be looked at;;;","23/May/22 20:27;brandon.williams;I did both a [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/499/workflows/a6c3e10c-39b8-468e-ba73-848be656e1bf/jobs/5840] and [j8|https://app.circleci.com/pipelines/github/driftx/cassandra/499/workflows/17b82ac4-136a-453e-bd8f-f5820bcea261/jobs/5842] repeated 500 runs each without failure, and the previous links are expired so I'm not sure what was wrong and I don't see any failures in butler.  I think we can close.;;;","24/May/22 14:44;adelapena;Indeed it doesn't seem to fail anymore. I have also run it again for both 4.1 ([j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1592/workflows/2febdefc-957b-42a6-b545-73ff7cbf17f9] and [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1592/workflows/0fb59648-ec0f-4b5d-af59-3ec9f36e6b22]) and trunk ([j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/1591/workflows/c6c21209-fcd1-4626-94d6-5a6bb38c5d0c] and [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/1591/workflows/40498ca4-7d06-4192-9dc5-b5b596e898d0]), and it survives another 500 runs. Also, it doesn't appear on Butler, so probably we should close.;;;","24/May/22 14:52;brandon.williams;Closing and returning to David since his patch solved this.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Wrong cqlsh python library location in cassandra-3.11.11-1 rhel packages ,CASSANDRA-16822,13392751,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,villesox,villesox,30/Jul/21 12:14,28/Sep/21 20:26,13/Jul/23 08:40,03/Sep/21 18:52,2.2.20,3.0.26,3.11.12,,,,,Packaging,,,,0,,,"cqlsh does not work because cqlshlib is in wrong location while I think it should be in python2.7 for cassandra-3.11

cassandra.spec seems to define python interpreter to /usr/bin/python so I think build environment has been changed after 3.11.10 so /usr/bin/python points to python3 instead of python2.

cassandra-3.11.10 did have chqlshlib in python2.7 site-packages
{noformat}
$ rpm -qpl cassandra-3.11.11-1.noarch.rpm |grep cql
warning: cassandra-3.11.11-1.noarch.rpm: Header V4 RSA/SHA512 Signature, key ID 0b84c041: NOKEY
/etc/cassandra/default.conf/cqlshrc.sample
/usr/bin/cqlsh
/usr/bin/cqlsh.py
/usr/bin/debug-cql
/usr/lib/python3.6/site-packages/cqlshlib
/usr/lib/python3.6/site-packages/cqlshlib/__init__.py
/usr/lib/python3.6/site-packages/cqlshlib/copyutil.py
/usr/lib/python3.6/site-packages/cqlshlib/cql3handling.py
/usr/lib/python3.6/site-packages/cqlshlib/cqlhandling.py
/usr/lib/python3.6/site-packages/cqlshlib/cqlshhandling.py
/usr/lib/python3.6/site-packages/cqlshlib/displaying.py
/usr/lib/python3.6/site-packages/cqlshlib/formatting.py
/usr/lib/python3.6/site-packages/cqlshlib/helptopics.py
/usr/lib/python3.6/site-packages/cqlshlib/pylexotron.py
/usr/lib/python3.6/site-packages/cqlshlib/saferscanner.py
/usr/lib/python3.6/site-packages/cqlshlib/sslhandling.py
/usr/lib/python3.6/site-packages/cqlshlib/tracing.py
/usr/lib/python3.6/site-packages/cqlshlib/util.py
/usr/lib/python3.6/site-packages/cqlshlib/wcwidth.py
{noformat}
 

Pull request to cassandra-3.11: https://github.com/apache/cassandra/pull/1124",,bkmdev,brandon.williams,mck,villesox,,,,,,,,,,,,"villesavolainen opened a new pull request #1124:
URL: https://github.com/apache/cassandra/pull/1124


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;30/Jul/21 12:34;githubbot;600","villesavolainen closed pull request #1124:
URL: https://github.com/apache/cassandra/pull/1124


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Sep/21 06:05;githubbot;600","villesavolainen closed pull request #1124:
URL: https://github.com/apache/cassandra/pull/1124


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Sep/21 20:26;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,CASSANDRA-16908,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Packaging,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Sep 23 23:02:24 UTC 2021,,,,,,,All,,,,"0|z0tha0:",9223372036854775807,,,,brandon.williams,,,,Normal,,3.0.25,,https://github.com/apache/cassandra/commit/2e547dfbc40e6b500db506353bced161c66f3113,,,,,,,,,CI,,,,,"30/Jul/21 12:51;brandon.williams;CASSANDRA-16477 is what caused this.  Does cqlsh fail to run for you? /cc [~mck];;;","30/Jul/21 12:55;villesox;{noformat}
# cqlsh
Traceback (most recent call last):
 File ""/usr/bin/cqlsh.py"", line 169, in <module>
 from cqlshlib import cql3handling, cqlhandling, pylexotron, sslhandling, cqlshhandling
ImportError: No module named cqlshlib{noformat}
I looked also for [https://downloads.apache.org/cassandra/redhat/30x/cassandra-3.0.25-1.noarch.rpm] which I think suffers same issue. I did not test.;;;","30/Jul/21 12:59;villesox;I did rebuild cassandra-3.11.11 from src.rpm with following change:
{noformat}
%define __python /usr/bin/python2{noformat}
And then cqlsh started to work because cqlshlib location changed to:
{noformat}
/usr/lib/python2.7/site-packages/cassandra_pylib-0.0.0-py2.7.egg-info
/usr/lib/python2.7/site-packages/cqlshlib
/usr/lib/python2.7/site-packages/cqlshlib/__init__.py
/usr/lib/python2.7/site-packages/cqlshlib/copyutil.py
/usr/lib/python2.7/site-packages/cqlshlib/cql3handling.py
/usr/lib/python2.7/site-packages/cqlshlib/cqlhandling.py
/usr/lib/python2.7/site-packages/cqlshlib/cqlshhandling.py
/usr/lib/python2.7/site-packages/cqlshlib/displaying.py
/usr/lib/python2.7/site-packages/cqlshlib/formatting.py
/usr/lib/python2.7/site-packages/cqlshlib/helptopics.py
/usr/lib/python2.7/site-packages/cqlshlib/pylexotron.py
/usr/lib/python2.7/site-packages/cqlshlib/saferscanner.py
/usr/lib/python2.7/site-packages/cqlshlib/sslhandling.py
/usr/lib/python2.7/site-packages/cqlshlib/tracing.py
/usr/lib/python2.7/site-packages/cqlshlib/util.py
/usr/lib/python2.7/site-packages/cqlshlib/wcwidth.py
{noformat};;;","30/Jul/21 13:05;brandon.williams;What version of python is it running without your change?  If it's python3 it would seem that it should pick it up from /usr/lib/python3.6/site-packages/;;;","30/Jul/21 13:11;villesox;This is CentOS7 and Python is 2.7.5. If I also install python3 it does not help. Looking inside /usr/bin/cqlsh.py reveals that it only supports python 2.7.
{noformat}
if sys.version_info[0] != 2 or sys.version_info[1] != 7:
    sys.exit(""\nCQL Shell supports only Python 2.7\n"")
{noformat};;;","30/Jul/21 13:16;brandon.williams;If python is 2.7.5 I'm confused how %{python_sitelib} chose /usr/lib/python3.6/, but also [~mck] this comment doesn't seem to be correct:

bq. The commit message is wrong: only 4.0 now requires python3. Other versions are compatible with python3 now (honouring the python you have installed). CHANGES.txt has been ninja-fixed.;;;","30/Jul/21 13:20;villesox;I think the build system which created packages might have /usr/bin/python -> python3 so then sitelib is python3.6 also in package.;;;","30/Jul/21 13:59;brandon.williams;Indeed, the build system is a centos8 docker image.;;;","02/Aug/21 07:04;mck;h3. To Reproduce
{code}
docker run -it centos /bin/sh

sh-4.4# echo '[cassandra]
name=Apache Cassandra
baseurl=https://downloads.apache.org/cassandra/redhat/311x
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://downloads.apache.org/cassandra/KEYS' > /etc/yum.repos.d/cassandra.repo

sh-4.4# yum -y update
sh-4.4# yum -y install cassandra
sh-4.4# yum -y install python2

sh-4.4# cassandra -R

sh-4.4# cqlsh
{code}

Replacing with python3 doesn't help, as mentioned above cqlsh forces python2.

Running with centos7 gives the same error (though python2 is already installed).

h4. Workaround
Works on both centos 7 and 8.
{code}
cp -r /usr/lib/python3.6/site-packages/cqlshlib /usr/lib/python2.7/site-packages/cqlshlib
{code};;;","02/Aug/21 13:17;mck;Patches
- [2.2|https://github.com/apache/cassandra/compare/cassandra-2.2...thelastpickle:mck/16822/2.2] [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/991/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/991/]
- [3.0|https://github.com/apache/cassandra/compare/cassandra-3.0...thelastpickle:mck/16822/3.0] [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/985/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/985/]
- [3.11|https://github.com/apache/cassandra/compare/cassandra-3.11...thelastpickle:mck/16822/3.11] [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/986/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/986/]

I am not sure if this is the way we want to go though. That is, building on python3, and installing that cqlshlib into site-packages for both python2 and python3. (This approach leaves arm64 as-is, and keeps the door open for cqlsh working on python3.)

RPMs built with these patches, for testing, can be found in https://nightlies.apache.org/cassandra/devbranch/misc/CASSANDRA-16822/
;;;","09/Aug/21 14:49;brandon.williams;bq. I am not sure if this is the way we want to go though

I'm not either, it kind of feels wrong.  But I'm not sure there is a better way, and eventually python2 will be gone, so +1.;;;","03/Sep/21 18:52;brandon.williams;I didn't find any better solutions.  Committed.;;;","23/Sep/21 23:02;bkmdev;Thanks [~mck], the workaround described worked over here (y)

In case anyone else encounters this issue it manifested as the below error instead for me, on an upgraded CentOS v7.9 box:  
{code:python}
$ cqlsh
Traceback (most recent call last):
  File ""/usr/bin/cqlsh.py"", line 173, in <module>
    from cqlshlib.formatting import (DEFAULT_DATE_FORMAT, DEFAULT_NANOTIME_FORMAT,
ImportError: cannot import name CqlType
$ python --version
Python 2.7.5
{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Documentation links broken, indexed by Google",CASSANDRA-16821,13392621,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mck,aratnofsky,aratnofsky,29/Jul/21 21:34,24/Jan/22 02:16,13/Jul/23 08:40,04/Aug/21 19:39,4.0.1,,,,,,,Documentation/Website,,,,0,,,"Internal documentation links like [https://cassandra.apache.org/doc/latest/operating/compaction/index.html] are now returning 404s. These links originate from within documentation (referenced from [https://cassandra.apache.org/doc/latest/)] and are indexed by Google (first result for ""apache cassandra compaction"", for example).

These links were working correctly as recently as late 2020: https://web.archive.org/web/20201020194414/https://cassandra.apache.org/doc/latest/operating/compaction/index.html",,aratnofsky,flightc,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,mck,,,,,,,,,,,,,Documentation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Aug 04 22:38:51 UTC 2021,,,,,,,All,,,,"0|z0tgh4:",9223372036854775807,,,,,,,,Normal,,,,https://github.com/apache/cassandra-website/commit/06c0af3ec53e0c9b375ec897172781041af1911f,,,,,,,,,,,,,,"04/Aug/21 19:39;mck;Thanks for the report [~aratnofsky].

Fixed with [06c0af3ec53e0c9b375ec897172781041af1911f|https://github.com/apache/cassandra-website/commit/06c0af3ec53e0c9b375ec897172781041af1911f].;;;","04/Aug/21 22:38;flightc;Thanks, Mick! (y);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix usage instructions about sstabledump -k and -x options,CASSANDRA-16818,13392370,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,adelapena,adelapena,28/Jul/21 16:10,27/May/22 19:25,13/Jul/23 08:40,30/Jul/21 17:18,4.0.1,4.1,4.1-alpha1,,,,,Tool/sstable,,,,0,,,"The options {{-k}} and {{-x}} of {{sstabledump}} admit multiple arguments, so users can include or exclude multiple partitions. The intended usage is, for example:
{code:java}
$ sstablepartitions <sstable_path> -k 1
$ sstablepartitions <sstable_path> -k 1 2 3
{code}
However, the following command will fail:
{code:java}
$ sstablepartitions -k 1 <sstable_path>
You must supply exactly one sstable
usage: sstabledump <sstable file path> <options>

Dump contents of given SSTable to standard output in JSON format.
 -d         CQL row per line internal representation
 -e         enumerate partition keys only
 -k <arg>   Partition key
 -t         Print raw timestamps instead of iso8601 date strings
 -x <arg>   Excluded partition key
{code}
This command fails because the sstable path is considered a fourth partition key, and the mandatory argument for the sstable path is missed. While I think this behaviour is correct, it can be a bit confusing for users, especially when the information about usage describes both {{-k}} and {{-x}} as single-argument.

I think that at least we should fix the description of the options to indicate that there could be multiple included/excluded keys, and probably improve the message about the missing sstable path when those options are used.

Alternatively we could modify the options to have a single argument and allow to repeat them, so we could accept things like:
{code:java}
$ sstablepartitions -k 1 <sstable_path>
$ sstablepartitions -k 1 -k 2 -k 3 <sstable_path>
$ sstablepartitions <sstable_path> -k 1 -k 2 -k 3
{code}
The main downside of the latter approach is that the change in the syntax of the command might cause compatibility issues. Also we would need to upgrade {{commons-cli}} to at least 1.2 due to CLI-137.",,adelapena,bereng,e.dimitrova,,,,,,,,,,,,,"adelapena opened a new pull request #1121:
URL: https://github.com/apache/cassandra/pull/1121


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jul/21 16:28;githubbot;600","adelapena opened a new pull request #1122:
URL: https://github.com/apache/cassandra/pull/1122


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jul/21 16:28;githubbot;600","adelapena closed pull request #1122:
URL: https://github.com/apache/cassandra/pull/1122


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:46;githubbot;600","adelapena closed pull request #1121:
URL: https://github.com/apache/cassandra/pull/1121


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:47;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,2400,,,0,2400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Code,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Aug 11 04:43:23 UTC 2021,,,,,,,All,,,,"0|z0texc:",9223372036854775807,,,,bereng,e.dimitrova,,,Low,,3.0.4,,https://github.com/apache/cassandra/commit/d319352fa89e324b3752c563f3c2d2bc21d8f914,,,,,,,,,The tests for {{SSTableExport}} are updated.,,,,,"28/Jul/21 16:37;adelapena;[This patch|https://github.com/apache/cassandra/compare/cassandra-4.0...adelapena:16818-4.0-instuctions-only] changes the description of the options adds extends the error message in this way:
{code:java}
$ /sstabledump -k 1 <sstable_path>
You must supply exactly one sstable, which should be before the -k/-x options so it's not interpreted as a partition key.
usage: sstabledump <sstable file path> <options>

Dump contents of given SSTable to standard output in JSON format.
 -d         CQL row per line internal representation
 -e         enumerate partition keys only
 -k <arg>   List of included partition keys
 -l         Output json lines, by partition
 -t         Print raw timestamps instead of iso8601 date strings
 -x <arg>   List of excluded partition keys
{code}
[This alternative patch|https://github.com/apache/cassandra/compare/cassandra-4.0...adelapena:16818-4.0-repeated-options] makes the options to accept a single argument but allows to repeat them, so the following commands are accepted:
{code:java}
$ sstablepartitions -k 1 <sstable_path>
$ sstablepartitions <sstable_path> -k 1
$ sstablepartitions -k 1 -k 2 -k 3 <sstable_path>
$ sstablepartitions <sstable_path> -k 1 -k 2 -k 3
{code}
However, some previously accepted commands will be rejected:
{code:java}
$ sstabledump <sstable_path> -k 1 2
You must supply exactly one sstable
usage: sstabledump <sstable file path> <options>

Dump contents of given SSTable to standard output in JSON format.
 -d         CQL row per line internal representation
 -e         enumerate partition keys only
 -k <arg>   Included partition key, can be used multiple times
 -l         Output json lines, by partition
 -t         Print raw timestamps instead of iso8601 date strings
 -x <arg>   Excluded partition key, can be used multiple times
{code}
Both patches include some minor improvements in {{SSTableExportTest}}, and the one changing the options includes some other minor test changes due to the way commons-cli changes help formatting.;;;","28/Jul/21 18:05;e.dimitrova;Good catch [~adelapena], I am in favor to improving the description and the error messages - first patch. I left two super small comments on your commit.

I am wondering, shall we add a test covering the specific case? ;;;","29/Jul/21 16:47;adelapena;Thanks for the review. I also think that improving the description and error messages is better, since the syntax itselt isn't wrong and it's only the description and documentation what is wrong and/or it's a bit misleading. Also, changing the syntax can lead to compatibility issues.
{quote}I am wondering, shall we add a test covering the specific case?
{quote}
The patch already contains four new tests in {{SSTableExportTest}} covering multiple keys and arguments in the wrong order for both arguments, do you mean any additional tests beyond those?
{quote}I left two super small comments on your commit.
{quote}
Thanks for the comments, I have added the {{SuppressWarnings}} annotation and modified the checks in {{assertPostTestEnv}} so they are in line with other tests. Here are the PRs for 4.0 and trunk:
||PR||CI||
|[4.0|https://github.com/apache/cassandra/pull/1121]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/708/workflows/eed7fc79-51b1-4f1c-8da5-8255cd9cf49f] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/708/workflows/8352fab0-d0c4-42f6-9dc7-db2fcef6b810]|
|[trunk|https://github.com/apache/cassandra/pull/1122]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/707/workflows/97a532c1-3415-484e-8cf2-1d59fe664825] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/707/workflows/738901f7-61f6-41fb-a257-4fe9b3350f43]|

The CI runs contain 100 repeated runs of {{SSTableExportTest}}.

I have also added some fixes to the [documentation for {{sstabledump}}|https://github.com/apache/cassandra/blob/b470459067641892855750c04e0b098af86e1e7b/doc/source/tools/sstable/sstabledump.rst].

I haven't prepared PRs for 3.0 nor 3.11 because IMO this isn't a very serious issue and we don't have either the test tooling or the docs in those branches, wdyt?;;;","30/Jul/21 15:13;adelapena;There were some CI test failures while checking {{assertSchemaNotLoaded}} with Java 11 that neither [~e.dimitrova] nor me have been able to reproduce locally. It seems that the loading of {{Schema}} class in the test cases that use {{TableMetadata}} might or might not load that class depending on the JVM version. I have changed the tests back to their previous form where that check is only done for the test cases where {{TableMetadata}} is used, adding a brief comment warning about the issue:
||PR||CI||
|[4.0|https://github.com/apache/cassandra/pull/1121]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/721/workflows/4decc78f-a2e5-43c0-90ee-618ad3c0d678] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/721/workflows/c72b39f7-eb58-4d93-a150-714244239825]|
|[trunk|https://github.com/apache/cassandra/pull/1122]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/722/workflows/fe5e7407-3af0-4a08-b196-434652ea8789] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/722/workflows/08f88bed-2879-4018-b76b-5dcc45e85ea3]|;;;","30/Jul/21 15:57;e.dimitrova;Agree on everything, +1, thanks [~adelapena]! ;;;","30/Jul/21 17:17;adelapena;Committed to {{cassandra-4.0}} as [d319352fa89e324b3752c563f3c2d2bc21d8f914|https://github.com/apache/cassandra/commit/d319352fa89e324b3752c563f3c2d2bc21d8f914] and merged to [{{trunk}}|https://github.com/apache/cassandra/commit/4e2464d44e72131934d1d223419c9fe5cc8bda5f]. Thanks for the review.;;;","09/Aug/21 07:09;bereng;[~adelapena] I see SSTableExport started failing in CI just after this commit. I was wondering if you might have some quick clue of what it might be before I jump into it?;;;","09/Aug/21 08:30;adelapena;[~bereng] it seems caused by the same assertions about schema loading mentioned above, even when they didn't failed either locally nor in the CircleCI multiplexer. I'm also looking into it.;;;","09/Aug/21 09:04;bereng;Seems to repro with the {{RepeatableRunner}}, j11 and cdc on around 100 iterations... #justfyi;;;","09/Aug/21 09:23;bereng;That schema loading check is noop imo. If you remove the {{if (not loadschema)}} [line|https://github.com/apache/cassandra/pull/1121/commits/f90301251dd3d761e18a9731025b364f7fc106f8#diff-71a75df34f06faf848378bdf1a20a7d54a3e282abfe24bb9def78d99b857081fR247] making the check trigger always the test will still pass!

And j11 seems to be loading that class at some point 'randomly'. So we can go down the rabbit hole of trying to pin down why/when j11 will load the class or just accept that's how it works and remove that check.

Also notice we have interleaved tests checking for the class to be loaded true/false, never clearing the loaded status in between, so once one test would have loaded it all later ones expecting it not to be loaded should fail. Which they don't bc of the above.

I would revert the schema class loading logic to what we had previously and then the test seems to pass for me locally.;;;","09/Aug/21 09:26;adelapena;The test also fails in the same way with {{RepeatableRunner}} if we revert the changes. I think that's because {{RepeatableRunner}} uses the same JVM, and that's messes with expectations about not loading the schema class only in some of the tests.;;;","09/Aug/21 09:38;bereng;^Correct. In the original code the schema loading seems to be checked only on the initial test. When using the {{RepeatableRunner}} yes, once a class has been loaded then that's it. You need to take that into account correct.;;;","09/Aug/21 09:49;adelapena;Yes, I was investigating the same approach, moving the new tests calling {{assertSchemaNotLoaded}} to the beginning of the class, since the tests that are in between may load or not load that class, producing the failure when they do load it.;;;","09/Aug/21 10:01;adelapena;Patch placing the tests calling {{assertSchemaNotLoaded}} at the beginning of the class:
||patch||CircleCI||Jenkins||
|[4.0|https://github.com/adelapena/cassandra/tree/16818-2-4.0]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/758/workflows/20a8027f-be2d-46db-a63f-2e7e9744ca3a] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/758/workflows/b5928d12-0df1-4bc5-a738-bbfe09ad32ff]|[run|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/995/pipeline]|
|[trunk|https://github.com/adelapena/cassandra/tree/16818-2-trunk]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/759/workflows/eb952c8c-1a14-4c7c-8ad3-f08940381f36] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/759/workflows/04d8368a-54e7-4f72-9267-6571bbbf06c1]|[run|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/996/pipeline]|;;;","09/Aug/21 10:21;bereng;Moving the tests to avoid interleaving true/false is a good step. But unless I am missing sthg that is still a no-op assert:
- We don't check the class was indeed loaded when {{true}}
- It doesn't matter if you call {{assertPostTestEnv()}} with true or false at all. The test always passes. The schema loading is a noop assert.

Do you see the same?
;;;","09/Aug/21 13:53;adelapena;We don't check the schema loading when {{loadsSchema}} is {{true}} because we can't be sure about whether the {{Schema}} class is going to be loaded when we load the table metadata. However, in the cases where {{loadsSchema}} is {{false}} we are sure that the {{TableMetadata}} isn't going to be loaded, so we can check that the schema isn't really loaded. If this weren't right we wouldn't be finding the test failure that concerns us.

I agree that there isn't a difference between calling {{assertPostTestEnv}} with {{true}} or {{false}} in the cases where the schema is loaded, but there would be a difference if the schema would be unexpectedly loaded in those cases, which is what we are trying to test. Also, for the cases that currently set {{loadsSchema}} to {{true}} there is a more obvious difference since they would just fail if we passed {{false}} instead.

In the end, a {{false}} {{loadsSchema}} parameter means that we are sure that the schema class shouldn't be loaded, and a {{true}} {{loadsSchema}} means that it may or may not load the schema. So maybe we could just rename the argument to {{maybeLoadsSchema}}, and add some JavaDoc about what it does and why it's necessary to run the tests in the right order, wdyt?;;;","09/Aug/21 14:16;adelapena;I have renamed {{loadsSchema}} to {{maybeLoadsSchema}} and added some JavaDoc  [here|https://github.com/adelapena/cassandra/commit/d4fa657eb24e91623549b68de7d97af03ed7fe1b].;;;","09/Aug/21 15:50;e.dimitrova;All changes and CI runs look good to me. +1 Thank you [~adelapena] for the quick fixes and improved docs!;;;","10/Aug/21 04:53;bereng;It still fails for me in the same way [~adelapena]:
* Fail:
**  Decorate [test|https://github.com/adelapena/cassandra/blob/d4fa657eb24e91623549b68de7d97af03ed7fe1b/test/unit/org/apache/cassandra/tools/SSTableExportTest.java] with
{code:java}
@RunWith(RepeatableRunner.class)
@RepeatableRunnerConfiguration(iterations = 100, runner = OrderedJUnit4ClassRunner.class)
{code}
** j11, ant real-clean, ant jar, ant -Duse.jdk11=true test-cdc -Dtest.name=SSTableExportTest
** Test fails
* Change iterations to 10 and test passes
* Replace all {{assertPostTestEnv(true);}} with {{assertPostTestEnv(false);}} and test passes

So unless I am missing sthg it's still failing?;;;","10/Aug/21 11:25;adelapena;I don't think that behaviour is unexpected given the limitations of {{RepeatableRunner}} and the reliance on the order in which the test are run.

The tests using {{assertPostTestEnv(true)}} are those that run beyond the instantiation of {{SSTableMetadata}}. Those tests may or may not load the schema, that's why we don't do any checks about schema loading. Placing the tests that never load the schema at the beginning of the test should guarantee that those tests can verify that the schema is not loaded without the risk of finding it loaded by one of the tests that may or may not load it. However, {{RepeatableRunner}} breaks this guarantee because it runs all the iterations in the same jvm, so some of the tests that never load the schema are run after the tests that may or may not load the schema from the previous iteration. This way, most runs pass a few initial iterations because the schema hasn't been loaded yet and, once an unlucky iteration has loaded it, they start to consistently fail.

To see this apparently random schema loading, we can remove all the tests in the class except one of the tests loading the table metadata, for example {{testTSFormatArg}}. Then we replace {{assertPostTestEnv(true)}} by {{assertPostTestEnv(false)}} in that test, so it verifies that the schema is not loaded. If we run the test repeatedly a few hundred times, we can see that the test survives a few rounds and then it starts to consistently fail. Conversely, if we replace the call to {{assertPostTestEnv}} by a call to {{assertSchemaLoaded}}, we will see the opposite behaviour, it fails a few times and then it consistently succeeds.
{quote}Change iterations to 10 and test passes
{quote}
It seems that the schema class is only loaded after a higher number of iterations, I have no clue about why that happens.
{quote}Replace all {{assertPostTestEnv(true);}} with {{assertPostTestEnv(false);}} and test passes
{quote}
That skips all checks about schema loading so it can never fail them, do you mean the opposite, replacing {{assertPostTestEnv(false)}} by {{assertPostTestEnv(true)}}? That would also fail.;;;","10/Aug/21 12:18;bereng;Ok so we're effectively checking schema loading classes only on the first tests as it was on the original code. Idk if I would have spared that boolean param then if it was me but it's just a nit.  Let's merge!;;;","10/Aug/21 13:10;adelapena;Right, only the first tests run the assertion about schema class loading, the only difference is that now we have multiple tests verifying that instead of just the first one. The reason for placing the assertion in a single centralized place is avoiding some [code duplication|https://github.com/apache/cassandra/blob/9802a70f68cdcd239a9128f90f5d8f9a941168de/test/unit/org/apache/cassandra/tools/SSTableExportTest.java#L54-L59], making sure that we test the same things after every test, and having a single place to document the need of running the tests in the right order and the unfeasibility of calling {{assertSchemaLoaded}}, in an attempt to ease things for those doing changes behind us.

I'll commit the changes in a bit if [~e.dimitrova] doesn't have anything else to add.;;;","10/Aug/21 14:02;e.dimitrova;{quote}in an attempt to ease things for those doing changes behind us
{quote}
*+1*

{quote} I'll commit the changes in a bit if [~e.dimitrova] doesn't have anything else to add.
{quote}
Nothing to add, thank you!;;;","10/Aug/21 14:35;adelapena;Great, thanks for the reviews.

Fix committed to {{cassandra-4.0}} as [a9abccb28b220f02e6d7628dffdb4678a399820c|https://github.com/apache/cassandra/commit/a9abccb28b220f02e6d7628dffdb4678a399820c] and merged to [{{trunk}}|https://github.com/apache/cassandra/commit/b26a4daf8624f77279b8a98df6fdc7094b6b6da2].

The multiplexer didn't manage to reproduce the last Jenkins failure, we can't use the repeated runner and we only have one set of clean Jenkins runs with the last fix, so I guess we'll need to keep an eye on the next nightlys to verify that the test is actually fixed.;;;","10/Aug/21 16:22;e.dimitrova;{quote}we'll need to keep an eye on the next nightlys to verify that the test is actually fixed.
{quote}
Agreed, thank you;;;","11/Aug/21 04:43;bereng;CI lgtm :-) nice!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix ERROR message which prints data information in the logs,CASSANDRA-16817,13392333,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,adelapena,adelapena,28/Jul/21 12:20,27/May/22 19:25,13/Jul/23 08:40,29/Jul/21 11:18,3.0.26,3.11.12,4.0.1,4.1,4.1-alpha1,,,Feature/Materialized Views,,,,0,,,"{{StorageProxy.mutateMV}} might log [an error message|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/service/StorageProxy.java#L880] that prints user data in the logs beyond the row key, for example:
{code}
ERROR [MutationStage-2] 2021-07-28 13:08:52,609 StorageProxy.java:1002 - Error applying local view update to keyspace k: Mutation(keyspace='k', key='00000001', modifications=[
  [k.mv] key=1 partition_deletion=deletedAt=-9223372036854775808, localDeletion=2147483647 columns=[[] | []]
    Row[info=[ts=1627474132606719] ]: k=0, v=MY CONFIDENTIAL DATA |
])
{code}
We should probably change that log message so it doesn't print the entire mutation but only the keyspace, tables and partition key of the mutation.",,adelapena,brandon.williams,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Security -> Information Leakage,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jul 29 11:16:22 UTC 2021,,,,,,,All,,,,"0|z0tep4:",9223372036854775807,,,,brandon.williams,,,,Low,,3.0.15,,https://github.com/apache/cassandra/commit/69b653a01f09874d73bc70e1e7a7670859a4e4a4,,,,,,,,,Changing the log message should be enough,,,,,"28/Jul/21 12:37;adelapena;Here is a trivial patch changing the log message:

||branch||CI||
|[3.0|https://github.com/apache/cassandra/compare/cassandra-3.0...adelapena:16817-3.0]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/700/workflows/b2490065-bb4b-43d9-aba0-14d7453ddc37]|
|[3.11|https://github.com/apache/cassandra/compare/cassandra-3.11...adelapena:16817-3.11]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/703/workflows/957642e6-6479-46e1-93a9-6b2d88860bca]|
|[4.0|https://github.com/apache/cassandra/compare/cassandra-4.0...adelapena:16817-4.0]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/702/workflows/36bd79c4-829c-41af-bee0-a9ad96e70f80] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/702/workflows/68d04e1c-f503-48d7-8959-4aa77ac2c3fd]|
|[trunk|https://github.com/apache/cassandra/compare/trunk...adelapena:16817-trunk]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/701/workflows/b3e17b4f-f2a1-42ab-87ea-a8d2a868ad17] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/701/workflows/3bf996fd-d041-4f7c-8f67-1510ad896d6f]|;;;","28/Jul/21 12:40;brandon.williams;+1 if CI looks good.;;;","28/Jul/21 13:58;adelapena;Thanks for the review, I'd say that the CI failures are not related to the change.;;;","28/Jul/21 14:55;brandon.williams;They look unrelated to me as well.;;;","29/Jul/21 11:16;adelapena;Committed to 3.0 as [69b653a01f09874d73bc70e1e7a7670859a4e4a4|https://github.com/apache/cassandra/commit/69b653a01f09874d73bc70e1e7a7670859a4e4a4] and merged to [3.11|https://github.com/apache/cassandra/commit/01add65597bc76927674e33db3f48552c06eb82c], [4.0|https://github.com/apache/cassandra/commit/bc51c57b0d63e3ad136cdede7c1b335224ae66c5] and [trunk|https://github.com/apache/cassandra/commit/592d5e336dca262a420fff385c94073725e7cc33].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nightlies.a.o usage is too high,CASSANDRA-16810,13390718,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,19/Jul/21 14:26,25/Jul/21 06:12,13/Jul/23 08:40,24/Jul/21 21:17,,,,,,,,Build,,,,0,,,"Gavin [reports|https://the-asf.slack.com/archives/CS6CA748J/p1626704126045500] that we're using over 1TB here and our documention is published in multiple locations ""some in Cassandra$x.$y and some in cassandra$x,$y""",,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sun Jul 25 06:12:12 UTC 2021,,,,,,,All,,,,"0|z0t4q8:",9223372036854775807,,,,,,,,Normal,,,,,,,,,,,,,,,,,,"19/Jul/21 15:19;brandon.williams;After an initial pass, I don't see anything obviously wrong with the tasks that publish to nightlies, for instance [here|https://github.com/apache/cassandra-builds/blob/trunk/jenkins-dsl/cassandra_job_dsl_seed.groovy#L408].;;;","19/Jul/21 16:00;brandon.williams;Spoke with Gavin, the ""some in Cassandra$x.$y and some in cassandra$x,$y"" is confusion over the pipeline and stage artifact separation.;;;","24/Jul/21 21:16;mck;Cleaning up tarball, deb and rpm, artefacts older than 30 days.
{code:java}
cd /Volumes/cassandra
find cassandra-*/Cassandra-*-artifacts -type f \( -name ""*.tar.gz"" -o -name ""*.deb"" -o -name ""*.rpm"" \) -print | wc -l
{code}
{noformat}
21253
{noformat}
There were 21253 such artefacts.
{code:java}
cd /Volumes/cassandra
du -chs cassandra-*/Cassandra-*-artifacts devbranch/Cassandra-devbranch-artifacts
{code}
{noformat}
  7.6G	cassandra-2.2/Cassandra-2.2-artifacts
 27G	cassandra-3.0/Cassandra-3.0-artifacts
 48G	cassandra-3.11/Cassandra-3.11-artifacts
 39G	cassandra-4.0.0/Cassandra-4.0.0-artifacts
106G	cassandra-4.0/Cassandra-4.0-artifacts
335G	devbranch/Cassandra-devbranch-artifacts
562G	total
{noformat}
Using 562G of disk space.
{code:java}
cd /Volumes/cassandra
find cassandra-*/Cassandra-*-artifacts devbranch/Cassandra-devbranch-artifacts -type f \( -name ""*.tar.gz"" -o -name ""*.deb"" -o -name ""*.rpm"" \) -mtime +30 -exec rm {} \;
{code}
After deleting those that are older than 30 days…
{code:java}
cd /Volumes/cassandra
du -chs cassandra-*/Cassandra-*-artifacts devbranch/Cassandra-devbranch-artifacts
{code}
{noformat}
   1.5G	cassandra-2.2/Cassandra-2.2-artifacts
   6.2G	cassandra-3.0/Cassandra-3.0-artifacts
   9.7G	cassandra-3.11/Cassandra-3.11-artifacts
  18G	cassandra-4.0.0/Cassandra-4.0.0-artifacts
  45G	cassandra-4.0/Cassandra-4.0-artifacts
  66G	devbranch/Cassandra-devbranch-artifacts
 146G	total
{noformat}
…. 416G of disk freed.;;;","24/Jul/21 21:17;mck;fyi [~gmcdonald];;;","25/Jul/21 06:12;gmcdonald;awesome ty!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pre-4.0 FWD_FRM message parameter serialization and message-id forwarding is incorrect,CASSANDRA-16808,13390199,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jmeredithco,jmeredithco,jmeredithco,17/Jul/21 04:32,27/May/22 19:24,13/Jul/23 08:40,21/Jul/21 17:21,4.0,4.0.0,4.1,4.1-alpha1,,,,Messaging/Internode,,,,1,,,"Fixing CASSANDRA-16797 has exposed an issue with the way {{FWD_FRM}} is serialized.

In the code cleanup during the internode messaging refactor, the serialization for {{FWD_FRM}} (the endpoint to respond to for forwarded messages) was implemented using the same serialization format as CompactEndpointSerializationHelper which prefixes the address bytes with their length, however the FWD_FRM parameter value does not include a length and just converts the parameter value to an InetAddress.

In a mixed version cluster this causes the pre-4.0 nodes to fail when deserializing the mutation
{code:java}
java.lang.RuntimeException: java.net.UnknownHostException: addr is of illegal length
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:72) ~[dtest-3.0.25.jar:na]
        at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[na:na]
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) ~[dtest-3.0.25.jar:na]
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:134) ~[dtest-3.0.25.jar:na]
        at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) ~[dtest-3.0.25.jar:na]
        at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
Caused by: java.net.UnknownHostException: addr is of illegal length
        at java.base/java.net.InetAddress.getByAddress(InetAddress.java:1208) ~[na:na]
        at java.base/java.net.InetAddress.getByAddress(InetAddress.java:1571) ~[na:na]
        at org.apache.cassandra.db.MutationVerbHandler.doVerb(MutationVerbHandler.java:57) ~[dtest-3.0.25.jar:na]
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:67) ~[dtest-3.0.25.jar:na]
        ... 5 common frames omitted
{code}
Unfortunately there isn't a clean fix I can see as {{org.apache.cassandra.io.IVersionedAsymmetricSerializer#deserialize}} used to deserialize the FWD_FRM address does not take a maximum length to deserialize and it's impossible to tell definitely know if it's an IPv4 or IPv6 address from the first four bytes.

The patch I'm submitting special-cases the deserializing pre-4.0 {{FWD_FRM}} parameters in the {{Message}} deserializer. That seems preferable to extending the deserialization interface or creating a new {{DataInputBuffer}} limited by the parameter value length.

Once that was fixed, the INSERT statements were still failing which I tracked down to the 4.0 optimization of serializing the forwarded message once if the message id is the same
 [https://github.com/apache/cassandra/blob/cassandra-4.0/src/java/org/apache/cassandra/db/MutationVerbHandler.java#L76]

In the test case I wrote, only one message was being forwarded and that had a different id to the original forwarded message. The {{useSameMessageID}} method only checked message Ids within the forwarded messages.

 

Code Details:

When MutationVerbHandler.forwardToLocalNodes is constructing the forwarding message it just stores the the byte array representing the IPv4 or IPv6 address in the parameter array.

(link [https://github.com/apache/cassandra/blob/44604b7316fcbfd7d0d7425e75cd7ebe267e3247/src/java/org/apache/cassandra/db/MutationVerbHandler.java#L90] )
{code:java}
    private static void forwardToLocalNodes(Mutation mutation, MessagingService.Verb verb, byte[] forwardBytes, InetAddress from) throws IOException
    {
        try (DataInputStream in = new DataInputStream(new FastByteArrayInputStream(forwardBytes)))
        {
            int size = in.readInt();

            // tell the recipients who to send their ack to
            MessageOut<Mutation> message = new MessageOut<>(verb, mutation, Mutation.serializer).withParameter(Mutation.FORWARD_FROM, from.getAddress());
{code}
When the message is serialized in 3.0 MessageOut.serialize, that raw entry of bytes is written with the length

(link [https://github.com/apache/cassandra/blob/44604b7316fcbfd7d0d7425e75cd7ebe267e3247/src/java/org/apache/cassandra/net/MessageOut.java#L119] )
{code:java}
    public void serialize(DataOutputPlus out, int version) throws IOException
    {
        CompactEndpointSerializationHelper.serialize(from, out);

        out.writeInt(MessagingService.Verb.convertForMessagingServiceVersion(verb, version).getId());
        out.writeInt(parameters.size());
        for (Map.Entry<String, byte[]> entry : parameters.entrySet())
        {
            out.writeUTF(entry.getKey());
            out.writeInt(entry.getValue().length);
            out.write(entry.getValue());
        }
        ....
    }
{code}
And we do the same on 4.0, however in 4.0 the parameter is serialized using the ParamType enum

(link [https://github.com/apache/cassandra/blob/fcd30b6e0db3622a8e78e9aa35221f630c77f6de/src/java/org/apache/cassandra/net/Message.java#L1154] )
{code:java}
            for (int i = 0; i < count; i++)
            {
                ParamType type = version >= VERSION_40
                    ? ParamType.lookUpById(Ints.checkedCast(in.readUnsignedVInt()))
                    : ParamType.lookUpByAlias(in.readUTF());

                int length = version >= VERSION_40
                    ? Ints.checkedCast(in.readUnsignedVInt())
                    : in.readInt();

                if (null != type)
                    params.put(type, type.serializer.deserialize(in, version));
                else
                    in.skipBytesFully(length); // forward compatibiliy with minor version changes
            }
{code}
(link [https://github.com/apache/cassandra/blob/fcd30b6e0db3622a8e78e9aa35221f630c77f6de/src/java/org/apache/cassandra/net/ParamType.java#L45] )
{code:java}
public enum ParamType
{
    FORWARD_TO          (0, ""FWD_TO"",        ForwardingInfo.serializer),
    RESPOND_TO          (1, ""FWD_FRM"",       inetAddressAndPortSerializer),
    ...
}
{code}
The {{InetAddressAndPortSerializer}} has been based on the 3.0 {{CompactEndpointSerializationHelper}} encoding used in the message header,
 however that format includes a single byte with the length of the address when pre-4.0 nodes are just expecting the parameter value
 to contain the raw address bytes.

(link [https://github.com/apache/cassandra/blob/fcd30b6e0db3622a8e78e9aa35221f630c77f6de/src/java/org/apache/cassandra/locator/InetAddressAndPort.java#L308] )
{code:java}
            if (version >= MessagingService.VERSION_40)
            {
                out.writeByte(buf.length + 2);
                out.write(buf);
                out.writeShort(endpoint.port);
            }
            else
            {
                out.writeByte(buf.length); //// Surprise!  Bonus byte!
                out.write(buf);
            }
{code}",,benedict,e.dimitrova,jeromatron,jjordan,jmeredithco,maedhroz,mck,yakir.g,,,,,,,,"jonmeredith opened a new pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111


   See https://issues.apache.org/jira/browse/CASSANDRA-16808


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Jul/21 04:36;githubbot;600","maedhroz commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672613021



##########
File path: src/java/org/apache/cassandra/net/Message.java
##########
@@ -1151,9 +1151,20 @@ private void serializeParams(Map<ParamType, Object> params, DataOutputPlus out,
                     : in.readInt();
 
                 if (null != type)
-                    params.put(type, type.serializer.deserialize(in, version));
-                else
+                {
+                    // Have to special case deserializer as pre-4.0 needs length to decode correctly
+                    if (version < VERSION_40 && type == ParamType.RESPOND_TO)
+                    {
+                        params.put(type, InetAddressAndPort.FwdFrmSerializer.fwdFrmSerializer.pre40DeserializeWithLength(in, version, length));
+                    }
+                    else
+                    {
+                        params.put(type, type.serializer.deserialize(in, version));
+                    }
+                }
+                else {

Review comment:
       nit: newline




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 20:36;githubbot;600","maedhroz commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672616626



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)
+        .setup(cluster -> {
+            cluster.schemaChange(""ALTER KEYSPACE "" + KEYSPACE +
+                "" WITH replication = {'class': 'NetworkTopologyStrategy', "" + ntsArgs + "" };"");
+
+            cluster.schemaChange(""CREATE TABLE ""+ KEYSPACE + ""."" + TABLE + "" (pk int, PRIMARY KEY(pk))"");
+
+            logger.info(""Testing after setup, all nodes running {}"", cluster.get(1).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .runAfterNodeUpgrade((UpgradeableCluster cluster, int nodeId) -> {
+            // Should be able to coordinate a write to any node and have a copy appear locally on all others
+            logger.info(""Testing after upgrading node{} to {}"", nodeId, cluster.get(nodeId).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .run();

Review comment:
       nit: This is very similar to the framework in `MixedModeReplicationTestBase`, although it clearly adds some new points of configurability. This test is already written, so it probably doesn't make sense to rework, but I figured I'd mention it at least to share some tribal knowledge.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 20:42;githubbot;600","maedhroz commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672617268



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)

Review comment:
       nit: Should we test 3.11 at all, or is the serialization apparatus basically the same in 3.11 as it is in 3.0?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 20:43;githubbot;600","maedhroz commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672634341



##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message
+    public static final class FwdFrmSerializer implements IVersionedSerializer<InetAddressAndPort>
+    {
+        public static final FwdFrmSerializer fwdFrmSerializer = new FwdFrmSerializer();
+        private FwdFrmSerializer() { }
+
+        public void serialize(InetAddressAndPort endpoint, DataOutputPlus out, int version) throws IOException
+        {
+            byte[] buf = endpoint.addressBytes;
+
+            if (version >= MessagingService.VERSION_40)
+            {
+                out.writeByte(buf.length + 2);
+                out.write(buf);
+                out.writeShort(endpoint.port);
+            }
+            else
+            {
+                out.write(buf);
+            }
+        }
+
+        public long serializedSize(InetAddressAndPort from, int version)
+        {
+            //4.0 includes a port number
+            if (version >= MessagingService.VERSION_40)
+            {
+                if (from.address instanceof Inet4Address)
+                    return 1 + 4 + 2;
+                assert from.address instanceof Inet6Address;
+                return 1 + 16 + 2;
+            }
+            else
+            {
+                if (from.address instanceof Inet4Address)
+                    return 4;
+                assert from.address instanceof Inet6Address;
+                return 16;
+            }
+        }
+
+        @Override
+        public InetAddressAndPort deserialize(DataInputPlus in, int version) throws IOException
+        {
+            if (version >= MessagingService.VERSION_40)
+            {
+                int size = in.readByte() & 0xFF;
+                switch (size)
+                {
+                    //Address and one port
+                    case 6:
+                    case 18:
+                    {
+                        byte[] bytes = new byte[size - 2];
+                        in.readFully(bytes);
+
+                        int port = in.readShort() & 0xFFFF;
+                        return getByAddressOverrideDefaults(InetAddress.getByAddress(bytes), bytes, port);

Review comment:
       nit: Block is duplicated in the original serializer.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 21:11;githubbot;600","maedhroz commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672637077



##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message

Review comment:
       nit: Both this and the comments for `Serializer` above could be in proper JavaDoc format. (Would allow for links and such, etc.)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 21:15;githubbot;600","maedhroz commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672637862



##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message
+    public static final class FwdFrmSerializer implements IVersionedSerializer<InetAddressAndPort>
+    {
+        public static final FwdFrmSerializer fwdFrmSerializer = new FwdFrmSerializer();
+        private FwdFrmSerializer() { }
+
+        public void serialize(InetAddressAndPort endpoint, DataOutputPlus out, int version) throws IOException
+        {
+            byte[] buf = endpoint.addressBytes;
+
+            if (version >= MessagingService.VERSION_40)
+            {
+                out.writeByte(buf.length + 2);
+                out.write(buf);
+                out.writeShort(endpoint.port);
+            }
+            else
+            {
+                out.write(buf);
+            }
+        }
+
+        public long serializedSize(InetAddressAndPort from, int version)
+        {
+            //4.0 includes a port number
+            if (version >= MessagingService.VERSION_40)
+            {
+                if (from.address instanceof Inet4Address)
+                    return 1 + 4 + 2;
+                assert from.address instanceof Inet6Address;
+                return 1 + 16 + 2;
+            }
+            else
+            {
+                if (from.address instanceof Inet4Address)
+                    return 4;
+                assert from.address instanceof Inet6Address;
+                return 16;
+            }
+        }

Review comment:
       @jonmeredith There are certainly chunks of `serialize()` and `serializedSize()` that are duplicated. (i.e. Only their pre-4.0 behavior diverges?) It may be nice to push some of this into a base class w/ abstract `pre40Serialize()` and `pre40SerializedSize()` methods to cut down on surface area until it all goes away if we ever break support for mixed 3.x <-> x.x version clusters.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 21:17;githubbot;600","maedhroz commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672640517



##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -34,6 +34,7 @@
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
 import org.apache.cassandra.net.MessagingService;
+import org.apache.cassandra.net.ParamType;

Review comment:
       nit: unused?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 21:22;githubbot;600","jonmeredith commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672646306



##########
File path: src/java/org/apache/cassandra/net/Message.java
##########
@@ -1151,9 +1151,20 @@ private void serializeParams(Map<ParamType, Object> params, DataOutputPlus out,
                     : in.readInt();
 
                 if (null != type)
-                    params.put(type, type.serializer.deserialize(in, version));
-                else
+                {
+                    // Have to special case deserializer as pre-4.0 needs length to decode correctly
+                    if (version < VERSION_40 && type == ParamType.RESPOND_TO)
+                    {
+                        params.put(type, InetAddressAndPort.FwdFrmSerializer.fwdFrmSerializer.pre40DeserializeWithLength(in, version, length));
+                    }
+                    else
+                    {
+                        params.put(type, type.serializer.deserialize(in, version));
+                    }
+                }
+                else {

Review comment:
       ack




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 21:32;githubbot;600","jonmeredith commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672646842



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)

Review comment:
       Serialization looked the same when I checked 3.11.  Not sure it's worth running every release, but I can test it once off.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 21:32;githubbot;600","jonmeredith commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672652730



##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message
+    public static final class FwdFrmSerializer implements IVersionedSerializer<InetAddressAndPort>
+    {
+        public static final FwdFrmSerializer fwdFrmSerializer = new FwdFrmSerializer();
+        private FwdFrmSerializer() { }
+
+        public void serialize(InetAddressAndPort endpoint, DataOutputPlus out, int version) throws IOException
+        {
+            byte[] buf = endpoint.addressBytes;
+
+            if (version >= MessagingService.VERSION_40)
+            {
+                out.writeByte(buf.length + 2);
+                out.write(buf);
+                out.writeShort(endpoint.port);
+            }
+            else
+            {
+                out.write(buf);
+            }
+        }
+
+        public long serializedSize(InetAddressAndPort from, int version)
+        {
+            //4.0 includes a port number
+            if (version >= MessagingService.VERSION_40)
+            {
+                if (from.address instanceof Inet4Address)
+                    return 1 + 4 + 2;
+                assert from.address instanceof Inet6Address;
+                return 1 + 16 + 2;
+            }
+            else
+            {
+                if (from.address instanceof Inet4Address)
+                    return 4;
+                assert from.address instanceof Inet6Address;
+                return 16;
+            }
+        }

Review comment:
       I had the patch that way originally but backed away as each method has to handle pre/post 4.0 messages so to when adding protections to make sure the wrong serializer wasn't called call paths longer/uglier so I went back to the simpler option of having the two full implementations.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 21:43;githubbot;600","jonmeredith commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672653081



##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -34,6 +34,7 @@
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
 import org.apache.cassandra.net.MessagingService;
+import org.apache.cassandra.net.ParamType;

Review comment:
       ack
   




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 21:44;githubbot;600","jonmeredith commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672670833



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)

Review comment:
       Confirmed running with `.upgrade(Versions.Major.v3X, Versions.Major.v4)` works. 
   
   Before this change there would be value in testing `nodesPerDC=2;` and a larger value to exercise different paths through `sameMessageId`, however the updated implementation doesn't special case single node forwarding.
   




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 22:21;githubbot;600","jonmeredith commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672681216



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)
+        .setup(cluster -> {
+            cluster.schemaChange(""ALTER KEYSPACE "" + KEYSPACE +
+                "" WITH replication = {'class': 'NetworkTopologyStrategy', "" + ntsArgs + "" };"");
+
+            cluster.schemaChange(""CREATE TABLE ""+ KEYSPACE + ""."" + TABLE + "" (pk int, PRIMARY KEY(pk))"");
+
+            logger.info(""Testing after setup, all nodes running {}"", cluster.get(1).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .runAfterNodeUpgrade((UpgradeableCluster cluster, int nodeId) -> {
+            // Should be able to coordinate a write to any node and have a copy appear locally on all others
+            logger.info(""Testing after upgrading node{} to {}"", nodeId, cluster.get(nodeId).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .run();

Review comment:
       I took a look at unifying them and the sticking point is I don't really want to re-implement NTS to work out where things should be written.  `MixedModeMessageForwardTest` sets the RF to make sure all nodes in the DC are written to so it's easier to check.
   
   I was able to remove node UP check, I think I added it when I didn't understand the messageId issue.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 22:45;githubbot;600","jonmeredith commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672646306



##########
File path: src/java/org/apache/cassandra/net/Message.java
##########
@@ -1151,9 +1151,20 @@ private void serializeParams(Map<ParamType, Object> params, DataOutputPlus out,
                     : in.readInt();
 
                 if (null != type)
-                    params.put(type, type.serializer.deserialize(in, version));
-                else
+                {
+                    // Have to special case deserializer as pre-4.0 needs length to decode correctly
+                    if (version < VERSION_40 && type == ParamType.RESPOND_TO)
+                    {
+                        params.put(type, InetAddressAndPort.FwdFrmSerializer.fwdFrmSerializer.pre40DeserializeWithLength(in, version, length));
+                    }
+                    else
+                    {
+                        params.put(type, type.serializer.deserialize(in, version));
+                    }
+                }
+                else {

Review comment:
       ack

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)

Review comment:
       Serialization looked the same when I checked 3.11.  Not sure it's worth running every release, but I can test it once off.

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message
+    public static final class FwdFrmSerializer implements IVersionedSerializer<InetAddressAndPort>
+    {
+        public static final FwdFrmSerializer fwdFrmSerializer = new FwdFrmSerializer();
+        private FwdFrmSerializer() { }
+
+        public void serialize(InetAddressAndPort endpoint, DataOutputPlus out, int version) throws IOException
+        {
+            byte[] buf = endpoint.addressBytes;
+
+            if (version >= MessagingService.VERSION_40)
+            {
+                out.writeByte(buf.length + 2);
+                out.write(buf);
+                out.writeShort(endpoint.port);
+            }
+            else
+            {
+                out.write(buf);
+            }
+        }
+
+        public long serializedSize(InetAddressAndPort from, int version)
+        {
+            //4.0 includes a port number
+            if (version >= MessagingService.VERSION_40)
+            {
+                if (from.address instanceof Inet4Address)
+                    return 1 + 4 + 2;
+                assert from.address instanceof Inet6Address;
+                return 1 + 16 + 2;
+            }
+            else
+            {
+                if (from.address instanceof Inet4Address)
+                    return 4;
+                assert from.address instanceof Inet6Address;
+                return 16;
+            }
+        }

Review comment:
       I had the patch that way originally but backed away as each method has to handle pre/post 4.0 messages so to when adding protections to make sure the wrong serializer wasn't called call paths longer/uglier so I went back to the simpler option of having the two full implementations.

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -34,6 +34,7 @@
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
 import org.apache.cassandra.net.MessagingService;
+import org.apache.cassandra.net.ParamType;

Review comment:
       ack
   

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)

Review comment:
       Confirmed running with `.upgrade(Versions.Major.v3X, Versions.Major.v4)` works. 
   
   Before this change there would be value in testing `nodesPerDC=2;` and a larger value to exercise different paths through `sameMessageId`, however the updated implementation doesn't special case single node forwarding.
   

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)
+        .setup(cluster -> {
+            cluster.schemaChange(""ALTER KEYSPACE "" + KEYSPACE +
+                "" WITH replication = {'class': 'NetworkTopologyStrategy', "" + ntsArgs + "" };"");
+
+            cluster.schemaChange(""CREATE TABLE ""+ KEYSPACE + ""."" + TABLE + "" (pk int, PRIMARY KEY(pk))"");
+
+            logger.info(""Testing after setup, all nodes running {}"", cluster.get(1).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .runAfterNodeUpgrade((UpgradeableCluster cluster, int nodeId) -> {
+            // Should be able to coordinate a write to any node and have a copy appear locally on all others
+            logger.info(""Testing after upgrading node{} to {}"", nodeId, cluster.get(nodeId).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .run();

Review comment:
       I took a look at unifying them and the sticking point is I don't really want to re-implement NTS to work out where things should be written.  `MixedModeMessageForwardTest` sets the RF to make sure all nodes in the DC are written to so it's easier to check.
   
   I was able to remove node UP check, I think I added it when I didn't understand the messageId issue.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 09:37;githubbot;600","maedhroz commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672613021



##########
File path: src/java/org/apache/cassandra/net/Message.java
##########
@@ -1151,9 +1151,20 @@ private void serializeParams(Map<ParamType, Object> params, DataOutputPlus out,
                     : in.readInt();
 
                 if (null != type)
-                    params.put(type, type.serializer.deserialize(in, version));
-                else
+                {
+                    // Have to special case deserializer as pre-4.0 needs length to decode correctly
+                    if (version < VERSION_40 && type == ParamType.RESPOND_TO)
+                    {
+                        params.put(type, InetAddressAndPort.FwdFrmSerializer.fwdFrmSerializer.pre40DeserializeWithLength(in, version, length));
+                    }
+                    else
+                    {
+                        params.put(type, type.serializer.deserialize(in, version));
+                    }
+                }
+                else {

Review comment:
       nit: newline

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)
+        .setup(cluster -> {
+            cluster.schemaChange(""ALTER KEYSPACE "" + KEYSPACE +
+                "" WITH replication = {'class': 'NetworkTopologyStrategy', "" + ntsArgs + "" };"");
+
+            cluster.schemaChange(""CREATE TABLE ""+ KEYSPACE + ""."" + TABLE + "" (pk int, PRIMARY KEY(pk))"");
+
+            logger.info(""Testing after setup, all nodes running {}"", cluster.get(1).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .runAfterNodeUpgrade((UpgradeableCluster cluster, int nodeId) -> {
+            // Should be able to coordinate a write to any node and have a copy appear locally on all others
+            logger.info(""Testing after upgrading node{} to {}"", nodeId, cluster.get(nodeId).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .run();

Review comment:
       nit: This is very similar to the framework in `MixedModeReplicationTestBase`, although it clearly adds some new points of configurability. This test is already written, so it probably doesn't make sense to rework, but I figured I'd mention it at least to share some tribal knowledge.

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)

Review comment:
       nit: Should we test 3.11 at all, or is the serialization apparatus basically the same in 3.11 as it is in 3.0?

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message
+    public static final class FwdFrmSerializer implements IVersionedSerializer<InetAddressAndPort>
+    {
+        public static final FwdFrmSerializer fwdFrmSerializer = new FwdFrmSerializer();
+        private FwdFrmSerializer() { }
+
+        public void serialize(InetAddressAndPort endpoint, DataOutputPlus out, int version) throws IOException
+        {
+            byte[] buf = endpoint.addressBytes;
+
+            if (version >= MessagingService.VERSION_40)
+            {
+                out.writeByte(buf.length + 2);
+                out.write(buf);
+                out.writeShort(endpoint.port);
+            }
+            else
+            {
+                out.write(buf);
+            }
+        }
+
+        public long serializedSize(InetAddressAndPort from, int version)
+        {
+            //4.0 includes a port number
+            if (version >= MessagingService.VERSION_40)
+            {
+                if (from.address instanceof Inet4Address)
+                    return 1 + 4 + 2;
+                assert from.address instanceof Inet6Address;
+                return 1 + 16 + 2;
+            }
+            else
+            {
+                if (from.address instanceof Inet4Address)
+                    return 4;
+                assert from.address instanceof Inet6Address;
+                return 16;
+            }
+        }
+
+        @Override
+        public InetAddressAndPort deserialize(DataInputPlus in, int version) throws IOException
+        {
+            if (version >= MessagingService.VERSION_40)
+            {
+                int size = in.readByte() & 0xFF;
+                switch (size)
+                {
+                    //Address and one port
+                    case 6:
+                    case 18:
+                    {
+                        byte[] bytes = new byte[size - 2];
+                        in.readFully(bytes);
+
+                        int port = in.readShort() & 0xFFFF;
+                        return getByAddressOverrideDefaults(InetAddress.getByAddress(bytes), bytes, port);

Review comment:
       nit: Block is duplicated in the original serializer.

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message

Review comment:
       nit: Both this and the comments for `Serializer` above could be in proper JavaDoc format. (Would allow for links and such, etc.)

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message
+    public static final class FwdFrmSerializer implements IVersionedSerializer<InetAddressAndPort>
+    {
+        public static final FwdFrmSerializer fwdFrmSerializer = new FwdFrmSerializer();
+        private FwdFrmSerializer() { }
+
+        public void serialize(InetAddressAndPort endpoint, DataOutputPlus out, int version) throws IOException
+        {
+            byte[] buf = endpoint.addressBytes;
+
+            if (version >= MessagingService.VERSION_40)
+            {
+                out.writeByte(buf.length + 2);
+                out.write(buf);
+                out.writeShort(endpoint.port);
+            }
+            else
+            {
+                out.write(buf);
+            }
+        }
+
+        public long serializedSize(InetAddressAndPort from, int version)
+        {
+            //4.0 includes a port number
+            if (version >= MessagingService.VERSION_40)
+            {
+                if (from.address instanceof Inet4Address)
+                    return 1 + 4 + 2;
+                assert from.address instanceof Inet6Address;
+                return 1 + 16 + 2;
+            }
+            else
+            {
+                if (from.address instanceof Inet4Address)
+                    return 4;
+                assert from.address instanceof Inet6Address;
+                return 16;
+            }
+        }

Review comment:
       @jonmeredith There are certainly chunks of `serialize()` and `serializedSize()` that are duplicated. (i.e. Only their pre-4.0 behavior diverges?) It may be nice to push some of this into a base class w/ abstract `pre40Serialize()` and `pre40SerializedSize()` methods to cut down on surface area until it all goes away if we ever break support for mixed 3.x <-> x.x version clusters.

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -34,6 +34,7 @@
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
 import org.apache.cassandra.net.MessagingService;
+import org.apache.cassandra.net.ParamType;

Review comment:
       nit: unused?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 09:43;githubbot;600","maedhroz commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672613021



##########
File path: src/java/org/apache/cassandra/net/Message.java
##########
@@ -1151,9 +1151,20 @@ private void serializeParams(Map<ParamType, Object> params, DataOutputPlus out,
                     : in.readInt();
 
                 if (null != type)
-                    params.put(type, type.serializer.deserialize(in, version));
-                else
+                {
+                    // Have to special case deserializer as pre-4.0 needs length to decode correctly
+                    if (version < VERSION_40 && type == ParamType.RESPOND_TO)
+                    {
+                        params.put(type, InetAddressAndPort.FwdFrmSerializer.fwdFrmSerializer.pre40DeserializeWithLength(in, version, length));
+                    }
+                    else
+                    {
+                        params.put(type, type.serializer.deserialize(in, version));
+                    }
+                }
+                else {

Review comment:
       nit: newline

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)
+        .setup(cluster -> {
+            cluster.schemaChange(""ALTER KEYSPACE "" + KEYSPACE +
+                "" WITH replication = {'class': 'NetworkTopologyStrategy', "" + ntsArgs + "" };"");
+
+            cluster.schemaChange(""CREATE TABLE ""+ KEYSPACE + ""."" + TABLE + "" (pk int, PRIMARY KEY(pk))"");
+
+            logger.info(""Testing after setup, all nodes running {}"", cluster.get(1).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .runAfterNodeUpgrade((UpgradeableCluster cluster, int nodeId) -> {
+            // Should be able to coordinate a write to any node and have a copy appear locally on all others
+            logger.info(""Testing after upgrading node{} to {}"", nodeId, cluster.get(nodeId).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .run();

Review comment:
       nit: This is very similar to the framework in `MixedModeReplicationTestBase`, although it clearly adds some new points of configurability. This test is already written, so it probably doesn't make sense to rework, but I figured I'd mention it at least to share some tribal knowledge.

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)

Review comment:
       nit: Should we test 3.11 at all, or is the serialization apparatus basically the same in 3.11 as it is in 3.0?

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message
+    public static final class FwdFrmSerializer implements IVersionedSerializer<InetAddressAndPort>
+    {
+        public static final FwdFrmSerializer fwdFrmSerializer = new FwdFrmSerializer();
+        private FwdFrmSerializer() { }
+
+        public void serialize(InetAddressAndPort endpoint, DataOutputPlus out, int version) throws IOException
+        {
+            byte[] buf = endpoint.addressBytes;
+
+            if (version >= MessagingService.VERSION_40)
+            {
+                out.writeByte(buf.length + 2);
+                out.write(buf);
+                out.writeShort(endpoint.port);
+            }
+            else
+            {
+                out.write(buf);
+            }
+        }
+
+        public long serializedSize(InetAddressAndPort from, int version)
+        {
+            //4.0 includes a port number
+            if (version >= MessagingService.VERSION_40)
+            {
+                if (from.address instanceof Inet4Address)
+                    return 1 + 4 + 2;
+                assert from.address instanceof Inet6Address;
+                return 1 + 16 + 2;
+            }
+            else
+            {
+                if (from.address instanceof Inet4Address)
+                    return 4;
+                assert from.address instanceof Inet6Address;
+                return 16;
+            }
+        }
+
+        @Override
+        public InetAddressAndPort deserialize(DataInputPlus in, int version) throws IOException
+        {
+            if (version >= MessagingService.VERSION_40)
+            {
+                int size = in.readByte() & 0xFF;
+                switch (size)
+                {
+                    //Address and one port
+                    case 6:
+                    case 18:
+                    {
+                        byte[] bytes = new byte[size - 2];
+                        in.readFully(bytes);
+
+                        int port = in.readShort() & 0xFFFF;
+                        return getByAddressOverrideDefaults(InetAddress.getByAddress(bytes), bytes, port);

Review comment:
       nit: Block is duplicated in the original serializer.

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message

Review comment:
       nit: Both this and the comments for `Serializer` above could be in proper JavaDoc format. (Would allow for links and such, etc.)

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message
+    public static final class FwdFrmSerializer implements IVersionedSerializer<InetAddressAndPort>
+    {
+        public static final FwdFrmSerializer fwdFrmSerializer = new FwdFrmSerializer();
+        private FwdFrmSerializer() { }
+
+        public void serialize(InetAddressAndPort endpoint, DataOutputPlus out, int version) throws IOException
+        {
+            byte[] buf = endpoint.addressBytes;
+
+            if (version >= MessagingService.VERSION_40)
+            {
+                out.writeByte(buf.length + 2);
+                out.write(buf);
+                out.writeShort(endpoint.port);
+            }
+            else
+            {
+                out.write(buf);
+            }
+        }
+
+        public long serializedSize(InetAddressAndPort from, int version)
+        {
+            //4.0 includes a port number
+            if (version >= MessagingService.VERSION_40)
+            {
+                if (from.address instanceof Inet4Address)
+                    return 1 + 4 + 2;
+                assert from.address instanceof Inet6Address;
+                return 1 + 16 + 2;
+            }
+            else
+            {
+                if (from.address instanceof Inet4Address)
+                    return 4;
+                assert from.address instanceof Inet6Address;
+                return 16;
+            }
+        }

Review comment:
       @jonmeredith There are certainly chunks of `serialize()` and `serializedSize()` that are duplicated. (i.e. Only their pre-4.0 behavior diverges?) It may be nice to push some of this into a base class w/ abstract `pre40Serialize()` and `pre40SerializedSize()` methods to cut down on surface area until it all goes away if we ever break support for mixed 3.x <-> x.x version clusters.

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -34,6 +34,7 @@
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
 import org.apache.cassandra.net.MessagingService;
+import org.apache.cassandra.net.ParamType;

Review comment:
       nit: unused?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 11:55;githubbot;600","jonmeredith commented on a change in pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#discussion_r672646306



##########
File path: src/java/org/apache/cassandra/net/Message.java
##########
@@ -1151,9 +1151,20 @@ private void serializeParams(Map<ParamType, Object> params, DataOutputPlus out,
                     : in.readInt();
 
                 if (null != type)
-                    params.put(type, type.serializer.deserialize(in, version));
-                else
+                {
+                    // Have to special case deserializer as pre-4.0 needs length to decode correctly
+                    if (version < VERSION_40 && type == ParamType.RESPOND_TO)
+                    {
+                        params.put(type, InetAddressAndPort.FwdFrmSerializer.fwdFrmSerializer.pre40DeserializeWithLength(in, version, length));
+                    }
+                    else
+                    {
+                        params.put(type, type.serializer.deserialize(in, version));
+                    }
+                }
+                else {

Review comment:
       ack

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)

Review comment:
       Serialization looked the same when I checked 3.11.  Not sure it's worth running every release, but I can test it once off.

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -382,4 +385,83 @@ public long serializedSize(InetAddressAndPort from, int version)
             }
         }
     }
+
+    // Serializer for handling FWD_FRM message parameters. Pre-4.0 deserialization is a special
+    // case in the message
+    public static final class FwdFrmSerializer implements IVersionedSerializer<InetAddressAndPort>
+    {
+        public static final FwdFrmSerializer fwdFrmSerializer = new FwdFrmSerializer();
+        private FwdFrmSerializer() { }
+
+        public void serialize(InetAddressAndPort endpoint, DataOutputPlus out, int version) throws IOException
+        {
+            byte[] buf = endpoint.addressBytes;
+
+            if (version >= MessagingService.VERSION_40)
+            {
+                out.writeByte(buf.length + 2);
+                out.write(buf);
+                out.writeShort(endpoint.port);
+            }
+            else
+            {
+                out.write(buf);
+            }
+        }
+
+        public long serializedSize(InetAddressAndPort from, int version)
+        {
+            //4.0 includes a port number
+            if (version >= MessagingService.VERSION_40)
+            {
+                if (from.address instanceof Inet4Address)
+                    return 1 + 4 + 2;
+                assert from.address instanceof Inet6Address;
+                return 1 + 16 + 2;
+            }
+            else
+            {
+                if (from.address instanceof Inet4Address)
+                    return 4;
+                assert from.address instanceof Inet6Address;
+                return 16;
+            }
+        }

Review comment:
       I had the patch that way originally but backed away as each method has to handle pre/post 4.0 messages so to when adding protections to make sure the wrong serializer wasn't called call paths longer/uglier so I went back to the simpler option of having the two full implementations.

##########
File path: src/java/org/apache/cassandra/locator/InetAddressAndPort.java
##########
@@ -34,6 +34,7 @@
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
 import org.apache.cassandra.net.MessagingService;
+import org.apache.cassandra.net.ParamType;

Review comment:
       ack
   

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)

Review comment:
       Confirmed running with `.upgrade(Versions.Major.v3X, Versions.Major.v4)` works. 
   
   Before this change there would be value in testing `nodesPerDC=2;` and a larger value to exercise different paths through `sameMessageId`, however the updated implementation doesn't special case single node forwarding.
   

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeMessageForwardTest.java
##########
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.upgrade;
+
+import org.apache.cassandra.distributed.UpgradeableCluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.shared.Shared;
+import org.apache.cassandra.distributed.shared.Versions;
+import org.awaitility.Awaitility;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Arrays;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import java.util.stream.IntStream;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.*;
+
+@Shared
+public class MixedModeMessageForwardTest extends UpgradeTestBase
+{
+    private static final Logger logger = LoggerFactory.getLogger(MixedModeMessageForwardTest.class);
+    private static int nextKey = 1;
+    private static String TABLE = ""tbl"";
+    private static String INSERT_QUERY = String.format(""INSERT INTO %s.%s(pk) VALUES (?)"", KEYSPACE, TABLE);
+    private static String CHECK_QUERY = String.format(""SELECT pk FROM %s.%s WHERE pk = ?"", KEYSPACE, TABLE);
+
+    private boolean checkClusterUp(UpgradeableCluster cluster, int coordId)
+    {
+        NodeToolResult result;
+        result = cluster.get(coordId).nodetoolResult(""ring"");
+
+        // Must have an Up line for each node
+        long upCount = Arrays.stream(result.getStdout().split(""\\r?\\n"")).filter(line -> line.contains("" Up "")).count();
+        if (upCount < cluster.size())
+        {
+            logger.info(""Only {}/{} are up."", upCount, cluster.size());
+            return false;
+        }
+
+        return true;
+    }
+
+    private void writeReadTest(UpgradeableCluster cluster)
+    {
+        // Coordinate a write from each node and then check present on all replicas
+        int readKey = nextKey;
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            final int checkNodeId = coordId;
+            Awaitility.await(""Cluster Up"").atMost(1, TimeUnit.MINUTES).until(() -> checkClusterUp(cluster, checkNodeId));
+
+            logger.info(""Coordinating CL.ALL Insert from node{} "", coordId);
+            cluster.get(coordId).coordinator().execute(INSERT_QUERY, ConsistencyLevel.ALL, nextKey++);
+        }
+
+        for (int coordId = 1; coordId <= cluster.size(); coordId++)
+        {
+            for (int nodeId = 1; nodeId <= cluster.size(); nodeId++) {
+                Object[][] results = cluster.get(nodeId).executeInternal(CHECK_QUERY, readKey);
+                assertRows(results, row(readKey));
+            }
+            readKey++;
+        }
+    }
+
+    /* Verify that messages sent with sendToHintedReplicas to non-local DCs
+     * are forwarded on to the hosts there.
+     *
+     * 1) creates a mixed cluster with multiple datacenters and a keyspace
+     *    configured to write to all replicas in the datacenter
+     * 2) check the original single-version cluster by issuing an INSERT
+     *    mutation from a coordinator on each node, then check that value
+     *    has locally been written to each of the nodes.
+     * 3) Upgrade nodes one at a time, rechecking that all writes are forwarded.
+     */
+    @Test
+    public void checkWritesForwardedToOtherDcTest() throws Throwable
+    {
+        int numDCs = 2;
+        int nodesPerDc = 3;
+        String ntsArgs = IntStream.range(1, numDCs + 1)
+                                  .mapToObj(dc -> String.format(""'datacenter%d' : %d"", dc, nodesPerDc))
+                                  .collect(Collectors.joining("",""));
+
+        new TestCase()
+        .withConfig(c -> c.with(Feature.GOSSIP, Feature.NETWORK).set(""request_timeout_in_ms"", 30000))
+        .withBuilder(b -> b.withRacks(numDCs, 1, nodesPerDc))
+        .nodes(numDCs * nodesPerDc)
+        .upgrade(Versions.Major.v30, Versions.Major.v4)
+        .setup(cluster -> {
+            cluster.schemaChange(""ALTER KEYSPACE "" + KEYSPACE +
+                "" WITH replication = {'class': 'NetworkTopologyStrategy', "" + ntsArgs + "" };"");
+
+            cluster.schemaChange(""CREATE TABLE ""+ KEYSPACE + ""."" + TABLE + "" (pk int, PRIMARY KEY(pk))"");
+
+            logger.info(""Testing after setup, all nodes running {}"", cluster.get(1).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .runAfterNodeUpgrade((UpgradeableCluster cluster, int nodeId) -> {
+            // Should be able to coordinate a write to any node and have a copy appear locally on all others
+            logger.info(""Testing after upgrading node{} to {}"", nodeId, cluster.get(nodeId).getReleaseVersionString());
+            writeReadTest(cluster);
+        })
+        .run();

Review comment:
       I took a look at unifying them and the sticking point is I don't really want to re-implement NTS to work out where things should be written.  `MixedModeMessageForwardTest` sets the RF to make sure all nodes in the DC are written to so it's easier to check.
   
   I was able to remove node UP check, I think I added it when I didn't understand the messageId issue.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 12:20;githubbot;600","maedhroz opened a new pull request #1112:
URL: https://github.com/apache/cassandra/pull/1112


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 21:20;githubbot;600","maedhroz commented on pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111#issuecomment-883727250


   see https://github.com/apache/cassandra/pull/1112/files


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 21:42;githubbot;600","maedhroz opened a new pull request #1113:
URL: https://github.com/apache/cassandra/pull/1113


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 21:48;githubbot;600","maedhroz opened a new pull request #1114:
URL: https://github.com/apache/cassandra/pull/1114


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 21:54;githubbot;600","maedhroz commented on pull request #1112:
URL: https://github.com/apache/cassandra/pull/1112#issuecomment-884356563


   Committed as https://github.com/apache/cassandra/commit/4d4e1e88d095e10d53b59bf004a59709c3cee186


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Jul/21 17:18;githubbot;600","maedhroz closed pull request #1112:
URL: https://github.com/apache/cassandra/pull/1112


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Jul/21 17:18;githubbot;600","maedhroz commented on pull request #1113:
URL: https://github.com/apache/cassandra/pull/1113#issuecomment-884356929


   Committed as https://github.com/apache/cassandra/commit/cdf68e39ba9ab399936d3359bc0d24b4f38dbae8


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Jul/21 17:19;githubbot;600","maedhroz closed pull request #1113:
URL: https://github.com/apache/cassandra/pull/1113


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Jul/21 17:19;githubbot;600","maedhroz commented on pull request #1114:
URL: https://github.com/apache/cassandra/pull/1114#issuecomment-884357254


   Committed as https://github.com/apache/cassandra/commit/c1f235f71d013318b86bddee3121beb4923ae0f9


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Jul/21 17:19;githubbot;600","maedhroz closed pull request #1114:
URL: https://github.com/apache/cassandra/pull/1114


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Jul/21 17:19;githubbot;600","asfgit closed pull request #1111:
URL: https://github.com/apache/cassandra/pull/1111


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Aug/21 13:32;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,0,17400,,,0,17400,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16799,,,,,,,,,,,0.0,jmeredithco,,,,,,,,,,,,,Degradation -> Other Exception,,,,,,,,Normal,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jul 21 17:21:45 UTC 2021,,,,,,,All,,,,"0|z0t1j4:",9223372036854775807,,,,benedict,brandonwilliams,maedhroz,,Normal,,NA,,https://github.com/apache/cassandra/commit/4d4e1e88d095e10d53b59bf004a59709c3cee186,,,,,,,,,"[Branch|https://github.com/jonmeredith/cassandra/tree/test-fwd-frm]
[Pull Request|https://github.com/apache/cassandra/pull/1111]
[CircleCI|https://app.circleci.com/pipelines/github/jonmeredith/cassandra?branch=C16808]

The branch has three commits, one to demonstrate the issue and two to fix the discovered issues.",,,,,"18/Jul/21 16:50;mck;CI [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/949/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/949/]
(jvm upgrade dtests known broken on the [cassandra-4.0.0|https://ci-cassandra.apache.org/job/Cassandra-4.0.0/52/#showFailuresLink] branch);;;","19/Jul/21 21:24;maedhroz;I've left some nits and structural thoughts in the PR, but the fixes and new test look good.

+1;;;","20/Jul/21 20:06;brandon.williams;+1;;;","20/Jul/21 21:58;maedhroz;Here are the pre-commit branches and in-progress Circle CI runs...

||[4.0.0|https://github.com/apache/cassandra/pull/1112]|[Circle CI|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16808-4.0.0]||
||[4.0|https://github.com/apache/cassandra/pull/1113]|[Circle CI|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16808-4.0]||
||[trunk|https://github.com/apache/cassandra/pull/1114]|[Circle CI|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16808-trunk]|;;;","21/Jul/21 03:44;maedhroz;The 4.0.0 test run is perfect.

[~jmeredithco] 4.0 and trunk aren't quite there. We're seeing CASSANDRA-16803 and some other assorted timeout and heap space problems, but those are almost certainly unrelated. The troubling bit is what looks like {{MixedModeMessageForwardTest.checkWritesForwardedToOtherDcTest}}, which is new, [failing|https://app.circleci.com/pipelines/github/maedhroz/cassandra/295/workflows/1e5bff9f-36db-46c8-bdf2-419f830a4b3f/jobs/1792/tests#failed-test-1].

UPDATE: This is a 3.0 -> 3.11 problem, so I'm slightly refactoring the 4.0 and trunk patches to mimic the single upgrade path test in 4.0.0, which is all we should need...;;;","21/Jul/21 07:54;benedict;+1

It's a shame we didn't actually maintain the serialisation behaviour with the introduction of ports as we had previously in 3.0, but what's a byte here or there amongst friends, I suppose.;;;","21/Jul/21 17:21;maedhroz;Committed.

4.0.0: https://github.com/apache/cassandra/commit/4d4e1e88d095e10d53b59bf004a59709c3cee186

4.0: https://github.com/apache/cassandra/commit/cdf68e39ba9ab399936d3359bc0d24b4f38dbae8

trunk: https://github.com/apache/cassandra/commit/c1f235f71d013318b86bddee3121beb4923ae0f9;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Weak visibility guarantees of Accumulator lead to failed assertions during digest comparison,CASSANDRA-16807,13390143,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,maedhroz,maedhroz,maedhroz,16/Jul/21 18:47,27/May/22 19:25,13/Jul/23 08:40,21/Jul/21 17:59,4.0,4.0.0,4.1,4.1-alpha1,,,,Consistency/Coordination,,,,0,,,"This problem could manifest on all versions, beginning on at least 3.0, but I’ll focus on the way it manifests in 4.0 here.

In what now seems like a wise move, CASSANDRA-16097 added an assertion to {{DigestResolver#responseMatch()}} that ensures the responses snapshot has at least one visible elements to compare (although of course only one element trivially cannot generate a mismatch and short-circuits immediately). However, at the point {{ReadCallback#onResponse()}} signals the waiting resolver, there is no guarantee that the size of the generated snapshot of the responses {{Accumulator}} is non-zero, or perhaps more worryingly, at least equal to the number of blocked-for responses. This seems to be a consequence of the documented weak visibility guarantees on {{Accumulator#add()}}. In short, if there are concurrent invocations of add(), is it not guaranteed that there is any visible size change after any one of them return, but only after all complete.

The particular exception looks something like this:

{noformat}
java.lang.AssertionError: Attempted response match comparison while no responses have been received.
	at org.apache.cassandra.service.reads.DigestResolver.responsesMatch(DigestResolver.java:110)
	at org.apache.cassandra.service.reads.AbstractReadExecutor.awaitResponses(AbstractReadExecutor.java:393)
	at org.apache.cassandra.service.StorageProxy.fetchRows(StorageProxy.java:2150)
	at org.apache.cassandra.service.StorageProxy.readRegular(StorageProxy.java:1979)
	at org.apache.cassandra.service.StorageProxy.read(StorageProxy.java:1882)
	at org.apache.cassandra.db.SinglePartitionReadCommand$Group.execute(SinglePartitionReadCommand.java:1121)
	at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:296)
	at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:248)
	at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:90)
{noformat}

It’s possible to reproduce this on simple single-partition reads without any short-read protection or replica filtering protection. I’ve also been able to reproduce this synthetically with [a unit test|https://github.com/apache/cassandra/pull/1110] on {{ReadCallback}}.

It seems like the most straightforward way to fix this would be to avoid signaling in {{ReadCallback#onResponse()}} until the visible size of the accumulator is at least the number of received responses. In most cases, this is trivially true, and our signaling behavior won’t change at all. In the very rare case that there are two (or more) concurrent calls to {{onResponse()}}, the second (or last) will signal, and having one more response than we strictly need should have no negative side effects. (We don’t seem to make any strict assertions about having exactly the number of required responses, only that we have enough.)",,adelapena,benedict,brandon.williams,e.dimitrova,jeromatron,maedhroz,mck,,,,,,,,,"maedhroz opened a new pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110


   an isolated reproduction of the assertion failure that occurs when the Accumulator size hasn't become visible by the time we check for digest mismatches


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Jul/21 18:59;githubbot;600","maedhroz commented on a change in pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#discussion_r671500382



##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +79,69 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException
+    {
+        SinglePartitionReadCommand command = SinglePartitionReadCommand.fullPartitionRead(cfm, nowInSec, dk);
+        EndpointsForToken targetReplicas = EndpointsForToken.of(dk.getToken(), full(EP1), full(EP2));
+        PartitionUpdate response = update(row(1000, 4, 4), row(1000, 5, 5)).build();
+        ReplicaPlan.SharedForTokenRead plan = plan(ConsistencyLevel.ONE, targetReplicas);
+
+        ExecutorService pool = Executors.newFixedThreadPool(4);
+
+        try
+        {
+            for (int i = 0; i < 10_000_000; i++)

Review comment:
       This test can obviously run for quite a while, but if it doesn't run long enough to catch the problem, it doesn't add much value. I'm open to throwing an `@Ignore` on it for now, leaving it to a suite of tests we don't run on every commit, or any other ideas...




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Jul/21 20:11;githubbot;600","adelapena commented on a change in pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#discussion_r671688310



##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +80,70 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException

Review comment:
       Nit: doesn't need `throws InterruptedException`




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Jul/21 11:57;githubbot;600","adelapena commented on a change in pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#discussion_r671688480



##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +80,70 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException

Review comment:
       Nit: We could mention the ticket number in a comment, maybe in the JavaDoc for the test.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Jul/21 11:59;githubbot;600","adelapena commented on a change in pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#discussion_r671689441



##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +80,70 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException
+    {
+        SinglePartitionReadCommand command = SinglePartitionReadCommand.fullPartitionRead(cfm, nowInSec, dk);
+        EndpointsForToken targetReplicas = EndpointsForToken.of(dk.getToken(), full(EP1), full(EP2));
+        PartitionUpdate response = update(row(1000, 4, 4), row(1000, 5, 5)).build();
+        ReplicaPlan.SharedForTokenRead plan = plan(ConsistencyLevel.ONE, targetReplicas);
+
+        ExecutorService pool = Executors.newFixedThreadPool(4);

Review comment:
       Nit: wouldn't it be enough with 2 threads?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Jul/21 12:09;githubbot;600","adelapena commented on a change in pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#discussion_r672205210



##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +80,70 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException
+    {
+        SinglePartitionReadCommand command = SinglePartitionReadCommand.fullPartitionRead(cfm, nowInSec, dk);
+        EndpointsForToken targetReplicas = EndpointsForToken.of(dk.getToken(), full(EP1), full(EP2));
+        PartitionUpdate response = update(row(1000, 4, 4), row(1000, 5, 5)).build();
+        ReplicaPlan.SharedForTokenRead plan = plan(ConsistencyLevel.ONE, targetReplicas);
+
+        ExecutorService pool = Executors.newFixedThreadPool(4);
+        long endTime = System.nanoTime() + TimeUnit.MINUTES.toNanos(2);
+
+        try
+        {
+            while (System.nanoTime() < endTime)
+            {
+                final long startNanos = System.nanoTime();
+                final DigestResolver<EndpointsForToken, ReplicaPlan.ForTokenRead> resolver = new DigestResolver<>(command, plan, startNanos);
+                final ReadCallback<EndpointsForToken, ReplicaPlan.ForTokenRead> callback = new ReadCallback<>(resolver, command, plan, startNanos);
+                
+                final CountDownLatch startlatch = new CountDownLatch(2);
+
+                pool.execute(() ->
+                             {
+                                 startlatch.countDown();
+
+                                 try
+                                 {
+                                     startlatch.await();
+                                 }
+                                 catch (InterruptedException e)
+                                 {
+                                     Thread.currentThread().interrupt();
+                                 }
+
+                                 callback.onResponse(response(command, EP1, iter(response), true));
+                             });
+
+                pool.execute(() ->
+                             {
+                                 startlatch.countDown();
+
+                                 try
+                                 {
+                                     startlatch.await();
+                                 }
+                                 catch (InterruptedException e)
+                                 {
+                                     Thread.currentThread().interrupt();
+                                 }
+
+                                 callback.onResponse(response(command, EP2, iter(response), true));
+                             });
+
+                callback.awaitResults();
+                Assert.assertTrue(resolver.isDataPresent());
+                resolver.responsesMatch();

Review comment:
       Perhaps we can put this inside an `assertTrue`, just in case.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 11:11;githubbot;600","adelapena commented on a change in pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#discussion_r672239464



##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +79,69 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException
+    {
+        SinglePartitionReadCommand command = SinglePartitionReadCommand.fullPartitionRead(cfm, nowInSec, dk);
+        EndpointsForToken targetReplicas = EndpointsForToken.of(dk.getToken(), full(EP1), full(EP2));
+        PartitionUpdate response = update(row(1000, 4, 4), row(1000, 5, 5)).build();
+        ReplicaPlan.SharedForTokenRead plan = plan(ConsistencyLevel.ONE, targetReplicas);
+
+        ExecutorService pool = Executors.newFixedThreadPool(4);
+
+        try
+        {
+            for (int i = 0; i < 10_000_000; i++)

Review comment:
       I think that the time bound of 1/2 of the JUnit timeout is a nice solution. If we find it problematic in the future we can always move it to long tests.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 12:08;githubbot;600","maedhroz commented on a change in pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#discussion_r672415239



##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +80,70 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException
+    {
+        SinglePartitionReadCommand command = SinglePartitionReadCommand.fullPartitionRead(cfm, nowInSec, dk);
+        EndpointsForToken targetReplicas = EndpointsForToken.of(dk.getToken(), full(EP1), full(EP2));
+        PartitionUpdate response = update(row(1000, 4, 4), row(1000, 5, 5)).build();
+        ReplicaPlan.SharedForTokenRead plan = plan(ConsistencyLevel.ONE, targetReplicas);
+
+        ExecutorService pool = Executors.newFixedThreadPool(4);

Review comment:
       Yeah, I think this might just be an artifact from before I added the start latch earlier.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jul/21 15:42;githubbot;600","adelapena commented on a change in pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#discussion_r672205210



##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +80,70 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException
+    {
+        SinglePartitionReadCommand command = SinglePartitionReadCommand.fullPartitionRead(cfm, nowInSec, dk);
+        EndpointsForToken targetReplicas = EndpointsForToken.of(dk.getToken(), full(EP1), full(EP2));
+        PartitionUpdate response = update(row(1000, 4, 4), row(1000, 5, 5)).build();
+        ReplicaPlan.SharedForTokenRead plan = plan(ConsistencyLevel.ONE, targetReplicas);
+
+        ExecutorService pool = Executors.newFixedThreadPool(4);
+        long endTime = System.nanoTime() + TimeUnit.MINUTES.toNanos(2);
+
+        try
+        {
+            while (System.nanoTime() < endTime)
+            {
+                final long startNanos = System.nanoTime();
+                final DigestResolver<EndpointsForToken, ReplicaPlan.ForTokenRead> resolver = new DigestResolver<>(command, plan, startNanos);
+                final ReadCallback<EndpointsForToken, ReplicaPlan.ForTokenRead> callback = new ReadCallback<>(resolver, command, plan, startNanos);
+                
+                final CountDownLatch startlatch = new CountDownLatch(2);
+
+                pool.execute(() ->
+                             {
+                                 startlatch.countDown();
+
+                                 try
+                                 {
+                                     startlatch.await();
+                                 }
+                                 catch (InterruptedException e)
+                                 {
+                                     Thread.currentThread().interrupt();
+                                 }
+
+                                 callback.onResponse(response(command, EP1, iter(response), true));
+                             });
+
+                pool.execute(() ->
+                             {
+                                 startlatch.countDown();
+
+                                 try
+                                 {
+                                     startlatch.await();
+                                 }
+                                 catch (InterruptedException e)
+                                 {
+                                     Thread.currentThread().interrupt();
+                                 }
+
+                                 callback.onResponse(response(command, EP2, iter(response), true));
+                             });
+
+                callback.awaitResults();
+                Assert.assertTrue(resolver.isDataPresent());
+                resolver.responsesMatch();

Review comment:
       Perhaps we can put this inside an `assertTrue`, just in case.

##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +79,69 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException
+    {
+        SinglePartitionReadCommand command = SinglePartitionReadCommand.fullPartitionRead(cfm, nowInSec, dk);
+        EndpointsForToken targetReplicas = EndpointsForToken.of(dk.getToken(), full(EP1), full(EP2));
+        PartitionUpdate response = update(row(1000, 4, 4), row(1000, 5, 5)).build();
+        ReplicaPlan.SharedForTokenRead plan = plan(ConsistencyLevel.ONE, targetReplicas);
+
+        ExecutorService pool = Executors.newFixedThreadPool(4);
+
+        try
+        {
+            for (int i = 0; i < 10_000_000; i++)

Review comment:
       I think that the time bound of 1/2 of the JUnit timeout is a nice solution. If we find it problematic in the future we can always move it to long tests.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 09:29;githubbot;600","maedhroz commented on a change in pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#discussion_r672415239



##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +80,70 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException
+    {
+        SinglePartitionReadCommand command = SinglePartitionReadCommand.fullPartitionRead(cfm, nowInSec, dk);
+        EndpointsForToken targetReplicas = EndpointsForToken.of(dk.getToken(), full(EP1), full(EP2));
+        PartitionUpdate response = update(row(1000, 4, 4), row(1000, 5, 5)).build();
+        ReplicaPlan.SharedForTokenRead plan = plan(ConsistencyLevel.ONE, targetReplicas);
+
+        ExecutorService pool = Executors.newFixedThreadPool(4);

Review comment:
       Yeah, I think this might just be an artifact from before I added the start latch earlier.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 09:57;githubbot;600","adelapena commented on a change in pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#discussion_r672239464



##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +79,69 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException
+    {
+        SinglePartitionReadCommand command = SinglePartitionReadCommand.fullPartitionRead(cfm, nowInSec, dk);
+        EndpointsForToken targetReplicas = EndpointsForToken.of(dk.getToken(), full(EP1), full(EP2));
+        PartitionUpdate response = update(row(1000, 4, 4), row(1000, 5, 5)).build();
+        ReplicaPlan.SharedForTokenRead plan = plan(ConsistencyLevel.ONE, targetReplicas);
+
+        ExecutorService pool = Executors.newFixedThreadPool(4);
+
+        try
+        {
+            for (int i = 0; i < 10_000_000; i++)

Review comment:
       I think that the time bound of 1/2 of the JUnit timeout is a nice solution. If we find it problematic in the future we can always move it to long tests.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 11:42;githubbot;600","maedhroz commented on a change in pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#discussion_r672415239



##########
File path: test/unit/org/apache/cassandra/service/reads/DigestResolverTest.java
##########
@@ -78,6 +80,70 @@ public void noRepairNeeded()
         assertPartitionsEqual(filter(iter(response)), resolver.getData());
     }
 
+    @Test
+    public void multiThreadedNoRepairNeededReadCallback() throws InterruptedException
+    {
+        SinglePartitionReadCommand command = SinglePartitionReadCommand.fullPartitionRead(cfm, nowInSec, dk);
+        EndpointsForToken targetReplicas = EndpointsForToken.of(dk.getToken(), full(EP1), full(EP2));
+        PartitionUpdate response = update(row(1000, 4, 4), row(1000, 5, 5)).build();
+        ReplicaPlan.SharedForTokenRead plan = plan(ConsistencyLevel.ONE, targetReplicas);
+
+        ExecutorService pool = Executors.newFixedThreadPool(4);

Review comment:
       Yeah, I think this might just be an artifact from before I added the start latch earlier.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 12:08;githubbot;600","maedhroz commented on pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#issuecomment-883701665


   Latest Circle runs are clean: https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16807-trunk


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jul/21 20:54;githubbot;600","maedhroz closed pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Jul/21 18:00;githubbot;600","maedhroz commented on pull request #1110:
URL: https://github.com/apache/cassandra/pull/1110#issuecomment-884381543


   see https://github.com/apache/cassandra/commit/29cc615fafe5f246dbc6668bcf85bfe4467152ee


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Jul/21 18:00;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,9000,,,0,9000,,,,,,,,,,,,,,,,,,,CASSANDRA-16883,,,,,,,,,,,,,,,,,,,0.0,maedhroz,,,,,,,,,,,,,Correctness -> Consistency,,,,,,,,Normal,Fuzz Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jul 21 17:59:55 UTC 2021,,,,,,,All,,,,"0|z0t16o:",9223372036854775807,,,,adelapena,benedict,,,Critical,,3.0.0,,https://github.com/apache/cassandra/commit/93496e826e7382adf52a99d4df38e73a43f892de,,,,,,,,,"a new time-bound multi-threaded unit test that ""fuzzes"" the problematic behavior described in this issue",,,,,"16/Jul/21 18:50;maedhroz;There is perhaps a question of whether to fix this in 3.x, but the exact nature of the fix may be a little different, given the refactoring that happened in 4.0. Perhaps a bigger question than that is whether this warrants inclusion in 4.0.0, but given it probably isn't entirely a regression from 3.x (i.e. the assertion is new in 4.0.0 but not the underlying issue), I could see a case for it not blocking 4.0 GA.;;;","16/Jul/21 20:01;maedhroz;Confirmed that the new test in {{DigestResolverTest}} fails on Circle: https://app.circleci.com/pipelines/github/maedhroz/cassandra/289/workflows/0baeade3-66eb-4772-bad3-1054efcef394/jobs/1718/parallel-runs/3?filterBy=FAILED;;;","16/Jul/21 20:49;maedhroz;I'm pushing up a trunk-based version of this fix to get review started, but a 4.0.x patch would be identical.

[trunk|https://github.com/apache/cassandra/pull/1110]
[j8|https://app.circleci.com/pipelines/github/maedhroz/cassandra/290/workflows/d0ce3435-7247-49fc-a61e-8ca29db7d64e]
[j11|https://app.circleci.com/pipelines/github/maedhroz/cassandra/290/workflows/71e4bfbc-96f9-47d4-8de8-95ae694762ff]

Note that in this run of the tests, I didn't have a time-bound on the new test, so the fact that they time out is actually a good thing. (i.e. They don't hit the assertion.);;;","16/Jul/21 20:51;maedhroz;If we come to consensus on the correctness of the patch, the only decision left is whether this can slip to 4.0.1. At the end of the day, the behavior is only a regression from 3.x in the sense that it will fail a query 3.x should fail but doesn't. 4.0.1 seems reasonable, when framed that way.;;;","17/Jul/21 11:46;adelapena;CI rounds for 4.0 and trunk with the time-bound and MIDRES, including 100 runs of the new test:
||branch||CI||
|[4.0|https://github.com/adelapena/cassandra/tree/16807-4.0]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/670/workflows/d7194549-4d0a-4755-b29c-a388dba36ba6] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/670/workflows/5bfa7be6-e8dd-44fc-bda3-2e29eec34285]|
|[trunk|https://github.com/adelapena/cassandra/tree/16807-trunk]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/669/workflows/6dcf2f39-ee29-45c4-91ba-9ad7ba76edf3] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/669/workflows/3abcb59f-d8a3-4746-87e1-94e8e0d15438]|;;;","19/Jul/21 12:21;adelapena;The patch looks good to me, I have left some minor suggestions on the PR.;;;","19/Jul/21 16:14;maedhroz;[~adelapena] Addressed your nits. Thanks for the review!;;;","19/Jul/21 21:57;maedhroz;My plan at this point is to prepare the 4.0 and 4.0.0 versions of the patch as soon as I get a second +1;;;","20/Jul/21 08:04;benedict;So, the only thing that has me worried is the code in {{waitingFor}}, which implies we might receive responses we don't require for our consistency level. I _think_ this is dead code and should be removed, and we should assert that we have only contacted relevant hosts. If, however, it isn't dead code then this fix would be insufficient, as we could have inserted these first, and may only have those visible. Only writes should contact replicas not involved in consistency, however, and I did perform a cursory check this is the case here.

So, I'd suggest:

1. Verify we do not send queries to replicas we don't want responses from
2. Do not pre-process responses we aren't {{waitingFor}}; or, assert we are {{waitingFor}} the commands 
3. Only test that {{resolver.getMessages().size() >= blockFor}}
4. Maybe remove {{received}} altogether, in favour of {{resolver.getMessages().size()}};;;","20/Jul/21 17:17;maedhroz;I think [~benedict] is right. More specifically, since CASSANDRA-14735, even speculating to non-local-DC nodes isn't possible for {{LOCAL_X}} reads. {{ReplicaPlans.forRead()}} and {{forRangeRead()}} all hit {{candidatesForRead()}}, which filters out non-local nodes for local CLs.

[~adelapena] I've [updated the PR|https://github.com/apache/cassandra/pull/1110/files?file-filters%5B%5D=.java#diff-5297967879d7d61d7874555b46b5c853138384f42724af2427271d613725eb2aL139] and kicked off new [test runs|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16807-trunk]. Let me know what you think...;;;","20/Jul/21 20:07;adelapena;Removing {{received}} and {{waitingFor}} make sense to me if we don't receive responses from unneeded replicas. I have left some very trivial suggestions [here|https://github.com/adelapena/cassandra/commit/97ca3a260d2e99fe030a743d5be8b4cd302ba8a9], feel free to ignore them if you don't agree.

Also, I was wondering whether it would make sense to, instead of just removing {{waitingFor}}, replacing it by an assertion verifying that we certainly don't receive those messages, for example [this way|https://github.com/adelapena/cassandra/commit/a573103522421034fa87030b68422c0d4f775467]. ;;;","20/Jul/21 22:39;maedhroz;Thanks [~adelapena]. I've applied all but one of your suggestions. Just waiting for a final test run: https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16807-trunk;;;","21/Jul/21 04:26;maedhroz;Alright, the trunk patch is looking good, and our only test failure is {{HostReplacementTest#replaceAliveHost}}, which appears to be failing on other trunk-based branches as we speak.;;;","21/Jul/21 11:01;adelapena;Looks good to me, +1. Here are CI runs for 4.0.0 and 4.0, where the patch applies cleanly:

||branch||CI||
|[4.0.0|https://github.com/adelapena/cassandra/tree/16807-4.0.0-review]|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/682/workflows/cfc7cda9-5818-4d84-a742-610e309bc174] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/682/workflows/90cbedfc-9c5e-478b-8a15-125707e05729]|
|[4.0|https://github.com/adelapena/cassandra/tree/16807-4.0-review]    |[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/681/workflows/0808b094-b872-462a-8a32-f6bed7af5524] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/681/workflows/f0b22050-e7af-49cb-9128-a6bb1ee2f81d]|;;;","21/Jul/21 17:23;benedict;+1;;;","21/Jul/21 17:59;maedhroz;Committed.

4.0.0: https://github.com/apache/cassandra/commit/93496e826e7382adf52a99d4df38e73a43f892de

4.0: https://github.com/apache/cassandra/commit/b91dcce865aae57077c4584351da6fc744e50705

trunk: https://github.com/apache/cassandra/commit/29cc615fafe5f246dbc6668bcf85bfe4467152ee;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE when running in-jvm upgrade dtest in CircleCI,CASSANDRA-16805,13389930,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,yifanc,yifanc,yifanc,16/Jul/21 00:11,16/Mar/22 16:25,13/Jul/23 08:40,19/Jul/21 21:32,4.0,4.0-rc2,,,,,,CI,,,,0,,,"CASSANDRA-16649 changed the upgrade dtest to test all upgrade paths. When running from trunk, the dtest jar of the lower version should present. 
 
CircleCI config is not updated to build the cassandra-4.0 dtest jar, so that most of the upgrade dtest fail. Add the 4.0 version to the dtest jar build task should fix. ",,brandon.williams,e.dimitrova,mck,yifanc,,,,,,,,,,,,"yifan-c opened a new pull request #1109:
URL: https://github.com/apache/cassandra/pull/1109


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Jul/21 17:53;githubbot;600","smiklosovic closed pull request #1109:
URL: https://github.com/apache/cassandra/pull/1109


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:25;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,CASSANDRA-16649,,,,,,,,,,,,,,,,,,,,,,,,,0.0,yifanc,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Jul 19 21:32:32 UTC 2021,,,,,,,All,,,,"0|z0szvc:",9223372036854775807,,,,brandon.williams,e.dimitrova,mck,,Low,,4.0-rc2,,https://github.com/apache/cassandra/commit/fd69375af0d31dccf4e14404ac58c9ced0f64dd9,,,,,,,,,circle ci,,,,,"16/Jul/21 17:54;yifanc;Updated the Circle CI config. [https://github.com/apache/cassandra/pull/1109]

Circle CI (jvm upgrade dtest task): https://app.circleci.com/pipelines/github/yifan-c/cassandra/259/workflows/b94928ff-e750-44f6-a58b-df5df3dfcfb9;;;","16/Jul/21 17:57;brandon.williams;+1;;;","16/Jul/21 20:19;yifanc;The jvm upgrade dtest in CircleCI no longer throws NPEs.

My plan is to commit into cassandra-4.0 and merge up.

The patch is not necessary for the lower branches. Thoughts?;;;","16/Jul/21 20:25;brandon.williams;I think your plan is fine.  I don't think this would make sense in lower branches, only add cruft to the build process.;;;","17/Jul/21 09:29;mck;+1

This matches https://github.com/apache/cassandra-builds/blob/trunk/build-scripts/cassandra-test.sh#L32-L47
(though ci-cassandra.a.o does the `cassandra-4.0..0`, which will need to be removed soon);;;","19/Jul/21 20:36;e.dimitrova;+1, thanks Yifan! ;;;","19/Jul/21 21:32;yifanc;Committed [fd69375|https://github.com/apache/cassandra/commit/fd69375af0d31dccf4e14404ac58c9ced0f64dd9] into cassandra-4.0 and merged up into trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"jvm-dtest-upgrade failing MixedModeReadTest.mixedModeReadColumnSubsetDigestCheck, ClassNotFoundException: com.vdurmont.semver4j.Semver",CASSANDRA-16803,13389618,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mck,mck,mck,14/Jul/21 12:25,27/May/22 19:25,13/Jul/23 08:40,10/Sep/21 22:44,3.0.26,3.11.12,4.0.2,4.1,4.1-alpha1,,,Test/dtest/java,,,,0,,,"Caused by CASSANDRA-16649

Reproducible locally. Oddly enough can be reproduced on cassandra-4.0 branch as well, though CI is not failing.

fyi [~ifesdjeen]",,e.dimitrova,ifesdjeen,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16649,,CASSANDRA-16907,,,,,,,,,,,,,,,,,,,,,,,0.0,mck,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Sep 10 22:44:37 UTC 2021,,,,,,,All,,,,"0|z0sxy0:",9223372036854775807,,,,ifesdjeen,,,,Normal,,2.2.20,,https://github.com/apache/cassandra-in-jvm-dtest-api/commit/e780640c5b5cd51f9a83539019302577671fd1ce https://github.com/apache/cassandra/commit/b6f0864982f335605e50e68aaf64374d34ec9024,,,,,,,,,CI,,,,,"14/Jul/21 12:27;mck;I'm not convinced the {{ClassNotFoundException: com.vdurmont.semver4j.Semver}} is the underlying cause here.;;;","16/Jul/21 12:13;mck;They are flakies…;;;","21/Jul/21 17:53;brandon.williams;This is failing under 3.11 also: https://app.circleci.com/pipelines/github/adelapena/cassandra/688/workflows/38ee8ece-9a72-49a0-8874-68060cc8d03e/jobs/7024;;;","21/Aug/21 20:26;mck;Lambdas in the test classes hold reference to the surrounding class, and this was failing the test. Because of this, the test class itself is getting loaded into the different cluster specific classloaders, and via UpgradeBaseTest the SemVer4j classes couldn't be loaded. Trying to work around this, e.g. by changing the lambda to a static class, just changed the fault to the static class not being able to be loaded in the cluster's classloader.

Patch: [cassandra-in-jvm-dtest-api/thelastpickle:mck/16803|https://github.com/apache/cassandra-in-jvm-dtest-api/compare/trunk...thelastpickle:mck/16803].

This patch works by adding SemVer4j to the default shared packages list, though this means that the test classes are still pulled through each cluster's classloader. A 0.0.9 release will be required after the patch is merged.

in-tree patches and CI:
- [trunk|https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/16803/trunk] [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/744/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/744/]
- 4.0 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/746/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/746/]
- 3.11 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/747/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/747/]
- 3.0 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/748/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/748/]
;;;","02/Sep/21 04:53;ifesdjeen;+1, well spotted! ;;;","02/Sep/21 07:51;mck;Committed [e780640c5b5cd51f9a83539019302577671fd1ce|https://github.com/apache/cassandra-in-jvm-dtest-api/commit/e780640c5b5cd51f9a83539019302577671fd1ce].

I'm starting on next steps, to stage and vote on a 0.0.9. After that then 2.0, 3.11, 4.0, trunk needs to use it.;;;","02/Sep/21 11:21;mck;Vote started: https://lists.apache.org/thread.html/r63d848432a34e30bb0b5c5b242b1085031a81f3bc5d0f4c119da87e3%40%3Cdev.cassandra.apache.org%3E ;;;","10/Sep/21 04:37;mck;Vote passed:
https://lists.apache.org/thread.html/rd37c6b37f196ca080c2647e3b4538ed25ad9ced0980dfe9c9593438b%40%3Cdev.cassandra.apache.org%3E;;;","10/Sep/21 22:44;mck;Committed in-tree as [b6f0864982f335605e50e68aaf64374d34ec9024|https://github.com/apache/cassandra/commit/b6f0864982f335605e50e68aaf64374d34ec9024].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PasswordObfuscator should not assume PASSWORD is the last item in the WITH clause,CASSANDRA-16801,13389459,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,maedhroz,maedhroz,13/Jul/21 19:34,27/May/22 19:24,13/Jul/23 08:40,25/Jan/22 06:19,4.0.2,4.1,4.1-alpha1,,,,,Tool/auditlogging,,,,0,,,"CASSANDRA-16669 introduced support for obfuscating passwords for audit log statements, but there are a few cases where the obfuscation logic can destroy some of the contents of the original/provided string.

ex. This is perfectly valid...

{noformat}
WITH LOGIN = false AND PASSWORD = 'bar' AND SUPERUSER = false
{noformat}

...but calling obfuscate() on it will produce...

{noformat}
WITH LOGIN = false AND PASSWORD *******
{noformat}

-We should be able to create a reasonable RegEx and use String#replaceAll() to both simplify and correct PasswordObfuscator#obfuscate().-",,bereng,blerer,brandon.williams,e.dimitrova,jeromatron,maedhroz,stefan.miklosovic,subkanthi,vkartik97,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17334,,,,,,,,,,CASSANDRA-16669,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Jan 24 11:51:41 UTC 2022,,,,,,,All,,,,"0|z0swzk:",9223372036854775807,,,,blerer,e.dimitrova,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/85248da628770d9d93fdd2cbd1eedd55b3ddc206,,,,,,,,,See PR,,,,,"13/Jul/21 19:36;brandon.williams;A regex was explored here and shot down.  The way to handle this properly is with the grammar parser, the same way the statement is parsed.;;;","13/Jul/21 20:04;maedhroz;bq. There can then be a follow up ticket that actually uses the ANTLR grammar parsed statement to pull out the password field and only remove that, if it is what people want.

WFM...we'll treat this as the follow-up ticket then.;;;","29/Jul/21 10:29;vkartik97;Can I take this up ?

I am new to java saw this as an easy bug fix :);;;","29/Jul/21 12:57;brandon.williams;[~vkartik97] sure!  But this may not be as easy as you think, I think the complexity was scoped with the belief a regex would suffice.  I've since adjusted it.;;;","25/Oct/21 08:19;bereng;Will be looking into this one in short #justfyi;;;","29/Oct/21 07:28;stefan.miklosovic;It would be ideal to see a progress towards antlr solution. Due to the complexity of this seemingly easy task and being short of time to do that before 4.0.0 we just went with solution Brandon mentioned. This ""brutal"" approach of deleting everything after PASSWORD was done on purpose.;;;","29/Oct/21 07:42;bereng;I must be missing sthg here. Antlr already parses the password into a DTO. And the attached PR does not delete everything after the password. It only obfuscates the password itself leaving the rest of the CQL intact.;;;","29/Oct/21 07:53;stefan.miklosovic;Honestly I dont remember the details. I saw it there too in RoleOptions but I was trying to do it somehow without introducing that interface or so ... So congrats on figuring that out :) ;;;","29/Oct/21 08:01;bereng;Oh well maybe sbdy has a better suggestion, let's wait and see what feedback comes.;;;","02/Nov/21 18:00;e.dimitrova;{quote}I must be missing sthg here. Antlr already parses the password into a DTO. And the attached PR does not delete everything after the password. It only obfuscates the password itself leaving the rest of the CQL intact.
{quote}
Seems to me you actually fall back to the old way in case of errors.

Look [here|https://github.com/apache/cassandra/pull/1293/files#diff-df97ca69d481fde559e155c724ca60967a1e57222ea845d8ee8299d7b014df46R251]

Syntax errors are indeed fully obfuscated, but other errors fall to the old way. This worries me a bit. My understanding was that we need to get rid in full of the old way.;;;","03/Nov/21 00:42;e.dimitrova;[~maedhroz], [~adelapena], [~blerer] anyone of you having cycles and up to be second reviewer? ;;;","03/Nov/21 06:17;bereng;bq. Seems to me you actually fall back to the old way in case of errors.

Correct I had mentioned it already. When antlr fails to parse we don't have the password available so the previous logic is used as a fallback. If sbdy with better antlr kung-fu chimes in that be great.;;;","12/Jan/22 11:14;bereng;Thanks [~blerer] for your latest review. I have rebased, added a PR for trunk which happens to be identical and CI for both. Now waiting on final +1s and let's merge it! :-);;;","13/Jan/22 11:42;bereng;Although the latest pushes have the final correct code GH has been giving plenty timeouts today. I will trigger CI again tomorrow as I don't feel comfortable with those weird CI runs despite there shouldn't be any problems.;;;","14/Jan/22 06:42;bereng;CI was ok today. Results attached to PRs. This is up for final consideration and hopefully +1 :-);;;","14/Jan/22 10:05;blerer;+1;;;","17/Jan/22 05:56;bereng;[~e.dimitrova] mentioned via Slack about improving the wording on docs regarding obfuscation corner cases. Latest [commit|https://github.com/apache/cassandra/pull/1293/commits/25aa6bd8c951a1824ba56fdbc729243f49fc08c5] should address that?;;;","23/Jan/22 18:24;e.dimitrova;{quote}Latest [commit|https://github.com/apache/cassandra/pull/1293/commits/25aa6bd8c951a1824ba56fdbc729243f49fc08c5]should address that?
{quote}
I would probably do it as a Note or Warning (I think we use Note in our docs normally) but otherwise looks ok to me. 

I left a few tiny formatting suggestions on the 4.0 PR. Those can be addressed on commit. I am +1 on final ""green"" CI, thanks :) ;;;","24/Jan/22 11:51;bereng;Thanks [~e.dimitrova] I think I applied all the suggestions or left a GH comment. I squashed, rebased and ran CI. I'll merge tomorrow unless sbdy objects to give some time.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Incompatible constants related to forwarded writes,CASSANDRA-16797,13389273,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,Yongkang Li,Yongkang Li,13/Jul/21 02:09,31/Jul/21 21:14,13/Jul/23 08:40,13/Jul/21 15:30,4.0,4.0.0,,,,,,Messaging/Internode,,,,0,,,"The header for forwarded writes changed from 3.x.x->4.0. In C* 3.x.x headers are ""FWD_TO"" or ""FWD_FROM"" while in C* 4.0 headers are ""FORWARD_TO"" or ""FORWARD_FROM"". Therefore, I suppose that there will be a failure during rolling upgrade from 3.x.x to 4.0.",,aleksey,jeromatron,mck,Yongkang Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Availability,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Jul 13 15:30:26 UTC 2021,,,,,,,All,,,,"0|z0svu8:",9223372036854775807,,,,aleksey,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/43b750341e2fd33559353d53d059a0cbc3911cb1,,,,,,,,,run tests,,,,,"13/Jul/21 13:52;brandon.williams;Do you have anything beyond a supposition?;;;","13/Jul/21 13:55;aleksey;I can confirm that this is legit (and very trivial to fix, a two-liner).;;;","13/Jul/21 14:02;aleksey;Caused by CASSANDRA-7544 all the way back in 2017, surviving further rewrites and refactors.

I think we should block GA on this, unfortunately.;;;","13/Jul/21 14:40;brandon.williams;[Branch|https://github.com/driftx/cassandra/tree/CASSANDRA-16797] and [circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16797];;;","13/Jul/21 14:50;brandon.williams;Created CASSANDRA-16799 to follow up.;;;","13/Jul/21 15:18;aleksey;+1 (if you can fix alignment slightly on commit, my OCD will appreciate it);;;","13/Jul/21 15:30;brandon.williams;Committed, thanks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clear pending ranges for a SHUTDOWN peer,CASSANDRA-16796,13389174,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,samt,samt,samt,12/Jul/21 15:32,20/Jul/21 18:42,13/Jul/23 08:40,20/Jul/21 18:42,3.0.25,3.11.11,4.0.1,,,,,Cluster/Membership,,,,0,,,"If a node involved in a MOVE operation should fail, peers can sometimes maintain pending ranges for it even when it has left the ring and/or been replaced (in practice until the peer is next bounced). This in turn can lead to bogus unavailable responses to clients if a replica for the any of the pending ranges should go down.

If the moving node crashes hard, a subsequent replacement will correctly fail as long as cassandra.consistent.rangemovement is set to true because the new node will learn the MOVING status from the remaining peers. A graceful shutdown, however, causes that status to be replaced with SHUTDOWN, but doesn't update TokenMetadata, so pending ranges remain for the down node, even after it has been removed from the ring.",,brandon.williams,e.dimitrova,maedhroz,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,samt,,,,,,,,,,,,,Availability -> Unavailable,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Jul 20 18:42:52 UTC 2021,,,,,,,All,,,,"0|z0sv88:",9223372036854775807,,,,maedhroz,,,,Normal,,3.0.0,,https://github.com/apache/cassandra/commit/fbb20b9162b73c4de8a82cf4ffdde3304e904603,,,,,,,,,new dtest added,,,,,"12/Jul/21 17:38;samt;||branch||Circle CI||
|[16796-3.0|https://github.com/beobal/cassandra/tree/16796-3.0]|[circle|https://circleci.com/gh/beobal/cassandra?branch=16796-3.0]|
|[16796-3.11|https://github.com/beobal/cassandra/tree/16796-3.11]|[circle|https://circleci.com/gh/beobal/cassandra?branch=16796-3.11]|
|[16796-4.0|https://github.com/beobal/cassandra/tree/16796-4.0]|[circle|https://circleci.com/gh/beobal/cassandra?branch=16796-4.0]|
|[16796-trunk|https://github.com/beobal/cassandra/tree/16796-trunk]|[circle|https://circleci.com/gh/beobal/cassandra?branch=16796-trunk]|

The 3.0/3.11 & 4.0/trunk patches are basically the same, so I've only kicked off ci-c jobs for 
[3.0|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/936] and [4.0|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/936]
;;;","19/Jul/21 23:31;maedhroz;Two questions...

1.) So just to make things explicit (for me, a non-gossip expert), notifying subscribers in {{onChange()}} means we hit {{updateNormalTokens()}}, which removes the endpoint from the ""moving endpoints"" set and eventually removes the pending ranges?

2.) What guarantees that a {{PendingRangeTask}} has run by the time {{gossipShutdownUpdatesTokenMetadata()}} verifies there are no longer pending range for node 2? 

The 3.0 patch looks good, so moving on to 4.0...

;;;","20/Jul/21 11:26;samt;Thanks [~maedhroz]

bq. So just to make things explicit (for me, a non-gossip expert), notifying subscribers in onChange() means we hit updateNormalTokens(), which removes the endpoint from the ""moving endpoints"" set and eventually removes the pending ranges?

Yes, that's right. The shutting down node is essentially returning to a {{NORMAL}} state, so we just make sure that all
relevant parties (i.e. {{TokenMetadata}} ) are aware.

bq. What guarantees that a PendingRangeTask has run by the time gossipShutdownUpdatesTokenMetadata() verifies there are no longer pending range for node 2?

Good catch, I haven't seen any failures yet, but this definitely has the potential for flakiness. I've added a log
statement at {{DEBUG}} at the end of {{Gossiper::markAsShutdown}} to gate the test on, plus a blocking wait in the
assertion to ensure the PRT is complete before we check.

Circle runs are in the same place as before, new ASF CI jobs here: [3.0|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/961], [4.0|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/962]
;;;","20/Jul/21 16:09;maedhroz;+1 on all patches

Just watch out for the unused imports in {{GossipTest}} ;);;;","20/Jul/21 18:42;samt;Thanks, cleaned up those unused imports and committed to 3.0 and merged to 3.11 -> 4.0 -> trunk. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CassandraVersion compareTo does not order SNAPSHOT versions properly,CASSANDRA-16794,13388589,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,blerer,blerer,09/Jul/21 09:57,01/Aug/21 13:32,13/Jul/23 08:40,12/Jul/21 11:16,4.0,,,,,,,Legacy/Core,,,,0,,,"{{CassandraVersion::compareTo}} does not order {{SNAPSHOT}} versions properly in several scenario.
It return wrong results for the 2 following usecases:

1. {{new CassandraVersion(""4.0-rc2"").compareTo((""4.0.0-SNAPSHOT"")}}
2. {{new CassandraVersion(""4.0-rc2"").compareTo((""4.0-rc2-SNAPSHOT"")}}
",,blerer,e.dimitrova,mck,,,,,,,,,,,,,"blerer opened a new pull request #1107:
URL: https://github.com/apache/cassandra/pull/1107


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Jul/21 10:04;githubbot;600","asfgit closed pull request #1107:
URL: https://github.com/apache/cassandra/pull/1107


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Aug/21 13:32;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Code,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Jul 12 11:16:59 UTC 2021,,,,,,,All,,,,"0|z0srmg:",9223372036854775807,,,,mck,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/b42855282d260bcd16412a1ed9da0227ee0c065e,,,,,,,,,The patch add some tests to cover the failling usecases,,,,,"09/Jul/21 10:07;blerer;|| Branch || CI ||
| [4.0.0|https://github.com/apache/cassandra/pull/1107] | [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/182/workflows/4a681f71-4a95-4456-84c0-b6f4940ca34c], [j11|https://app.circleci.com/pipelines/github/blerer/cassandra/182/workflows/0b9d07ba-7e7e-4487-8c91-d699026a22e0]|;;;","09/Jul/21 10:26;mck;+1;;;","12/Jul/21 10:31;blerer;Sorry, I hit another issue with the {{lowerFamilyBound}} initial patch. I pushed a modified version of the patch that addressed that issue and updated the CI runs.;;;","12/Jul/21 11:16;blerer;Committed into cassandra-4.0.0 at b42855282d260bcd16412a1ed9da0227ee0c065e and merged into cassandra-4.0 and trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Delay auth setup to after gossip has settled to avoid unavailables on startup,CASSANDRA-16783,13387084,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,01/Jul/21 14:54,27/May/22 19:25,13/Jul/23 08:40,01/Sep/21 08:57,4.0.2,4.1,4.1-alpha1,,,,,Local/Startup and Shutdown,,,,0,,,We should delay trying to do auth setup until after gossip has settled to avoid getting unavailables from trying to read the auth tables before knowing of any neighbours ,,marcuse,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Availability -> Unavailable,,,,,,,,Low Hanging Fruit,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Sep 01 08:57:18 UTC 2021,,,,,,,All,,,,"0|z0sidk:",9223372036854775807,,,,samt,,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/c36c081e5c33362daae748c2da1be4da9ef18fa6,,,,,,,,,cci run,,,,,"01/Jul/21 14:56;marcuse;[https://github.com/krummas/cassandra/commits/marcuse/16783]

[https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16783] ;;;","27/Aug/21 15:59;samt;LGTM, +1;;;","01/Sep/21 08:57;marcuse;thanks, committed with a fix to {{RepairDigestTest.testLocalDataAndRemoteRequestConcurrency}} by [~maedhroz] to make sure node1 gets a digest request - when delaying the auth queries the dynamic snitch started sending the data request to node1 which made the test hang.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix upgrade dtests (after cassandra-4.0 branch bumped to 4.0.1),CASSANDRA-16781,13387036,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mck,mck,mck,01/Jul/21 11:57,27/May/22 19:25,13/Jul/23 08:40,04/Jul/21 10:55,4.0.1,4.1,4.1-alpha1,,,,,Test/dtest/python,,,,0,,,"{noformat}
Regression
dtest-upgrade.upgrade_tests.paging_test.TestPagingDataNodes2RF1_Upgrade_current_4_0_x_To_indev_4_0_x.test_static_columns_paging (from Cassandra dtests)

Failing for the past 1 build (Since Unstable#116 )
Took 46 sec.
 Failed 1 times in the last 29 runs. Flakiness: 3%, Stability: 96%
Error Message
TypeError: '<' not supported between instances of 'str' and 'int'
Stacktrace
self = <abc.TestPagingDataNodes2RF1_Upgrade_current_4_0_x_To_indev_4_0_x object at 0x7f5ff1817c10>

    @since('2.0.6')
    def test_static_columns_paging(self):
        """"""
            Exercises paging with static columns to detect bugs
            @jira_ticket CASSANDRA-8502.
            """"""
        cursor = self.prepare(row_factory=named_tuple_factory)
        cursor.execute(""CREATE TABLE test (a int, b int, c int, s1 int static, s2 int static, PRIMARY KEY (a, b))"")
    
        for is_upgraded, cursor in self.do_upgrade(cursor, row_factory=named_tuple_factory):
>           min_version = min(self.get_node_versions())

upgrade_tests/paging_test.py:661: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.8/distutils/version.py:52: in __lt__
    c = self._cmp(other)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = LooseVersion ('4.0-rc1'), other = LooseVersion ('4.0.1')

    def _cmp (self, other):
        if isinstance(other, str):
            other = LooseVersion(other)
    
        if self.version == other.version:
            return 0
>       if self.version < other.version:
E       TypeError: '<' not supported between instances of 'str' and 'int'

/usr/lib/python3.8/distutils/version.py:337: TypeError
{noformat}
from https://ci-cassandra.apache.org/job/Cassandra-4.0/116/testReport/junit/dtest-upgrade.upgrade_tests.paging_test/TestPagingDataNodes2RF1_Upgrade_current_4_0_x_To_indev_4_0_x/test_static_columns_paging/ 

ref: https://the-asf.slack.com/archives/CK23JSY2K/p1625125464283300 ",,bereng,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16648,,,,,,,,,,,,,,,,,,,0.0,mck,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sun Jul 04 10:55:23 UTC 2021,,,,,,,All,,,,"0|z0si2w:",9223372036854775807,,,,bereng,brandon.williams,,,Critical,,4.0-rc2,,https://github.com/apache/cassandra-dtest/commit/a1080b1ef3c77bc4c5e6a4fff154d1c17f115e22,,,,,,,,,CI,,,,,"01/Jul/21 12:25;mck;patch https://github.com/apache/cassandra-dtest/compare/trunk...thelastpickle:mck/16781 

CI
 - 4.0.0 https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/388/
 - 4.0 https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/389/
 - trunk https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/390/;;;","01/Jul/21 12:48;brandon.williams;CI is looking good, +1 assuming it continues.;;;","01/Jul/21 15:13;mck;A number of dtests do {{'…  >= CASSANDRA_4_0 '}} comparisons.

I've updated the patch so the cassandra-4.0.0 branch is the {{CASSANDRA_4_0}} version family, and the cassandra-4.0 branch is the {{CASSANDRA_4_0_X}} version family, so that {{'CASSANDRA_4_0_X  >= CASSANDRA_4_0 '}}.

CI
- 4.0.0 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/401/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/401/]
- 4.0 [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/402/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/402/]
- trunk [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/403/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/403/];;;","01/Jul/21 21:43;mck;{{upgrade_tests/upgrade_through_versions_test.py}} [broke a test in trunk|https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/396/label=cassandra-dtest,split=1/testReport/junit/dtest-upgrade.upgrade_tests.upgrade_through_versions_test/TestProtoV4Upgrade_AllVersions_EndsAt_Trunk_HEAD/test_rolling_upgrade/]. working on it…;;;","02/Jul/21 07:57;mck;bq. upgrade_tests/upgrade_through_versions_test.py broke a test in trunk. working on it…

Looks to be a flaky, ignoring it for now.;;;","02/Jul/21 10:45;bereng;Just checked and lgmt except for the fact the 4.0.0 CI run is unfortunately a 4.0 in fact. So +1 assuming a successful and correct 4.0.0 run.;;;","03/Jul/21 09:24;mck;4.0.0 needed another fix… (CI above updated);;;","04/Jul/21 10:55;mck;Committed as [a1080b1ef3c77bc4c5e6a4fff154d1c17f115e22|https://github.com/apache/cassandra-dtest/commit/a1080b1ef3c77bc4c5e6a4fff154d1c17f115e22].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky ViewTest,CASSANDRA-16777,13386949,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,01/Jul/21 04:57,01/Aug/21 11:33,13/Jul/23 08:40,05/Jul/21 09:21,4.0,4.0.0,4.0.1,,,,,Test/unit,,,,0,,,"ViewTest has been [failing|https://ci-cassandra.apache.org/job/Cassandra-4.0/113/testReport/junit/org.apache.cassandra.cql3/ViewTest/testFrozenCollectionsWithComplicatedInnerType/] every now and then on the 4.0 line. Being so close to having 0 faky failures I want to scratch that itch so I propose we split it like we did with ViewComplexTest.",,adelapena,bereng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jul 02 09:42:07 UTC 2021,,,,,,,All,,,,"0|z0shjk:",9223372036854775807,,,,adelapena,,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/6d16a531b1b4b3d63dfa182cd8484fb4d9e93c86,,,,,,,,,See PR,,,,,"01/Jul/21 18:06;adelapena;+1 to splitting {{ViewTest}}. Perhaps we could either make the tests inherit from a common super class to avoid code duplication, more or less [this way|https://github.com/adelapena/cassandra/commit/68d7d1247a24671688e030d1275710c8f4efd84e], wdyt?

It seems that several MV tests can still find server-side timeouts:
 * [{{ViewPKTest.testPartitionKeyOnlyTable}}|https://app.circleci.com/pipelines/github/adelapena/cassandra/631/workflows/d40373e0-d85a-4a7e-b3e6-0d7aa0c599c7/jobs/6183]
 * [{{ViewRangesTest.testRangeTombstone}}|https://app.circleci.com/pipelines/github/adelapena/cassandra/632/workflows/82218abb-cdb8-4445-823f-70ea3762885d/jobs/6193]
 * [{{ViewRangesTest.testRangeTombstone}}|https://app.circleci.com/pipelines/github/adelapena/cassandra/632/workflows/82218abb-cdb8-4445-823f-70ea3762885d/jobs/6194]
 * [{{ViewTimesTest.ttlTest}}|https://app.circleci.com/pipelines/github/adelapena/cassandra/633/workflows/0fab87e7-26bc-457a-b742-517a04e6eca5/jobs/6198]

I think we can investigate those separately, if we are worried that they might be caused by something different than just an unusually slow CI run.
  ;;;","02/Jul/21 04:47;bereng;[~adelapena] those failures are different timeouts. This ticket addresses the junit watchdog test timeout. The ones you point out are connection timeouts during the test. Iiuc they are different things and out for scope for this ticket. wdyt?

Yes we can pull and abstract class to avoid the 4 overloaded methods. Let me add that to the PR.

Edit: Added and new CI ran;;;","02/Jul/21 09:42;adelapena;{quote}
those failures are different timeouts. This ticket addresses the junit watchdog test timeout. The ones you point out are connection timeouts during the test. Iiuc they are different things and out for scope for this ticket. wdyt?
{quote}
I agree, that's what I meant by investigate them separately, that we can do it in a separate ticket(s) if needed. Let's keep this ticket focused on the JUnit timeout.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BinLog does not close chronicle queue leaving this to GC to cleanup,CASSANDRA-16774,13386861,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,30/Jun/21 17:06,27/May/22 19:25,13/Jul/23 08:40,02/Jul/21 18:33,4.0.0,4.1,4.1-alpha1,,,,,Test/dtest/python,Tool/fql,,,0,,,"auditlog_test.py::TestAuditlog::test_archiving_fql  and test_fql_nodetool_options fail from time to time due to the test relying on a race condition; we do not close chronicle queue so rotation may not happen before stopping archiver, the tests fail if rotation happens before stopping archiver (which is done based off GC).",,bereng,dcapwell,e.dimitrova,jmeredithco,maedhroz,marcuse,yifanc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Recoverable Corruption / Loss,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jul 07 16:20:32 UTC 2021,,,,,,,All,,,,"0|z0sh00:",9223372036854775807,,,,maedhroz,marcuse,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/f0a7ea411fe237543200b3c67a2f0fb34536c162,,,,,,,,,python dtest,,,,,"30/Jun/21 18:15;dcapwell;tests look clean, only the two tests in this ticket are failing (as expected, they only pass when the race condition happens, which I just fixed); updating python dtests now;;;","30/Jun/21 18:37;dcapwell;pushed python dtests and updated the CI to run against it;;;","30/Jun/21 19:07;maedhroz;+1 (local dtest changes against your branch are green for me across a few runs);;;","30/Jun/21 19:34;brandon.williams;I bet this was the problem with CASSANDRA-16526 too.;;;","30/Jun/21 20:02;dcapwell;looking at the test I feel more is going on as well.

* BinLog is async and max size is only used by the archiver, which is triggered on release (I don't see how we control it)
* max weight is 10, and our records don't override weight, so 1 record = 1 weight; aka max queue size of 10 records
* test is waiting until a log exists which has 2 records... but 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, and 10 are all valid states

Unless I am missing something, org.apache.cassandra.utils.binlog.BinLogTest#flakyTestTruncationReleasesLogSpace doesn't make sense to me. The test would make more sense if it controlled the archiver and wrote 11 records, you can then detect release got triggered and then the log size should be 1

But to your point, since stop doesn't release the resources the files cleanup when GC triggered, so previous tests may have other log files in the test directory;;;","01/Jul/21 08:39;marcuse;+1;;;","02/Jul/21 17:44;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|cassandra-4.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16774-cassandra-4.0-F7958CBF-9DF6-44CE-A83C-E236C6694AFF]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16774-cassandra-4.0-F7958CBF-9DF6-44CE-A83C-E236C6694AFF]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/888/]|
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16774-trunk-F7958CBF-9DF6-44CE-A83C-E236C6694AFF]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16774-trunk-F7958CBF-9DF6-44CE-A83C-E236C6694AFF]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/889/]|
;;;","02/Jul/21 18:33;dcapwell;https://github.com/apache/cassandra-dtest/commit/2fddec7e516a8a2dbfbd2ad51837116556116ee6;;;","06/Jul/21 05:25;bereng;Hi,

I have been bisecting a bit and I think recent 4.0.0 [failures|https://ci-cassandra.apache.org/job/Cassandra-4.0.0/44/] and due to this ticket? Could sbdy familiar with it confirm please?

Thx in advance;;;","06/Jul/21 17:09;maedhroz;[~bereng] I think you are correct. The simplest fix is probably just to make sure that the two line change from [this commit|https://github.com/dcapwell/cassandra/commit/f0a7ea411fe237543200b3c67a2f0fb34536c162] ends up in 4.0.0 instead of just 4.0. Seems like a reasonable candidate for a ninja-fix.;;;","06/Jul/21 18:52;maedhroz;[~bereng] [~marcuse] [~e.dimitrova] [~jmeredithco] [~dcapwell] Here is a small patch to back-port the change to {{cassandra-4.0.0}} (with a Jenkins run in progress):

[branch|https://github.com/apache/cassandra/pull/1102], [Jenkins|https://ci-cassandra.apache.org/job/Cassandra-devbranch/897/];;;","06/Jul/21 19:30;jmeredithco;+1, change looks good pending tests.;;;","06/Jul/21 21:47;maedhroz;Tests [look good|https://ci-cassandra.apache.org/job/Cassandra-devbranch/897/], outside what appear to be 3 entirely unrelated failures.

[~edimitrova] [~bereng] Any idea if the failure in [UnableToParseClientMessageTest|https://ci-cassandra.apache.org/job/Cassandra-devbranch/897/testReport/junit/org.apache.cassandra.distributed.test/UnableToParseClientMessageTest/badHeader_version_4_v4_/] is new. That's the only one I didn't find a Jira for.;;;","07/Jul/21 01:12;e.dimitrova;I haven't seen it before. It doesn't fail for me locally in 4.0.0. Considering that the failing assert is based on a grep in the logs, I would say probably there is some test flakiness somewhere and we should improve the test... I can take a look these days. This failing test doesn't exercise the code you changed;;;","07/Jul/21 04:32;bereng;The failures are unrelated. And that {{UnableToParseClientMessageTest}} I'd swear I've seen before. So I think we're good to merge imo. +1;;;","07/Jul/21 16:20;maedhroz;4.0.0 back-port committed as https://github.com/apache/cassandra/commit/68bf950f72d20be9f31fd3f91669be7e28c050e4

(Also changed release to 4.0-rc3.)

Thanks everyone!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky MessageFiltersTest,CASSANDRA-16771,13386432,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,29/Jun/21 06:27,27/May/22 19:25,13/Jul/23 08:40,30/Jun/21 07:43,4.0.1,4.1,4.1-alpha1,,,,,Test/unit,,,,0,,,"Flaky [MessageFiltersTest|https://ci-cassandra.apache.org/job/Cassandra-4.0.0/39/testReport/junit/org.apache.cassandra.distributed.test/MessageFiltersTest/testFilters/]

{noformat}
Error Message

Operation failed - received 1 responses and 1 failures: TIMEOUT from /127.0.0.2:7012

Stacktrace

org.apache.cassandra.exceptions.ReadFailureException: Operation failed - received 1 responses and 1 failures: TIMEOUT from /127.0.0.2:7012
	at org.apache.cassandra.service.reads.ReadCallback.awaitResults(ReadCallback.java:127)
	at org.apache.cassandra.service.reads.range.SingleRangeResponse.waitForResponse(SingleRangeResponse.java:58)
	at org.apache.cassandra.service.reads.range.SingleRangeResponse.computeNext(SingleRangeResponse.java:65)
	at org.apache.cassandra.service.reads.range.SingleRangeResponse.computeNext(SingleRangeResponse.java:31)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.service.StorageProxy$6.hasNext(StorageProxy.java:1883)
	at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:93)
	at org.apache.cassandra.service.reads.range.RangeCommandIterator.computeNext(RangeCommandIterator.java:101)
	at org.apache.cassandra.service.reads.range.RangeCommandIterator.computeNext(RangeCommandIterator.java:54)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.cql3.statements.SelectStatement.process(SelectStatement.java:777)
	at org.apache.cassandra.cql3.statements.SelectStatement.processResults(SelectStatement.java:425)
	at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:296)
	at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:246)
	at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:88)
	at org.apache.cassandra.distributed.impl.Coordinator.executeInternal(Coordinator.java:103)
	at org.apache.cassandra.distributed.impl.Coordinator.lambda$executeWithResult$0(Coordinator.java:65)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

{noformat}
",,bereng,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Jun 29 12:59:49 UTC 2021,,,,,,,All,,,,"0|z0secw:",9223372036854775807,,,,brandon.williams,e.dimitrova,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/cfefdfd76e4ac35ee748132013718e7196b04742,,,,,,,,,See PR,,,,,"29/Jun/21 06:34;bereng;This is just a plain timeout. The traceback doesn't pin down which exact test case failed but there is only one candidate {{testMessageMatching}} as it's the only one issuing a {{SELECT}} that shouldn't fail. Seems like a reasonable guess despite the other test case with {{SELECT}}

It can be reproduced by placing a breakpoint [here|https://github.com/bereng/cassandra/blob/CASSANDRA-16771-4.0.0/src/java/org/apache/cassandra/service/reads/ReadCallback.java#L101]. The solution is to raise the timeout for this test and now it survives a 1K CI run.;;;","29/Jun/21 12:32;brandon.williams;+1;;;","29/Jun/21 12:59;e.dimitrova;LGTM, thanks;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Avoid sending cdc column in serialization header to 3.0 nodes,CASSANDRA-16770,13386302,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,28/Jun/21 16:25,04/Aug/21 09:12,13/Jul/23 08:40,04/Aug/21 09:12,3.11.12,,,,,,,Cluster/Schema,,,,0,,,"We try to not send the cdc column to any 3.0 nodes, but it is still there in the SerializationHeader",,azotcsit,blerer,marcuse,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16735,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Degradation -> Other Exception,,,,,,,,Normal,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Aug 04 09:12:12 UTC 2021,,,,,,,All,,,,"0|z0sdk0:",9223372036854775807,,,,azotcsit,blerer,mck,,Normal,,3.11.0,,https://github.com/apache/cassandra/commit/cb370350a7520cabf87fc88a2ff37b068fb8e22d,,,,,,,,,dtest run,,,,,"28/Jun/21 16:29;marcuse;https://github.com/krummas/cassandra/commits/marcuse/16770

dtest run: https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2Ffollowup_16735 - note that this is against a different [branch|https://github.com/krummas/cassandra/commit/472780c93a3e17509512a74c119d02c8ce9b1049], apparently our upgrade dtests don't run against the current branch - it clones the 3.11 repo and runs against that

-I'll also need to figure out why this doesn't affect 4.0- - we don't exchange schema between 3.0 and 4.0;;;","09/Jul/21 23:18;azotcsit;Hi [~marcuse]

I checked the change, it looks good and clear to me. The only question: is there a way to write tests for this fix? I feel we can either cover 

_convertSchemaToMutations_ method with tests or make _makeUpdateForSchema_ method package private and then cover with tests.;;;","25/Jul/21 19:51;mck;[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/972/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch/972/]

+1 ;;;","25/Jul/21 21:18;brandon.williams;bq. is there a way to write tests

It was a lot of broken dtests that caught this in CASSANDRA-16735;;;","26/Jul/21 07:27;azotcsit;Ok, got it. Thanks for the explanation [~brandon.williams]!;;;","29/Jul/21 10:11;blerer;Sorry, for the delay [~marcuse]. 
The patch looks good to me. The only nit I found is that documentation of {{SchemaKeyspace.makeUpdateForSchema}} need to be changed as it is not accurate anymore but it can be done on commit. ;;;","04/Aug/21 09:12;marcuse;and committed with the comment updated, thanks;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Avoid memoizing the wrong min cluster version during upgrades,CASSANDRA-16759,13385448,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,23/Jun/21 15:19,01/Aug/21 11:33,13/Jul/23 08:40,27/Jun/21 05:17,4.0,4.0.1,4.0-rc2,,,,,Consistency/Coordination,,,,0,,,"CASSANDRA-16525 avoids trying to calculate the cluster min version if gossiper is not enabled.

This makes us memoize the wrong version for up to a minute causing us to send 4.0-messages to 3.0 nodes, for example in [ColumnFilter|https://github.com/apache/cassandra/blob/05beda90a9206db165a3997a736ecb06f8dc695e/src/java/org/apache/cassandra/db/filter/ColumnFilter.java#L210]

This was discovered by python upgrade dtests, [here|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/993/workflows/2afef6f0-1356-41f6-93dc-5385ac19dca1/jobs/5977/tests#failed-test-0] after reverting CASSANDRA-15899 in CASSANDRA-16735",,brandon.williams,e.dimitrova,jmeredithco,marcuse,mck,yifanc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jmeredithco,marcuse,,,,,,,,,,,,Degradation -> Other Exception,,,,,,,,Challenging,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sun Jun 27 05:17:05 UTC 2021,,,,,,,All,,,,"0|z0s8a8:",9223372036854775807,,,,brandon.williams,yifanc,,,Critical,,4.0-rc1,,https://github.com/apache/cassandra/commit/2fba5c80ce7bf71d04c62043ffa1088b9e832d83,,,,,,,,,cci run,,,,,"23/Jun/21 15:28;marcuse;https://github.com/krummas/cassandra/commits/marcuse/16759
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16759;;;","23/Jun/21 16:02;brandon.williams;+1 if CI looks good.;;;","23/Jun/21 17:33;brandon.williams;Unfortunately the jvm dtest failures look legit:

{noformat}
org.apache.cassandra.exceptions.ReadFailureException: Operation failed - received 0 responses and 1 failures: INCOMPATIBLE_SCHEMA from /127.0.0.4:7012
{noformat};;;","24/Jun/21 12:08;marcuse;by clearing out the memoized minVersion in {{start()}} we might call {{upgradeFromVersionSupplier}} before we know anything about the cluster

pushed a new patch which makes sure we don't memoize anything before we actually have {{endpointStateMap}} populated with something usable, tests running (edit: still broken);;;","25/Jun/21 00:46;jmeredithco;I've been investigating a few of the test failures and they seem to be related to the node not waiting to receive an up to date schema and starting bootstrap with the default schema which does not contain any non-system keyspaces so does not do any streaming.

In 4.0, MigrationCoordinator is responsible for awaiting having all  schema and it gets told about schema versions from the StorageService.onChange listener. It only processes the ApplicationState.SCHEMA entries if the endpoint exists in TokenMetadata.

Endpoints are added to TokenMetadata when StorageService.onJoin handles the STATUS or STATUS_WITH_PORT application states.

The EnumMap.values() that onJoin iterates over seems to return the application states in the order they are defined in the enum, so if STATUS is present, it comes first and all is good.

If STATUS is not present, like when a 4.0 cluster thinks there are no nodes with a version lower than 4.0 and gossip filters it out, then only the items in ApplicationState after STATUS_WITH_PORT (currently only SSTABLE_VERSIONS) will be processed by onChange. Then it takes a subsequent gossip of that ApplicationState to apply theother states which is making tests racy.

This is all very fiddly and I'm not 100% sure that's the exact sequence, but there is definitely a change in behavior for when nodes switch to not having STATUS any more.

I've pushed up a minimal change to onJoin to make it behave [on a branch|https://github.com/jonmeredith/cassandra/pull/new/marcuse/16759-fix-status-with-port], with  [CircleCI Here|https://app.circleci.com/pipelines/github/jonmeredith/cassandra?branch=marcuse%2F16759-fix-status-with-port]

A possible cleaner alternative solution would be to sort with a customer key comparator, but wasn't sure about performance during gossip storms.;;;","25/Jun/21 07:57;yifanc;The analysis makes sense. Thanks [~jmeredithco].

In the following scenarios, the STATUS field can be absent onJoin. 
1. {{hasMajorVersion3Nodes()}} that is called in {{Gossiper#applyStateLocally}} improperly returns false. It happens when gossiper is just started and there is no known peers. [This commit|https://github.com/apache/cassandra/commit/195e7d2f9c7a5cbe935f3f7cd38f975f0f48276d] fixes it. But the change also brings up a concern that in a single node cluster (that runs 4.0), {{hasMajorVersion3Nodes()}} always returns true. 
2. In the tests with more than 2 nodes, it is possible the gossip state is received via a third 4.0 node that has removed the STATUS field of its peer already. 

So the change to the {{onJoin}} is necessary. Beside correcting the order to handle STATUS* first then the others, a node also avoids double handling the redundant STATUS* fields received. Instead, it only handles either STATUS or STATUS_WITH_PORT.;;;","25/Jun/21 14:13;brandon.williams;This makes sense to me too.  Thanks for the summary, [~yifanc].  I do feel that this special casing in onJoin may need to be repeated elsewhere and may in general be good to always process in this order, but perhaps YAGNI and we can look into a custom comparator later if we do. +1;;;","25/Jun/21 16:53;yifanc;+1 on the patch. ;;;","25/Jun/21 17:21;yifanc;Starting commit

CI Results:
||Branch||Source||Circle CI||Jenkins||
|cassandra-4.0.0|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16759-cassandra-4.0.0-BCA6D5DB-7312-49A5-B80B-DF81DA5A9AF1]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16759-cassandra-4.0.0-BCA6D5DB-7312-49A5-B80B-DF81DA5A9AF1]|[build|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/874/]|
|cassandra-4.0|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16759-cassandra-4.0-6F66B066-B39F-4096-951C-053D52D8BE1D]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16759-cassandra-4.0-6F66B066-B39F-4096-951C-053D52D8BE1D]|[build|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/873/]|
|cassandra-trunk|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16759-trunk-6F66B066-B39F-4096-951C-053D52D8BE1D]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16759-trunk-6F66B066-B39F-4096-951C-053D52D8BE1D]|[build|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/872/]|

– edit –
 Both [Circle|https://app.circleci.com/pipelines/github/yifan-c/cassandra/241/workflows/d39bedff-be86-42c0-b9a8-75eb356b1ae6/jobs/1496] and [Jenkins|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/874/tests/] have gossip failures from the upgrade dtest.;;;","26/Jun/21 00:47;yifanc;Since we do not memorize the Cassandra version when the gossiper is not started or not know others, the node runs the check more frequently. It is possible that the remote peers are not in the live members yet, and the check ({{upgradeFromVersionSupplier}}) memorize the wrong lowest version. 
 It causes the upgrade test to fail.

The check should not only iterate though the live member (i.e., the peers that the node has directly contacted). Instead, it should check all the hosts that the gossiper has heard of.
 I have put a fix here. [https://github.com/yifan-c/cassandra/commit/ee2bf298ec427c3283ac04d0ac87b395d50fff6a]
 Running the CI with the new commit: [https://app.circleci.com/pipelines/github/yifan-c/cassandra/242/workflows/02c8a073-67e9-4cf9-abe5-03a8d3a4281e]

[~jmeredithco] and [~brandon.williams], please take a look.

 

– edit – 
 Bunch of unit test in {{InsertUpdateIfConditionTest}} failed. The cause is the test assertion asserts ""4.0.0-rc2-SNAPSHOT"" >= ""4.0.0"". It is not true according to the compactor defined in {{CassandraVersion}}. The prior has preRelease strings, i.e., ""rc2, SNAPSHOT"" and the latter one does not have it. So the prior version is lower than ""4.0.0"". Therefore, *it is a test issue.* I updated the test in [this commit|https://github.com/apache/cassandra/commit/929ff35ed7ab02b6770e614332540ad6e08f8a78]. (How the tests work earlier??!);;;","26/Jun/21 05:17;yifanc;Starting CI with the my recent commits.

CI Results:
||Branch||Source||Circle CI||Jenkins||
|cassandra-4.0.0|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16759-cassandra-4.0.0-EE11F5CA-D50A-4497-8ACA-107F76CA86F7]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16759-cassandra-4.0.0-EE11F5CA-D50A-4497-8ACA-107F76CA86F7]|[build|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/875/pipeline]|
|cassandra-4.0|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16759-cassandra-4.0-EE11F5CA-D50A-4497-8ACA-107F76CA86F7]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16759-cassandra-4.0-EE11F5CA-D50A-4497-8ACA-107F76CA86F7]|[build|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/876/pipeline]|
|trunk|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16759-trunk-026ECB22-6F8B-4F4C-A937-A992D342F85A]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16759-trunk-026ECB22-6F8B-4F4C-A937-A992D342F85A]|[build|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/877/pipeline]|

Both Jenkins and Circle results look good.;;;","26/Jun/21 11:56;brandon.williams;Your fix looks good, +1.  Not sure what happened with that test, very strange.;;;","27/Jun/21 05:17;yifanc;Committed into 4.0.0 as [2fba5c|https://github.com/apache/cassandra/commit/2fba5c80ce7bf71d04c62043ffa1088b9e832d83], and merged up to 4.0 and to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky ClientResourceLimitsTest,CASSANDRA-16758,13385348,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,23/Jun/21 08:08,30/Jun/21 19:41,13/Jul/23 08:40,30/Jun/21 11:32,4.0,4.0.0,,,,,,Test/unit,,,,0,,,"Flaky [ClientResourceLimitsTest|https://ci-cassandra.apache.org/job/Cassandra-4.0.0/35/testReport/junit/org.apache.cassandra.transport/ClientResourceLimitsTest/testBackPressureWhenEndpointLimitExceeded_cdc/]

{noformat}
Error Message

Timed out after waiting 5 seconds for paused connections metric to increment due to backpressure expected:<11> but was:<24>

Stacktrace

junit.framework.AssertionFailedError: Timed out after waiting 5 seconds for paused connections metric to increment due to backpressure expected:<11> but was:<24>
	at org.apache.cassandra.Util.spinAssertEquals(Util.java:610)
	at org.apache.cassandra.transport.ClientResourceLimitsTest.backPressureTest(ClientResourceLimitsTest.java:218)
	at org.apache.cassandra.transport.ClientResourceLimitsTest.testBackPressureWhenEndpointLimitExceeded(ClientResourceLimitsTest.java:179)

Standard Output

INFO  [main] 2021-06-22 01:56:41,489 YamlConfigurationLoader.java:93 - Configuration location: file:////home/cassandra/cassandra/build/test/cassandra.cdc.yaml
DEBUG [main] 2021-06-22 01:56:41,491 YamlConfigurationLoader.java:112 - Loading settings from file:////home/cassandra/cassandra/build/test/cassandra.cdc.yaml
DEBUG [main] 2021-06-22 01:56:41,551 InternalLoggerFactory.java:63 - Using SLF4J as the default logging framework
DEBUG [main] 2021-06-22 01:56:41,565 PlatformDependent0.java:417 - -D
...[truncated 765272 chars]...
 org.apache.cassandra.transport.SimpleClient.execute(SimpleClient.java:275)
	at org.apache.cassandra.transport.ClientResourceLimitsTest.lambda$testQueryUpdatesConcurrentMetricsUpdate$11(ClientResourceLimitsTest.java:352)
	at java.lang.Thread.run(Thread.java:748)
DEBUG [Test Cluster-nio-worker-0] 2021-06-22 01:57:08,353 Slf4JLogger.java:81 - Freed 24 thread-local buffer(s) from thread: Test Cluster-nio-worker-0
INFO  [main] 2021-06-22 01:57:08,364 Server.java:171 - Stop listening for CQL clients
{noformat}
",,adelapena,bereng,jeromatron,maedhroz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16663,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,bereng,maedhroz,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jun 30 14:48:01 UTC 2021,,,,,,,All,,,,"0|z0s7o8:",9223372036854775807,,,,adelapena,bereng,maedhroz,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/636e8b99226703d643cc4b30e5c30a64ce830434,,,,,,,,,See PR,,,,,"23/Jun/21 10:12;bereng;Queries in the background can alter stats. It's easy to repro locally by adding a sleep just after starting the thread [here|https://github.com/apache/cassandra/pull/1082/files#diff-c801dfb00bc39ce5bf66a5876779350dba35def185588d13f5e492b6d79212f7R214]. Also printing out the values in the spin assert loop makes that very obvious and visible. Waiting for background cleaning tasks of {{CQLTtester}} is not enough. The equality assert can't be guaranteed but a GTE can.

Passes 1K runs whereas it used to fail.;;;","23/Jun/21 16:07;maedhroz;[~bereng] I noticed this while working on CASSANDRA-16663, and I think I fixed it there, although in a [slightly different|https://github.com/apache/cassandra/pull/1045/files#diff-c801dfb00bc39ce5bf66a5876779350dba35def185588d13f5e492b6d79212f7R77] way. Basically, the background queries are from the driver control connections, which we don't actually use for {{ClientResourceLimitsTest}}. My patch for 16663 is obviously only for trunk, but you could use it here, and then I could just rebase my stuff and pick it up when this issue resolves. I think we can avoid relaxing the assertion to GTE...;;;","23/Jun/21 17:29;adelapena;Indeed getting rid of the driver's interferences without relaxing the assertion sounds like the way to go. Also it seems to fix the occasional failures in other tests in {{ClientResourceLimitsTest}}, like [these ones|https://app.circleci.com/pipelines/github/adelapena/cassandra/612/workflows/09dec5a9-2ac4-4595-b455-fce14aa381cf/jobs/6010]. Unfortunately {{testQueryUpdatesConcurrentMetricsUpdate}} seems [flaky|https://app.circleci.com/pipelines/github/adelapena/cassandra/613/workflows/693bbc01-eae8-4f56-8298-2811d72892d2/jobs/6015] with both approaches, but we can deal with that in a separate ticket if we think that it's not related.;;;","25/Jun/21 20:11;adelapena;Using the {{requireNetworkWithoutDriver}} method suggested in CASSANDRA-16663 in 4.0.0 definitely solves all the failures but the one in {{testQueryUpdatesConcurrentMetricsUpdate}}, as it can be seen in [this multiplexer run|https://app.circleci.com/pipelines/github/adelapena/cassandra/614/workflows/974352fc-a2d7-453e-ae07-002280b9910e/jobs/6020].

Regarding the failure in {{testQueryUpdatesConcurrentMetricsUpdate}}, I think that the creation of the startup message of {{SimpleClient}} is messing with the metrics. We can simply use {{spinAssertEquals}}/{{Awaitility}} to wait until the moment the startup message finishes and the client metric goes back to zero, as it's done [this way|https://github.com/adelapena/cassandra/commit/c0caca66eae1dd388a15cf415ffc25fc37190d2d]. With that change the test survives [5000 runs|https://app.circleci.com/pipelines/github/adelapena/cassandra/623/workflows/b69efc53-0e20-4466-a90a-78f162dde54b/jobs/6097].;;;","28/Jun/21 07:49;bereng;I agree with you both filtering out driver noise is a superior solution. Also if [~adelapena] managed to get 5K runs for the other failure lurking here then I say +1 to everything after reviewing it and let [~adelapena] commit it. There's no point in me duplicating the effort of building the same PR etc. ;;;","28/Jun/21 17:16;maedhroz;+1 on the [16758-4.0.0-review-caleb|https://github.com/adelapena/cassandra/compare/16758-4.0.0-review-caleb] branch;;;","29/Jun/21 03:41;bereng;Andres is OOO but back tomorrow so I'd rather wait for him to be around than hijack his PR in case he had some outstanding work we're not aware of.;;;","30/Jun/21 09:49;bereng;Good the concurrent update [failed|http://https://ci-cassandra.apache.org/job/Cassandra-4.0.0-test-compression/37/jdk=jdk_11_latest,label=cassandra,split=7/testReport/junit/org.apache.cassandra.transport/ClientResourceLimitsTest/testQueryUpdatesConcurrentMetricsUpdate_compression/] today but this should fix it. 2 birds with one stone.;;;","30/Jun/21 10:22;adelapena;It's good to know that we have a real Jenkins failure for the last fix :)

I don't have any outstanding work besides some trivial warning fixes. The final patch is [here|https://github.com/adelapena/cassandra/commit/506ebff98860a25f76d936a1a1b67b5509189cd4], I'm running the multiplexer [one last time|https://app.circleci.com/pipelines/github/adelapena/cassandra/624/workflows/3b758554-0e14-41e7-847b-01da79daf27f] just in case before committing.;;;","30/Jun/21 10:36;bereng;sgtm +1;;;","30/Jun/21 11:30;adelapena;Committed to 4.0.0 as [636e8b99226703d643cc4b30e5c30a64ce830434|https://github.com/apache/cassandra/commit/636e8b99226703d643cc4b30e5c30a64ce830434] and merged up to [4.0|https://github.com/apache/cassandra/commit/07803c8cd22d6918ef9bdbb6653cb90f45291ed9] and [trunk|https://github.com/apache/cassandra/commit/700c290350c86444c81e3ab3fa4c7988050ac82f].;;;","30/Jun/21 14:48;bereng;Thx [~adelapena];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix test testNullClusteringValues - org.apache.cassandra.distributed.upgrade.CompactStorage3to4UpgradeTest,CASSANDRA-16756,13385251,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,22/Jun/21 20:05,01/Aug/21 11:33,13/Jul/23 08:40,22/Jun/21 22:29,4.0,4.0.1,4.0-rc2,,,,,Test/dtest/java,,,,0,,,"https://app.circleci.com/pipelines/github/dcapwell/cassandra/951/workflows/d99b4bd4-935f-47fe-aaa2-85adc6b2bea0/jobs/5831

{code}
java.lang.RuntimeException: java.lang.RuntimeException: org.apache.cassandra.exceptions.InvalidRequestException: DROP COMPACT STORAGE is disabled. Enable in cassandra.yaml to use.
	at org.apache.cassandra.distributed.impl.IsolatedExecutor.waitOn(IsolatedExecutor.java:209)
	at org.apache.cassandra.distributed.impl.IsolatedExecutor.lambda$sync$7(IsolatedExecutor.java:112)
	at org.apache.cassandra.distributed.impl.AbstractCluster.schemaChange(AbstractCluster.java:646)
	at org.apache.cassandra.distributed.impl.AbstractCluster.schemaChange(AbstractCluster.java:630)
	at org.apache.cassandra.distributed.impl.AbstractCluster.schemaChange(AbstractCluster.java:613)
	at org.apache.cassandra.distributed.upgrade.CompactStorage3to4UpgradeTest.lambda$testNullClusteringValues$1(CompactStorage3to4UpgradeTest.java:52)
	at org.apache.cassandra.distributed.upgrade.UpgradeTestBase$TestCase.run(UpgradeTestBase.java:187)
	at org.apache.cassandra.distributed.upgrade.CompactStorage3to4UpgradeTest.testNullClusteringValues(CompactStorage3to4UpgradeTest.java:59)
Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.InvalidRequestException: DROP COMPACT STORAGE is disabled. Enable in cassandra.yaml to use.
	at org.apache.cassandra.distributed.impl.IsolatedExecutor.waitOn(IsolatedExecutor.java:209)
	at org.apache.cassandra.distributed.impl.IsolatedExecutor.lambda$sync$5(IsolatedExecutor.java:109)
	at org.apache.cassandra.distributed.impl.Coordinator.executeWithResult(Coordinator.java:69)
	at org.apache.cassandra.distributed.api.ICoordinator.execute(ICoordinator.java:32)
	at org.apache.cassandra.distributed.impl.AbstractCluster.lambda$schemaChange$9(AbstractCluster.java:643)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:83)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.cassandra.exceptions.InvalidRequestException: DROP COMPACT STORAGE is disabled. Enable in cassandra.yaml to use.
	at org.apache.cassandra.cql3.statements.AlterTableStatement.announceMigration(AlterTableStatement.java:295)
	at org.apache.cassandra.cql3.statements.SchemaAlteringStatement.execute(SchemaAlteringStatement.java:123)
	at org.apache.cassandra.distributed.impl.Coordinator.executeInternal(Coordinator.java:107)
	at org.apache.cassandra.distributed.impl.Coordinator.lambda$executeWithResult$0(Coordinator.java:69)
{code}",,dcapwell,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jun 23 13:22:20 UTC 2021,,,,,,,All,,,,"0|z0s72o:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0-rc2,,https://github.com/apache/cassandra/commit/50f851c2a02dc10d5958eb0afa33d6c87989cc84,,,,,,,,,local and circle,,,,,"22/Jun/21 20:52;e.dimitrova;The [fix |https://the-asf.slack.com/archives/CK23JSY2K/p1624392906239600?thread_ts=1624392530.239400&cid=CK23JSY2K] you posted in Slack is the one we need here. I also tested it locally. +1, thank you;;;","22/Jun/21 22:24;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|cassandra-4.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16756-cassandra-4.0-D4B9EA1B-989B-48D4-B0AC-2FEDDBF279A5]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16756-cassandra-4.0-D4B9EA1B-989B-48D4-B0AC-2FEDDBF279A5]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/866/]|
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16756-trunk-D4B9EA1B-989B-48D4-B0AC-2FEDDBF279A5]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16756-trunk-D4B9EA1B-989B-48D4-B0AC-2FEDDBF279A5]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/867/]|
;;;","23/Jun/21 00:17;e.dimitrova;I think we need the patch in 4.0.0, too? ;;;","23/Jun/21 00:31;brandon.williams;+1 for 4.0.0,  this is tagged rc2.;;;","23/Jun/21 13:22;e.dimitrova;Backported by [~blerer]. Thank you!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky o.a.c.distributed.test.SchemaTest,CASSANDRA-16754,13385147,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,adelapena,adelapena,22/Jun/21 11:38,01/Aug/21 13:32,13/Jul/23 08:40,22/Jun/21 14:09,3.0.25,3.11.11,4.0,4.0-rc2,,,,Test/dtest/java,,,,0,,,"The JVM dtest {{org.apache.cassandra.distributed.test.SchemaTest}} is flaky:
 [https://ci-cassandra.apache.org/job/Cassandra-4.0.0/34/testReport/junit/org.apache.cassandra.distributed.test/SchemaTest/readRepairWithCompaction_2/]
{code:java}
Error Message
FSWriteError in /home/cassandra/cassandra/tmp/dtests5018452609443646984/node2/commitlog/CommitLog-7-1624286958980.log
Stacktrace
java.lang.RuntimeException: FSWriteError in /home/cassandra/cassandra/tmp/dtests5018452609443646984/node2/commitlog/CommitLog-7-1624286958980.log
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:582)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: FSWriteError in /home/cassandra/cassandra/tmp/dtests5018452609443646984/node2/commitlog/CommitLog-7-1624286958980.log
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:256)
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:273)
	at org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager.handleReplayedSegment(AbstractCommitLogSegmentManager.java:349)
	at org.apache.cassandra.db.commitlog.CommitLog.recoverSegmentsOnDisk(CommitLog.java:178)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:508)
Caused by: java.nio.file.NoSuchFileException: /home/cassandra/cassandra/tmp/dtests5018452609443646984/node2/commitlog/CommitLog-7-1624286958980.log
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:249)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105)
	at java.base/java.nio.file.Files.delete(Files.java:1142)
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:250)
{code}
Although it doesn't fail frequently on CI it's quite easy to reproduce it locally.

I think the failure is caused by the two tests on the class not waiting for the future returned by {{IInstance#shutdown()}}.",,adelapena,bereng,,,,,,,,,,,,,,"adelapena opened a new pull request #1079:
URL: https://github.com/apache/cassandra/pull/1079


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Jun/21 11:42;githubbot;600","asfgit closed pull request #1079:
URL: https://github.com/apache/cassandra/pull/1079


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Aug/21 13:32;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Jun 22 14:07:09 UTC 2021,,,,,,,All,,,,"0|z0s6fk:",9223372036854775807,,,,adelapena,bereng,,,Low,,3.0.25,,https://github.com/apache/cassandra/commit/f329c63d86e8e123be360004fb61bf6c08f8b01a,,,,,,,,,Flaky test,,,,,"22/Jun/21 12:01;adelapena;[PR|https://github.com/apache/cassandra/pull/1079] and CI results with a few multiplexer runs:

* [j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/609/workflows/ca0bc153-20ac-41f4-9919-d3b295c63fb2]
* [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/609/workflows/475f8ec9-3fd3-4118-9809-061cfb8a5fbe];;;","22/Jun/21 12:10;bereng;+1 Assuming the j11 CI runs green;;;","22/Jun/21 14:07;adelapena;Thanks for the review, CI for j11 is also green.

Merged to 3.0 as [f329c63d86e8e123be360004fb61bf6c08f8b01a|https://github.com/apache/cassandra/commit/f329c63d86e8e123be360004fb61bf6c08f8b01a] and merged up to [3.11|https://github.com/apache/cassandra/commit/7486302d3ae4eac334e6669d7d4038b48fa6cce5], [4.0.0|https://github.com/apache/cassandra/commit/b555eeaf3d7f111d39faaf8bb31bed40936b6841], [4.0|https://github.com/apache/cassandra/commit/eda1aa2f188930402b3e9918ad354f31c780c67b] and [trunk|https://github.com/apache/cassandra/commit/3ed4a0f9ca219378b90e4632342203275f04da1f].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade lz4-java to 1.8.0 to add RH6 support back,CASSANDRA-16753,13385017,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,21/Jun/21 21:32,01/Nov/22 20:09,13/Jul/23 08:40,23/Jun/21 20:13,4.0.1,4.1,4.1-alpha1,,,,,Local/SSTable,,,,0,,,"After upgrading lz4-java the native version is disabled on RHEL 6 hosts as the libc there isn’t new enough; this was reported to lz4-java in https://github.com/lz4/lz4-java/issues/163 and they released 1.8.0 (https://github.com/lz4/lz4-java/releases/tag/1.8.0) to fix this issue, we should upgrade to add RHEL 6 support back.",,brandon.williams,dcapwell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-15941,,,,CASSANDRA-18002,,,,,,,,,,,,,,,,,,,"23/Jun/21 17:29;dcapwell;Screen Shot 2021-06-23 at 10.28.30 AM.png;https://issues.apache.org/jira/secure/attachment/13027205/Screen+Shot+2021-06-23+at+10.28.30+AM.png",,,,,1.0,dcapwell,,,,,,,,,,,,,Degradation -> Performance Bug/Regression,,,,,,,,Low Hanging Fruit,Performance Regression Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jun 23 18:45:21 UTC 2021,,,,,,,All,,,,"0|z0s5mo:",9223372036854775807,,,,brandon.williams,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/26e21bb5766d2957a529fa5a8216e62ad5c96214,,,,,,,,,unit and cluster testing,,,,,"23/Jun/21 17:29;dcapwell;Finished testing; unit and regression tests look clean, and running on a cluster I see (by profiling) that JNI is used.;;;","23/Jun/21 17:31;brandon.williams;+1;;;","23/Jun/21 18:45;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|cassandra-4.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16753-cassandra-4.0-535DBC46-8F39-483E-8F90-EAEDFA6B946A]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16753-cassandra-4.0-535DBC46-8F39-483E-8F90-EAEDFA6B946A]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/869/]|
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16753-trunk-535DBC46-8F39-483E-8F90-EAEDFA6B946A]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16753-trunk-535DBC46-8F39-483E-8F90-EAEDFA6B946A]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/870/]|
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Python dtest queries executed after restarting a node might fail,CASSANDRA-16752,13384589,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,adelapena,adelapena,18/Jun/21 19:52,21/Jun/21 15:46,13/Jul/23 08:40,21/Jun/21 15:37,4.0,4.0-rc2,,,,,,Test/dtest/python,,,,0,,,"We have multiple dtest failures in queries with CL=ALL that are executed right after restarting a node:
 * [test_14330|https://ci-cassandra.apache.org/job/Cassandra-4.0.0/26/testReport/dtest.consistency_test/TestConsistency/test_14330/]
 * [test_multiple_repair|https://ci-cassandra.apache.org/job/Cassandra-4.0.0/29/testReport/dtest.repair_tests.incremental_repair_test/TestIncRepair/test_multiple_repair/]
 * [test_multiple_repair(offheap)|https://ci-cassandra.apache.org/job/Cassandra-4.0.0/26/testReport/dtest-offheap.repair_tests.incremental_repair_test/TestIncRepair/test_multiple_repair/]

The error is a server-side failure telling that there aren't enough replicas alive to achieve the required consistency level:
{code:java}
tools/assertions.py:182: in assert_all
    res = session.execute(simple_query) if timeout is None else session.execute(simple_query, timeout=timeout)
../venv/src/cassandra-driver/cassandra/cluster.py:2618: in execute
    return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile, paging_state, host, execute_as).result()
...
E           cassandra.Unavailable: Error from server: code=1000 [Unavailable exception] message=""Cannot achieve consistency level ALL"" info={'consistency': 'ALL', 'required_replicas': 2, 'alive_replicas': 1}
{code}
The Jenkins failure in {{test_14330}} can be reproduced in the multiplexer, although it requires many iterations:
 * [https://app.circleci.com/pipelines/github/adelapena/cassandra/600/workflows/2f1b7455-1217-4553-985a-a255fe98ba47/jobs/5784]
 * [https://app.circleci.com/pipelines/github/adelapena/cassandra/600/workflows/2f1b7455-1217-4553-985a-a255fe98ba47/jobs/5786]

As a hint, this same test [survives the multiplexer|https://app.circleci.com/pipelines/github/adelapena/cassandra/605/workflows/aba5e7a6-c988-40d9-ab56-7848e711b5e1] if we add [a short sleep|https://github.com/adelapena/cassandra-dtest/commit/28ca11bf31db4c836e9c34500d18cbb9316e3cca] right after restarting the node.

I think that the reason for the failure is that CCM is no properly waiting for the propagation of the node status. So, the session uses a not-restarted nodes to run the query with CL=ALL before that node actually sees the restarted node. The parameter {{wait_other_notice}} in {{node.start}} should guarantee that this doesn't happen, but I suspect that it isn't working as expected. When using the {{wait_other_notice}} option on node start, the [{{node.watch_log_for_alive}}|https://github.com/riptano/ccm/blob/358c06781c4a8b85dcfca49449232b7405dacc0c/ccmlib/node.py#L657-L664] function looks for the regexp {{%s.* now UP}} in the logs of the other nodes, to ensure that they consider that node as up. However, that expression is matched by two different log entries emitted on log restart:
{code:java}
Node /127.0.0.2:7000 has restarted, now UP
...
Node /127.0.0.2:7000 is now UP
{code}
The first message is emitted by [{{Gossiper.handleMajorStateChange}}|https://github.com/apache/cassandra/blob/cassandra-4.0.0/src/java/org/apache/cassandra/gms/Gossiper.java#L1313], while the second message is emitted by [{{Gossiper.realMarkAlive}}|https://github.com/apache/cassandra/blob/cassandra-4.0.0/src/java/org/apache/cassandra/gms/Gossiper.java#L1263]. I think that we need to wait for the second one, while CCM is waiting only for the first one.

Indeed, we can easily reproduce the failure in any of the affected dtests by adding a sleep at the beginning of {{Gossiper.realMarkAlive}}. We can get around the failure if we manually modify the test to wait for the right log message, as it's done [here|https://github.com/adelapena/cassandra-dtest/commit/7355be7dd94c91c44b78bd2ccfa1c731a00d6a63]. With that wait the test [survives the multiplexer rounds|https://app.circleci.com/pipelines/github/adelapena/cassandra/605/workflows/6ec189fc-4701-4a27-a7af-382a6c53dd0d].

This problem seems quite unlikely to happen since the time window is very short, but we have seen it in CI and it affects multiple Python dtests.",,adelapena,brandon.williams,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,DTest,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Jun 21 15:37:56 UTC 2021,,,,,,,All,,,,"0|z0s2zk:",9223372036854775807,,,,brandon.williams,,,,Normal,,NA,,https://github.com/riptano/ccm/commit/ce612ea71587bf263ed513cb8f8d5dfcf7c8dadb,,,,,,,,,Some of the affected tests should survive the multiplexer.,,,,,"21/Jun/21 15:33;adelapena;This [PR for CCM|https://github.com/riptano/ccm/pull/733] fixes the regular expression to wait only for the log message emitted by {{Gossiper.realMarkAlive}}. A CircleCI round multiplexing {{consistency_test.py::TestConsistency::test_14330}} shows that this test doesn't fail anymore when using that regex:
* [j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/606/workflows/eb7524e9-5534-4130-9121-60a1ce4f6741]
* [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/606/workflows/86829803-7bd8-4abf-976d-4ccee0633577]

The fix should also prevent similar failures in another similar tests around, for example the other six tests in {{consistency_test.py}} running CQL queries right after restarting a node.;;;","21/Jun/21 15:37;brandon.williams;I merged the CCM PR, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky AlibabaCloudSnitchTest,CASSANDRA-16750,13384478,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,18/Jun/21 08:11,27/May/22 19:25,13/Jul/23 08:40,21/Jun/21 06:42,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/unit,,,,0,,,"Flaky test 

Test error

{noformat}
Error Message

Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.

Stacktrace

junit.framework.AssertionFailedError: Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.
	at jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.util.Vector.forEach(Vector.java:1388)
	at jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.util.Vector.forEach(Vector.java:1388)
	at jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.util.Vector.forEach(Vector.java:1388)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at jdk.scripting.nashorn.scripts/jdk.nashorn.internal.scripts.Script$Recompilation$30$\^eval\_$cu1$restOf/0x00000008403db840.:program(<eval>:13)
	at jdk.scripting.nashorn/jdk.nashorn.internal.runtime.ScriptFunctionData.invoke(ScriptFunctionData.java:655)
	at jdk.scripting.nashorn/jdk.nashorn.internal.runtime.ScriptFunction.invoke(ScriptFunction.java:513)
	at jdk.scripting.nashorn/jdk.nashorn.internal.runtime.ScriptRuntime.apply(ScriptRuntime.java:527)
	at jdk.scripting.nashorn/jdk.nashorn.api.scripting.NashornScriptEngine.evalImpl(NashornScriptEngine.java:456)
	at jdk.scripting.nashorn/jdk.nashorn.api.scripting.NashornScriptEngine.evalImpl(NashornScriptEngine.java:413)
	at jdk.scripting.nashorn/jdk.nashorn.api.scripting.NashornScriptEngine.evalImpl(NashornScriptEngine.java:409)
	at jdk.scripting.nashorn/jdk.nashorn.api.scripting.NashornScriptEngine.eval(NashornScriptEngine.java:162)
	at java.scripting/javax.script.AbstractScriptEngine.eval(AbstractScriptEngine.java:264)
	at jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.util.Vector.forEach(Vector.java:1388)
	at jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)

{noformat}


Log error:
{noformat}
AlibabaCloudSnitchTest.BeforeFirstTest failure was

ERROR [COMMIT-LOG-ALLOCATOR] 2021-06-05 00:41:36,750 Exiting due to error while processing commit log during initialization.
java.lang.RuntimeException: Tried to hard link to file that does not exist build/test/cassandra/commitlog/CommitLog-7-1622853696662.log
	at org.apache.cassandra.io.util.FileUtils.createHardLink(FileUtils.java:184)
	at org.apache.cassandra.db.commitlog.CommitLogSegmentManagerCDC.createSegment(CommitLogSegmentManagerCDC.java:149)
	at org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager$1.runMayThrow(AbstractCommitLogSegmentManager.java:115)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)


ref: https://nightlies.apache.org/cassandra/cassandra-4.0.0/Cassandra-4.0.0-test-cdc/6/Cassandra-4.0.0-test-cdc/jdk=jdk_1.8_latest,label=cassandra,split=6/build/test/logs/cdc/TEST-org.apache.cassandra.locator.AlibabaCloudSnitchTest.log.xz
{noformat}
",,bereng,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Jun 21 04:41:55 UTC 2021,,,,,,,All,,,,"0|z0s2aw:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/a4af55fe2af836904004c4db1aa6a87cea18ee92,,,,,,,,,See PR,,,,,"18/Jun/21 09:22;bereng;CDC creates a hard link on {{[CommitLogSegmentManagerCDC.createSegment()|https://github.com/apache/cassandra/blob/cassandra-4.0.0/src/java/org/apache/cassandra/db/commitlog/CommitLogSegmentManagerCDC.java#L149]}} but this happens in an async operation originating at {{AbstractCommitLogSegmentManager.start()}}. We can see [here|https://github.com/apache/cassandra/pull/1074/files#diff-b5c6007ec3a4b31965b4dc10e8c8c50766237f1ce8ac88011035b91215060fc8R51] the test calls {{cleanup()}} just after staring the commit log service. This can remove files from under the commit log's feet making the hardlinking fail. We need to wait for completion.

It can be repro'd easily in a 1K circle run and the fix indeed passes now;;;","18/Jun/21 15:43;e.dimitrova;Good catch, +1. I believe this is a trick used also in other tests.;;;","21/Jun/21 04:41;bereng;I went over over all other uses before moving this one into review and I didn't see more uses of it, but happy to be corrected if you find any.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ALTER ... ADD can increase the number of SSTables being read,CASSANDRA-16737,13383729,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,blerer,blerer,14/Jun/21 13:20,16/Mar/22 16:16,13/Jul/23 08:40,01/Jul/21 12:17,3.11.11,4.0.1,,,,,,CQL/Semantics,,,,0,,,"With the following SSTables:
{code:java}
CREATE TABLE my_table (pk int, ck int, v1 int, PRIMARY KEY(pk, ck))

INSERT INTO my_table (pk, ck, v1) VALUES (1, 1, 1) USING TIMESTAMP 1000;
--> flush()
INSERT INTO my_table (pk, ck, v1) VALUES (1, 1, 2) USING TIMESTAMP 2000;
--> flush()
INSERT INTO my_table  (pk, ck, v1) VALUES (1, 1, 3) USING TIMESTAMP 3000
--> flush()
{code}
the following query:
{code:java}
SELECT pk, ck, v1 FROM my_table WHERE pk = 1 AND ck = 1{code}
will only read the third SSTable.

If we add a column to the table (e.g. {{ALTER TABLE my_table ADD v2 int}}) and rerun the query, the query will read the 3 SSTables.

The reason for this behavior is due to the fact that C* is trying to read all the {{fetched}} columns to ensure that it will return a row if at least one of its column is non null.

In practice for CQL tables, C* does not need to fetch all columns if the row contains a primary key liveness as it is enough to guaranty that the row exists. By consequence, even after the addition of the new column C* should read only the third SSTable.",,blerer,e.dimitrova,maedhroz,mck,,,,,,,,,,,,"blerer opened a new pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Jun/21 09:57;githubbot;600","blerer opened a new pull request #1084:
URL: https://github.com/apache/cassandra/pull/1084


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Jun/21 09:58;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083#discussion_r660078145



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -1033,7 +1033,15 @@ private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filte
 
         SearchIterator<Clustering, Row> searchIter = result.searchIterator(columnFilter(), false);
 
-        PartitionColumns columns = columnFilter().fetchedColumns();
+        // According to the CQL semantics a row exists if at least one of its columns is not null (including the primary key columns).
+        // Having the queried columns not null is unfortunately not enough to prove that a row exists has some column deletion

Review comment:
       `// Having the queried columns not null is unfortunately not enough to prove that a row exists because some column deletion`

##########
File path: test/distributed/org/apache/cassandra/distributed/test/SinglePartitionReadCommandTest.java
##########
@@ -144,4 +144,47 @@ public void testPartitionWithStaticColumnsOnlyOnOneNodeAndColumnDeletionOnTheOth
             assertRows(cluster.coordinator(2).execute(withKeyspace(""SELECT DISTINCT s1 FROM %s.tbl WHERE pk=2""), ConsistencyLevel.ALL));
         }
     }
+
+    @Test
+    public void testNonCompactTableWithEmptyRowOnBothNodes() throws Throwable

Review comment:
       I think you meant empty column, not really a row? 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jun/21 01:21;githubbot;600","blerer commented on a change in pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083#discussion_r660327845



##########
File path: test/distributed/org/apache/cassandra/distributed/test/SinglePartitionReadCommandTest.java
##########
@@ -144,4 +144,47 @@ public void testPartitionWithStaticColumnsOnlyOnOneNodeAndColumnDeletionOnTheOth
             assertRows(cluster.coordinator(2).execute(withKeyspace(""SELECT DISTINCT s1 FROM %s.tbl WHERE pk=2""), ConsistencyLevel.ALL));
         }
     }
+
+    @Test
+    public void testNonCompactTableWithEmptyRowOnBothNodes() throws Throwable

Review comment:
       Both nodes have an empty row: a row with only primary key. The column deletion is simply used to create the empty row. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jun/21 06:50;githubbot;600","blerer commented on a change in pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083#discussion_r660330824



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -1033,7 +1033,15 @@ private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filte
 
         SearchIterator<Clustering, Row> searchIter = result.searchIterator(columnFilter(), false);
 
-        PartitionColumns columns = columnFilter().fetchedColumns();
+        // According to the CQL semantics a row exists if at least one of its columns is not null (including the primary key columns).
+        // Having the queried columns not null is unfortunately not enough to prove that a row exists has some column deletion

Review comment:
       It was a typo I mean `as` and not `has`




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jun/21 06:55;githubbot;600","blerer commented on a change in pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083#discussion_r660327845



##########
File path: test/distributed/org/apache/cassandra/distributed/test/SinglePartitionReadCommandTest.java
##########
@@ -144,4 +144,47 @@ public void testPartitionWithStaticColumnsOnlyOnOneNodeAndColumnDeletionOnTheOth
             assertRows(cluster.coordinator(2).execute(withKeyspace(""SELECT DISTINCT s1 FROM %s.tbl WHERE pk=2""), ConsistencyLevel.ALL));
         }
     }
+
+    @Test
+    public void testNonCompactTableWithEmptyRowOnBothNodes() throws Throwable

Review comment:
       Both nodes have an empty row: a row with only primary key. The column deletion is simply used to create the empty row. 

##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -1033,7 +1033,15 @@ private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filte
 
         SearchIterator<Clustering, Row> searchIter = result.searchIterator(columnFilter(), false);
 
-        PartitionColumns columns = columnFilter().fetchedColumns();
+        // According to the CQL semantics a row exists if at least one of its columns is not null (including the primary key columns).
+        // Having the queried columns not null is unfortunately not enough to prove that a row exists has some column deletion

Review comment:
       It was a typo I mean `as` and not `has`




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jun/21 13:51;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083#discussion_r660078145



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -1033,7 +1033,15 @@ private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filte
 
         SearchIterator<Clustering, Row> searchIter = result.searchIterator(columnFilter(), false);
 
-        PartitionColumns columns = columnFilter().fetchedColumns();
+        // According to the CQL semantics a row exists if at least one of its columns is not null (including the primary key columns).
+        // Having the queried columns not null is unfortunately not enough to prove that a row exists has some column deletion

Review comment:
       `// Having the queried columns not null is unfortunately not enough to prove that a row exists because some column deletion`

##########
File path: test/distributed/org/apache/cassandra/distributed/test/SinglePartitionReadCommandTest.java
##########
@@ -144,4 +144,47 @@ public void testPartitionWithStaticColumnsOnlyOnOneNodeAndColumnDeletionOnTheOth
             assertRows(cluster.coordinator(2).execute(withKeyspace(""SELECT DISTINCT s1 FROM %s.tbl WHERE pk=2""), ConsistencyLevel.ALL));
         }
     }
+
+    @Test
+    public void testNonCompactTableWithEmptyRowOnBothNodes() throws Throwable

Review comment:
       I think you meant empty column, not really a row? 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jun/21 13:52;githubbot;600","maedhroz commented on a change in pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083#discussion_r660999048



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -692,7 +692,7 @@ private UnfilteredRowIterator queryMemtableAndDiskInternal(ColumnFamilyStore cfs
          *      we can't guarantee an older sstable won't have some elements that weren't in the most recent sstables,
          *      and counters are intrinsically a collection of shards and so have the same problem).
          */
-        if (clusteringIndexFilter() instanceof ClusteringIndexNamesFilter && !queriesMulticellType())
+        if (clusteringIndexFilter() instanceof ClusteringIndexNamesFilter && !metadata().isCounter() && !queriesMulticellType())

Review comment:
       Counters were mentioned in the comment but not in the conditional :D




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jun/21 22:13;githubbot;600","maedhroz commented on a change in pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083#discussion_r661005855



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -1033,7 +1033,15 @@ private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filte
 
         SearchIterator<Clustering, Row> searchIter = result.searchIterator(columnFilter(), false);
 
-        PartitionColumns columns = columnFilter().fetchedColumns();
+        // According to the CQL semantics a row exists if at least one of its columns is not null (including the primary key columns).
+        // Having the queried columns not null is unfortunately not enough to prove that a row exists has some column deletion
+        // for the queried columns can exist on another node.
+        // For CQL tables it is enough to have the primary key liveness and the queried columns as the primary key liveness prove that
+        // the row exists even if all the other columns are deleted.
+        // COMPACT tables do not have primary key liveness by consequence we are forced to get  all the fetched columns to ensure that

Review comment:
       ```suggestion
           // COMPACT tables do not have primary key liveness, and by consequence we are forced to get all the fetched columns to ensure that
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jun/21 22:29;githubbot;600","maedhroz commented on a change in pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083#discussion_r661009982



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -870,9 +870,9 @@ public void onPartitionClose()
 
     private boolean queriesMulticellType()
     {
-        for (ColumnDefinition column : columnFilter().fetchedColumns())
+        for (ColumnDefinition column : columnFilter().queriedColumns())
         {
-            if (column.type.isMultiCell() || column.type.isCounter())
+            if (column.type.isMultiCell())

Review comment:
       This and the change above are safe because we can't even issue INSERT statements against counter tables? (Might be useful to briefly comment on that somewhere.)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jun/21 22:39;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083#discussion_r661050470



##########
File path: test/unit/org/apache/cassandra/cql3/KeyCacheCqlTest.java
##########
@@ -262,7 +262,7 @@ private void test2iKeyCachePaths() throws Throwable
         long hits = metrics.hits.getCount();
         long requests = metrics.requests.getCount();
         assertEquals(0, hits);
-        assertEquals(210, requests);
+        assertEquals(206, requests);

Review comment:
       @blerer, knowing you I am pretty sure you checked this formula, also the number goes down in the right direction, but we talked with @maedhroz that it would be great to add a comment on it, how did we receive this number




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;30/Jun/21 00:35;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #1084:
URL: https://github.com/apache/cassandra/pull/1084#discussion_r660836308



##########
File path: test/unit/org/apache/cassandra/cql3/validation/miscellaneous/SSTablesIteratedTest.java
##########
@@ -1333,7 +1358,9 @@ public void testNonCompactTableWithMultipleRegularColumnsAndColumnDeletion() thr
 
         executeAndCheck(""SELECT * FROM %s WHERE pk = 1"", 3, row(1, null, 1));
         executeAndCheck(""SELECT v1, v2 FROM %s WHERE pk = 1"", 3, row((Integer) null, 1));
-        executeAndCheck(""SELECT v1 FROM %s WHERE pk = 1"", 3, row((Integer) null));
+        // As the primary key liveness is found on the second SSTable, we can stop there as it it enough to ensure

Review comment:
       super nit, typo: it is enough that the row exists




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;30/Jun/21 00:37;githubbot;600","blerer commented on a change in pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083#discussion_r661415716



##########
File path: test/unit/org/apache/cassandra/cql3/KeyCacheCqlTest.java
##########
@@ -262,7 +262,7 @@ private void test2iKeyCachePaths() throws Throwable
         long hits = metrics.hits.getCount();
         long requests = metrics.requests.getCount();
         assertEquals(0, hits);
-        assertEquals(210, requests);
+        assertEquals(206, requests);

Review comment:
       The expected number for queries without indices = previous number of request + Sum for each request of (1 (the row is only in one sstable) + number of bloom filter false positive for the request)
   
   For indices queries you have to add the index query + the number of bloom filter false positive for index query
   
   I will try to find a way to make it explicite in the test. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;30/Jun/21 12:29;githubbot;600","blerer commented on a change in pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083#discussion_r661415716



##########
File path: test/unit/org/apache/cassandra/cql3/KeyCacheCqlTest.java
##########
@@ -262,7 +262,7 @@ private void test2iKeyCachePaths() throws Throwable
         long hits = metrics.hits.getCount();
         long requests = metrics.requests.getCount();
         assertEquals(0, hits);
-        assertEquals(210, requests);
+        assertEquals(206, requests);

Review comment:
       The expected number for queries without indices = previous number of request + Sum for each request of (1 (the row is only in one sstable) + number of bloom filter false positive for the request)
   
   I will try to find a way to make it explicite in the test. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;30/Jun/21 16:32;githubbot;600","smiklosovic closed pull request #1083:
URL: https://github.com/apache/cassandra/pull/1083


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:16;githubbot;600","smiklosovic closed pull request #1084:
URL: https://github.com/apache/cassandra/pull/1084


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:16;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,9600,,,0,9600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jul 01 12:17:49 UTC 2021,,,,,,,All,,,,"0|z0rxow:",9223372036854775807,,,,e.dimitrova,maedhroz,,,Normal,,3.0.0,,https://github.com/apache/cassandra/commit/3aa49b9ff803adba85261b983ce6e56ae5c52479,,,,,,,,,The patch add several tests and relies on the tests previously added in CASSANDRA-16671,,,,,"28/Jun/21 07:52;blerer;|| Branche || CI ||
|[3.11|https://github.com/apache/cassandra/pull/1083] | [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/172/workflows/73c2be44-4d53-4b4e-b073-98d461d318de] |
|[4.0|https://github.com/apache/cassandra/pull/1084] | [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/174/workflows/4305a452-286c-47c3-be7b-16a3556900d4], [j11|https://app.circleci.com/pipelines/github/blerer/cassandra/174/workflows/9fd2044e-da79-40c5-be3f-bdbd84a9e2c7] |

The patches rely on the fact that if a row has some primary key liveness then the row is guaranty to exist even if some of the non-primary key columns are deleted later on by deletions coming from other nodes. By consequence, when reading SSTables in a time ordered way once C* find a row with a primary key liveness and all the queried columns it can safely stop reading extra SSTables.
That approach will not work for {{COMPACT}} tables has they do not have a primary key liveness information. Due to that for COMPACT tables C* will still need to retrieve all the fetched columns to ensure that it can returns the correct results.
That approach will also not work for scenarios where the row has been inserted through only {{UPDATE}} statements as those statements do not set the primary key liveness information.   ;;;","28/Jun/21 18:39;e.dimitrova;I wanted to help here so I will take a look but [~jlewandowski] -and- [~adelapena] might also want to look at it as they were reviewing the previous ticket. Also, I am going on vacation on Wednesday so no need to be pending on me in case we don't finish working on it async tomorrow. 

EDIT: It was [~maedhroz] reviewing the previous one, [~jlewandowski] and [~adelapena] looked at a different one, my bad.;;;","29/Jun/21 23:01;maedhroz;Good find! Both branches LGTM, but I've made some very minor comments inline in the 3.11 PR.;;;","30/Jun/21 00:39;e.dimitrova;+1 Great finding and elegant solution. I love the test coverage! I left just one request for comment and some typo but this is really super nit... Thank you [~blerer]!

PS CI failures don't look related. I think we need to check and maybe raise a ticket if needed for the 3.11 failure.;;;","01/Jul/21 12:14;blerer;[~e.dimitrova], [~maedhroz] I modified the KeyCache tests to clarify from where were coming the expected numbers.
Thanks a lot for the reviews.;;;","01/Jul/21 12:17;blerer;Committed into 3.11 at 3aa49b9ff803adba85261b983ce6e56ae5c52479 and merged into 4.0 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Adding columns via ALTER TABLE can generate corrupt sstables,CASSANDRA-16735,13383482,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,11/Jun/21 17:51,14/Oct/21 12:11,13/Jul/23 08:40,21/Jun/21 14:00,3.0.25,3.11.11,4.0,4.0-rc2,,,,Consistency/Repair,Local/SSTable,,,0,,,"This is similar to CASSANDRA-13004 and was caused by CASSANDRA-15899

Basically the column placeholders introduced in 15899 can get read-repaired in to the memtable and later flushed to disk and in some cases this can conflict with the actual column (if the actual column is a collection for example) and cause CorruptSSTableExceptions.

Fix is probably to just revert 15899, at least until if and when we find a solution that we can rely on. Will post that + test next week.",,brandon.williams,e.dimitrova,ifesdjeen,jeromatron,jlewandowski,marcuse,mck,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16770,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Correctness -> Unrecoverable Corruption / Loss,,,,,,,,Normal,Fuzz Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Oct 14 12:11:30 UTC 2021,,,,,,,All,,,,"0|z0rw60:",9223372036854775807,,,,ifesdjeen,samt,,,Critical,,3.0.23,,https://github.com/apache/cassandra/commit/1d87da3f6fc0eca4e805238c19db16e6607b44a7,,,,,,,,,"new test, cci run",,,,,"11/Jun/21 19:13;e.dimitrova;[~marcuse], I am not familiar with these works but I am trying to filter the blockers for 4.0.0 Jira board and I saw this ticket. Reading your thoughts in the description, do you think we can revert 15899 to unblock 4.0.0? ;;;","11/Jun/21 19:15;brandon.williams;+1 to revert for 4.0.0;;;","14/Jun/21 17:58;marcuse;https://github.com/krummas/cassandra/commits/marcuse/16735-4.0.0
https://github.com/krummas/cassandra/commits/marcuse/16735-3.11
https://github.com/krummas/cassandra/commits/marcuse/16735

https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16735-4.0.0
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16735-3.11
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16735
;;;","14/Jun/21 19:18;brandon.williams;Looks like this broke the in-jvm schema disagreement tests, and the 3.11 run didn't get the last commit to fix its build before it ran.;;;","18/Jun/21 09:21;marcuse;removed the failing 15899 tests, now the cci runs look good (the sstableverify test fails locally without this patch as well);;;","18/Jun/21 14:44;e.dimitrova;Thank you for all your work [~marcuse]! :) I was wondering, should we really remove the _readWithSchemaDisagreement_ test?

PS Indeed, sstableverify test is a known issue, not related to this patch;;;","18/Jun/21 16:40;samt;LGTM +1;;;","21/Jun/21 10:19;ifesdjeen;LGTM +1 ;;;","21/Jun/21 14:00;marcuse;committed to 3.0 and merged all the way up to trunk, thanks!;;;","25/Jun/21 16:30;brandon.williams;Note that this broke ~370 tests in the 3.0 to 3.11 upgrade: https://ci-cassandra.apache.org/job/Cassandra-3.11/186/ caused by our old friend ""Unknown column cdc during deserialization"";;;","28/Jun/21 16:29;marcuse;thanks [~brandon.williams] https://issues.apache.org/jira/browse/CASSANDRA-16770;;;","14/Oct/21 12:03;jlewandowski;Hi, I'm looking at `SchemaTest` modified in this ticket - what is that test doing? I mean - is the only way to reproduce that issue executing internal statements?
;;;","14/Oct/21 12:11;marcuse;we use {{schemaChangeInternal}} to introduce a schema mismatch between nodes, and {{executeInternal}} to make sure we read repair later when doing a read;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow operators to disable 'ALTER ... DROP COMPACT STORAGE' statements,CASSANDRA-16733,13383418,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,blerer,blerer,11/Jun/21 13:08,20/Oct/21 12:38,13/Jul/23 08:40,18/Jun/21 13:29,3.0.25,3.11.11,4.0,4.0-rc2,,,,Legacy/CQL,,,,0,,,"{{ALTER ... DROP COMPACT STORAGE}} statements have not been extensively tested and suffer from several issues like:

* As COMPACT tables did not have primary key liveness there empty rows
inserted AFTER the ALTER will be returned whereas the one inserted before
the ALTER will not.
* Also due to the lack of primary key liveness the amount of SSTables being
read will increase resulting in slower queries (CASSANDRA-16675)
* After DROP COMPACT it becomes possible to ALTER the table in a way that
makes all the row disappears
* There is a loss of functionality around null clustering when dropping
compact storage (CASSANDRA-16069)

To avoid running into those issues this ticket will introduce a new flag that allow operators to disable those statements on their clusters.

see https://www.mail-archive.com/dev@cassandra.apache.org/msg16789.html",,adelapena,aholmber,blerer,brandon.williams,e.dimitrova,jeromatron,mck,,,,,,,,,"blerer opened a new pull request #1063:
URL: https://github.com/apache/cassandra/pull/1063


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:19;githubbot;600","adelapena commented on a change in pull request #1061:
URL: https://github.com/apache/cassandra/pull/1061#discussion_r650104833



##########
File path: src/java/org/apache/cassandra/config/Config.java
##########
@@ -322,6 +322,8 @@
 
     public boolean enable_materialized_views = true;
 
+    public volatile boolean enable_drop_compact_storage = true;

Review comment:
       Does this one need to be volatile?

##########
File path: src/java/org/apache/cassandra/cql3/statements/AlterTableStatement.java
##########
@@ -290,6 +290,10 @@ public void validate(ClientState state)
                                                                     columnFamily()));
                 break;
             case DROP_COMPACT_STORAGE:
+
+                if (!DatabaseDescriptor.enableDropCompactStorage())
+                    throw new InvalidRequestException(""DROP COMPACT STORAGE is disabled. Enable in cassandra.yaml to use."");

Review comment:
       When we added the experimental flags for MVs and SASI indexes in CASSANDRA-14866 we also added a client warning for each of them, [here](https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/cql3/statements/schema/CreateViewStatement.java#L340) and [here](https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/cql3/statements/schema/CreateIndexStatement.java#L148). Shouldn't we warn users about `DROP COMPACT STORAGE` being experimatal too, especially given that it's allowed by default in the config?

##########
File path: src/java/org/apache/cassandra/cql3/statements/AlterTableStatement.java
##########
@@ -290,6 +290,10 @@ public void validate(ClientState state)
                                                                     columnFamily()));
                 break;
             case DROP_COMPACT_STORAGE:
+
+                if (!DatabaseDescriptor.enableDropCompactStorage())
+                    throw new InvalidRequestException(""DROP COMPACT STORAGE is disabled. Enable in cassandra.yaml to use."");

Review comment:
       Of course the warning is not going to be that useful since in this case the damage is already done when the query is run. So probably it's better to just disable it by default.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:26;githubbot;600","blerer opened a new pull request #1061:
URL: https://github.com/apache/cassandra/pull/1061


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:33;githubbot;600","blerer opened a new pull request #1062:
URL: https://github.com/apache/cassandra/pull/1062


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:41;githubbot;600","blerer commented on a change in pull request #1061:
URL: https://github.com/apache/cassandra/pull/1061#discussion_r650754292



##########
File path: src/java/org/apache/cassandra/cql3/statements/AlterTableStatement.java
##########
@@ -290,6 +290,10 @@ public void validate(ClientState state)
                                                                     columnFamily()));
                 break;
             case DROP_COMPACT_STORAGE:
+
+                if (!DatabaseDescriptor.enableDropCompactStorage())
+                    throw new InvalidRequestException(""DROP COMPACT STORAGE is disabled. Enable in cassandra.yaml to use."");

Review comment:
       That was my reasoning once you have run the command and saw the warning it is effectively too late :-(




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 08:42;githubbot;600","blerer commented on a change in pull request #1061:
URL: https://github.com/apache/cassandra/pull/1061#discussion_r650754292



##########
File path: src/java/org/apache/cassandra/cql3/statements/AlterTableStatement.java
##########
@@ -290,6 +290,10 @@ public void validate(ClientState state)
                                                                     columnFamily()));
                 break;
             case DROP_COMPACT_STORAGE:
+
+                if (!DatabaseDescriptor.enableDropCompactStorage())
+                    throw new InvalidRequestException(""DROP COMPACT STORAGE is disabled. Enable in cassandra.yaml to use."");

Review comment:
       That was my reasoning. Once you have run the command and saw the warning it is effectively too late :-(




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 08:42;githubbot;600","adelapena commented on a change in pull request #1061:
URL: https://github.com/apache/cassandra/pull/1061#discussion_r654432816



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/UpgradeTestBase.java
##########
@@ -131,6 +131,12 @@ public TestCase setup(RunOnCluster setup)
             return this;
         }
 
+        public TestCase runBeforeNodeRestart(RunOnClusterAndNode runBeforeNodeRestart)
+        {
+            this.runBeforeNodeRestart = runBeforeNodeRestart;
+            return this;
+        }

Review comment:
       Nice!




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Jun/21 20:51;githubbot;600","blerer merged pull request #145:
URL: https://github.com/apache/cassandra-dtest/pull/145


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Jun/21 21:03;githubbot;600","blerer closed pull request #1061:
URL: https://github.com/apache/cassandra/pull/1061


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Oct/21 12:38;githubbot;600","blerer closed pull request #1063:
URL: https://github.com/apache/cassandra/pull/1063


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Oct/21 12:38;githubbot;600","blerer closed pull request #1062:
URL: https://github.com/apache/cassandra/pull/1062


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Oct/21 12:38;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,6600,,,0,6600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jun 18 13:29:31 UTC 2021,,,,,,,All,,,,"0|z0rvrs:",9223372036854775807,,,,adelapena,brandon.williams,,,Normal,,3.0.16,,https://github.com/apache/cassandra/commit/9b6dd382bdf4a71c06091736ff98cb1307ff0e97,,,,,,,,,The patch add a test to check the flag behavior,,,,,"11/Jun/21 15:48;blerer;|| Branch || CI ||
|[3.0|https://github.com/apache/cassandra/pull/1061]|[J8|https://app.circleci.com/pipelines/github/blerer/cassandra?branch=CASSANDRA-16733-3.0]|
|[3.11|https://github.com/apache/cassandra/pull/1062]|[J8|https://app.circleci.com/pipelines/github/blerer/cassandra/166/workflows/637b5eda-690d-4c71-8d25-e02cd83d11f2]|
|[4.0|https://github.com/apache/cassandra/pull/1063]|[J8|https://app.circleci.com/pipelines/github/blerer/cassandra/149/workflows/275bba43-e1ff-4604-94af-c8343b49db27], [J11|https://app.circleci.com/pipelines/github/blerer/cassandra/162/workflows/43d06df1-4c1e-40a7-b41b-9507e3545042]|;;;","11/Jun/21 15:57;brandon.williams;I think we should default the flag to false to ensure the operator is aware of what's possible when this is enabled (and it is experimental, after all.)  Otherwise +1.;;;","11/Jun/21 17:12;adelapena;It seems that the flag defaults to true in 3.0 and 3.11 but not in 4.0, is there a reason to not always defaulting to false?

There is a trivial failure in [{{CompactStorageUpgradeTest.compactStorageUpgradeTest}}|https://app.circleci.com/pipelines/github/blerer/cassandra/148/workflows/429e34ca-0ad1-4bda-aacc-bbc3a96c7c0d/jobs/1391] due to the disabled drop compact storage. If I'm right JVM dtests don't use {{test/conf/cassandra.yaml}}, we should enable the flag programmatically in that test:
{code:java}
.withConfig(config -> config.with(GOSSIP, NETWORK).set(""enable_drop_compact_storage"", true))
{code};;;","14/Jun/21 08:35;blerer;Regarding the flag default. I simply followed what we did so far for all the other experimental features. Kept the flag to {{true}} for released versions. For MVs for example: it is {{true}} in [3.0|https://github.com/apache/cassandra/blob/cassandra-3.0/conf/cassandra.yaml#L990] and [3.11|https://github.com/apache/cassandra/blob/cassandra-3.11/conf/cassandra.yaml#L1276], but {{false}} in [4.0|https://github.com/apache/cassandra/blob/cassandra-4.0/conf/cassandra.yaml#L1428]. The same logic is used for SASI. ;;;","14/Jun/21 10:45;adelapena;{quote}Regarding the flag default. I simply followed what we did so far for all the other experimental features. Kept the flag to {{true}} for released versions. For MVs for example: it is {{true}} in [3.0|https://github.com/apache/cassandra/blob/cassandra-3.0/conf/cassandra.yaml#L990] and [3.11|https://github.com/apache/cassandra/blob/cassandra-3.11/conf/cassandra.yaml#L1276], but {{false}} in [4.0|https://github.com/apache/cassandra/blob/cassandra-4.0/conf/cassandra.yaml#L1428]. The same logic is used for SASI.
{quote}
I think that the reason to keep the experimental features enabled in 3.0 and 3.x is that there could be code out there creating MVs or SASI indexes automatically (original discussion [here|https://lists.apache.org/thread.html/33666941e697af2d8097b9fd8c3b4301a727f8b7555dbbb544dc69a2%40%3Cdev.cassandra.apache.org%3E]. I'm not sure whether that could also be the case for a migration thing like dropping compact storage, and I see dropping CS as more potentially harmful than creating MVs/SASI, but I'd be happy keeping the same criteria for all experimental features for the sake of consistency.;;;","14/Jun/21 12:28;blerer;I pushed a change as [~adelapena] suggested for the test failures and CI looks [better|https://app.circleci.com/pipelines/github/blerer/cassandra/149/workflows/275bba43-e1ff-4604-94af-c8343b49db27].;;;","14/Jun/21 12:42;brandon.williams;bq. I see dropping CS as more potentially harmful

That is my reasoning.  It's simple to drop an index, but my understanding is unringing the DROP COMPACT STORAGE bell is fairy involved.;;;","14/Jun/21 17:08;adelapena;The last commit setting {{enable_drop_compact_storage}} as false by default in 3.0 and 3.11 looks good to me, +1 if CI is ok.;;;","14/Jun/21 18:19;adelapena;Nit: I think we should mention the new property in [the documentation for {{cassandra.yaml}}|https://github.com/apache/cassandra/blob/a800d7e47c9a4e2ddc8dcbf374f239a8ee718ccb/doc/source/configuration/cass_yaml_file.rst].;;;","17/Jun/21 15:07;blerer;I pushed some changes on the PRs to fix some failures with the In-JVM upgrade test. I also opened a [PR|https://github.com/apache/cassandra-dtest/pull/145] to fix the python upgrade DTests.;;;","18/Jun/21 09:36;blerer;I updated the CI runs they now look good.;;;","18/Jun/21 13:23;blerer;Thank you very much for your help with the test issues [~adelapena], [~brandon.williams] and [~e.dimitrova]. ;;;","18/Jun/21 13:29;blerer;Committed into 3.0 at 9b6dd382bdf4a71c06091736ff98cb1307ff0e97 and merged into 3.11, 4.0.0, 4.0 and trunk ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky test user_types_test.py::TestUserTypes::test_type_keyspace_permission_isolation,CASSANDRA-16729,13383285,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,10/Jun/21 23:34,14/Jun/21 07:11,13/Jul/23 08:40,10/Jun/21 23:55,NA,,,,,,,Test/dtest/python,,,,0,,,"user_types_test.py::TestUserTypes::test_type_keyspace_permission_isolation adds a 5 second sleep to give time for roles to load, this causes tests to fail from time to time.  Rather than hoping the roles are loaded, we can retry if the expected error is seen.",,dcapwell,,,,,,,,,,,,,,,"dcapwell opened a new pull request #143:
URL: https://github.com/apache/cassandra-dtest/pull/143


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:11;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jun 10 23:46:22 UTC 2021,,,,,,,All,,,,"0|z0ruyg:",9223372036854775807,,,,brandon.williams,,,,Low,,NA,,https://github.com/apache/cassandra-dtest/commit/f9ff078c3f54119ef8c7aa22987dd33f57d56de2,,,,,,,,,tested locally,,,,,"10/Jun/21 23:36;dcapwell;been running the patch in a loop and see its stable, and logs

{code}
23:29:21,184 tools.flaky INFO Retrying as error 'Error from server: code=2200 [Invalid query] message=""Cannot process role related query as the role manager isn't yet setup. This is likely because some of nodes in the cluster are on versi
on 2.1 or earlier. You need to upgrade all nodes to Cassandra 2.2 or more to use roles.""' was seen; sleeping for 10 seconds
23:29:34,110 cassandra.cluster INFO New Cassandra host <Host: 127.0.0.3:9042 datacenter1> discovered
23:29:34,114 cassandra.cluster INFO New Cassandra host <Host: 127.0.0.2:9042 datacenter1> discovered
23:29:34,225 cassandra.cluster INFO New Cassandra host <Host: 127.0.0.3:9042 datacenter1> discovered
23:29:34,230 cassandra.cluster INFO New Cassandra host <Host: 127.0.0.2:9042 datacenter1> discovered
PASSED
{code};;;","10/Jun/21 23:46;brandon.williams;+1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"test_tombstone_failure_threshold_message assert checking if array == string, should check for array truthiness",CASSANDRA-16728,13383058,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,09/Jun/21 22:59,10/Jun/21 00:13,13/Jul/23 08:40,10/Jun/21 00:13,NA,,,,,,,Test/dtest/python,,,,0,,,"The test pushed_notifications_test.py::TestVariousNotifications::test_tombstone_failure_threshold_message checks for the log message ""Scanned over.* tombstones.* query aborted”, but this can happen on any node, so it will timeout checking node1 then check the other nodes; when this happens it checks that the returned result equals ""Cannot find tombstone failure threshold error in log after failed query”, which isn’t possible as the return is matching log lines, this should be replaced by checking for failure truthiness.",,dcapwell,yifanc,,,,,,,,,,,,,,"dcapwell opened a new pull request #142:
URL: https://github.com/apache/cassandra-dtest/pull/142


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Jun/21 23:01;githubbot;600","dcapwell closed pull request #142:
URL: https://github.com/apache/cassandra-dtest/pull/142


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 00:00;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jun 09 23:40:39 UTC 2021,,,,,,,All,,,,"0|z0rtjs:",9223372036854775807,,,,yifanc,,,,Low,,NA,,https://github.com/apache/cassandra-dtest/commit/964051b04767689a1a3a84493c0b4afe77d6edfc,,,,,,,,,tested locally,,,,,"09/Jun/21 23:40;yifanc;+1 on the patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LICENSE Text addition to Layout.html breaks Cassandra Website rendering,CASSANDRA-16727,13383013,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bhouser,bhouser,bhouser,09/Jun/21 17:47,27/May/22 19:25,13/Jul/23 08:40,25/Jun/21 11:20,3.11.11,4.0.1,4.1,4.1-alpha1,,,,Documentation/Website,,,,0,pull-request-available,,"The newest docs contain a license agreement comment found in the layout.html of the theme.  This occurs before front matter indicator...
 [https://github.com/apache/cassandra/blob/cassandra-3.11/doc/source/_theme/cassandra_theme/layout.html]

Jekyll assumes that the front matter while be at the top ""—"".  This causes Jekyll to break when serving the page on the website.

There are a few other docs that seem to have this problem, and serving the latest docs of the website breaks the rendering.",,bhouser,e.dimitrova,mck,,,,,,,,,,,,,"bhouse99 opened a new pull request #1081:
URL: https://github.com/apache/cassandra/pull/1081


   Marked the license text as an RST comment and moved display of the license text in html to
   cassandra website.  The comment placement affected Jekyll processing
   
   Tested via desktop jekyll build


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Jun/21 19:37;githubbot;600","michaelsembwever commented on pull request #1081:
URL: https://github.com/apache/cassandra/pull/1081#issuecomment-868428726


   Merged manually with b3cdc131ab53fe9affd6115ac9e3aaf495ea8530


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Jun/21 11:21;githubbot;600","michaelsembwever closed pull request #1081:
URL: https://github.com/apache/cassandra/pull/1081


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Jun/21 11:21;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,CASSANDRA-16633,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bhouser,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jun 25 11:20:38 UTC 2021,,,,,,,All,,,,"0|z0rt9s:",9223372036854775807,,,,mck,,,,Low,,4.0-rc1,,https://github.com/apache/cassandra/commit/b3cdc131ab53fe9affd6115ac9e3aaf495ea8530,,,,,,,,,Manual testing of Cassandra branch and website on desktop using Jekyll,,,,,"09/Jun/21 17:48;bhouser;Found during https://issues.apache.org/jira/browse/CASSANDRA-16573.  Seems that this will work just find if the comment is placed underneath the front matter.

There are other elements of the theme that have this problem.  Currently working on a fix.

 

 ;;;","09/Jun/21 18:08;e.dimitrova;Thank you [~bhouser]! I moved the ticket through the phases, hope you don't mind. 

 ;;;","22/Jun/21 19:40;bhouser;Two related patches...
This one to make the comment visible on pages in the website...
https://github.com/apache/cassandra-website/pull/61

This one to make the source files contain the comment....
https://github.com/apache/cassandra/pull/1081;;;","22/Jun/21 22:05;mck;Thanks [~bhouser]!

I think we can skip the PR on cassandra-website. Providing the copyright in the html is not required AFAIK, and the website it currently getting rewritten to antora (see CASSANDRA-16066).

I will take a closer look at #1081 tomorrow.;;;","25/Jun/21 11:20;mck;Committed as [b3cdc131ab53fe9affd6115ac9e3aaf495ea8530|https://github.com/apache/cassandra/commit/b3cdc131ab53fe9affd6115ac9e3aaf495ea8530].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ClientMetrics should be initialised in CQLConnectionTest,CASSANDRA-16722,13382553,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,samt,samt,samt,07/Jun/21 19:19,16/Jun/21 15:59,13/Jul/23 08:40,09/Jun/21 15:15,4.0,4.0-rc2,,,,,,Test/unit,,,,0,,,"Without a call to {{ClientMetrics.instance.init}}, client protocol errors cause an NPE when the server attempts to mark the relevant meter.",,mck,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,samt,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jun 09 15:15:49 UTC 2021,,,,,,,All,,,,"0|z0rqg0:",9223372036854775807,,,,mck,,,,Low,,NA,,https://github.com/apache/cassandra/commit/546792169e7df90c905139d1a275056bbef850d4,,,,,,,,,test only fix,,,,,"07/Jun/21 19:25;samt;This only affects test code and only appears to have caused a single failure of the 4.0.0 nightlies.

 

https://ci-cassandra.apache.org/job/Cassandra-4.0.0/3/testReport/;;;","07/Jun/21 19:34;samt;||branch||Circle CI|Apache CI|
|[16722-4.0.0|https://github.com/beobal/cassandra/tree/16722-4.0.0]|[circle|https://circleci.com/gh/beobal/cassandra?branch=16722-4.0.0]|[apache|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/849]|;;;","08/Jun/21 12:16;mck;+1;;;","09/Jun/21 15:15;samt;Thanks, committed with one additional tweak to remove a race in {{CQLConnectionTest}} when the server closes the channel.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Repaired data tracking on a read coordinator is susceptible to races between local and remote requests,CASSANDRA-16721,13382551,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,maedhroz,samt,samt,07/Jun/21 18:37,27/May/22 19:25,13/Jul/23 08:40,27/Aug/21 17:03,4.0.1,4.1,4.1-alpha1,,,,,Consistency/Coordination,,,,0,,,"At read time on a coordinator which is also a replica, the local and remote reads can race such that the remote responses are received while the local read is executing. If the remote responses are mismatching, triggering a {{DigestMismatchException}} and subsequent round of full data reads and read repair, the local runnable may find the {{isTrackingRepairedStatus}} flag flipped mid-execution.  If this happens after a certain point in execution, it would mean
that the RepairedDataInfo instance in use is the singleton null object {{RepairedDataInfo.NULL_REPAIRED_DATA_INFO}}. If this happens, it can lead to an NPE when calling {{RepairedDataInfo::extend}} when the local results are iterated.",,maedhroz,samt,,,,,,,,,,,,,,"maedhroz opened a new pull request #1160:
URL: https://github.com/apache/cassandra/pull/1160


   patch by Caleb Rackliffe; reviewed by Sam Tunnicliffe for CASSANDRA-16721
   
   Co-authored-by: Sam Tunnicliffe <sam@beobal.com>
   Co-authored-by: Caleb Rackliffe <calebrackliffe@gmail.com>


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Aug/21 00:08;githubbot;600","maedhroz commented on a change in pull request #1160:
URL: https://github.com/apache/cassandra/pull/1160#discussion_r693047174



##########
File path: src/java/org/apache/cassandra/service/reads/AbstractReadExecutor.java
##########
@@ -155,7 +156,11 @@ private void makeRequests(ReadCommand readCommand, Iterable<Replica> replicas)
         if (hasLocalEndpoint)
         {
             logger.trace(""reading {} locally"", readCommand.isDigestQuery() ? ""digest"" : ""data"");
-            Stage.READ.maybeExecuteImmediately(new LocalReadRunnable(command, handler));
+
+            if (TEST_FORCE_ASYNC_LOCAL_READS)
+                new Thread(new LocalReadRunnable(readCommand, handler)).start();

Review comment:
       Initially I tried to just have this hit `Stage.READ.execute()`, but the initial read and the read on read-repair seemed to both try to use the same ReadStage thread :/




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Aug/21 15:46;githubbot;600","smiklosovic commented on a change in pull request #1160:
URL: https://github.com/apache/cassandra/pull/1160#discussion_r693054226



##########
File path: test/distributed/org/apache/cassandra/distributed/test/RepairDigestTrackingTest.java
##########
@@ -340,6 +347,99 @@ else if (ccAfterPartitionRead != ccBefore)
         }
     }
 
+    /**
+     * In CASSANDRA-16721, we discovered that if responses from remote replicas came back while the local runnable was 
+     * still executing, the fact that {@link ReadCommand} was mutable meant that the trackRepairedStatus flag on the
+     * command instance could move from false to true in executeLocally(), between setting the 
+     * RepairedDataInfo/gathering the sstables and calling extend(). When this happened, the RDI was still the 
+     * stand-in object NO_OP_REPAIRED_DATA_INFO, which has a null repairedDataCounter, and we hit the NPE.
+     * 
+     * Similarly, the trackRepairedStatus flag could be set after the point at which the RDI is set on the local 
+     * read, assigned to the repairedDataInfo in {@link ReadCommand}, and improperly shared between initial local read
+     * and the local read triggered by read repair.
+     * 
+     * These problems are now sidestepped completely by CASSANDRA-16721, as an RDI instance is ow created and destroyed 

Review comment:
       ow -> now




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Aug/21 15:57;githubbot;600","ifesdjeen commented on a change in pull request #1160:
URL: https://github.com/apache/cassandra/pull/1160#discussion_r694693100



##########
File path: src/java/org/apache/cassandra/db/ReadExecutionController.java
##########
@@ -171,6 +200,51 @@ public void close()
             addSample();
     }
 
+    public boolean isTrackingRepairedStatus()
+    {
+        return repairedDataInfo != RepairedDataInfo.NO_OP_REPAIRED_DATA_INFO;
+    }
+
+    /**
+     * Returns a digest of the repaired data read in the execution of this command.
+     *
+     * If either repaired status tracking is not active or the command has not yet been
+     * executed, then this digest will be an empty buffer.
+     * Otherwise, it will contain a digest* of the repaired data read, or empty buffer

Review comment:
       is `*` after ""digest"" intended?

##########
File path: src/java/org/apache/cassandra/db/ReadExecutionController.java
##########
@@ -171,6 +200,51 @@ public void close()
             addSample();
     }
 
+    public boolean isTrackingRepairedStatus()
+    {
+        return repairedDataInfo != RepairedDataInfo.NO_OP_REPAIRED_DATA_INFO;
+    }
+
+    /**
+     * Returns a digest of the repaired data read in the execution of this command.
+     *
+     * If either repaired status tracking is not active or the command has not yet been
+     * executed, then this digest will be an empty buffer.
+     * Otherwise, it will contain a digest* of the repaired data read, or empty buffer
+     * if no repaired data was read.
+     * @return digest of the repaired data read in the execution of the command
+     */
+    public ByteBuffer getRepairedDataDigest()
+    {
+        return repairedDataInfo.getDigest();
+    }
+
+    /**
+     * Returns a boolean indicating whether any relevant sstables were skipped during the read
+     * that produced the repaired data digest.
+     *
+     * If true, then no pending repair sessions or partition deletes have influenced the extent
+     * of the repaired sstables that went into generating the digest.
+     * This indicates whether or not the digest can reliably be used to infer consistency
+     * issues between the repaired sets across replicas.
+     *
+     * If either repaired status tracking is not active or the command has not yet been
+     * executed, then this will always return true.
+     *
+     * @return boolean to indicate confidence in the dwhether or not the digest of the repaired data can be

Review comment:
       `dwether`  -> `wether`

##########
File path: src/java/org/apache/cassandra/service/reads/AbstractReadExecutor.java
##########
@@ -155,7 +156,11 @@ private void makeRequests(ReadCommand readCommand, Iterable<Replica> replicas)
         if (hasLocalEndpoint)
         {
             logger.trace(""reading {} locally"", readCommand.isDigestQuery() ? ""digest"" : ""data"");
-            Stage.READ.maybeExecuteImmediately(new LocalReadRunnable(command, handler));
+
+            if (TEST_FORCE_ASYNC_LOCAL_READS)
+                new Thread(new LocalReadRunnable(readCommand, handler)).start();

Review comment:
       wondering if it could be best to just create a separate method for executing read runnable, and using ByteBuddy during test




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Aug/21 20:32;githubbot;600","maedhroz commented on a change in pull request #1160:
URL: https://github.com/apache/cassandra/pull/1160#discussion_r695217927



##########
File path: src/java/org/apache/cassandra/db/ReadExecutionController.java
##########
@@ -171,6 +200,51 @@ public void close()
             addSample();
     }
 
+    public boolean isTrackingRepairedStatus()
+    {
+        return repairedDataInfo != RepairedDataInfo.NO_OP_REPAIRED_DATA_INFO;
+    }
+
+    /**
+     * Returns a digest of the repaired data read in the execution of this command.
+     *
+     * If either repaired status tracking is not active or the command has not yet been
+     * executed, then this digest will be an empty buffer.
+     * Otherwise, it will contain a digest* of the repaired data read, or empty buffer

Review comment:
       Nope, will fix.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Aug/21 21:08;githubbot;600","maedhroz commented on a change in pull request #1160:
URL: https://github.com/apache/cassandra/pull/1160#discussion_r695219769



##########
File path: src/java/org/apache/cassandra/service/reads/AbstractReadExecutor.java
##########
@@ -155,7 +156,11 @@ private void makeRequests(ReadCommand readCommand, Iterable<Replica> replicas)
         if (hasLocalEndpoint)
         {
             logger.trace(""reading {} locally"", readCommand.isDigestQuery() ? ""digest"" : ""data"");
-            Stage.READ.maybeExecuteImmediately(new LocalReadRunnable(command, handler));
+
+            if (TEST_FORCE_ASYNC_LOCAL_READS)
+                new Thread(new LocalReadRunnable(readCommand, handler)).start();

Review comment:
       That sounds better than what I've got here. I'll give it a shot...




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Aug/21 21:11;githubbot;600","beobal commented on a change in pull request #1160:
URL: https://github.com/apache/cassandra/pull/1160#discussion_r695998593



##########
File path: src/java/org/apache/cassandra/service/reads/AbstractReadExecutor.java
##########
@@ -155,7 +156,11 @@ private void makeRequests(ReadCommand readCommand, Iterable<Replica> replicas)
         if (hasLocalEndpoint)
         {
             logger.trace(""reading {} locally"", readCommand.isDigestQuery() ? ""digest"" : ""data"");
-            Stage.READ.maybeExecuteImmediately(new LocalReadRunnable(command, handler));
+
+            if (TEST_FORCE_ASYNC_LOCAL_READS)
+                new Thread(new LocalReadRunnable(readCommand, handler)).start();

Review comment:
       +1 to this suggestion

##########
File path: src/java/org/apache/cassandra/db/RepairedDataInfo.java
##########
@@ -34,12 +36,16 @@
 import org.apache.cassandra.tracing.Tracing;
 import org.apache.cassandra.utils.ByteBufferUtil;
 
+@NotThreadSafe
 class RepairedDataInfo
 {
-    public static final RepairedDataInfo NULL_REPAIRED_DATA_INFO = new RepairedDataInfo(null)
+    public static final RepairedDataInfo NO_OP_REPAIRED_DATA_INFO = new RepairedDataInfo(null)
     {
-        boolean isConclusive(){ return true; }
-        ByteBuffer getDigest(){ return ByteBufferUtil.EMPTY_BYTE_BUFFER; }
+        @Override
+        public UnfilteredPartitionIterator extend(UnfilteredPartitionIterator partitions, DataLimits.Counter limit)
+        {
+           throw new UnsupportedOperationException(""Attempted to extend with the no-op implementation!"");

Review comment:
       It's a really trivial nit, but this feels kind of counter to the null object pattern being employed here. This could just return `partitions` unchanged to be safe. I get that there isn't a code path which could lead to `extend` being called on this instance, unlike `isConclusive/getDigest`, it's just a tiny bit inconsistent. 
   




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Aug/21 18:10;githubbot;600","beobal commented on a change in pull request #1160:
URL: https://github.com/apache/cassandra/pull/1160#discussion_r696006742



##########
File path: src/java/org/apache/cassandra/service/reads/range/RangeCommandIterator.java
##########
@@ -176,34 +176,36 @@ static int computeConcurrencyFactor(int totalRangeCount, int rangesQueried, int
     private SingleRangeResponse query(ReplicaPlan.ForRangeRead replicaPlan, boolean isFirst)
     {
         PartitionRangeReadCommand rangeCommand = command.forSubRange(replicaPlan.range(), isFirst);
+        
+        boolean trackRepairedStatus = false;
+        
         // If enabled, request repaired data tracking info from full replicas but
         // only if there are multiple full replicas to compare results from
         if (DatabaseDescriptor.getRepairedDataTrackingForRangeReadsEnabled()
             && replicaPlan.contacts().filter(Replica::isFull).size() > 1)
         {
-            command.trackRepairedStatus();
-            rangeCommand.trackRepairedStatus();
+            trackRepairedStatus = true;

Review comment:
       nit: can initialize according to the condition at declaration.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Aug/21 18:21;githubbot;600","beobal commented on a change in pull request #1160:
URL: https://github.com/apache/cassandra/pull/1160#discussion_r696008838



##########
File path: src/java/org/apache/cassandra/service/reads/repair/AbstractReadRepair.java
##########
@@ -124,18 +129,28 @@ public void startRepair(DigestResolver<E, P> digestResolver, Consumer<PartitionI
     {
         getRepairMeter().mark();
 
+        /*
+         * When repaired data tracking is enabled, a digest will be created from data reads from repaired SSTables.
+         * The digests from each replica can then be compared on the coordinator to detect any divergence in their
+         * repaired datasets. In this context, an SSTable is considered repaired if it is marked repaired or has a 
+         * pending repair session which has been committed. In addition to the digest, a set of ids for any pending but 
+         * as yet uncommitted repair sessions is recorded and returned to the coordinator. This is to help reduce false 
+         * positives caused by compaction lagging which can leave sstables from committed sessions in the pending state
+         * for a time.
+         */
+        boolean trackRepairedStatus = DatabaseDescriptor.getRepairedDataTrackingForPartitionReadsEnabled();
+
         // Do a full data read to resolve the correct response (and repair node that need be)
-        DataResolver<E, P> resolver = new DataResolver<>(command, replicaPlan, this, queryStartNanoTime);
+        DataResolver<E, P> resolver = new DataResolver<>(command, replicaPlan, this, queryStartNanoTime, trackRepairedStatus);
         ReadCallback<E, P> readCallback = new ReadCallback<>(resolver, command, replicaPlan, queryStartNanoTime);
 
         digestRepair = new DigestRepair(resolver, readCallback, resultConsumer);
 
         // if enabled, request additional info about repaired data from any full replicas

Review comment:
       this comment is probably a little redundant now




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Aug/21 18:24;githubbot;600","maedhroz commented on pull request #1160:
URL: https://github.com/apache/cassandra/pull/1160#issuecomment-907344505


   Committed as https://github.com/apache/cassandra/commit/585bc692918deea2b8c4b1098ee7e7478881f138


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/Aug/21 17:02;githubbot;600","maedhroz closed pull request #1160:
URL: https://github.com/apache/cassandra/pull/1160


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/Aug/21 17:02;githubbot;600","maedhroz commented on pull request #1171:
URL: https://github.com/apache/cassandra/pull/1171#issuecomment-907344824


   Merged up to trunk as https://github.com/apache/cassandra/commit/33979e3c916b2006e75a042fa4c806364dbbe5c1


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/Aug/21 17:03;githubbot;600","maedhroz closed pull request #1171:
URL: https://github.com/apache/cassandra/pull/1171


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/Aug/21 17:03;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,7800,,,0,7800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,maedhroz,samt,,,,,,,,,,,,Availability -> Response Crash,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Aug 27 17:03:22 UTC 2021,,,,,,,All,,,,"0|z0rqfk:",9223372036854775807,,,,ifesdjeen,maedhroz,samt,,Normal,,4.0.0,,https://github.com/apache/cassandra/commit/585bc692918deea2b8c4b1098ee7e7478881f138,,,,,,,,,New dtests added,,,,,"07/Jun/21 19:16;samt;||branch||Circle CI|Apache CI|
|[16721-4.0|https://github.com/beobal/cassandra/tree/16721-4.0]|[circle|https://circleci.com/gh/beobal/cassandra?branch=16721-4.0]|[ci-c|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/848]|
;;;","16/Aug/21 19:44;maedhroz;I've made a first pass at the patch, and I think it does solve the problem described in the description above. However, there are a few questions I'm struggling with:
  

1.) Why do we share any aspect of {{RepairedDataInfo}} across threads at all? It seems like both the problem above and a class of other possible problems (read on) would be sidestepped completely. More specifically, perhaps we could do something like just indicating to the {{ReadExecutionController}} whether we should track repaired status?

2.) If we follow the scenario above, and two remote reads return and indicate a mismatch while the local read is still executing, is it possible that both the local read (likely on a Native Transport thread, but possibly on a ReadStage thread) and the local read started in {{startRepair()}} (and now on a ReadStage thread) use the same {{RepairedDataInfo}} instance as they serialize their local data responses? (In other words, is there ever a reason of an initial local data read to use RDI?)

 
 Even if the second item above isn't possible, it still seems like our implementation would be less brittle if if we could find a minimally invasive way to make the change in the first item. I'm open to making a pass at it, but I want to make sure my starting assumptions are correct.;;;","17/Aug/21 04:32;maedhroz;I took a stab at it [here|https://github.com/apache/cassandra/pull/1149]. (There are still a few TODOs lying around.) Let's see if I [broke|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16721-local-rdi] anything...

 

UPDATE: The unit and in-jvm tests look ok, with the exception of {{RowIterationTest}}, where there is something strange going on between tests when we drop tables and keyspaces. (Looks like I forgot to close the controller in the modified read utilities.);;;","18/Aug/21 16:14;samt;Your approach is a great improvement, makes a lot more sense for {{ReadExecutionController}} to handle {{RepairedDataInfo}}. The only non-obvious thing I noticed is that the sub-controllers for index reads should probably not inherit the tracking flag, just always make it false. It should be safe and not inefficient either way, but it just doesn't make sense for a read of the index table to be set to track.;;;","20/Aug/21 00:12;maedhroz;[~samt] Alright, I think this is back in a reviewable state if you'd like to take a look.

||Branch||Circle CI ||
|[4.0|https://github.com/apache/cassandra/pull/1160]|[J8 and J11|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16721-4.0]|

(This should merge up pretty cleanly.);;;","20/Aug/21 16:16;maedhroz;Just noticed that {{oldestUnrepairedTombstone}} is still mutable on {{ReadCommand}} as well, and might be accessed concurrently by two local reads. I might expand the scope of this slightly to move that to the controller as well. (It looks like the controller is already available in most of the places we modify it already.)

UPDATE: fixed in https://github.com/apache/cassandra/pull/1160/commits/2d8509a9e4eb95c0b0e313fc4fdaa405d3f00e47;;;","25/Aug/21 18:39;samt;Looks good to me, modulo a [few|https://github.com/apache/cassandra/pull/1160/files#r695998655], [trivial|https://github.com/apache/cassandra/pull/1160/files#r696006742], [nits|https://github.com/apache/cassandra/pull/1160/files#r696008838] (sorry, I forgot it was a PR not just a branch). I'm also a fan of Alex's suggestion to replace {{TEST_FORCE_ASYNC_LOCAL_READS}} with some ByteBuddy manipulation in the test. 

All of the above can be fixed (or not) on commit, so +1 from me too & thanks!
;;;","26/Aug/21 17:21;maedhroz;Review feedback addressed, tests in progress, and will get tests running against a trunk version shortly...;;;","26/Aug/21 20:37;maedhroz;||Branch||Circle CI||Apache CI||
|[4.0|https://github.com/apache/cassandra/pull/1160]|[J8 and J11|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16721-4.0]|[1075|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1075/]|
|[trunk|https://github.com/apache/cassandra/pull/1171]|[J8 and J11|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16721-trunk]|[1074|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1074/]|

UPDATE: The changes in CASSANDRA-16850 introduced a few minor conflicts for the trunk patch, and I've addressed those [here|https://github.com/apache/cassandra/pull/1171]. Tests are running again, and in the meantime, I'm likely going to make a few of those changes to the 4.0 patch as well just to keep things consistent.;;;","27/Aug/21 17:03;maedhroz;Committed in {{cassandra-4.0}} as https://github.com/apache/cassandra/commit/585bc692918deea2b8c4b1098ee7e7478881f138 and merged up via https://github.com/apache/cassandra/commit/33979e3c916b2006e75a042fa4c806364dbbe5c1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix  org.apache.cassandra.distributed.test.FqlReplayDDLExclusionTest.test,CASSANDRA-16720,13382538,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,e.dimitrova,e.dimitrova,07/Jun/21 16:54,31/Jul/21 21:14,13/Jul/23 08:40,09/Jun/21 14:40,4.0,4.0.0,4.0-rc2,,,,,Test/dtest/java,,,,0,,,"It failed a few times in Jenkins lately. Example:

[https://jenkins-cm4.apache.org/job/Cassandra-4.0.0/12/testReport/junit/org.apache.cassandra.distributed.test/FqlReplayDDLExclusionTest/test/]
{code:java}
Error Message
Expected: [[1]] Actual: []

Stacktrace
junit.framework.AssertionFailedError: Expected: [[1]] Actual: [] at org.apache.cassandra.distributed.shared.AssertUtils.assertRows(AssertUtils.java:58) at org.apache.cassandra.distributed.test.FqlReplayDDLExclusionTest.test(FqlReplayDDLExclusionTest.java:102)
{code}
I was also able to reproduce it locally on the latest 4.0.0 so I believe it is worth it to be checked. 

//CC [~stefan.miklosovic] and [~bereng] as I see you two are the only people who worked on that test up to now so If you have any thoughts to share, as usual, that will be highly appreciated :)",,e.dimitrova,stefan.miklosovic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jun/21 16:45;brandon.williams;fqllogs.tar.bz2;https://issues.apache.org/jira/secure/attachment/13026558/fqllogs.tar.bz2",,,,,1.0,brandon.williams,,,,,,,,,,,,,Degradation,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Jul 05 22:27:17 UTC 2021,,,,,,,,,,,"0|z0rqco:",9223372036854775807,,,,brandon.williams,e.dimitrova,,,Normal,,4.0-beta1,,https://github.com/apache/cassandra/commit/1b24f3e1a772127c716c75b47651646087030ee0,,,,,,,,,add dtest,,,,,"07/Jun/21 17:45;e.dimitrova;The exception I saw locally when it failed:
{code:java}
Exception in thread ""background~resource~releaser"" java.lang.IllegalStateException: Can't load ch.qos.logback.classic.spi.ThrowableProxy. Instance class loader is already closed.Exception in thread ""background~resource~releaser"" java.lang.IllegalStateException: Can't load ch.qos.logback.classic.spi.ThrowableProxy. Instance class loader is already closed. at org.apache.cassandra.distributed.shared.InstanceClassLoader.loadClassInternal(InstanceClassLoader.java:93) at org.apache.cassandra.distributed.shared.InstanceClassLoader.loadClass(InstanceClassLoader.java:87) at ch.qos.logback.classic.spi.LoggingEvent.<init>(LoggingEvent.java:119) at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:419) at ch.qos.logback.classic.Logger.filterAndLog_0_Or3Plus(Logger.java:383) at ch.qos.logback.classic.Logger.warn(Logger.java:692) at net.openhft.chronicle.core.onoes.Slf4jExceptionHandler$2.on(Slf4jExceptionHandler.java:38) at net.openhft.chronicle.core.onoes.ThreadLocalisedExceptionHandler.on(ThreadLocalisedExceptionHandler.java:36) at net.openhft.chronicle.core.io.BackgroundResourceReleaser.performRelease(BackgroundResourceReleaser.java:85) at net.openhft.chronicle.core.io.BackgroundResourceReleaser.runReleaseResources(BackgroundResourceReleaser.java:28) at java.lang.Thread.run(Thread.java:748)
java.lang.AssertionError: Expected: [[1]]Actual: []{code};;;","07/Jun/21 17:48;e.dimitrova;Also failed this way too:
{code:java}
Exception in thread ""background~resource~releaser"" java.lang.IllegalStateException: Can't load ch.qos.logback.core.status.WarnStatus. Instance class loader is already closed.Exception in thread ""background~resource~releaser"" java.lang.IllegalStateException: Can't load ch.qos.logback.core.status.WarnStatus. Instance class loader is already closed. at org.apache.cassandra.distributed.shared.InstanceClassLoader.loadClassInternal(InstanceClassLoader.java:93) at org.apache.cassandra.distributed.shared.InstanceClassLoader.loadClass(InstanceClassLoader.java:87) at ch.qos.logback.classic.LoggerContext.noAppenderDefinedWarning(LoggerContext.java:186) at ch.qos.logback.classic.Logger.callAppenders(Logger.java:264) at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:421) at ch.qos.logback.classic.Logger.filterAndLog_0_Or3Plus(Logger.java:383) at ch.qos.logback.classic.Logger.warn(Logger.java:692) at net.openhft.chronicle.core.onoes.Slf4jExceptionHandler$2.on(Slf4jExceptionHandler.java:38) at net.openhft.chronicle.core.onoes.ThreadLocalisedExceptionHandler.on(ThreadLocalisedExceptionHandler.java:36) at net.openhft.chronicle.core.io.BackgroundResourceReleaser.performRelease(BackgroundResourceReleaser.java:85) at net.openhft.chronicle.core.io.BackgroundResourceReleaser.runReleaseResources(BackgroundResourceReleaser.java:28) at java.lang.Thread.run(Thread.java:748){code};;;","07/Jun/21 17:53;brandon.williams;I'll take a look at this.;;;","07/Jun/21 19:29;stefan.miklosovic;I can not reproduce it. Passes just fine in IDE.;;;","08/Jun/21 16:47;brandon.williams;This reproduces fairly frequently for me.  Near as I could tell, FQL was simply failing to replay any statements aside from DDL.  I modified the test to retain the FQL logs, and indeed the statements appear to be missing from a failed run - I've attached both here.  This seems to be a legitimate bug in FQL.;;;","08/Jun/21 16:49;brandon.williams;I'll note though that I didn't see any of the ""background~resource~releaser"" issues.;;;","08/Jun/21 20:00;stefan.miklosovic;I am not sure I follow, I do exactly same steps as in the test but manually and it replays it just fine.

{code}
cql> CREATE KEYSPACE fql_ks WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};
shell> nodetool enablefullquerylog --path /tmp/cassandra/fqllogs
cql> CREATE TABLE fql_ks.fql_table (id int primary key);
cql> INSERT INTO fql_ks.fql_table (id) VALUES (1);
shell> nodetool disablefullquerylog
cql> DROP TABLE fql_ks.fql_table;
shell> nodetool replay --keyspace fql_ks --target 127.0.0.1 -- /tmp/cassandra/fqllogs 
cql> SELECT * from fql_ks.fql_table // this fails which we want
shell> nodetool replay --keyspace fql_ks --target 127.0.0.1 --replay-ddl-statements -- /tmp/cassandra/fqllogs 
cql> SELECT * from fql_ks.fql_table // I get 1 row
{code};;;","09/Jun/21 14:00;brandon.williams;I copied this test's behavior to a [python dtest|https://github.com/driftx/cassandra-dtest/tree/CASSANDRA-16720] which has looped thousands of times without failure. Given this I'm left to conclude we're dealing with another spooky behavior from an in-jvm dtest.  I propose we commit the python version and remove this one to retain coverage and get CI closer to green.;;;","09/Jun/21 14:16;e.dimitrova;+1 I was about to say that those class loaders issues seem like in-jvm framework issue. We should fix them at some point but I would suggest this to be post 4.0. I also don't think this is a product defect. Thanks [~brandon.williams]

I would suggest we commit the python test and leave this ticket marked open 4.0.x maybe? ;;;","09/Jun/21 14:40;stefan.miklosovic;However, I see that ""recycler"" exception from time to time when Cassandra is running long enough, seems non-deterministic at first sight ...

I will try to nail down if it is or is not happening really randomly. However, it is already released so that is not too bad but that log is concerning.

WARN [background~resource~releaser] 2021-06-09 14:37:32,315 Slf4jExceptionHandler.java:38 - Failed in release/close
 net.openhft.chronicle.core.io.ClosedIllegalStateException: net.openhft.chronicle.bytes.MappedBytesStore already released
 at net.openhft.chronicle.core.io.VanillaReferenceCounted.callOnRelease(VanillaReferenceCounted.java:99)
 at net.openhft.chronicle.core.io.VanillaReferenceCounted.release(VanillaReferenceCounted.java:90)
 at net.openhft.chronicle.core.io.AbstractReferenceCounted.release(AbstractReferenceCounted.java:123)
 at net.openhft.chronicle.bytes.AbstractBytes.performRelease(AbstractBytes.java:341)
 at net.openhft.chronicle.bytes.MappedBytes.performRelease(MappedBytes.java:535)
 at net.openhft.chronicle.core.io.BackgroundResourceReleaser.performRelease(BackgroundResourceReleaser.java:79)
 at net.openhft.chronicle.core.io.BackgroundResourceReleaser.runReleaseResources(BackgroundResourceReleaser.java:28)
 at java.lang.Thread.run(Thread.java:748)

 ;;;","09/Jun/21 14:40;brandon.williams;Committed and created CASSANDRA-16726 to follow up on the jvm dtest.;;;","09/Jun/21 15:11;e.dimitrova;Thank you [~stefan.miklosovic]. Looking forward to your findings and please reopen the ticket if you find legit bug. I don't want to ignore a valid issue. ;;;","05/Jul/21 22:27;stefan.miklosovic;I think [~dcapwell] has fixed this in CASSANDRA-16774.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Changing listen_address with prefer_local may lead to issues,CASSANDRA-16718,13382473,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,Jan Karlsson,Jan Karlsson,07/Jun/21 12:49,10/Jul/23 15:13,13/Jul/23 08:40,16/May/23 14:04,4.0.10,4.1.2,5.0,,,,,Local/Config,,,,0,,,"Many container based solution function by assigning new listen_addresses when nodes are stopped. Changing the listen_address is usually as simple as turning off the node and changing the yaml file. 

However, if prefer_local is enabled, I observed that nodes were unable to join the cluster and fail with 'Unable to gossip with any seeds'. 

Trace shows that the changing node will try to communicate with the existing node but the response is never received. I assume it is because the existing node attempts to communicate with the local address during the shadow round.

 ",,bereng,brandon.williams,e.dimitrova,Jan Karlsson,masokol,mfleming,tommy_s,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-18560,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Availability,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Jul 10 15:08:37 UTC 2023,,,,,,,All,,,,"0|z0rpy8:",9223372036854775807,,,,bereng,,,,Normal,,NA,,https://github.com/apache/cassandra/commit/b791644fda91b343a679bb0c2c1e33e594524636,,,,,,,,,"test included, CI",,,,,"07/Jun/21 12:57;Jan Karlsson;dtest to repro can be found [here|https://github.com/itskarlsson/cassandra-dtest/tree/CASSANDRA-16718]. It works if prefer_local is set to false.

 ;;;","03/Aug/21 09:31;Jan Karlsson;Took a look at the code base. It seems to be quite a difficult thing to change as it is intertwined with the message pools per node. Maybe someone with more experience with the networking can shed some light on the issue.;;;","25/Aug/21 14:56;brandon.williams;Can you describe the network configuration here that requires prefer_local?;;;","01/Sep/21 07:09;esimfon;Hi [~brandon.williams],

Jan asked me to answer since I have a deeper knowledge in the issue at hand.

We deploy Cassandra in a Kubernetes cluster. To achieve external connectivity to remote DCs (Cassandra DCs in different Kubernetes clusters) we use MetalLB (one LoadBalancer Service per Pod). Some of our deployments use traffic policy ""Cluster"" which doesn't preserve source IP.
{quote}However, kube-proxy will obscure the source IP address of the connection when it does load balancing, so your pod logs will show that external traffic appears to be coming from the service’s leader node.
{quote}
- [https://metallb.universe.tf/usage/#cluster-traffic-policy]

We have a Cassandra plugin which uses the IP for its execution logic. With prefer_local=false all traffic (incl. local traffic) will go through the load balancer and therefore obscures the source IP. With prefer_local the source IP for local nodes is preserved so it's available to our plugin.

Let me know if you need more details.;;;","01/Sep/21 14:26;brandon.williams;Adjusting fixvers as this passes on 3.0, but not 3.11 or 4.0.;;;","01/Sep/21 22:15;brandon.williams;-This has been broken since CASSANDRA-10134, though I'm not sure how yet-.  What is strange to me is that this issue persists even if both nodes are restarted, so something is being persisted incorrectly here.;;;","03/Sep/21 17:05;brandon.williams;-This issue boils down to CASSANDRA-10134 loading the ring state, which includes preferred_ip.-  OTC then queries this directly if it exists and uses it before any changes can be learned.  Given this, I'm not sure it even makes sense to store the preferred_ip, since if we try to use it eagerly we'll never be able to learn of the change to it, as this issue exemplifies.  I think the best plan is just to remove this optimization and do the reconnection dance every time, which still shouldn't be super-often. WDYT, [~samt]?

-In the meantime, operators may add {{-Dcassandra.load_ring_state=false}} if that's an acceptable workaround.-;;;","07/Sep/21 20:33;brandon.williams;Actually, CASSANDRA-10134 didn't break this, but it fixed the server's behavior such that the test was deterministic after it; before we will mark the node up, but then fail to connect to the old IP forever and eventually mark the node back down due to lack of communication, tricking the test into thinking it passed. :(  I will keep digging, but I suspect the solution is likely the same: don't persist and use preferred_ip, only the gossip state that is present.;;;","08/Sep/21 08:07;Jan Karlsson;Great findings so far. Thank you for taking the time to dig into this.

I agree that the old local address is persisted somewhere and therefore used by the existing node. However, in an attempt to verify your findings I modified my test case to manually change the preferred_ip before I start the last node so that it points to the correct address. The test still fails even with an updated preferred_ip.

My original thought was that the Gossiper was persisting this ip in endpointStateMap. During checkEndpointCollison, the UP node will attempt to connect through the local address before this address is updated by the ShadowRound.;;;","09/Sep/21 22:54;brandon.williams;What I have discovered is that with all persistence removed and every call relying what information the Gossiper has for the node, this will _still_ use the old address, because only a SYN has been received from the updated node, so checks on the internal state will use the stale information.  This is going to be trickier than I suspected.
;;;","10/Sep/21 21:55;brandon.williams;[Here|https://github.com/driftx/cassandra/tree/CASSANDRA-16718] is a 3.11 branch that passes a slightly more thorough [dtest that reads at ALL|https://github.com/driftx/cassandra-dtest/tree/CASSANDRA-16718] in a [CI run|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1109/pipeline].

This works by removing the _use_ of persistence in OutboundTcpConnectionPool, but still persists the IP for later usage, and ReconnectingSnitchHelper _removes_ the INTERNAL_IP state upon the node being marked down so that changes can be learned in the next connection.

I'll have to come up with something similar for 4.0 and trunk, since they don't have OTCP after the messaging service refactoring.
;;;","13/Sep/21 20:19;brandon.williams;||Branch||Jenkins||Circle||
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16718]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1116/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1116/pipeline]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16718]|
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-4.0]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1113/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1113/pipeline]|[j8, j11|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16718-4.0]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-trunk]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/1115/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/1115/pipeline]|[j8, j11|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16718-trunk]|
;;;","14/Sep/21 20:08;brandon.williams;There are a couple of tests that are now too synthetic to pass like the EC2SnitchTest.testEc2MRSnitch and OutboundConnectionsTest.reconnectWithNewIp since both try to pass an arbitrary IP address to reconnect to, where now only the live gossip value is used.  I'm not sure it's worth fleshing those into more thorough tests like the dtest in the patch that covers this.;;;","16/Sep/21 10:42;Jan Karlsson;LGTM. Seems to fix the issue completely. However, preferred_ip is null after your patch throughout the test. Is this an intended side effect?;;;","16/Sep/21 15:48;brandon.williams;Hmm, no.  I left the [call in reconnect that updates it|https://github.com/driftx/cassandra/commit/f2b7b335a89c64eb478424eb6a9a027e59995c4a#diff-3fe65944fc6b986688040b3a9400cd5a0bd798cca29e0f3b399db5ece33dc1f1L108] intentionally so CASSANDRA-8084 would continue to work, I only removed an earlier call to retrieve it.  How did you observe this?

This raises a greater question though, perhaps we should remove the persistence altogether and rework CASSANDRA-8084's bits to work like this too.  I'll wait for reviewer feedback before pulling that trigger though.;;;","17/Sep/21 06:54;Jan Karlsson;Observed this by fetching the peers table before stopping node2 in my dtest.

Without the patch I observed preferred_ip populated but with the patch it is null throughout the test.;;;","27/Apr/22 09:57;Jan Karlsson;[~brandon.williams] The ticket has been quiet for awhile now. What is the status on this? Are we waiting for a reviewer?;;;","27/Apr/22 11:30;brandon.williams;Yes and I don't imagine we will get one at this point until after 4.1 releases.  After that I will come back to this and see if it can be driven forward.;;;","20/Jan/23 10:10;tommy_s;Any status updates on this issue? since 4.1 has been release for a while.;;;","20/Jan/23 11:54;brandon.williams;Let me refresh this for the current branches and locate a reviewer.;;;","24/Jan/23 14:57;brandon.williams;||Branch||CI||
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-3.11]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/816/workflows/dba0aab7-0267-49bf-8306-19720c065b92] |
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-4.0]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/815/workflows/e84f0d6c-6497-45f8-b81f-9443c59762a3] [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/815/workflows/c131fd88-74e7-46d6-869d-5199c11d898b] |
|[4.1|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-4.1]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/814/workflows/82a2acd8-d124-4c93-b018-e29642655e33] [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/814/workflows/754fe3ba-a08f-4ceb-b95f-65596e1710b0] |
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-trunk]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/813/workflows/bf6e0bcf-53a2-4888-bc8d-3234af2b3c23] [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/813/workflows/4df118dc-b1a7-4034-bc2e-114c5676126a] |

The current state here is the 3.11 patch breaks test_prefer_local_reconnect_on_listen_address and seems to legitimately not reconnect (but does pass the restart test), and the 4.x patch doesn't seem to work, it's still holding on to the old address somewhere.;;;","30/Jan/23 14:40;masokol;I've tried your patch for 4.0 Brandon. What still holds the old address are the connectionPools that are cached in MessagingService.

When the affected connectionPools are removed the dtest is green. Here's [my branch|https://github.com/masokol/cassandra/tree/CASSANDRA-16718-4.0] for reference.;;;","01/Feb/23 16:04;brandon.williams;Thanks, Maciej!  That's very helpful and I've incorporated your patch into my branch.  I think I also figured out what was wrong with 3.11, let's see what circle thinks.

||Branch||CI||
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-3.11]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/848/workflows/9bc58300-b9ab-4676-b850-5fbedd6221d9]|
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-4.0]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/849/workflows/28bb4215-1a9c-4cc5-a1cf-91140dd8f998], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/849/workflows/ad575adc-a991-4290-a221-b0d1031fef7c]|
|[4.1|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-4.1]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/846/workflows/42d858fc-66ea-473c-9315-92c1da75c1ed], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/846/workflows/226864ea-73a0-4bb5-94f2-96abcf0a3331]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-trunk]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/847/workflows/1e8c1c54-3ddc-4184-a592-46912379e4c4], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/847/workflows/c4cdccb4-8318-4dd7-8279-806c66acf14e]|
;;;","01/Feb/23 17:17;brandon.williams;bq.  I think I also figured out what was wrong with 3.11

Well, partially.  Now the reconnect test fails.  We can probably just remove testEc2MRSnitch since that was done in CASSANDRA-8457 and it's covered by the other reconnection tests.  Then there's the HandshakeTest in trunk.;;;","06/Feb/23 15:00;masokol;There's a Jira for the handshake being flaky CASSANDRA-17979;;;","17/Feb/23 07:52;masokol;[~brandon.williams] could you rebase and rerun CI? I think the ticket i linked in previous comment should resolve the failing test in trunk. If that's the case then I guess we only need to decide what to do with testEc2MRSnitch and then the patch should be ready?;;;","17/Feb/23 11:23;brandon.williams;We can remove testEc2MRSnitch since that is removed in 4.0 and later anyway... but the real issue is 3.11 doesn't work correctly.  Either test_prefer_local_reconnect_on_listen_address or test_prefer_local_reconnect_on_restart fails depending on which approach is attempted.

Given this, and that the message service was [rewritten|https://issues.apache.org/jira/browse/CASSANDRA-15066] for 4.0, and with 4.2/5.0 releasing in the coming months which will EOL it, I think we should just quit targeting 3.11.

Then we can rebase and run CI and we should be ready.;;;","21/Apr/23 13:32;masokol;You are right, it feels strange to break existing functionality in an older branch. [~brandon.williams] could you rebase and run CI when you get the time? Or are we waiting for something?;;;","26/Apr/23 18:07;brandon.williams;Rebased:

||Branch||CI||
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-4.0]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/987/workflows/10f7377e-82a4-4e3c-a1ef-9a4434cf2dec], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/987/workflows/62eee3b3-b51b-4f86-bdaf-77e102787b47]|
|[4.1|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-4.1]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/985/workflows/5341072c-542e-4f0a-af90-98624e59cc07], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/985/workflows/5e3a1e1f-7004-48fc-b0c6-faff7ef95914]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-trunk]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/986/workflows/9ab17625-3937-4daf-9c73-ffa77cc0f703], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/986/workflows/1d17e818-b3b2-4732-bb11-75f77d6de8d3]|
;;;","04/May/23 06:13;bereng;[~brandon.williams] are those branch links correct? the latest commit in the history takes me to a massive merge commit.;;;","04/May/23 10:34;brandon.williams;Heh, it's actually in there, it's just the code is from 2021 at this point.  Let me recreate the branches so it's easy to find.;;;","04/May/23 10:51;brandon.williams;Branch links above updated so the commit you need is first; no code changes.;;;","04/May/23 21:37;mfleming;Patch looks good to me. nb +1;;;","05/May/23 07:24;bereng;^Can you please trigger upgrade tests [~brandon.williams]? I've had some re-connect errors show in them that wouldn't otherwise.;;;","05/May/23 10:03;brandon.williams;Upgrade tests started.;;;","05/May/23 12:55;bereng;Idk if circle is having issues, if there are legit bootstrap failures or both. Looks like the bootstrap tests are failing. You should also trigger the jvm_upgrade ones in light of those failures.;;;","05/May/23 13:57;brandon.williams;{noformat}
node1: ERROR [main] 2023-05-05 10:29:38,129 CassandraDaemon.java:910 - Exception encountered during startup
org.apache.cassandra.exceptions.ConfigurationException: JavaScript user-defined functions were removed in CASSANDRA-18252. Hooks are planned to be introduced as part of CASSANDRA-17280
{noformat}

I'm not sure what's going on here, it doesn't seem to be from this patch.  I see other upgrade issues on CASSANDRA-18499, perhaps this is related.  I started the jvm upgrade tests anyway, let's see how that goes.;;;","05/May/23 14:15;brandon.williams;Ekaterina pointed out I completely hosed the circle config when I rebased and my dtest branch wasn't rebased.  I've fixed both of those, let's try again:

||Branch||CI||
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-4.0]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/1005/workflows/40522429-d127-4625-88ec-c95756012745], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/1005/workflows/831b59b2-6414-4e67-a01f-1ec2dc4a54fe]|
|[4.1|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-4.1]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/1006/workflows/458edc48-bff7-41be-82ee-e1cd5aaf604a], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/1006/workflows/4b14c842-4962-453d-a7b8-4230e5aa8ddb]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16718-trunk]|[j8|https://app.circleci.com/pipelines/github/driftx/cassandra/1004/workflows/855c944b-a0b2-4d04-b635-6a4a6aed2c14], [j11|https://app.circleci.com/pipelines/github/driftx/cassandra/1004/workflows/201189e7-637d-429c-90bd-98adf9b3f3fc]|
;;;","08/May/23 05:24;bereng;It seems there is a failure in trunk that doesn't align with current trunk CI. It would be good to also put up the link to the dtests branch and amend that one so the latest commit is just the changes from the branch, rather than the big merge?;;;","15/May/23 20:45;brandon.williams;Those failures are CASSANDRA-18499.  I've rebased the dtest branch [here|https://github.com/driftx/cassandra-dtest/tree/CASSANDRA-16718] with Jan's commit (and my addition to it) as the latest.;;;","16/May/23 05:18;bereng;+1;;;","16/May/23 14:04;brandon.williams;Finally committed!  Thanks for the review!;;;","10/Jul/23 15:08;brandon.williams;This was reverted in CASSANDRA-18560.  We will make another attempt on CASSANDRA-18657.;;;",,,,,,,,,,
Flaky TestConsistency.test_13880,CASSANDRA-16716,13382389,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,07/Jun/21 07:31,27/May/22 19:25,13/Jul/23 08:40,08/Jun/21 05:45,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/dtest/python,,,,0,,,"Flaky [TestConsistency.test_13880|https://ci-cassandra.apache.org/job/Cassandra-4.0.0/8/testReport/junit/dtest.consistency_test/TestConsistency/test_13880/]

{noformat}
Error Message

cassandra.Unavailable: Error from server: code=1000 [Unavailable exception] message=""Cannot achieve consistency level ALL"" info={'consistency': 'ALL', 'required_replicas': 2, 'alive_replicas': 1}

Stacktrace

self = <consistency_test.TestConsistency object at 0x7f9d2245d070>

    @since('3.0')
    @ported_to_in_jvm('4.0')
    def test_13880(self):
        """"""
            @jira_ticket CASSANDRA-13880
            """"""
        cluster = self.cluster
    
        # disable hinted handoff and set batch commit log so this doesn't interfere with the test
        cluster.set_configuration_options(values={'hinted_handoff_enabled': False})
        cluster.set_batch_commitlog(enabled=True)
    
        cluster.populate(2).start()
        node1, node2 = cluster.nodelist()
    
        session = self.patient_cql_connection(node1)
    
        query = ""CREATE KEYSPACE IF NOT EXISTS test WITH replication = {'class': 'NetworkTopologyStrategy', 'datacenter1': 2};""
        session.execute(query)
    
        query = ""CREATE TABLE IF NOT EXISTS test.test (id int PRIMARY KEY);""
        session.execute(query)
    
        stmt = SimpleStatement(""INSERT INTO test.test (id) VALUES (0);"",
                               consistency_level=ConsistencyLevel.ALL)
        session.execute(stmt)
    
        # with node2 down and hints disabled, delete the partition on node1
        node2.stop(wait_other_notice=True)
        session.execute(""DELETE FROM test.test WHERE id = 0;"")
        node2.start()
    
        # with both nodes up, do a CL.ALL query with per partition limit of 1;
        # prior to CASSANDRA-13880 this would cause short read protection to loop forever
>       assert_none(session, ""SELECT DISTINCT id FROM test.test WHERE id = 0;"", cl=ConsistencyLevel.ALL)

consistency_test.py:1170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tools/assertions.py:147: in assert_none
    res = session.execute(simple_query)
../venv/src/cassandra-driver/cassandra/cluster.py:2618: in execute
    return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile, paging_state, host, execute_as).result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ResponseFuture: query='<SimpleStatement query=""SELECT DISTINCT id FROM test.test WHERE id = 0;"", consistency=ALL>' re...cy level ALL"" info={'consistency': 'ALL', 'required_replicas': 2, 'alive_replicas': 1} coordinator_host=127.0.0.1:9042>

    def result(self):
        """"""
            Return the final result or raise an Exception if errors were
            encountered.  If the final result or error has not been set
            yet, this method will block until it is set, or the timeout
            set for the request expires.
    
            Timeout is specified in the Session request execution functions.
            If the timeout is exceeded, an :exc:`cassandra.OperationTimedOut` will be raised.
            This is a client-side timeout. For more information
            about server-side coordinator timeouts, see :class:`.policies.RetryPolicy`.
    
            Example usage::
    
                >>> future = session.execute_async(""SELECT * FROM mycf"")
                >>> # do other stuff...
    
                >>> try:
                ...     rows = future.result()
                ...     for row in rows:
                ...         ... # process results
                ... except Exception:
                ...     log.exception(""Operation failed:"")
    
            """"""
        self._event.wait()
        if self._final_result is not _NOT_SET:
            return ResultSet(self, self._final_result)
        else:
>           raise self._final_exception
E           cassandra.Unavailable: Error from server: code=1000 [Unavailable exception] message=""Cannot achieve consistency level ALL"" info={'consistency': 'ALL', 'required_replicas': 2, 'alive_replicas': 1}

../venv/src/cassandra-driver/cassandra/cluster.py:4894: Unavailable

REST API
CloudBees CI Client Master 2.263.4.2-rolling

    Documentation
    KnowledgeBase
    www.cloudbees.com
{noformat}
",,adelapena,bereng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Jun 08 11:00:02 UTC 2021,,,,,,,All,,,,"0|z0rpfk:",9223372036854775807,,,,adelapena,,,,Normal,,4.0,,https://github.com/apache/cassandra-dtest/commit/213e87b97944dd9f0562c57435ceb42b2b83e07a,,,,,,,,,See PR,,,,,"07/Jun/21 07:54;bereng;The problem appears to be waiting for nodes to be ready to accept CQL. I had the intention to review the rest of node starts in the class, but every test case seems to specialized and would require individual investigation of edge cases per test case basis.;;;","07/Jun/21 16:36;adelapena;The fix looks good to me, +1. I have run the patched test in the multiplexer 1000 times for each affected branch:
||branch||vnodes||Java version||run||
|3.0|no|j8-j8|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/549/workflows/8359c5ba-7e5d-4518-a88b-14eef750495c/jobs/5013]|
|3.0|yes|j8-j8|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/550/workflows/b776a80e-cfaf-41e3-b052-218a0298bc08/jobs/5019]|
|3.11|no|j8-j8|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/548/workflows/e36686eb-8152-4694-b122-d355e5cf7736/jobs/5008]|
|3.11|yes|j8-j8|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/551/workflows/dc63ce83-4fdd-4c69-a772-fc72d43b5d20/jobs/5017]|
|4.0.0|yes|j8-j8|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/554/workflows/2d392810-dede-49ce-93f4-3463fbc7a643/jobs/5047]|
|4.0.0|yes|j8-j11|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/554/workflows/2d392810-dede-49ce-93f4-3463fbc7a643/jobs/5049]|
|4.0.0|yes|j11-j11|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/554/workflows/fcf34d67-7d35-41cf-9c10-c74e0921959c/jobs/5053]|
|4.0|yes|j8-j8|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/552/workflows/86dafd41-9d45-4a5f-9856-d81368190685/jobs/5032]|
|4.0|yes|j8-j11|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/552/workflows/86dafd41-9d45-4a5f-9856-d81368190685/jobs/5028]|
|4.0|yes|j11-j11|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/552/workflows/7a3bc034-bed5-444b-aabe-f23b74bdb73a/jobs/5025]|
|trunk|yes|j8-j8|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/553/workflows/c2ee6a5b-fad9-4d8d-9f0c-e496ee247e34/jobs/5039]|
|trunk|yes|j8-j11|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/553/workflows/c2ee6a5b-fad9-4d8d-9f0c-e496ee247e34/jobs/5035]|
|trunk|yes|j11-j11|[link|https://app.circleci.com/pipelines/github/adelapena/cassandra/553/workflows/c85c9b63-53a4-4be0-8347-982a7b18e756/jobs/5041]|

All the above runs pass.;;;","08/Jun/21 05:00;bereng;Oh did you run it yourself out of completion bc you wanted 1K runs? I had done 100 runs maybe it was not clear in the PR.;;;","08/Jun/21 11:00;adelapena;Yes, I wanted to try some more runs just in case, and also test other branches for completion.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix org.apache.cassandra.utils.SlidingTimeRateTest.testConcurrentUpdateAndGet,CASSANDRA-16714,13382240,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,Gerrrr,e.dimitrova,e.dimitrova,04/Jun/21 22:51,07/Jul/21 18:12,13/Jul/23 08:40,07/Jul/21 18:10,,,,,,,,Test/unit,,,,0,,,"Fix org.apache.cassandra.utils.SlidingTimeRateTest.testConcurrentUpdateAndGet in Cassandra 3.11 

[https://jenkins-cm4.apache.org/job/Cassandra-3.11/174/testReport/junit/org.apache.cassandra.utils/SlidingTimeRateTest/testConcurrentUpdateAndGet_cdc/]

We should also propagate the fix to 4.0 where the utility class and the tests also exist but they are not currently in use so to remove the noise the tests are currently skipped from running at the moment. For reference - CASSANDRA-16713

 ",,e.dimitrova,Gerrrr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16713,,,,CASSANDRA-16713,,,,,,,,,,,,,,,,,,,0.0,Gerrrr,,,,,,,,,,,,,Degradation,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jul 07 18:12:06 UTC 2021,,,,,,,All,,,,"0|z0roig:",9223372036854775807,,,,e.dimitrova,,,,Normal,,3.11.5,,https://github.com/apache/cassandra/commit/f3c2d3a0f9e1867f6976fabec35e4e02f5289c37,,,,,,,,,"{{SlidingTimeRateTest}} fails if the executor runs with a higher thread count, and the run is lucky enough to get a near-uniform work distribution.

I was able to reproduce the issue by decreasing {{updates}} to 10000 and adding a sleep statement after {{rate.update(1)}}:
{noformat}
            executor.submit(() -> {
                threadCnt.computeIfAbsent(Thread.currentThread().getId(), (n) -> new AtomicInteger())
                         .incrementAndGet();
                time.sleep(1, TimeUnit.MILLISECONDS);
                rate.update(1);
                try
                {
                    Thread.sleep(2);
                }
                catch (InterruptedException ie) {}
            });
{noformat}

In the snippet above I've also added a per-thread increment to measure work distribution. The results are:

Without sleep (test passes):
{noformat}
{16=1752, 17=1441, 18=420, 19=1434, 20=468, 21=1259, 22=582, 23=568, 24=670, 13=387, 14=508, 15=511}
{noformat}

With sleep (test fails):
{noformat}
{16=833, 17=834, 18=835, 19=833, 20=833, 21=833, 22=833, 23=833, 24=834, 13=833, 14=833, 15=833}
{noformat}

As a result of the uniform work distribution, concurrent updates hit same timestamp more frequently which in turn makes the test run quicker in {{TestTimeSource}} terms with more hits per timestamp. 

I suggest to set thread pool size to, say, 4 as well as to increase tolerated delta to 150. The former will limit the impact of the work distribution effect  while the latter sets more realistic boundaries on the possible values ([patch|https://github.com/apache/cassandra/compare/trunk...Gerrrr:16714-3.11?expand=1]). ",,,,,"29/Jun/21 00:40;e.dimitrova;I took a quick look on the patch and I think that should work and lead to deterministic behavior. I just pushed CI run and the test in a loop 10 000 times with your patch [here|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/1012/workflows/7ddcc619-9bf1-40af-a781-3fc541cfa187]

I will finish my review tomorrow.;;;","30/Jun/21 01:04;e.dimitrova;LGTM and it passes 10 000 runs in CI. +1

[~brandon.williams], can you also review it, please? 

 ;;;","30/Jun/21 01:13;brandon.williams;+1;;;","07/Jul/21 18:12;e.dimitrova;Fixed for 3.11. I didn't apply the patch and remove the ignore for 4.0 and trunk intentionally for now. 

I will come back to this after 4.0 GA. The class s not currently even in use in 4.0 and trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix org.apache.cassandra.utils.SlidingTimeRateTest.testConcurrentUpdateAndGet,CASSANDRA-16713,13382226,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,04/Jun/21 21:01,27/May/22 19:25,13/Jul/23 08:40,04/Jun/21 22:49,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/unit,,,,0,,,"Example failure:

[https://ci-cassandra.apache.org/job/Cassandra-4.0/67/testReport/junit/org.apache.cassandra.utils/SlidingTimeRateTest/testConcurrentUpdateAndGet_cdc/]

History of failing 3-4 times lately like that in Jenkins:

https://jenkins-cm4.apache.org/job/Cassandra-4.0/76/testReport/junit/org.apache.cassandra.utils/SlidingTimeRateTest/testConcurrentUpdateAndGet_cdc/history/

 ",,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16714,,,,CASSANDRA-16714,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Degradation,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jun 04 22:55:57 UTC 2021,,,,,,,All,,,,"0|z0rofc:",9223372036854775807,,,,brandon.williams,e.dimitrova,,,Normal,,3.11.10,,https://github.com/ekaterinadimitrova2/cassandra/commit/fa016965c0c1399d4f0ef497ce79ef43e83bd051,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16713?focusedCommentId=17357656&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17357656,,,,,"04/Jun/21 21:03;e.dimitrova;I didn't manage to reproduce it locally and in Circle CI multiplexer for now;;;","04/Jun/21 21:44;e.dimitrova;I have a suspicion we don't even need/use the utility SlidingTimeRate anymore... update coming soon;;;","04/Jun/21 22:27;e.dimitrova;Objects from SlidingTimeRate are created only in 3.11. I see failures for this test in Jenkins for 3.11 too so I think this will deserve some attention but it is not an urgent priority for 4.0 or a blocker

I suggest to skip the test in 4.0 plus add a comment in SlidingTimeRate in case someone decides to use it at some point... Patch suggested [here|https://github.com/ekaterinadimitrova2/cassandra/commit/fa016965c0c1399d4f0ef497ce79ef43e83bd051]

Probably we can then close this ticket for 4.0 and open one for 3.11 to fix the test whoever has the time? Unfortunately, I won't have the time to dig into this problem now as part of this ticket. ;;;","04/Jun/21 22:27;e.dimitrova;[~brandon.williams] do you mind to review it, please? ;;;","04/Jun/21 22:31;brandon.williams;+1;;;","04/Jun/21 22:48;e.dimitrova;Committed:

520489791f..f83f2a3570  cassandra-4.0 -> cassandra-4.0

0f034373de..159469834a  cassandra-4.0.0 -> cassandra-4.0.0

6f2807b9f5..4fd2124572  trunk -> trunk

Thank you very much for the quick review and happy weekend :) ;;;","04/Jun/21 22:55;e.dimitrova;New ticket was opened to facilitate the fix of the issue in Cassandra 3.11 - CASSANDRA-16714;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DROP COMPACT STORAGE does not invalidate prepared statements as it should ,CASSANDRA-16712,13382092,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,blerer,blerer,04/Jun/21 09:00,04/Jun/21 16:00,13/Jul/23 08:40,04/Jun/21 11:29,3.0.25,3.11.11,,,,,,Cluster/Schema,,,,0,,,"{{DROP COMPACT STORAGE}} might change the number of columns of a table but as the prepared statement cache is not invalidate the query will not return the correct set of columns until the statement as been invalidate. That can lead to a surprising behavior where the resultset change at un expected point in time.

This problem only affect 3.0 and 3.11",,blerer,mck,,,,,,,,,,,,,,"blerer opened a new pull request #1040:
URL: https://github.com/apache/cassandra/pull/1040


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 09:17;githubbot;600","blerer commented on pull request #1040:
URL: https://github.com/apache/cassandra/pull/1040#issuecomment-854836368


   Merged manually


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 16:00;githubbot;600","blerer closed pull request #1040:
URL: https://github.com/apache/cassandra/pull/1040


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 16:00;githubbot;600","blerer commented on pull request #1039:
URL: https://github.com/apache/cassandra/pull/1039#issuecomment-854836597


   Merged manually


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 16:00;githubbot;600","blerer closed pull request #1039:
URL: https://github.com/apache/cassandra/pull/1039


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 16:00;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,3000,,,0,3000,,,,,,,,,,,,,,,CASSANDRA-16671,,,,CASSANDRA-16361,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Correctness -> Transient Incorrect Response,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jun 04 11:29:52 UTC 2021,,,,,,,All,,,,"0|z0rnlk:",9223372036854775807,,,,blerer,mck,,,Normal,,3.0.0,,https://github.com/apache/cassandra/commit/0e1f217079fa01366d9c8d758498016300467d31,,,,,,,,,One of the result expected by a test was wrong. The test was modified to expect the correct behavior.,,,,,"04/Jun/21 09:20;blerer;|| Branches || CI ||
| [3.0|https://github.com/apache/cassandra/pull/1039] | [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/132/workflows/ab9add3f-4f8a-4993-946d-3ad7a59b4a66] |
| [3.11|https://github.com/apache/cassandra/pull/1040] | [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/131/workflows/150a3108-3afb-4a73-a70e-cd79b78ffd6e] |;;;","04/Jun/21 10:16;mck;+1

CASSANDRA-16361 missed including this change on the 3.0 and 3.11 branches.;;;","04/Jun/21 11:29;blerer;Patch committed into 3.0 at 0e1f217079fa01366d9c8d758498016300467d31 and merged into cassandra-3.11;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Split ViewComplexTest to avoid timeouts after being moved away from 'long' junits,CASSANDRA-16711,13382054,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,04/Jun/21 04:31,27/May/22 19:25,13/Jul/23 08:40,09/Jun/21 06:51,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/unit,,,,0,,,Under CASSANDRA-16670 we decided to move some tickets from the 'long' junit section to the std one. This required splitting them to avoid timing out but ViewComplexTest needs further splitting.,,bereng,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16670,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jun 09 07:02:32 UTC 2021,,,,,,,All,,,,"0|z0rnd4:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/3e153c88547de4227f2758d15abeadc82a7138fe,,,,,,,,,See PR,,,,,"04/Jun/21 05:46;bereng;[~edimitrova] up for review the latest test split. Now they are 1m and 2m respectively and it should get them under the 4m timeout. There's no way to get 50% split as a single test case takes 1m alone...;;;","04/Jun/21 15:27;e.dimitrova;A super nit there that could be addressed on commit but LGTM, I will submit now Jenkins run for completeness as this is where we see the timeouts and I think we should be good to go. Thank you;;;","04/Jun/21 15:36;e.dimitrova;Jenkins CI run was submitted [here |https://ci-cassandra.apache.org/job/Cassandra-devbranch/843/];;;","04/Jun/21 18:36;e.dimitrova;-In the meanwhile I will open another ticket for this for Monday - [https://jenkins-cm4.apache.org/job/Cassandra-4.0.0/5/testReport/junit/org.apache.cassandra.cql3/ViewTest/testClusteringOrder/] :( Seems like we need more for that one too...-

Not opening a ticket, after more careful check seems like random timeout this time;;;","07/Jun/21 04:31;bereng;^Yep we have a bunch of these, I keep thinking we need to raise timeouts.

Jenkins run lgtm but again, in my experience while working on tickets, it depends a lot on what was running on jenkins at the time...;;;","07/Jun/21 05:57;bereng;[~e.dimitrova] I added that nit but also:
- I saw ViewFilteringClusteriong
- I saw ViewTest timming out. This one was not touched in CASSANDRA-16670, so it's just the generic low timeout issue.;;;","07/Jun/21 20:04;e.dimitrova;I would suggest we leave this issue for a bit as IMHO this is just tuning and not really a blocker for 4.0, WDYT?

I mean I am +1 to commit the proposed split but if it continues to timeout here or there for the same reasons, let's leave it away for a bit.;;;","08/Jun/21 05:07;bereng;-1. It is ready to commit and it would be 'wasted effort' imo. I am happy to not go splitting tests further and explore the timeout issue, but lets merge this as it's ready. wdyt?;;;","08/Jun/21 13:27;e.dimitrova;Sorry, I wasn't clear, +1 to commit and by "" if *it* continues to timeout here or there for the same reasons, let's leave *it* away for a bit"" I meant to leave *the problem* post-commit for a bit if we see again timeouts. Thank you;;;","09/Jun/21 07:02;bereng;Ah thx I understand now apologies. Thx!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix org.apache.cassandra.tools.nodetool.StatusTest.testOutputWhileBootstrapping,CASSANDRA-16708,13381800,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,02/Jun/21 22:13,27/May/22 19:25,13/Jul/23 08:40,04/Jun/21 01:09,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/unit,,,,0,,,[https://jenkins-cm4.apache.org/job/Cassandra-4.0/71/testReport/junit/org.apache.cassandra.tools.nodetool/StatusTest/testOutputWhileBootstrapping_cdc/],,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16612,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jun 04 01:05:28 UTC 2021,,,,,,,All,,,,"0|z0rlso:",9223372036854775807,,,,brandon.williams,e.dimitrova,,,Low,,4.0-rc1,,https://github.com/apache/cassandra/commit/31c1bbe87f8e376f353df2a16881124122045936,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16708?focusedCommentId=17356740&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17356740,,,,,"03/Jun/21 21:35;e.dimitrova;It seems that _FileUtils#stringifyFileSize_ returns an Integer if we provide a Double number like #.00.

For example _FileUtils#stringifyFileSize(4.00)_ or _FileUtils#stringifyFileSize(4.0)_ will turn into ""4"".

That is how the java format() method used by _FileUtils#stringifyFileSize_ works.

I fixed the tests in  org.apache.cassandra.tools.nodetool.StatusTest to look for both Integer and Double in this [patch|https://github.com/ekaterinadimitrova2/cassandra/pull/134/commits/faf03246dd568188a7c3c5eeb7b0727cb15b2070].

Thousand successful runs can be found here:
[Java 8|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/921/workflows/e5e6b3d3-b080-4e4e-a87c-161fc52c2c63/jobs/5489]
[Java 11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/921/workflows/2c51455d-6ebd-4627-b764-f59f71c23585/jobs/5484]
[build Java 8, run Java 11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/921/workflows/e5e6b3d3-b080-4e4e-a87c-161fc52c2c63/jobs/5485] 
;;;","03/Jun/21 21:36;e.dimitrova;[~brandon.williams], do you mind to review this one, please?;;;","03/Jun/21 21:44;brandon.williams;+1, good catch.;;;","04/Jun/21 01:05;e.dimitrova;Pushed to all three branches where we have those tests, thank you:

e6946e7ddb..f74ce55dab  cassandra-4.0 -> cassandra-4.0

3875fd26ea..31c1bbe87f  cassandra-4.0.0 -> cassandra-4.0.0

2227057ac3..51c6669676  trunk -> trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JmxHistogram#getRecentValues() is not thread-safe,CASSANDRA-16707,13381769,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,maedhroz,maedhroz,maedhroz,02/Jun/21 18:24,27/May/22 19:25,13/Jul/23 08:40,03/Jun/21 18:41,4.0.1,4.1,4.1-alpha1,,,,,Observability/JMX,,,,0,,,"Published {{JmxHistogram}} instances do not protect their “last” field. This isn’t a hot path, and there is a multi-part calculation based on it in {{getRecentValues()}}, so we should probably just synchronize that method.",,maedhroz,yifanc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-13642,,,,,,,,,,,,,,,,,,,,,,,0.0,maedhroz,,,,,,,,,,,,,Correctness -> Transient Incorrect Response,,,,,,,,Low Hanging Fruit,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jun 03 18:41:19 UTC 2021,,,,,,,All,,,,"0|z0rlls:",9223372036854775807,,,,brandon.williams,yifanc,,,Low,,4.0-rc2,,https://github.com/apache/cassandra/commit/e6946e7ddb76bd72109995664289e988b0e9818c,,,,,,,,,n/a,,,,,"02/Jun/21 18:38;brandon.williams;+1 if you just want to ninja a synchronize in there.;;;","02/Jun/21 20:01;maedhroz;[patch|https://github.com/apache/cassandra/pull/1035], [j8|https://app.circleci.com/pipelines/github/maedhroz/cassandra/248/workflows/e3aa2faf-e8c9-415e-9bbc-d6bab47a7123], [j11|https://app.circleci.com/pipelines/github/maedhroz/cassandra/248/workflows/117c61b9-165c-4006-a2fd-6c220d6460d2];;;","02/Jun/21 20:04;yifanc;I think we also need to synchronize the implementation in the JmxTimer.;;;","02/Jun/21 20:12;yifanc;+1 on the patch.;;;","03/Jun/21 18:41;maedhroz;Committed as https://github.com/apache/cassandra/commit/e6946e7ddb76bd72109995664289e988b0e9818c;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CCM extra logging,CASSANDRA-16705,13381399,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,01/Jun/21 07:48,27/May/22 19:24,13/Jul/23 08:40,04/Jun/21 07:40,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/dtest/python,,,,0,,,During CASSANDRA-16644 it was detected extra logging in CCM would come by very useful so we're adding it here,,bereng,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jun 04 12:58:33 UTC 2021,,,,,,,All,,,,"0|z0rjc0:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0,,https://github.com/riptano/ccm/commit/358c06781c4a8b85dcfca49449232b7405dacc0c,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16705?focusedCommentId=17356249&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17356249,,,,,"03/Jun/21 07:32;bereng;[CI|https://ci-cassandra.apache.org/job/Cassandra-devbranch/839/] unrelated failures. [~edimitrova] this sould be a quick review for you. After all the time and many CI changes I did run CI to be on the safe side.;;;","03/Jun/21 13:04;e.dimitrova;Technically already approved in CASSANDRA-16644, still LGTM :);;;","04/Jun/21 04:22;bereng;Yep but I didn't want to merge without a quic+1 thx :-);;;","04/Jun/21 12:58;e.dimitrova;Thanks;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Fix imports; run tests with packaged dependencies",CASSANDRA-16704,13381019,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,polo-language,polo-language,polo-language,28/May/21 16:03,27/May/22 19:25,13/Jul/23 08:40,12/Jun/21 10:05,4.0.1,4.1,4.1-alpha1,,,,,Build,Test/burn,Test/unit,,0,,,"Tests are currently run with a classpath containing _all_ downloaded jars. The tests would be more reflective of the behavior of a runtime environment if the test classpath only contained jars that are bundled with the binary release, together with explicit test dependencies. Ideally we'd use the build/lib/ jars for the classpath since that's what gets packaged, but since these aren't available at test compile time and should be identical to lib/ anyway, I've used the later.

Doing so exposed a couple of references in src/java to ""org.apache.commons.lang"", which is not available at runtime (should be ""org.apache.commons.lang*3*"").

Attached patch modifies the test classpath, fixes various imports in both test/ and src/ classes, and makes some simple substitutions in the tests such as using AbstractMap.SimpleEntry in place of org.apache.commons.collections.keyvalue.AbstractMapEntry.",,brandon.williams,mck,polo-language,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jun/21 17:26;polo-language;cleanup-imports.patch;https://issues.apache.org/jira/secure/attachment/13026625/cleanup-imports.patch","09/Jun/21 17:26;polo-language;dedup-deps.patch;https://issues.apache.org/jira/secure/attachment/13026624/dedup-deps.patch",,,,2.0,polo-language,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sat Jun 12 10:05:39 UTC 2021,,,,,,,All,,,,"0|z0rh14:",9223372036854775807,,,,mck,,,,Low,,4.0-rc1,,https://github.com/apache/cassandra/commit/d93e43ed9b3abad438c4ec9db6ae94d768f52896,,,,,,,,,run ci,,,,,"01/Jun/21 15:37;brandon.williams;[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/828/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/828/pipeline]
;;;","02/Jun/21 15:16;brandon.williams;LGTM, [~mck] can you take a look as well?;;;","03/Jun/21 10:53;mck;(To rehash, mostly for my own sake…)
The differences between {{build/lib/jars/}} and {{lib/}} are the following.

Only {{lib/}} contains:
- cassandra-driver-internal-only-3.25.0.zip
- futures-2.1.6-py2.py3-none-any.zip
- geomet-0.1.0.zip
- sigar-bin/
- six-1.12.0-py2.py3-none-any.zip

This is just the additional binary and python dependencies.

Only {{build/lib/jars/}} contains:
- antlr-3.5.2.jar
- assertj-core-3.15.0.jar
- byteman-4.0.6.jar
- byteman-bmunit-4.0.6.jar
- byteman-install-4.0.6.jar
- byteman-submit-4.0.6.jar
- commons-beanutils-1.7.0.jar
- commons-beanutils-core-1.8.0.jar
- commons-collections-3.2.1.jar
- commons-configuration-1.6.jar
- commons-digester-1.8.jar
- commons-el-1.0.jar
- commons-httpclient-3.0.1.jar
- commons-lang-2.4.jar
- commons-math-2.1.jar
- commons-net-1.4.1.jar
- compile-command-annotations-1.2.0.jar
- compress-lzf-0.8.4.jar
- ftplet-api-1.0.0.jar
- ftpserver-core-1.0.0.jar
- ftpserver-deprecated-1.0.0-M2.jar
- hadoop-core-1.0.3.jar
- hadoop-minicluster-1.0.3.jar
- hadoop-test-1.0.3.jar
- hsqldb-1.8.0.10.jar
- jackson-core-asl-1.0.1.jar
- jackson-mapper-asl-1.0.1.jar
- jacocoagent.jar
- jasper-compiler-5.5.12.jar
- jasper-runtime-5.5.12.jar
- jersey-core-1.0.jar
- jersey-server-1.0.jar
- jets3t-0.7.1.jar
- jetty-6.1.26.jar
- jetty-util-6.1.26.jar
- jsp-2.1-6.1.14.jar
- jsp-api-2.1-6.1.14.jar
- jsr305-2.0.2.jar
- jsr311-api-1.0.jar
- kfs-0.3.jar
- mina-core-2.0.0-M5.jar
- netty-bom-4.1.58.Final.pom
- oro-2.0.8.jar
- servlet-api-2.5-6.1.14.jar
- xmlenc-0.52.jar

This should be only the additional ""provided"" scope.

Maybe there are jar files here that should be removed, i.e. should not even be part the provided scope?

bq. Tests are currently run with a classpath containing all downloaded jars. 

To be accurate {{build/lib/jars/}}  is intended to be the [compile+provided scoped|https://github.com/apache/cassandra/blob/cassandra-4.0-rc1/.build/build-resolver.xml#L174] dependency tree, while {{lib/}} is only the [compile|https://github.com/apache/cassandra/blob/cassandra-4.0-rc1/.build/build-resolver.xml#L196] scoped dependency tree.

bq. The tests would be more reflective of the behavior of a runtime environment if the test classpath only contained jars that are bundled with the binary release, together with explicit test dependencies. 

Tests can run against those optional dependencies that we don't bundle. I don't think that is currently the case for any tests, but it can be.

bq. Ideally we'd use the build/lib/ jars for the classpath since that's what gets packaged, but since these aren't available at test compile time and should be identical to lib/ anyway, I've used the later.

I'm not quite understanding this statement, if {{build/lib/jars/}} doesn't exist then neither does {{lib/}}.

The {{lib/}} contents are put together later in the build cycle (under the {{resolver-dist-lib}} target) than the {{build/lib/jars/}} contents (which are done under the {{resolver-retrieve-build}} target). There is a valid question here as to whether we want tests to now depend upon the {{resolver-dist-lib}} target.
;;;","03/Jun/21 11:36;polo-language;{quote}Tests can run against those optional dependencies that we don't bundle. I don't think that is currently the case for any tests, but it can be.
{quote}
My thinking is that such dependencies should then become explicit test dependencies, rather than allowing transitive dependencies (which may disappear or change version when any other dependency is updated) to creep into the tests. Though I don't know what 'provided' means here so hopefully I haven't misunderstood something.
{quote}I'm not quite understanding this statement, if build/lib/jars/ doesn't exist then neither does lib/.
{quote}
Oops, this was supposed to be build/dist/lib/.

 

My patch doesn't touch the IDE classpaths. Should just be a matter of removing this [fileset|https://github.com/apache/cassandra/blob/3282f5ecf187ecbb56b8d73ab9a9110c010898b0/build.xml#L2005].

 ;;;","03/Jun/21 11:44;mck;bq. My thinking is that such dependencies should then become explicit test dependencies…

They are in places, see all those marked as ""provided"" or ""optional"" [here|https://github.com/apache/cassandra/blob/cassandra-4.0-rc1/build.xml#L491-L657] and [here|https://github.com/apache/cassandra/blob/cassandra-4.0-rc1/build.xml#L749-L833].

Note, these do also include those dependencies needed solely for the sake of compiling.

bq. …rather than allowing transitive dependencies (which may disappear or change version when any other dependency is updated) to creep into the tests.

The {{lib/}} folder also contains transitive dependencies, just of the more restricted scope.;;;","03/Jun/21 16:41;polo-language;If the 'provided' scope is intentionally part of the test dependencies (and not just the 'test' scope), then does it make sense to remove the exclusion of 'provided' from [test jars resolution|https://github.com/apache/cassandra/blob/3282f5ecf187ecbb56b8d73ab9a9110c010898b0/.build/build-resolver.xml#L178]? Unless there's some other detail with the transitive dependencies, looks like this is what provided is for: ""A dependency with this scope is added to the classpath used for compilation and test, but not the runtime classpath."" (http://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html#Dependency_Scope).

Then as a bonus, there's no need to duplicate dependencies across provided and test. For example:

./build.xml:733: <dependency groupId=""org.jboss.byteman"" artifactId=""byteman-install"" scope=""test""/>
 ./build.xml:734: <dependency groupId=""org.jboss.byteman"" artifactId=""byteman"" scope=""test""/>
 ./build.xml:735: <dependency groupId=""org.jboss.byteman"" artifactId=""byteman-submit"" scope=""test""/>
 ./build.xml:736: <dependency groupId=""org.jboss.byteman"" artifactId=""byteman-bmunit"" scope=""test""/>
 ./build.xml:830: <dependency groupId=""org.jboss.byteman"" artifactId=""byteman-install"" scope=""provided""/>
 ./build.xml:831: <dependency groupId=""org.jboss.byteman"" artifactId=""byteman"" scope=""provided""/>
 ./build.xml:832: <dependency groupId=""org.jboss.byteman"" artifactId=""byteman-submit"" scope=""provided""/>
 ./build.xml:833: <dependency groupId=""org.jboss.byteman"" artifactId=""byteman-bmunit"" scope=""provided""/>

Though in terms of classpath, we're effectively back where we started since instead of joining the compile and provided scopes from build/lib/ with the test scope in build/test/lib/ we'd be joining the compile scope in lib/ with the test and provided scopes in build/test/lib/.

So let me know if you me to remove the modification to build.xml from the patch. At a minimum, I think the two changes to src/ are required for runtime correctness.;;;","03/Jun/21 17:02;mck;bq. Though in terms of classpath, we're effectively back where we started since instead of joining the compile and provided scopes from build/lib/ with the test scope in build/test/lib/ we'd be joining the compile scope in lib/ with the test and provided scopes in build/test/lib/.

Yeah, we have three separate concerns:
- compiling, requires compile and provided scopes,
- packaging, requires compile scope,
- testing, requires compile and test scopes, and sometimes provided/optional scope.

I'm open to suggestions on how to tackle this, but not sure the current patch to build.xml really puts us in a significantly better situation. The rest of the patch LGTM!

bq.  there's no need to duplicate dependencies across provided and test.

Shouldn't we be able to remove the test scoped duplicated lines then?;;;","03/Jun/21 18:19;polo-language;I would think so. I can check and create a second patch for those.

A side comment:
{quote}Maybe there are jar files here that should be removed, i.e. should not even be part the provided scope?
{quote}
Byteman in particular seems to be in 'provided' because of the single class src/java/org/apache/cassandra/utils/TestRateLimiter.java, which appears to be only used for testing. Without knowing the details of how byteman works, since this class doesn't seem to make any reference to other Cassandra classes, the package name would be the only relevant thing here (if even that) and it could be moved to test/. The byteman deps could then all be 'test' scoped only. Or is this class in src/ simply because it could be used by test/unit/, test/distributed/, etc., whose trees shouldn't depend on each other? (That would seem a weak reason to include a class with ordinarily unresolvable imports in the end product, but so long as no one uses it no harm done, and I'm not up to speed on the organization of tests categories anyhow.);;;","03/Jun/21 19:14;mck;A second patch would be good. And I agree with your analysis of TestRateLimiter.java, something seems off there, though maybe it's how byteman (mutation_limiter.btm) needs its classpaths setup…?;;;","08/Jun/21 08:05;polo-language;{quote}They are in places, see all those marked as ""provided"" or ""optional"" [here|https://github.com/apache/cassandra/blob/cassandra-4.0-rc1/build.xml#L491-L657] and [here|https://github.com/apache/cassandra/blob/cassandra-4.0-rc1/build.xml#L749-L833].
{quote}
Is it intentional that the scope for some entries is repeated across the two pom definitions, while missing for others? Below is for 'provided' scope, similar situation for 'test' scope. Those shown in blue are declared with scope in only one place, those in green are given a scope in both places:

parent-pom:
{color:#4c9aff}<dependency groupId=""com.ning"" artifactId=""compress-lzf"" version=""0.8.4"" scope=""provided""/>{color}
{color:#57d9a3}<dependency groupId=""org.apache.hadoop"" artifactId=""hadoop-core"" version=""1.0.3"" scope=""provided"">{color}
{color:#57d9a3}<dependency groupId=""org.apache.hadoop"" artifactId=""hadoop-minicluster"" version=""1.0.3"" scope=""provided"">{color}
{color:#4c9aff}<dependency groupId=""io.netty"" artifactId=""netty-bom"" version=""4.1.58.Final"" type=""pom"" scope=""provided""/>{color}
{color:#57d9a3}<dependency groupId=""com.google.code.findbugs"" artifactId=""jsr305"" version=""2.0.2"" scope=""provided""/>{color}
{color:#57d9a3}<dependency groupId=""net.ju-n.compile-command-annotations"" artifactId=""compile-command-annotations"" version=""1.2.0"" scope=""provided""/>{color}


all-pom:
{color:#4c9aff}<dependency groupId=""org.antlr"" artifactId=""antlr"" scope=""provided""/>{color}
{color:#57d9a3}<dependency groupId=""org.apache.hadoop"" artifactId=""hadoop-core"" optional=""true"" scope=""provided""/>{color}
{color:#57d9a3}<dependency groupId=""org.apache.hadoop"" artifactId=""hadoop-minicluster"" optional=""true"" scope=""provided""/>{color}
{color:#57d9a3}<dependency groupId=""com.google.code.findbugs"" artifactId=""jsr305"" scope=""provided""/>{color}
{color:#57d9a3}<dependency groupId=""net.ju-n.compile-command-annotations"" artifactId=""compile-command-annotations"" scope=""provided""/>{color}
{color:#4c9aff}<dependency groupId=""org.assertj"" artifactId=""assertj-core"" scope=""provided""/>{color}
{color:#4c9aff}<dependency groupId=""org.jboss.byteman"" artifactId=""byteman-install"" scope=""provided""/>{color}
{color:#4c9aff}<dependency groupId=""org.jboss.byteman"" artifactId=""byteman"" scope=""provided""/>{color}
{color:#4c9aff}<dependency groupId=""org.jboss.byteman"" artifactId=""byteman-submit"" scope=""provided""/>{color}
{color:#4c9aff}<dependency groupId=""org.jboss.byteman"" artifactId=""byteman-bmunit"" scope=""provided""/>{color}

 ;;;","08/Jun/21 12:29;mck;bq. Is it intentional that the scope for some entries is repeated across the two pom definitions, while missing for others?

Not in general. Definitely jsr305 and compile-command-annotations looks like they can have the duplicated scope removed.  I think the others are just explicit because they are overridden, but yes: duplicated overrides are a bit silly. byteman-* for example could be defined as provided, and then overridden to test in build-deps-pom. I can't remember how optional interferes with the scope (ref hadoop* deps).;;;","09/Jun/21 17:31;polo-language;The patch 'cleanup-imports.patch' is simply the old patch with the change to build.xml removed.
The patch 'dedup-deps.patch' contains the following changes, exclusively modifying build.xml, from my understanding of our discussion above:
 * Removed duplicates of test scope that are already in provided scope.
 * Removed duplicated scope attributes. All scope attributes are now uniformly provided in parent-pom.
 * Added <dependency groupId=""org.apache.ant"" artifactId=""ant-junit"" version=""1.9.7"" scope=""test""/> to parent-pom. Was previously only declared in build-deps-pom.;;;","11/Jun/21 15:08;mck;Testing both patches on this [branch|https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/4.0/16704].

Between builds on cassandra-4.0.0 and these patches, the {{lib/}} and {{build/lib/jars/}} result in identical contents.

But the {{build/test/lib/jars/}} directory contains differences:
{code:java}
❯ diff <(ls build/test/lib/jars/) <(ls ../cassandra/build/test/lib/jars/)
11d10
< assertj-core-3.15.0.jar
15,18d13
< byteman-4.0.6.jar
< byteman-bmunit-4.0.6.jar
< byteman-install-4.0.6.jar
< byteman-submit-4.0.6.jar
22d16
< compile-command-annotations-1.2.0.jar {code}
 ;that is those jar files no longer appear under {{build/test/lib/jars/}} which is the intentional of the patch (as they are already ""provided"" and so under {{build/lib/jars/}}).

 

CI:  [!https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/862/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/862/pipeline];;;","12/Jun/21 07:31;mck;+1;;;","12/Jun/21 10:05;mck;Committed as [d93e43ed9b3abad438c4ec9db6ae94d768f52896|https://github.com/apache/cassandra/commit/d93e43ed9b3abad438c4ec9db6ae94d768f52896].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Exception thrown by custom QueryHandler constructor is ignored,CASSANDRA-16703,13381007,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,zoltanersek,efrasio,efrasio,28/May/21 15:15,07/Jul/21 20:13,13/Jul/23 08:40,07/Jul/21 16:50,3.0.25,3.11.11,4.0.1,,,,,Local/Startup and Shutdown,,,,0,,,"When a exception is thrown during the instantiation of the _cassandra.custom_query_handler_class,_ depending on the exception thrown cassandra will simply log an info message and proceed with the bootstraping with the standard _QueryHandler_ as a fallback measure: [https://github.com/apache/cassandra/blob/cassandra-3.11.10/src/java/org/apache/cassandra/service/ClientState.java#L107|https://github.com/apache/cassandra/blob/3b553d8e13dbdbe59119de9c917d9aacc440741e/src/java/org/apache/cassandra/service/ClientState.java#L104]

The end-user will never know if the custom _QueryHandler_ is actually registered or not, unless he notices the info message on the logs.

Ideally, the message should be logged as error and JVM should stop as it cannot proceed according with the user expected configuration.

*Scenario*:

In our scenario, we have a custom _QueryHandler_ that receives specific configuration, and we throw a _ConfigurationException_ at instantiation time in case of any invalid config value. It is expected that cassandra stop the bootstraping instead of skipping the QH.",,blerer,efrasio,tommy_s,zoltanersek,,,,,,,,,,,,"zoltanersek opened a new pull request #1096:
URL: https://github.com/apache/cassandra/pull/1096


   …s ignored
   
   https://issues.apache.org/jira/browse/CASSANDRA-16703


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jul/21 11:43;githubbot;600","chicobento commented on a change in pull request #1096:
URL: https://github.com/apache/cassandra/pull/1096#discussion_r662252328



##########
File path: src/java/org/apache/cassandra/service/ClientState.java
##########
@@ -100,8 +100,8 @@
             }
             catch (Exception e)
             {
-                JVMStabilityInspector.inspectThrowable(e);
-                logger.info(""Cannot use class {} as query handler ({}), ignoring by defaulting on normal query handling"", customHandlerClass, e.getMessage());
+                logger.error(""Cannot use class {} as query handler ({})"", customHandlerClass, e.getMessage());

Review comment:
       In our case, the exception thrown by the QueryHandler is a cassandra ConfigurationException, which has nested exception that gives valuable information to the user. 
   In that sense, I'd recommend to pass the whole exception to the logger rather than just the message, like:
   `
   logger.error(""Cannot use class {} as query handler ({})"", customHandlerClass, e);
   `

##########
File path: src/java/org/apache/cassandra/service/ClientState.java
##########
@@ -100,8 +100,8 @@
             }
             catch (Exception e)
             {
-                JVMStabilityInspector.inspectThrowable(e);
-                logger.info(""Cannot use class {} as query handler ({}), ignoring by defaulting on normal query handling"", customHandlerClass, e.getMessage());
+                logger.error(""Cannot use class {} as query handler ({})"", customHandlerClass, e.getMessage());
+                JVMStabilityInspector.killCurrentJVM(e, false);

Review comment:
       Since the contextualized exception is already being logged above and the root cause is well known, I think quiet parameter could be **true**, otherwise it will print the stackTrace to System.err and to the logger.error ""JVM state determined to be unstable.  Exiting forcefully due to:"" which is not really necessary in this case.
   
   Overall, this is how Im currently handling this situation in my custom query handler:
   ```
   MyQueryHandler() {
      try {
        configure();
      } catch (ConfigurationException e) {
        log.error(""Error registering MyQueryHandler"", e);
        JVMStabilityInspector.killCurrentJVM(e, true);
      }
   }
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jul/21 12:46;githubbot;600","zersek commented on a change in pull request #1096:
URL: https://github.com/apache/cassandra/pull/1096#discussion_r662280565



##########
File path: src/java/org/apache/cassandra/service/ClientState.java
##########
@@ -100,8 +100,8 @@
             }
             catch (Exception e)
             {
-                JVMStabilityInspector.inspectThrowable(e);
-                logger.info(""Cannot use class {} as query handler ({}), ignoring by defaulting on normal query handling"", customHandlerClass, e.getMessage());
+                logger.error(""Cannot use class {} as query handler ({})"", customHandlerClass, e.getMessage());

Review comment:
       done




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jul/21 13:18;githubbot;600","zersek commented on a change in pull request #1096:
URL: https://github.com/apache/cassandra/pull/1096#discussion_r662281237



##########
File path: src/java/org/apache/cassandra/service/ClientState.java
##########
@@ -100,8 +100,8 @@
             }
             catch (Exception e)
             {
-                JVMStabilityInspector.inspectThrowable(e);
-                logger.info(""Cannot use class {} as query handler ({}), ignoring by defaulting on normal query handling"", customHandlerClass, e.getMessage());
+                logger.error(""Cannot use class {} as query handler ({})"", customHandlerClass, e.getMessage());
+                JVMStabilityInspector.killCurrentJVM(e, false);

Review comment:
       done
   this is the output I get:
   ```
   ERROR [main] 2021-07-01 16:16:33,552 ClientState.java:103 - Cannot use class org.apache.cassandra.cql3.CustomPayloadMirroringQueryHandler2 as query handler
   org.apache.cassandra.exceptions.ConfigurationException: Unable to find QueryHandler class 'org.apache.cassandra.cql3.CustomPayloadMirroringQueryHandler2'
   	at org.apache.cassandra.utils.FBUtilities.classForName(FBUtilities.java:720)
   	at org.apache.cassandra.utils.FBUtilities.construct(FBUtilities.java:753)
   	at org.apache.cassandra.service.ClientState.<clinit>(ClientState.java:98)
   	at org.apache.cassandra.cql3.QueryProcessor$InternalStateInstance.<init>(QueryProcessor.java:129)
   	at org.apache.cassandra.cql3.QueryProcessor$InternalStateInstance.<clinit>(QueryProcessor.java:123)
   	at org.apache.cassandra.cql3.QueryProcessor.internalQueryState(QueryProcessor.java:174)
   	at org.apache.cassandra.cql3.QueryProcessor.prepareInternal(QueryProcessor.java:312)
   	at org.apache.cassandra.cql3.QueryProcessor.executeInternal(QueryProcessor.java:322)
   	at org.apache.cassandra.db.SystemKeyspace.checkHealth(SystemKeyspace.java:973)
   	at org.apache.cassandra.service.StartupChecks$10.execute(StartupChecks.java:442)
   	at org.apache.cassandra.service.StartupChecks.verify(StartupChecks.java:132)
   	at org.apache.cassandra.service.CassandraDaemon.runStartupChecks(CassandraDaemon.java:487)
   	at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:262)
   	at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:763)
   	at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:887)
   Caused by: java.lang.ClassNotFoundException: org.apache.cassandra.cql3.CustomPayloadMirroringQueryHandler2
   	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
   	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
   	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
   	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
   	at java.lang.Class.forName0(Native Method)
   	at java.lang.Class.forName(Class.java:264)
   	at org.apache.cassandra.utils.FBUtilities.classForName(FBUtilities.java:716)
   	... 14 common frames omitted
   
   Process finished with exit code 100
   ```
   




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jul/21 13:18;githubbot;600","chicobento commented on pull request #1096:
URL: https://github.com/apache/cassandra/pull/1096#issuecomment-872251456


   LGTM, thanks a lot for fixing this issue.
   Would love to see it backported to 3.x if possible.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jul/21 13:32;githubbot;600","zoltanersek commented on pull request #1096:
URL: https://github.com/apache/cassandra/pull/1096#issuecomment-875887233


   Committed into cassandra-3.0 at eadb171d5dfa9de3ecc6dce47515d48771fa98f9 and merged into cassandra-3.11, cassandra-4.0 and trunk


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;07/Jul/21 19:53;githubbot;600","zoltanersek closed pull request #1096:
URL: https://github.com/apache/cassandra/pull/1096


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;07/Jul/21 19:53;githubbot;600","chicobento commented on pull request #1096:
URL: https://github.com/apache/cassandra/pull/1096#issuecomment-875900660


   Great! Thanks a lot for taking your time to work on this issue.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;07/Jul/21 20:13;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,4800,,,0,4800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jul/21 13:21;zoltanersek;16703-trunk.txt;https://issues.apache.org/jira/secure/attachment/13027530/16703-trunk.txt",,,,,1.0,zoltanersek,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,Wed Jul 07 16:51:36 UTC 2021,,,,,,,All,,,,"0|z0rgyg:",9223372036854775807,,,,blerer,brandon.williams,efrasio,,Low,,3.0.0,,https://github.com/apache/cassandra/commit/eadb171d5dfa9de3ecc6dce47515d48771fa98f9,,,,,,,,,"Started cassandra with invalid custom query handler, verified it fails and dies

Started cassandra with valid custom query handler, verified it started up and info log appeared",,,,,"01/Jul/21 11:43;zoltanersek;https://github.com/apache/cassandra/pull/1096;;;","01/Jul/21 14:09;brandon.williams;[Circle CI|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16703];;;","01/Jul/21 16:03;brandon.williams;+1;;;","02/Jul/21 09:04;zoltanersek;Let me know if a patch over 3.0 is needed, I'm not familiar with the process of merging it to different versions, do we create a new ticket for all versions or should this cover all of them?;;;","02/Jul/21 13:16;blerer;[~zoltanersek] Ideally, you should provide a patch for all the versions unless the patch for the lowest version merge cleanly in the others.;;;","02/Jul/21 15:55;brandon.williams;This one merges cleanly, so no need for separate patches, but I only did trunk originally.

||Branch||CI||
|[3.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16703]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16703]|
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16703-3.11]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16703-3.11]|
|[4.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16703-4.0]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16703-4.0]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16703]|[circle|https://app.circleci.com/pipelines/github/driftx/cassandra?branch=CASSANDRA-16703-trunk]|
;;;","05/Jul/21 08:13;blerer;+1;;;","07/Jul/21 16:50;blerer;Committed into cassandra-3.0 at eadb171d5dfa9de3ecc6dce47515d48771fa98f9 and merged into cassandra-3.11, cassandra-4.0 and trunk;;;","07/Jul/21 16:51;blerer;Thanks a lot [~zoltanersek] and [~brandon.williams];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Python driver dependency missing,CASSANDRA-16700,13380570,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,polo-language,polo-language,26/May/21 15:11,27/May/22 19:24,13/Jul/23 08:40,26/May/21 19:00,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Dependencies,,,,0,,,"Cqlsh depends on the python driver, which is not included in the downloaded dependencies.
{noformat}
$ bin/cqlsh

Python Cassandra driver not installed, or not on PYTHONPATH.
You might try ""pip install cassandra-driver"".

Python: /usr/local/bin/python3
Module load path: ['/usr/local/share/java/cassandra/bin/../lib/geomet-0.1.0.zip', '/usr/local/share/java/cassandra/bin/../lib/six-1.12.0-py2.py3-none-any.zip', '/usr/local/share/java/cassandra/bin/../lib/futures-2.1.6-py2.py3-none-any.zip', '/usr/local/share/java/cassandra/bin', '/usr/local/lib/python37.zip', '/usr/local/lib/python3.7', '/usr/local/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/site-packages']

Error: No module named 'cassandra'

{noformat}",,mck,polo-language,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Availability,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed May 26 19:00:12 UTC 2021,,,,,,,All,,,,"0|z0re9k:",9223372036854775807,,,,,,,,Normal,,,,,,,,,,,,,manual inspection,,,,,"26/May/21 15:39;brandon.williams;[~mck] shouldn't we at least let a user with a source dist pull in the driver when they build with ant?;;;","26/May/21 16:08;mck;I'm thinking we leave the python dependency in the source artefact.

On the last board report we were told that the policy has been updated.

It currently stands as…
{quote}
SOURCE PACKAGES
Every ASF release MUST contain one or more source packages, which MUST be sufficient for a user to build and test the release provided they have access to the appropriate platform and tools. A source release SHOULD not contain compiled code.
{quote}

Those python zip files are not compiled. And it only says ""SHOULD not"";;;","26/May/21 16:20;brandon.williams;Should we just ninja out the removal then?;;;","26/May/21 16:55;mck;bq. Should we just ninja out the removal then?

+1;;;","26/May/21 17:29;brandon.williams;The line removing the driver https://github.com/apache/cassandra/blob/cassandra-4.0/build.xml#L1167 is also excluding the rest of lib, so this won't be a simple single line removal.  I'll post a patch shortly.;;;","26/May/21 19:00;brandon.williams;Not very complicated after all, so done in https://github.com/apache/cassandra/commit/f4ab8cce1e4f517406c1343d369326916586db67.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky TestPaxos.test_replica_availability,CASSANDRA-16693,13380245,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,25/May/21 06:43,27/May/22 19:25,13/Jul/23 08:40,26/May/21 05:35,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/dtest/python,,,,0,,,"Flaky [TestPaxos.test_replica_availability|https://ci-cassandra.apache.org/job/Cassandra-4.0/55/testReport/junit/dtest.paxos_test/TestPaxos/test_replica_availability/]
{noformat}
Error Message

cassandra.Unavailable: Error from server: code=1000 [Unavailable exception] message=""Cannot achieve consistency level SERIAL"" info={'consistency': 'SERIAL', 'required_replicas': 2, 'alive_replicas': 1}

Stacktrace

self = <paxos_test.TestPaxos object at 0x7ff6f83299d0>

    def test_replica_availability(self):
        """"""
            @jira_ticket CASSANDRA-8640
    
            Regression test for a bug (CASSANDRA-8640) that required all nodes to
            be available in order to run LWT queries, even if the query could
            complete correctly with quorum nodes available.
            """"""
        session = self.prepare(nodes=3, rf=3)
        session.execute(""CREATE TABLE test (k int PRIMARY KEY, v int)"")
        session.execute(""INSERT INTO test (k, v) VALUES (0, 0) IF NOT EXISTS"")
    
        self.cluster.nodelist()[2].stop()
        session.execute(""INSERT INTO test (k, v) VALUES (1, 1) IF NOT EXISTS"")
    
        self.cluster.nodelist()[1].stop()
        assert_unavailable(session.execute, ""INSERT INTO test (k, v) VALUES (2, 2) IF NOT EXISTS"")
    
        self.cluster.nodelist()[1].start()
>       session.execute(""INSERT INTO test (k, v) VALUES (3, 3) IF NOT EXISTS"")

paxos_test.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../venv/src/cassandra-driver/cassandra/cluster.py:2618: in execute
    return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile, paging_state, host, execute_as).result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ResponseFuture: query='<SimpleStatement query=""INSERT INTO test (k, v) VALUES (3, 3) IF NOT EXISTS"", consistency=Not ...el SERIAL"" info={'consistency': 'SERIAL', 'required_replicas': 2, 'alive_replicas': 1} coordinator_host=127.0.0.1:9042>

    def result(self):
        """"""
            Return the final result or raise an Exception if errors were
            encountered.  If the final result or error has not been set
            yet, this method will block until it is set, or the timeout
            set for the request expires.
    
            Timeout is specified in the Session request execution functions.
            If the timeout is exceeded, an :exc:`cassandra.OperationTimedOut` will be raised.
            This is a client-side timeout. For more information
            about server-side coordinator timeouts, see :class:`.policies.RetryPolicy`.
    
            Example usage::
    
                >>> future = session.execute_async(""SELECT * FROM mycf"")
                >>> # do other stuff...
    
                >>> try:
                ...     rows = future.result()
                ...     for row in rows:
                ...         ... # process results
                ... except Exception:
                ...     log.exception(""Operation failed:"")
    
            """"""
        self._event.wait()
        if self._final_result is not _NOT_SET:
            return ResultSet(self, self._final_result)
        else:
>           raise self._final_exception
E           cassandra.Unavailable: Error from server: code=1000 [Unavailable exception] message=""Cannot achieve consistency level SERIAL"" info={'consistency': 'SERIAL', 'required_replicas': 2, 'alive_replicas': 1}

../venv/src/cassandra-driver/cassandra/cluster.py:4894: Unavailable
{noformat}


",,bereng,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue May 25 13:03:10 UTC 2021,,,,,,,All,,,,"0|z0rc9c:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0,,https://github.com/apache/cassandra-dtest/commit/c67b12d14d75a70336b7b7fef8d4f81d80e32124,,,,,,,,,See PR,,,,,"25/May/21 08:08;bereng;[~edimitrova] you probably want to review this one as I stole the fix from you :-);;;","25/May/21 13:03;e.dimitrova;+1, thank you ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to replace node with stale schema,CASSANDRA-16692,13380206,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bdeggleston,mattl,mattl,24/May/21 23:03,27/Sep/21 13:53,13/Jul/23 08:40,28/May/21 23:45,3.0.25,3.11.11,4.0,4.0-rc1,,,,Cluster/Schema,,,,0,,," 

After CASSANDRA-15158 operators are no longer permitted to replace a terminated node with a stale schema. That is, launching a node to replace NodeA in the following scenario:
{code:java}
NodeA (terminated): schema=V0
All others (alive): schema=V1{code}
yields:
{code:java}
ERROR [main] 2021-04-30 19:10:23,410 CassandraDaemon.java:822 - Exception encountered during startup
java.lang.RuntimeException: Didn't receive schemas for all known versions within the timeout
        at org.apache.cassandra.service.StorageService.waitForSchema(StorageService.java:887) ~[nf-cassandra-3.0.24.1.jar:3.0.24.1]
        at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:937) ~[nf-cassandra-3.0.24.1.jar:3.0.24.1]
        at org.apache.cassandra.service.StorageService.initServer(StorageService.java:746) ~[nf-cassandra-3.0.24.1.jar:3.0.24.1]
        at org.apache.cassandra.service.StorageService.initServer(StorageService.java:654) ~[nf-cassandra-3.0.24.1.jar:3.0.24.1]
        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:374) [nf-cassandra-3.0.24.1.jar:3.0.24.1]
        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:616) [nf-cassandra-3.0.24.1.jar:3.0.24.1]
        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:809) [nf-cassandra-3.0.24.1.jar:3.0.24.1]{code}
This can be reproduced like so:
 # Shut down C* on one node in a 3.0.24 cluster
 # Create a new keyspace and table from one of the other nodes
 # Terminate and replace the node on which C* was shut down.

Waiting for agreement of the nodes not being replaced seems prudent as not doing so could induce data loss, the node being replaced should be exempted from this check.

Reference CASSANDRA-16577 for more context.",,bdeggleston,brandon.williams,e.dimitrova,mattl,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16998,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bdeggleston,,,,,,,,,,,,,Availability,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri May 28 23:45:55 UTC 2021,,,,,,,All,,,,"0|z0rc0o:",9223372036854775807,,,,bdeggleston,brandon.williams,,,Normal,,3.0.23,,https://github.com/apache/cassandra/commit/5f09226a0d56f6d2d5e60f83465f9f17beed0572,,,,,,,,,circle,,,,,"24/May/21 23:46;bdeggleston;[~brandon.williams] we should add some system properties to allow MigrationCoordinator to ignore specific schema versions / endpoints as an temporary work for future bugs. Also, let me know if your hands are full, I can take this if you're busy.;;;","24/May/21 23:53;brandon.williams;bq. we should add some system properties to allow MigrationCoordinator to ignore specific schema versions / endpoints as an temporary work for future bugs

Completely agree there since this is our second round, although probably a single broad flag is enough?

bq. I can take this if you're busy.

You already took it actually, so go ahead :) I haven't started on anything here yet.;;;","24/May/21 23:56;bdeggleston;oh oops, I only meant to tag myself as reviewer. I guess Jira is hard :);;;","25/May/21 22:36;bdeggleston;|[3.0|https://github.com/bdeggleston/cassandra/tree/16692-3.0]|[circle|https://app.circleci.com/pipelines/github/bdeggleston/cassandra?branch=16692-3.0]|
|[3.11|https://github.com/bdeggleston/cassandra/tree/16692-3.11]|[circle|https://app.circleci.com/pipelines/github/bdeggleston/cassandra?branch=16692-3.11]|
|[trunk|https://github.com/bdeggleston/cassandra/tree/16692-trunk]|[circle|https://app.circleci.com/pipelines/github/bdeggleston/cassandra?branch=16692-trunk]|

[~brandon.williams] are you interested in reviewing?;;;","25/May/21 22:52;brandon.williams;+1.  I now recall cassandra.skip_schema_check as being the existing broad flag.;;;","28/May/21 17:34;mattl;Per Sumanth: the patch is confirmed working on 3.0.;;;","28/May/21 23:45;bdeggleston;committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky NativeAllocatorTest.testBookKeeping,CASSANDRA-16690,13380037,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,bereng,bereng,24/May/21 07:47,27/May/22 19:25,13/Jul/23 08:40,08/Jun/21 16:46,3.0.25,3.11.11,4.0,4.0-rc2,4.1,4.1-alpha1,,Test/unit,,,,0,,,"Flaky [here|https://ci-cassandra.apache.org/job/Cassandra-4.0/52/testReport/junit/org.apache.cassandra.utils.memory/NativeAllocatorTest/testBookKeeping_cdc/]

{noformat}
Error Message

java.lang.AssertionError: expected:<0> but was:<1>

Stacktrace

java.util.concurrent.ExecutionException: java.lang.AssertionError: expected:<0> but was:<1>
	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
	at org.apache.cassandra.utils.memory.NativeAllocatorTest.testBookKeeping(NativeAllocatorTest.java:154)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Caused by: java.lang.AssertionError: expected:<0> but was:<1>
	at org.apache.cassandra.utils.memory.NativeAllocatorTest.lambda$testBookKeeping$2(NativeAllocatorTest.java:131)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
{noformat}
",,adelapena,bereng,e.dimitrova,jeromatron,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Jun 08 16:45:36 UTC 2021,,,,,,,All,,,,"0|z0razc:",9223372036854775807,,,,adelapena,bereng,,,Normal,,,,https://github.com/apache/cassandra/commit/a9f472c432fbe5c45662837f7d7ee578f59fd862,,,,,,,,,"Test issue so we just fixed the current test to prevent potential flakiness:

[https://github.com/ekaterinadimitrova2/cassandra/pull/136/commits/3888fbace8ae96ab0426853d2583d5adc62a5d97]",,,,,"26/May/21 22:19;e.dimitrova;It shows again passed when I open the link. If I search in the runs I found it failed with cdc once.
But then I ran it with Java 8 and Java 11 1000 times and nothing so I close as not  reproducible.....
https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/903/workflows/aeb8aea1-92d5-445a-a257-21c2295a5681/jobs/5378
https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/903/workflows/35333c7f-0548-4e54-b372-f6d861ffc10d/jobs/5373
https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/903/workflows/aeb8aea1-92d5-445a-a257-21c2295a5681/jobs/5375;;;","26/May/21 22:19;e.dimitrova;Please reopen if by chance you see it again;;;","27/May/21 04:45;bereng;Stage test reports don't do the fail/pass/fail thing: https://ci-cassandra.apache.org/job/Cassandra-4.0-test-cdc/47/jdk=jdk_11_latest,label=cassandra,split=8/testReport/junit/org.apache.cassandra.utils.memory/NativeAllocatorTest/testBookKeeping_cdc/

Did you try looping locally?;;;","27/May/21 13:21;e.dimitrova;Yes, I  did...;;;","07/Jun/21 18:44;e.dimitrova;Ok, failed again in Jenkins... 

[https://jenkins-cm4.apache.org/job/Cassandra-4.0.0/13/testReport/junit/org.apache.cassandra.utils.memory/NativeAllocatorTest/testBookKeeping_cdc/]

:( ;;;","07/Jun/21 19:45;e.dimitrova;BUT here a tiny patch comes. 

I think that the time of 10ms probably sometimes it is not enough for the cleaner. I raised the time to 20 MILISECONDS plus added an assertion [here|https://github.com/ekaterinadimitrova2/cassandra/pull/136/commits/3888fbace8ae96ab0426853d2583d5adc62a5d97]. I was not able to reproduce the issue but my assumption is based on reviewing the code. 

[~adelapena] or [~maedhroz], does anyone of you have the time to look at this, please? As you were reviewing my changes in that area of the code at the beginning of the year. This wasn't a new test added but somehow related. 

Thank you in advance. I can't reproduce the issue locally, CircleCI Multiplexer and in our company Jenkins multiplexer. I just pushed a CI run in cassandra Jenkins, dev - [https://jenkins-cm4.apache.org/job/Cassandra-devbranch/851/] I suggest we push the commit if there is no failure in Jenkins. ;;;","07/Jun/21 20:22;adelapena;[~e.dimitrova] sure, I can review;;;","08/Jun/21 02:42;e.dimitrova;Thanks [~adelapena]! In the meanwhile, the Jenkins run finished and I don't see the test failing...at least in this run.;;;","08/Jun/21 09:16;bereng;It's easy to repro adding a Thread.sleep() before {{isClean.countDown()}} in the cleaner code. Adding the assertion, to check for a successful clean, and raising the wait timeout is the way to go +1. But I would raise it to 500ms or so, then we won't have to fight this again the day we timeout on 20ms. At the end of the day that timeout being high has no semantics.;;;","08/Jun/21 10:44;adelapena;Agree, raising the timeout and adding the assertion looks good to me. I would also raise the timeout, perhaps to even longer than 500ms since we have seen longer pauses in CircleCI, maybe something like 5-10 seconds to be on the safe side. I think that the patch should also be applied to 3.0 and 3.11, since those branches also have the 10ms timeout.;;;","08/Jun/21 13:51;e.dimitrova;Thank you both, I will apply the patch to 3,3.11 and 4 with the suggested raised timeout of 10 seconds.;;;","08/Jun/21 16:45;e.dimitrova;Pushed to all branches after I ran successfully locally the test on all branches:

To https://github.com/apache/cassandra.git

   0e1f217079..a9f472c432  cassandra-3.0 -> cassandra-3.0

   dc8ccb7fb9..27f4cb68f2  cassandra-3.11 -> cassandra-3.11

   f83f2a3570..7d1c0131f6  cassandra-4.0 -> cassandra-4.0

   159469834a..82bd4567e2  cassandra-4.0.0 -> cassandra-4.0.0

   33ff36cc42..3b97e4bd7b  trunk -> trunk

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky LeaveAndBootstrapTest,CASSANDRA-16689,13380029,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,bereng,bereng,24/May/21 06:26,31/Jul/21 21:28,13/Jul/23 08:40,15/Jun/21 19:55,4.0,4.0-rc1,4.0-rc2,,,,,Test/unit,,,,0,,,"Failing in a circle run [here|https://app.circleci.com/pipelines/github/bereng/cassandra/309/workflows/a645b956-dcd7-431e-b109-7857af3c523f/jobs/2937]

{noformat}
Testcase: testStateJumpToNormal(org.apache.cassandra.service.LeaveAndBootstrapTest):	Caused an ERROR
[junit-timeout] null
[junit-timeout] java.lang.NullPointerException
[junit-timeout] 	at org.apache.cassandra.service.StorageService.updatePeerInfo(StorageService.java:2418)
[junit-timeout] 	at org.apache.cassandra.service.StorageService.handleStateNormal(StorageService.java:2756)
[junit-timeout] 	at org.apache.cassandra.service.StorageService.onChange(StorageService.java:2299)
[junit-timeout] 	at org.apache.cassandra.Util.createInitialRing(Util.java:236)
[junit-timeout] 	at org.apache.cassandra.service.LeaveAndBootstrapTest.testStateJumpToNormal(LeaveAndBootstrapTest.java:550)
{noformat}
",,adelapena,bereng,jeromatron,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jun 16 04:55:17 UTC 2021,,,,,,,All,,,,"0|z0raxk:",9223372036854775807,,,,adelapena,,,,Normal,,NA,,https://github.com/apache/cassandra/commit/658e08dc7e7561a6313675a73a6dbd43c73bbde4,,,,,,,,,test,,,,,"02/Jun/21 15:25;brandon.williams;This is rather odd since this occurs in Util.createInitialRing, where it does not appear to be used incorrectly, so I would expect this to be more widespread given the use of this function in about 8 other tests.  I have not been able to reproduce myself and the multiplexer has been no help there either: https://app.circleci.com/pipelines/github/driftx/cassandra/141/workflows/5b322f7d-32ce-41ec-88cb-7af1236af133/jobs/1099/steps;;;","04/Jun/21 15:32;brandon.williams;It is also interesting to note that this NPE is rooted in getting the [native_transport_port|https://github.com/apache/cassandra/blob/cassandra-4.0/src/java/org/apache/cassandra/service/StorageService.java#L2418] which is explicitly defined in [Config.java|https://github.com/apache/cassandra/blob/cassandra-4.0/src/java/org/apache/cassandra/config/Config.java#L186] and so it would need to be explicitly nulled out somehow for this to occur, yet nowhere do we keep a yaml with it unset, and there are no -D overrides for it either, so it's rather confounding where this is even coming from.;;;","07/Jun/21 17:55;brandon.williams;I don't see anywhere to go from here, so unassigning and hoping someone else comes up with something actionable.;;;","08/Jun/21 06:53;bereng;You're looking at the wrong code. If you check the SHA of the test failure you'll see the NPE comes from [pulling endpoint states|https://github.com/bereng/cassandra/blob/f7cd1c1f2508a9faf36c9ac2023f65841bb4628d/src/java/org/apache/cassandra/service/StorageService.java#L2418] not from config loading iiuc #collaborating;;;","11/Jun/21 15:24;adelapena;I haven't been able to reproduce the failure in {{LeaveAndBootstrapTest.testStateJumpToNormal}}, but I have found the same NPE in {{LeaveAndBootstrapTest.newTestWriteEndpointsDuringLeave}} and {{LeaveAndBootstrapTest.testSimultaneousMove}} while running the entire class in the multiplexer 10K times:
||[j8-j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/575/workflows/2286e1e3-f103-422d-9492-c8c951b49e01/jobs/5367]||[j8-j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/575/workflows/2286e1e3-f103-422d-9492-c8c951b49e01/jobs/5368]||[j11-j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/575/workflows/9823e967-29ca-4f2f-ac5c-623b0dfca5b9/jobs/5361]||

The failure can also be reproduced by running {{testSimultaneousMove}} in isolation, for example [here|https://app.circleci.com/pipelines/github/adelapena/cassandra/576/workflows/9060086d-4c2a-4689-9987-bd3354532777/jobs/5377], so it doesn't seem a problem of interaction between tests.;;;","14/Jun/21 14:31;brandon.williams;Thanks for these!  Indeed it looks like the same problem rooted in createInitialRing.;;;","15/Jun/21 16:25;brandon.williams;bq. so it doesn't seem a problem of interaction between tests.

On the surface it doesn't but in that case it was actually previous runs of the same test interfering, which is the entire cause of the failures in all these tests, since the bootstrapping (gossip-only) clients are sometimes being expired due to the modified (1s) ring delay at just the right time to break things.

With the ring delay changes removed these pass the 10k test:
https://app.circleci.com/pipelines/github/driftx/cassandra/150/workflows/80a208ec-3b42-4de4-965c-f8a900311c30/jobs/1271

but obviously doing that is too broad for all the tests.  I will work on another solution.;;;","15/Jun/21 18:43;brandon.williams;Added a clearUnsafe to Gossiper similar to TMD [here|https://github.com/driftx/cassandra/tree/CASSANDRA-16689] that allows us to pass the [10k test|https://app.circleci.com/pipelines/github/driftx/cassandra/152/workflows/4d317e35-ed5a-4ae1-a7cd-1b265afe149c/jobs/1287].  Given how many times I've seen this kind of problem with just ring delay alone, I almost added it to TMD.clearUnsafe since if you're clearing that, you probably want to clear the gossiper too, but I didn't want to make a large sweeping change.;;;","15/Jun/21 19:45;adelapena;Nice investigation! Looks good to me, +1.

Adding the clearing of {{Gossiper}} to {{TokenMetadata}} sounds tempting but I agree that maybe it's better to leave that change for the future.

I have left a trivial comment on the patch that can be addressed on commit, if needed.;;;","15/Jun/21 19:55;brandon.williams;Committed w/nits addressed.  Thanks!;;;","16/Jun/21 04:55;bereng;Nice investigation!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CircleCI - python dtests failing because of ccm issue,CASSANDRA-16688,13379844,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,21/May/21 19:24,27/May/22 19:25,13/Jul/23 08:40,24/May/21 18:39,2.2.20,3.0.25,3.11.11,4.0,4.0-rc2,4.1,4.1-alpha1,CI,,,,0,,,"Circle CI fails to run dtests.

[https://app.circleci.com/pipelines/github/adelapena/cassandra/483/workflows/e9a5f84e-e465-40e6-92f4-08e8632edf47/jobs/4315]
{code:java}
Obtaining ccm from git+
[https://github.com/riptano/ccm.git@cassandra-test#egg=ccm]
 (from -r /home/cassandra/cassandra-dtest/requirements.txt (line 9))
  Updating ./env3.6/src/ccm clone (to revision cassandra-test)
  Running command git fetch -q --tags
WARNING: Discarding git+
[https://github.com/riptano/ccm.git@cassandra-test#egg=ccm]
. Command errored out with exit status 1: git fetch -q --tags Check the logs for full command output.
ERROR: Could not find a version that satisfies the requirement ccm (unavailable)
ERROR: No matching distribution found for ccm (unavailable)
WARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.



{code}",,bereng,e.dimitrova,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16672,,,,,,,,,,,,,,,,,,,,,,,,,0.0,mck,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon May 24 21:13:20 UTC 2021,,,,,,,All,,,,"0|z0r9so:",9223372036854775807,,,,bereng,dcapwell,e.dimitrova,,Normal,,4.0-rc1,,https://github.com/apache/cassandra-dtest/commit/cec38211bfb7e5aceea114be9ef79b5ec40d505e,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16688?focusedCommentId=17350249&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17350249,,,,,"21/May/21 21:03;e.dimitrova;I think the latest ccm patch which triggered us to see retag hasn't been done recently is still not committed. [~dcapwell] found a workaround which I plan to ninja fix until Monday when we can commit that patch (want to double-check with [~Bereng] whether the mentioned commit should be really committed or he had some concerns), retag CCM and rebuild the docker image (I am positive that will solve the problem). I am also not sure whether I will have the rights to push a new image on docker hub actually.;;;","22/May/21 00:20;e.dimitrova;Unfortunately, it turned out the ninja fix solved only the issue for 4.0 and trunk. I will work on full permanent solution on Monday. In the meanwhile, Jenkins works properly. The ninja fix for 4.0 and trunk was committed. ;;;","23/May/21 15:58;mck;To reproduce…
{code}
docker run -it apache/cassandra-testing-ubuntu2004-java11-w-dependencies /bin/bash
git clone --single-branch --branch trunk --depth 1 https://github.com/apache/cassandra-dtest.git ~/cassandra-dtest
cd cassandra-dtest/
source ~/env3.6/bin/activate
pip3 install -r requirements.txt
{code}

The patch that has been committed to 4.0 and trunk, switches the cassandra-dtest's requirement.txt from using  https://github.com/riptano/ccm.git@cassandra-test to using git://github.com/riptano/ccm.git@cassandra-test for the ccm dependency. That works the first time because the repository needs to get cloned again to switch from one upstream URL to another. But it won't work when ccm gets re-tagged again.

Talking with [~dcapwell], the correct approach appears to be removing the {{`-e`}} flag from requirements.txt, so that ccm is not installed by pip in editable mode. This will make pip install ccm fresh each time, working around the problem (for developers and CI).

Patch: https://github.com/apache/cassandra-dtest/compare/trunk...thelastpickle:mck/16688
[!https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest/701/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest/701/] and [circleci|https://app.circleci.com/pipelines/github/michaelsembwever/cassandra?branch=mck%2F16688%2Ftrunk]

;;;","24/May/21 05:15;bereng;I'm not quite following why this is failing. If you go to the circle runs in CASSANDRA-16672 you can see it does indeed download what it's supposed to download:

{noformat}
Obtaining ccm from git+https://github.com/riptano/ccm.git#egg=ccm (from -r /home/cassandra/cassandra-dtest/requirements.txt (line 9))
  Updating ./env3.6/src/ccm clone
  Running command git fetch -q --tags
  Running command git reset --hard -q 435f3210e16d0b648fbf33d6390d5ab4c9e630d4
{noformat}

We can see it gets the tunk SHA, doesn't use the tag...And everything worked ok. So I am not sure why it would suddenly fail...;;;","24/May/21 05:47;bereng;Creating PRs with latest proposed solution from Mick and David + reverted 4.0 and trunk sed commands to replace the url:

- Branch [Trunk|https://github.com/apache/cassandra/pull/1017]: CI [j8|https://app.circleci.com/pipelines/github/bereng/cassandra/307/workflows/d2ce5a5f-bada-4832-95d2-7f68bed15d66] & [j11|https://app.circleci.com/pipelines/github/bereng/cassandra/307/workflows/b1c7c875-f9ea-45c6-9706-ac50d7219a95]
- Branch [4.0|https://github.com/apache/cassandra/pull/1018]: CI [j8|https://app.circleci.com/pipelines/github/bereng/cassandra/309/workflows/a645b956-dcd7-431e-b109-7857af3c523f] & [j11|https://app.circleci.com/pipelines/github/bereng/cassandra/309/workflows/cd663541-e465-4f71-a3df-12c903742d45]
- Branch [3.11|https://github.com/apache/cassandra/pull/1019]: [CI|https://app.circleci.com/pipelines/github/bereng/cassandra/310/workflows/efb64362-97f9-41a5-8ec6-20c6db390ff7]
- Branch [3.0|https://github.com/apache/cassandra/pull/1020]: [CI|https://app.circleci.com/pipelines/github/bereng/cassandra/311/workflows/76bb62e6-a9f5-4602-ab9f-d6871cade2da]

Waiting on CI with [~mck]'s latest proposal;;;","24/May/21 06:55;bereng;^LGTM for all branches it doesn't fail setting up ccm and dtests are being run.;;;","24/May/21 16:56;e.dimitrova;{quote}The patch that has been committed to 4.0 and trunk, switches the cassandra-dtest's requirement.txt from using [https://github.com/riptano/ccm.git@cassandra-test] to using git://github.com/riptano/ccm.git@cassandra-test for the ccm dependency. That works the first time because the repository needs to get cloned again to switch from one upstream URL to another. But it won't work when ccm gets re-tagged again.
{quote}
True, it was just a ninja fix until full-fledged solution this week comes, in case someone needs to run CI In the meanwhile. Thank you for the patch [~mck], appreciate it!

+1 on the dtest patch and reverting the temporary ninja fix for 4.0 and trunk.

Also, I think we can add the last ccm patch and retag, that one was just a correction of the debug messages so I think it should be harmless. Thank you

 

 ;;;","24/May/21 18:39;mck;Committed as [cec38211bfb7e5aceea114be9ef79b5ec40d505e|https://github.com/apache/cassandra-dtest/commit/cec38211bfb7e5aceea114be9ef79b5ec40d505e].;;;","24/May/21 21:13;e.dimitrova;Ninja fix reverted. Running CI:

[cassandra-3.0|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/880/workflows/8e92034a-71f4-4187-a8c0-498a0d5f6bbf]

[cassandra-3.11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/882/workflows/aad4bf4a-ba22-42ae-ade2-ec9a645fd39c]

cassandra-4.0: [Java 8 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/884/workflows/d86b294c-7409-4fd8-81eb-17826aa3f227] | [Java 11 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/884/workflows/7b15e781-8383-4aa7-ae50-3822a8105ab7]

trunk: [Java 8 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/875/workflows/5efb55cb-4087-47d3-9983-bdc85ad2bb45] | [Java 11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/875/workflows/361d7d05-d9a0-4f47-98a8-1990842215c7]

Looks good;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Queries returning static content when the partition has no rows might fail to return some rows,CASSANDRA-16686,13379727,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,blerer,blerer,21/May/21 10:00,14/Jun/21 07:35,13/Jul/23 08:40,10/Jun/21 09:18,4.0,4.0-rc2,,,,,,CQL/Interpreter,,,,0,,,"The problem can be reproduced with the following test:
{code}
    @Test
    public void testStaticColumnDeletionWithMultipleStaticColumns() throws Throwable
    {
        createTable(""CREATE TABLE %s (pk int, ck int, s1 int static, s2 int static, v int, PRIMARY KEY(pk, ck))"");
        execute(""INSERT INTO %s (pk, s1, s2) VALUES (1, 1, 1) USING TIMESTAMP 1000"");
        flush();
        execute(""INSERT INTO %s (pk, s1) VALUES (1, 2) USING TIMESTAMP 2000"");
        flush();
        execute(""DELETE s1 FROM %s USING TIMESTAMP 3000 WHERE pk = 1"");
        flush();
        assertRows(execute(""SELECT * FROM %s WHERE pk=1""), row(1, null, null, 1, null));
        assertRows(execute(""SELECT s1, s2 FROM %s WHERE pk=1""), row((Integer) null, 1));
        assertRows(execute(""SELECT s1 FROM %s WHERE pk=1""), row((Integer) null)); // <-FAIL
    }
{code}

This problem is a regression in 4.0 and trunk",,adelapena,aholmber,blerer,jeromatron,,,,,,,,,,,,"blerer closed pull request #1030:
URL: https://github.com/apache/cassandra/pull/1030


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 08:38;githubbot;600","blerer opened a new pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 08:39;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r643028189



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeReadTest.java
##########
@@ -51,7 +51,7 @@ public void mixedModeReadColumnSubsetDigestCheck() throws Throwable
             // we need to let gossip settle or the test will fail
             int attempts = 1;
             //noinspection Convert2MethodRef
-            while (!((IInvokableInstance) (cluster.get(1))).callOnInstance(() -> Gossiper.instance.isUpgradingFromVersionLowerThan(CassandraVersion.CASSANDRA_4_0.familyLowerBound.get()) &&

Review comment:
       🤦 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 11:47;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r643043366



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -49,111 +48,166 @@
  * in its request.
  *
  * The reason for distinguishing those 2 sets is that due to the CQL semantic (see #6588 for more details), we
- * often need to internally fetch all regular columns for the queried table, but can still do some optimizations for
- * those columns that are not directly queried by the user (see #10657 for more details).
+ * often need to internally fetch all regular columns or all columns for the queried table, but can still do some
+ * optimizations for those columns that are not directly queried by the user (see #10657 for more details).
  *
  * Note that in practice:
  *   - the _queried_ columns set is always included in the _fetched_ one.
- *   - whenever those sets are different, we know 1) the _fetched_ set contains all regular columns for the table and 2)
- *     _fetched_ == _queried_ for static columns, so we don't have to record this set, we just keep a pointer to the
- *     table metadata. The only set we concretely store is thus the _queried_ one.
+ *   - whenever those sets are different, the _fetched_ columns can contains either all the regular columns and
+ *     the static columns queried by the user or all the regular and static queries. If the query is a partition level
+ *     query (no restrictions on clustering or regular columns) all the static columns will need to be fetched as
+ *     some data will need to be returned to the user if the partition has no row but some static data. For all the
+ *     other scenarios only the all the regular columns are required.
  *   - in the special case of a {@code SELECT *} query, we want to query all columns, and _fetched_ == _queried.
- *     As this is a common case, we special case it by keeping the _queried_ set {@code null} (and we retrieve
- *     the columns through the metadata pointer).
+ *     As this is a common case, we special case it by using a specific subclass for it.
  *
  * For complex columns, this class optionally allows to specify a subset of the cells to query for each column.
  * We can either select individual cells by path name, or a slice of them. Note that this is a sub-selection of
  * _queried_ cells, so if _fetched_ != _queried_, then the cell selected by this sub-selection are considered
  * queried and the other ones are considered fetched (and if a column has some sub-selection, it must be a queried
  * column, which is actually enforced by the Builder below).
  */
-public class ColumnFilter
+public abstract class ColumnFilter
 {
     private final static Logger logger = LoggerFactory.getLogger(ColumnFilter.class);
 
     public static final ColumnFilter NONE = selection(RegularAndStaticColumns.NONE);
 
     public static final Serializer serializer = new Serializer();
 
-    // True if _fetched_ includes all regular columns (and any static in _queried_), in which case metadata must not be
-    // null. If false, then _fetched_ == _queried_ and we only store _queried_.
-    @VisibleForTesting
-    final boolean fetchAllRegulars;
+    /**
+     * The fetching strategy for the different queries.
+     */
+    private enum FetchingStrategy
+    {
+        /**
+         * This strategy will fetch all the regular and static columns.
+         *
+         * <p>According to the CQL semantic a partition exist if has at least one row or one of its static columns not null.
+         * For queries that have no restrictions on the clustering or regular columns, C* returns will return some data for

Review comment:
       nit: `C* returns will return` -> `C* returns` or `C* will return`




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 12:10;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r643045124



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -49,111 +48,166 @@
  * in its request.
  *
  * The reason for distinguishing those 2 sets is that due to the CQL semantic (see #6588 for more details), we
- * often need to internally fetch all regular columns for the queried table, but can still do some optimizations for
- * those columns that are not directly queried by the user (see #10657 for more details).
+ * often need to internally fetch all regular columns or all columns for the queried table, but can still do some
+ * optimizations for those columns that are not directly queried by the user (see #10657 for more details).
  *
  * Note that in practice:
  *   - the _queried_ columns set is always included in the _fetched_ one.
- *   - whenever those sets are different, we know 1) the _fetched_ set contains all regular columns for the table and 2)
- *     _fetched_ == _queried_ for static columns, so we don't have to record this set, we just keep a pointer to the
- *     table metadata. The only set we concretely store is thus the _queried_ one.
+ *   - whenever those sets are different, the _fetched_ columns can contains either all the regular columns and
+ *     the static columns queried by the user or all the regular and static queries. If the query is a partition level
+ *     query (no restrictions on clustering or regular columns) all the static columns will need to be fetched as
+ *     some data will need to be returned to the user if the partition has no row but some static data. For all the
+ *     other scenarios only the all the regular columns are required.
  *   - in the special case of a {@code SELECT *} query, we want to query all columns, and _fetched_ == _queried.
- *     As this is a common case, we special case it by keeping the _queried_ set {@code null} (and we retrieve
- *     the columns through the metadata pointer).
+ *     As this is a common case, we special case it by using a specific subclass for it.
  *
  * For complex columns, this class optionally allows to specify a subset of the cells to query for each column.
  * We can either select individual cells by path name, or a slice of them. Note that this is a sub-selection of
  * _queried_ cells, so if _fetched_ != _queried_, then the cell selected by this sub-selection are considered
  * queried and the other ones are considered fetched (and if a column has some sub-selection, it must be a queried
  * column, which is actually enforced by the Builder below).
  */
-public class ColumnFilter
+public abstract class ColumnFilter
 {
     private final static Logger logger = LoggerFactory.getLogger(ColumnFilter.class);
 
     public static final ColumnFilter NONE = selection(RegularAndStaticColumns.NONE);
 
     public static final Serializer serializer = new Serializer();
 
-    // True if _fetched_ includes all regular columns (and any static in _queried_), in which case metadata must not be
-    // null. If false, then _fetched_ == _queried_ and we only store _queried_.
-    @VisibleForTesting
-    final boolean fetchAllRegulars;
+    /**
+     * The fetching strategy for the different queries.
+     */
+    private enum FetchingStrategy

Review comment:
       this enum is a really nice idea, I like that




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 12:13;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r643775187



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);

Review comment:
       Although it seems to be valid, it sounds counterintuitive to check `queried` here - isn't it the case where `queried == fetched` and we could just use `fetched` collection instead?

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);
+        }
+
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried() || queried.contains(column);

Review comment:
       same question as above




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;02/Jun/21 09:32;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r643808671



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;

Review comment:
       I was going to ask about whether it works correctly and I noticed that you removed the relevant test case - why?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;02/Jun/21 10:00;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r643871108



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -431,7 +495,20 @@ else if (""3.11"".equals(clusterMinVersion))
     @Test
     public void testSelectStaticColumnCellWithMetadata()
     {
-        ColumnFilter filter = ColumnFilter.allRegularColumnsBuilder(metadata).select(s2, path1).build();
+        testSelectStaticColumnCellWithMetadata(false);
+    }
+
+    @Test
+    public void testSelectStaticColumnCellWithMetadataAndReturnStaticContentOnPartitionWithNoRows()
+    {
+        testSelectStaticColumnCellWithMetadata(true);
+    }
+
+    public void testSelectStaticColumnCellWithMetadata(boolean returnStaticContentOnPartitionWithNoRows)

Review comment:
       nit: perhaps private




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;02/Jun/21 11:32;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r643878884



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -416,6 +470,16 @@ else if (""3.11"".equals(clusterMinVersion))
             assertCellFetchedQueried(true, false, filter, v2, path0, path2, path3, path4);
             assertCellFetchedQueried(true, false, filter, s2, path0, path1, path2, path3, path4);
         }
+        else if (returnStaticContentOnPartitionWithNoRows && ""4.0"".equals(clusterMinVersion))
+        {
+            assertEquals(""*/[v2[1]]"", filter.toString());
+            assertEquals(""v2[1]"", filter.toCQLString());
+            assertFetchedQueried(true, false, filter, v1);
+            assertFetchedQueried(true, false, filter, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path1);
+            assertCellFetchedQueried(true, false, filter, v2, path0, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);

Review comment:
       I guess we should expect `fetches=true` here since all statics are fetched




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;02/Jun/21 11:44;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r643879604



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -416,6 +470,16 @@ else if (""3.11"".equals(clusterMinVersion))
             assertCellFetchedQueried(true, false, filter, v2, path0, path2, path3, path4);
             assertCellFetchedQueried(true, false, filter, s2, path0, path1, path2, path3, path4);
         }
+        else if (returnStaticContentOnPartitionWithNoRows && ""4.0"".equals(clusterMinVersion))
+        {
+            assertEquals(""*/[v2[1]]"", filter.toString());
+            assertEquals(""v2[1]"", filter.toCQLString());
+            assertFetchedQueried(true, false, filter, v1);
+            assertFetchedQueried(true, false, filter, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path1);
+            assertCellFetchedQueried(true, false, filter, v2, path0, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);

Review comment:
       In general, isn't the case `4.0` and `returnStaticContentOnPartitionWithNoRows` identical to `3.11` ?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;02/Jun/21 11:45;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r643881676



##########
File path: test/unit/org/apache/cassandra/db/SSTableAndMemTableDigestMatchTest.java
##########
@@ -114,27 +148,47 @@ private void testWithFilter(Function<TableMetadata, ColumnFilter> filterFactory)
         execute(""INSERT INTO %s (k, v1, v2, m) values (?, ?, ?, ?) USING TIMESTAMP ?"", 1, 2, 3, m, writeTime);
 
         ColumnFamilyStore cfs = getCurrentColumnFamilyStore();
-        ColumnFilter filter = filterFactory.apply(cfs.metadata());
-        String digest1 = getDigest(filter);
+        assertDigestsAreEqualsBeforeAndAfterFlush(filterFactory.apply(cfs.metadata()), Clustering.EMPTY);
+    }
+
+    private void testWithFilterAndStaticColumnsOnly(Function<TableMetadata, ColumnFilter> filterFactory) throws Throwable
+    {
+        createTable(""CREATE TABLE %s (pk int, ck int, s1 int static, s2 int static, v int, PRIMARY KEY(pk, ck))"");
+        execute(""INSERT INTO %s (pk, s1, s2) VALUES (1, 1, 1) USING TIMESTAMP 1000"");
+        flush();
+        execute(""INSERT INTO %s (pk, s1) VALUES (1, 2) USING TIMESTAMP 2000"");
+        flush();
+        execute(""DELETE s1 FROM %s USING TIMESTAMP 3000 WHERE pk = 1"");
+        flush();
+
+        ColumnFamilyStore cfs = getCurrentColumnFamilyStore();
+        assertDigestsAreEqualsBeforeAndAfterFlush(filterFactory.apply(cfs.metadata()));

Review comment:
       Using this assertion this way does not bring much value because the data is already flushed - so we check digest, flush again (but there nothing to flush, so this is no-op) and check digest.
   
   I suggest replacing each flush in this test with this assertion




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;02/Jun/21 11:48;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r643901853



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;

Review comment:
       similar question for tester




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;02/Jun/21 12:15;githubbot;600","adelapena commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r643893258



##########
File path: src/java/org/apache/cassandra/cql3/restrictions/StatementRestrictions.java
##########
@@ -835,6 +835,32 @@ public boolean hasRegularColumnsRestrictions()
     {
         return hasRegularColumnsRestrictions;
     }
+
+    /**
+     * Checks if the query is a full partitions selection.
+     * @return {@code true} if the query is a full partitions selection, {@code false} otherwise.
+     */
+    private boolean queriesFullPartitions()
+    {
+        return !hasClusteringColumnsRestrictions() && !hasRegularColumnsRestrictions();
+    }
+
+    /**
+     * Determines if the query should return the static content when a partition without rows is returned (as a
+     * result set row with null for all other regular columns.)
+     *
+     * @return {@code true} if the query should return the static content when a partition without rows is returned, {@code false} otherwise.

Review comment:
       Nit: we can split this line:
   ```suggestion
        * @return {@code true} if the query should return the static content when a partition without rows is returned,
        * {@code false} otherwise.
   ```

##########
File path: src/java/org/apache/cassandra/cql3/restrictions/StatementRestrictions.java
##########
@@ -835,6 +835,32 @@ public boolean hasRegularColumnsRestrictions()
     {
         return hasRegularColumnsRestrictions;
     }
+
+    /**
+     * Checks if the query is a full partitions selection.
+     * @return {@code true} if the query is a full partitions selection, {@code false} otherwise.
+     */
+    private boolean queriesFullPartitions()
+    {
+        return !hasClusteringColumnsRestrictions() && !hasRegularColumnsRestrictions();
+    }
+
+    /**
+     * Determines if the query should return the static content when a partition without rows is returned (as a
+     * result set row with null for all other regular columns.)
+     *
+     * @return {@code true} if the query should return the static content when a partition without rows is returned, {@code false} otherwise.
+     */
+    public boolean returnStaticContentOnPartitionWithNoRows()
+    {
+        if (table.isStaticCompactTable())
+            return true;
+
+        // The general rational is that if some rows are specifically selected by the query (have clustering or
+        // regular columns restrictions), we ignore partitions that are empty outside of static content, but if it's a full partition
+        // query, then we include that content.

Review comment:
       ```suggestion
           // The general rationale is that if some rows are specifically selected by the query (have clustering or
           // regular columns restrictions), we ignore partitions that are empty outside of static content, but if it's
           // a full partition query, then we include that content.
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -49,111 +48,166 @@
  * in its request.
  *
  * The reason for distinguishing those 2 sets is that due to the CQL semantic (see #6588 for more details), we
- * often need to internally fetch all regular columns for the queried table, but can still do some optimizations for
- * those columns that are not directly queried by the user (see #10657 for more details).
+ * often need to internally fetch all regular columns or all columns for the queried table, but can still do some
+ * optimizations for those columns that are not directly queried by the user (see #10657 for more details).
  *
  * Note that in practice:
  *   - the _queried_ columns set is always included in the _fetched_ one.
- *   - whenever those sets are different, we know 1) the _fetched_ set contains all regular columns for the table and 2)
- *     _fetched_ == _queried_ for static columns, so we don't have to record this set, we just keep a pointer to the
- *     table metadata. The only set we concretely store is thus the _queried_ one.
+ *   - whenever those sets are different, the _fetched_ columns can contains either all the regular columns and
+ *     the static columns queried by the user or all the regular and static queries. If the query is a partition level

Review comment:
       ```suggestion
    *     the static columns queried by the user or all the regular and static columns. If the query is a partition level
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -49,111 +48,166 @@
  * in its request.
  *
  * The reason for distinguishing those 2 sets is that due to the CQL semantic (see #6588 for more details), we
- * often need to internally fetch all regular columns for the queried table, but can still do some optimizations for
- * those columns that are not directly queried by the user (see #10657 for more details).
+ * often need to internally fetch all regular columns or all columns for the queried table, but can still do some
+ * optimizations for those columns that are not directly queried by the user (see #10657 for more details).
  *
  * Note that in practice:
  *   - the _queried_ columns set is always included in the _fetched_ one.
- *   - whenever those sets are different, we know 1) the _fetched_ set contains all regular columns for the table and 2)
- *     _fetched_ == _queried_ for static columns, so we don't have to record this set, we just keep a pointer to the
- *     table metadata. The only set we concretely store is thus the _queried_ one.
+ *   - whenever those sets are different, the _fetched_ columns can contains either all the regular columns and
+ *     the static columns queried by the user or all the regular and static queries. If the query is a partition level
+ *     query (no restrictions on clustering or regular columns) all the static columns will need to be fetched as
+ *     some data will need to be returned to the user if the partition has no row but some static data. For all the
+ *     other scenarios only the all the regular columns are required.
  *   - in the special case of a {@code SELECT *} query, we want to query all columns, and _fetched_ == _queried.
- *     As this is a common case, we special case it by keeping the _queried_ set {@code null} (and we retrieve
- *     the columns through the metadata pointer).
+ *     As this is a common case, we special case it by using a specific subclass for it.
  *
  * For complex columns, this class optionally allows to specify a subset of the cells to query for each column.
  * We can either select individual cells by path name, or a slice of them. Note that this is a sub-selection of
  * _queried_ cells, so if _fetched_ != _queried_, then the cell selected by this sub-selection are considered
  * queried and the other ones are considered fetched (and if a column has some sub-selection, it must be a queried
  * column, which is actually enforced by the Builder below).
  */
-public class ColumnFilter
+public abstract class ColumnFilter
 {
     private final static Logger logger = LoggerFactory.getLogger(ColumnFilter.class);
 
     public static final ColumnFilter NONE = selection(RegularAndStaticColumns.NONE);
 
     public static final Serializer serializer = new Serializer();
 
-    // True if _fetched_ includes all regular columns (and any static in _queried_), in which case metadata must not be
-    // null. If false, then _fetched_ == _queried_ and we only store _queried_.
-    @VisibleForTesting
-    final boolean fetchAllRegulars;
+    /**
+     * The fetching strategy for the different queries.
+     */
+    private enum FetchingStrategy
+    {
+        /**
+         * This strategy will fetch all the regular and static columns.
+         *
+         * <p>According to the CQL semantic a partition exist if has at least one row or one of its static columns not null.
+         * For queries that have no restrictions on the clustering or regular columns, C* returns will return some data for
+         * the partition even if it does not contains any row as long as one of the static columns contains data.
+         * To be able to ensure those queries all columns need to be fetched.</p>
+         *
+         * <p>This strategy is also used, instead of the ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS one, in mixed version clusters
+         * where some nodes have a version lower than 4.0. To ensure backward compatibility with those version that interpret the
+         * _fetchAll_ serialization flag as a true fetch all request.</p>
+         */
+        ALL_COLUMNS
+        {
+            @Override
+            boolean fetchesAllColumns(boolean isStatic)
+            {
+                return true;
+            }
 
-    // This flag can be only set when fetchAllRegulars is set. When fetchAllRegulars is set and queried==null then
-    // it is implied to be true. The flag when set allows for interpreting the column filter in the same way as it was
-    // interpreted by pre 4.0 Cassandra versions (3.4 ~ 4.0), that is, we fetch all columns (both regulars and static)
-    // but we query only some of them. This allows for proper behaviour during upgrades.
-    private final boolean fetchAllStatics;
+            @Override
+            RegularAndStaticColumns getFetchedColumns(TableMetadata metadata, RegularAndStaticColumns queried)
+            {
+                return metadata.regularAndStaticColumns();
+            }
+        },
 
-    @VisibleForTesting
-    final RegularAndStaticColumns fetched;
+        /**
+         * This strategy will fetch all the regular and selected static columns.
+         *
+         * <p>According to the CQL semantic a row exist if has at least one of its columns is not null.

Review comment:
       ```suggestion
            * <p>According to the CQL semantic a row exists if at least one of its columns is not null.
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -49,111 +48,166 @@
  * in its request.
  *
  * The reason for distinguishing those 2 sets is that due to the CQL semantic (see #6588 for more details), we
- * often need to internally fetch all regular columns for the queried table, but can still do some optimizations for
- * those columns that are not directly queried by the user (see #10657 for more details).
+ * often need to internally fetch all regular columns or all columns for the queried table, but can still do some
+ * optimizations for those columns that are not directly queried by the user (see #10657 for more details).
  *
  * Note that in practice:
  *   - the _queried_ columns set is always included in the _fetched_ one.
- *   - whenever those sets are different, we know 1) the _fetched_ set contains all regular columns for the table and 2)
- *     _fetched_ == _queried_ for static columns, so we don't have to record this set, we just keep a pointer to the
- *     table metadata. The only set we concretely store is thus the _queried_ one.
+ *   - whenever those sets are different, the _fetched_ columns can contains either all the regular columns and
+ *     the static columns queried by the user or all the regular and static queries. If the query is a partition level
+ *     query (no restrictions on clustering or regular columns) all the static columns will need to be fetched as
+ *     some data will need to be returned to the user if the partition has no row but some static data. For all the
+ *     other scenarios only the all the regular columns are required.
  *   - in the special case of a {@code SELECT *} query, we want to query all columns, and _fetched_ == _queried.
- *     As this is a common case, we special case it by keeping the _queried_ set {@code null} (and we retrieve
- *     the columns through the metadata pointer).
+ *     As this is a common case, we special case it by using a specific subclass for it.
  *
  * For complex columns, this class optionally allows to specify a subset of the cells to query for each column.
  * We can either select individual cells by path name, or a slice of them. Note that this is a sub-selection of
  * _queried_ cells, so if _fetched_ != _queried_, then the cell selected by this sub-selection are considered
  * queried and the other ones are considered fetched (and if a column has some sub-selection, it must be a queried
  * column, which is actually enforced by the Builder below).
  */
-public class ColumnFilter
+public abstract class ColumnFilter
 {
     private final static Logger logger = LoggerFactory.getLogger(ColumnFilter.class);
 
     public static final ColumnFilter NONE = selection(RegularAndStaticColumns.NONE);
 
     public static final Serializer serializer = new Serializer();
 
-    // True if _fetched_ includes all regular columns (and any static in _queried_), in which case metadata must not be
-    // null. If false, then _fetched_ == _queried_ and we only store _queried_.
-    @VisibleForTesting
-    final boolean fetchAllRegulars;
+    /**
+     * The fetching strategy for the different queries.
+     */
+    private enum FetchingStrategy
+    {
+        /**
+         * This strategy will fetch all the regular and static columns.
+         *
+         * <p>According to the CQL semantic a partition exist if has at least one row or one of its static columns not null.

Review comment:
       ```suggestion
            * <p>According to the CQL semantic a partition exists if it has at least one row or one of its static columns is not null.
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -201,40 +260,59 @@ public static ColumnFilter all(TableMetadata metadata)
      */
     public static ColumnFilter selection(RegularAndStaticColumns columns)
     {
-        return new ColumnFilter(false, false, (TableMetadata) null, columns, null);
+        return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS,
+                                                 (TableMetadata) null,
+                                                 columns,
+                                                 null);

Review comment:
       Nit: I think we don't need the cast of null, and without it this can be a one-liner:
   ```suggestion
           return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, null, columns, null);
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -49,111 +48,166 @@
  * in its request.
  *
  * The reason for distinguishing those 2 sets is that due to the CQL semantic (see #6588 for more details), we
- * often need to internally fetch all regular columns for the queried table, but can still do some optimizations for
- * those columns that are not directly queried by the user (see #10657 for more details).
+ * often need to internally fetch all regular columns or all columns for the queried table, but can still do some
+ * optimizations for those columns that are not directly queried by the user (see #10657 for more details).
  *
  * Note that in practice:
  *   - the _queried_ columns set is always included in the _fetched_ one.
- *   - whenever those sets are different, we know 1) the _fetched_ set contains all regular columns for the table and 2)
- *     _fetched_ == _queried_ for static columns, so we don't have to record this set, we just keep a pointer to the
- *     table metadata. The only set we concretely store is thus the _queried_ one.
+ *   - whenever those sets are different, the _fetched_ columns can contains either all the regular columns and
+ *     the static columns queried by the user or all the regular and static queries. If the query is a partition level
+ *     query (no restrictions on clustering or regular columns) all the static columns will need to be fetched as
+ *     some data will need to be returned to the user if the partition has no row but some static data. For all the
+ *     other scenarios only the all the regular columns are required.
  *   - in the special case of a {@code SELECT *} query, we want to query all columns, and _fetched_ == _queried.
- *     As this is a common case, we special case it by keeping the _queried_ set {@code null} (and we retrieve
- *     the columns through the metadata pointer).
+ *     As this is a common case, we special case it by using a specific subclass for it.
  *
  * For complex columns, this class optionally allows to specify a subset of the cells to query for each column.
  * We can either select individual cells by path name, or a slice of them. Note that this is a sub-selection of
  * _queried_ cells, so if _fetched_ != _queried_, then the cell selected by this sub-selection are considered
  * queried and the other ones are considered fetched (and if a column has some sub-selection, it must be a queried
  * column, which is actually enforced by the Builder below).
  */
-public class ColumnFilter
+public abstract class ColumnFilter
 {
     private final static Logger logger = LoggerFactory.getLogger(ColumnFilter.class);
 
     public static final ColumnFilter NONE = selection(RegularAndStaticColumns.NONE);
 
     public static final Serializer serializer = new Serializer();
 
-    // True if _fetched_ includes all regular columns (and any static in _queried_), in which case metadata must not be
-    // null. If false, then _fetched_ == _queried_ and we only store _queried_.
-    @VisibleForTesting
-    final boolean fetchAllRegulars;
+    /**
+     * The fetching strategy for the different queries.
+     */
+    private enum FetchingStrategy
+    {
+        /**
+         * This strategy will fetch all the regular and static columns.
+         *
+         * <p>According to the CQL semantic a partition exist if has at least one row or one of its static columns not null.
+         * For queries that have no restrictions on the clustering or regular columns, C* returns will return some data for
+         * the partition even if it does not contains any row as long as one of the static columns contains data.
+         * To be able to ensure those queries all columns need to be fetched.</p>
+         *
+         * <p>This strategy is also used, instead of the ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS one, in mixed version clusters
+         * where some nodes have a version lower than 4.0. To ensure backward compatibility with those version that interpret the
+         * _fetchAll_ serialization flag as a true fetch all request.</p>
+         */
+        ALL_COLUMNS
+        {
+            @Override
+            boolean fetchesAllColumns(boolean isStatic)
+            {
+                return true;
+            }
 
-    // This flag can be only set when fetchAllRegulars is set. When fetchAllRegulars is set and queried==null then
-    // it is implied to be true. The flag when set allows for interpreting the column filter in the same way as it was
-    // interpreted by pre 4.0 Cassandra versions (3.4 ~ 4.0), that is, we fetch all columns (both regulars and static)
-    // but we query only some of them. This allows for proper behaviour during upgrades.
-    private final boolean fetchAllStatics;
+            @Override
+            RegularAndStaticColumns getFetchedColumns(TableMetadata metadata, RegularAndStaticColumns queried)
+            {
+                return metadata.regularAndStaticColumns();
+            }
+        },
 
-    @VisibleForTesting
-    final RegularAndStaticColumns fetched;
+        /**
+         * This strategy will fetch all the regular and selected static columns.
+         *
+         * <p>According to the CQL semantic a row exist if has at least one of its columns is not null.
+         * To ensure that we need to fetch all regular columns.</p>
+         */
+        ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS
+        {
+            @Override
+            boolean fetchesAllColumns(boolean isStatic)
+            {
+                return !isStatic;
+            }
 
-    private final RegularAndStaticColumns queried; // can be null if fetchAllRegulars, to represent a wildcard query (all
+            @Override
+            RegularAndStaticColumns getFetchedColumns(TableMetadata metadata, RegularAndStaticColumns queried)
+            {
+                return new RegularAndStaticColumns(queried.statics, metadata.regularColumns());
+            }
+        },
 
-    // static and regular columns are both _fetched_ and _queried_).
-    private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+        /**
+         * Fetch only the columns that have been selected.
+         *
+         * <p>With this strategy _queried_ == _fetched_. This strategy is only used for internal queries.</p>
+         */
+        ONLY_QUERIED_COLUMNS
+        {
+            @Override
+            boolean fetchesAllColumns(boolean isStatic)
+            {
+                return false;
+            }
 
-    private ColumnFilter(boolean fetchAllRegulars,
-                         boolean fetchAllStatics,
-                         TableMetadata metadata,
-                         RegularAndStaticColumns queried,
-                         SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
-    {
-        assert !fetchAllRegulars || metadata != null;
-        assert fetchAllRegulars || queried != null;
-        assert !fetchAllStatics || fetchAllRegulars;
-        this.fetchAllRegulars = fetchAllRegulars;
-        this.fetchAllStatics = fetchAllStatics || fetchAllRegulars && queried == null;
+            @Override
+            boolean areAllFetchedColumnsQueried()
+            {
+                return true;
+            }
 
-        if (fetchAllRegulars)
-        {
-            RegularAndStaticColumns all = metadata.regularAndStaticColumns();
+            @Override
+            RegularAndStaticColumns getFetchedColumns(TableMetadata metadata, RegularAndStaticColumns queried)
+            {
+                return queried;
+            }
+        };
 
-            this.fetched = (all.statics.isEmpty() || queried == null || fetchAllStatics)
-                           ? all
-                           : new RegularAndStaticColumns(queried.statics, all.regulars);
-        }
-        else
+        /**
+         * Checks if the strategy fetch all the specified columns
+         *
+         * @param isStatic {@code true} is the check is for static columns, {@code false} otherwise
+         * @return {@code true} if the strategy fetch all the static columns, {@code false} otherwise.
+         */
+        abstract boolean fetchesAllColumns(boolean isStatic);
+
+        /**
+         * Checks if all the fetched columns are guaranteed to be queried
+         *
+         * @return {@code true} if all the fetched columns are guaranteed to be queried, {@code false} otherwise.
+         */
+        boolean areAllFetchedColumnsQueried()
         {
-            this.fetched = queried;
+            return false;
         }
 
-        this.queried = queried;
-        this.subSelections = subSelections;
+        /**
+         * Returns the columns that must be fetched to answer the query.
+         *
+         * @param metadata the table metadata
+         * @param queried the queried columns
+         * @return the columns that must be fetched
+         */
+        abstract RegularAndStaticColumns getFetchedColumns(TableMetadata metadata, RegularAndStaticColumns queried);
     }
 
     /**
-     * Used on replica for deserialisation
+     * Returns {@code true} if there are 4.0 pre-release nodes in the cluster (e.g. 4.0-rc1), {@code false} otherwise.
+     *
+     * <p>ColumnFilters from 4.0 release before RC2 wrongly assumed that fetching all regular columns and not the all
+     * the static columns was enough. That was not the case for queries that needed to return rows for empty partitions.
+     * See CASSANDRA-16686 for more details.</p>
      */
-    private ColumnFilter(boolean fetchAllRegulars,
-                         boolean fetchAllStatics,
-                         RegularAndStaticColumns fetched,
-                         RegularAndStaticColumns queried,
-                         SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+    private static boolean isUpgradingFromVersionLowerThan40RC2()

Review comment:
       I think that both the description and the trace message of this method suggest that it returns true for releases between 4.0-alpha1 and 4.0-rc1, whereas it returns true for any version below 4.0-rc2, even if it isn't in the 4.0 group.

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -49,111 +48,166 @@
  * in its request.
  *
  * The reason for distinguishing those 2 sets is that due to the CQL semantic (see #6588 for more details), we
- * often need to internally fetch all regular columns for the queried table, but can still do some optimizations for
- * those columns that are not directly queried by the user (see #10657 for more details).
+ * often need to internally fetch all regular columns or all columns for the queried table, but can still do some
+ * optimizations for those columns that are not directly queried by the user (see #10657 for more details).
  *
  * Note that in practice:
  *   - the _queried_ columns set is always included in the _fetched_ one.
- *   - whenever those sets are different, we know 1) the _fetched_ set contains all regular columns for the table and 2)
- *     _fetched_ == _queried_ for static columns, so we don't have to record this set, we just keep a pointer to the
- *     table metadata. The only set we concretely store is thus the _queried_ one.
+ *   - whenever those sets are different, the _fetched_ columns can contains either all the regular columns and
+ *     the static columns queried by the user or all the regular and static queries. If the query is a partition level
+ *     query (no restrictions on clustering or regular columns) all the static columns will need to be fetched as
+ *     some data will need to be returned to the user if the partition has no row but some static data. For all the
+ *     other scenarios only the all the regular columns are required.
  *   - in the special case of a {@code SELECT *} query, we want to query all columns, and _fetched_ == _queried.
- *     As this is a common case, we special case it by keeping the _queried_ set {@code null} (and we retrieve
- *     the columns through the metadata pointer).
+ *     As this is a common case, we special case it by using a specific subclass for it.
  *
  * For complex columns, this class optionally allows to specify a subset of the cells to query for each column.
  * We can either select individual cells by path name, or a slice of them. Note that this is a sub-selection of
  * _queried_ cells, so if _fetched_ != _queried_, then the cell selected by this sub-selection are considered
  * queried and the other ones are considered fetched (and if a column has some sub-selection, it must be a queried
  * column, which is actually enforced by the Builder below).
  */
-public class ColumnFilter
+public abstract class ColumnFilter
 {
     private final static Logger logger = LoggerFactory.getLogger(ColumnFilter.class);
 
     public static final ColumnFilter NONE = selection(RegularAndStaticColumns.NONE);
 
     public static final Serializer serializer = new Serializer();
 
-    // True if _fetched_ includes all regular columns (and any static in _queried_), in which case metadata must not be
-    // null. If false, then _fetched_ == _queried_ and we only store _queried_.
-    @VisibleForTesting
-    final boolean fetchAllRegulars;
+    /**
+     * The fetching strategy for the different queries.
+     */
+    private enum FetchingStrategy
+    {
+        /**
+         * This strategy will fetch all the regular and static columns.
+         *
+         * <p>According to the CQL semantic a partition exist if has at least one row or one of its static columns not null.
+         * For queries that have no restrictions on the clustering or regular columns, C* returns will return some data for
+         * the partition even if it does not contains any row as long as one of the static columns contains data.
+         * To be able to ensure those queries all columns need to be fetched.</p>
+         *
+         * <p>This strategy is also used, instead of the ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS one, in mixed version clusters
+         * where some nodes have a version lower than 4.0. To ensure backward compatibility with those version that interpret the
+         * _fetchAll_ serialization flag as a true fetch all request.</p>
+         */
+        ALL_COLUMNS
+        {
+            @Override
+            boolean fetchesAllColumns(boolean isStatic)
+            {
+                return true;
+            }
 
-    // This flag can be only set when fetchAllRegulars is set. When fetchAllRegulars is set and queried==null then
-    // it is implied to be true. The flag when set allows for interpreting the column filter in the same way as it was
-    // interpreted by pre 4.0 Cassandra versions (3.4 ~ 4.0), that is, we fetch all columns (both regulars and static)
-    // but we query only some of them. This allows for proper behaviour during upgrades.
-    private final boolean fetchAllStatics;
+            @Override
+            RegularAndStaticColumns getFetchedColumns(TableMetadata metadata, RegularAndStaticColumns queried)
+            {
+                return metadata.regularAndStaticColumns();
+            }
+        },
 
-    @VisibleForTesting
-    final RegularAndStaticColumns fetched;
+        /**
+         * This strategy will fetch all the regular and selected static columns.
+         *
+         * <p>According to the CQL semantic a row exist if has at least one of its columns is not null.
+         * To ensure that we need to fetch all regular columns.</p>
+         */
+        ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS
+        {
+            @Override
+            boolean fetchesAllColumns(boolean isStatic)
+            {
+                return !isStatic;
+            }
 
-    private final RegularAndStaticColumns queried; // can be null if fetchAllRegulars, to represent a wildcard query (all
+            @Override
+            RegularAndStaticColumns getFetchedColumns(TableMetadata metadata, RegularAndStaticColumns queried)
+            {
+                return new RegularAndStaticColumns(queried.statics, metadata.regularColumns());
+            }
+        },
 
-    // static and regular columns are both _fetched_ and _queried_).
-    private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+        /**
+         * Fetch only the columns that have been selected.
+         *
+         * <p>With this strategy _queried_ == _fetched_. This strategy is only used for internal queries.</p>
+         */
+        ONLY_QUERIED_COLUMNS
+        {
+            @Override
+            boolean fetchesAllColumns(boolean isStatic)
+            {
+                return false;
+            }
 
-    private ColumnFilter(boolean fetchAllRegulars,
-                         boolean fetchAllStatics,
-                         TableMetadata metadata,
-                         RegularAndStaticColumns queried,
-                         SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
-    {
-        assert !fetchAllRegulars || metadata != null;
-        assert fetchAllRegulars || queried != null;
-        assert !fetchAllStatics || fetchAllRegulars;
-        this.fetchAllRegulars = fetchAllRegulars;
-        this.fetchAllStatics = fetchAllStatics || fetchAllRegulars && queried == null;
+            @Override
+            boolean areAllFetchedColumnsQueried()
+            {
+                return true;
+            }
 
-        if (fetchAllRegulars)
-        {
-            RegularAndStaticColumns all = metadata.regularAndStaticColumns();
+            @Override
+            RegularAndStaticColumns getFetchedColumns(TableMetadata metadata, RegularAndStaticColumns queried)
+            {
+                return queried;
+            }
+        };
 
-            this.fetched = (all.statics.isEmpty() || queried == null || fetchAllStatics)
-                           ? all
-                           : new RegularAndStaticColumns(queried.statics, all.regulars);
-        }
-        else
+        /**
+         * Checks if the strategy fetch all the specified columns
+         *
+         * @param isStatic {@code true} is the check is for static columns, {@code false} otherwise
+         * @return {@code true} if the strategy fetch all the static columns, {@code false} otherwise.
+         */
+        abstract boolean fetchesAllColumns(boolean isStatic);
+
+        /**
+         * Checks if all the fetched columns are guaranteed to be queried
+         *
+         * @return {@code true} if all the fetched columns are guaranteed to be queried, {@code false} otherwise.
+         */
+        boolean areAllFetchedColumnsQueried()
         {
-            this.fetched = queried;
+            return false;
         }
 
-        this.queried = queried;
-        this.subSelections = subSelections;
+        /**
+         * Returns the columns that must be fetched to answer the query.
+         *
+         * @param metadata the table metadata
+         * @param queried the queried columns
+         * @return the columns that must be fetched
+         */
+        abstract RegularAndStaticColumns getFetchedColumns(TableMetadata metadata, RegularAndStaticColumns queried);
     }
 
     /**
-     * Used on replica for deserialisation
+     * Returns {@code true} if there are 4.0 pre-release nodes in the cluster (e.g. 4.0-rc1), {@code false} otherwise.
+     *
+     * <p>ColumnFilters from 4.0 release before RC2 wrongly assumed that fetching all regular columns and not the all

Review comment:
       ```suggestion
        * <p>ColumnFilters from 4.0 releases before RC2 wrongly assumed that fetching all regular columns and not
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -201,40 +260,59 @@ public static ColumnFilter all(TableMetadata metadata)
      */
     public static ColumnFilter selection(RegularAndStaticColumns columns)
     {
-        return new ColumnFilter(false, false, (TableMetadata) null, columns, null);
+        return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS,
+                                                 (TableMetadata) null,
+                                                 columns,
+                                                 null);
     }
 
     /**
      * A filter that fetches all columns for the provided table, but returns
      * only the queried ones.
      */
-    public static ColumnFilter selection(TableMetadata metadata, RegularAndStaticColumns queried)
+    public static ColumnFilter selection(TableMetadata metadata,
+                                          RegularAndStaticColumns queried,
+                                          boolean returnStaticContentOnPartitionWithNoRows)
     {
-        return new ColumnFilter(true, shouldFetchAllStatics(), metadata, shouldQueriedBeNull() ? null : queried, null);
+        // pre CASSANDRA-10657 (3.4-), when fetchAll is enabled, queried columns are not considered at all, and it
+        // is assumed that all columns are queried.
+        if (isUpgradingFromVersionLowerThan34())
+        {
+            return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+        }
+
+        // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+        if (isUpgradingFromVersionLowerThan40())
+        {
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, null);
+        }
+
+        // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+        // for some queries

Review comment:
       ```suggestion
           // pre CASSANDRA-16686 (4.0-RC2-) static columns were not fetched unless queried which led to some wrong
           // results for some queries
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -201,40 +260,59 @@ public static ColumnFilter all(TableMetadata metadata)
      */
     public static ColumnFilter selection(RegularAndStaticColumns columns)
     {
-        return new ColumnFilter(false, false, (TableMetadata) null, columns, null);
+        return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS,
+                                                 (TableMetadata) null,
+                                                 columns,
+                                                 null);
     }
 
     /**
      * A filter that fetches all columns for the provided table, but returns
      * only the queried ones.
      */
-    public static ColumnFilter selection(TableMetadata metadata, RegularAndStaticColumns queried)
+    public static ColumnFilter selection(TableMetadata metadata,
+                                          RegularAndStaticColumns queried,
+                                          boolean returnStaticContentOnPartitionWithNoRows)

Review comment:
       Nit: alignement
   ```suggestion
       public static ColumnFilter selection(TableMetadata metadata,
                                            RegularAndStaticColumns queried,
                                            boolean returnStaticContentOnPartitionWithNoRows)
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);
+        }
+
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried() || queried.contains(column);
+        }
+
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            assert path != null;
+
+            // first verify that the column to which the cell belongs is queried
+            if (!fetchedColumnIsQueried(column))
+                return false;
+
+            if (subSelections == null)
+                return true;
+
+            SortedSet<ColumnSubselection> s = subSelections.get(column.name);
+            // No subsection for this column means everything is queried
+            if (s.isEmpty())
+                return true;
+
+            for (ColumnSubselection subSel : s)
+                if (subSel.compareInclusionOf(path) == 0)
+                    return true;
+
+            return false;
+        }
 
-        while (columns.hasNext())
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
         {
-            ColumnMetadata column = columns.next();
-            String columnName = cql ? column.name.toCQLString() : String.valueOf(column.name);
+            Tester tester = newTester(column);
+            if (tester == null)
+                return cells;
 
-            SortedSet<ColumnSubselection> s = subSelections != null
-                                            ? subSelections.get(column.name)
-                                            : Collections.emptySortedSet();
+            return Iterators.filter(cells, cell -> tester.fetchedCellIsQueried(cell.path()));

Review comment:
       Maybe we can consider null cells:
   ```suggestion
               return Iterators.filter(cells, cell -> cell != null && tester.fetchedCellIsQueried(cell.path()));
   ```

##########
File path: test/unit/org/apache/cassandra/cql3/validation/operations/DeleteTest.java
##########
@@ -1423,6 +1420,51 @@ public void testWithEmptyRange() throws Throwable
         execute(""DELETE FROM %s WHERE k = ? AND a >= ? AND a < ?"", ""a"", 0, 2);
     }
 
+    @Test
+    public void testStaticColumnDeletionWithMultipleStaticColumns() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (pk int, ck int, s1 int static, s2 int static, v int, PRIMARY KEY(pk, ck))"");
+
+        execute(""INSERT INTO %s (pk, s1, s2) VALUES (1, 1, 1) USING TIMESTAMP 1000"");
+        flush();
+        execute(""INSERT INTO %s (pk, s1) VALUES (1, 2) USING TIMESTAMP 2000"");
+        flush();
+        execute(""DELETE s1 FROM %s USING TIMESTAMP 3000 WHERE pk = 1"");
+        flush();
+
+        assertRows(execute(""SELECT * FROM %s WHERE pk=1""), row(1, null, null, 1, null));
+        assertRows(execute(""SELECT pk, s1, s2 FROM %s WHERE pk=1""), row(1, (Integer) null, 1));
+        assertRows(execute(""SELECT s1, s2 FROM %s WHERE pk=1""), row((Integer) null, 1));
+        assertRows(execute(""SELECT pk, s1 FROM %s WHERE pk=1""), row(1, (Integer) null)); 
+        assertRows(execute(""SELECT s1 FROM %s WHERE pk=1""), row((Integer) null));
+        assertRows(execute(""SELECT pk, s2 FROM %s WHERE pk=1""), row(1, 1));
+        assertRows(execute(""SELECT s2 FROM %s WHERE pk=1""), row(1));
+        assertRows(execute(""SELECT pk, ck FROM %s WHERE pk=1""), row(1, null));
+        assertRows(execute(""SELECT ck FROM %s WHERE pk=1""), row((Integer) null));
+        assertRows(execute(""SELECT DISTINCT pk, s1, s2 FROM %s WHERE pk=1""), row(1, (Integer) null, 1));
+        assertRows(execute(""SELECT DISTINCT s1, s2 FROM %s WHERE pk=1""), row((Integer) null, 1));
+        assertRows(execute(""SELECT DISTINCT pk, s1 FROM %s WHERE pk=1""), row(1, (Integer) null));
+        assertRows(execute(""SELECT DISTINCT pk, s2 FROM %s WHERE pk=1""), row(1, 1));
+        assertRows(execute(""SELECT DISTINCT s1 FROM %s WHERE pk=1""), row((Integer) null));
+        assertRows(execute(""SELECT DISTINCT s2 FROM %s WHERE pk=1""), row(1));
+    }
+
+    @Test
+    public void testStaticColumnDeletionWithMultipleStaticColumnsAndRegularColumns() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (pk int, ck int, s1 int static, s2 int static, v int, PRIMARY KEY(pk, ck))"");
+
+        execute(""INSERT INTO %s (pk, ck, v, s2) VALUES (1, 1, 1, 1) USING TIMESTAMP 1000"");
+        flush();
+        execute(""INSERT INTO %s (pk, s1) VALUES (1, 2) USING TIMESTAMP 2000"");
+        flush();
+        execute(""DELETE s1 FROM %s USING TIMESTAMP 3000 WHERE pk = 1"");
+        flush();
+
+        assertRows(execute(""SELECT * FROM %s WHERE pk=1""), row(1, 1, null, 1, 1));
+        assertRows(execute(""SELECT s1, s2 FROM %s WHERE pk=1""), row((Integer) null, 1));
+        assertRows(execute(""SELECT s1 FROM %s WHERE pk=1""), row((Integer) null));

Review comment:
       Maybe we can add some `DISTINCT` queries here:
   ```suggestion
           assertRows(execute(""SELECT * FROM %s WHERE pk=1""), row(1, 1, null, 1, 1));
           assertRows(execute(""SELECT s1, s2 FROM %s WHERE pk=1""), row(null, 1));
           assertRows(execute(""SELECT s1 FROM %s WHERE pk=1""), row((Integer) null));
           assertRows(execute(""SELECT DISTINCT s1, s2 FROM %s WHERE pk=1""), row(null, 1));
           assertRows(execute(""SELECT DISTINCT s1 FROM %s WHERE pk=1""), row((Integer) null));
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues

Review comment:
       ```suggestion
            * <p>The class does not rely on TableMetadata and expects a fix set of columns to prevent issues
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues

Review comment:
       ```suggestion
        * <p>The class does not rely on TableMetadata and expects a fix set of columns to prevent issues
   ```

##########
File path: test/unit/org/apache/cassandra/cql3/validation/operations/CompactTableTest.java
##########
@@ -112,4 +112,21 @@ public void compactStorageSemanticsTest() throws Throwable
         assertRows(execute(""SELECT * FROM %s WHERE pk = ?"",2),
                    row(2, 2, null, 2));
     }
+
+    @Test
+    public void testColumnDeletionWithCompactTableWithMultipleColumns() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (pk int PRIMARY KEY, v1 int, v2 int) WITH COMPACT STORAGE"");
+
+        execute(""INSERT INTO %s (pk, v1, v2) VALUES (1, 1, 1) USING TIMESTAMP 1000"");
+        flush();
+        execute(""INSERT INTO %s (pk, v1) VALUES (1, 2) USING TIMESTAMP 2000"");
+        flush();
+        execute(""DELETE v1 FROM %s USING TIMESTAMP 3000 WHERE pk = 1"");
+        flush();
+
+        assertRows(execute(""SELECT * FROM %s WHERE pk=1""), row(1, null, 1));
+        assertRows(execute(""SELECT v1, v2 FROM %s WHERE pk=1""), row((Integer) null, 1));
+        assertRows(execute(""SELECT v1 FROM %s WHERE pk=1""), row((Integer) null)); // <-fail

Review comment:
       ```suggestion
           assertRows(execute(""SELECT v1, v2 FROM %s WHERE pk=1""), row(null, 1));
           assertRows(execute(""SELECT v1 FROM %s WHERE pk=1""), row((Integer) null));
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);
+        }
+
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried() || queried.contains(column);
+        }
+
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            assert path != null;
+
+            // first verify that the column to which the cell belongs is queried
+            if (!fetchedColumnIsQueried(column))
+                return false;
+
+            if (subSelections == null)
+                return true;
+
+            SortedSet<ColumnSubselection> s = subSelections.get(column.name);
+            // No subsection for this column means everything is queried
+            if (s.isEmpty())
+                return true;
+
+            for (ColumnSubselection subSel : s)
+                if (subSel.compareInclusionOf(path) == 0)
+                    return true;
+
+            return false;
+        }
 
-        while (columns.hasNext())
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
         {
-            ColumnMetadata column = columns.next();
-            String columnName = cql ? column.name.toCQLString() : String.valueOf(column.name);
+            Tester tester = newTester(column);
+            if (tester == null)
+                return cells;
 
-            SortedSet<ColumnSubselection> s = subSelections != null
-                                            ? subSelections.get(column.name)
-                                            : Collections.emptySortedSet();
+            return Iterators.filter(cells, cell -> tester.fetchedCellIsQueried(cell.path()));
+        }
 
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            if (subSelections == null || !column.isComplex())
+                return null;
+
+            SortedSet<ColumnSubselection> s = subSelections.get(column.name);
             if (s.isEmpty())
-                joiner.add(columnName);
-            else
-                s.forEach(subSel -> joiner.add(String.format(""%s%s"", columnName, subSel)));
+                return null;
+
+            return new Tester(fetchingStrategy.fetchesAllColumns(column.isStatic()), s.iterator());
+        }
+
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return subSelections;
+        }
+
+        @Override
+        public boolean equals(Object other)
+        {
+            if (other == this)
+                return true;
+
+            if (!(other instanceof SelectionColumnFilter))
+                return false;
+
+            SelectionColumnFilter otherCf = (SelectionColumnFilter) other;
+
+            return otherCf.fetchingStrategy == this.fetchingStrategy &&
+                   Objects.equals(otherCf.queried, this.queried) &&
+                   Objects.equals(otherCf.fetched, this.fetched) &&
+                   Objects.equals(otherCf.subSelections, this.subSelections);
+        }
+
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchingStrategy, queried, fetched, subSelections);
+        }
+
+        @Override
+        public String toString()
+        {
+            String prefix = """";
+
+            if (fetchingStrategy.fetchesAllColumns(true))
+                prefix = ""*/"";
+
+            if (fetchingStrategy == FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS)
+            {
+                prefix = queried.statics.isEmpty()
+                       ? ""<all regulars>/""
+                       : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            }
+
+            return prefix + toString(queried.selectOrderIterator(), false);
+        }
+
+        public String toCQLString()

Review comment:
       ```suggestion
           @Override
           public String toCQLString()
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -49,111 +48,166 @@
  * in its request.
  *
  * The reason for distinguishing those 2 sets is that due to the CQL semantic (see #6588 for more details), we
- * often need to internally fetch all regular columns for the queried table, but can still do some optimizations for
- * those columns that are not directly queried by the user (see #10657 for more details).
+ * often need to internally fetch all regular columns or all columns for the queried table, but can still do some
+ * optimizations for those columns that are not directly queried by the user (see #10657 for more details).
  *
  * Note that in practice:
  *   - the _queried_ columns set is always included in the _fetched_ one.
- *   - whenever those sets are different, we know 1) the _fetched_ set contains all regular columns for the table and 2)
- *     _fetched_ == _queried_ for static columns, so we don't have to record this set, we just keep a pointer to the
- *     table metadata. The only set we concretely store is thus the _queried_ one.
+ *   - whenever those sets are different, the _fetched_ columns can contains either all the regular columns and

Review comment:
       ```suggestion
    *   - whenever those sets are different, the _fetched_ columns can contain either all the regular columns and
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -325,50 +375,51 @@ public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
      * @return the created tester or {@code null} if all the cells from the provided column
      * are queried.
      */
-    public Tester newTester(ColumnMetadata column)
-    {
-        if (subSelections == null || !column.isComplex())
-            return null;
-
-        SortedSet<ColumnSubselection> s = subSelections.get(column.name);
-        if (s.isEmpty())
-            return null;
+    public abstract Tester newTester(ColumnMetadata column);

Review comment:
       Can we mark the method as `Nullable`?
   ```suggestion
       @Nullable
       public abstract Tester newTester(ColumnMetadata column);
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -49,111 +48,166 @@
  * in its request.
  *
  * The reason for distinguishing those 2 sets is that due to the CQL semantic (see #6588 for more details), we
- * often need to internally fetch all regular columns for the queried table, but can still do some optimizations for
- * those columns that are not directly queried by the user (see #10657 for more details).
+ * often need to internally fetch all regular columns or all columns for the queried table, but can still do some
+ * optimizations for those columns that are not directly queried by the user (see #10657 for more details).
  *
  * Note that in practice:
  *   - the _queried_ columns set is always included in the _fetched_ one.
- *   - whenever those sets are different, we know 1) the _fetched_ set contains all regular columns for the table and 2)
- *     _fetched_ == _queried_ for static columns, so we don't have to record this set, we just keep a pointer to the
- *     table metadata. The only set we concretely store is thus the _queried_ one.
+ *   - whenever those sets are different, the _fetched_ columns can contains either all the regular columns and
+ *     the static columns queried by the user or all the regular and static queries. If the query is a partition level
+ *     query (no restrictions on clustering or regular columns) all the static columns will need to be fetched as
+ *     some data will need to be returned to the user if the partition has no row but some static data. For all the
+ *     other scenarios only the all the regular columns are required.

Review comment:
       ```suggestion
    *     other scenarios only the regular columns are required.
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -665,49 +1046,99 @@ public ColumnFilter deserialize(DataInputPlus in, int version, TableMetadata met
 
             if (hasQueried)
             {
-                Columns statics = Columns.serializer.deserializeStatics(in, metadata);
-                Columns regulars = Columns.serializer.deserializeRegulars(in, metadata);
-                queried = new RegularAndStaticColumns(statics, regulars);
+                queried = deserializeRegularAndStaticColumns(in, metadata);
             }
 
             SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections = null;
             if (hasSubSelections)
             {
-                subSelections = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                int size = (int) in.readUnsignedVInt();
-                for (int i = 0; i < size; i++)
+                subSelections = deserializeSubSelection(in, version, metadata);
+            }
+
+            if (isFetchAll)
+            {
+                // pre CASSANDRA-10657 (3.4-), when fetchAll is enabled, queried columns are not considered at all, and it
+                // is assumed that all columns are queried.
+                if (!hasQueried || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(fetched);
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
+                {
+                    return new SelectionColumnFilter(FetchingStrategy.ALL_COLUMNS, queried, fetched, subSelections);
+                }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !isFetchAllStatics)
                 {
-                    ColumnSubselection subSel = ColumnSubselection.serializer.deserialize(in, version, metadata);
-                    subSelections.put(subSel.column().name, subSel);
+                    return new SelectionColumnFilter(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, queried, fetched, subSelections);
                 }
+
+                return new SelectionColumnFilter(FetchingStrategy.ALL_COLUMNS, queried, fetched, subSelections);
             }
 
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), fetched, isFetchAll && shouldQueriedBeNull() ? null : queried, subSelections);
+            return new SelectionColumnFilter(FetchingStrategy.ONLY_QUERIED_COLUMNS, queried, queried, subSelections);

Review comment:
       Maybe we can assert that `queried` is not null to get rid of the warning

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -201,40 +260,59 @@ public static ColumnFilter all(TableMetadata metadata)
      */
     public static ColumnFilter selection(RegularAndStaticColumns columns)
     {
-        return new ColumnFilter(false, false, (TableMetadata) null, columns, null);
+        return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS,
+                                                 (TableMetadata) null,
+                                                 columns,
+                                                 null);
     }
 
     /**
      * A filter that fetches all columns for the provided table, but returns
      * only the queried ones.
      */
-    public static ColumnFilter selection(TableMetadata metadata, RegularAndStaticColumns queried)
+    public static ColumnFilter selection(TableMetadata metadata,
+                                          RegularAndStaticColumns queried,
+                                          boolean returnStaticContentOnPartitionWithNoRows)
     {
-        return new ColumnFilter(true, shouldFetchAllStatics(), metadata, shouldQueriedBeNull() ? null : queried, null);
+        // pre CASSANDRA-10657 (3.4-), when fetchAll is enabled, queried columns are not considered at all, and it
+        // is assumed that all columns are queried.
+        if (isUpgradingFromVersionLowerThan34())
+        {
+            return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+        }
+
+        // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+        if (isUpgradingFromVersionLowerThan40())
+        {
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, null);
+        }
+
+        // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+        // for some queries
+        if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)

Review comment:
       Maybe we can check the simpler `returnStaticContentOnPartitionWithNoRows` first in the lazy or:
   ```suggestion
           if (!returnStaticContentOnPartitionWithNoRows || isUpgradingFromVersionLowerThan40RC2())
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;02/Jun/21 12:40;githubbot;600","blerer commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r644560764



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -49,111 +48,166 @@
  * in its request.
  *
  * The reason for distinguishing those 2 sets is that due to the CQL semantic (see #6588 for more details), we
- * often need to internally fetch all regular columns for the queried table, but can still do some optimizations for
- * those columns that are not directly queried by the user (see #10657 for more details).
+ * often need to internally fetch all regular columns or all columns for the queried table, but can still do some
+ * optimizations for those columns that are not directly queried by the user (see #10657 for more details).
  *
  * Note that in practice:
  *   - the _queried_ columns set is always included in the _fetched_ one.
- *   - whenever those sets are different, we know 1) the _fetched_ set contains all regular columns for the table and 2)
- *     _fetched_ == _queried_ for static columns, so we don't have to record this set, we just keep a pointer to the
- *     table metadata. The only set we concretely store is thus the _queried_ one.
+ *   - whenever those sets are different, the _fetched_ columns can contains either all the regular columns and
+ *     the static columns queried by the user or all the regular and static queries. If the query is a partition level
+ *     query (no restrictions on clustering or regular columns) all the static columns will need to be fetched as
+ *     some data will need to be returned to the user if the partition has no row but some static data. For all the
+ *     other scenarios only the all the regular columns are required.
  *   - in the special case of a {@code SELECT *} query, we want to query all columns, and _fetched_ == _queried.
- *     As this is a common case, we special case it by keeping the _queried_ set {@code null} (and we retrieve
- *     the columns through the metadata pointer).
+ *     As this is a common case, we special case it by using a specific subclass for it.
  *
  * For complex columns, this class optionally allows to specify a subset of the cells to query for each column.
  * We can either select individual cells by path name, or a slice of them. Note that this is a sub-selection of
  * _queried_ cells, so if _fetched_ != _queried_, then the cell selected by this sub-selection are considered
  * queried and the other ones are considered fetched (and if a column has some sub-selection, it must be a queried
  * column, which is actually enforced by the Builder below).
  */
-public class ColumnFilter
+public abstract class ColumnFilter
 {
     private final static Logger logger = LoggerFactory.getLogger(ColumnFilter.class);
 
     public static final ColumnFilter NONE = selection(RegularAndStaticColumns.NONE);
 
     public static final Serializer serializer = new Serializer();
 
-    // True if _fetched_ includes all regular columns (and any static in _queried_), in which case metadata must not be
-    // null. If false, then _fetched_ == _queried_ and we only store _queried_.
-    @VisibleForTesting
-    final boolean fetchAllRegulars;
+    /**
+     * The fetching strategy for the different queries.
+     */
+    private enum FetchingStrategy

Review comment:
       Thanks :-)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Jun/21 07:40;githubbot;600","blerer commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r644640856



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;

Review comment:
       I believe that the existing logic was due to the complexity of the class rather than to a realistic usecase.
   True wildcard queries do not allow sub-selections (as it will not be a wildcard query otherwise).
   The issue was with the fact that we used also wildcard queries for pre 3.4 nodes. I checked those versions and they rely on `isFetchAll` to avoid unecessary work. As the wildcard query will result on those version on `isFetchAll=true` the sub-selection will never be checked and that part of the logic can be removed.
   Of course, I might have missed something. :-)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Jun/21 09:33;githubbot;600","blerer commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r644762176



##########
File path: test/unit/org/apache/cassandra/db/SSTableAndMemTableDigestMatchTest.java
##########
@@ -114,27 +148,47 @@ private void testWithFilter(Function<TableMetadata, ColumnFilter> filterFactory)
         execute(""INSERT INTO %s (k, v1, v2, m) values (?, ?, ?, ?) USING TIMESTAMP ?"", 1, 2, 3, m, writeTime);
 
         ColumnFamilyStore cfs = getCurrentColumnFamilyStore();
-        ColumnFilter filter = filterFactory.apply(cfs.metadata());
-        String digest1 = getDigest(filter);
+        assertDigestsAreEqualsBeforeAndAfterFlush(filterFactory.apply(cfs.metadata()), Clustering.EMPTY);
+    }
+
+    private void testWithFilterAndStaticColumnsOnly(Function<TableMetadata, ColumnFilter> filterFactory) throws Throwable
+    {
+        createTable(""CREATE TABLE %s (pk int, ck int, s1 int static, s2 int static, v int, PRIMARY KEY(pk, ck))"");
+        execute(""INSERT INTO %s (pk, s1, s2) VALUES (1, 1, 1) USING TIMESTAMP 1000"");
+        flush();
+        execute(""INSERT INTO %s (pk, s1) VALUES (1, 2) USING TIMESTAMP 2000"");
+        flush();
+        execute(""DELETE s1 FROM %s USING TIMESTAMP 3000 WHERE pk = 1"");
+        flush();
+
+        ColumnFamilyStore cfs = getCurrentColumnFamilyStore();
+        assertDigestsAreEqualsBeforeAndAfterFlush(filterFactory.apply(cfs.metadata()));

Review comment:
       🤦 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Jun/21 12:47;githubbot;600","blerer commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r644770390



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -416,6 +470,16 @@ else if (""3.11"".equals(clusterMinVersion))
             assertCellFetchedQueried(true, false, filter, v2, path0, path2, path3, path4);
             assertCellFetchedQueried(true, false, filter, s2, path0, path1, path2, path3, path4);
         }
+        else if (returnStaticContentOnPartitionWithNoRows && ""4.0"".equals(clusterMinVersion))
+        {
+            assertEquals(""*/[v2[1]]"", filter.toString());
+            assertEquals(""v2[1]"", filter.toCQLString());
+            assertFetchedQueried(true, false, filter, v1);
+            assertFetchedQueried(true, false, filter, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path1);
+            assertCellFetchedQueried(true, false, filter, v2, path0, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);

Review comment:
       Good point! I will merge the `if` branches




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Jun/21 12:59;githubbot;600","blerer commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r644772204



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);

Review comment:
       Good point. :-)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Jun/21 13:01;githubbot;600","blerer commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r644776568



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);
+        }
+
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried() || queried.contains(column);

Review comment:
       I think that this one is fine as what we need to check is that the fetched column provided is also queried.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Jun/21 13:08;githubbot;600","blerer commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r644560764



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -49,111 +48,166 @@
  * in its request.
  *
  * The reason for distinguishing those 2 sets is that due to the CQL semantic (see #6588 for more details), we
- * often need to internally fetch all regular columns for the queried table, but can still do some optimizations for
- * those columns that are not directly queried by the user (see #10657 for more details).
+ * often need to internally fetch all regular columns or all columns for the queried table, but can still do some
+ * optimizations for those columns that are not directly queried by the user (see #10657 for more details).
  *
  * Note that in practice:
  *   - the _queried_ columns set is always included in the _fetched_ one.
- *   - whenever those sets are different, we know 1) the _fetched_ set contains all regular columns for the table and 2)
- *     _fetched_ == _queried_ for static columns, so we don't have to record this set, we just keep a pointer to the
- *     table metadata. The only set we concretely store is thus the _queried_ one.
+ *   - whenever those sets are different, the _fetched_ columns can contains either all the regular columns and
+ *     the static columns queried by the user or all the regular and static queries. If the query is a partition level
+ *     query (no restrictions on clustering or regular columns) all the static columns will need to be fetched as
+ *     some data will need to be returned to the user if the partition has no row but some static data. For all the
+ *     other scenarios only the all the regular columns are required.
  *   - in the special case of a {@code SELECT *} query, we want to query all columns, and _fetched_ == _queried.
- *     As this is a common case, we special case it by keeping the _queried_ set {@code null} (and we retrieve
- *     the columns through the metadata pointer).
+ *     As this is a common case, we special case it by using a specific subclass for it.
  *
  * For complex columns, this class optionally allows to specify a subset of the cells to query for each column.
  * We can either select individual cells by path name, or a slice of them. Note that this is a sub-selection of
  * _queried_ cells, so if _fetched_ != _queried_, then the cell selected by this sub-selection are considered
  * queried and the other ones are considered fetched (and if a column has some sub-selection, it must be a queried
  * column, which is actually enforced by the Builder below).
  */
-public class ColumnFilter
+public abstract class ColumnFilter
 {
     private final static Logger logger = LoggerFactory.getLogger(ColumnFilter.class);
 
     public static final ColumnFilter NONE = selection(RegularAndStaticColumns.NONE);
 
     public static final Serializer serializer = new Serializer();
 
-    // True if _fetched_ includes all regular columns (and any static in _queried_), in which case metadata must not be
-    // null. If false, then _fetched_ == _queried_ and we only store _queried_.
-    @VisibleForTesting
-    final boolean fetchAllRegulars;
+    /**
+     * The fetching strategy for the different queries.
+     */
+    private enum FetchingStrategy

Review comment:
       Thanks :-)

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;

Review comment:
       I believe that the existing logic was due to the complexity of the class rather than to a realistic usecase.
   True wildcard queries do not allow sub-selections (as it will not be a wildcard query otherwise).
   The issue was with the fact that we used also wildcard queries for pre 3.4 nodes. I checked those versions and they rely on `isFetchAll` to avoid unecessary work. As the wildcard query will result on those version on `isFetchAll=true` the sub-selection will never be checked and that part of the logic can be removed.
   Of course, I might have missed something. :-)

##########
File path: test/unit/org/apache/cassandra/db/SSTableAndMemTableDigestMatchTest.java
##########
@@ -114,27 +148,47 @@ private void testWithFilter(Function<TableMetadata, ColumnFilter> filterFactory)
         execute(""INSERT INTO %s (k, v1, v2, m) values (?, ?, ?, ?) USING TIMESTAMP ?"", 1, 2, 3, m, writeTime);
 
         ColumnFamilyStore cfs = getCurrentColumnFamilyStore();
-        ColumnFilter filter = filterFactory.apply(cfs.metadata());
-        String digest1 = getDigest(filter);
+        assertDigestsAreEqualsBeforeAndAfterFlush(filterFactory.apply(cfs.metadata()), Clustering.EMPTY);
+    }
+
+    private void testWithFilterAndStaticColumnsOnly(Function<TableMetadata, ColumnFilter> filterFactory) throws Throwable
+    {
+        createTable(""CREATE TABLE %s (pk int, ck int, s1 int static, s2 int static, v int, PRIMARY KEY(pk, ck))"");
+        execute(""INSERT INTO %s (pk, s1, s2) VALUES (1, 1, 1) USING TIMESTAMP 1000"");
+        flush();
+        execute(""INSERT INTO %s (pk, s1) VALUES (1, 2) USING TIMESTAMP 2000"");
+        flush();
+        execute(""DELETE s1 FROM %s USING TIMESTAMP 3000 WHERE pk = 1"");
+        flush();
+
+        ColumnFamilyStore cfs = getCurrentColumnFamilyStore();
+        assertDigestsAreEqualsBeforeAndAfterFlush(filterFactory.apply(cfs.metadata()));

Review comment:
       🤦 

##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -416,6 +470,16 @@ else if (""3.11"".equals(clusterMinVersion))
             assertCellFetchedQueried(true, false, filter, v2, path0, path2, path3, path4);
             assertCellFetchedQueried(true, false, filter, s2, path0, path1, path2, path3, path4);
         }
+        else if (returnStaticContentOnPartitionWithNoRows && ""4.0"".equals(clusterMinVersion))
+        {
+            assertEquals(""*/[v2[1]]"", filter.toString());
+            assertEquals(""v2[1]"", filter.toCQLString());
+            assertFetchedQueried(true, false, filter, v1);
+            assertFetchedQueried(true, false, filter, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path1);
+            assertCellFetchedQueried(true, false, filter, v2, path0, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);

Review comment:
       Good point! I will merge the `if` branches

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);

Review comment:
       Good point. :-)

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);
+        }
+
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried() || queried.contains(column);

Review comment:
       I think that this one is fine as what we need to check is that the fetched column provided is also queried.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 08:04;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r645424631



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);
+        }
+
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried() || queried.contains(column);

Review comment:
       yes, though the rule as it is now can be read as: return all fetched columns are queried or the column is queried (regardless whether it is fetched od not) - i know that it is legitimate - maybe some comment would be enough




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 09:20;githubbot;600","blerer commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r645434109



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);
+        }
+
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried() || queried.contains(column);

Review comment:
       I did not add any comment because the javadoc was clear about that.
   ```
   Whether the provided column, which is assumed to be _fetched_ by this filter (so the caller must guarantee 
   that {@code fetches(column) == true}, is also _queried_ by the user.
   ```
   The problem being that the javadoc is now in the parent class.
   What I can do is duplicate the javadoc. I can also put an assert for more safety.
   What do you think?
   
   




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 09:35;githubbot;600","adelapena commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r645553982



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);
+        }
+
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried() || queried.contains(column);

Review comment:
       If anything I would go with an assertion, although I think that the method name makes the precondition clear and we might lose some performance especially if multicell columns if assertions are enabled.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 13:05;githubbot;600","adelapena commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r645556866



##########
File path: src/java/org/apache/cassandra/cql3/selection/ColumnFilterFactory.java
##########
@@ -62,25 +63,27 @@ public static ColumnFilterFactory fromColumns(TableMetadata table,
      * @param table the table metadata
      * @param factories the {@code SelectorFactories}
      * @param orderingColumns the columns used for ordering
-     * @param nonPKRestrictedColumns the non primary key columns that have been resticted in the WHERE clause
+     * @param nonPKRestrictedColumns the non primary key columns that have been restricted in the WHERE clause
+     * @param returnStaticContentOnPartitionWithNoRows {@code true} if the query will return the static content when the partition has no rows, {@code false} otherwise.

Review comment:
       Nit: we can break this line
   ```suggestion
        * @param returnStaticContentOnPartitionWithNoRows {@code true} if the query will return the static content when the 
        * partition has no rows, {@code false} otherwise.
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -665,49 +1048,99 @@ public ColumnFilter deserialize(DataInputPlus in, int version, TableMetadata met
 
             if (hasQueried)
             {
-                Columns statics = Columns.serializer.deserializeStatics(in, metadata);
-                Columns regulars = Columns.serializer.deserializeRegulars(in, metadata);
-                queried = new RegularAndStaticColumns(statics, regulars);
+                queried = deserializeRegularAndStaticColumns(in, metadata);
             }
 
             SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections = null;
             if (hasSubSelections)
             {
-                subSelections = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                int size = (int) in.readUnsignedVInt();
-                for (int i = 0; i < size; i++)
+                subSelections = deserializeSubSelection(in, version, metadata);
+            }
+
+            if (isFetchAll)
+            {
+                // pre CASSANDRA-10657 (3.4-), when fetchAll is enabled, queried columns are not considered at all, and it
+                // is assumed that all columns are queried.
+                if (!hasQueried || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(fetched);
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
+                {
+                    return new SelectionColumnFilter(FetchingStrategy.ALL_COLUMNS, queried, fetched, subSelections);
+                }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !isFetchAllStatics)

Review comment:
       Nit: we can check the simple boolean before calling the method:
   ```suggestion
                   if (!isFetchAllStatics || isUpgradingFromVersionLowerThan40RC2())
   ```

##########
File path: src/java/org/apache/cassandra/cql3/selection/ColumnFilterFactory.java
##########
@@ -112,17 +115,19 @@ public ColumnFilter newInstance(List<Selector> selectors)
     {
         private final TableMetadata table;
         private final Set<ColumnMetadata> nonPKRestrictedColumns;
+        private final boolean returnStaticContentOnPartitionWithNoRows;
 
-        public OnRequestColumnFilterFactory(TableMetadata table, Set<ColumnMetadata> nonPKRestrictedColumns)
+        public OnRequestColumnFilterFactory(TableMetadata table, Set<ColumnMetadata> nonPKRestrictedColumns, boolean returnStaticContentOnPartitionWithNoRows)

Review comment:
       Nit: we can break this signature:
   ```suggestion
           public OnRequestColumnFilterFactory(TableMetadata table,
                                               Set<ColumnMetadata> nonPKRestrictedColumns,
                                               boolean returnStaticContentOnPartitionWithNoRows)
   ```

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeReadTest.java
##########
@@ -51,7 +51,7 @@ public void mixedModeReadColumnSubsetDigestCheck() throws Throwable
             // we need to let gossip settle or the test will fail
             int attempts = 1;
             //noinspection Convert2MethodRef
-            while (!((IInvokableInstance) (cluster.get(1))).callOnInstance(() -> Gossiper.instance.isUpgradingFromVersionLowerThan(CassandraVersion.CASSANDRA_4_0.familyLowerBound.get()) &&
+            while (!((IInvokableInstance) (cluster.get(1))).callOnInstance(() -> Gossiper.instance.isUpgradingFromVersionLowerThan(CassandraVersion.CASSANDRA_4_0) &&

Review comment:
       Nit: we can remove a couple of parenthesis and the `Convert2MethodRef` inspection suppression, which I think doesn't apply here:
   ```suggestion
               while (!((IInvokableInstance) cluster.get(1)).callOnInstance(() -> Gossiper.instance.isUpgradingFromVersionLowerThan(CassandraVersion.CASSANDRA_4_0) &&
   ```

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,475 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)

Review comment:
       Nit: we can check the simple boolean before calling the method:
   ```suggestion
                   if (!returnStaticContentOnPartitionWithNoRows || isUpgradingFromVersionLowerThan40RC2())
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 13:20;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r646298945



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;
+        }
 
-        if (fetchAllRegulars && queried == null)
-            return ""*/*"";
+        @Override
+        public Iterator<Cell<?>> filterComplexCells(ColumnMetadata column, Iterator<Cell<?>> cells)
+        {
+            return cells;
+        }
 
-        if (fetchAllRegulars && fetchAllStatics)
-            prefix = ""*/"";
+        @Override
+        public Tester newTester(ColumnMetadata column)
+        {
+            return null;
+        }
 
-        if (fetchAllRegulars && !fetchAllStatics)
+        @Override
+        public boolean equals(Object other)
         {
-            prefix = queried.statics.isEmpty()
-                   ? ""<all regulars>/""
-                   : String.format(""<all regulars>+%s/"", toString(queried.statics.selectOrderIterator(), false));
+            if (other == this)
+                return true;
+
+            if (!(other instanceof WildCardColumnFilter))
+                return false;
+
+            WildCardColumnFilter w = (WildCardColumnFilter) other;
+
+            return fetchedAndQueried.equals(w.fetchedAndQueried);
         }
 
-        return prefix + toString(queried.selectOrderIterator(), false);
-    }
+        @Override
+        public int hashCode()
+        {
+            return Objects.hash(fetchedAndQueried);
+        }
 
-    public String toCQLString()
-    {
-        if (queried == null || queried.isEmpty())
+        @Override
+        public String toString()
+        {
+            return ""*/*"";
+        }
+
+        public String toCQLString()
+        {
             return ""*"";
+        }
+
+        @Override
+        public boolean isWildcard()
+        {
+            return true;
+        }
 
-        return toString(queried.selectOrderIterator(), true);
+        @Override
+        protected SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections()
+        {
+            return null;
+        }
     }
 
-    private String toString(Iterator<ColumnMetadata> columns, boolean cql)
+    /**
+     * {@code ColumnFilter} sub-class for queries with selected columns.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of fetched columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class SelectionColumnFilter extends ColumnFilter
     {
-        StringJoiner joiner = cql ? new StringJoiner("", "") : new StringJoiner("", "", ""["", ""]"");
+        public final FetchingStrategy fetchingStrategy;
+
+        /**
+         * The selected columns
+         */
+        private final RegularAndStaticColumns queried;
+
+        /**
+         * The columns that need to be fetched to be able
+         */
+        private final RegularAndStaticColumns fetched;
+
+        private final SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections; // can be null
+
+        public static SelectionColumnFilter newInstance(FetchingStrategy fetchingStrategy,
+                                                        TableMetadata metadata,
+                                                        RegularAndStaticColumns queried,
+                                                        SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetchingStrategy != FetchingStrategy.ONLY_QUERIED_COLUMNS || metadata == null;
+            assert queried != null;
+
+            return new SelectionColumnFilter(fetchingStrategy,
+                                             queried,
+                                             fetchingStrategy.getFetchedColumns(metadata, queried),
+                                             subSelections);
+        }
+
+        /**
+         * Creates a {@code ColumnFilter} for queries with selected columns.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchingStrategy the strategy used to select the fetched columns
+         * @param fetched the columns that must be fetched
+         * @param queried the queried columns
+         * @param subSelections the columns sub-selections
+         */
+        public SelectionColumnFilter(FetchingStrategy fetchingStrategy,
+                                     RegularAndStaticColumns queried,
+                                     RegularAndStaticColumns fetched,
+                                     SortedSetMultimap<ColumnIdentifier, ColumnSubselection> subSelections)
+        {
+            assert fetched.includes(queried);
+
+            this.fetchingStrategy = fetchingStrategy;
+            this.queried = queried;
+            this.fetched = fetched;
+            this.subSelections = subSelections;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetched;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return queried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
+            return fetchingStrategy.fetchesAllColumns(isStatic);
+        }
+
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried();
+        }
+
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return fetchingStrategy.fetchesAllColumns(column.isStatic()) || queried.contains(column);
+        }
+
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return fetchingStrategy.areAllFetchedColumnsQueried() || queried.contains(column);

Review comment:
       the doc comment is enough for me




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;07/Jun/21 06:19;githubbot;600","jacek-lewandowski commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r646303707



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;

Review comment:
       Well, I only know that test was identical to what we test in 3.0 (https://github.com/apache/cassandra/blob/0e1f217079fa01366d9c8d758498016300467d31/test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java#L333). That is, it is possible to build a column filter in 3.0 with fetch-all, which has specified subselections and which can distinguish between fetched and queried for the selected cells. In fact, when I was writing those tests, I implemented them on 3.0 and copied to 3.11, checked if they work the same way assuming the cluster is on 3.0, then copied all the tests to 4.0 and did similar thing. So anything you change only in 4.0 for 3.0-tests, will be a behaviour different to what we have in 3.0 with the same filter. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;07/Jun/21 06:29;githubbot;600","blerer commented on a change in pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#discussion_r648425904



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -502,149 +561,473 @@ public ColumnFilter build()
             boolean isFetchAll = metadata != null;
 
             RegularAndStaticColumns queried = queriedBuilder == null ? null : queriedBuilder.build();
+
             // It's only ok to have queried == null in ColumnFilter if isFetchAll. So deal with the case of a selectionBuilder
             // with nothing selected (we can at least happen on some backward compatible queries - CASSANDRA-10471).
             if (!isFetchAll && queried == null)
                 queried = RegularAndStaticColumns.NONE;
 
-            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = null;
-            if (subSelections != null)
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = buildSubSelections();
+
+            if (isFetchAll)
             {
-                s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
-                for (ColumnSubselection subSelection : subSelections)
+                // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
+                // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
+                // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
+                // interpreted in a different way on 3.4- and 3.4+.
+                //
+                // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
+                // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
+                //
+                // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
+                // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
+                //
+                // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
+                if (queried == null || isUpgradingFromVersionLowerThan34())
+                {
+                    return new WildCardColumnFilter(metadata.regularAndStaticColumns());
+                }
+
+                // pre CASSANDRA-12768 (4.0-) all static columns should be fetched along with all regular columns.
+                if (isUpgradingFromVersionLowerThan40())
                 {
-                    if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
-                        s.put(subSelection.column().name, subSelection);
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
                 }
+
+                // pre CASSANDRA-16686 (4.0-RC2-) static columns where not fetched unless queried witch lead to some wrong results
+                // for some queries
+                if (isUpgradingFromVersionLowerThan40RC2() || !returnStaticContentOnPartitionWithNoRows)
+                {
+                    return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_REGULARS_AND_QUERIED_STATICS_COLUMNS, metadata, queried, s);
+                }
+
+                return SelectionColumnFilter.newInstance(FetchingStrategy.ALL_COLUMNS, metadata, queried, s);
+            }
+
+            return SelectionColumnFilter.newInstance(FetchingStrategy.ONLY_QUERIED_COLUMNS, (TableMetadata) null, queried, s);
+        }
+
+        private SortedSetMultimap<ColumnIdentifier, ColumnSubselection> buildSubSelections()
+        {
+            if (subSelections == null)
+                return null;
+
+            SortedSetMultimap<ColumnIdentifier, ColumnSubselection> s = TreeMultimap.create(Comparator.naturalOrder(), Comparator.naturalOrder());
+            for (ColumnSubselection subSelection : subSelections)
+            {
+                if (fullySelectedComplexColumns == null || !fullySelectedComplexColumns.contains(subSelection.column()))
+                    s.put(subSelection.column().name, subSelection);
             }
 
-            // When fetchAll is enabled on pre CASSANDRA-10657 (3.4-), queried columns are not considered at all, and it
-            // is assumed that all columns are queried. CASSANDRA-10657 (3.4+) brings back skipping values of columns
-            // which are not in queried set when fetchAll is enabled. That makes exactly the same filter being
-            // interpreted in a different way on 3.4- and 3.4+.
-            //
-            // Moreover, there is no way to convert the filter with fetchAll and queried != null so that it is
-            // interpreted the same way on 3.4- because that Cassandra version does not support such filtering.
-            //
-            // In order to avoid inconsitencies in data read by 3.4- and 3.4+ we need to avoid creation of incompatible
-            // filters when the cluster contains 3.4- nodes. We do that by forcibly setting queried to null.
-            //
-            // see CASSANDRA-10657, CASSANDRA-15833, CASSANDRA-16415
-            return new ColumnFilter(isFetchAll, isFetchAll && shouldFetchAllStatics(), metadata, isFetchAll && shouldQueriedBeNull() ? null : queried, s);
+            return s;
         }
     }
 
-    @Override
-    public boolean equals(Object other)
+    /**
+     * {@code ColumnFilter} sub-class for wildcard queries.
+     *
+     * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+     * with Schema race propagation. See CASSANDRA-15899.</p>
+     */
+    public static class WildCardColumnFilter extends ColumnFilter
     {
-        if (other == this)
+        /**
+         * The queried and fetched columns.
+         */
+        private final RegularAndStaticColumns fetchedAndQueried;
+
+        /**
+         * Creates a {@code ColumnFilter} for wildcard queries.
+         *
+         * <p>The class  does not rely on TableMetadata and expect a fix set of columns to prevent issues
+         * with Schema race propagation. See CASSANDRA-15899.</p>
+         *
+         * @param fetchedAndQueried the fetched and queried columns
+         */
+        private WildCardColumnFilter(RegularAndStaticColumns fetchedAndQueried)
+        {
+            this.fetchedAndQueried = fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns fetchedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public RegularAndStaticColumns queriedColumns()
+        {
+            return fetchedAndQueried;
+        }
+
+        @Override
+        public boolean fetchesAllColumns(boolean isStatic)
+        {
             return true;
+        }
 
-        if (!(other instanceof ColumnFilter))
-            return false;
+        @Override
+        public boolean allFetchedColumnsAreQueried()
+        {
+            return true;
+        }
 
-        ColumnFilter otherCf = (ColumnFilter) other;
+        @Override
+        public boolean fetches(ColumnMetadata column)
+        {
+            return true;
+        }
 
-        return otherCf.fetchAllRegulars == this.fetchAllRegulars &&
-               otherCf.fetchAllStatics == this.fetchAllStatics &&
-               Objects.equals(otherCf.fetched, this.fetched) &&
-               Objects.equals(otherCf.queried, this.queried) &&
-               Objects.equals(otherCf.subSelections, this.subSelections);
-    }
+        @Override
+        public boolean fetchedColumnIsQueried(ColumnMetadata column)
+        {
+            return true;
+        }
 
-    @Override
-    public String toString()
-    {
-        String prefix = """";
+        @Override
+        public boolean fetchedCellIsQueried(ColumnMetadata column, CellPath path)
+        {
+            return true;

Review comment:
       In the 3.0 version the only use case where sub-selections are used is for slice queries on super column and the code always use a `selectionBuilder` for those scenarios. By consequence, the test use case is not a true use case in 3.0.  
   Moreover, sub selection through CQL queries is only possible since 4.0 (see CASSANDRA-7396) and Thrift support has been removed in 4.0 so mix-cluster queries (3.0-4.0 or 3.11-4.0)  involving sub-selections should never occurs.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Jun/21 15:29;githubbot;600","blerer closed pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:23;githubbot;600","blerer commented on pull request #1031:
URL: https://github.com/apache/cassandra/pull/1031#issuecomment-859669688


   Merged manually


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:35;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,0,17400,,,0,17400,,,,,,,,,,,,,,,CASSANDRA-16671,,,,,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Correctness -> Transient Incorrect Response,,,,,,,,Normal,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jun 10 09:18:09 UTC 2021,,,,,,,All,,,,"0|z0r92o:",9223372036854775807,,,,adelapena,jlewandowski,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/2059c7586ef6bf10900977d4f5bb1072313e0b74,,,,,,,,,The patch add multiple unit tests,,,,,"31/May/21 16:20;blerer;When an CQL query is done at the partition level (without clustering or regular column restrictions), if a partition does not contains any row but contains some static columns a row will be returned to the user with {{null}} values for all the clustering and regular columns.  
Since CASSANDRA-12768, Cassandra fetch all the regular columns but only the static columns that have been selected by the user. By consequence, Cassandra will fetch only {{s1}} for the {{SELECT s1 FROM %s WHERE pk=1}} query from the description example. Due to that it will NOT attempt to fetch the {{s2}} value and will look only at the third and second SSTables. The partition having no value for {{s1}} Cassandra will consider the partition empty and will not return a row for it as it should. 
    ;;;","01/Jun/21 08:51;blerer;| [PR|https://github.com/apache/cassandra/pull/1031] | [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/129/workflows/519bc951-fac9-4950-87fc-7e3b0725414f] | [j11|https://app.circleci.com/pipelines/github/blerer/cassandra/129/workflows/906c3374-d8b5-4164-a42e-3981b801bbc3] |
The patch fix the issue by adding all the static columns to the fetched columns when the query is at the partition level (without clustering or regular column restrictions). I took the opportunity to simplify the {{ColumnFilter}} logic that was starting to become really confusing.

 As 4.0-rc1 has been released we need to ensure backward compatibility with it in a mixed cluster environment. To ensure that some extra changes were required in {{ColumnFilter}} and in {{Gossiper}}.;;;","03/Jun/21 16:15;blerer;[~adelapena], [~jlewandowski] Thanks for the fast review. I incorporated your suggestions updated the PR and re-run CI. The 3 failing test seems unrelated.;;;","04/Jun/21 11:40;adelapena;Here are some multiplexer runs for the modified tests (still running):

|| Test || j8-j8 || j8-j11 || j11-j11 ||
| ColumnFilterTest                   | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/541/workflows/4305b64a-a373-4529-a8ef-4e15e8efb1a8/jobs/4914] | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/541/workflows/4305b64a-a373-4529-a8ef-4e15e8efb1a8/jobs/4917] | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/541/workflows/4d42f088-d8e6-49fa-8187-9718fe66566d/jobs/4911] |
| DeleteTest                         | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/545/workflows/245e1ff1-fed0-4167-80fc-c9ea779bd813/jobs/4964] | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/545/workflows/245e1ff1-fed0-4167-80fc-c9ea779bd813/jobs/4961] | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/545/workflows/c0bc2011-2bf5-4d6f-a56e-c4b2b420c3d7/jobs/4957] |
| CompactTableTest                   | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/542/workflows/43645359-d5a0-478c-9c97-e651c652afdc/jobs/4947] | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/542/workflows/43645359-d5a0-478c-9c97-e651c652afdc/jobs/4948] | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/542/workflows/81d327f6-b10c-4beb-ab95-b701523f4fbc/jobs/4949] |
| SSTableAndMemTableDigestMatchTest  | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/543/workflows/4ce325de-e996-4200-bddf-be7142d3df81/jobs/4950] | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/543/workflows/4ce325de-e996-4200-bddf-be7142d3df81/jobs/4951] | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/543/workflows/0288fa96-cc38-452c-b7f6-19dc211fa9b4/jobs/4952] |
| InsertUpdateIfConditionStaticsTest | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/544/workflows/d100ab2f-6b00-42c6-a755-ab58f42d1c63/jobs/4953] | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/544/workflows/d100ab2f-6b00-42c6-a755-ab58f42d1c63/jobs/4954] | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/544/workflows/cdd6a17f-79e5-40aa-bf04-1258ceecdefb/jobs/4955] |
| MixedModeReadTest                  | [link|https://app.circleci.com/pipelines/github/adelapena/cassandra/541/workflows/4305b64a-a373-4529-a8ef-4e15e8efb1a8/jobs/4922] | -- | -- |
;;;","10/Jun/21 09:16;blerer;[~adelapena], [~jlewandowski] Thanks a lot for the reviews.;;;","10/Jun/21 09:18;blerer;Committed into cassandra-4.0.0 and merged into cassandra-4.0 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky ActiveRepairServiceTest.testRejectWhenPoolFullStrategy,CASSANDRA-16685,13379724,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,21/May/21 09:39,27/May/22 19:25,13/Jul/23 08:40,11/Jun/21 06:54,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/unit,,,,0,,,"Flaky [ActiveRepairServiceTest.testRejectWhenPoolFullStrategy|https://ci-cassandra.apache.org/job/Cassandra-4.0/50/testReport/junit/org.apache.cassandra.service/ActiveRepairServiceTest/testRejectWhenPoolFullStrategy_compression/]

{noformat}
Error Message

Task java.util.concurrent.FutureTask@63553e9f[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@52cb52bd[Wrapped task = org.apache.cassandra.service.ActiveRepairServiceTest$Task@1d1c37d5]] rejected from org.apache.cassandra.concurrent.JMXEnabledThreadPoolExecutor@218df7d6[Running, pool size = 2, active threads = 2, queued tasks = 0, completed tasks = 0]

Stacktrace

java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.FutureTask@63553e9f[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@52cb52bd[Wrapped task = org.apache.cassandra.service.ActiveRepairServiceTest$Task@1d1c37d5]] rejected from org.apache.cassandra.concurrent.JMXEnabledThreadPoolExecutor@218df7d6[Running, pool size = 2, active threads = 2, queued tasks = 0, completed tasks = 0]
	at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)
	at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)
	at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)
	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.execute(DebuggableThreadPoolExecutor.java:176)
	at java.base/java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:118)
	at org.apache.cassandra.service.ActiveRepairServiceTest.testRejectWhenPoolFullStrategy(ActiveRepairServiceTest.java:380)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)

Standard Output

INFO  [main] 2021-05-18 22:04:31,694 YamlConfigurationLoader.java:93 - Configuration location: file:////home/cassandra/cassandra/build/test/cassandra.compressed.yaml
DEBUG [main] 2021-05-18 22:04:31,698 YamlConfigurationLoader.java:112 - Loading settings from file:////home/cassandra/cassandra/build/test/cassandra.compressed.yaml
DEBUG [main] 2021-05-18 22:04:31,807 InternalLoggerFactory.java:63 - Using SLF4J as the default logging framework
DEBUG [main] 2021-05-18 22:04:31,827 PlatformDependent0
...[truncated 95289 chars]...
andra/build/test/cassandra/data/system/local-7ad54392bcdd35a684174e047860b377/nb_txn_flush_08e70270-b825-11eb-a393-871312b17b94.log 
DEBUG [MemtableFlushWriter:1] 2021-05-18 22:04:36,792 ColumnFamilyStore.java:1197 - Flushed to [BigTableReader(path='/home/cassandra/cassandra/build/test/cassandra/data/system/local-7ad54392bcdd35a684174e047860b377/nb-15-big-Data.db')] (1 sstables, 4.944KiB), biggest 4.944KiB, smallest 4.944KiB
DEBUG [main] 2021-05-18 22:04:36,795 StorageService.java:1619 - NORMAL
{noformat}
",,adelapena,bereng,jeromatron,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jun 11 06:57:24 UTC 2021,,,,,,,All,,,,"0|z0r920:",9223372036854775807,,,,adelapena,mck,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/23ad7c301e227d5ea88cea0784b32e6351603912,,,,,,,,,See PR,,,,,"25/May/21 10:24;bereng;Managed to repro with the {{RepeatableRunner}} locally on 500 iterations. Basically there is a small window where the task signals completion on a count down latch but the pool executor is still tidying up the environment. Hence a new submission is rejected. The fix is to wait for the pool to be ready to accept new tasks.;;;","01/Jun/21 07:40;bereng;The underlying root problem seems to stem from java's {{ThreadPool}} and {{SynchronousQueue}} interactions. The queue will fail {{offer()}} calls if there is no thread ready to read. At the same time the TP can be bouncing and spinning threads around internally. If you happen to submit a task during that window you will get false rejections. Other people have hit this, it can be googled easily, and it seems to be an internal Java thing.

Reproduction is easy with the {{RepeteableRunner}} for the single test method where it fails around 10%. 500 runs is a good start, you'll have to rename the KS on each iteration though. I am providing a pure java test, with no C* code involved, as proof this is a generic issue and not related to our codebase

{code:java}
    @Test
    public void testTP() throws InterruptedException
    {
        ExecutorService validationExecutor = null;
        try
        {
            ThreadPoolExecutor executor = new ThreadPoolExecutor(1,
                                                                 2,
                                                                 1,
                                                                 TimeUnit.HOURS,
                                                                 new SynchronousQueue<>(),
                                                                 new NamedThreadFactory(""Repair-Task""));
            executor.setRejectedExecutionHandler(new ThreadPoolExecutor.AbortPolicy());
            executor.prestartAllCoreThreads();
            validationExecutor = executor;
            Condition blocked = new SimpleCondition();
            CountDownLatch completed = new CountDownLatch(2);
            //Thread.sleep(100);
            validationExecutor.submit(new Task(blocked, completed));
            //Thread.sleep(100);
            validationExecutor.submit(new Task(blocked, completed));
            blocked.signalAll();
            completed.await(11, TimeUnit.SECONDS);
        }
        finally
        {
            validationExecutor.shutdownNow();
        }
    }
{code}

The solution is to add a {{Thread.sleep()}} to give the TP time to sort itself before accepting new tasks. It's ugly but I can't come up with a better idea.

In the PR 1K CI repeats can be found.;;;","10/Jun/21 08:24;mck;+1 ;;;","10/Jun/21 12:26;adelapena;+1;;;","11/Jun/21 06:57;bereng;Thx for the review guys!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky MemtableSizeTest,CASSANDRA-16684,13379722,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,bereng,bereng,21/May/21 09:36,27/May/22 19:25,13/Jul/23 08:40,03/Jun/21 16:23,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/unit,,,,0,,,"Flaky [MemtableSizeTest|https://ci-cassandra.apache.org/job/Cassandra-4.0/50/testReport/junit/org.apache.cassandra.cql3/MemtableSizeTest/testSize_compression/]

{noformat}
Error Message

Expected heap usage close to 50.085MiB, got 41.294MiB.

Stacktrace

junit.framework.AssertionFailedError: Expected heap usage close to 50.085MiB, got 41.294MiB.

	at org.apache.cassandra.cql3.MemtableSizeTest.testSize(MemtableSizeTest.java:121)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)

Standard Output

INFO  [main] 2021-05-18 22:08:42,837 YamlConfigurationLoader.java:93 - Configuration location: file:////home/cassandra/cassandra/build/test/cassandra.compressed.yaml
DEBUG [main] 2021-05-18 22:08:42,840 YamlConfigurationLoader.java:112 - Loading settings from file:////home/cassandra/cassandra/build/test/cassandra.compressed.yaml
DEBUG [main] 2021-05-18 22:08:42,934 InternalLoggerFactory.java:63 - Using SLF4J as the default logging framework
DEBUG [main] 2021-05-18 22:08:42,956 PlatformDependent0
...[truncated 86028 chars]...
hed transaction log, deleting /home/cassandra/cassandra/build/test/cassandra/data/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb_txn_flush_a3253f00-b825-11eb-b0ec-cd4f0218a6b5.log 
DEBUG [MemtableFlushWriter:2] 2021-05-18 22:08:55,552 ColumnFamilyStore.java:1197 - Flushed to [BigTableReader(path='/home/cassandra/cassandra/build/test/cassandra/data/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-6-big-Data.db')] (1 sstables, 4.894KiB), biggest 4.894KiB, smallest 4.894KiB

{noformat}
",,bereng,blambov,e.dimitrova,jeromatron,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Jun 07 09:10:02 UTC 2021,,,,,,,All,,,,"0|z0r91k:",9223372036854775807,,,,blambov,e.dimitrova,,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/3875fd26ea3c16e57bf08454d570e3359d2ce5fc,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16684?focusedCommentId=17356498&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17356498,,,,,"25/May/21 06:13;bereng;https://ci-cassandra.apache.org/job/Cassandra-4.0/56/testReport/junit/org.apache.cassandra.cql3/MemtableSizeTest/testSize/ #collaborating;;;","26/May/21 19:53;e.dimitrova;[~bereng] now both links show passed and I ran it [1000 times|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/898/workflows/157d2d48-f3be-4709-b3e0-b49c900177a3/jobs/5340/artifacts] and it succeeded. I am puzzled.... I saw it failing in CI too, but now the status is changed....;;;","26/May/21 22:22;e.dimitrova;Alright, it failed three times out of 1000 with Java 11 but this time it shows we used less heap space... To be precise - Build on Java 8 run with Java 11 - https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/898/workflows/157d2d48-f3be-4709-b3e0-b49c900177a3/jobs/5380

Java 11 build and run is passing 1000 times 
https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/898/workflows/0bd57270-df52-4572-be97-fc55b05e59d7/jobs/5379
;;;","26/May/21 22:25;e.dimitrova;/CC [~barnie] as I am running out of ideas with this one...;;;","27/May/21 04:42;bereng;[~e.dimitrova] if jenkins does the fail/pass/fail dance to you go to the actual stage test results and the it shows failed always: https://ci-cassandra.apache.org/job/Cassandra-4.0-test/51/jdk=jdk_11_latest,label=cassandra,split=2/testReport/junit/org.apache.cassandra.cql3/MemtableSizeTest/testSize/ ;;;","27/May/21 20:39;e.dimitrova;One observation I have is that the times when the test fails the _deepSizeBefore_ is the only thing that differs and leads to the difference and test failures. So now I am wondering what causes that. 

That one we measure [here |https://github.com/apache/cassandra/blob/3b553d8e13dbdbe59119de9c917d9aacc440741e/test/unit/org/apache/cassandra/cql3/MemtableSizeTest.java#L69].;;;","03/Jun/21 14:58;e.dimitrova;I had an offline discussion and it seems this test can flake sometimes based on the CI infrastructure and not due to product defect. -The suggestion is to mark it as flaky which I have done- [-here-|https://github.com/ekaterinadimitrova2/cassandra/commit/dd0f55567/3c26e90b1a1a13204195b89b1644]

[~blerer] -or- [~blambov]-, do you mind to review, please?- 

[~blambov] already did a pass. 

New version:

[https://github.com/ekaterinadimitrova2/cassandra/blob/f635755025ebf27bf3868b40e033d04ae1133689/test/unit/org/apache/cassandra/cql3/MemtableSizeTest.java|https://github.com/ekaterinadimitrova2/cassandra/commit/f635755025ebf27bf3868b40e033d04ae1133689];;;","03/Jun/21 15:48;blambov;New version LGTM.;;;","03/Jun/21 16:22;e.dimitrova;Thank you for the quick review!

Committed:

aef535cae1..3875fd26ea  cassandra-4.0 -> cassandra-4.0

bedf6ca998..4acfd3bdf1  trunk -> trunk;;;","07/Jun/21 09:10;bereng;[~e.dimitrova] this came up again [here|https://ci-cassandra.apache.org/job/Cassandra-4.0.0/8/testReport/junit/org.apache.cassandra.cql3/MemtableSizeTest/testTruncationReleasesLogSpace_cdc/] and it is already the version that has been marked as flaky #collaborating I am wondering if env can have such an impact whether this test makes sense? Do you remember details of that offline conversation on how env might make it fail? I am curious thx!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"StandaloneVerifier does not fail when unable to verify SSTables, it only fails if Corruption is thrown",CASSANDRA-16683,13379621,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,21/May/21 00:45,27/May/22 19:25,13/Jul/23 08:40,21/May/21 23:58,3.0.25,3.11.11,4.0,4.0-rc2,4.1,4.1-alpha1,,Test/dtest/python,Tool/sstable,,,0,,,"offline_tools_test.py::TestOfflineTools::test_sstableverify has the following check

{code}
       try:
           (out, error, rc) = node1.run_sstableverify(""keyspace1"", ""standard1"", options=['-v'])
       except ToolError as e:
           # Process sstableverify output to normalize paths in string to Python casing as above
           error = re.sub(""(?<=Corrupted: ).*"", lambda match: os.path.normcase(match.group(0)), str(e))

           assert re.search(""Corrupted: "" + sstable1, error)
           assert e.exit_status == 1, str(e.exit_status)
{code}

This checks if the corrupt log is present IFF ToolError is thrown, but does not validate that the error is actually thrown.  I tried calling the same logic before the try to validate and see that it does not fail.  If we fix the test to check for error we also see that the log that is returned to the user does not match 2.2’s behavior but instead returns different logic as digest validation throws IOException, which we do not convert to a CorruptSSTableException (which is the message the test checks for).

This also shows another big issue, that when the digest fails verify passes",,dcapwell,e.dimitrova,marcuse,stefan.miklosovic,,,,,,,,,,,,"dcapwell opened a new pull request #137:
URL: https://github.com/apache/cassandra-dtest/pull/137


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/May/21 01:47;githubbot;600","dcapwell opened a new pull request #1015:
URL: https://github.com/apache/cassandra/pull/1015


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/May/21 01:49;githubbot;600","smiklosovic closed pull request #1015:
URL: https://github.com/apache/cassandra/pull/1015


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:14;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Unrecoverable Corruption / Loss,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Sep 13 13:28:43 UTC 2021,,,,,,,All,,,,"0|z0r8f4:",9223372036854775807,,,,marcuse,,,,Normal,,2.2.0,,https://github.com/apache/cassandra/commit/79e3669796430413287d4e6c256fc0bf1a7e5f30,,,,,,,,,local / ci testing,,,,,"21/May/21 07:19;marcuse;+1;;;","21/May/21 22:28;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|cassandra-3.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16683-cassandra-3.0-60A366A1-0D9E-42A6-A7AF-06A338809BF6]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16683-cassandra-3.0-60A366A1-0D9E-42A6-A7AF-06A338809BF6]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/793/]|
|cassandra-3.11|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16683-cassandra-3.11-60A366A1-0D9E-42A6-A7AF-06A338809BF6]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16683-cassandra-3.11-60A366A1-0D9E-42A6-A7AF-06A338809BF6]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/794/]|
|cassandra-4.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16683-cassandra-4.0-60A366A1-0D9E-42A6-A7AF-06A338809BF6]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16683-cassandra-4.0-60A366A1-0D9E-42A6-A7AF-06A338809BF6]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/795/]|
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16683-trunk-60A366A1-0D9E-42A6-A7AF-06A338809BF6]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16683-trunk-60A366A1-0D9E-42A6-A7AF-06A338809BF6]|[build|unknown]|
;;;","21/May/21 23:02;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|cassandra-3.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16683-cassandra-3.0-EE2779F4-1496-4C96-B603-E79E9C948014]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16683-cassandra-3.0-EE2779F4-1496-4C96-B603-E79E9C948014]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/797/]|
|cassandra-3.11|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16683-cassandra-3.11-EE2779F4-1496-4C96-B603-E79E9C948014]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16683-cassandra-3.11-EE2779F4-1496-4C96-B603-E79E9C948014]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/798/]|
|cassandra-4.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16683-cassandra-4.0-EE2779F4-1496-4C96-B603-E79E9C948014]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16683-cassandra-4.0-EE2779F4-1496-4C96-B603-E79E9C948014]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/799/]|
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16683-trunk-EE2779F4-1496-4C96-B603-E79E9C948014]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16683-trunk-EE2779F4-1496-4C96-B603-E79E9C948014]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/800/]|
;;;","21/May/21 23:58;dcapwell;dtest commit: https://github.com/apache/cassandra-dtest/commit/dfeb14d53ecda8868293af0234c3955df07fd1cc;;;","21/May/21 23:59;dcapwell;Python dtests were failing in the automation as CASSANDRA-16688 is impacting them.  When I manually tweak the builds they end up passing, so went ahead and merged.;;;","13/Sep/21 12:32;stefan.miklosovic;FYI  test fails for me at least when building 3.11, for offline_tools_test.py::TestOfflineTools::test_sstableverify. It seems like the output was changed from 3.11 to 4 and one test, as written, does not cover it all anymore for both versions.;;;","13/Sep/21 13:28;brandon.williams;Created CASSANDRA-16948 to follow up.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cassandra 4.0 RC1 ... Audit Logs going to wrong location,CASSANDRA-16682,13379485,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,oramad,oramad,20/May/21 10:29,27/May/22 19:24,13/Jul/23 08:40,21/May/21 19:01,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Tool/auditlogging,,,,0,,,"Version : Cassandra 4.0 RC1

Settings in my : <CASSANDRA_HOME>/conf/cassandra.yaml 
{code:yaml}
audit_logging_options: 
    enabled: true
     logger: 
      - class_name: FileAuditLogger
     excluded_categories: QUERY, DML
     audit_logs_dir: ""/apps/opt/cassandra/logs/audit""
     roll_cycle: DAILY
     block: false
{code}
 After restart of Cassandra ... I can see the Audit Logs. But they are going into system.log and debug.log. They are NOT going into 
{noformat}
""/apps/opt/cassandra/logs/audit/audit.log""{noformat}
 

Also noticed that : it does not ignore the ""excluded_categories"" and logs everything ...",,e.dimitrova,oramad,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri May 21 19:00:21 UTC 2021,,,,,,,All,,,,"0|z0r7kw:",9223372036854775807,,,,brandon.williams,oramad,,,Normal,,4.0-rc1,,https://github.com/apache/cassandra/commit/658f3e11a66aca7333157a9b20bf7189005329cf,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16682?focusedCommentId=17349383&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17349383,,,,,"20/May/21 13:27;oramad;also noticed that : it does not ignore the ""excluded_categories"" and logs everything ...;;;","20/May/21 14:04;e.dimitrova;Hi [~oramad], thank you for the report and the ticket, really appreciate it!

I will look into this today. In the meanwhile - you use the default cassandra.yaml config? Or if you come up with any other specifics you might want to share,  that will be appreciated. Thanks again;;;","20/May/21 14:31;oramad;Settings in my : <CASSANDRA_HOME>/conf/cassandra.yaml

audit_logging_options:
    enabled: true
      logger:
      - class_name: FileAuditLogger
      excluded_categories: QUERY, DML
     audit_logs_dir: ""/apps/opt/cassandra/logs/audit""
     roll_cycle: DAILY
     block: false

 ;;;","20/May/21 19:26;e.dimitrova;Hi [~oramad],

I think you might be missing to follow this instruction maybe:

[https://cassandra.apache.org/doc/latest/operating/audit_logging.html?highlight=audit%20logging#configuring-fileauditlogger]

After I made this addition to my logback.xml, everything worked as expected, logging to audit.log. Can you, please, verify this?

In the meanwhile I am looking at the other issue about ignoring the ""excluded_categories"".;;;","20/May/21 20:39;oramad;OK. After modifying my logback.xml it is working.
 # audit is now going into audit.log
 # documentation has provided sample entry for audit into logback.xml — however documentation has no mention where to add it ... by looking at formatting of that xml i know it is logback.xml file ... others might not know.
 # Cassandra 4.x software itself should ship with default logback.xml with these required entries ... it does not harm to have the logback.xml entries ... since auditing is enabled or disabled via cassandra.yaml

 

It is still not honoring my request to ""excluded_categories: QUERY, DML"" and still recording everything.

 ;;;","20/May/21 20:56;oramad;I might have identified the issue with excluded_categories ... please give me some time ... i will provide update.;;;","20/May/21 20:56;e.dimitrova;Thank you for confirming!

All valid points and on my list already. Looking to fix the issue and improve docs and logback.xml.

Thank you!;;;","20/May/21 23:07;oramad;$ cat ~/conf/cassandra.yaml | grep excluded_categories

– bad settings : only uses first entry and ignores other values after first space
 excluded_categories: OTHER, QUERY, DDL
 excluded_categories: ""OTHER, QUERY, DDL""

– correct setting : string_comma_separated_without_spaces
 excluded_categories: OTHER,DML,DDL
 $

----------------------------
 MY TEST RESULTS :
 excluded_categories: QUERY,DML
 Duration : 90 minutes
 Various # Transactions : 80,000

following type of audit logs are recorded :
 type:LOGIN_ERROR|category:AUTH
 type:LOGIN_SUCCESS|category:AUTH
 type:PREPARE_STATEMENT|category:PREPARE
 type:USE_KEYSPACE|category:OTHER

NO QUERIES AND DMLS in the audit.log

TEST RESULT : SUCCESSFUL
 ----------------------------;;;","20/May/21 23:08;oramad;I think this ticket can be CLOSED.;;;","20/May/21 23:32;e.dimitrova;I confirm I didn't find any other issue with the _AuditLogFilter_. We also have a unit test for that one. 

I will use this ticket to improve the docs and logback.xml tomorrow. Thank you! ;;;","21/May/21 17:07;e.dimitrova;[Patch |https://github.com/ekaterinadimitrova2/cassandra/commit/5c4f035e611c448ed6e2afa49c7b9c60ec2feb48]

[~oramad], do you mind to review it if you have a bit of time, please? Your feedback is really valuable.

In any case we will need one more committer to review it. [~brandon.williams], [~mck], will anyone of you have a bit of time to check it, please?

Thank you in advance.;;;","21/May/21 17:13;brandon.williams;LGTM, with one super-duper-ultra-nit: ""time stamp"" could be ""timestamp"";;;","21/May/21 17:23;oramad;thinking ....

in default ""logback.xml"" ... do we need to keep the new default entries for audit logging in COMMENTED OUT mode ?

can we leave it in there WITHOUT commenting it out ? because on/off switch is somewhere else ""cassandra.yaml  : audit_logging_options : enabled: true/false"" + it will require ""logger : class_name: FileAuditLogger"".;;;","21/May/21 17:23;oramad;BTW ... rest of changes looking good.;;;","21/May/21 17:44;e.dimitrova;Thank you both for the quick reviews.
{quote}can we leave it in there WITHOUT commenting it out ? because on/off switch is somewhere else ""cassandra.yaml  : audit_logging_options : enabled: true/false"" + it will require ""logger : class_name: FileAuditLogger"".
{quote}
I thought about it, but this will be a change to the original default behavior which is as per design for audit logs to be directed to system logs and separated only on user decision (by adding the config in logback.xml). I am not sure we should change it now before the release. ;;;","21/May/21 18:03;oramad;got it ... i was not aware of the original design and decisions.

we should not introduce new flow before the major release.

please leave the new entries in logback.xml in COMMENTED OUT section.;;;","21/May/21 19:00;e.dimitrova;Thank you both, the patch was committed to 4.0 and trunk. I also checked locally the doc build. I took care of the  super-duper-ultra-nit on commit :) 

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
org.apache.cassandra.utils.memory.LongBufferPoolTest - tests are flaky,CASSANDRA-16681,13379350,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,pkolaczk,e.dimitrova,e.dimitrova,19/May/21 19:12,22/Oct/22 11:33,13/Jul/23 08:40,11/Oct/22 14:54,3.11.14,4.0.7,4.1-rc1,5.0,,,,CI,,,,0,,,"Jenkins history:

[https://jenkins-cm4.apache.org/job/Cassandra-4.0/50/testReport/junit/org.apache.cassandra.utils.memory/LongBufferPoolTest/testPoolAllocateWithRecyclePartially/history/]

Fails being run in a loop in CircleCI:

https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/844/workflows/945011f4-00ac-4678-89f6-5c0db0a40169/jobs/5008

 ",,adelapena,aholmber,aleksey,benedict,bereng,blerer,e.dimitrova,gianluca,jeromatron,maedhroz,pkolaczk,,,,,"aholmberg closed pull request #1014:
URL: https://github.com/apache/cassandra/pull/1014


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/May/21 20:03;githubbot;600","aholmberg opened a new pull request #1014:
URL: https://github.com/apache/cassandra/pull/1014


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/May/21 20:03;githubbot;600","smiklosovic closed pull request #1619: CASSANDRA-16681: BufferPool and LongBufferPoolTest fixes
URL: https://github.com/apache/cassandra/pull/1619


;22/Oct/22 11:32;githubbot;600","smiklosovic closed pull request #1618: CASSANDRA-16681: BufferPool and LongBufferPoolTest fixes
URL: https://github.com/apache/cassandra/pull/1618


;22/Oct/22 11:32;githubbot;600","smiklosovic closed pull request #1617: CASSANDRA-16681: Make LongBufferPoolTest insensitive to timing
URL: https://github.com/apache/cassandra/pull/1617


;22/Oct/22 11:33;githubbot;600","smiklosovic closed pull request #1614: CASSANDRA-16681: BufferPool and LongBufferPoolTest fixes
URL: https://github.com/apache/cassandra/pull/1614


;22/Oct/22 11:33;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,3600,,,0,3600,,,,,,,,,,CASSANDRA-17552,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,pkolaczk,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Byzantine,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Oct 11 14:54:26 UTC 2022,,,stefania_alborghetti,,,,All,,,,"0|z0r6qw:",9223372036854775807,,,,aleksey,blerer,,,Normal,,4.0.0,,https://github.com/apache/cassandra/commit/e13356d75d2d3c200f1636337cf15329bd1b829b,,,,,,,,,"Unit tested by LongBufferPoolTest and BufferPoolTest.
Documentation: commit message + source code comments where necessary
",,,,,"19/May/21 21:16;aholmber;I think this is a test issue. I think we have a race [here|https://github.com/apache/cassandra/blob/9a432418f2277c40a1fe4b64049688d6354ecdca/test/burn/org/apache/cassandra/utils/memory/LongBufferPoolTest.java#L276-L284] where, if threads exit after {{doneThreads}} is sampled, the assumptions mentioned in the comment are violated.

I haven't assigned or posted a change because I'm still looking at some other weirdness around this test and trying to understand how it was intended to work.

If anyone else wants to take a look and corroborate or just take the ticket, it's fine by me.;;;","26/May/21 17:53;aholmber;Although I still think there is a race as described, more troubleshooting has indicated that it is not the cause for this assertion error most times. It's happening earlier on in the test when the threads would not be exiting. When it does happen, there is always only a single tracked chunk that has not been recycled a given time interval. It appears that the chunk is not being acquired or cycled in any way after entering this state. Still digging on it, but if anyone with more knowledge in the area wants to take a look, they are welcome.;;;","03/Jun/21 18:17;aholmber;I think I've found a race. I know [~gianluca] also said he's working on a patch, so I'm just going to post my findings here so we can compare notes.

What I think is happening: 

LocalPool.addChunk [evicts|https://lists.apache.org/thread.html/r75b09da8df530aa382605887a63dfa57b9c8d647b10f9064dd2b027a%40%3Cdev.cassandra.apache.org%3E] a non-empty chunk in thread A. {{evict.release()}} finds a ""not free"" chunk and does not recycle. Meanwhile, thread B does {{LocalPooll.put}}, freeing the last buffer from the chunk. {{free}} returns -1, but the [status CaS|https://github.com/apache/cassandra/blob/4acfd3bdf1acdb6b28059a49dd39823d7ea0689d/src/java/org/apache/cassandra/utils/memory/BufferPool.java#L808] fails because thread A has not yet {{setEvicted}}. We therefore leave the function with the chunk totally freed, but not recycled.

I have a patch with some synchronization around the release+status update that removes this flakiness. Currently wondering how big an issue it actually is, and if we care. Also pondering if this should be moved out of 4.0 for a number of reasons:

1.) 4.0 is close and I don't have much appetite for touching such integral code
2.) I think this issue is low-impact since the chunk would just be GC'd instead of being recycled
3.) The test is fairly pathological and this is perhaps even less likely to happen in the running server (pure speculation)

Curious to get input on this and hear what Gianluca has found.;;;","09/Jun/21 14:43;aholmber;bq. I have a patch with some synchronization around the release+status update that removes this flakiness.

Getting back to this after some time, I'm less confident in the patch. I ported the fix without all my instrumentation and I'm back seeing flakiness. I will be looking into it more, but meanwhile I'm open to input if there are other leads.;;;","14/Jun/21 09:35;bereng;How did you repro this one [~aholmber]? I have given it a go with no luck so far.;;;","14/Jun/21 14:51;aholmber;I have never reproduced locally. I could get it occasionally in the test multiplexer in CircleCI, but I have not developed any good leads. I have not spent a lot of time on it more recently. I was thinking of un-assigning and asking whether we should punt on this, unless someone has energy to devote to it. Thoughts?;;;","16/Jun/21 15:48;aholmber;I haven't bottomed out on this, and I haven't produced a complete solution thus far. I'm going to continue looking at it intermittently as I'm able, but meanwhile I'll un-assign to make sure I'm not dissuading anyone else from taking it up.;;;","16/Jun/21 19:56;brandon.williams;{noformat}
[junit-timeout] Testcase: testPoolAllocateWithRecyclePartially(org.apache.cassandra.utils.memory.LongBufferPoolTest):   FAILED
[junit-timeout] null
[junit-timeout] junit.framework.AssertionFailedError
[junit-timeout]         at org.apache.cassandra.utils.memory.LongBufferPoolTest$Debug.check(LongBufferPoolTest.java:106)
[junit-timeout]         at org.apache.cassandra.utils.memory.LongBufferPoolTest.testAllocate(LongBufferPoolTest.java:288)
[junit-timeout]         at org.apache.cassandra.utils.memory.LongBufferPoolTest.testPoolAllocate(LongBufferPoolTest.java:139)
[junit-timeout]         at org.apache.cassandra.utils.memory.LongBufferPoolTest.testPoolAllocateWithRecyclePartially(LongBufferPoolTest.java:127)
[junit-timeout]
[junit-timeout]
[junit-timeout] Testcase: testPoolAllocateWithoutRecyclePartially(org.apache.cassandra.utils.memory.LongBufferPoolTest):        FAILED
[junit-timeout] null
[junit-timeout] junit.framework.AssertionFailedError
[junit-timeout]         at org.apache.cassandra.utils.memory.LongBufferPoolTest$Debug.check(LongBufferPoolTest.java:106)
[junit-timeout]         at org.apache.cassandra.utils.memory.LongBufferPoolTest.testAllocate(LongBufferPoolTest.java:288)
[junit-timeout]         at org.apache.cassandra.utils.memory.LongBufferPoolTest.testPoolAllocate(LongBufferPoolTest.java:139)
[junit-timeout]         at org.apache.cassandra.utils.memory.LongBufferPoolTest.testPoolAllocateWithoutRecyclePartially(LongBufferPoolTest.java:133)
{noformat}

Just adding these since I had not seen them before.;;;","17/Jun/21 21:14;aholmber;Looking at this more today. I'm wondering if we should review and maybe move forward a patch for the race I described above. As mentioned, I could still get failures following that, but what I realized today:
 - Failures go from ~dozens per hundred runs to single digit
 - Even though one mode of flakiness fails the same assertion, I now believe it may be arriving there by a different mechanism

Is it worth taking a look at those changes in the interest of getting more stability, and possibly spinning out investigation looking for more issues?;;;","18/Jun/21 05:11;bereng;That sounds good to me unless [~brandon.williams] beats us to it. If we do that though I would put here a detailed description of the findings and thread interactions because in a few months time, if we revisit this, we don't want to ramp up again on such things.;;;","22/Jun/21 04:45;gianluca;I've been on and off looking into this ticket too.

What I noticed is that sometimes a worker thread is simply lagging behind and the corresponding chunk doesn't get recycled in the arbitrary window of 10 seconds. But if we were to wait a couple more seconds (instead of failing with the assertion) we'd see it would eventually catch up.
 The problem is that the {{sharedRecycle}} queues fill up more quickly than the other threads can process them.

In order to reproduce the failure locally, I simply increase the number of concurrent worker threads from a factor of 2 to, say, 10 here [https://github.com/apache/cassandra/blob/699a1f74fcc1da1952da6b2b0309c9e2474c67f4/test/burn/org/apache/cassandra/utils/memory/LongBufferPoolTest.java#L139].

I believe some sort of CPU contention is also happening in CircleCI, given the test can't determine the right number of processors available to the Docker container.
 The xlarge instance has only 8 vCPUs, but from the logs we can see the test identifies 36 cores and so it starts 72 threads:
{code:java}
[junit-timeout] INFO  [main] 2021-05-19 16:18:52,488 LongBufferPoolTest.java:264 - 2021/05/19 16:18:52 - testing 72 threads for 2m
{code}
I tested with different instance sizes (small, medium, xlarge) and they all report 36 cores.
 This seems to be a problem with CircleCI in general:

[https://circleci.com/docs/2.0/configuration-reference/#resourceclass]
{quote}Note: Java, Erlang and any other languages that introspect the /proc directory for information about CPU count may require additional configuration to prevent them from slowing down when using the CircleCI 2.0 resource class feature. Programs with this issue may request 32 CPU cores and run slower than they would when requesting one core. Users of languages with this issue should pin their CPU count to their guaranteed CPU resources.
{quote}
I have a patch to set a fixed number of workers threads (16) for this test that should help with this issue: [https://github.com/grighetto/cassandra/pull/8]

All other assertions in the test that deal with integrity/correctness always passed, which also indicates this is really just a timing issue.;;;","22/Jun/21 11:21;brandon.williams;FWIW, I can reproduce this on a plain linux machine running java 8 without any modification.;;;","22/Jun/21 12:47;gianluca;Without the modification, I've seen it cut pretty close too (meaning the last chunk got recycled just the before the latch timeout), but increasing the threads favors it.
But anything that causes a delay has the potential to fail that assertion because it's time based. There are many random choices going on in the test, if so it happens that many workers are queuing their buffers for their neighbours to release them, but their neighbours don't get scheduled to clear the queues, it has the potential to fail too.

My initial proposal consisted in reducing the ratio of queuing/direct release: https://github.com/grighetto/cassandra/pull/7/commits/aa3ba87f137f0ccba94957a1f100de3953b172bf
That also works for me, even with the increased number of threads.

Anyway, there might be other issues too, but I'm pretty sure CPU contention is playing a part on CircleCI because {{Runtime.getRuntime().availableProcessors()}} doesn't work properly there.;;;","23/Jun/21 21:13;brandon.williams;bq. All other assertions in the test that deal with integrity/correctness always passed, which also indicates this is really just a timing issue.

I agree with your analysis.  Even doubling your reduction ratio to 1 out of 20 and reducing the threads to 2, this test still fails for me, not that I'm surprised.

I believe like many other tests that rely on timing, we're never going to be able to fully prevent this from being flaky in the real world where things can be slower than theory.;;;","25/Jun/21 22:48;brandon.williams;For 4.0.0 I suggest we disable this test and examine rewriting it later.;;;","06/Jul/21 21:45;maedhroz;Saw this here: https://ci-cassandra.apache.org/job/Cassandra-devbranch/897/;;;","16/Sep/21 16:32;e.dimitrova;I just found this in 3.11 - https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1119/testReport/junit/org.apache.cassandra.utils.memory/LongBufferPoolTest/testAllocate/;;;","22/Mar/22 12:03;adelapena;New error on trunk: [https://ci-cassandra.apache.org/job/Cassandra-trunk/1032/testReport/org.apache.cassandra.utils.memory/LongBufferPoolTest/testPoolAllocateWithRecyclePartially_2/]

It can be reproduced [with CircleCI|https://app.circleci.com/pipelines/github/adelapena/cassandra/1406/workflows/ef197b74-0805-404f-bdcd-851cdd75a846].;;;","13/Apr/22 15:04;pkolaczk;See the other (duplicate) ticket. There are more modes of failure than mentioned here, and this is likely not (only) a test issue. 
The code under test is not properly synchronized in at least one place (MicroQueueOfChunks is one obvious place).;;;","10/May/22 08:57;pkolaczk;I submitted a patch for 4.0+ version.
Now looking into 3.11 branch, but it turns out it is different and it actually doesn't have some of the issues I fixed. 
For instance, 3.11 doesn't seem to have the biggest thread-safety issue in the MicroQueueOfChunks caused by Chunk#recycler  reference, because it doesn't have the recycler field at all (and no tinyPool either). 
It also doesn't seem to have the memory in use bug addressed by my first patch. 

However, it does seem to rely on the same assumptions in the LongBufferPoolTest, so the test is probably flaky there as well. 
Do you think it is worth backporting the relevant fixes to 3.11? 


CC [~stefania_alborghetti] [~jasonstack];;;","10/May/22 09:13;bereng;3.11 is a supported version, so unless sbdy corrects me I am afraid we have to.;;;","11/May/22 13:28;pkolaczk;Ok, I created the following PRs:

casssandra-3.11: https://github.com/apache/cassandra/pull/1617
cassandra-4.0: https://github.com/apache/cassandra/pull/1614
cassandra-4.1: https://github.com/apache/cassandra/pull/1618
trunk: https://github.com/apache/cassandra/pull/1619

Basically all patches go to 4.0 and higher.
For 3.11, I backported only the LongBufferPoolTest patch, because the other issues in the BufferPool are not present there (also 3.11 version of BufferPool is a lot simpler than 4.0).

;;;","11/May/22 16:49;benedict;[~pkolaczk] could you provide more clear justifications for your perceived bugs, and the resultant refactors, to guide review?

Which other threads do you think are accessing {{LocalPool.release()}} via what access path? The bugs you perceive seem to hinge on this eventuality, however I can see only two locations invoking {{LocalPool.release}}: {{LocalBufferPoolAllocator.release()}} and {{localPool.onRemoval}}. The former invokes on its own private pool, and has only single ownership semantics, and so should be fine. The latter should only be invoked when the thread is terminating? It could in principle be invoked at another time, but I do not think it is.

Chunks are released only via this path, or when there are no references to the chunk from application threads. So, if the above is fine this is likely also fine?

;;;","31/May/22 07:39;pkolaczk;[~benedict] it is all described in the commit message. It answers exactly your questions.

Quoting the relevant part of the commit message for your convenience:

1. LocalPool is meant to be managed by a single thread.
Unfortunately there was a code path that allowed
a thread enter the context of the LocalPool owned by another
thread by attempting to recycle a chunk using its
recycler reference. This led to a situation where unsynchronized
data structures were modified from multiple threads.
The patch ensures LocalPool state is modified by the owning thread
only.

The following sequence triggered the bug:
a) The app asks the BufferPool for a tiny chunk on Thread A.
We get the chunk from the thread local LocalPool A, we set
its recycler to the parent LocalPool and owner to its tinyPool.
b) Eventually the tiny chunk gets evicted. Now its owner is set
to null, but the chunk is not free yet, so nothing more happens.
c) In the meantime buffer(s) of the tiny chunk get(s)
transferred to Thread B on the client side.
d) Eventually the client releases the last buffer of the tiny chunk
by calling BufferPool#put, but it does that on Thread B.
e) BufferPool grabs a reference to the thread local LocalPool B and
calls put on it. So far all correct. We are returning the buffer
to the LocalPool B, owned by Thread B.
f) First we call free to mark appropriate freeSlots of the chunk.
It is the last buffer, so all bits turn to ones (freeSlots == -1).
The chunk has been evicted, so its owner == null.
We're not the owner, so we don't need to remove the chunk from
the micro queue (no need because it is not there) and we can
give it back to the pool we got the chunk from.
So we call chunk.tryRecycle.
g) chunk.tryRecycle realizes freeSlots == -1, CAS succeeds,
now freeSlots == 0 and the chunk needs to be recycled.
h) chunk.recycle gets called and calls chunk.recycler.recycle()
underneath. But the chunk was allocated by thread A,
so chunk.recycler points to LocalPool A owned by Thread A.
Here we enter the context of the wrong thread!
i) chunk.recycler.recycle() gets the parent chunk and its slab
and calls put again. Notice we're calling put the second time now.
We're calling it on a LocalPool A, but we are still on Thread B.
Danger!
j) LocalPool A is the owner of chunk's slab we got the buffer
from in step b). So owner == this.
k) Now, we're additionally unlucky, and it turns out this was
the last buffer of the normal chunk as well.
So we have free = 0 and owner == this, the first condition after
free is true, so we remove the chunk from the micro queue.
The micro queue is managed by Thread A, and we're
doing this on Thread B. Here we crash.

 

BTW: You will not see this path in cassandra-3.x branches, because the `recycler` thing and tinypool was added on cassandra-4.0. So the bug in the BufferPool applies to 4.0 only.

 

> Chunks are released only via this path, or when there are no references to the chunk from application threads

 

That holds only on 3.x.

In 4.x chunks may be released following the `recycler` reference, which doesn't guarantee pointing to the LocalPool of the current thread.;;;","31/May/22 08:02;benedict;Thank you, that explains the bug and I agree it is one. 

However, I believe there is a much simpler solution to this problem, which is to introduce an additional parameter to `put` that indicates if it has been invoked by the owning pool directly, and indicate this is not the case when invoked by the `Recycler` implementation in `LocalPool`. This can actually replace the `owner == this` test, and we can introduce a method overload that computes `owner == this` to pass to an `isOwner` parameter. This has the added benefit of not breaking use cases where a `BufferPool` may be (safely) shared between threads - not currently a problem, I don't think, but better to avoid surprises in future.;;;","31/May/22 08:23;pkolaczk;# How is that simpler than an internal check for currentThread? It adds a parameter to the public API of LocalPool and moves the burden of correctness on the caller.
 # It would make the code analysis harder - it is not immediately obvious the correct thread would touch the private non-synchronized stuff. In my patch it is obvious.
 # I expect the majority of buffers are returned by the same thread which allocated it. So if you disable recycling of buffers invoked from tinypool in all cases of indirect returns, it would be overly conservative.

BTW point 3 leads me to thinking - do we even really need it that much to recycle at all when we notice an owned buffer is completely free? Why not keep it for future allocations from that thread? I can imagine eager recycling could get us in some pathological edge-case performance problem if the caller requests just one buffer, returns it, requests another, returns etc. In this case such buffer would constantly travel between the GlobalPool and LocalPool which kinda defeats the purpose of local pools.

 ;;;","31/May/22 08:29;benedict;bq. How is that simpler than an internal check for currentThread? It adds a parameter to the public API of LocalPool and moves the burden of correctness on the caller.

Because we do not modify the logic in any other way, we just pass `isOwner`. The public API is not modified, it is entirely internal to `BufferPool`.

bq. It would make the code analysis harder - it is not immediately obvious the correct thread would touch the private non-synchronized stuff. In my patch it is obvious.

See above. Code analysis is simpler, as less is changed. I also disagree this makes it significantly more complex even from first principles, particularly if we suitably name the methods to make clear the semantics.

bq. I expect the majority of buffers are returned by the same thread which allocated it. So if you disable recycling of buffers invoked from tinypool in all cases of indirect returns, it looks overly conservative.

No, this would behave correctly as we would be invoking it on the tinyPool that we own, and so we would pass `isOwner = true`

bq. do we even really need it that much to recycle at all when we notice an owned buffer is completely free

Lazy recycling can introduce more pathological behaviour, particularly for `TinyPool` as we may have large allocations that have all been freed, and a single tiny slither in a number of tiny pools that prevent them from being released. If these are themselves part of mostly free _chunks_ we could end up exhausting our global pool entirely without any of it being in use.;;;","31/May/22 08:59;benedict;Hmm, we have another option of course which is to make `MicroQueueOfChunks` thread safe for this use case. If we remove `count` and simply read all three registers, so that we insert into the first null entry, this should work fine, as Thread B can only null these entries, which is entirely safe for Thread A (it will either see it, or not; the attempt to allocate will be correctly linearised and it would just remove it again, if still present). 

This potentially scopes the changes even more narrowly, logically at least.

That is to say, we permit only exclusive access for `add` but permit `removeIf` and `forEach` to be invoked by any thread safely.;;;","31/May/22 09:00;benedict;My goal here is to avoid significant changes to the logic of `BufferPool`, both to reduce the risk of the changes and also because I have been asked to review it, and I do not have the time.;;;","31/May/22 09:20;pkolaczk;> Code analysis is simpler, as less is changed. 

How adding a new parameter + modifying all callers is ""less change"" than a single `Thread.currentThread() == owningThread` check that is explicit and guaranteed to do the right thing?

The thread check was the only thing needed to correct for that particular problem described in point 1. 

Anyway, I'm fine as long as we still keep an `assert Thread.currentThread() == owningThread` in that place, to make it obvious and fail fast in case someone gets the boolean flag wrong.

The fact it was broken and multiple people didn't see it for many months already proves the property of ""only one thread can enter here"" is totally not obvious.

And now it would be even harder when we have one more parameter, because now the reader of the code would have to analyze all the callers who call put if they set this flag properly.

 

> The public API is not modified, it is entirely internal to `BufferPool`.

Technically you're right, but this is one of the main APIs of a major internal component, which in itself is quite complex and has many callers.

LocalPool's put is called from the main API of the BufferPool as well  as indirectly from chunks when they get recycled, including recursive call from other put (you can have put twice in a call trace). 

 

> No, this would behave correctly as we would be invoking it on the tinyPool that we own, and so we would pass `isOwner = true`

But what about the already evicted tiny buffers? Owner == null for those.

 

> Lazy recycling can introduce more pathological behaviour, particularly for `TinyPool` as we may have large allocations that have all been freed, and a single tiny slither in a number of tiny pools that prevent them from being released. If these are themselves part of mostly free _chunks_ we could end up exhausting our global pool entirely without any of it being in use.

Indeed, good point.;;;","31/May/22 09:23;pkolaczk;> Hmm, we have another option of course which is to make `MicroQueueOfChunks` thread safe for this use case.

 

I considered that, but then this gets us into a pandora box of Java memory model peculiarities. IMHO risky approach, and I actually like the ""only one thread owns this"" approach much better.;;;","31/May/22 09:27;benedict;bq. The thread check was the only thing needed to correct for that particular problem described in point 1.

If you want to submit a patch that modifies only this, I can review it simply. It retains the problem I mentioned before, of preventing an allocator being safely shared between threads, and it does so unnecessarily. But I'm fine with it.

bq. The fact it was broken and multiple people didn't see it for many months already proves the property of ""only one thread can enter here"" is totally not obvious.

The amount of time is sort of meaningless here, since nobody is looking at it. The problem here was that ownership was being calculated by the method itself; by calculating it in the caller we must consider at each call-site if this can be known, and if not propagate the parameter to the caller (until we do know). So, I think this adequately mitigates the risk.

bq. LocalPool's put is called from the main API of the BufferPool

I suggested overloading this method, so the overload with the additional method can be made private to indicate it is not a part of the ""main API"" (although this is all internal to the class, so this is only communicative to the reader)

bq. But what about the already evicted tiny buffers? Owner == null for those.

Good point. Perhaps my proposal of making `MicroQueueOfChunks` thread-safe is superior, then, so that we may in fact recycle these in all cases and avoid more pathological situations if tiny buffers are shared between threads?

;;;","31/May/22 09:32;pkolaczk;> My goal here is to avoid significant changes to the logic of `BufferPool`, both to reduce the risk of the changes and also because I have been asked to review it, and I do not have the time.

 

Fair enough, but the problem 1. was not the *only* problem. Actually after fixing it, some other things popped up. For example there was another race condition related to marking chunks evicted. Which led to a slightly bigger refactor how partial recycling is handled; because partial recycling relies on proper chunk statuses.;;;","31/May/22 09:33;benedict;bq. I considered that, but then this gets us into a pandora box of Java memory model peculiarities.

What JMM peculiarities are you worried about? We would just need to ensure that every method invoke by `removeIf` was itself thread-safe, which they are but we might want to annotate them and comment that they must be idempotent. We would also need to be certain the `Chunk` are themselves safe-published, but since all their member-fields are final or volatile this is already true as well.

That said, if most of the refactors you introduced were not necessary to fix these concerns I would be happy with simply reducing the scope of changes to those strictly necessary to fix the issue.;;;","31/May/22 09:34;benedict;bq. Actually after fixing it, some other things popped up. For example there was another race condition related to marking chunks evicted. 

Hmm, ok. Well that scuppers that plan, then.;;;","31/May/22 09:53;benedict;So, the remaining bugs are unfamiliar to me as I wasn't involved in introducing the {{status}} logic. [~aleksey] perhaps you might be able to take a look at this, since you reviewed the patch that introduced it?

I will take a look anyway, since this code is fairly important, but I don't know I will have time to familiarise myself with it all adequately for a sufficiently confident review.;;;","31/May/22 09:55;benedict;Also, [~pkolaczk], apologies - I see your earlier commit message is very thorough, explaining these details. I only saw the later commit message in GitHub, which was itself very detailed but did not outline all of the bugs or the precipitating scenario to the above bug.;;;","31/May/22 10:00;pkolaczk;> The amount of time is sort of meaningless here, since nobody is looking at it. 

I was referring to a few people to whom I showed the bug initially by saying ""here, I have the evidence the MicroQueueOfChunks is being accessed from multiple threads"" and the response was:

""how so? I looked at the code and it looks correct"".

For example here:

>  I can see only two locations invoking {{{}LocalPool.release{}}}: {{LocalBufferPoolAllocator.release()}} and {{{}localPool.onRemoval{}}}. The former invokes on its own private pool, and has only single ownership semantics, and so should be fine. The latter should only be invoked when the thread is terminating? It could in principle be invoked at another time, but I do not think it is. Chunks are released only via this path, or when there are no references to the chunk from application threads. So, if the above is fine this is likely also fine?

;)

And BTW, that was also *my* initial reaction when I saw the exceptions for the first time and required many days until we figured this out. Hence I conclude, it was far from obvious and I wanted to make the code a bit more explicit so the next time noone has to figure this out again.

Anyway, let me get some time to split this patch into just the essential part and the nice-to-have cosmetic / simplification parts, because indeed maybe some stuff could be left out.;;;","31/May/22 10:08;pkolaczk;> What JMM peculiarities are you worried about?

The fact this is a non-atomic data structure that supports both writes and reads already puts it in territory of ""lockless concurrent data structures"", which is by definition hard and risky.

E.g. this structure has a counter of non-null fields. When either adding or removing it updates the fields and updates the counter. How do you ensure the other threads see a consistent state? Not sure, but I'm afraid at least some CAS would be needed somewhere. 

I'm not saying it cannot be done, but IMHO keeping LocalPool really thread local avoids a lot of complexity. 

 ;;;","31/May/22 10:23;benedict;bq. E.g. this structure has a counter of non-null fields. When either adding or removing it updates the fields and updates the counter. How do you ensure the other threads see a consistent state? Not sure, but I'm afraid at least some CAS would be needed somewhere.

I was proposing removing the count entirely, as it is a minor optimisation. Simply use the three fields and their null/non-null status. The owning thread is only permitted to set to non-null (and assures safe publication), and the other threads may only set to null, and may either only do so if they have taken ownership of the act, by first transitioning -1 -> 0, or perhaps would do so using CAS (whereas the owning thread could perhaps do so with e.g. {{putOrdered}} )

This at least is a very narrow piece of code to analyse, which is probably safer than modifying the `BufferPool` which appears to have grown too complex since it was first introduced. Some time in future, we should consider refactoring more fully, to perhaps distinguish the `LocalPool` and `TinyPool` concepts more fully so that we do not make this kind of mistake, as the behaviour is subtly different between the two, and it is easy to forget this and fail to account for the special-casing.

Still, you have indicated that this wouldn't materially simplify the patch (indeed, it sounds like it would make it more complicated), so I agree that's a waste of time.;;;","31/May/22 11:17;pkolaczk;> I was proposing removing the count entirely, as it is a minor optimisation. Simply use the three fields and their null/non-null status.

I agree, this makes sense as well. So that's actually not that complex as I initially thought. The fact we have a fixed number of items (3) and if we remove the counter, we could allow ""add from one thread, remove from any"" and probably even volatile would be enough.

Well, now I actually like this idea, and you seem to have (almost) convinced me. :)

There is also some nice symmetry with chunks, which can also only be allocated from by a single thread, yet any thread can return buffers to them.

One minor concern is though, that what about eviction racing with recycle. I mean, the owner evicts a chunk and at the same time the application returns the last buffer into that chunk and triggers recycling (on another thread). I guess one must be careful with first nulling the owner and then removing from the queue to prevent this....

Anyway, that's slightly more complex than the isOwner param / thread check, so let's leave it for the future.

 

>  Some time in future, we should consider refactoring more fully, to perhaps distinguish the `LocalPool` and `TinyPool` concepts more fully so that we do not make this kind of mistake, as the behaviour is subtly different between the two, and it is easy to forget this and fail to account for the special-casing.

 

+1

 ;;;","31/May/22 11:27;benedict;Well, {{volatile}} by itself is probably insufficient, as we can have a race condition where all three chunks have been freed by another thread but not yet cleared from the queue, and the owning thread needs to clear an entry and insert a new one. So we either have to have a yield spin (in which case we don't even need {{volatile}}, we can use plain memory accesses), or we need to use CAS for clearing (which I marginally prefer, as I dislike yield spins, even if it comes at a cost of increased volatile usage)

;;;","09/Jun/22 14:07;pkolaczk;[~benedict] I have split the patch into smaller ones. Should be easier to review now. The biggest one are the changes related to chunk status and partial recycling, but the test doesn't pass without it, so they are needed.;;;","09/Jun/22 14:10;benedict;Thanks [~pkolaczk]. [~aleksey] has agreed to review that part, as he reviewed the initial patch the introduced it. Tagging him here so he can take a look now it's ready.;;;","10/Jun/22 11:23;aleksey;Cool, tagged self as a reviewer.;;;","01/Aug/22 18:16;aleksey;Have just noticed the Patch Available transition - will take a look soon.;;;","03/Oct/22 16:43;aleksey;First 6 out of 7 commits look good to me. Some nice catches there.

Almost done convincing myself that the changes in the very last commit - ""Fix and simplify chunk status management"" - is safe. Won't be long now, and my apologies for the delay again.;;;","05/Oct/22 11:25;aleksey;May I suggest that we only commit the first 6 out of 7 changes, without the simplification patch?

It’s not incorrect, it does address the (non-critical) issue of returning fully freed chunks to the partially recycled queue, but in my opinion it’s not definitively significantly simpler enough to justify.

It shifts some of the existing complexity to {{Chunk}} but the coupling with LP recycling logic remains effectively the same, and I’m not the biggest fan of {{recycleFully()}} essentially having to be aware of the call stack to decide which CAS to do.

Do you mind delaying further simplification until a further refactor, in a different ticket, that would also include a {{LocalPool}} refactor wrt handling of the tiny pool?

If you don’t mind, then I’m +1 to commit the initial 6 patches and consider the ticket resolved. Cheers.;;;","05/Oct/22 12:59;blerer;We have seen some memory leaks in production that could be related to threading issue that the fifth commit address. So I would love to see the 6 first commits being committed. They look good to me. I do not have a strong opinion for the last one but it might be because I ended up more familiar with the previous version of the code. In any case thanks a lot for your investigation [~pkolaczk]. It is some really nice work.;;;","07/Oct/22 07:16;pkolaczk;[~aleksey] I'm not sure if the the last patch didn't fix something actually. Let me try to rerun the test with only 6 changes and see if it works and I get back to you. There was simply many back-and-forth already on this and I don't remember exactly at the moment, but the fact that the original control flow didn't go through the same CAS could be a correctness issue, not just code style issue.

// edit:
Looking at the description, there was a race fixed there, not just code style:
{quote}
   2. When a chunk was evicted, it was first released and later marked as
       EVICTED. The actual order of operations with partial recycling
       enabled was as follows:
       a) release: clear owner -> tryRecycle -> try change status
          EVICTED to IN_USE (fail)
       b) change status to EVICTED
    
       This not only didn't really recycle the chunk, but could also race
       with an other thread trying to recycle the very same chunk and
       accidentally mark an already recycled chunk as EVICTED.
       The order has been fixed and now chunk is marked as evicted before
       attempting to recycle it.

{quote};;;","07/Oct/22 07:40;pkolaczk;The `testPoolAllocateWithRecyclePartially` fails quite reliably  if I exclude the last patch:

{noformat}
INFO  [main] 2022-10-07 09:31:39,811 LongBufferPoolTest.java:329 - 2022/10/07 09:31:39 - testing 16 threads for 2m
INFO  [main] 2022-10-07 09:31:39,811 LongBufferPoolTest.java:330 - Testing BufferPool with memoryUsageThreshold=16777216 and enabling BufferPool.DEBUG
INFO  [test:5] 2022-10-07 09:31:39,829 NoSpamLogger.java:92 - Maximum memory usage reached (16,000MiB), cannot allocate chunk of 8,000MiB

java.lang.AssertionError: Last recycled 5 < last acquired 6
	at org.apache.cassandra.utils.memory.LongBufferPoolTest$Debug.check(LongBufferPoolTest.java:122)
	at org.apache.cassandra.utils.memory.LongBufferPoolTest.testAllocate(LongBufferPoolTest.java:353)
	at org.apache.cassandra.utils.memory.LongBufferPoolTest.testPoolAllocate(LongBufferPoolTest.java:159)
	at org.apache.cassandra.utils.memory.LongBufferPoolTest.testPoolAllocateWithRecyclePartially(LongBufferPoolTest.java:147)
{noformat}
 

The other test `testPoolAllocateWithoutRecyclePartially` works fine with only 6 patches.

So the 7-th patch fixes partial recycling. Not sure how serious this is - looks like some chunks would simply be not recycled, so that could cause a memory leak worst case? 


;;;","07/Oct/22 10:14;aleksey;Yep. That's why I've actually delayed that a bit and only committed the test fix so far. Not placing the recycled chunk in the optimal queue is a minor performance issue, but failing to recycle altogether is more serious than that.;;;","11/Oct/22 14:54;aleksey;Committed the test fix as dc2acba043c6978b32a9556e0d610251d5535ce6 to 3.11 and merged up (to 4.0, 4.1, and trunk (4.2)).

Committed the {{BufferPool}} fixes and improvements -verbatim - as e13356d75d2d3c200f1636337cf15329bd1b829b to 4.0 and merged up (to 4.1 and trunk (4.2)).

Thank you [~pkolaczk] for the great work and the patience.;;;"
TimeWindowCompactionStrategyTest flaky,CASSANDRA-16680,13379309,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,e.dimitrova,e.dimitrova,19/May/21 14:07,27/May/22 19:25,13/Jul/23 08:40,01/Jun/21 15:36,3.0.25,3.11.11,4.0-rc2,4.1,4.1-alpha1,,,CI,,,,0,,,"Seen in Jenkins:

https://ci-cassandra.apache.org/job/Cassandra-devbranch/785/

Failed two times with the multiplexer 

[https://app.circleci.com/pipelines/github/adelapena/cassandra/461/workflows/7a837b82-c0d1-4e10-8932-c5908d2585de/jobs/4114]",,adelapena,e.dimitrova,,,,,,,,,,,,,,"adelapena opened a new pull request #1026:
URL: https://github.com/apache/cassandra/pull/1026


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/May/21 14:14;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #1026:
URL: https://github.com/apache/cassandra/pull/1026#discussion_r640889614



##########
File path: test/unit/org/apache/cassandra/db/compaction/TimeWindowCompactionStrategyTest.java
##########
@@ -253,37 +256,39 @@ public void testDropExpiredSSTables() throws InterruptedException
 
         ByteBuffer value = ByteBuffer.wrap(new byte[100]);
 
-        // create 2 sstables
-        DecoratedKey key = Util.dk(String.valueOf(""expired""));
-        new RowUpdateBuilder(cfs.metadata(), System.currentTimeMillis(), 1, key.getKey())
+        // Create a expiring sstable with a TTL
+        DecoratedKey key = Util.dk(""expired"");
+        new RowUpdateBuilder(cfs.metadata(), System.currentTimeMillis(), TTL_SECONDS, key.getKey())
             .clustering(""column"")
             .add(""val"", value).build().applyUnsafe();
-
         cfs.forceBlockingFlush();
         SSTableReader expiredSSTable = cfs.getLiveSSTables().iterator().next();
         Thread.sleep(10);
 
-        key = Util.dk(String.valueOf(""nonexpired""));
+        // Create a second sstable without TTL
+        key = Util.dk(""nonexpired"");
         new RowUpdateBuilder(cfs.metadata(), System.currentTimeMillis(), key.getKey())
             .clustering(""column"")
             .add(""val"", value).build().applyUnsafe();
-

Review comment:
       Not a big deal, but I would keep this line probably, for readability. I will leave it up to you

##########
File path: test/unit/org/apache/cassandra/db/compaction/TimeWindowCompactionStrategyTest.java
##########
@@ -253,37 +256,39 @@ public void testDropExpiredSSTables() throws InterruptedException
 
         ByteBuffer value = ByteBuffer.wrap(new byte[100]);
 
-        // create 2 sstables
-        DecoratedKey key = Util.dk(String.valueOf(""expired""));
-        new RowUpdateBuilder(cfs.metadata(), System.currentTimeMillis(), 1, key.getKey())
+        // Create a expiring sstable with a TTL
+        DecoratedKey key = Util.dk(""expired"");
+        new RowUpdateBuilder(cfs.metadata(), System.currentTimeMillis(), TTL_SECONDS, key.getKey())
             .clustering(""column"")
             .add(""val"", value).build().applyUnsafe();
-
         cfs.forceBlockingFlush();
         SSTableReader expiredSSTable = cfs.getLiveSSTables().iterator().next();
         Thread.sleep(10);
 
-        key = Util.dk(String.valueOf(""nonexpired""));
+        // Create a second sstable without TTL
+        key = Util.dk(""nonexpired"");
         new RowUpdateBuilder(cfs.metadata(), System.currentTimeMillis(), key.getKey())
             .clustering(""column"")
             .add(""val"", value).build().applyUnsafe();
-
         cfs.forceBlockingFlush();
+
         assertEquals(cfs.getLiveSSTables().size(), 2);
 
         Map<String, String> options = new HashMap<>();
-
         options.put(TimeWindowCompactionStrategyOptions.COMPACTION_WINDOW_SIZE_KEY, ""30"");
         options.put(TimeWindowCompactionStrategyOptions.COMPACTION_WINDOW_UNIT_KEY, ""SECONDS"");
         options.put(TimeWindowCompactionStrategyOptions.TIMESTAMP_RESOLUTION_KEY, ""MILLISECONDS"");
         options.put(TimeWindowCompactionStrategyOptions.EXPIRED_SSTABLE_CHECK_FREQUENCY_SECONDS_KEY, ""0"");
         TimeWindowCompactionStrategy twcs = new TimeWindowCompactionStrategy(cfs, options);
         for (SSTableReader sstable : cfs.getLiveSSTables())
             twcs.addSSTable(sstable);
+
         twcs.startup();
-        assertNull(twcs.getNextBackgroundTask((int) (System.currentTimeMillis() / 1000)));
-        Thread.sleep(2000);
-        AbstractCompactionTask t = twcs.getNextBackgroundTask((int) (System.currentTimeMillis()/1000));
+        assertNull(twcs.getNextBackgroundTask(nowInSeconds()));
+
+        // wait for the expiration of the first sstable

Review comment:
       wait with capital letter, just mentioning because I saw you corrected it before :-) 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/May/21 19:01;githubbot;600","adelapena opened a new pull request #1032:
URL: https://github.com/apache/cassandra/pull/1032


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 12:51;githubbot;600","adelapena opened a new pull request #1033:
URL: https://github.com/apache/cassandra/pull/1033


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 12:51;githubbot;600","adelapena opened a new pull request #1034:
URL: https://github.com/apache/cassandra/pull/1034


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 12:52;githubbot;600","adelapena closed pull request #1032:
URL: https://github.com/apache/cassandra/pull/1032


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 15:36;githubbot;600","adelapena closed pull request #1034:
URL: https://github.com/apache/cassandra/pull/1034


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 15:36;githubbot;600","adelapena closed pull request #1033:
URL: https://github.com/apache/cassandra/pull/1033


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 15:36;githubbot;600","adelapena closed pull request #1026:
URL: https://github.com/apache/cassandra/pull/1026


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 15:36;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,5400,,,0,5400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Degradation,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Jun 01 15:33:33 UTC 2021,,,,,,,All,,,,"0|z0r6hs:",9223372036854775807,,,,e.dimitrova,,,,Normal,,3.0.8,,https://github.com/apache/cassandra/commit/844c8b03482d5cd7b8faac04d2e7a95694bd52a6,,,,,,,,,The fixed flaky test has survived 10K runs in the CircleCI test multiplexer,,,,,"27/May/21 14:42;adelapena;I think there are two separate causes for the failures.

One is that both [{{testDropExpiredSSTables}}|https://github.com/apache/cassandra/blob/ce877cbe2b7c11355b07cac6f1996a9c9006d89f/test/unit/org/apache/cassandra/db/compaction/TimeWindowCompactionStrategyTest.java#L258] and [{{testDropOverlappingExpiredSSTables}}|https://github.com/apache/cassandra/blob/ce877cbe2b7c11355b07cac6f1996a9c9006d89f/test/unit/org/apache/cassandra/db/compaction/TimeWindowCompactionStrategyTest.java#L306] create an expiring table with a TTL of one second and then they verify the next compaction task, assuming that the TTL hasn't expired yet ([here|https://github.com/apache/cassandra/blob/ce877cbe2b7c11355b07cac6f1996a9c9006d89f/test/unit/org/apache/cassandra/db/compaction/TimeWindowCompactionStrategyTest.java#L306] and [here|https://github.com/apache/cassandra/blob/ce877cbe2b7c11355b07cac6f1996a9c9006d89f/test/unit/org/apache/cassandra/db/compaction/TimeWindowCompactionStrategyTest.java#L336-L338]). In a slow CI run that check can happen after the TTL of one second has expired, so the assert will fail. The proposed PR [simply uses an TTL of 10 seconds|https://github.com/apache/cassandra/pull/1026/commits/1504474dc3453905558766ba44c05802eeb06635], which seems long enough to survive 10K multiplexer runs. It would be ideal to change the test to not be based on sleeps, but I'm afraid that would require some refactoring out of the test, and I'm not sure we want to do that at this point.

The second problem happens when [{{testDropOverlappingExpiredSSTables}}|https://github.com/apache/cassandra/blob/ce877cbe2b7c11355b07cac6f1996a9c9006d89f/test/unit/org/apache/cassandra/db/compaction/TimeWindowCompactionStrategyTest.java#L314] creates a sstable with a TTLed row, and a second sstable with another version of the same row without TTL and with and older timestamp. The intention is that the TTLed row should supersede the non-TTLed row. The problem is that the timestamps assigned to each row are based on separated calls to {{System.currentTimeMillis()}}, in such a way that a slow run can produce the opposite ordering of timestamps, so the non-TTLed row supersedes the TTLed one. The proposed solution is making the values of both timestamps based on the same call to {{System.currentTimeMillis()}}, as it's done [here|https://github.com/apache/cassandra/pull/1026/commits/ad602fa02135be6a1a43e6fe4dd87c9915885f66].

The PR also includes some minor cosmetic changes and fixes for typos and IDE warnings, in [this commit|https://github.com/apache/cassandra/pull/1026/commits/9d80053e5053f23a3eade9f294dd1fd2436d96c0].

The test has passed 10K multiplexer runs with [j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/515/workflows/e22d1a2f-bdc9-4bbb-a8d0-f2302bf406fd] and [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/515/workflows/2fa6965f-b5f1-4897-b3c0-186a6aa9f530].;;;","27/May/21 19:03;e.dimitrova;Thank you, [~adelapena], the fixes look good to me. Also, thank you for taking care about warnings and formatting. Plus, it was great you split those things in separate commits!;;;","01/Jun/21 14:17;adelapena;CI results for all branches, with 1000 multiplexer runs:
 * 3.0 [j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/531/workflows/e354f82f-9c51-42bd-bcb2-2d4b0f89b433]
 * 3.11 [j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/532/workflows/5a62fe8b-e3df-4b4f-a04f-62258d482ed6]
 * 4.0 [j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/527/workflows/588898aa-85be-4653-a901-0ddca1ae303f] and [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/527/workflows/750ee932-e3d4-4edd-9030-8547539f0edb]
 * trunk [j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/528/workflows/632ff752-e029-456e-9569-d0efb431973f] and [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/528/workflows/ab212979-1b8e-4d89-a435-7a70c36afadc];;;","01/Jun/21 15:33;adelapena;Committed to 3.0 as [844c8b03482d5cd7b8faac04d2e7a95694bd52a6|https://github.com/apache/cassandra/commit/844c8b03482d5cd7b8faac04d2e7a95694bd52a6] and merged up to [3.11|https://github.com/apache/cassandra/commit/a20913910574e290458d1875e86ce37bcf67c86f], [4.0|https://github.com/apache/cassandra/commit/2dcb454cafe1b9b2ad72ccaf94c7f799ce3797cb] and [trunk|https://github.com/apache/cassandra/commit/4697e119afa42fd6c25a79e1700b4443535e63ca].

Thanks for the review.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HintedHandoffAddRemoveNodesTest is failing,CASSANDRA-16679,13379308,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,maedhroz,e.dimitrova,e.dimitrova,19/May/21 14:01,07/Mar/23 10:38,13/Jul/23 08:40,07/Sep/22 21:08,4.0.x,4.1-beta1,5.0,,,,,CI,,,,0,,,"https://ci-cassandra.apache.org/job/Cassandra-devbranch/785/testReport/junit/org.apache.cassandra.distributed.test/HintedHandoffAddRemoveNodesTest/shouldStreamHintsDuringDecommission/

Java 8

[https://app.circleci.com/pipelines/github/adelapena/cassandra/464/workflows/888e47fb-e432-47f2-97df-c34a0d33753a/jobs/4104] 

and Java 11

 [https://app.circleci.com/pipelines/github/adelapena/cassandra/464/workflows/ce0f0690-e488-4b5b-ab82-ce92a2f336d8/jobs/4105]",,e.dimitrova,maedhroz,,,,,,,,,,,,,,"maedhroz opened a new pull request, #1838:
URL: https://github.com/apache/cassandra/pull/1838

   patch by Caleb Rackliffe; reviewed by ? for CASSANDRA-16679


;02/Sep/22 05:08;githubbot;600","maedhroz commented on PR #1838:
URL: https://github.com/apache/cassandra/pull/1838#issuecomment-1235071934

   https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16679-4.0


;02/Sep/22 05:09;githubbot;600","maedhroz opened a new pull request, #1842:
URL: https://github.com/apache/cassandra/pull/1842

   patch by Caleb Rackliffe; reviewed by ? for [CASSANDRA-16679](https://issues.apache.org/jira/browse/CASSANDRA-16679)


;02/Sep/22 17:17;githubbot;600","maedhroz commented on PR #1842:
URL: https://github.com/apache/cassandra/pull/1842#issuecomment-1235739940

   https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16679-4.1


;02/Sep/22 17:18;githubbot;600","maedhroz commented on PR #1843:
URL: https://github.com/apache/cassandra/pull/1843#issuecomment-1235870815

   https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16679-trunk


;02/Sep/22 20:26;githubbot;600","maedhroz commented on PR #1843:
URL: https://github.com/apache/cassandra/pull/1843#issuecomment-1239886202

   Committed in https://github.com/apache/cassandra/commit/97a5ff9925802c81e22dc38a6bf58e8835b2c20a


;07/Sep/22 21:09;githubbot;600","maedhroz closed pull request #1843: CASSANDRA-16679 HintedHandoffAddRemoveNodesTest now accounts for the fact that StorageMetrics.totalHints is not updated synchronously w/ writes
URL: https://github.com/apache/cassandra/pull/1843


;07/Sep/22 21:09;githubbot;600","maedhroz commented on PR #1842:
URL: https://github.com/apache/cassandra/pull/1842#issuecomment-1239886883

   Committed in https://github.com/apache/cassandra/commit/adb01284852a6c7943f7038dcee3cae101f47d23


;07/Sep/22 21:10;githubbot;600","maedhroz closed pull request #1842: CASSANDRA-16679 HintedHandoffAddRemoveNodesTest now accounts for the fact that StorageMetrics.totalHints is not updated synchronously w/ writes
URL: https://github.com/apache/cassandra/pull/1842


;07/Sep/22 21:10;githubbot;600","maedhroz commented on PR #1838:
URL: https://github.com/apache/cassandra/pull/1838#issuecomment-1239887258

   Committed in https://github.com/apache/cassandra/commit/c56952efb570df2b09a7d428319a9b7755a0c387


;07/Sep/22 21:10;githubbot;600","maedhroz closed pull request #1838: CASSANDRA-16679 HintedHandoffAddRemoveNodesTest now accounts for the fact that StorageMetrics.totalHints is not updated synchronously w/ writes
URL: https://github.com/apache/cassandra/pull/1838


;07/Sep/22 21:10;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,6600,,,0,6600,,,,,,,,,,,,,,,,,,,CASSANDRA-17808,,,,,,,,,,,,,,,,,,,0.0,maedhroz,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Sep 07 21:08:54 UTC 2022,,,,,,,All,,,,"0|z0r6hk:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/c56952efb570df2b09a7d428319a9b7755a0c387,,,,,,,,,patch fixes existing test,,,,,"19/May/21 16:37;e.dimitrova;CC [~maedhroz] - just FYI;;;","19/May/21 19:31;e.dimitrova;First observations - this test fails only when  the whole class is run. Running on its own it succeeds 500 runs. Also, the original python DTest looks good in Jenkins. 

I am wondering whether it is not in-jvm issue. This reminds me of 
 CASSANDRA-16598
  where there is a suspicion that the node didn't really go down

//CC [~blerer] as he is tackling CASSANDRA-16598;;;","26/May/21 18:51;e.dimitrova;After experimenting more with this one I think this is probably some very tiny race around the  in-jvm tests framework.

If I remove node 4 never to get back up, I still can see in the logs of node 2 that node 4 goes down and then a connection is established between node 2 and node4 and node 4 is marked immediately up in the logs of node 2...

Then I looped the original python dtest 500 times and it succeeded. 

My suggestion is to fix this issue but not to block the release on it. [~ifesdjeen], [~blerer], [~maedhroz], any thoughts? 

 ;;;","26/May/21 19:30;e.dimitrova;Node 2:

 
{code:java}
INFO [node2_GossipStage:1] node2 2021-05-26 16:14:07,666 InetAddress /127.0.0.4:7012 is now DOWN
DEBUG [node2_GossipStage:1] node2 2021-05-26 16:14:07,667 Forcing conviction of /127.0.0.4:7012
INFO [node2_Messaging-EventLoop-3-7] node2 2021-05-26 16:14:07,673 /127.0.0.2:7012(/127.0.0.1:50938)->/127.0.0.4:7012-URGENT_MESSAGES-5627f198 successfully connected, version = 12, framing = CRC, encryption = unencrypted
DEBUG [node2_GossipStage:1] node2 2021-05-26 16:14:07,676 removing expire time for endpoint : /127.0.0.4:7012
INFO [node2_GossipStage:1] node2 2021-05-26 16:14:07,676 InetAddress /127.0.0.4:7012 is now UP
DEBUG [node2_GossipStage:1] node2 2021-05-26 16:14:07,676 removing expire time for endpoint : /127.0.0.4:7012
INFO [node2_GossipStage:1] node2 2021-05-26 16:14:07,676 InetAddress /127.0.0.4:7012 is now UP
{code}
 

 

This is from node 4:
{code:java}
INFO [node4_isolatedExecutor:3] node4 2021-05-26 16:14:07,660 Announcing shutdown
DEBUG [node4_isolatedExecutor:3] node4 2021-05-26 16:14:07,660 Node /127.0.0.4:7012 state shutdown, token [9223372036854775801]
INFO [node4_isolatedExecutor:6] node4 2021-05-26 16:14:07,660 Paused hints dispatch
INFO [node4_isolatedExecutor:3] node4 2021-05-26 16:14:07,660 Node /127.0.0.4:7012 state jump to shutdown
DEBUG [node4_isolatedExecutor:3] node4 2021-05-26 16:14:07,661 Node /127.0.0.4:7012 state shutdown, token [9223372036854775801]
INFO [node4_isolatedExecutor:3] node4 2021-05-26 16:14:07,661 Node /127.0.0.4:7012 state jump to shutdown
INFO [node4_Messaging-EventLoop-3-19] node4 2021-05-26 16:14:07,673 /127.0.0.2:7012(/127.0.0.1:50938)->/127.0.0.4:7012-URGENT_MESSAGES-e48b31a6 messaging connection established, version = 12, framing = CRC, encryption = unencrypted
INFO [node4_Messaging-EventLoop-3-20] node4 2021-05-26 16:14:08,604 /127.0.0.1:7012(/127.0.0.1:51090)->/127.0.0.4:7012-URGENT_MESSAGES-559580c8 messaging connection established, version = 12, framing = CRC, encryption = unencrypted
INFO [node4_isolatedExecutor:17] node4 2021-05-26 16:14:09,666 Waiting for messaging service to quiesce{code}
 ;;;","09/Jun/21 19:16;e.dimitrova;Until the in-jvm tests framework issue is solved I suggest [here |https://github.com/ekaterinadimitrova2/cassandra/commit/80122161d3723dea57db268e5d8f1332d084b365] we @Ignore the tests so we can have a clean CI view. The python DTests are still in place, completing successfully. [~brandon.williams], up for review/comment before I commit it? ;;;","09/Jun/21 19:25;brandon.williams;+1;;;","09/Jun/21 19:36;e.dimitrova;Committed, thanks

To https://github.com/apache/cassandra.git

   c7795ee62c..dfd5a0b4a5  cassandra-4.0 -> cassandra-4.0

   546792169e..e151fa5b89  cassandra-4.0.0 -> cassandra-4.0.0

   922872b38f..6c30261bc8  trunk -> trunk;;;","09/Jun/21 19:48;e.dimitrova;Removing myself from assignment in case someone else has cycles to look at it in the meanwhile;;;","02/Sep/22 02:47;maedhroz;I've created a branch [here|https://github.com/maedhroz/cassandra/commits/CASSANDRA-16679-unignore] that re-enables this test class and started a 300x repeat run of that class [here|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16679-unignore]. If there are no issues in that run, it would seem unlikely that the original issue persists, and that wouldn't be too strange, given recent changes to fix in-JVM test shutdown order, etc.

Also, I've made some small fixes that should make things more deterministic in CASSANDRA-17808, and there is already a successful 300x run on the books there. If the run above actually does surface failures, it's possible that these fixes matter, and this issue could be closed along w/ CASSANDRA-17808, at least for trunk. (I suppose we'd need to pull those changes down to 4.0 and 4.1 if they really matter.);;;","02/Sep/22 04:37;maedhroz;It looks like the fixes I made in my [17808 patch|https://github.com/apache/cassandra/pull/1835/files] address exactly the problem that was making this test flaky. The [multiplexer run|https://app.circleci.com/pipelines/github/maedhroz/cassandra/517/workflows/8e9b8fd1-d6bf-4aeb-8424-f48532ebd309/jobs/4728/tests#failed-test-0] on trunk with the tests un-ignored shows failures around the {{totalHints}} metric not being updated synchronously w/ the writes that generated them.;;;","02/Sep/22 20:30;maedhroz;|PR|
|[4.0|https://github.com/apache/cassandra/pull/1838]|
|[4.1|https://github.com/apache/cassandra/pull/1842]|
|[trunk|https://github.com/apache/cassandra/pull/1843]|

Note: PRs contain links to 300x multiplexer runs against the full {{HintedHandoffAddRemoveNodesTest}} suite.;;;","06/Sep/22 14:33;e.dimitrova;2 questions:

1) Do we need follow up ticket, does the issue with the immortal node still exists? I do not expect it to be fixed here but if it is still presented we will need to spin a new ticket. 

2) The original Python test does not suffer from this issue? I think it sounds suspicious, what do I miss?;;;","06/Sep/22 15:53;maedhroz;bq. 2) The original Python test does not suffer from this issue? I think it sounds suspicious, what do I miss?

The original Python dtest does not make any assertions around the hint-related metrics, so I wouldn't expect it to have the issue my patch addresses.;;;","06/Sep/22 16:27;maedhroz;[~e.dimitrova] I browsed the logs from one of the [4.0 multiplexer runs|https://output.circle-artifacts.com/output/job/972c7b84-f976-4756-a65b-8babccad5409/artifacts/0/logs/passes/01/org.apache.cassandra.distributed.test.HintedHandoffAddRemoveNodesTest/cluster-7b24809c-6a9c-428b-a3bd-9f9a4910a85d/node2/system.log] of the decommission hint delivery test.

(This is node 2...)

{noformat}
DEBUG [node2_GossipStage:1] node2 2022-09-02 05:16:36,208 Marked /127.0.0.4:7012 as shutdown
...
INFO  [node2_Messaging-EventLoop-3-3] node2 2022-09-02 05:16:41,798 /127.0.0.2:7012->/127.0.0.4:7012-URGENT_MESSAGES-[no-channel] failed to connect
io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /127.0.0.4:7012
Caused by: java.net.ConnectException: Connection refused
...
INFO  [node2_GossipStage:1] node2 2022-09-02 05:17:28,148 Node /127.0.0.4:7012 has restarted, now UP
{noformat}

The progression of things looks pretty normal, and if there *was* some issue with shutdown/startup for node 4, I would expect 1800+ runs across the three branches to expose it. In the end, I think the original failure report was so long ago that we should fix what appears to be the (reproducible on trunk, etc.) failure and open a new Jira if somehow this test ever gives us more problems;;;","06/Sep/22 20:24;e.dimitrova;{quote}The progression of things looks pretty normal, and if there *was* some issue with shutdown/startup for node 4, I would expect 1800+ runs across the three branches to expose it. In the end, I think the original failure report was so long ago that we should fix what appears to be the (reproducible on trunk, etc.) failure and open a new Jira if somehow this test ever gives us more problems
{quote}
Agreed, thanks for checking. You and David fixed a lot of things in the start/stop order for in-jvm tests framework so I guess this got fixed in time.
{quote}The original Python dtest does not make any assertions around the hint-related metrics, so I wouldn't expect it to have the issue my patch addresses.
{quote}
(y)

So now that we have already support for vnodes if we want to match the python dtests, _test_hintedhandoff_decom_ has a mark {_}no_vnode{_}, we need to do the same for the in-jvm version of the test (the original test was added before vnodes support for in-jvm framework was added)

The rest LGTM;;;","07/Sep/22 03:11;maedhroz;Thanks! I'll add that annotation and start getting ready to commit...;;;","07/Sep/22 21:08;maedhroz;Committed

4.0 - https://github.com/apache/cassandra/commit/c56952efb570df2b09a7d428319a9b7755a0c387

4.1 - https://github.com/apache/cassandra/commit/adb01284852a6c7943f7038dcee3cae101f47d23

trunk - https://github.com/apache/cassandra/commit/97a5ff9925802c81e22dc38a6bf58e8835b2c20a;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConnectionTest is flaky,CASSANDRA-16678,13379305,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,e.dimitrova,e.dimitrova,19/May/21 13:43,19/May/21 13:44,13/Jul/23 08:40,19/May/21 13:44,,,,,,,,Test/dtest/java,,,,0,,,"Failure observed: 

[https://ci-cassandra.apache.org/job/Cassandra-devbranch/785/testReport/junit/org.apache.cassandra.net/ConnectionTest/testMessageDeliveryOnReconnect_compression/]

 

3/100 failures in {{ConnectionTest observed in the new multiplexer, Java 8}}: [https://app.circleci.com/pipelines/github/adelapena/cassandra/460/workflows/cf7dcec6-612c-45d1-8471-623bde481dca/jobs/4069]

And 2/100 with Java 11: [https://app.circleci.com/pipelines/github/adelapena/cassandra/460/workflows/b750cd38-0263-4b5e-9bb8-a8be98214378/jobs/4065]",,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16677,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,2021-05-19 13:43:09.0,,,,,,,All,,,,"0|z0r6gw:",9223372036854775807,,,,,,,,Normal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Avoid race in AbstractReplicationStrategy endpoint caching,CASSANDRA-16673,13379013,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,18/May/21 11:45,27/May/22 19:25,13/Jul/23 08:40,17/Jan/22 13:20,3.0.26,3.11.12,4.0.2,4.1,4.1-alpha1,,,Cluster/Membership,,,,0,,,"We should make sure we track which ringVersion we are caching in AbstractReplicationStrategy to avoid a race where we might return the wrong EndpointsForRange.

{code}
Caused by: java.lang.IllegalArgumentException: 9010454139840013625 is not contained within (9223372036854775801,-4611686018427387905]
	at org.apache.cassandra.locator.EndpointsForRange.forToken(EndpointsForRange.java:59)
	at org.apache.cassandra.locator.AbstractReplicationStrategy.getNaturalReplicasForToken(AbstractReplicationStrategy.java:104)
	at org.apache.cassandra.locator.ReplicaLayout.forTokenReadLiveSorted(ReplicaLayout.java:330)
	at org.apache.cassandra.locator.ReplicaPlans.forRead(ReplicaPlans.java:594)
{code}",,ifesdjeen,jonmeredith,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Availability -> Unavailable,,,,,,,,Normal,Fuzz Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Jan 17 13:20:41 UTC 2022,,,,,,,All,,,,"0|z0r4o0:",9223372036854775807,,,,ifesdjeen,jonmeredith,,,Low,,3.0 alpha 1,,https://github.com/apache/cassandra/commit/b1a8a56c563b85ab9a34d3bbf9c16278dd441157,,,,,,,,,"new test, cci run",,,,,"18/May/21 11:51;marcuse;patch makes sure we don't overwrite endpoints calculated with an older ring version and that we don't return endpoints calculated with a newer ringversion after having calculated TokenMetadata.firstToken with an older TMD

https://github.com/krummas/cassandra/commits/marcuse/16673
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16673;;;","10/Sep/21 13:42;ifesdjeen;Sorry for taking so long to review this: issue has slipped under my radar, and I've only noticed it now.

+1 for the solution, just had two relatively minor comments that I have left on the [PR|https://github.com/apache/cassandra/pull/1195]. Please let me know what you think.;;;","27/Sep/21 14:03;marcuse;thanks for the review, pushed a commit with the fixes mentioned in the PR;;;","12/Oct/21 11:46;ifesdjeen;+1, thank you for the updates. I like the new state. I think we can avoid {{maybeClear}} in {{get}} because we'll remove {{null}} anyways, and in {{put}} - because we'll CAS on a newer version anyways. I don't mind to commit without this change though.;;;","13/Jan/22 17:49;jonmeredith;+1

There's still a pending nit about {{cloneWithNewPartitioner}} not copying the ring version, and up to you if you'd like to add the stress test as well [https://github.com/jonmeredith/cassandra/commit/349694482456b0bdbbd33cf2076b4c410a77cf78] (though the imports look like they need a cleanup)

Looks like this race has been here since natural endpoint caching was introduced - so fix from 3.0 and up?;;;","17/Jan/22 13:20;marcuse;committed, thanks!

test failures below look unrelated (bootstrap tests are fixed in CASSANDRA-17256)

[3.0|https://app.circleci.com/pipelines/github/krummas/cassandra/750/workflows/424ae7ef-5d44-4573-89cc-8f37c738d4d5]
[3.11|https://app.circleci.com/pipelines/github/krummas/cassandra/752/workflows/c55b24da-dae2-471c-8700-ddca1ae7eed4]
[4.0|https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16673&filter=all] (the failing MV test passes locally and on [jenkins|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch/1356/#showFailuresLink])
[trunk|https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16673-trunk&filter=all];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cassandra can return no row when the row columns have been deleted.,CASSANDRA-16671,13378842,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,blerer,blerer,17/May/21 15:22,14/Jun/21 07:26,13/Jul/23 08:40,11/Jun/21 09:33,3.0.25,3.11.11,4.0,4.0-rc2,,,,Legacy/Local Write-Read Paths,,,,0,,,"It is the semantic of CQL that a (CQL) row exists as long as it has one non-null column (including the PK columns).

To determine if a row has some *non-null primary key*, Cassandra relies on the row primary key liveness. 

For example:

{code}
CREATE TABLE test (pk int, ck int, v int, PRIMARY KEY(pk, ck));
INSERT INTO test(pk, ck, v) VALUES (1, 1, 1);
DELETE v FROM test WHERE pk = 1 AND ck = 1
SELECT v FROM test;
{code}
will return
{code}
v
---
null 
{code}

{{UPDATE}} statements do not set the row primary key liveness by consequence if the user had used an {{UPDATE}} statement instead of an {{INSERT}} the {{SELECT}} query would *not have returned any rows*.

CASSANDRA-16226 introduced a regression by stopping early in the timestamp ordered logic if an {{UPDATE}} statement covering all the columns was found in an SSTable. As the row returned did not have a primary key liveness if another node was also returning a column deletion, the expected row will not be returned.

The problem can be reproduced with the following test:
{code}
   @Test
    public void testSelectWithUpdatedColumnOnOneNodeAndColumnDeletionOnTheOther() throws Throwable
    {
        try (Cluster cluster = init(builder().withNodes(2).start()))
        {
            cluster.schemaChange(withKeyspace(""CREATE TABLE %s.tbl (pk int, ck text, v int, PRIMARY KEY (pk, ck))""));
            cluster.get(1).executeInternal(withKeyspace(""INSERT INTO %s.tbl (pk, ck, v) VALUES (1, '1', 1) USING TIMESTAMP 1000""));
            cluster.get(1).flush(KEYSPACE);
            cluster.get(1).executeInternal(withKeyspace(""UPDATE %s.tbl USING TIMESTAMP 2000 SET v = 2 WHERE pk = 1 AND ck = '1'""));
            cluster.get(1).flush(KEYSPACE);

            cluster.get(2).executeInternal(withKeyspace(""DELETE v FROM %s.tbl USING TIMESTAMP 3000 WHERE pk=1 AND ck='1'""));
            cluster.get(2).flush(KEYSPACE);

            assertRows(cluster.coordinator(2).execute(withKeyspace(""SELECT * FROM %s.tbl WHERE pk=1 AND ck='1'""), ConsistencyLevel.ALL),
                       row(1, ""1"", null)); // <-- FAIL
            assertRows(cluster.coordinator(2).execute(withKeyspace(""SELECT v FROM %s.tbl WHERE pk=1 AND ck='1'""), ConsistencyLevel.ALL),
                       row((Integer) null));

        }
    }
{code}

 cc: [~maedhroz], [~ifesdjeen]

",,aholmber,blerer,e.dimitrova,jeromatron,jjordan,maedhroz,mck,,,,,,,,,"blerer opened a new pull request #1030:
URL: https://github.com/apache/cassandra/pull/1030


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/May/21 16:03;githubbot;600","blerer opened a new pull request #1041:
URL: https://github.com/apache/cassandra/pull/1041


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 15:36;githubbot;600","blerer opened a new pull request #1042:
URL: https://github.com/apache/cassandra/pull/1042


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 15:40;githubbot;600","blerer opened a new pull request #1054:
URL: https://github.com/apache/cassandra/pull/1054


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 13:30;githubbot;600","maedhroz commented on a change in pull request #1041:
URL: https://github.com/apache/cassandra/pull/1041#discussion_r649432125



##########
File path: src/java/org/apache/cassandra/db/SinglePartitionReadCommand.java
##########
@@ -1049,26 +1047,20 @@ private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filte
      */
     private boolean isRowComplete(Row row, Columns requestedColumns, long sstableTimestamp)
     {
+

Review comment:
       nit: extra newline




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 18:38;githubbot;600","maedhroz commented on a change in pull request #1041:
URL: https://github.com/apache/cassandra/pull/1041#discussion_r649433126



##########
File path: test/distributed/org/apache/cassandra/distributed/test/SinglePartitionReadCommandTest.java
##########
@@ -0,0 +1,147 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import org.junit.Test;
+
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+
+import static org.apache.cassandra.distributed.shared.AssertUtils.assertRows;
+import static org.apache.cassandra.distributed.shared.AssertUtils.row;
+
+public class SinglePartitionReadCommandTest extends TestBaseImpl
+{
+    @Test
+    public void testNonCompactTableWithOnlyUpdatedColumnOnOneNodeAndColumnDeletionOnTheOther() throws Throwable
+    {
+        try (Cluster cluster = init(builder().withNodes(2).start()))
+        {
+            cluster.schemaChange(withKeyspace(""CREATE TABLE %s.tbl (pk int, ck text, v1 int, v2 int, PRIMARY KEY (pk, ck)) WITH dclocal_read_repair_chance=0""));
+            cluster.get(1).executeInternal(withKeyspace(""UPDATE %s.tbl USING TIMESTAMP 1000 SET v1 = 1, v2 = 2 WHERE pk = 1 AND ck = '1'""));
+            cluster.get(1).executeInternal(withKeyspace(""UPDATE %s.tbl USING TIMESTAMP 1001 SET v1 = 1, v2 = 2 WHERE pk = 2 AND ck = '1'""));
+            cluster.get(1).flush(KEYSPACE);
+
+            cluster.get(2).executeInternal(withKeyspace(""DELETE v1 FROM %s.tbl USING TIMESTAMP 2000 WHERE pk=1 AND ck='1'""));
+            cluster.get(2).executeInternal(withKeyspace(""DELETE v1 FROM %s.tbl USING TIMESTAMP 2001 WHERE pk=2 AND ck='1'""));
+            cluster.get(2).flush(KEYSPACE);
+            cluster.get(2).executeInternal(withKeyspace(""DELETE v2 FROM %s.tbl USING TIMESTAMP 3000 WHERE pk=2 AND ck='1'""));
+            cluster.get(2).flush(KEYSPACE);
+
+            assertRows(cluster.coordinator(2).execute(withKeyspace(""SELECT * FROM %s.tbl WHERE pk=1 AND ck='1'""), ConsistencyLevel.ALL),
+                       row(1, ""1"", null, 2));
+            assertRows(cluster.coordinator(2).execute(withKeyspace(""SELECT v1 FROM %s.tbl WHERE pk=1 AND ck='1'""), ConsistencyLevel.ALL),
+                       row((Integer) null));
+            assertRows(cluster.coordinator(2).execute(withKeyspace(""SELECT v2 FROM %s.tbl WHERE pk=1 AND ck='1'""), ConsistencyLevel.ALL),
+                       row((Integer) 2));

Review comment:
       nit: Not a big deal, but there are some unnecessary `Integer` casts scattered across these two test classes.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 18:39;githubbot;600","blerer commented on pull request #1041:
URL: https://github.com/apache/cassandra/pull/1041#issuecomment-859668436


   Merged manually


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:14;githubbot;600","blerer closed pull request #1041:
URL: https://github.com/apache/cassandra/pull/1041


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:15;githubbot;600","blerer closed pull request #1042:
URL: https://github.com/apache/cassandra/pull/1042


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:15;githubbot;600","blerer commented on pull request #1054:
URL: https://github.com/apache/cassandra/pull/1054#issuecomment-859667915


   Merged manually


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:16;githubbot;600","blerer closed pull request #1054:
URL: https://github.com/apache/cassandra/pull/1054


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:18;githubbot;600","blerer commented on pull request #1042:
URL: https://github.com/apache/cassandra/pull/1042#issuecomment-859668770


   Merged manually


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:26;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,7200,,,0,7200,,,,,,,,,,,,,CASSANDRA-16226,,,,,,CASSANDRA-16675,CASSANDRA-16686,CASSANDRA-16712,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jun 11 09:33:42 UTC 2021,,,,,,,All,,,,"0|z0r3m0:",9223372036854775807,,,,maedhroz,,,,Normal,,3.11.10,,https://github.com/apache/cassandra/commit/24346d17899df8610a5f425c7074ddd5dc8082bb,,,,,,,,,The patches add several extra unit tests and in-jvm dtests,,,,,"17/May/21 17:21;maedhroz;The simplest way to revert this logic in a way that doesn't completely obliterate the fixes for the regressions in compact table query performance CASSANDRA-16226 was intended to address would probably be the original patch for that issue: https://github.com/apache/cassandra/pull/789/files. This simply doesn't account for the related regression in query performance that might result from subsequently dropping compact storage on the table (see https://issues.apache.org/jira/browse/CASSANDRA-16226?focusedCommentId=17221593&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17221593.);;;","17/May/21 20:20;maedhroz;[~blerer] I've had a chance to read back through this, and to page back into my brain the entire conversation around CASSANDRA-16226. Right now, the logic in {{SPRC#isRowComplete()}} essentially chooses to preserve read performance (for tables that transition from using compact storage to dropping it) at the cost of maintaining the CQL treatment of empty rows in result sets. (This was even [documented|https://cassandra.apache.org/doc/latest/cql/appendices.html#appendix-c-dropping-compact-storage] as part of the change.) In other words, a CQL table can return empty rows the way a compact table would have. For applications used to handling empty rows that way (i.e. applications written when the table was initially compact), this probably isn't such a burden. What's not ideal is the behavior reported above, where a table that has never been compact does this.

It would still be nice to try to avoid having to write extra metadata at the SSTable level, a format version bump, etc. What if, instead of that path, we just record in a system table (and pull into {{TableMetadata}}) the time when DROP COMPACT STORAGE is executed. If a time exists for that table, we can treat it as being formerly compact, and leave the CASSANDRA-16226 logic essentially the same. However, if there is no drop time, and a table is currently not compact, we can assume the table has always been non-compact, and reintroduce the short circuit test in {{SPRC#isRowComplete()}} that would avoid the issue reported here:

{noformat}
if (row.primaryKeyLivenessInfo().isEmpty() || row.primaryKeyLivenessInfo().timestamp() <= sstableTimestamp)
    return false;
{noformat}

This would put us in a situation where we would only persist in allowing the pre-CQL representation of empty rows when we have truly ambiguous data on disk (i.e. rows in SSTables written before DROP CS where we have no idea whether they got there via UPDATE or INSERT).;;;","18/May/21 11:04;blerer;{quote}It would still be nice to try to avoid having to write extra metadata at the SSTable level, a format version bump, etc.{quote}

CASSANDRA-16619 introduce a new format version and it has not been released yet. So, introducing a new flag right now should not be an issue.

Both approach: storing the drop compact timestamp in the {{TableSchema}} and comparing it to the SSTables {{maxDataAge}} or looking at an {{isCompact}} flag in the SSTable metadata should work in my opinion.

Having some sort of flag in the {{TableSchema}} like the drop compact timestamp might prove itself more useful than the information at the SSTable level for fixing the other issues that exists currently with {{DROP COMPACT STORAGE}}. So, I would probably go this way.

Considering the fact that {{DROP COMPACT STORAGE}} is far from being production ready and that fixing its performance issue require some specific changes, we should probably try to fix it in a different ticket. What do you think?
;;;","18/May/21 15:28;maedhroz;Summary of a chat w/ [~blerer]...

1.) We'll make the minimal change in this Jira to preserve the never-compact/CQL empty row behavior, which is likely just the [original solution|https://github.com/apache/cassandra/pull/789/files] for 16226. In addition, I'd suggest we simply disable DROP COMPACT STORAGE by default (with a runtime-configurable override on {{StorageProxyMBean}}) for now if we really don't think it's production ready, for the possible performance regression issues outlined above...or any other reason.

2.) I'll create a follow-up issue, preferably just for 4.0.x, that addresses the [TableMetadata-based solution|https://issues.apache.org/jira/browse/CASSANDRA-16671?focusedCommentId=17346419&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17346419] described above, which seems like the least invasive way to arrive at the behavior we want in almost every case. (UPDATE: See CASSANDRA-16675);;;","10/Jun/21 13:33;blerer;|| Branches || CI ||
| [3.0|https://github.com/apache/cassandra/pull/1041] | [J8|https://app.circleci.com/pipelines/github/blerer/cassandra/141/workflows/78828f57-1f7e-48ec-ba86-09fe2c20b008] |
| [3.11|https://github.com/apache/cassandra/pull/1042] | [J8|https://app.circleci.com/pipelines/github/blerer/cassandra/142/workflows/317e57ec-70bf-4a9e-a7cd-42ae88457698] |
| [4.0|https://github.com/apache/cassandra/pull/1054] | [J8|https://app.circleci.com/pipelines/github/blerer/cassandra/144/workflows/a853b951-e115-4648-9f1e-713de142ca4a] [J11|https://app.circleci.com/pipelines/github/blerer/cassandra/144/workflows/c459c1b3-697d-43d3-958a-dd32b4d37dae] |

[~maedhroz] The patch is the one that you suggested. The patch simply add extra tests on top of that. Those test lead me to discover CASSANDRA-16712 and CASSANDRA-16686   ;;;","10/Jun/21 19:07;maedhroz;All three branches LGTM. (Dropped a couple inconsequential nits in [the 3.0 PR|https://github.com/apache/cassandra/pull/1041].)

Thanks for the additional test coverage!;;;","11/Jun/21 09:05;blerer;[~maedhroz] thanks for the fast review. 
Sorry, I missed the nits in 3.0 :-(
I have a followup patch that will touch this area on 3.0. I will incorporate them in it.  ;;;","11/Jun/21 09:33;blerer;Committed into 3.0 at 24346d17899df8610a5f425c7074ddd5dc8082bb and merged into 3.11, 4.0.0, 4.0 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Flaky ViewComplexTest, ViewFilteringTest and InsertUpdateIfConditionTest",CASSANDRA-16670,13378783,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,17/May/21 10:38,02/Sep/22 05:01,13/Jul/23 08:40,04/Jun/21 04:27,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/unit,,,,0,,,"*ViewComplexTest*

Flaky [test|https://ci-cassandra.apache.org/job/Cassandra-4.0/43/testReport/junit/org.apache.cassandra.cql3/ViewComplexTest/testPartialDeleteSelectedColumnWithoutFlush_3_/] and move back away from 'long' section.

*InsertUpdateIfConditionTest* (CASSANDRA-16676)

Fails [here|https://ci-cassandra.apache.org/job/Cassandra-4.0/46/testReport/junit/org.apache.cassandra.cql3.validation.operations/InsertUpdateIfConditionTest/testListItem_2__clusterMinVersion_4_0_0_rc2_SNAPSHOT_/] with a timeout. We can see in the history it takes quite a while in [CI|https://ci-cassandra.apache.org/job/Cassandra-4.0/46/testReport/junit/org.apache.cassandra.cql3.validation.operations/InsertUpdateIfConditionTest/history/] _but_ it takes just 1m locally. Probably due to constrained resources. Looking at the [individual|https://ci-cassandra.apache.org/job/Cassandra-4.0/46/testReport/junit/org.apache.cassandra.cql3.validation.operations/InsertUpdateIfConditionTest/] test cases, for compression i.e., we can see 378 at an average of 1s each it can easily go over the timeout of 240s. Recommendation is to either move to 'long' section of to raise the timeout for the class for CI.

*ViewFilteringTest*

Move back from 'long' section
",,bereng,e.dimitrova,jaid,jeromatron,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16711,,,CASSANDRA-16676,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Sep 02 05:01:41 UTC 2022,,,,,,,All,,,,"0|z0r38w:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0,,https://github.com/apache/cassandra/commit/6ad259238d82d7fe752eff6373d55bd225d8c630,,,,,,,,,See PR,,,,,"17/May/21 10:57;bereng;[~edimitrova] I see you played with this test. Probably this is the one you recently referred to as having to have to move to the 'long' section. It does almost timeout for me locally on my laptop and the stdout seems to be around the 10m timeout for the long tests which makes sense.

I have put up a proposal to raise only the timeout of this class but you know this test better than me. Wdyt?;;;","19/May/21 02:46;e.dimitrova;Same old Jenkins bugs.... when you open everything has passed, no failures. :( 
{quote}Probably this is the one you recently referred to as having to have to move to the 'long' section
{quote}
Yes, this is one of the two unit test classes I moved. The reason was that they are parameterized and there is no easy way to raise the timeout only per class. Check also this [discussion|https://the-asf.slack.com/archives/CK23JSY2K/p1620402158398900] for reference. 

So I guess if this is again borderline (wasn't the case when I ran it in a loop locally :( ), we should split the class instead of being parameterized. I can look at it tomorrow with fresh eyes as it is already 10.30 pm now.;;;","19/May/21 04:46;bereng;^my PR raises the timeout only for this class. Is that ok or am I misunderstanding sthg?

EDIT: I mean: you were adding a rule that affects at the method level. I am adding a _class_ rule that affects the whole class. I tested by lowering to 1m and see it fail so it is effective indeed.;;;","19/May/21 06:49;bereng;I added a fix for {{InsertUpdateIfConditionTest}} also for convenience. With that one we can either move to the {{long}} section or raise timeout. I have mixed thoughts about it as it's fast locally so I don't have a strong preference...;;;","19/May/21 15:20;e.dimitrova;When you run with the rules locally it works fine, but did you try in a full CI? From what I remember and I read in the mentioned discussion, the rules are overwritten by the build.xml timeouts when you run full CI.

We can verify this again by pushing a dev branch to Jenkins with low build.xml timeout and higher timeout on a class level.

I will push a run later, thanks

About _InsertUpdateIfConditionTest,_ I haven't looked at it and its timings but if it exceeds the unit tests' timeout significantly and qualifies for long test, without exceeding also the long tests' timeouts, I would move it to a long test.  If it needs just a bit of time, and not frequently - I would add a bit of time probably on a class level.

My reasoning comes from the point that if it exceeds the timeout just a bit - we don't have to raise its timeout to a long test and wait for its timeouts too long on a failure. ;;;","20/May/21 02:55;e.dimitrova;Very low timeout in build.xml using your patch and it timed out:

https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/856/workflows/57238d25-d581-4117-872a-422c9f785b6d/jobs/5096/tests;;;","20/May/21 06:03;bereng;icwym now. {{JStackJUnitTask}} sets the watchdog to the timeout in the build.xml. So despite the class rule working whichever timeout is hit first, the lowest one, wins. Works both locally and on CI, I just hadn't happened to test the unlucky path.

Given we can confirm we can't raise timeout at a class level the only solution I can think of is to move them to the 'long' section I am afraid. They still run per commit on CI. wdyt? I don't see other options...;;;","20/May/21 23:46;e.dimitrova;Moving to long tests will work fine for  _InsertUpdateIfConditionTest_ but _ViewComplexTest_ is already moved to be a long test. So for that one I guess we will have no choice but to split the class as also David mentioned in the chat. ;;;","21/May/21 08:45;bereng;[~e.dimitrova] I just realized we can't happily move things to the 'long' section. CI works under std, cdc and compression variants but not for the 'long' section, moving a test to long removes testing coverage so:
A. InsertUpdateIfConditionTest has been split into 3 themes: std, collections and statics and it does _not_ move to 'long' section
B. ViewComplexTest has been split into 3 themes: std, deletions and TTL that should be good enough for the 'long' section.

The q I have now is double: first wdyt? and secondly is whether we should split ViewComplexTest further so it can go back away from 'long' to the std test path bc of test coverage reasons?;;;","21/May/21 17:36;e.dimitrova;I agree with you, we need both test classes back away from 'long', unfortunately. :-( 
While on this, can you also do the same for _ViewFilteringTest_, please? As It seems I didn't have to move that one too as part of CASSANDRA-16613.
Thank you!;;;","24/May/21 10:17;bereng;Done. CI lgtm but I am afraid we won't know if we're flying under the timeouts until we merge and we get a few runs in jenkins. I have all splits around the 2m mark or less.;;;","25/May/21 02:03;e.dimitrova;Looks good, I left only a few small questions/suggestions.
{quote}we won't know if we're flying under the timeouts until we merge and we get a few runs in jenkins.
{quote}
I think that if a back-of-the-envelope calculation is done, that should help. What I mean - we can check the timings of the splits and the timeout for the long tests. The tests were not exceeding with a lot the timeout. We check the ratio between the splits and the whole long test and the timeout for testsome target and that should give us a good idea where we are. Then CI run of course, but that rough calculation should help to establish a good baseline I think. Worst case scenario we can loop them now when we have the multiplexer :) ;;;","26/May/21 05:22;bereng;Last typo review comment addressed.;;;","26/May/21 13:44;e.dimitrova;As soon as you did the timing calculation and we have green CI, I think this is ready for commit. Thank you ;;;","27/May/21 04:54;bereng;CI is green already, please find links in the PR. Back of the envelope calculation is how splits were generated already. But there is big divergence between local, jenkins  devbranch and jenkins commit CI runs. So I don't think we can go much further i.e.. timeout is around 10m and there are 3 to 4 splits which should be under the new 4m timeout...;;;","27/May/21 18:41;e.dimitrova;Posting CI runs here for general visibility CI [j11,|https://app.circleci.com/pipelines/github/bereng/cassandra/319/workflows/1dd551f5-e09e-42ab-bdf9-5d821e360d0d]CI [j8.|https://app.circleci.com/pipelines/github/bereng/cassandra/319/workflows/60191f62-f2df-493e-aaef-9995c52e89b4]

Ready for commit, thank you;;;","31/May/21 10:02;bereng;PRs rebased and new CIs on it's way once circle gets back online as it's non responsive for me atm. Will commit asap circle is back.;;;","01/Jun/21 05:15;bereng;Holding off commit due to massive CI failures on these tests for unknown reasons yet.;;;","01/Jun/21 13:09;e.dimitrova;Thanks [~bereng].

I took a quick look and I am wondering whether there was some drivers update maybe?

Those were not failing up to now and now I see this:
{code:java}
Error Message
An unexpected protocol error occurred on host localhost/127.0.0.1:46739. This is a bug in this library, please report: Must not send frame with WARNING flag for native protocol version < 4

Stacktrace
com.datastax.driver.core.exceptions.ProtocolError: An unexpected protocol error occurred on host localhost/127.0.0.1:46739. This is a bug in this library, please report: Must not send frame with WARNING flag for native protocol version < 4 at com.datastax.driver.core.exceptions.ProtocolError.copy(ProtocolError.java:66) at com.datastax.driver.core.exceptions.ProtocolError.copy(ProtocolError.java:27) at com.datastax.driver.core.DriverThrowables.propagateCause(DriverThrowables.java:35) at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:293) at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:58) at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:45) at org.apache.cassandra.cql3.CQLTester.executeNet(CQLTester.java:956) at org.apache.cassandra.cql3.ViewComplexTest.testBaseTTLWithSameTimestampTest(ViewComplexTest.java:641) Caused by: com.datastax.driver.core.exceptions.ProtocolError: An unexpected protocol error occurred on host localhost/127.0.0.1:46739. This is a bug in this library, please report: Must not send frame with WARNING flag for native protocol version < 4
{code}
 //CC [~aholmber] and [~samt] ;;;","02/Jun/21 04:31;bereng;All back to normal. Some docker changes in the CI scripts were the culprit although I can't tell how the schema and driver problems came about. In any case I'll be committing this today.;;;","03/Jun/21 04:39;bereng;ViewComplexTest seems to be the only split that timeouts out sometimes, so I almost go it right. It might need another split #justfyi;;;","04/Jun/21 01:06;e.dimitrova;Thank you. I reopened the ticket so we can fix those. I can also look at this if you don't have the time;;;","04/Jun/21 04:27;bereng;Not  a big fan of reopening, I prefer a 'linear' hsitory. I'll open a new quick ticket thx.;;;","01/Sep/22 05:29;jaid;[~e.dimitrova] Were you able to find why the errors that you mentioned in the [comment|https://issues.apache.org/jira/browse/CASSANDRA-16670?focusedCommentId=17355084&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17355084] happened? We see a similar errors where the driver version is 4.13.0 and the server version is 4.0.5. ;;;","01/Sep/22 22:24;e.dimitrova;Hi [~jaid] , this was more than a year ago and unfortunately I do not recall the details and the logs are gone but there were a bunch of changes happening pre-release and I remember it was something temporary. We haven't seen it anymore in our test environment, as far as I can see.

I think I noticed in ASF Slack you figured out your issue?

 ;;;","01/Sep/22 22:59;jaid;thanks for your response. Yes I figured out the issue by looking at the error message but my only confusion was why it started all of a sudden. The server was upgraded almost 10 days back but the error started only 2 days ago.;;;","02/Sep/22 05:01;bereng;I'm not going to be of much help here but I remember those driver errors just came and went away. Somebody must have fixed them somewhere else as the fix for this ticket was completely unrelated to drivers.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,
Password obfuscation for DCL audit log statements,CASSANDRA-16669,13378551,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,sumanth.pasupuleti,vinaykumarcse,vinaykumarcse,15/May/21 01:44,27/May/22 19:24,13/Jul/23 08:40,15/Jun/21 12:46,4.0.0,4.1,4.1-alpha1,,,,,Tool/auditlogging,,,,0,audit,security,"The goal of this JIRA is to obfuscate passwords or any sensitive information from DCL audit log statements.

Currently, (Cassandra version 4.0-rc1) logs query statements for any DCL ([ROLE|https://cassandra.apache.org/doc/latest/cql/security.html#database-roles] and [USER|https://cassandra.apache.org/doc/latest/cql/security.html#users] ) queries with passwords in plaintext format in audit log files.

The current workaround to avoid plain text passwords from being logged in audit log files is either by [excluding|https://cassandra.apache.org/doc/latest/operating/audit_logging.html#options] DCL statements from auditing or by excluding the user who is creating these roles from auditing.

It would be ideal for Cassandra to provide an option or default to obfuscate passwords or any sensitive information from DCL audit log statements.

Sample audit logs with DCL queries
{code:sh}
Type: audit
LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:51908|timestamp:1620190499676|type:CREATE_ROLE|category:DCL|operation:CREATE ROLE new_role;
Type: audit
LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:51908|timestamp:1620190505313|type:CREATE_ROLE|category:DCL|operation:CREATE ROLE alice WITH PASSWORD = 'password_a' AND LOGIN = true;
Type: audit
LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:51908|timestamp:1620190519521|type:REQUEST_FAILURE|category:ERROR|operation:ALTER ROLE bob WITH PASSWORD = 'PASSWORD_B' AND SUPERUSER = false;; bob doesn't exist
Type: audit
LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:51908|timestamp:1620190525376|type:CREATE_ROLE|category:DCL|operation:CREATE ROLE bob WITH PASSWORD = 'password_b' AND LOGIN = true AND SUPERUSER = true;
Type: audit
LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:51908|timestamp:1620190532462|type:ALTER_ROLE|category:DCL|operation:ALTER ROLE bob WITH PASSWORD = 'PASSWORD_B' AND SUPERUSER = false;
{code}

It is also ideal to document this workaround or assumption in Cassandra audit log documentation until we close this JIRA",,adelapena,aholmber,bereng,brandon.williams,e.dimitrova,jeromatron,jjordan,mck,stefan.miklosovic,sumanth.pasupuleti,vinaykumarcse,,,,,"sumanth-pasupuleti opened a new pull request #1028:
URL: https://github.com/apache/cassandra/pull/1028


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/May/21 21:21;githubbot;600","smiklosovic commented on a change in pull request #1028:
URL: https://github.com/apache/cassandra/pull/1028#discussion_r644795764



##########
File path: src/java/org/apache/cassandra/audit/IObfuscator.java
##########
@@ -0,0 +1,25 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.audit;
+
+public interface IObfuscator
+{
+    // Obfuscates the source string and returns the obfuscated string

Review comment:
       @sumanth-pasupuleti Would you mind to comment this with ""proper"" Java doc, not just with one-liner? Thank you very much in advance.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Jun/21 13:32;githubbot;600","smiklosovic commented on a change in pull request #1028:
URL: https://github.com/apache/cassandra/pull/1028#discussion_r644796651



##########
File path: src/java/org/apache/cassandra/audit/AuditLogManager.java
##########
@@ -114,6 +113,11 @@ private void log(AuditLogEntry logEntry)
     {
         if (!filter.isFiltered(logEntry))
         {
+            // we may need to obfuscate password (CASSANDRA-16669)

Review comment:
       @sumanth-pasupuleti I believe this is not acually necessary, the code is pretty much self-evident.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Jun/21 13:33;githubbot;600","smiklosovic commented on a change in pull request #1028:
URL: https://github.com/apache/cassandra/pull/1028#discussion_r644795764



##########
File path: src/java/org/apache/cassandra/audit/IObfuscator.java
##########
@@ -0,0 +1,25 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.audit;
+
+public interface IObfuscator
+{
+    // Obfuscates the source string and returns the obfuscated string

Review comment:
       @sumanth-pasupuleti Would you mind to comment this with ""proper"" Java doc, not just with one-liner? Thank you very much in advance.

##########
File path: src/java/org/apache/cassandra/audit/AuditLogManager.java
##########
@@ -114,6 +113,11 @@ private void log(AuditLogEntry logEntry)
     {
         if (!filter.isFiltered(logEntry))
         {
+            // we may need to obfuscate password (CASSANDRA-16669)

Review comment:
       @sumanth-pasupuleti I believe this is not acually necessary, the code is pretty much self-evident.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 08:00;githubbot;600","vinaykumarchella commented on a change in pull request #1028:
URL: https://github.com/apache/cassandra/pull/1028#discussion_r645629256



##########
File path: doc/source/new/auditlogging.rst
##########
@@ -89,6 +89,7 @@ Audit logging does not log:
 
 1. Configuration changes made in ``cassandra.yaml``
 2. Nodetool Commands
+3. Passwords mentioned as part of DCL statements. Passwords are instead obfuscated as ******
 

Review comment:
       @sumanth-pasupuleti Can you also update the documentation at `doc/source/operating/audit_logging.rst`, while you are at it, can you add a few example log statements with DCL and password obfuscation at `Sample output` section. 

##########
File path: test/unit/org/apache/cassandra/audit/PasswordObfuscatorTest.java
##########
@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.audit;
+
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+
+public class PasswordObfuscatorTest
+{
+    @Test
+    public void testCreatRoleWithLoginPriorToPassword()
+    {
+        assertEquals(String.format(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATED_TOKEN), PasswordObfuscator.instance.obfuscate(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testCreatRoleWithLoginAfterPassword()
+    {
+        assertEquals(String.format(""CREATE ROLE role1 WITH password = '%s' AND LOGIN = true"", PasswordObfuscator.OBFUSCATED_TOKEN), PasswordObfuscator.instance.obfuscate(""CREATE ROLE role1 WITH password = '123' AND LOGIN = true""));
+    }
+
+    @Test
+    public void testCreateRoleWithoutPassword()
+    {
+        assertEquals(""CREATE ROLE role1"", PasswordObfuscator.instance.obfuscate(""CREATE ROLE role1""));
+    }
+
+    @Test
+    public void testAlterRoleWithPassword()
+    {
+        assertEquals(String.format(""ALTER ROLE role1 with PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATED_TOKEN), PasswordObfuscator.instance.obfuscate(""ALTER ROLE role1 with PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithoutPassord()
+    {
+        assertEquals(""ALTER ROLE role1"", PasswordObfuscator.instance.obfuscate(""ALTER ROLE role1""));
+    }
+
+    @Test
+    public void testCreateUserWithPassword()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATED_TOKEN), PasswordObfuscator.instance.obfuscate(""CREATE USER user1 with PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testCreateUserWithoutPassword()
+    {
+        assertEquals(""CREATE USER user1"", PasswordObfuscator.instance.obfuscate(""CREATE USER user1""));
+    }
+
+    @Test
+    public void testAlterUserWithPassword()

Review comment:
       Can you add few more tests with different query formats (spaces, newlines, mixed casing at PASSWORD token etc.,), some of these could fail in query validations themselves, but good to have these test cases to validate the regex?
   
   A few examples that I can think of
   
   - ALTER USER user1 with PASSWORD='123' - No spaces, validation error
   - ALTER USER user1 with PASSWORD ='123' - valid
   - ALTER USER user1 with PASSWORD= '123' - valid
   - ALTER USER user1 with PassWoRD = '123' - valid, mixed case
   - ALTER USER user1 with passwprd = '123' - valid, small case
   - ALTER USER user1 with PassWoRD = '123 - validation error 
   - ALTER USER user1 with passwprd = \n '123' - valid, new line? not sure how the cql parser treats these newlines though.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 15:09;githubbot;600","smiklosovic commented on pull request #1028:
URL: https://github.com/apache/cassandra/pull/1028#issuecomment-854811838


   @sumanth-pasupuleti it would be awesome if you apply comments of @vinaykumarchella on top of https://github.com/sumanth-pasupuleti/cassandra/pull/3/files
   
   thank you


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 15:23;githubbot;600","sumanth-pasupuleti commented on a change in pull request #1028:
URL: https://github.com/apache/cassandra/pull/1028#discussion_r645763013



##########
File path: doc/source/new/auditlogging.rst
##########
@@ -89,6 +89,7 @@ Audit logging does not log:
 
 1. Configuration changes made in ``cassandra.yaml``
 2. Nodetool Commands
+3. Passwords mentioned as part of DCL statements. Passwords are instead obfuscated as ******
 

Review comment:
       Couldn't quite find doc/source/operating/audit_logging.rst; must have been removed as part of recent website changes I suppose. 
   Added a few example dcl statements indicating obfuscated password in the sample output.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 18:12;githubbot;600","sumanth-pasupuleti commented on a change in pull request #1028:
URL: https://github.com/apache/cassandra/pull/1028#discussion_r645781195



##########
File path: test/unit/org/apache/cassandra/audit/PasswordObfuscatorTest.java
##########
@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.audit;
+
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+
+public class PasswordObfuscatorTest
+{
+    @Test
+    public void testCreatRoleWithLoginPriorToPassword()
+    {
+        assertEquals(String.format(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATED_TOKEN), PasswordObfuscator.instance.obfuscate(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testCreatRoleWithLoginAfterPassword()
+    {
+        assertEquals(String.format(""CREATE ROLE role1 WITH password = '%s' AND LOGIN = true"", PasswordObfuscator.OBFUSCATED_TOKEN), PasswordObfuscator.instance.obfuscate(""CREATE ROLE role1 WITH password = '123' AND LOGIN = true""));
+    }
+
+    @Test
+    public void testCreateRoleWithoutPassword()
+    {
+        assertEquals(""CREATE ROLE role1"", PasswordObfuscator.instance.obfuscate(""CREATE ROLE role1""));
+    }
+
+    @Test
+    public void testAlterRoleWithPassword()
+    {
+        assertEquals(String.format(""ALTER ROLE role1 with PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATED_TOKEN), PasswordObfuscator.instance.obfuscate(""ALTER ROLE role1 with PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithoutPassord()
+    {
+        assertEquals(""ALTER ROLE role1"", PasswordObfuscator.instance.obfuscate(""ALTER ROLE role1""));
+    }
+
+    @Test
+    public void testCreateUserWithPassword()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATED_TOKEN), PasswordObfuscator.instance.obfuscate(""CREATE USER user1 with PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testCreateUserWithoutPassword()
+    {
+        assertEquals(""CREATE USER user1"", PasswordObfuscator.instance.obfuscate(""CREATE USER user1""));
+    }
+
+    @Test
+    public void testAlterUserWithPassword()

Review comment:
       I have added these variants into PasswordObfuscatorTest.java 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 18:46;githubbot;600","vinaykumarchella commented on a change in pull request #1028:
URL: https://github.com/apache/cassandra/pull/1028#discussion_r645883847



##########
File path: doc/source/new/auditlogging.rst
##########
@@ -89,6 +89,7 @@ Audit logging does not log:
 
 1. Configuration changes made in ``cassandra.yaml``
 2. Nodetool Commands
+3. Passwords mentioned as part of DCL statements. Passwords are instead obfuscated as ******
 

Review comment:
       Looks like these 2 were merged as part of CASSANDRA-16682.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Jun/21 22:16;githubbot;600","smiklosovic commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r648987763



##########
File path: doc/source/new/auditlogging.rst
##########
@@ -450,37 +451,45 @@ The ``auditlogviewer`` tool is used to dump audit logs. Run the ``auditlogviewer
 
  [ec2-user@ip-10-0-2-238 hourly]$ auditlogviewer /cassandra/audit/logs/hourly
  WARN  03:12:11,124 Using Pauser.sleepy() as not enough processors, have 2, needs 8+
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427328|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE AuditLogKeyspace;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427329|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE ""auditlogkeyspace""
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711446279|type :SELECT|category:QUERY|ks:auditlogkeyspace|scope:t|operation:SELECT * FROM t;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564713878834|type :DROP_TABLE|category:DDL|ks:auditlogkeyspace|scope:t|operation:DROP TABLE IF EXISTS
- AuditLogKeyspace.t;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42382|timestamp:1564714618360|ty
- pe:REQUEST_FAILURE|category:ERROR|operation:CREATE KEYSPACE AuditLogKeyspace
- WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};; Cannot add
- existing keyspace ""auditlogkeyspace""
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714690968|type :DROP_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:DROP KEYSPACE AuditLogKeyspace;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42406|timestamp:1564714708329|ty pe:CREATE_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:CREATE KEYSPACE
- AuditLogKeyspace
- WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714870678|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE auditlogkeyspace;
- [ec2-user@ip-10-0-2-238 hourly]$
+ Type: audit

Review comment:
       hi @ekaterinadimitrova2 , it was never AuditLog (or was but it is not anymore), what I see from logs now is that it is ""audit""




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 08:53;githubbot;600","smiklosovic commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r648988555



##########
File path: doc/source/new/auditlogging.rst
##########
@@ -450,37 +451,45 @@ The ``auditlogviewer`` tool is used to dump audit logs. Run the ``auditlogviewer
 
  [ec2-user@ip-10-0-2-238 hourly]$ auditlogviewer /cassandra/audit/logs/hourly
  WARN  03:12:11,124 Using Pauser.sleepy() as not enough processors, have 2, needs 8+
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427328|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE AuditLogKeyspace;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427329|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE ""auditlogkeyspace""
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711446279|type :SELECT|category:QUERY|ks:auditlogkeyspace|scope:t|operation:SELECT * FROM t;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564713878834|type :DROP_TABLE|category:DDL|ks:auditlogkeyspace|scope:t|operation:DROP TABLE IF EXISTS
- AuditLogKeyspace.t;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42382|timestamp:1564714618360|ty
- pe:REQUEST_FAILURE|category:ERROR|operation:CREATE KEYSPACE AuditLogKeyspace
- WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};; Cannot add
- existing keyspace ""auditlogkeyspace""
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714690968|type :DROP_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:DROP KEYSPACE AuditLogKeyspace;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42406|timestamp:1564714708329|ty pe:CREATE_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:CREATE KEYSPACE
- AuditLogKeyspace
- WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714870678|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE auditlogkeyspace;
- [ec2-user@ip-10-0-2-238 hourly]$
+ Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427328|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE AuditLogKeyspace;
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427329|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE ""auditlogkeyspace""
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711446279|type :SELECT|category:QUERY|ks:auditlogkeyspace|scope:t|operation:SELECT * FROM t;
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564713878834|type :DROP_TABLE|category:DDL|ks:auditlogkeyspace|scope:t|operation:DROP TABLE IF EXISTS
+  AuditLogKeyspace.t;
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42382|timestamp:1564714618360|ty
+  pe:REQUEST_FAILURE|category:ERROR|operation:CREATE KEYSPACE AuditLogKeyspace
+  WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};; Cannot add
+  existing keyspace ""auditlogkeyspace""
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714690968|type :DROP_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:DROP KEYSPACE AuditLogKeyspace;
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42406|timestamp:1564714708329|ty pe:CREATE_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:CREATE KEYSPACE
+  AuditLogKeyspace
+  WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714870678|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE auditlogkeyspace;
+  [ec2-user@ip-10-0-2-238 hourly]$
+  Type: audit
+  LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:65282|timestamp:1622630496708|type:CREATE_ROLE|category:DCL|operation:create role role1 WITH password = '*******';

Review comment:
       maybe for the purpose of the documentation but they are recorded as they were typed in cqlsh so if you enter it lowercase, it will be lowercased in the log too.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 08:54;githubbot;600","alex-ninja commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r648999196



##########
File path: src/java/org/apache/cassandra/cql3/PasswordObfuscator.java
##########
@@ -0,0 +1,63 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * Obfuscates passwords in a given string
+ */
+class PasswordObfuscator implements IObfuscator
+{
+    private static final String OBFUSCATION_TOKEN = ""*******"";
+    private static final String PASSWORD_TOKEN = ""password"";
+
+    private static final int PATTERN_FLAGS = Pattern.CASE_INSENSITIVE | Pattern.DOTALL;
+    private static final Pattern PASSWORD_PATTERN = Pattern.compile("".*password\\s*=?\\s*'(?<password>[^\\s]+)'.*"",

Review comment:
       As far as I understand, you assume passwords to not have whitespace characters, right? Even though it is highly unlikely to have a whitespace character in the password, it is currently allowed (tested manually on version 3.11.10):
   ```
   # create a user with a password that contains spaces
   $ ./bin/cqlsh -u cassandra -p cassandra
   cassandra@cqlsh> CREATE ROLE alice WITH PASSWORD = 'PASSWORD WITH SPACES' AND SUPERUSER = true AND LOGIN = true;
   cassandra@cqlsh> exit
   
   # login using such a password
   $ ./bin/cqlsh -u alice -p ""PASSWORD WITH SPACES""
   cassandra@cqlsh> exit
   ```
   I have not found any documentation that clearly explains what characters are allowed in passwords. My current assumption is that all characters are allowed (including control and whitespace characters). I doubt that someone really uses control characters, but whitespace character seems to be possible. I'd consider the following pattern `(?<password>.*)`  - everything including whitespace characters and the empty password (see below).
   
   It turned out that empty password is also allowed to set:
   ```
   # create a user with empty password
   $ ./bin/cqlsh -u cassandra -p cassandra
   cassandra@cqlsh> CREATE ROLE bob WITH PASSWORD = '' AND SUPERUSER = true AND LOGIN = true;
   ```
   Despite I was unable to login through `cqlsh`:
   ```
   $ ./bin/cqlsh -u bob -p """"
   Password: Traceback (most recent call last):
     File ""/home/azotov/opt/apache-cassandra-3.11.10/bin/cqlsh.py"", line 2458, in <module>
       main(*read_options(sys.argv[1:], os.environ))
     File ""/home/azotov/opt/apache-cassandra-3.11.10/bin/cqlsh.py"", line 2436, in main
       encoding=options.encoding)
     File ""/home/azotov/opt/apache-cassandra-3.11.10/bin/cqlsh.py"", line 466, in __init__
       password = getpass.getpass()
     File ""/usr/lib/python2.7/getpass.py"", line 71, in unix_getpass
       passwd = _raw_input(prompt, stream, input=input)
     File ""/usr/lib/python2.7/getpass.py"", line 135, in _raw_input
       raise EOFError
   EOFError
   ```
   I feel it is related to the logic in Python wrapper rather than to a protocol limit. So I bet I'd be able to login using a Java client. Assuming it is possible to set and login with the empty password, we also need to obfuscate it.
   
   Both use cases seem to be corner cases (pretty rare and weird), but I believe we need to handle them properly. Please, let me know your thoughts.
   




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 09:07;githubbot;600","smiklosovic commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649020676



##########
File path: doc/source/new/auditlogging.rst
##########
@@ -450,37 +451,45 @@ The ``auditlogviewer`` tool is used to dump audit logs. Run the ``auditlogviewer
 
  [ec2-user@ip-10-0-2-238 hourly]$ auditlogviewer /cassandra/audit/logs/hourly
  WARN  03:12:11,124 Using Pauser.sleepy() as not enough processors, have 2, needs 8+
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427328|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE AuditLogKeyspace;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427329|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE ""auditlogkeyspace""
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711446279|type :SELECT|category:QUERY|ks:auditlogkeyspace|scope:t|operation:SELECT * FROM t;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564713878834|type :DROP_TABLE|category:DDL|ks:auditlogkeyspace|scope:t|operation:DROP TABLE IF EXISTS
- AuditLogKeyspace.t;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42382|timestamp:1564714618360|ty
- pe:REQUEST_FAILURE|category:ERROR|operation:CREATE KEYSPACE AuditLogKeyspace
- WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};; Cannot add
- existing keyspace ""auditlogkeyspace""
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714690968|type :DROP_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:DROP KEYSPACE AuditLogKeyspace;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42406|timestamp:1564714708329|ty pe:CREATE_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:CREATE KEYSPACE
- AuditLogKeyspace
- WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714870678|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE auditlogkeyspace;
- [ec2-user@ip-10-0-2-238 hourly]$
+ Type: audit

Review comment:
       I fixed that and I ll deliver in the separate commit.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 09:36;githubbot;600","smiklosovic commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649020934



##########
File path: doc/source/new/auditlogging.rst
##########
@@ -450,37 +451,45 @@ The ``auditlogviewer`` tool is used to dump audit logs. Run the ``auditlogviewer
 
  [ec2-user@ip-10-0-2-238 hourly]$ auditlogviewer /cassandra/audit/logs/hourly
  WARN  03:12:11,124 Using Pauser.sleepy() as not enough processors, have 2, needs 8+
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427328|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE AuditLogKeyspace;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427329|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE ""auditlogkeyspace""
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711446279|type :SELECT|category:QUERY|ks:auditlogkeyspace|scope:t|operation:SELECT * FROM t;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564713878834|type :DROP_TABLE|category:DDL|ks:auditlogkeyspace|scope:t|operation:DROP TABLE IF EXISTS
- AuditLogKeyspace.t;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42382|timestamp:1564714618360|ty
- pe:REQUEST_FAILURE|category:ERROR|operation:CREATE KEYSPACE AuditLogKeyspace
- WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};; Cannot add
- existing keyspace ""auditlogkeyspace""
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714690968|type :DROP_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:DROP KEYSPACE AuditLogKeyspace;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42406|timestamp:1564714708329|ty pe:CREATE_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:CREATE KEYSPACE
- AuditLogKeyspace
- WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714870678|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE auditlogkeyspace;
- [ec2-user@ip-10-0-2-238 hourly]$
+ Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427328|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE AuditLogKeyspace;
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427329|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE ""auditlogkeyspace""
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711446279|type :SELECT|category:QUERY|ks:auditlogkeyspace|scope:t|operation:SELECT * FROM t;
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564713878834|type :DROP_TABLE|category:DDL|ks:auditlogkeyspace|scope:t|operation:DROP TABLE IF EXISTS
+  AuditLogKeyspace.t;
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42382|timestamp:1564714618360|ty
+  pe:REQUEST_FAILURE|category:ERROR|operation:CREATE KEYSPACE AuditLogKeyspace
+  WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};; Cannot add
+  existing keyspace ""auditlogkeyspace""
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714690968|type :DROP_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:DROP KEYSPACE AuditLogKeyspace;
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42406|timestamp:1564714708329|ty pe:CREATE_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:CREATE KEYSPACE
+  AuditLogKeyspace
+  WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};
+  Type: audit
+  LogMessage:
+  user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714870678|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE auditlogkeyspace;
+  [ec2-user@ip-10-0-2-238 hourly]$
+  Type: audit
+  LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:65282|timestamp:1622630496708|type:CREATE_ROLE|category:DCL|operation:create role role1 WITH password = '*******';

Review comment:
       changed to uppercase, resolving.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 09:36;githubbot;600","smiklosovic commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649021592



##########
File path: src/java/org/apache/cassandra/audit/AuditLogManager.java
##########
@@ -135,7 +135,7 @@ else if (e instanceof AuthenticationException)
             builder.setType(AuditLogEntryType.REQUEST_FAILURE);
         }
 
-        builder.appendToOperation(e.getMessage());
+        builder.appendToOperation(QueryEvents.instance.getObfuscator().obfuscate(e.getMessage()));

Review comment:
       I am not sure I have seen this in action yet, I just want to be sure we have not forgot anything. I do not have any example to test.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 09:37;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649162765



##########
File path: src/java/org/apache/cassandra/cql3/PasswordObfuscator.java
##########
@@ -0,0 +1,63 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * Obfuscates passwords in a given string
+ */
+class PasswordObfuscator implements IObfuscator
+{
+    private static final String OBFUSCATION_TOKEN = ""*******"";
+    private static final String PASSWORD_TOKEN = ""password"";
+
+    private static final int PATTERN_FLAGS = Pattern.CASE_INSENSITIVE | Pattern.DOTALL;
+    private static final Pattern PASSWORD_PATTERN = Pattern.compile("".*password\\s*=?\\s*'(?<password>[^\\s]+)'.*"",

Review comment:
       Oh that is a great catch! Let's still test in 4.0 though whether something has changed. I was thinking last night to confirm we use the pattern Cassandra uses.
   Also, I think your point we lack a doc is a good one, probably we can file an improvement to add that info.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 13:05;githubbot;600","alex-ninja commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649238470



##########
File path: src/java/org/apache/cassandra/cql3/PasswordObfuscator.java
##########
@@ -0,0 +1,63 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * Obfuscates passwords in a given string
+ */
+class PasswordObfuscator implements IObfuscator
+{
+    private static final String OBFUSCATION_TOKEN = ""*******"";
+    private static final String PASSWORD_TOKEN = ""password"";
+
+    private static final int PATTERN_FLAGS = Pattern.CASE_INSENSITIVE | Pattern.DOTALL;
+    private static final Pattern PASSWORD_PATTERN = Pattern.compile("".*password\\s*=?\\s*'(?<password>[^\\s]+)'.*"",

Review comment:
       I've just tested the same scenarios on 4.0-rc1 (downloaded from https://cassandra.apache.org/download/). The behavior is nearly the same, the only difference is the response for login with empty password:
   ```
   $ ./bin/cqlsh -u bob -p """"
   Password: 
   Connection error: ('Unable to connect to any servers', {'127.0.0.1:9042': AuthenticationFailed('Failed to authenticate to 127.0.0.1:9042: Error from server: code=0100 [Bad credentials] message=""Password must not be null""')})
   ```
   Looks like it is possible to set empty password, but it is impossible to login using that because of: https://github.com/apache/cassandra/blob/cassandra-4.0/src/java/org/apache/cassandra/auth/PasswordAuthenticator.java#L233
   
   And such a behavior seems to be confusing.
   
   The proper fix would be to limit possible values for the password and use the same pattern for obfuscation, but I guess it is not directly related to this PR and 4.0 as it seems to be a new feature rather than a critical fix.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 14:29;githubbot;600","smiklosovic commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649251711



##########
File path: src/java/org/apache/cassandra/cql3/PasswordObfuscator.java
##########
@@ -0,0 +1,63 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * Obfuscates passwords in a given string
+ */
+class PasswordObfuscator implements IObfuscator
+{
+    private static final String OBFUSCATION_TOKEN = ""*******"";
+    private static final String PASSWORD_TOKEN = ""password"";
+
+    private static final int PATTERN_FLAGS = Pattern.CASE_INSENSITIVE | Pattern.DOTALL;
+    private static final Pattern PASSWORD_PATTERN = Pattern.compile("".*password\\s*=?\\s*'(?<password>[^\\s]+)'.*"",

Review comment:
       Thanks, I fixed empty passwords and passwords with spaces.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 14:43;githubbot;600","sumanth-pasupuleti commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649277548



##########
File path: src/java/org/apache/cassandra/cql3/QueryEvents.java
##########
@@ -72,8 +82,9 @@ public void notifyQuerySuccess(CQLStatement statement,
     {
         try
         {
+
             for (Listener listener : listeners)
-                listener.querySuccess(statement, query, options, state, queryTime, response);
+                listener.querySuccess(statement, possiblyObfuscateQuery(statement, query), options, state, queryTime, response);

Review comment:
       > Another idea:
   > Can we do this before for loop to avoid the overhead / unnecessary cost
   > `query = listeners.size()>0? possiblyObfuscateQuery(statement, query) : query; `
   
   incorporating ^




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 15:11;githubbot;600","sumanth-pasupuleti commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649278425



##########
File path: src/java/org/apache/cassandra/cql3/IObfuscator.java
##########
@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+public interface IObfuscator

Review comment:
       I do not think we have any other implementations planned yet, except for Password




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 15:12;githubbot;600","sumanth-pasupuleti commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649278847



##########
File path: src/java/org/apache/cassandra/cql3/PasswordObfuscator.java
##########
@@ -0,0 +1,63 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * Obfuscates passwords in a given string
+ */
+class PasswordObfuscator implements IObfuscator
+{
+    private static final String OBFUSCATION_TOKEN = ""*******"";
+    private static final String PASSWORD_TOKEN = ""password"";
+
+    private static final int PATTERN_FLAGS = Pattern.CASE_INSENSITIVE | Pattern.DOTALL;
+    private static final Pattern PASSWORD_PATTERN = Pattern.compile("".*password\\s*=?\\s*'(?<password>[^\\s]+)'.*"",

Review comment:
       Thanks @alex-ninja for catching this, and @smiklosovic for incorporating




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 15:13;githubbot;600","sumanth-pasupuleti commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649286800



##########
File path: doc/source/new/auditlogging.rst
##########
@@ -450,37 +451,45 @@ The ``auditlogviewer`` tool is used to dump audit logs. Run the ``auditlogviewer
 
  [ec2-user@ip-10-0-2-238 hourly]$ auditlogviewer /cassandra/audit/logs/hourly
  WARN  03:12:11,124 Using Pauser.sleepy() as not enough processors, have 2, needs 8+
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427328|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE AuditLogKeyspace;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711427329|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE ""auditlogkeyspace""
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564711446279|type :SELECT|category:QUERY|ks:auditlogkeyspace|scope:t|operation:SELECT * FROM t;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564713878834|type :DROP_TABLE|category:DDL|ks:auditlogkeyspace|scope:t|operation:DROP TABLE IF EXISTS
- AuditLogKeyspace.t;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42382|timestamp:1564714618360|ty
- pe:REQUEST_FAILURE|category:ERROR|operation:CREATE KEYSPACE AuditLogKeyspace
- WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};; Cannot add
- existing keyspace ""auditlogkeyspace""
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714690968|type :DROP_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:DROP KEYSPACE AuditLogKeyspace;
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/3.91.56.164|port:42406|timestamp:1564714708329|ty pe:CREATE_KEYSPACE|category:DDL|ks:auditlogkeyspace|operation:CREATE KEYSPACE
- AuditLogKeyspace
- WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};
- Type: AuditLog
- LogMessage:
- user:anonymous|host:10.0.2.238:7000|source:/127.0.0.1|port:46264|timestamp:1564714870678|type :USE_KEYSPACE|category:OTHER|ks:auditlogkeyspace|operation:USE auditlogkeyspace;
- [ec2-user@ip-10-0-2-238 hourly]$
+ Type: audit

Review comment:
       yes, this was changed as part of https://issues.apache.org/jira/browse/CASSANDRA-15076. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 15:22;githubbot;600","sumanth-pasupuleti commented on pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#issuecomment-858723649


   fyi, incorporated @smiklosovic changes into the PR. 
   @smiklosovic @vinaykumarchella @alex-ninja curious if you have any additional feedback


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 15:32;githubbot;600","ekaterinadimitrova2 commented on pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#issuecomment-858741352


   Thank you @sumanth-pasupuleti and @smiklosovic for the quick changes. 
   I am still testing the patch. Also, I believe @smiklosovic is still looking into the BATCH issue mentioned here https://issues.apache.org/jira/browse/CASSANDRA-16669?focusedCommentId=17360888&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17360888
   and we need to add more tests for the corner cases.  Can we also add tests for empty passwords and passwords with whitespaces? Thank you


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 15:54;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649317414



##########
File path: src/java/org/apache/cassandra/cql3/IObfuscator.java
##########
@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+public interface IObfuscator

Review comment:
       Yes, this was from the initial not centralized patch and Stefan removed it, thanks :-)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 15:56;githubbot;600","smiklosovic commented on pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#issuecomment-858744614


   @ekaterinadimitrova2 yes they are there, in my branch, tests covering empty passwords and spaces too


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 15:58;githubbot;600","ekaterinadimitrova2 commented on pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#issuecomment-858751499


   Great, thank you! 


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 16:07;githubbot;600","alex-ninja commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649374095



##########
File path: test/unit/org/apache/cassandra/cql3/PasswordObfuscatorTest.java
##########
@@ -0,0 +1,160 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import org.junit.Ignore;
+import org.junit.Test;
+
+import static java.lang.String.format;
+import static org.junit.Assert.assertEquals;
+
+public class PasswordObfuscatorTest
+{
+    private static final PasswordObfuscator obfuscator = new PasswordObfuscator();
+
+    @Test
+    public void testCreatRoleWithLoginPriorToPassword()
+    {
+        assertEquals(format(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testCreatRoleWithLoginAfterPassword()
+    {
+        assertEquals(format(""CREATE ROLE role1 WITH password = '%s' AND LOGIN = true"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE ROLE role1 WITH password = '123' AND LOGIN = true""));
+    }
+
+    @Test
+    public void testCreateRoleWithoutPassword()
+    {
+        assertEquals(""CREATE ROLE role1"", obfuscator.obfuscate(""CREATE ROLE role1""));
+    }
+
+    @Test
+    public void testAlterRoleWithPassword()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithPasswordNoSpace()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD='%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD='123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithPasswordNoImmediateSpace()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD= '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD= '123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithoutPassword()
+    {
+        assertEquals(""ALTER ROLE role1"", obfuscator.obfuscate(""ALTER ROLE role1""));
+    }
+
+    @Test
+    public void testCreateUserWithPassword()
+    {
+        assertEquals(format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD '123'""));
+    }
+
+    @Test
+    public void testCreateUserWithoutPassword()
+    {
+        assertEquals(""CREATE USER user1"", obfuscator.obfuscate(""CREATE USER user1""));
+    }
+
+    @Test
+    public void testAlterUserWithPassword()
+    {
+        assertEquals(format(""ALTER USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with PASSWORD '123'""));
+    }
+
+    @Test
+    public void testAlterUserWithPasswordMixedCase()
+    {
+        assertEquals(format(""ALTER USER user1 with paSSwoRd '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with paSSwoRd '123'""));
+    }
+
+    @Test
+    public void testAlterUserWithPasswordWithNewLine()
+    {
+        assertEquals(format(""ALTER USER user1 with PASSWORD\n'%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with PASSWORD\n'123'""));
+    }
+
+    @Test
+    public void testPasswordWithNewLinesObfuscation()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD 'a\nb'""));
+    }
+
+    @Test
+    public void testEmptyPasswordObfuscation()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD ''""));
+    }
+
+    @Test
+    public void testPasswordWithSpaces()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD 'p a ss wor d'""));

Review comment:
       Theoretically we can add a test for `CREATE ROLE user1 WITH PASSWORD = 'password_a' AND LOGIN = true AND ACCESS TO DATACENTERS {'DC1', 'DC3'};` - the idea is to have two variables with quotes and ensure that the regex works in ""greedy manner"" and obfuscates `password_a` instead of `password_a' AND LOGIN = true AND ACCESS TO DATACENTERS {'DC1', 'DC3`. I'm pretty sure the current logic works properly, so it is up to you whether to add such a test.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 17:10;githubbot;600","alex-ninja commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649379025



##########
File path: src/java/org/apache/cassandra/cql3/PasswordObfuscator.java
##########
@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * Obfuscates passwords in a given string
+ */
+public class PasswordObfuscator
+{
+    public static final String OBFUSCATION_TOKEN = ""*******"";
+    private static final String PASSWORD_TOKEN = ""password"";
+
+    private static final int PATTERN_FLAGS = Pattern.CASE_INSENSITIVE | Pattern.DOTALL;
+
+    private static final Pattern PASSWORD_PATTERN = Pattern.compile("".*password\\s*=?\\s*'(?<password>.*)'.*"", PATTERN_FLAGS);

Review comment:
       Another idea came to my mind with regard to the following use case/statement:
   ```
   CREATE ROLE user1 WITH OPTIONS = { 'custom_option1' : 'password', 'custom_option2' : 99 } AND PASSWORD 'pwd';
   ```
   I guess the current logic won't be working properly (meaning `', '` part will be obfuscated). Could you, please, add the corresponding test to prove / reject the assumption.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 17:18;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649332307



##########
File path: src/java/org/apache/cassandra/cql3/QueryEvents.java
##########
@@ -205,7 +219,7 @@ public void notifyPrepareSuccess(Supplier<QueryHandler.Prepared> preparedProvide
                 try
                 {
                     for (Listener listener : listeners)
-                        listener.prepareSuccess(prepared.statement, query, state, queryTime, response);
+                        listener.prepareSuccess(prepared.statement, possiblyObfuscateQuery(prepared.statement, query), state, queryTime, response);

Review comment:
       Don't we need again before the loop `final String possiblyObfuscatedQuery = listeners.size() > 0 ? possiblyObfuscateQuery(statement, query) : query;`?

##########
File path: test/unit/org/apache/cassandra/audit/AuditLoggerAuthTest.java
##########
@@ -38,6 +38,8 @@
 import org.apache.cassandra.config.OverrideConfigurationLoader;
 import org.apache.cassandra.config.ParameterizedClass;
 import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.cql3.PasswordObfuscator;
+import org.apache.cassandra.cql3.QueryEvents;

Review comment:
       nit: unused import

##########
File path: test/unit/org/apache/cassandra/cql3/PasswordObfuscatorTest.java
##########
@@ -0,0 +1,160 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import org.junit.Ignore;
+import org.junit.Test;
+
+import static java.lang.String.format;
+import static org.junit.Assert.assertEquals;
+
+public class PasswordObfuscatorTest
+{
+    private static final PasswordObfuscator obfuscator = new PasswordObfuscator();
+
+    @Test
+    public void testCreatRoleWithLoginPriorToPassword()
+    {
+        assertEquals(format(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testCreatRoleWithLoginAfterPassword()
+    {
+        assertEquals(format(""CREATE ROLE role1 WITH password = '%s' AND LOGIN = true"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE ROLE role1 WITH password = '123' AND LOGIN = true""));
+    }
+
+    @Test
+    public void testCreateRoleWithoutPassword()
+    {
+        assertEquals(""CREATE ROLE role1"", obfuscator.obfuscate(""CREATE ROLE role1""));
+    }
+
+    @Test
+    public void testAlterRoleWithPassword()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithPasswordNoSpace()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD='%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD='123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithPasswordNoImmediateSpace()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD= '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD= '123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithoutPassword()
+    {
+        assertEquals(""ALTER ROLE role1"", obfuscator.obfuscate(""ALTER ROLE role1""));
+    }
+
+    @Test
+    public void testCreateUserWithPassword()
+    {
+        assertEquals(format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD '123'""));
+    }
+
+    @Test
+    public void testCreateUserWithoutPassword()
+    {
+        assertEquals(""CREATE USER user1"", obfuscator.obfuscate(""CREATE USER user1""));
+    }
+
+    @Test
+    public void testAlterUserWithPassword()
+    {
+        assertEquals(format(""ALTER USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with PASSWORD '123'""));
+    }
+
+    @Test
+    public void testAlterUserWithPasswordMixedCase()
+    {
+        assertEquals(format(""ALTER USER user1 with paSSwoRd '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with paSSwoRd '123'""));
+    }
+
+    @Test
+    public void testAlterUserWithPasswordWithNewLine()
+    {
+        assertEquals(format(""ALTER USER user1 with PASSWORD\n'%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with PASSWORD\n'123'""));
+    }
+
+    @Test
+    public void testPasswordWithNewLinesObfuscation()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD 'a\nb'""));
+    }
+
+    @Test
+    public void testEmptyPasswordObfuscation()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD ''""));
+    }
+
+    @Test
+    public void testPasswordWithSpaces()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD 'p a ss wor d'""));
+    }
+
+    @Test
+    public void testSimpleBatch()
+    {
+        assertEquals(format(""BEGIN BATCH \n"" +
+                            ""    CREATE ROLE alice1 WITH PASSWORD = '%s' and LOGIN = true; \n"" +
+                            ""APPLY BATCH;"",
+                            PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""BEGIN BATCH \n"" +
+                                          ""    CREATE ROLE alice1 WITH PASSWORD = 'alice123' and LOGIN = true; \n"" +
+                                          ""APPLY BATCH;""));
+    }
+
+    @Test
+    @Ignore

Review comment:
       Also, small observation, If we add more` ""    CREATE ROLE alice1 WITH PASSWORD = '%s' and LOGIN = true; \n"" +`, it obfuscates only the last occurrence... I need to check the code to see why.

##########
File path: src/java/org/apache/cassandra/cql3/QueryEvents.java
##########
@@ -235,6 +250,12 @@ public void notifyPrepareFailure(@Nullable CQLStatement statement, String query,
         }
     }
 
+    private String possiblyObfuscateQuery(CQLStatement statement, String query)
+    {
+        // statement might be null as side-effect of failed parsing, originates from QueryMessage#execute

Review comment:
       ```suggestion
           // Statement might be null as side-effect of failed parsing, originates from QueryMessage#execute
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 17:26;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649385194



##########
File path: src/java/org/apache/cassandra/cql3/PasswordObfuscator.java
##########
@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * Obfuscates passwords in a given string
+ */
+public class PasswordObfuscator
+{
+    public static final String OBFUSCATION_TOKEN = ""*******"";
+    private static final String PASSWORD_TOKEN = ""password"";
+
+    private static final int PATTERN_FLAGS = Pattern.CASE_INSENSITIVE | Pattern.DOTALL;
+
+    private static final Pattern PASSWORD_PATTERN = Pattern.compile("".*password\\s*=?\\s*'(?<password>.*)'.*"", PATTERN_FLAGS);

Review comment:
       I think there might be even more use cases and I am wondering whether really the regex is the best option. I need to test more though. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 17:27;githubbot;600","smiklosovic opened a new pull request #1059:
URL: https://github.com/apache/cassandra/pull/1059


   patch by Sumanth Pasupuleti; reviewed by Stefan Miklosovic and Vinay Chella for CASSANDRA-16669


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:19;githubbot;600","alex-ninja commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649751658



##########
File path: src/java/org/apache/cassandra/cql3/PasswordObfuscator.java
##########
@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+/**
+ * Obfuscates passwords in a given string
+ */
+public class PasswordObfuscator
+{
+    public static final String OBFUSCATION_TOKEN = ""*******"";
+    private static final String PASSWORD_TOKEN = ""password"";
+
+    public String obfuscate(String sourceString)

Review comment:
       I guess it is not the final version because the existing tests should fail. The issues I can think of:
   1. the last part of the query (that is located after the password) is rejected, but the password is not always the last statement
   2. the query may have multiple password statements (actual for `BATCH`), there should be a loop
   3. password value is quoted, I do not see any logic to calculate indexes of `'`
   

##########
File path: src/java/org/apache/cassandra/cql3/PasswordObfuscator.java
##########
@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+/**
+ * Obfuscates passwords in a given string
+ */
+public class PasswordObfuscator
+{
+    public static final String OBFUSCATION_TOKEN = ""*******"";
+    private static final String PASSWORD_TOKEN = ""password"";
+
+    public String obfuscate(String sourceString)

Review comment:
       ok, that makes sense to me!




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:28;githubbot;600","smiklosovic closed pull request #1059:
URL: https://github.com/apache/cassandra/pull/1059


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:28;githubbot;600","sumanth-pasupuleti commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649706756



##########
File path: src/java/org/apache/cassandra/cql3/PasswordObfuscator.java
##########
@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * Obfuscates passwords in a given string
+ */
+public class PasswordObfuscator
+{
+    public static final String OBFUSCATION_TOKEN = ""*******"";
+    private static final String PASSWORD_TOKEN = ""password"";
+
+    private static final int PATTERN_FLAGS = Pattern.CASE_INSENSITIVE | Pattern.DOTALL;
+
+    private static final Pattern PASSWORD_PATTERN = Pattern.compile("".*password\\s*=?\\s*'(?<password>.*)'.*"", PATTERN_FLAGS);

Review comment:
       Replacing regex with a simpler approach (initial version of the patch) of obfuscating everything after password keyword, similar to what postgres audit does

##########
File path: src/java/org/apache/cassandra/cql3/QueryEvents.java
##########
@@ -205,7 +219,7 @@ public void notifyPrepareSuccess(Supplier<QueryHandler.Prepared> preparedProvide
                 try
                 {
                     for (Listener listener : listeners)
-                        listener.prepareSuccess(prepared.statement, query, state, queryTime, response);
+                        listener.prepareSuccess(prepared.statement, possiblyObfuscateQuery(prepared.statement, query), state, queryTime, response);

Review comment:
       We do, thanks for catching this. fixed.

##########
File path: test/unit/org/apache/cassandra/audit/AuditLoggerAuthTest.java
##########
@@ -38,6 +38,8 @@
 import org.apache.cassandra.config.OverrideConfigurationLoader;
 import org.apache.cassandra.config.ParameterizedClass;
 import org.apache.cassandra.cql3.CQLTester;
+import org.apache.cassandra.cql3.PasswordObfuscator;
+import org.apache.cassandra.cql3.QueryEvents;

Review comment:
       fixed

##########
File path: test/unit/org/apache/cassandra/cql3/PasswordObfuscatorTest.java
##########
@@ -0,0 +1,160 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import org.junit.Ignore;
+import org.junit.Test;
+
+import static java.lang.String.format;
+import static org.junit.Assert.assertEquals;
+
+public class PasswordObfuscatorTest
+{
+    private static final PasswordObfuscator obfuscator = new PasswordObfuscator();
+
+    @Test
+    public void testCreatRoleWithLoginPriorToPassword()
+    {
+        assertEquals(format(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testCreatRoleWithLoginAfterPassword()
+    {
+        assertEquals(format(""CREATE ROLE role1 WITH password = '%s' AND LOGIN = true"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE ROLE role1 WITH password = '123' AND LOGIN = true""));
+    }
+
+    @Test
+    public void testCreateRoleWithoutPassword()
+    {
+        assertEquals(""CREATE ROLE role1"", obfuscator.obfuscate(""CREATE ROLE role1""));
+    }
+
+    @Test
+    public void testAlterRoleWithPassword()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithPasswordNoSpace()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD='%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD='123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithPasswordNoImmediateSpace()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD= '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD= '123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithoutPassword()
+    {
+        assertEquals(""ALTER ROLE role1"", obfuscator.obfuscate(""ALTER ROLE role1""));
+    }
+
+    @Test
+    public void testCreateUserWithPassword()
+    {
+        assertEquals(format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD '123'""));
+    }
+
+    @Test
+    public void testCreateUserWithoutPassword()
+    {
+        assertEquals(""CREATE USER user1"", obfuscator.obfuscate(""CREATE USER user1""));
+    }
+
+    @Test
+    public void testAlterUserWithPassword()
+    {
+        assertEquals(format(""ALTER USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with PASSWORD '123'""));
+    }
+
+    @Test
+    public void testAlterUserWithPasswordMixedCase()
+    {
+        assertEquals(format(""ALTER USER user1 with paSSwoRd '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with paSSwoRd '123'""));
+    }
+
+    @Test
+    public void testAlterUserWithPasswordWithNewLine()
+    {
+        assertEquals(format(""ALTER USER user1 with PASSWORD\n'%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with PASSWORD\n'123'""));
+    }
+
+    @Test
+    public void testPasswordWithNewLinesObfuscation()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD 'a\nb'""));
+    }
+
+    @Test
+    public void testEmptyPasswordObfuscation()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD ''""));
+    }
+
+    @Test
+    public void testPasswordWithSpaces()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD 'p a ss wor d'""));
+    }
+
+    @Test
+    public void testSimpleBatch()
+    {
+        assertEquals(format(""BEGIN BATCH \n"" +
+                            ""    CREATE ROLE alice1 WITH PASSWORD = '%s' and LOGIN = true; \n"" +
+                            ""APPLY BATCH;"",
+                            PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""BEGIN BATCH \n"" +
+                                          ""    CREATE ROLE alice1 WITH PASSWORD = 'alice123' and LOGIN = true; \n"" +
+                                          ""APPLY BATCH;""));
+    }
+
+    @Test
+    @Ignore

Review comment:
       This is now resolved with the simpler logic of obfuscating everything after the first password occurrence

##########
File path: src/java/org/apache/cassandra/cql3/QueryEvents.java
##########
@@ -235,6 +250,12 @@ public void notifyPrepareFailure(@Nullable CQLStatement statement, String query,
         }
     }
 
+    private String possiblyObfuscateQuery(CQLStatement statement, String query)
+    {
+        // statement might be null as side-effect of failed parsing, originates from QueryMessage#execute

Review comment:
       fixed.

##########
File path: test/unit/org/apache/cassandra/cql3/PasswordObfuscatorTest.java
##########
@@ -0,0 +1,160 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+import org.junit.Ignore;
+import org.junit.Test;
+
+import static java.lang.String.format;
+import static org.junit.Assert.assertEquals;
+
+public class PasswordObfuscatorTest
+{
+    private static final PasswordObfuscator obfuscator = new PasswordObfuscator();
+
+    @Test
+    public void testCreatRoleWithLoginPriorToPassword()
+    {
+        assertEquals(format(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE ROLE role1 WITH LOGIN = true AND PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testCreatRoleWithLoginAfterPassword()
+    {
+        assertEquals(format(""CREATE ROLE role1 WITH password = '%s' AND LOGIN = true"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE ROLE role1 WITH password = '123' AND LOGIN = true""));
+    }
+
+    @Test
+    public void testCreateRoleWithoutPassword()
+    {
+        assertEquals(""CREATE ROLE role1"", obfuscator.obfuscate(""CREATE ROLE role1""));
+    }
+
+    @Test
+    public void testAlterRoleWithPassword()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD = '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD = '123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithPasswordNoSpace()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD='%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD='123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithPasswordNoImmediateSpace()
+    {
+        assertEquals(format(""ALTER ROLE role1 with PASSWORD= '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER ROLE role1 with PASSWORD= '123'""));
+    }
+
+    @Test
+    public void testAlterRoleWithoutPassword()
+    {
+        assertEquals(""ALTER ROLE role1"", obfuscator.obfuscate(""ALTER ROLE role1""));
+    }
+
+    @Test
+    public void testCreateUserWithPassword()
+    {
+        assertEquals(format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD '123'""));
+    }
+
+    @Test
+    public void testCreateUserWithoutPassword()
+    {
+        assertEquals(""CREATE USER user1"", obfuscator.obfuscate(""CREATE USER user1""));
+    }
+
+    @Test
+    public void testAlterUserWithPassword()
+    {
+        assertEquals(format(""ALTER USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with PASSWORD '123'""));
+    }
+
+    @Test
+    public void testAlterUserWithPasswordMixedCase()
+    {
+        assertEquals(format(""ALTER USER user1 with paSSwoRd '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with paSSwoRd '123'""));
+    }
+
+    @Test
+    public void testAlterUserWithPasswordWithNewLine()
+    {
+        assertEquals(format(""ALTER USER user1 with PASSWORD\n'%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""ALTER USER user1 with PASSWORD\n'123'""));
+    }
+
+    @Test
+    public void testPasswordWithNewLinesObfuscation()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD 'a\nb'""));
+    }
+
+    @Test
+    public void testEmptyPasswordObfuscation()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD ''""));
+    }
+
+    @Test
+    public void testPasswordWithSpaces()
+    {
+        assertEquals(String.format(""CREATE USER user1 with PASSWORD '%s'"", PasswordObfuscator.OBFUSCATION_TOKEN),
+                     obfuscator.obfuscate(""CREATE USER user1 with PASSWORD 'p a ss wor d'""));

Review comment:
       resolving since we moved to a simpler logic from using regex




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:29;githubbot;600","smiklosovic commented on a change in pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043#discussion_r649805220



##########
File path: src/java/org/apache/cassandra/cql3/PasswordObfuscator.java
##########
@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.cql3;
+
+/**
+ * Obfuscates passwords in a given string
+ */
+public class PasswordObfuscator
+{
+    public static final String OBFUSCATION_TOKEN = ""*******"";
+    private static final String PASSWORD_TOKEN = ""password"";
+
+    public String obfuscate(String sourceString)

Review comment:
       hi @alex-ninja , the way to do it ""properly"" - covering all the cases possible, it not so simple at all, it gets complicated pretty quickly and there is still yet some other corner case not covered. This whole feature has to be treated differently by parsing CQL via ANTLR (ideally) and just replacing password tokens there - that is the direction we would like to see ideally drift towards, but due to lack of time to implement that and due to refactoring related so close before the release, we just come with ""simple and stupid"" solution which would obfuscate just everything after `password`, even though it would render the whole CQL statement invalid. The fact that the passwords are not leaked - and we have to be 100% sure of that, is more important than having these clauses obfuscated nicely. We can deal with that later.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:37;githubbot;600","smiklosovic opened a new pull request #1060:
URL: https://github.com/apache/cassandra/pull/1060


   patch by Sumanth Pasupuleti; reviewed by Stefan Miklosovic and Vinay Chella for CASSANDRA-16669


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:44;githubbot;600","smiklosovic closed pull request #1060:
URL: https://github.com/apache/cassandra/pull/1060


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Jun/21 09:03;githubbot;600","smiklosovic closed pull request #1043:
URL: https://github.com/apache/cassandra/pull/1043


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Jun/21 09:03;githubbot;600","smiklosovic closed pull request #1028:
URL: https://github.com/apache/cassandra/pull/1028


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Jun/21 09:04;githubbot;600",,,,,,,,,,,,,,,,,0,24000,,,0,24000,,,,,,,,,,,,,,,,,,,CASSANDRA-16801,,,,,,,,,,,,,,,,,,,0.0,sumanth.pasupuleti,,,,,,,,,,,,,,,,,,,,Operability,Normal,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,Security,,Tue Jun 15 15:54:48 UTC 2021,,,,,,,All,,,,"0|z0r1tc:",9223372036854775807,,,,bereng,e.dimitrova,smiklosovic,vinaykumarcse,,,4.0-alpha1,,https://github.com/apache/cassandra/commit/f978bea272409109e312a27a121f849879650bdb,,,,,,,,,"[https://github.com/ekaterinadimitrova2/cassandra/pull/140]

Additional tests and docs added as part of the patch",,,,,"15/May/21 07:06;stefan.miklosovic;Hi [~sumanth.pasupuleti],

hit me if you want a reviewer / committer, I think I can manage to get this to trunk.;;;","17/May/21 02:22;sumanth.pasupuleti;Thanks [~stefan.miklosovic]. I should be ready with a patch in a day or two.;;;","25/May/21 08:38;stefan.miklosovic;Hi [~sumanth.pasupuleti], any progress?;;;","28/May/21 21:37;sumanth.pasupuleti;Here is the first version of the patch https://github.com/apache/cassandra/pull/1028.

This follows a rather less complicated approach of obfuscating anything that follows ""password"" token in the DCL query, inspired from what the [PostgreSQL Audit Extension (pgAudit)|https://github.com/pgaudit/pgaudit/blob/master/pgaudit.c#L489-L535] does. ;;;","29/May/21 07:36;stefan.miklosovic;Thanks [~sumanth.pasupuleti], I will review on Monday morning CEST.;;;","31/May/21 07:13;stefan.miklosovic;Hi [~sumanth.pasupuleti],

thanks for the patch.

1) Are you aware of ecaudit from Ericsson? They did this obfuscation very robustly, treating new lines, obfuscating just passwords and so on. I do not think we should be inspired by what PG audit does when there is obviously more appropriate solution already existing. Check this (1) and (2). We can nicely obfuscate just passwords leaving other parts untouched.

(1) [https://github.com/Ericsson/ecaudit/issues/170]

(2) [https://github.com/emolsson/ecaudit/blob/f01e3c1f75a9df2d767abc051b5b224d9b6c66f9/ecaudit/src/main/java/com/ericsson/bss/cassandra/ecaudit/obfuscator/PasswordObfuscator.java]

2) Do you think that we would ever have a need to see these passwords _not_ obfuscated? What is the use case? Why would we want to see them in plaintext? I am not sure we ever need this, even it is configurable. I just do not see the reason for that configuration option to exist. It would also simplify the code.

3) I prefer to change the obfuscation string from ""<OBFUSCATED>"" to ""*******"" as ecaudit has it to be somehow ""compatible"". If people are migrating from that to our stuff, it would be nice to have the least amount of differencies here.

4) I would prefer to have a separate class which would implement obfuscator interface where this logic would be done. It would be also better testable and so on - encapsulating all the logic just there. 

 ;;;","01/Jun/21 04:13;vinaykumarcse;Thanks for the patch [~sumanth.pasupuleti], good test coverage for the patch.

Few comments from my first glance.
 * I +1 [~stefan.miklosovic] comment on the option to enable password obfuscation. Why should obfuscate_password be an option? the database should not allow logging passwords in plain text files.

 * Why did you choose to obfuscate passwords in AuditLogging vs QueryEvents? What is your stance on password being visible in FQL or other subscribers of QueryEvents?
 * Please update the documentation with the details of password obfuscation.;;;","03/Jun/21 06:42;sumanth.pasupuleti;Thanks [~stefan.miklosovic] and [~vinaykumarcse] for the feedback.

I've incorporated following updates and the [PR|https://github.com/apache/cassandra/pull/1028] reflects the changes.
1. I changed obfuscation logic to just replace the password with ****** and retain rest of the operation string.
2. Having thought about it again, I agree we may not need a toggle to turn off password obfuscation for audit logging. I've now removed the configurable, and we now always obfuscate password for DCL statements
3. Extracted obfuscation logic into its own (singleton) class that implements an interface.
4. Added test cases specific to password obfuscation logic.
5. Audit logging documentation has been updated to reflect this change about obfuscating passwords

With regards to ""Why did you choose to obfuscate passwords in AuditLogging vs QueryEvents? What is your stance on password being visible in FQL or other subscribers of QueryEvents?"",
1. Given that QueryEvents is a centralized common emitter of events to all registered listeners, choosing to obfuscate password in QueryEvents would force the obfuscation behavior to all the registered listeners vs leaving that decision to individual listeners. This is the reason why I chose to keep this obfuscation change localized to AuditLogging.
2. My stance on password visibility in FQL is that, given FQL is meant to replay traffic to achieve identical results, I would vote for password staying visible in FQL.

Please let me know if you have further feedback on the updated PR.;;;","03/Jun/21 14:34;stefan.miklosovic;Thanks [~sumanth.pasupuleti]

after initial scan, this looks way better. I will review closely again very soon.;;;","04/Jun/21 14:16;stefan.miklosovic;Hi [~sumanth.pasupuleti]

I added few minor improvements into this branch of mine [https://github.com/sumanth-pasupuleti/cassandra/pull/3/files]

All you did is fine with me it is just about moving it over the line and it is just hard to tell exactly how it should be and so on. I hope you are not finding this offensive, I really just try to move this forward soon and doing communication ping-pong is quite time consuming. To make review more comfortable, maybe you could include these changes into your branch and squash so the final review is easier for everybody.

You will be still the original author of the work after we squash it.

Please go over it and tell me what you think.

I am running the build here: https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/842/;;;","04/Jun/21 15:21;vinaykumarcse;Thank you for the update [~sumanth.pasupuleti]. I left a few nitpicks (doc updates and few more specific tests covering regex) on your PR.
{quote}1. Given that QueryEvents is a centralized common emitter of events to all registered listeners, choosing to obfuscate password in QueryEvents would force the obfuscation behavior to all the registered listeners vs leaving that decision to individual listeners. This is the reason why I chose to keep this obfuscation change localized to AuditLogging.
 2. My stance on password visibility in FQL is that given FQL is meant to replay traffic to achieve identical results, I would vote for password staying visible in FQL.
{quote}
SGTM, thanks to [~stefan.miklosovic] for asking about FQL password obfuscation on dev list, I would love to hear other's opinions on this,;;;","04/Jun/21 19:03;sumanth.pasupuleti;[~stefan.miklosovic] [~vinaykumarcse] Incorporated your review comments. Please verify and let me know if you have further feedback. https://github.com/apache/cassandra/pull/1028

>I hope you are not finding this offensive
Absolutely not :), one of the biggest advantage working as a community is to improve and provide quality patches, so please keep the feedback coming.

[~stefan.miklosovic] jfyi, I merged your PR but made slight modifications to comments in IObfuscator to keep it generic from PasswordObfuscator. I added specific comments in PasswordObfuscator.;;;","04/Jun/21 19:50;stefan.miklosovic;[~sumanth.pasupuleti] superb stuff, I will run all the builds soonish, I still wait to see what we do about FQL though.;;;","07/Jun/21 05:01;sumanth.pasupuleti;[~stefan.miklosovic] Thank you. Meanwhile, here is the patch against QueryEvents that would apply obfuscation to all the listeners like AuditLogger and FullQueryLogger - https://github.com/apache/cassandra/pull/1043/files

All UTs and JVMDtests pass except for one that seems unrelated (incompletePropose jvm dtest failed with timeout)
https://app.circleci.com/pipelines/github/sumanth-pasupuleti/cassandra?branch=feature%2FCASSANDRA-16669-queryevents-ut
JVMDtest re-run succeeded (https://app.circleci.com/pipelines/github/sumanth-pasupuleti/cassandra/67/workflows/fa067000-181f-4ceb-8998-78e39f26e00e/jobs/1343/tests);;;","09/Jun/21 22:15;stefan.miklosovic;Hi [~sumanth.pasupuleti],

I have covered one corner case here:

[https://github.com/instaclustr/cassandra/commit/1b19a8257340118aa9423d8e8bb40ed0e327ecb5]

I saw this kind of entry in audit logs:

LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:49190|timestamp:1623273348839|type:REQUEST_FAILURE|category:ERROR|operation:ALTER USER stefan3 WITH PASSWORD = 'bleble';; line 1:33 mismatched input '=' expecting STRING_LITERAL (ALTER USER stefan3 WITH PASSWORD [=]...)

That happens when somebody executes an invalid cql statement. It should be _without_ that ""="" (interesting why it is like that though).

That statement is then not an instance of AuthenticationStatement because it failed to be instantiated in QueryMessage#execute which means that an exception is caught in its catch block and it is propagated to 

QueryEvents.instance.notifyQueryFailure as ""null"".

""null"" is not an instance of AuthenticationStatement so obfuscation is skipped.

My fix consists of obfuscating if statement is null every time. I also obfuscate in AuditLogManager where log with exception is treated because there an exception message appended to that log entry and just to be safe I rather obfuscate it there as well.;;;","10/Jun/21 04:24;e.dimitrova;Hi all,

First of all, great job.

Feedback/questions:
 * I guess you opted in for the centralized solution and maybe the question is whether we want the users to be given the chance not to obfuscate passwords if they want to when they use FQL? Is that correct?  
 * The ticket is still work in progress not in review but I made a review on the latest pull request as I see everyone was working on it lately and I had the impression that is what was decided? 
 * I think we might want to add tests for the corner cases identified in the previous comment by Stefan. (Great catch!) Also, I found one more weird corner case which Stefan's patch took care of. If a user does an invalid batch request including DCL - that would be logged as below with the password still being _password_a_:

{code:java}
INFO  [Native-Transport-Requests-1] 2021-06-09 23:38:05,965 FileAuditLogger.java:51 - user:anonymous|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:63360|timestamp:1623296285965|type:REQUEST_FAILURE|category:ERROR|operation:BEGIN BATCH CREATE ROLE alice WITH PASSWORD = 'password_a' AND LOGIN = true; CREATE ROLE new_role; APPLY BATCH;; line 1:12 mismatched input 'CREATE' expecting K_APPLY (BEGIN BATCH [CREATE]...){code}
I know it is highly unlikely to happen but It was there and Stefan's latest patch takes care of it. We might want to add a test for that edge case too 

 * I didn't see [this question |https://github.com/apache/cassandra/pull/1043/commits/07990ebaba79e6d9553de14733e28d89caa5e171#diff-df97ca69d481fde559e155c724ca60967a1e57222ea845d8ee8299d7b014df46R86] being resolved
 * Do we need an interface? What other implementations are planned? 
 * I believe the rest is nits on the PR itself.

I will make another pass tomorrow morning again;;;","10/Jun/21 04:30;e.dimitrova;One more comment which probably we can address in a new ticket for improvement:
{code:java}
cqlsh> CREATE ROLE role1 WITH PASSWORD = 'me' AND LOGIN = true;
InvalidRequest: Error from server: code=2200 [Invalid query] message=""org.apache.cassandra.auth.CassandraRoleManager doesn't support PASSWORD""
cqlsh> CREATE ROLE role1;
Unauthorized: Error from server: code=2100 [Unauthorized] message=""You have to be logged in and not anonymous to perform this request""
{code}
I believe the first error message might be confusing for a user.  ;;;","10/Jun/21 13:20;stefan.miklosovic;Hi [~e.dimitrova]
 * we decided on not providing a user any possibility to not obfuscated passwords. We do not see any use case behind that. Why would you want to have them in plain text in the first place?
 * yes, still WIP be we were about to close the last bits but we found more issues

This batch issue is rather complicated, it also leaks stuff like this: 
{code:java}
BEGIN BATCH
   CREATE ROLE alice WITH PASSWORD = 'alice123' and LOGIN = true;
   CREATE ROLE alice2 WITH PASSWORD = 'alice2123' and LOGIN = true;
APPLY BATCH;{code}
The entry, currently, looks like:

 
{code:java}
Type: audit
LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:56698|timestamp:1623322819632|type:REQUEST_FAILURE|category:ERROR|operation:BEGIN BATCH
CREATE ROLE alice WITH PASSWORD = 'alice123' and LOGIN = true;
CREATE ROLE alice2 WITH PASSWORD = '*******' and LOGIN = true;
APPLY BATCH;; line 2:0 mismatched input 'CREATE' expecting K_APPLY (BEGIN BATCH[CREATE]...){code}
I started to fix this but that is more complicated than it looks so I am not fixing it as of now.
 * I added it to my commits
 * thinking more about it, we do not need an interface tbh, I was thinking we do but it is not necessary, if we ever needed that, we might just create one afterwards so we should return to simple impl, sorry for the mess.
 * I addressed your issues

The problem with adding a test for failing request like that is that I can not receive it in the tests of AuditAuthLoggerTest, if I want to do something like this:
{code:java}
@Test
public void testREQUEST_FAILUREAuditing()
{
    createTestRole();
    String cql = ""BEGIN BATCH \n"" +
                 ""    CREATE ROLE alice WITH PASSWORD = 'alice123' and LOGIN = true; \n"" +
                 ""APPLY BATCH"";
    executeWithCredentials(Arrays.asList(cql), CASS_USER, CASS_PW, AuditLogEntryType.REQUEST_FAILURE);
    assertTrue(getInMemAuditLogger().size() > 0);
    AuditLogEntry logEntry = getInMemAuditLogger().poll();
    assertLogEntry(logEntry, AuditLogEntryType.REQUEST_FAILURE, cql, CASS_USER);
}
{code}
the method ""executeWithCredentials"" will fails as such so the test will never proceed because the underlying driver evaluates this as a failure and it throws an exception and whole test fails so I think it is enough to test this empirically of you do not have any idea how to actually solve this. We might add a test which tests the obfuscator though, there is not any problem with that. 

[~sumanth.pasupuleti] I have put these things together here [https://github.com/instaclustr/cassandra/tree/CASSANDRA-16669-queryevents]

I do not know why but I am not able to create a pull request against your branch anymore.

 ;;;","10/Jun/21 14:21;e.dimitrova;{quote}bq.  {color:#172b4d}we decided on not providing a user any possibility to not obfuscated passwords. We do not see any use case behind that. Why would you want to have them in plain text in the first place?{color}
{quote}
 

Benjamin pointed me correctly to the mailing list that was agreed already, my bad. 
{quote} * yes, still WIP be we were about to close the last bits but we found more issues{quote}
That is fine, I will continue testing and thinking of other cases. Thank you for addressing my comments and looking into the BATCH part. Please, let me know if I can help with something there.
{quote} * thinking more about it, we do not need an interface tbh, I was thinking we do but it is not necessary, if we ever needed that, we might just create one afterwards so we should return to simple impl, sorry for the mess.{quote}
I think it was needed with the initial solution but not with the centralized one. Thanks for removing it. Not a mess, it is just still work in progress. Appreciate all your efforts. 
{quote}We might add a test which tests the obfuscator though, there is not any problem with that. 
{quote}
What test do you have in mind? I will think about it too. ;;;","10/Jun/21 18:32;e.dimitrova;I have one main concern here and it is that we might be missing cases with the regex and it is hard to cover all possible corner cases. Also, one little change somewhere in behavior can break it. Did anyone of you think about a more robust way to extract only the PASSWORD value? I just wanted to run the idea here before I start digging into that. Also, if this is not really an option with this patch, should we consider going back to Vinay's idea from the dev mailing list to exclude the DCL statements for 4.0.0 and finish the obfuscation for 4.0.1? ;;;","10/Jun/21 19:06;jjordan;I would suggest going back to the simplified version for 4.0.0.

bq. This follows a rather less complicated approach of obfuscating anything that follows ""password"" token in the DCL query, inspired from what the PostgreSQL Audit Extension (pgAudit) does.

That or just excluding all CREATE/ALTER ROLE DCL statements.

There can then be a follow up ticket that actually uses the ANTLR grammar parsed statement to pull out the password field and only remove that, if it is what people want.;;;","10/Jun/21 19:10;brandon.williams;bq. I would suggest going back to the simplified version for 4.0.0.

+1 to that and following up with ANTLR later.  I don't think we have the resources for the full proper solution at this point in time in the release cycle.;;;","10/Jun/21 19:21;e.dimitrova;One suggestion is to get as intermediate solution to the initial proposal based on Postgre for 4.0.0 so we can have something better than removing DCL as a whole but to work on the robust solution to obfuscate only the particular password field in 4.0.1. Not perfect but intermediate and we can take the time to do a robust solution. Any thoughts anyone? I am open for brainstorming, looking into it with Sumanth and Stefan in Slack at the moment. ;;;","10/Jun/21 19:26;e.dimitrova;Our comments crashed, thank you [~jjordan] and [~brandon.williams] for looking into this. ;;;","10/Jun/21 20:44;vinaykumarcse;I am on +1 on 
{quote}I would suggest going back to the simplified version for 4.0.0.
{quote}
It is better than excluding DCL, and an operator mistake/oops could lead to exposing passwords, so I feel this is better.;;;","11/Jun/21 13:31;e.dimitrova;Thank you all! [~sumanth.pasupuleti] already updated his PR and I am starting another round of review. ;;;","11/Jun/21 13:43;stefan.miklosovic;Hey, I am running builds, I target the merging on Monday to sleep on it.;;;","11/Jun/21 18:39;sumanth.pasupuleti;I am out due to emergency. [~vinaykumarcse] / [~stefan.miklosovic] / [~e.dimitrova] please take the patch forward, thank you!;;;","12/Jun/21 00:28;e.dimitrova;Thank you [~sumanth.pasupuleti] for all your work. I spent some time on the patch today and I did also a lot of additional manual testing to be sure about my understanding about how things work. 

Attached is a [PR |https://github.com/ekaterinadimitrova2/cassandra/pull/140] containing your [commit |https://github.com/ekaterinadimitrova2/cassandra/pull/140/commits/b2ed399c0818c0d3616fdb353a089829be469d3e] and [commit |https://github.com/ekaterinadimitrova2/cassandra/pull/140/commits/3b57f9ccfc6cec0a677463bc1f0cef722d61dbab] with my small review comments. The new tests are all passing locally for me. 

I added a few sentences to the docs to reflect the current limitations around password obfuscation.

I am currently running full CI - [Java 8 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/954/workflows/5e3fa9b6-0c5f-443a-880f-7635d04cea18] | [Java 11 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/954/workflows/edb2b149-f237-4302-8814-3c41b8fb9035]

I was thinking of more tests to add but after running more FQL and the AuditLogging locally I think the current suite satisfies the needs as we have a centralized solution within the _QueryEvents_. [~vinaykumarcse], please, correct me if I am wrong as you are the author and you might have some additional deep knowledge. Please let me know If you want me to add something more.

Currently we obfuscate with ******** everything after the word password in a DCL statement record so I would expect more information than less to be obfuscated. 

 

*NOTE:* On green CI and +1 from [~vinaykumarcse] I will propagate to cassandra-4.0 and trunk branches and commit. I was informed by [~aholmber]  that [~stefan.miklosovic] agreed if we are done before he is back next week to merge the change on +1 from me and [~vinaykumarcse] so we can unblock the 4.0 RC2

I am +1 to the patch on green CI completion. I will check back a bit later tonight if there are any new failures.

 ;;;","12/Jun/21 02:13;e.dimitrova;There is one [single failure |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/954/workflows/5e3fa9b6-0c5f-443a-880f-7635d04cea18/jobs/5693] which is not related. ;;;","15/Jun/21 06:16;vinaykumarcse;[~e.dimitrova] Latest changes LGTM, except for a couple of minor nitpicks at latest [PR|https://github.com/ekaterinadimitrova2/cassandra/pull/140].

I confirm that the local testing of valid/invalid DCL statements obfuscated passwords

*before*
{code:java}
Type: audit
LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:62542|timestamp:1621049034578|type:REQUEST_FAILURE|category:ERROR|operation:CREATE ROLE bob WITH PASSWORD='password_b' AND LOGIN = true AND SUPERUSER = true;; bob already exists
Type: audit
LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:62542|timestamp:1621049057271|type:REQUEST_FAILURE|category:ERROR|operation:CREATE ROLE bob WITH PASSWORD='password_b' AND LOGIN = true AND SUPERUSER = true;; bob already exists

{code}
*after*
{code:java}
Type: audit
LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:59634|timestamp:1623736337400|type:REQUEST_FAILURE|category:ERROR|operation:CREATE ROLE bob WITH PASSWORD *******; bob already exists
Type: audit
LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:59634|timestamp:1623736351148|type:REQUEST_FAILURE|category:ERROR|operation:CREATE ROLE bob1 WITH PASSWORD *******; bob1 already exists
Type: audit
LogMessage: user:cassandra|host:localhost/127.0.0.1:7000|source:/127.0.0.1|port:59634|timestamp:1623736356902|type:CREATE_ROLE|category:DCL|operation:CREATE ROLE bob12 WITH PASSWORD *******
{code}
*CircleCI Tests:*
 I could not run tests due to circleci account restrictions on my side, so I am leaning your test results.;;;","15/Jun/21 07:29;bereng;I wanted to give a hand here and went over the PR. I focused on:
- Invalid stmnts which do indeed obfuscate
- Bypassing Audit logging through: inline cql comments, lexer & parser token hacking and similar corner cases
- Generic review

And my feedback would be:
- Add a test case for {{CREATE /\*password\*/ ROLE bla bla}} which would be a way to bypass
- In the future move to lexer/parser level obfuscation
- You can only hack the thing with useless stmnts like {{ALTER ROLE alicepassword...}} that lead nowhere
- So overall +1;;;","15/Jun/21 07:50;stefan.miklosovic;I think we complicate this already, I am just fine how it is with a test from Vinay in GH I added. I am going to merge this today.;;;","15/Jun/21 07:59;stefan.miklosovic;https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/864/;;;","15/Jun/21 15:54;e.dimitrova;Thank you all for your work!

For visibility and the sake of completeness:
 * There is a failure in the Jenkins devbranch run which is because the branch with the patch was not rebased so the [patch|https://github.com/apache/cassandra/commit/a0af091a5cbceeaa2b8f724b1790b61ef512b033] for which the failing test was created was missing. No new failures introduced by this patch. The post-commit CI is still running but the cqlsh tests are already [successfully completed|https://jenkins-cm4.apache.org/blue/organizations/jenkins/Cassandra-4.0.0/detail/Cassandra-4.0.0/27/pipeline].
 *  

{quote} - Add a test case for {{CREATE /*password*/ ROLE bla bla}} which would be a way to bypass
 - In the future move to lexer/parser level obfuscation

 - You can only hack the thing with useless stmnts like {{ALTER ROLE alicepassword...}} that lead nowhere{quote}
These cases are covered in the latest patch as the patch is simple and drastic at this point until we work on the mentioned improvement for 4.0.1, It simply takes the DCL statement as a String and checks for password substring (upper case, mixed case, and lower case covered) and then obfuscates everything after it; non-valid statements are also covered which is visible from the test added by Vinay.;;;",,,,,,,,,,,,,,,,,,
Intermittent failure of SEPExecutorTest.changingMaxWorkersMeetsConcurrencyGoalsTest caused by race condition when shrinking maximum pool size to zero,CASSANDRA-16668,13378373,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mfleming,mfleming,mfleming,13/May/21 21:13,27/May/22 19:25,13/Jul/23 08:40,21/May/21 18:34,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Local/Other,,,,0,,,"A difficult-to-hit race condition exists in changingMaxWorkersMeetsConcurrencyGoalsTest when changing the maximum pool size from 0 -> 4 which results in the test failing like so:

{{junit.framework.AssertionFailedError: Test tasks did not hit max concurrency goal expected:<true> but was:<false>junit.framework.AssertionFailedError: Test tasks did not hit max concurrency goal expected:<true> but was:<false> at org.apache.cassandra.concurrent.SEPExecutorTest.assertMaxTaskConcurrency(SEPExecutorTest.java:198) at org.apache.cassandra.concurrent.SEPExecutorTest.changingMaxWorkersMeetsConcurrencyGoalsTest(SEPExecutorTest.java:132)}}

I can hit this issue maybe 2/3 times for every 100 invocations of the unit test.

The issue that causes the failure is that if tasks are still enqueued when the maximum pool size is set to zero and if all of the SEPWorker threads enter the STOP state before the pool size is bumped to 4, then no SEPWorker threads will be spun up to service the task queue. This causes the above error.

Why don't we spin up SEPWorker threads when enqueing tasks? Because of the guard logic in addTask: [https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/concurrent/SEPExecutor.java#L113,L121]

In this scenario taskPermits will not be zero (because we have tasks on the queue) so we never call {{maybeStartSpinningWorker()}}.

A trick to make this issue much easier to hit is to insert a {{Thread.sleep(500)}} immediately after setting the pool size to zero. This has the effect of guaranteeing that all SEPWorker threads will be STOP'd before enqueueing more work.

Here's a fix that attempts to spin up an SEPWorker whenever we grow the number of work permits: https://github.com/mfleming/cassandra/commit/071516d29e41da9924af24e8002822d3c6af0e01",,adelapena,e.dimitrova,jmeredithco,mfleming,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-15709,,,,,,,,,,,,,,,,,,,,,,,0.0,mfleming,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri May 21 18:34:02 UTC 2021,,,,,,,All,,,,"0|z0r0ps:",9223372036854775807,,,,adelapena,e.dimitrova,jmeredithco,,Low,,,,https://github.com/apache/cassandra/commit/8cd02afce972ecaf0e0cf0fe09c610d67d9af9c5,,,,,,,,,[https://github.com/mfleming/cassandra/commit/071516d29e41da9924af24e8002822d3c6af0e01],,,,,"13/May/21 21:36;e.dimitrova;Jenkins [CI run | https://jenkins-cm4.apache.org/job/Cassandra-devbranch/776/];;;","17/May/21 12:35;adelapena;Here are 10K runs of {{SEPExecutorTest}} with the patch, using the [CircleCI multiplexer|https://github.com/apache/cassandra/blob/trunk/doc/source/development/testing.rst#circleci]:
 * [j8-j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/457/workflows/cb5b1d27-75d4-4b3a-814c-04454fb4f4ef/jobs/4017]
 * [j8-j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/457/workflows/cb5b1d27-75d4-4b3a-814c-04454fb4f4ef/jobs/4015]
 * [j11-j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/457/workflows/1b82f571-9dd8-4a98-892b-1c0e3704f2d9/jobs/4013]

It seems that {{changingMaxWorkersMeetsConcurrencyGoalsTest}} happily survives the three 10K runs, but there are some uncommon failures on {{shutdownTest}}:
 * [j8-j8 runner 62 iteration 49|https://4017-85817267-gh.circle-artifacts.com/62/stdout/fails/049/testsome-org.apache.cassandra.concurrent.SEPExecutorTest.txt]
 * [j8-j11 runner 73 iteration 9|https://4015-85817267-gh.circle-artifacts.com/73/stdout/fails/009/testsome-org.apache.cassandra.concurrent.SEPExecutorTest.txt]
 * [j11-j11 runner 68 iteration 51|https://4013-85817267-gh.circle-artifacts.com/68/stdout/fails/051/testsome-org.apache.cassandra.concurrent.SEPExecutorTest.txt]

Not sure whether that is related or an independent failure.;;;","18/May/21 13:21;mfleming;I think that failure is probably unrelated because we saw similar failures for shutdownTest before this patch here [https://app.circleci.com/pipelines/github/adelapena/cassandra/441/workflows/bcf154ff-0b56-48ed-9f82-6b3e395f53ed/jobs/3880/tests#failed-test-0]

Btw, I've also written a new unit test to catch this bug in the future: [https://github.com/mfleming/cassandra/commit/b4f43608c9a8db23a622608804d95629616a66da] ;;;","18/May/21 22:26;jmeredithco;+1 from me on 071516d29e41da9924af24e8002822d3c6af0e01 and b4f43608c9a8db23a622608804d95629616a66da . Thanks so much for fixing it and updating the tests. 

I think it fixes the issue you found, and I don't think it is possible to create an unbounded number of threads in the shared pool by frequently calling {{setMaximumPoolSize}} as it only calls schedule if there are no spinning threads, and tries to satisfy itself for work from the parked/spinning pools first.

I'm slightly concerned about the fixed duration sleep() in the new test given how much variability there is in CI infrastructure timing. Ideally the test would verify that all of the SEPWorkers were parked (and none spinning), but there's not any straightforward way I can see to do that without refactoring. Worst case is the test doesn't always cover the all-SEPWorkers parked case every time, but seems unlikely to fail and create a new flaky test.

On the {{shutdownTest} failures I agree it is unlikely related to the change. Perhaps 100 milliseconds is not long enough for the thread to notice it is being shutdown and exit for the join call. Threads should request a nano sleep for at most 10ms, but are not guaranteed to be awoken on a busy CI server and may exceed the test deadline. What do you think about an increase from 100 milliseconds up to 1 second to see if it improves things?
;;;","20/May/21 16:38;adelapena;+1 on both changes.
{quote}
On the {{shutdownTest} failures I agree it is unlikely related to the change. Perhaps 100 milliseconds is not long enough for the thread to notice it is being shutdown and exit for the join call. Threads should request a nano sleep for at most 10ms, but are not guaranteed to be awoken on a busy CI server and may exceed the test deadline. What do you think about an increase from 100 milliseconds up to 1 second to see if it improves things?
{quote}
Indeed [a wait of 1 second|https://github.com/adelapena/cassandra/commit/87351868a2b09b605fbd7931e4aba7ef26928ecb] seems to make {{shutdownTest}} not to fail anymore, at least not in these 20K runs:
* [j8-j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/475/workflows/71011b7f-3883-4a73-89cf-552099ff5896/jobs/4200]
* [j8-j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/475/workflows/71011b7f-3883-4a73-89cf-552099ff5896/jobs/4201]
* [j11-j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/475/workflows/a20f69cd-ec0e-499b-ad7f-0d2e4a92a2fb/jobs/4208]

I think we could include that here, as part of the fix.

I'm leaving a few very minor suggestions in the commit for {{SEPExecutorTest}}.;;;","21/May/21 14:50;e.dimitrova;+1 from me too, if it is fine with the others I can address on commit the nits from Andres later today. Thank you!;;;","21/May/21 15:30;adelapena;[~e.dimitrova] I have the two patches, the suggestions and few additional minor warning fixes in [this branch|https://github.com/adelapena/cassandra/tree/16668-trunk-review], which is the one used for the CircleCI runs above.;;;","21/May/21 15:51;mfleming;[~adelapena] your changes look good! Thanks for doing that. +1;;;","21/May/21 18:34;e.dimitrova;Committed to 4.0 and propagated to trunk. Thank you all!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky TestTransientReplicationRing.test_move_forwards_and_cleanup,CASSANDRA-16667,13378241,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,13/May/21 05:22,27/May/22 19:24,13/Jul/23 08:40,13/May/21 05:24,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/dtest/python,,,,0,,,"Flaky TestTransientReplicationRing.[test_move_forwards_and_cleanup|https://ci-cassandra.apache.org/job/Cassandra-4.0/38/testReport/junit/dtest-novnode.transient_replication_ring_test/TestTransientReplicationRing/test_move_forwards_and_cleanup/]",,bereng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu May 13 05:23:15 UTC 2021,,,,,,,All,,,,"0|z0qzwo:",9223372036854775807,,,,,,,,Normal,,,,,,,,,,,,,,,,,,"13/May/21 05:23;bereng;Given I am working on a similar ticket in CASSANDRA-16644 this one will get fixed there. Creating ticket for tracking, stats and avoiding duplicating efforts.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix typo: Alterting -> Altering,CASSANDRA-16661,13377288,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,eribeiro,eribeiro,07/May/21 16:57,27/May/22 19:25,13/Jul/23 08:40,11/May/21 05:09,4.0,4.0-rc1,4.1,4.1-alpha1,,,,CQL/Syntax,,,,0,,,Fix a typo in the response message when trying to alter a type of an UDT field.,,e.dimitrova,eribeiro,,,,,,,,,,,,,,"eribeiro opened a new pull request #999:
URL: https://github.com/apache/cassandra/pull/999


   Fix a typo in the response message when trying to alter a type of an UDT field.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;07/May/21 17:01;githubbot;600","eribeiro closed pull request #999:
URL: https://github.com/apache/cassandra/pull/999


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/May/21 12:26;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,Tue May 11 01:07:31 UTC 2021,,,,,,,All,,,,"0|z0qu14:",9223372036854775807,,,,e.dimitrova,,,,Low,,4.0,,https://github.com/apache/cassandra/commit/8a6dc6a723778374f6db626fa07d242c6dca59e8,,,,,,,,,Just a typo,,,,,"10/May/21 12:27;e.dimitrova;Left a message for one more typo I saw. Otherwise, +1;;;","11/May/21 01:07;e.dimitrova;Ignore my comment, it was before the morning coffee :) +1, thank you!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
python test failures caused by error checks not filtering JAVA_TOOL_OPTIONS,CASSANDRA-16660,13377096,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,06/May/21 20:44,07/May/21 16:37,13/Jul/23 08:40,07/May/21 16:37,NA,,,,,,,Test/dtest/python,,,,0,,,"In order to test some code paths in Cassandra we need to set system properties, which can be done using JAVA_TOOL_OPTIONS, when we do this some tests fail as it expects stderr to be empty; we have a function assert_stderr_clean which does the same check but filters out stuff like JAVA_TOOL_OPTIONS",,blerer,dcapwell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri May 07 07:59:19 UTC 2021,,,,,,,All,,,,"0|z0qsug:",9223372036854775807,,,,blerer,,,,Low,,NA,,https://github.com/apache/cassandra-dtest/commit/155175cbbba068afdfd2cc4c97d1d659b3eeeff6,,,,,,,,,manual/Ci testing where JAVA_TOOL_OPTIONS is present,,,,,"07/May/21 07:59;blerer;The patch looks good to me.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"cqlsh 6.0.0 treats ""config"" as a reserved keyword",CASSANDRA-16659,13377064,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,Bowen Song,Bowen Song,06/May/21 16:11,18/May/21 17:32,13/Jul/23 08:40,17/May/21 13:20,4.0,4.0-rc2,,,,,,CQL/Interpreter,,,,0,,,"Based on the information [here|https://github.com/apache/cassandra/blob/cassandra-4.0-rc1/doc/source/cql/appendices.rst] from the Cassandra 4.0 RC1, ""config"" is not a keyword, and certainly is not a reserved keyword.

However, Cassandra 4.0 RC1 / cqlsh 6.0.0 cannot fully agree:
{noformat}
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 4.0-rc1 | CQL spec 3.4.5 | Native protocol v5]
Use HELP for help.
cqlsh> create keyspace config WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
cqlsh> use config;
Improper use command.
cqlsh> desc config;
Improper desc command.
cqlsh> use ""config"";
cqlsh:config> desc ""config"";
CREATE KEYSPACE config WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}  AND durable_writes = true;
cqlsh:config> 
{noformat}
For reference:
 * Non-reserved keywords, such as ""all"", don't have the above problem. They can be used as keyspace name in any statement without quoting.
{noformat}
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 4.0-rc1 | CQL spec 3.4.5 | Native protocol v5]
Use HELP for help.
cqlsh> create keyspace all WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
cqlsh> use all;
cqlsh:all> desc all;

CREATE KEYSPACE all WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}  AND durable_writes = true;
cqlsh:all> 
{noformat}

 * Reserved keywords, such as ""add"", can be used as keyspace name but requires quoting wherever it's used.
{noformat}
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 4.0-rc1 | CQL spec 3.4.5 | Native protocol v5]
Use HELP for help.
cqlsh> create keyspace add WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
SyntaxException: line 1:16 no viable alternative at input 'add' (create keyspace [add]...)
cqlsh> create keyspace ""add"" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
cqlsh> use add;
Improper use command.
cqlsh> use ""add"";
cqlsh:add> desc add;
Improper desc command.
cqlsh:add> desc ""add"";

CREATE KEYSPACE ""add"" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}  AND durable_writes = true;
{noformat}

The treating of ""config"" in cqlsh 6.0.0 is somewhere in between, it can be used in the ""create keyspace"" statement without quoting, but requires quoting in the ""use"" and ""desc"" statements.

 
 I believe this is a bug in cqlsh 6.0.0, because it behaves the same way when it's connected to a Cassandra 3.11 cluster:
{noformat}
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 3.11.10 | CQL spec 3.4.4 | Native protocol v4]
Use HELP for help.
cqlsh> create keyspace config WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
cqlsh> use config;
Improper use command.
cqlsh> desc config;
Improper desc command.
cqlsh> use ""config"";
cqlsh:config> 
{noformat}
Yet cqlsh 5.0.1 doesn't have any issue at all:
{noformat}
Connected to Test Cluster at 127.0.0.1:9042.
[cqlsh 5.0.1 | Cassandra 3.11.10 | CQL spec 3.4.4 | Native protocol v4]
Use HELP for help.
cqlsh> create keyspace config WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
cqlsh> use config;
cqlsh:config> desc config;

CREATE KEYSPACE config WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}  AND durable_writes = true;

cqlsh:config> 
{noformat}",,adelapena,aholmber,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon May 17 13:20:04 UTC 2021,,,,,,,All,,,,"0|z0qsnk:",9223372036854775807,,,,adelapena,aholmber,,,Low,,,,https://github.com/apache/cassandra/commit/326d61e835b17a2f8395baf7017ae0a24255cdb3,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16659?focusedCommentId=17342907&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17342907,,,,,"10/May/21 19:30;aholmber;I think this is because of the updated driver:
https://datastax-oss.atlassian.net/browse/PYTHON-1270
https://issues.apache.org/jira/browse/CASSANDRA-16240
https://github.com/datastax/python-driver/blob/master/cassandra/metadata.py#L62-L68;;;","10/May/21 19:53;e.dimitrova;:D Figured it out 3 minutes ago.

Thanks [~aholmber], I will check the tickets you pointed to;;;","10/May/21 23:33;e.dimitrova;I experimented a bit and the behavior Is quite inconsistent. According to CASSANDRA-16240, in Ubuntu the newly created table should appear in """" when we run _describe tables;_ This is not the case on my Mac.  Not sure whether something somewhere has been also changed since that ticket. 

Below is some output to show the current behavior. Seems like all operations would work but we should put _reserved_keywords in """"_ when we do _DESCRIBE_ or _USE_.

I think that the best would be really this to be fixed on the driver side. [~aholmber], do you know by chance if [PYTHON-1270|https://datastax-oss.atlassian.net/browse/PYTHON-1270] is planned for work soon?

 
{code:java}
cqlsh> create keyspace config WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
cqlsh> use config;
Improper use command.
cqlsh> use ""config"";
cqlsh:config> CREATE TABLE emp(
          ...    emp_id int PRIMARY KEY,
          ...    emp_name text,
          ...    emp_city text,
          ...    emp_sal varint,
          ...    emp_phone varint
          ...    );
cqlsh:config> CREATE TABLE config.emp2(    emp_id int PRIMARY KEY,    emp_name text,    emp_city text,    emp_sal varint,    emp_phone varint    );
cqlsh:config> select emp_id from config.emp2;
 emp_id
--------
(0 rows)
cqlsh:config> describe config;
Improper describe command.
cqlsh:config> describe ""config"";
CREATE KEYSPACE config WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}  AND durable_writes = true;
CREATE TABLE config.emp (
    emp_id int PRIMARY KEY,
    emp_city text,
    emp_name text,
    emp_phone varint,
    emp_sal varint
) WITH additional_write_policy = '99p'
    AND bloom_filter_fp_chance = 0.01
    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
    AND cdc = false
    AND comment = ''
    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
    AND crc_check_chance = 1.0
    AND default_time_to_live = 0
    AND extensions = {}
    AND gc_grace_seconds = 864000
    AND max_index_interval = 2048
    AND memtable_flush_period_in_ms = 0
    AND min_index_interval = 128
    AND read_repair = 'BLOCKING'
    AND speculative_retry = '99p';
CREATE TABLE config.emp2 (
    emp_id int PRIMARY KEY,
    emp_city text,
    emp_name text,
    emp_phone varint,
    emp_sal varint
) WITH additional_write_policy = '99p'
    AND bloom_filter_fp_chance = 0.01
    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
    AND cdc = false
    AND comment = ''
    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
    AND crc_check_chance = 1.0
    AND default_time_to_live = 0
    AND extensions = {}
    AND gc_grace_seconds = 864000
    AND max_index_interval = 2048
    AND memtable_flush_period_in_ms = 0
    AND min_index_interval = 128
    AND read_repair = 'BLOCKING'
    AND speculative_retry = '99p';
cqlsh:config> drop keyspace config;
cqlsh:config> create keyspace config WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
cqlsh:config> drop keyspace ""config"";
cqlsh:config> create keyspace config WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
cqlsh:config> describe keyspaces;
config  system_auth         system_schema  system_views         
system  system_distributed  system_traces  system_virtual_schema
cqlsh:config> CREATE TABLE config.config(    emp_id int PRIMARY KEY,    emp_name text,    emp_city text,    emp_sal varint,    emp_phone varint    );
cqlsh:config> describe tables;
config
cqlsh:config> CREATE TABLE config.profiles(    emp_id int PRIMARY KEY,    emp_name text,    emp_city text,    emp_sal varint,    emp_phone varint    );
cqlsh:config> 
cqlsh:config> describe tables;
config  profiles
cqlsh:config> describe keyspaces config  system_auth         system_schema  system_views          system  system_distributed  system_traces  system_virtual_schema cqlsh:config> drop keyspace config; cqlsh:config> describe keyspaces; system       system_distributed  system_traces  system_virtual_schema system_auth  system_schema       system_views 
{code}
 

 

 ;;;","11/May/21 16:34;aholmber;bq. PYTHON-1270 is planned for work soon?
I am not aware of anyone planning to work on this. We could provide a patch and make a release happen if need be.

I'm wondering if instead we should continue the [trend|https://issues.apache.org/jira/browse/CASSANDRA-14825?focusedCommentId=16662631&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16662631] of getting drivers out of this game, and instead define keyword lists in cqlsh code that ships with a given version. That would get away from the inconsistencies coming from relying on a driver that is maintained separately, and is designed to connect to varying server versions and variants.;;;","11/May/21 17:17;e.dimitrova;bq. I'm wondering if instead we should continue the trend of getting drivers out of this game, and instead define keyword lists in cqlsh code that ships with a given version. That would get away from the inconsistencies coming from relying on a driver that is maintained separately, and is designed to connect to varying server versions and variants. 

+1
Thanks [~aholmber]

 ;;;","11/May/21 22:47;e.dimitrova;[Patch 4.0|https://github.com/apache/cassandra/commit/19e3cf95d58bd193f50fbbbc1eee767c0ec8e1f0]

[CI|https://app.circleci.com/pipelines/github/ekaterinadimitrova2]

Two tests timed out, not related. _testMetricsWithRebuildAndStreamingFromTwoNodes_ is a known issue

 Also, I tested manually cqlsh as before and things look good to me now, everything as per the expectations. ;;;","12/May/21 19:36;aholmber;Patch looks good to me. Do you think we should add a maintainer breadcrumb [like so|https://github.com/apache/cassandra/blob/4e47bfb3a1abb8074fb9a24f98a97dbf25806522/src/antlr/Lexer.g#L59-L60]?

A separate thought: what would you think of a unit test that makes sure this list is in sync with the antlr files in-tree? I'm experimenting with that locally. I can share if you think it's worth doing.;;;","12/May/21 19:54;e.dimitrova;I like both ideas.

bq. I can share if you think it's worth doing.

Yes, please, I would be happy to see what you have in mind. Thank you!;;;","12/May/21 21:46;aholmber;Looking into my first idea, it was going to be more involved than anticipated. I have another idea, but I don't think we should hold this ticket. I can explore and propose a separate patch.;;;","13/May/21 13:24;e.dimitrova;Thank you.

I just updated the [patch|https://github.com/ekaterinadimitrova2/cassandra/commit/68a0e85fe508696712ea52cc1ede1694ee8cd9ea] with your suggestion, I believe we need only a committer's +1

[~blerer], [~adelapena], does anyone of you have time to check this one, please? ;;;","13/May/21 15:19;adelapena;I can take a look;;;","13/May/21 15:26;e.dimitrova;Thank you [~adelapena]!;;;","13/May/21 16:09;aholmber;I understand that we ported in the list derived from existing driver behavior. While looking at possible ways to test I see there are some discrepancies between this list and the one codified in [{{ReservedKeywords.java}}|https://github.com/apache/cassandra/blob/f637198484c74b71429b1bc884d3fe9a86a4a926/src/java/org/apache/cassandra/cql3/ReservedKeywords.java].

{noformat}
Reserved keywords in cqlsh reserved keywords not read from source .../cassandra/src/java/org/apache/cassandra/cql3/ReservedKeywords.java.
    ""{'unset', 'mbeans', 'mbean', 'replace', 'default'}
{noformat}

Actually as I write this it looks like those were recently unreserved in the grammar, and maybe not flowed into the driver.
https://github.com/apache/cassandra/commit/b74d7370cc89fa899f47f50c825ddaed2dd05c3f

I have a small unit test that scans the above source and compares to the cqlsh list. I will push shortly.;;;","13/May/21 16:56;aholmber;This branch builds on Ekaterina's fix and adds a small sanity check unit test:
https://github.com/aholmberg/cassandra/pull/61/commits
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=16659-4.0];;;","13/May/21 20:33;e.dimitrova;Good catch, thank you for the test and the fix!  Also, CI looks good and I believe this test is mandatory as it will ensure if people miss the comments, it will fail and they will make the needed updates everywhere.

If [~adelapena] doesn't have anything to add after he makes his review, I will squash everything. ;;;","14/May/21 11:29;adelapena;The patch looks good to me, it's probably better to not get the list of keywords from the driver.
{quote}A separate thought: what would you think of a unit test that makes sure this list is in sync with the antlr files in-tree? I'm experimenting with that locally. I can share if you think it's worth doing.
{quote}
It would be nice to have that test to detect future inconsistencies between the lists of reserved keywords, probably something similar to Java's [{{ReservedKeywordsTest}}|https://github.com/apache/cassandra/blob/cassandra-4.0/test/unit/org/apache/cassandra/cql3/ReservedKeywordsTest.java]. [~aholmber] did you make a prototype of this?;;;","14/May/21 11:57;adelapena;I see that the list of reserved keywords in {{cqlhandling.py}} contains some keywords that are present in {{Parser.g}}'s {{basic_unreserved_keyword}} and absent from {{ReservedKeywords}}:
* default
* mbean
* mbeans
* replace
* unset

I understand that those are not reserved keywords in 4.0 so they shouldn't be in the {{cqlhandling.py}} list, is this right?;;;","14/May/21 12:48;e.dimitrova;Hey [~adelapena] , I think you probably looked at my PR and missed Adam's latest comments.  

Test and fix of the mentioned by you issue are already in place [here|https://github.com/aholmberg/cassandra/pull/61/commits]

[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=16659-4.0]

I had to change the PR link with his one, I am sorry for the confusion.;;;","14/May/21 12:58;adelapena;My fault, I missed the last comments, I'll review the new PR in a bit.;;;","14/May/21 15:08;adelapena;Now I'm reading the right PR, sorry for the confusion. Having the test to verify that the two lists of reserved keywords is nice. However I'm a bit concerned about parsing the Java file since it might be a bit brittle, a single line comment on {{ReservedKeywords}} might break it, for example:
{code:java}
    @VisibleForTesting
    static final String[] reservedKeywords = new String[]
                                                     {
                                                     ""SELECT"", // this is the most important keyword
                                                     ""FROM"",
                                                     ""WHERE"",
{code}
or
{code:java}
    @VisibleForTesting
    static final String[] reservedKeywords = new String[]
                                                     {
                                                     ""SELECT"",
                                                    // ""JOIN"",
                                                     ""FROM"",
                                                     ""WHERE"",
{code}
would break it, and it wouldn't be detected until the test is run. This is unlikely to happen and not very hard to fix if it happens, but we could add a comment mentioning the existence of {{test_cql_reserved_keywords}} in {{ReservedKeywords}} to warn maintainers.

Alternatively, I wonder if we could just place the list of reserved keywords in a unique plain text file, so both {{cqlhandling.py}} and {{ReservedKeywords}} can read it. That way we wouldn't need to maintain two copies of the same list and a test to detect inconsistencies between them. Indeed the test parsing code wouldn't even be necessary, wdyt?;;;","14/May/21 15:14;aholmber;I agree it's a bit brittle, but thought it would be okay as a sanity check. Totally cool making it a text file. Less sure about how that should be organized in-tree. Would it be a resource to be embedded in the jar and read at runtime? Happy to have you show or tell me how to do that. 

Another thing I considered was just adding a utility ""main"" to the class that the test would invoke to dump the keywords. Originally did not opt for that because I didn't think it was worth the complexity for such a simple check.;;;","14/May/21 16:32;e.dimitrova;Good catch [~adelapena] and maintainability is a great topic, I am wondering whether we have to do that as part of this ticket or leave it as a required improvement in another one? 

CI is mandatory and a new comment added can easily be caught and corrected. Also, I saw that this list was changed 5 times in 5 years. I personally do not expect many changes and comments added. That is why I thought that this test is good enough at this point in time.;;;","14/May/21 17:21;adelapena;[~aholmber] I'm fine with leaving it as it is. I think there isn't an obvious place to put that file with the reserved keywords once the project is distributed without sources, so getting rid of the duplicated lists is not as easy as I initially thought.

However, what can be done quite easily instead is placing the Java's list of keywords in a resources file, so both {{ReservedKeywords}} and the {{test_constants.py}} test (but not {{cqlhandling.py}}) read that file, avoiding the need of parsing Java code. I gave it a go [in this commit|https://github.com/adelapena/cassandra/commit/ef6870e3f0ff0033ee422b75e4cfb2b5c20ff25b]. Please feel free of just ignoring it if you don't like it, I'm fine with both approaches.;;;","14/May/21 17:50;e.dimitrova;I am fine with this idea for maintainability as soon as this file is read only once during initialization. If [~aholmber] confirms he doesn't have any concerns, I will pull, squash, run final CI and commit. Thank you both! ;;;","14/May/21 18:07;aholmber;+1 no concerns, better solution. Thanks.;;;","14/May/21 23:23;e.dimitrova;[4.0 patch| https://github.com/apache/cassandra/commit/3257230e32223cae3edcdfdd15fd5cfdd47d2ca7] is merged to [trunk|https://github.com/apache/cassandra/pull/1008/commits/c53226d1279f3606edcc258b8499f69c056b91c8].

Last CI runs:

4.0: [Java 8 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/826/workflows/f6d8aeee-48c1-44a8-b79f-be3ca4085781] |  [Java 11 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/826/workflows/1742730b-a0ea-4a84-bcfc-2fad18d6315a]

trunk: [Java 8 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/828/workflows/0e39bfe8-f4a3-455a-93f8-5a3c744cb0f9] |  [Java 11 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/828/workflows/f4385c8b-7ef3-4e6d-93ef-4ebd6f8acb78] 

NOTE: The trunk branch name says different Jira number by mistake, but the content is there, don't get confused. I saw the mistake only after I pushed the branch to CI....;;;","17/May/21 12:53;e.dimitrova;There is one unrelated issue which I am going to tackle separately later.

I'll commit soon;;;","17/May/21 13:20;e.dimitrova;Committed:

4.0 - d35f36cd05..326d61e835

trunk - 8a507d04b4..9422d92603

Thank you both! I marked all of us as authors and reviewers as it ended as a teamwork :) ;;;",,,,,,,,,,,,,,,,,,,,,,,,,
"Broken ""help"" command on cqlsh 6.0.0",CASSANDRA-16658,13377060,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aholmber,Bowen Song,Bowen Song,06/May/21 15:45,12/Jun/21 10:13,13/Jul/23 08:40,14/May/21 22:16,4.0,4.0-rc2,,,,,,CQL/Interpreter,,,,0,,,"On cqlsh 5.0.1, ""help select"" command prints this:
{noformat}
cqlsh> help select
*** No browser to display CQL help. URL for help topic select : https://cassandra.apache.org/doc/cql3/CQL-3.2.html#selectStmt
{noformat}
However, on cqlsh 6.0.0, ""help select"" command prints this:
{noformat}
cqlsh> help select
object of type 'NoneType' has no len()
{noformat}
Steps to reproduce:
 # Create and start a Cassandra 4 docker container
{noformat}
~ $ docker create --name cassandra4 cassandra:4.0
~ $ docker start cassandra4{noformat}
 # Get a shell inside the docker container
{noformat}
 docker exec -ti CONTAINER_NAME bash{noformat}
 # Start a cqlsh and run the ""help"" command inside it (you have to wait for the Cassandra server starting, I had to run ""nodetool enablebinary"" too, not sure why)
{noformat}
root@b03a20987964:/# cqlsh
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 4.0-rc1 | CQL spec 3.4.5 | Native protocol v5]
Use HELP for help.
cqlsh> help select
object of type 'NoneType' has no len()
cqlsh> 
{noformat}",,adelapena,aholmber,Bowen Song,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,aholmber,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri May 14 22:15:29 UTC 2021,,,,,,,All,,,,"0|z0qsmo:",9223372036854775807,,,,adelapena,e.dimitrova,,,Low,,,,https://github.com/apache/cassandra/commit/9783d47b9fe3e370f4ccddbb8eae5a065a9cf3a5,,,,,,,,,"Tested manually with CQLSH_PYTHON set in Python 2.7, 3.6, 3.8",,,,,"10/May/21 19:16;aholmber;[patch|https://github.com/aholmberg/cassandra/pull/60]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16658];;;","11/May/21 02:55;e.dimitrova;LGTM;;;","14/May/21 13:22;e.dimitrova;[~adelapena], [~Bereng], will anyone of you have time to check this one, please?;;;","14/May/21 18:26;adelapena;Looks good to me too, +1.;;;","14/May/21 22:15;e.dimitrova;Committed:

[4.0|https://github.com/apache/cassandra/commit/9783d47b9fe3e370f4ccddbb8eae5a065a9cf3a5] and merged to trunk 

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky TestPaxos,CASSANDRA-16657,13376987,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,bereng,bereng,06/May/21 08:21,12/Jun/21 10:13,13/Jul/23 08:40,19/May/21 13:17,4.0,4.0-rc2,,,,,,Test/dtest/python,,,,0,,,"During testing for some other ticket I found in a test run [this|https://ci-cassandra.apache.org/job/Cassandra-devbranch/736/testReport/junit/dtest-novnode.paxos_test/TestPaxos/test_cluster_availability/] paxos failure

{noformat}
Error Message

cassandra.Unavailable: Error from server: code=1000 [Unavailable exception] message=""Cannot achieve consistency level SERIAL"" info={'consistency': 'SERIAL', 'required_replicas': 1, 'alive_replicas': 0}

Stacktrace

self = <paxos_test.TestPaxos object at 0x7fafbd3f4850>

    @pytest.mark.no_vnodes
    def test_cluster_availability(self):
        # Warning, a change in partitioner or a change in CCM token allocation
        # may require the partition keys of these inserts to be changed.
        # This must not use vnodes as it relies on assumed token values.
    
        session = self.prepare(nodes=3)
        session.execute(""CREATE TABLE test (k int PRIMARY KEY, v int)"")
        session.execute(""INSERT INTO test (k, v) VALUES (0, 0) IF NOT EXISTS"")
    
        self.cluster.nodelist()[2].stop()
        session.execute(""INSERT INTO test (k, v) VALUES (1, 1) IF NOT EXISTS"")
    
        self.cluster.nodelist()[1].stop()
        session.execute(""INSERT INTO test (k, v) VALUES (3, 2) IF NOT EXISTS"")
    
        self.cluster.nodelist()[1].start()
        session.execute(""INSERT INTO test (k, v) VALUES (5, 5) IF NOT EXISTS"")
    
        self.cluster.nodelist()[2].start()
>       session.execute(""INSERT INTO test (k, v) VALUES (6, 6) IF NOT EXISTS"")

paxos_test.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../venv/src/cassandra-driver/cassandra/cluster.py:2618: in execute
    return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile, paging_state, host, execute_as).result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ResponseFuture: query='<SimpleStatement query=""INSERT INTO test (k, v) VALUES (6, 6) IF NOT EXISTS"", consistency=Not ...el SERIAL"" info={'consistency': 'SERIAL', 'required_replicas': 1, 'alive_replicas': 0} coordinator_host=127.0.0.2:9042>

    def result(self):
        """"""
            Return the final result or raise an Exception if errors were
            encountered.  If the final result or error has not been set
            yet, this method will block until it is set, or the timeout
            set for the request expires.
    
            Timeout is specified in the Session request execution functions.
            If the timeout is exceeded, an :exc:`cassandra.OperationTimedOut` will be raised.
            This is a client-side timeout. For more information
            about server-side coordinator timeouts, see :class:`.policies.RetryPolicy`.
    
            Example usage::
    
                >>> future = session.execute_async(""SELECT * FROM mycf"")
                >>> # do other stuff...
    
                >>> try:
                ...     rows = future.result()
                ...     for row in rows:
                ...         ... # process results
                ... except Exception:
                ...     log.exception(""Operation failed:"")
    
            """"""
        self._event.wait()
        if self._final_result is not _NOT_SET:
            return ResultSet(self, self._final_result)
        else:
>           raise self._final_exception
E           cassandra.Unavailable: Error from server: code=1000 [Unavailable exception] message=""Cannot achieve consistency level SERIAL"" info={'consistency': 'SERIAL', 'required_replicas': 1, 'alive_replicas': 0}

../venv/src/cassandra-driver/cassandra/cluster.py:4894: Unavailable
{noformat}
",,bereng,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed May 19 13:16:22 UTC 2021,,,,,,,All,,,,"0|z0qs6g:",9223372036854775807,,,,bereng,e.dimitrova,,,Normal,,,,https://github.com/apache/cassandra-dtest/commit/e94e930d2c1de6b7b6824d163e0c42f6b96ba492,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16657?focusedCommentId=17347264&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17347264,,,,,"12/May/21 19:06;e.dimitrova;Jenkins shows failures, but then everything fixed... same old known bug.

I managed to reproduce it [3 times out of 1000 runs|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=16657-4.0] with both Java 8 and Java 11 in the new CircleCI multiplexer.;;;","18/May/21 20:16;e.dimitrova;I have added some logging around Paxos [here|https://github.com/ekaterinadimitrova2/cassandra/pull/113/commits/b67b9779d8d85bd85dbe5c85dcccc3daf63bca42] and I didn't find any Paxos related errors in the logs of the failed runs of this test.

According to this [warning|https://github.com/apache/cassandra-dtest/blob/trunk/paxos_test.py#L65-L6], I verified which key corresponds to which token using our partitioner utility functions and also printing from the code which node is targeted for replica for which key (double-checking myself).

-The last _INSERT_ (where all the failures of this test happen) should insert to node 2. So my first thought was that there was delay in bringing up node 2. But it turned out that for that statement to be executed, we need  both node 2 and node 3 to be up, if I comment out the start of any of those 2, the test consistently fails. -

My understanding is that this test has to verify that the following issue was solved - PAXOS required all nodes for CAS (CASSANDRA-8640). -It seems to me that maybe this was solved partially or something has changed later(I will dig into that as a next step) as this is a pretty old ticket. What I mean is that the first 4 operations always succeed but the last one always fails in case node 3 is also down, even if we should require only the replica, node2 to be available at this point. The replication factor is 1.-
{code:java}
session.execute(""INSERT INTO test (k, v) VALUES (0, 0) IF NOT EXISTS"") # respective token belongs to node 2 

node3.stop()
session.execute(""INSERT INTO test (k, v) VALUES (1, 1) IF NOT EXISTS"") # respective token belongs to node 2 

node2.stop()
session.execute(""INSERT INTO test (k, v) VALUES (3, 2) IF NOT EXISTS"") # respective token belongs to node 1

node2.start()
session.execute(""INSERT INTO test (k, v) VALUES (5, 5) IF NOT EXISTS"") # respective token belongs to node1

node3.start()
session.execute(""INSERT INTO test (k, v) VALUES (6, 6) IF NOT EXISTS"") # respective token belongs to node2{code}
-So now the logical question was why the first insert of key 1 to node 2 after stopping node 3 is always successful? Then I checked the logs and here it comes the confusion:-

CAS completes on node2 before node3 is stopped:-
{code:java}
DEBUG [MutationStage-1] 2021-05-18 02:49:54,316 PaxosState.java:78 - Promising ballot b958b790-b783-11eb-52d1-a2e59ce8c54f
DEBUG [MutationStage-1] 2021-05-18 02:49:54,323 PaxosState.java:116 - Accepting proposal Commit(b958b790-b783-11eb-52d1-a2e59ce8c54f, [ks.test] key=1 partition_deletion=deletedAt=-9223372036854775808, localDeletion=2147483647 columns=[[] | [v]]
 Row[info=[ts=1621306194313000] ]: EMPTY | [v=1 ts=1621306194313000])
DEBUG [MutationStage-1] 2021-05-18 02:49:54,326 PaxosState.java:153 - Committing proposal Commit(b958b790-b783-11eb-52d1-a2e59ce8c54f, [ks.test] key=1 partition_deletion=deletedAt=-9223372036854775808, localDeletion=2147483647 columns=[[] | [v]]
 Row[info=[ts=1621306194313000] ]: EMPTY | [v=1 ts=1621306194313000])
{code}

-node3 stop:-

{code:java}
DEBUG [StorageServiceShutdownHook] 2021-05-18 02:49:47,201 StorageService.java:1619 - DRAINING: starting drain process
INFO  [StorageServiceShutdownHook] 2021-05-18 02:49:47,202 HintsService.java:220 - Paused hints dispatch
INFO  [StorageServiceShutdownHook] 2021-05-18 02:49:47,204 Server.java:171 - Stop listening for CQL clients
INFO  [StorageServiceShutdownHook] 2021-05-18 02:49:47,204 Gossiper.java:1962 - Announcing shutdown
{code}-

 I will add further logs and check for related post-CASSANDRA-8640 changes in the area.

 //CC [~blerer] as I remember you were working at some point on some PAXOS related issues too

 ;;;","19/May/21 02:34;e.dimitrova;Please ignore my previous comment, after adding more logs and revising again what I have I realized I made a mistake and the last two INSERTs insert keys corresponding to tokens which belong respectively to node 2 and node 3 and now everything clicks! So the issue is really that in rare cases node 3 is not ready after being started for the last INSERT and then we see the mentioned failure.

I strengthened the test [here |https://github.com/ekaterinadimitrova2/cassandra-dtest/commit/e58ddf8f99f9b8d9a1ee36e618929798fc509cea] to ensure the replica is up before the respective INSERT.
 1000 successful runs done [Java 8 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/837/workflows/b04066b9-ceab-4b31-8d9c-9a180d97dfda] and [Java 11 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/837/workflows/b941b1b2-1655-40fd-ab80-2a9c6fa2e46a];;;","19/May/21 05:40;bereng;[~e.dimitrova] I left a comment but I think the approach lgtm. I have seen many similar ones in dtests before and the fail/success multiplex runs repro'ing the failure and the fix settle it for me. +1 assuming my comment is addressed and that also succeeds a new CI run.;;;","19/May/21 13:16;e.dimitrova;Comment addressed, thanks!

1000 successful runs:

[Java 8|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/838/workflows/53ce0b4f-25c3-40d7-a5e1-c9d4ad03dcbc/jobs/4972] | [Java 11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/838/workflows/0fc0909a-c4b4-41af-9f36-6f9c491f0e4b/jobs/4968]

Patch committed [here |https://github.com/apache/cassandra-dtest/commit/e94e930d2c1de6b7b6824d163e0c42f6b96ba492], thanks;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cqlsh-tests.sh should return different return codes on circle vs jenkins,CASSANDRA-16655,13376767,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,,bereng,bereng,05/May/21 09:51,27/May/22 19:25,13/Jul/23 08:40,05/May/21 16:11,4.0,4.0-rc2,4.1,4.1-alpha1,,,,CI,,,,0,,,"Recent jenkins runs appear broken (red) bc of a cqlsh test failure. That reports the whole run as broken instead of that specific step with failures and an unstable (yellow) run.

It appears the reason may be [this|https://github.com/apache/cassandra/blame/trunk/pylib/cassandra-cqlsh-tests.sh#L146] change. At that time that was necessary to make circle fail that step. Otherwise cqlsh failures would be ignored and that step rendered green regarless making it useless. But it has been found now this makes jenkins report the whole run red upon a cqlsh test failure.

The solution seems to be to return different codes depending on whether we're on jenkins or circle. [~mck] has suggested sthg along these lines:

{code}
# circleci wants non-zero exit to report failures, jenkins wants zero exit for a unstable status
[[ command -v circleci >/dev/null 2>&1 ]] && exit ${RETURN}
exit 0
{code}

Procedure:
- Fix the sh script
- Break a cqlsh test
- Test the test gets reported as a failure in circle
- Test the test gets reported as a failure in jenkins and that the run and step are yellow (not red)
- Fix the test
- Both circle and jenkins report green for that step",,bereng,brandon.williams,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16121,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,mck,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu May 06 04:07:18 UTC 2021,,,,,,,All,,,,"0|z0qqts:",9223372036854775807,,,,mck,,,,Critical,,4.0-beta4,,https://github.com/apache/cassandra/commit/b67d04b6fe311d8c923d125c722e7a094a921f0c,,,,,,,,,,,,,,"05/May/21 10:35;bereng;The current sh returns the error code upon a test failure and circle command presence
{noformat}
+ command -v circleci
+ exit 1
{noformat}

It returns '0' if the command is not found. I used a mock command for testing purposes
{noformat}
+ command -v circleci2
+ exit 0
{noformat};;;","05/May/21 10:48;bereng;I amended versions bc the cqlsh tests on circle where only added to the 4.0 line. So we need to fix it on 4.0 and trunk only if I am not missing anything.;;;","05/May/21 10:50;mck;bq. I amended versions bc the cqlsh tests on circle where only added to the 4.0 line. 

Correct, 3.11 and older still have the `exit 0` last line: https://github.com/apache/cassandra/blob/cassandra-3.11/pylib/cassandra-cqlsh-tests.sh#L123

But `4.0-rc2` isn't to be used until the issue is resolved. (It should be `4.0-rc` or `4.0.x` up until that.);;;","05/May/21 14:15;mck;tested:
 - (circleci intentional fail) https://app.circleci.com/pipelines/github/michaelsembwever/cassandra/26/workflows/f9ee119c-9b69-46fa-8fab-fc06614d1a8e/jobs/416
- (circleci pass) https://app.circleci.com/pipelines/github/michaelsembwever/cassandra/24/workflows/bb8ce7be-7f41-4107-85de-cfb5ab32f3c4/jobs/390
- (ci-cassandra unstable) https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-cqlsh-tests/738/
;;;","05/May/21 16:03;mck;Patch: https://github.com/apache/cassandra/compare/trunk...thelastpickle:CASSANDRA-16655-trunk;;;","06/May/21 04:07;bereng;Just checked latest jobs. It works! :-) Thanks for taking it over the finish line!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Junit RepeatableRunner flaky tests helper,CASSANDRA-16654,13376758,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,05/May/21 09:06,27/May/22 19:25,13/Jul/23 08:40,18/May/21 04:47,3.0.25,3.11.11,4.0,4.0-rc2,4.1,4.1-alpha1,,Test/unit,,,,0,,,"Some flakies only fail when the full suite is ran. If it's a quick test you can do thousands of runs if a few seconds. Looping at the sh level is not an option as every loop takes a few seconds.

As I have found this very useful I am proposing committing it",,adelapena,bereng,e.dimitrova,jeromatron,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16627,CASSANDRA-16625,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,bereng,,,,,,,,,,,,Code,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon May 17 13:07:26 UTC 2021,,,,,,,All,,,,"0|z0qqrs:",9223372036854775807,,,,adelapena,,,,Normal,,3.0.0,,https://github.com/apache/cassandra/commit/fdabda1da849efdb2f0066a341b9cc24de7fd05c,,,,,,,,,If can be tested by trying to run {{DirectoriesTest}} a few times i.e.,,,,,"12/May/21 16:21;adelapena;I think this is a nice addition to our tool belt, thanks. It will be useful at least until we have JUnit 5's [@RepeatedTest|https://junit.org/junit5/docs/5.0.1/api/org/junit/jupiter/api/RepeatedTest.html] available, someday.

Maybe we could add a few implementations for our most common runners, as proposed [here|https://github.com/adelapena/cassandra/commit/65cd829bc73e1a9232e11c0bcfbeaccee2536c53], so we can use annotations such as {{@RunWith(RepeatableRunner.Parameterized.class)}}, {{@RunWith(RepeatableRunner.BMUnitRunner.class)}}, etc., wdyt?

I would add a note in the documentation about how many tests alter singletons and so they don't work with the repeatable runner.

We could put the number of repetitions in a {{RepeatableRunner}} constant for better visibility, and maybe also add the possibility of reading the value from a JVM property, as it's done [here|https://github.com/adelapena/cassandra/blob/65cd829bc73e1a9232e11c0bcfbeaccee2536c53/test/unit/org/apache/cassandra/RepeatableRunner.java#L35]. The later is probably not so useful since we are nevertheless forced to temporary modify the code when setting the runner.;;;","13/May/21 07:37;bereng;[~adelapena] your proposal sounds great. I modified it a bit to have a param for the runner for the number of repetitions. Sounds most convenient imo wdyt?. Please check the [4.0 PR|https://github.com/apache/cassandra/pull/1006] not the trunk one for the final version. {{DirectoriesTest}} modifications are not part of the PR, I left it there just for your convenience to test it.;;;","13/May/21 12:04;adelapena;I really like the idea of using an annotation for the runner parameters. I spent some time trying to figure out how to extend {{RunWith}} without any success, but the additional annotation approach is simple and effective. Indeed, we could get rid of the inner subclasses for wrapped runners and just add the wrapped runner to the annotation, so we can use something like:
{code:java}
@RunWith(RepeatableRunner.class)
@RepeatableRunnerConfiguration(iterations = 5, runner = Parameterized.class)
{code}
Or:
{code:java}
@RunWith(RepeatableRunner.class)
@RepeatableRunnerConfiguration(iterations = 5, runner = BMUnitRunner.class)
{code}
Differently from the subclasses approach, this should work with any kind of runner. I gave it a go [here|https://github.com/adelapena/cassandra/commit/b222faab156e119bfa82b6b8d7e909c22d8be12c] (some examples included), wdyt? ;;;","13/May/21 12:10;adelapena;Also, I wonder if we should mention the existence of this runner in the [documentation for testing|https://github.com/apache/cassandra/blob/trunk/doc/source/development/testing.rst#unit-testing].;;;","13/May/21 12:25;bereng;Ha! I was thinking along the same lines but for some reason it didn't occur to me as you did it which is super-nice imo. This is great as it is completely Runner agnostic and non-invasive. Also I think junit5 repeats at the method level not a _class_ level.

What we have is good but I want to linger here a bit more and see if I can somehow avoid having to decorate a class with Runners. Like call a Runner programmatically and pass the test class as a param...;;;","13/May/21 15:16;adelapena;{quote}What we have is good but I want to linger here a bit more and see if I can somehow avoid having to decorate a class with Runners. Like call a Runner programmatically and pass the test class as a param...
{quote}
Being able to run repeatedly without modifying the test would certainly be great, looking forward to something that can do that.;;;","14/May/21 08:31;bereng;There's no easy way to make ant take a runner as a parameter. You have to create a plugin etc etc. Alternatives are also quite involved. If I have not lost track of the things I think what we have is the most reasonable option.

Edit: Added doc notes.;;;","14/May/21 10:26;adelapena;{quote}There's no easy way to make ant take a runner as a parameter. You have to create a plugin etc etc. Alternatives are also quite involved. If I have not lost track of the things I think what we have is the most reasonable option.
{quote}
Agree, I played a bit with {{JUnitTask}}/{{JStackJUnitTask}} while working on the CircleCI multiplexer and it seems probably more involved than we need right now. I think it's better if we commit this as it is, so it starts to help us with 4.0 immediately. We can always come back later to add the repetitions as an Ant parameter.
{quote}Edit: Added doc notes.
{quote}
The new section about flaky tests is nice, thanks. I've left a couple of very minor suggestions in the PR that can be addressed during commit.

I think we are ready to commit. IMO it would be nice if we added the runner also to 3.0 and 3.11, it should be a straightforward merge.

Also, just a reminder to remove the usages of {{RepeatableRunner}} that we have added as examples ({{DirectoriesTest}}, {{ColumnFilterTest}}, {{AssureSufficientLiveNodesTest}} and {{SpeculativeRetryParseTest}});;;","17/May/21 08:12;bereng;[~adelapena] all cleaned, PRs for all versions pushed & CI attached. I'll wait for your final +1 before committing just to be on the safe side now we have all PRs up.;;;","17/May/21 10:50;adelapena;Looks good to me, +1, I think this runner will be very helpful :);;;","17/May/21 13:07;e.dimitrova;Hey, I just sneaked into this ticket quickly and it seems great tool for someone new who can use it locally. I suggest you mentioned it on the mailing list, same as the other multiplexer from last week so people don't miss it as it will be very helpful! Thank you!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multinode counters don't get updated,CASSANDRA-16653,13376725,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,bereng,bereng,05/May/21 06:21,13/May/21 15:41,13/Jul/23 08:40,12/May/21 19:51,4.0,4.0-rc2,,,,,,Feature/Counters,,,,0,,,"A multi node setup with counters doesn't update counters value. Works as expected on a single node though. Comes from [this|https://github.com/apache/cassandra-dtest/blob/trunk/upgrade_tests/cql_tests.py#L460] test. Repro:


{noformat}
ccm create counters40
ccm populate -n 2
ccm start
ccm node1 cqlsh
  CREATE KEYSPACE foo WITH REPLICATION = { 'class' : 'NetworkTopologyStrategy', 'datacenter1' : 1 } ;
  use foo;
  CREATE TABLE clicks ( userid int, url text, total counter, PRIMARY KEY (userid, url) ) WITH COMPACT STORAGE;
  ALTER TABLE clicks DROP COMPACT STORAGE;
  TRUNCATE clicks;
  UPDATE clicks SET total = total + 1 WHERE userid = 1 AND url = 'http://foo.com';
  SELECT total FROM clicks WHERE userid = 1 AND url = 'http://foo.com';

     total
    -------
         1
  UPDATE clicks SET total = total - 4 WHERE userid = 1 AND url = 'http://foo.com';
  SELECT total FROM clicks WHERE userid = 1 AND url = 'http://foo.com';

     total
    -------
         1 *********** Should be '-3'
{noformat}
",,adelapena,bereng,blerer,e.dimitrova,mck,,,,,,,,,,,"adelapena opened a new pull request #136:
URL: https://github.com/apache/cassandra-dtest/pull/136


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/May/21 16:55;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #136:
URL: https://github.com/apache/cassandra-dtest/pull/136#discussion_r630364306



##########
File path: upgrade_tests/cql_tests.py
##########
@@ -461,18 +461,26 @@ def test_counters(self):
         """""" Validate counter support """"""
         cursor = self.prepare()
 
-        cursor.execute(""""""
+        logger.debug('*** VERSION FAMILY: ' + str(self.UPGRADE_PATH.upgrade_meta.family))
+        logger.debug('*** VERSION: ' + str(self.cluster.version()))
+
+        create_table_query = """"""
             CREATE TABLE clicks (
                 userid int,
                 url text,
                 total counter,
                 PRIMARY KEY (userid, url)
-            ) WITH COMPACT STORAGE;
-        """""")
+            )
+        """"""
 
-        #4.0 doesn't support compact storage
-        if self.is_40_or_greater():
-            cursor.execute(""ALTER TABLE clicks DROP COMPACT STORAGE;"")
+        if self.cluster.version() >= LooseVersion('4.0'):
+            cursor.execute(create_table_query)
+        else:
+            cursor.execute(create_table_query + '  WITH COMPACT STORAGE')
+
+            # 4.0 doesn't support compact storage

Review comment:
       It didn't until CASSANDRA-16217 was born, unfortunately. 
   For more info, docs updated here - https://github.com/apache/cassandra/commit/0a49d25078665da0ec30d9e69a036de163deb9c3




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/May/21 17:01;githubbot;600","adelapena closed pull request #136:
URL: https://github.com/apache/cassandra-dtest/pull/136


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/May/21 15:41;githubbot;600","adelapena closed pull request #996:
URL: https://github.com/apache/cassandra/pull/996


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/May/21 15:41;githubbot;600","adelapena closed pull request #997:
URL: https://github.com/apache/cassandra/pull/997


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/May/21 15:41;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,3000,,,0,3000,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16648,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed May 12 19:51:39 UTC 2021,,,,,,,All,,,,"0|z0qqkg:",9223372036854775807,,,,blerer,e.dimitrova,,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/fb76baa60898db82831df44796bd224d30e3236d,,,,,,,,,The patch includes a JVM dtest with the reproduction steps included in the description.,,,,,"06/May/21 17:04;adelapena;It seems that the problem is that {{AlterTableStatement}} replaces all the flags in the {{TableMetadata}} by a single {{COMPOUND}} flag ([here|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/cql3/statements/schema/AlterTableStatement.java#L437]). This removes the {{DENSE}} flag, as it's desired. The problem is that the {{COUNTER}} flag is also removed, so the table is not considered as a counters table anymore. This leads to sending wrong mutations to the table, producing the problem that we can see in the provided reproduction steps.

The proposed patch simply makes sure that the {{COUNTER}} flag is preserved.

CI is running:
 4.0:
 * [CircleCI J8|https://app.circleci.com/pipelines/github/adelapena/cassandra/406/workflows/7bafc2a3-4c98-4d1b-9869-24407099147b]
 * [CircleCI J11|https://app.circleci.com/pipelines/github/adelapena/cassandra/406/workflows/86f980d7-5566-4d65-a2b7-e573dc70d737]

trunk:
 * [CircleCI J8|https://app.circleci.com/pipelines/github/adelapena/cassandra/405/workflows/ae9977c7-02d6-4050-89fd-3683fe8fc581]
 * [CircleCI J11|https://app.circleci.com/pipelines/github/adelapena/cassandra/405/workflows/d5f61277-870e-45b7-9d14-99d93da24b82];;;","06/May/21 20:27;e.dimitrova;+1 on green CI. ;;;","07/May/21 08:28;blerer;+1. The failing tests do not look related. ;;;","07/May/21 17:03;adelapena;Thanks for the reviews.

Committed to {{cassandra-4.0}} as [fb76baa60898db82831df44796bd224d30e3236d|https://github.com/apache/cassandra/commit/fb76baa60898db82831df44796bd224d30e3236d] and merged up to [{{trunk}}|https://github.com/apache/cassandra/commit/2c3c3e639aec8b7515db0e59b606adbea411626a].;;;","10/May/21 08:33;bereng;[~adelapena] [this|https://ci-cassandra.apache.org/job/Cassandra-4.0/31/#showFailuresLink] run still fails [counters|https://ci-cassandra.apache.org/job/Cassandra-4.0/31/testReport/junit/dtest-upgrade.upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_4_0_x_To_indev_4_0_x/test_counters/] and I can see it's on {{62e1d74701bcb59437aeb1c778ba7a81aac84741}} which should include your fix already?;;;","10/May/21 15:00;adelapena;It seems that the test needs some fixing. The failing case is an upgrade from 4.0-rc1 to indev 4.0. The {{DROP COMPACT STORAGE}} is run in the original version, 4.0-rc1. That version doesn't contain this bug fix, so the table wrongly stops being a counter table ever before doing the upgrade. I'm working on a patch fixing the dtest.;;;","11/May/21 17:09;adelapena;The proposed [PR|https://github.com/apache/cassandra-dtest/pull/136] changes the dtest to not use compact storage when the origin version is >= 4.0, although previous version will still do it.

Maybe it would have been preferable to skip the compact storage part only in origin versions between {{4.0-beta4}} and {{4.0-rc1}}, which is where the bug is, but AFAIK there isn't an easy way to get that from the cluster version. Nevertheless, I don't think that compact storage is an important part of the 4.0-4.0/4.x counters upgrade path, and we already have our new JVM dtest for dropping compact storage in 4.0/4.x counter tables.

CI is running:

Jenkins:
 * [3.0|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/764/pipeline]
 * [3.11|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/765/pipeline]
 * [4.0|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/762/pipeline]
 * [trunk|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/766/pipeline]

CircleCI:
 * [3.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/450/workflows/65855969-e4e5-4dd8-b9cb-226f641f99cd]
 * [3.11|https://app.circleci.com/pipelines/github/adelapena/cassandra/448/workflows/19b48d88-64ad-4981-8f30-ea2d6f3a0cc5]
 * [4.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/449/workflows/af262f01-bf4c-47b6-bf5d-7b4c6ce837ae]
 * [trunk|https://app.circleci.com/pipelines/github/adelapena/cassandra/452/workflows/b6c1e360-3456-4d58-8e76-f7818e415c49]

 ;;;","12/May/21 16:20;e.dimitrova;+1, especially now when we have the mentioned in-jvm test.

Thanks [~adelapena];;;","12/May/21 19:51;adelapena;Thanks [~e.dimitrova], dtest fix committed as [7542dfe3921089dae35c2ab70616a7fb1f526fe8|https://github.com/apache/cassandra-dtest/commit/7542dfe3921089dae35c2ab70616a7fb1f526fe8].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""desc"" on cqlsh 6.0.0 not working with a Cassandra 3.x server",CASSANDRA-16652,13376643,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,Bowen Song,Bowen Song,04/May/21 21:50,12/Jun/21 10:13,13/Jul/23 08:40,18/May/21 16:11,4.0,4.0-rc2,,,,,,CQL/Interpreter,,,,0,,,"The ""desc"" statement on cqlsh 6.0.0 shipped with Cassandra 4.0 RC1 is not working correctly when it's connected to a Cassandra 3.x server.

Steps to reproduce:
 * Ensure you have docker installed and running
 * Run the following docker commands to create and start a Cassandra 3.11 container
{code:java}
~ $ docker create --name cassandra3 cassandra:3.11.10
5d903e48e0661e39080198de5e8752356a5a666132211a500ea38af0fc2a0356
~ $ docker start cassandra3
cassandra3
~ $ docker exec -ti cassandra3 bash
{code}

 * Inside the docker container, try the default cqlsh version, make sure everything is working correctly
{code:java}
root@5d903e48e066:/# cqlsh
Connected to Test Cluster at 127.0.0.1:9042.
[cqlsh 5.0.1 | Cassandra 3.11.10 | CQL spec 3.4.4 | Native protocol v4]
Use HELP for help.
cqlsh> desc keyspaces;

system_traces  system_schema  system_auth  system  system_distributed

cqlsh> use system_auth;
cqlsh:system_auth> desc tables;

resource_role_permissons_index  role_permissions  role_members  roles

cqlsh:system_auth> select * from roles;

 role      | can_login | is_superuser | member_of | salted_hash
-----------+-----------+--------------+-----------+--------------------------------------------------------------
 cassandra |      True |         True |      null | $2a$10$8UNyioBF41/OZfcCa2aqXOHvXiNXArBHKaUUhMyPAFKpfN8byXonm

(1 rows)
cqlsh:system_auth> exit
{code}

 * Okay, everything worked as expected. Now install {{git}} to clone the Cassandra 4.0 RC1 source code, and {{python3-six}}, which is a dependency of cqlsh
{code:java}
root@5d903e48e066:/# apt-get update -qq && apt-get install -qq git python3-six
...... [truncated]
{code}

* Clone the Cassandra repository and checkout the cassandra-4.0-rc1 tag
{code:java}
root@5d903e48e066:/# git clone -b cassandra-4.0-rc1 --depth 1 https://github.com/apache/cassandra.git cassandra-4.0-rc1
Cloning into 'cassandra-4.0-rc1'...
...... [truncated]
{code}

* Run the cqlsh from the Git repository, and then repeat all the cqlsh statements above
{code:java}
root@5d903e48e066:/# cd cassandra-4.0-rc1/bin
root@5d903e48e066:/cassandra-4.0-rc1/bin# ./cqlsh
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 3.11.10 | CQL spec 3.4.4 | Native protocol v4]
Use HELP for help.
cqlsh> desc keyspaces;

cqlsh> use system_auth;
cqlsh:system_auth> desc tables;

cqlsh:system_auth> select * from roles;

 role      | can_login | is_superuser | member_of | salted_hash
-----------+-----------+--------------+-----------+--------------------------------------------------------------
 cassandra |      True |         True |      null | $2a$10$8UNyioBF41/OZfcCa2aqXOHvXiNXArBHKaUUhMyPAFKpfN8byXonm

(1 rows)
cqlsh:system_auth> exit
root@5d903e48e066:/cassandra-4.0-rc1/bin#
{code}

""desc"" did not work correctly, but ""use"" and ""select"" worked.",,aholmber,blerer,Bowen Song,e.dimitrova,jeromatron,weisslj,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness -> API / Semantic Implementation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue May 18 16:07:56 UTC 2021,,,,,,,All,,,,"0|z0qq28:",9223372036854775807,,,,aholmber,blerer,,,Normal,,4.0-rc1,,https://github.com/apache/cassandra/commit/77a370c424b767486d2484cc15965de6dc98b265,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16652?focusedCommentId=17343426&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17343426,,,,,"05/May/21 08:23;blerer;Effectively {{DESCRIBE}}|{{DESC}} will not work properly because in 4.0 we moved to server side DESCRIBE (CASSANDRA-14825) which do not exist in 3.11.
If we want to support that scenario we need to provide a fallback mechanism in cqlsh. That basically mean re-introducing the cqlsh code that was removed in CASSANDRA-14825. 
For the record, I am not fully sure that the output will be exactly the same and our current tests will not test that path (as they run only against the current version) 
so we will need to introduce some upgrade tests that actually test the query that we test in {{DescribeStatementTest}}.

The other option is to not support that feature and warn the user in the upgrade section of the NEWS.txt.
I am probably not the best one to judge of how critical is this feature. [~clohfink], [~jolynch] as you are involved in managing big production clusters, I would like to hear you opinion about that ticket.  
  ;;;","05/May/21 12:41;brandon.williams;bq. The other option is to not support that feature and warn the user in the upgrade section

I think it should be possible to detect it in cqlsh when it happens and warn the user there that it doesn't work as well.;;;","05/May/21 23:42;e.dimitrova;Thank you both.

So from what I here we have two options - backward compatibility or to add a proper warning in 4.0 to prevent further confusion.

I am also interested as [~blerer] to hear what [~cnlwsu] and [~jolynch] think. ;;;","11/May/21 15:18;blerer;+1 for warning on query the user and adding a warning in the upgrade section of the NEWS.txt.;;;","12/May/21 18:02;e.dimitrova;[Patch|https://github.com/ekaterinadimitrova2/cassandra/commit/06c155420526a4744a8748d929fe237d5f2d1643]
 Green CI: [Java 8 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/815/workflows/775c7bbf-8e9c-4ae7-bfb3-a0efeb474395] | [Java 11 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/815/workflows/01eb71ac-d12c-4068-91fd-ec9f84dbf45c];;;","13/May/21 18:41;aholmber;Patch looks good. +1
Two very minor comments on the commit. ;;;","17/May/21 18:17;e.dimitrova;[~blerer] do you think you will have a bit of time to review this one, please? ;;;","18/May/21 08:00;blerer;The patch looks good to me. Thanks a lot [~e.dimitrova];;;","18/May/21 16:07;e.dimitrova;Committed to 4.0 and trunk, thank you!

2ca525b6b7..77a370c424  cassandra-4.0 -> cassandra-4.0

   5d2c2f5ee3..2e9ce1b88f  trunk -> trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky test testHasVersion3Nodes - org.apache.cassandra.gms.GossiperTest,CASSANDRA-16651,13376461,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,04/May/21 00:56,27/May/22 19:25,13/Jul/23 08:40,04/May/21 03:52,4.1,4.1-alpha1,,,,,,Test/unit,,,,0,,,"https://app.circleci.com/pipelines/github/dcapwell/cassandra/893/workflows/3737a7f7-e636-4aac-ac52-a215ec9b008f/jobs/5374

{code}
junit.framework.AssertionFailedError: expected null, but was:<4.0.0-SNAPSHOT>
	at org.apache.cassandra.gms.GossiperTest.testHasVersion3Nodes(GossiperTest.java:148)
{code}",,bereng,dcapwell,e.dimitrova,,,,,,,,,,,,,"dcapwell opened a new pull request #991:
URL: https://github.com/apache/cassandra/pull/991


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/May/21 00:58;githubbot;600","smiklosovic closed pull request #991:
URL: https://github.com/apache/cassandra/pull/991


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:21;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue May 04 04:21:48 UTC 2021,,,,,,,All,,,,"0|z0qoxs:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0.x,,https://github.com/apache/cassandra/commit/9c25d3e0c7b79cd54e7950373c0c89c36369cd8a,,,,,,,,,CI,,,,,"04/May/21 02:03;e.dimitrova;CI still running but code wise looks good to me, thanks.

+1 on green CI;;;","04/May/21 03:48;dcapwell;passes in circle ci;;;","04/May/21 04:21;bereng;[~dcapwell] your 'Source Control Link' seems broken #collaborating;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky ConnectionBurnTest,CASSANDRA-16650,13376326,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,03/May/21 05:48,27/May/22 19:24,13/Jul/23 08:40,04/May/21 07:58,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Test/unit,,,,0,,,"Flaky see [here|https://ci-cassandra.apache.org/job/Cassandra-trunk/484/testReport/junit/org.apache.cassandra.net/ConnectionBurnTest/test/]",,bereng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon May 03 13:26:52 UTC 2021,,,,,,,All,,,,"0|z0qo40:",9223372036854775807,,,,brandon.williams,,,,Low,,4.0,,https://github.com/apache/cassandra/commit/b69297ebb28dc8b4e110c2d9785a04f91acb5558,,,,,,,,,See comments,,,,,"03/May/21 07:49;bereng;That was an easy one to repro and fix. Just a plain timeout and it can be reproed by reducing it to 1 ms in my case.;;;","03/May/21 12:24;bereng;Good on a multiplex run of 100 were it seems it does only timeout as it takes hours to complete. Otherwise no test failures.;;;","03/May/21 13:26;brandon.williams;+1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky TestTransientReplicationRing.test_move_backwards_and_cleanup,CASSANDRA-16644,13375986,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,30/Apr/21 07:29,31/Jul/21 21:28,13/Jul/23 08:40,17/May/21 09:05,4.0,4.0-rc1,,,,,,Test/dtest/python,,,,0,,,"Failure [here|https://ci-cassandra.apache.org/job/Cassandra-trunk/472/testReport/junit/dtest-novnode.transient_replication_ring_test/TestTransientReplicationRing/test_move_backwards_and_cleanup/]


{noformat}
Error Message

ccmlib.node.TimeoutError: 27 Apr 2021 00:01:00 [node4] after 90.11/90 seconds Missing: ['Starting listening for CQL clients'] not found in system.log: Tail: INFO  [main] 2021-04-26 23:59:22,590 YamlConfigura

Stacktrace

self = <transient_replication_ring_test.TestTransientReplicationRing object at 0x7f66c51ebd90>

    @flaky(max_runs=1)
    @pytest.mark.no_vnodes
    def test_move_backwards_and_cleanup(self):
        """"""Test moving a node backwards without moving past a neighbor token""""""
        move_token = '00005'
        expected_after_move = [gen_expected(range(0, 6), range(31, 40)),
                               gen_expected(range(0, 21, 2)),
                               gen_expected(range(1, 6, 2), range(6, 31)),
                               gen_expected(range(7, 20, 2), range(21, 40))]
        expected_after_repair = [gen_expected(range(0, 6), range(31, 40)),
                                 gen_expected(range(0, 21)),
                                 gen_expected(range(6, 31)),
                                 gen_expected(range(21, 40))]
>       self.move_test(move_token, expected_after_move, expected_after_repair)

transient_replication_ring_test.py:333: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
transient_replication_ring_test.py:235: in move_test
    node4.start(wait_for_binary_proto=True)
transient_replication_ring_test.py:50: in new_start
    return old_start(*args, **kwargs)
../venv/src/ccm/ccmlib/node.py:901: in start
    self.wait_for_binary_interface(from_mark=self.mark)
../venv/src/ccm/ccmlib/node.py:687: in wait_for_binary_interface
    self.watch_log_for(""Starting listening for CQL clients"", **kwargs)
../venv/src/ccm/ccmlib/node.py:588: in watch_log_for
    TimeoutError.raise_if_passed(start=start, timeout=timeout, node=self.name,
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

start = 1619481570.0236456, timeout = 90
msg = ""Missing: ['Starting listening for CQL clients'] not found in system.log:\nTail: INFO  [main] 2021-04-26 23:59:22,590 YamlConfigura""
node = 'node4'

    @staticmethod
    def raise_if_passed(start, timeout, msg, node=None):
        if start + timeout < time.time():
>           raise TimeoutError.create(start, timeout, msg, node)
E           ccmlib.node.TimeoutError: 27 Apr 2021 00:01:00 [node4] after 90.11/90 seconds Missing: ['Starting listening for CQL clients'] not found in system.log:
E           Tail: INFO  [main] 2021-04-26 23:59:22,590 YamlConfigura

../venv/src/ccm/ccmlib/node.py:56: TimeoutError
{noformat}
",,adelapena,bereng,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16672,CASSANDRA-16705,,CASSANDRA-16667,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Code,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon May 17 13:33:54 UTC 2021,,,,,,,All,,,,"0|z0qm0w:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0,,https://github.com/apache/cassandra-dtest/commit/a3b24d7617bff1eb9aa1a30474f09b211ea4c1db,,,,,,,,,See comments,,,,,"30/Apr/21 07:46;bereng;In order to follow the chain of events you need the logs [here|https://nightlies.apache.org/cassandra/trunk/Cassandra-trunk-dtest-novnode/403/Cassandra-trunk-dtest-novnode/label=cassandra-dtest,split=64/]

The test fails on

bq. ccmlib.node.TimeoutError: 27 Apr 2021 00:01:00 [node4] after 90.11/90 seconds Missing: ['Starting listening for CQL clients'] not found in system.log:

But inspecting stdout logs we can see the node is started around 23:59:21

{noformat}
23:59:21,502 ccm INFO Starting node4 with JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 java_version=8 cassandra_version=4.0, install_dir=/home/cassandra/cassandra
00:00:19,524 cassandra.cluster INFO New Cassandra host <Host: 127.0.0.4:9042 datacenter1> discovered
{noformat}

in node4 system logs we can see the actual message is really present in the log and the node has started:

{noformat}
INFO  [main] 2021-04-27 00:00:18,493 PipelineConfigurator.java:125 - Starting listening for CQL clients on /127.0.0.4:9042 (unencrypted)...
{noformat}

Didn't manage to repro locally either after several runs of 10 each

{noformat}
10 passed in 1706.22 seconds
{noformat}


We seem to have a failure where a message present at 00:00:18 is not being detected and the failure is triggered at 00:01:00 which makes no sense. I have followed the code looking for holes in the log {{mark}} logic but I didn't see any obvious problems. The test seems pretty solid looking at jenkins history, it is a test problem not a code problem, we have no previous tickets on it, there doesn't seem to be anything else to investigate,... 

Proposal: 
So I am proposing closing this one and reopening if it raises again. Then I would add some further debug to have some thread we can start pulling.;;;","03/May/21 20:16;e.dimitrova;I want to look at the test more but my first observation is the tests in that class are marked flaky with max number of runs 1.

At first I thought it is 1 run more if it fails but a quick check showed me just one run at all which makes flaky useless in this case.

So if nothing else and those should be really flaky (I didn't find a discussion around them in the original ticket where they were added), at least I would say run them twice - let's mark them with _@flaky(max_runs=2)_;;;","04/May/21 03:12;e.dimitrova;I feel that It is still a matter of timing and that the difference between the messages when they appeared in the logs doesn't mean that It took the same time for them to be processed, maybe?

I had some trouble with my local ccm and didn't manage to check this but you might want to try first reducing significantly the time out to verify my theory.;;;","04/May/21 04:36;bereng;Flaky or not, what I am worried about is the log perusing logic not having caught up on that message being present in the logs indeed. Either that or the log messages reach the log with a delay. But then it would mean there's a 20s delay somewhere which makes no sense. If that'd be the case adding flaky=2 won't help here as that would be a general problem affecting all tests. So I having no sensible proposal I can only suggest we close until/if it resurfaces as investigating further won't take me anywhere imo. But maybe a new pair of eyes have better ideas wdyt?;;;","04/May/21 11:36;adelapena;If it's of any help, it seems that the CircleCi-based test multiplexer proposed in CASSANDRA-16625 has managed to reproduce the failure 54 times in [this run|https://app.circleci.com/pipelines/github/adelapena/cassandra/376/workflows/eb463f0a-ad93-488a-89a3-bb44fbc0c578/jobs/3270] with 1000 iterations.;;;","04/May/21 12:43;e.dimitrova;I am sorry [~bereng] , it seems I confused you. These are two different unrelated things I was talking about:
 1) I saw the @flaky mark and I felt that it is worth it to mention it while we are looking into these tests as it seems useless now.

2) Indeed, the current timeout issue is a different problem. So what I meant is that the log file is processed line by line as far as I remember, if for some reason the processing was slow, that line where the message is might have not been reached yet until the 90 seconds pass.

I will try to add some logging and use the new multiplexer job from [~adelapena] to verify my theory. Thanks [~adelapena], indeed it helps. ;;;","05/May/21 04:11;bereng;Thx for the clarification [~e.dimitrova]. That would mean there is around 20s delay between the log line being issued and actually making it into the log file. I will take a look at Andres multiplex run and see if I can see anything in there.;;;","05/May/21 08:21;bereng;The only failure I could track down from [~adelapena] multi run repros the problem

We can see [here|https://circle-production-customer-artifacts.s3.amazonaws.com/picard/52e11c3bf7d0f78c41388745/608de58867e0447553dcf233-1-build/artifacts/dtest/stdout.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210505T081400Z&X-Amz-SignedHeaders=host&X-Amz-Expires=60&X-Amz-Credential=AKIAJR3Q6CR467H7Z55A%2F20210505%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=e0c2ac533b07578c306d0500b9b9c618a04799610ae57e9294a0c50827bea00d]

bq. ccmlib.node.TimeoutError: 02 May 2021 00:01:09 [node4] after 90.12/90 seconds Missing: ['Starting listening for CQL clients'] not found in system.log

it hasn't found it at 00:01:09 when it was already [present|https://circle-production-customer-artifacts.s3.amazonaws.com/picard/52e11c3bf7d0f78c41388745/608de58867e0447553dcf233-1-build/artifacts/dtest_logs/1619913669551_test_move_backwards_and_cleanup%5B9-10%5D/node4.log?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210505T081501Z&X-Amz-SignedHeaders=host&X-Amz-Expires=60&X-Amz-Credential=AKIAJR3Q6CR467H7Z55A%2F20210505%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=518882b8276c0aa7947db0d75e58beb67c63be95f5b5540fac1f13fa03e026b8] at 00:00:27
bq. INFO  [main] 2021-05-02 00:00:27,098 PipelineConfigurator.java:125 - Starting listening for CQL clients on /127.0.0.4:9042 (unencrypted)...

So sthg doesn't add up somewhere indeed...

P.D.: I tracked the failure down manually and I was lucky the 2nd run was failing as we have missing 'fail/pass' paths in this multi run.
;;;","05/May/21 12:16;e.dimitrova;I played with the new multiplexer yesterday, added some debug messages but my first try of 1000 runs didn't fail even once. I tried both java 8 and java 11. Started another run with more repetitions but it fails as the build is failing for some reason.

I will check again later today when the build is fixed;;;","06/May/21 00:07;e.dimitrova;That is so weird, I tried to push two times 1000 runs since last night, same config and same jobs on java 11 as [~adelapena] and I can't reproduce anything.

I would like to suggest this [tiny patch |https://github.com/ekaterinadimitrova2/ccm/commit/3f4ba3597f0809201f88dae403a15c33d12dd021] which in case the test fails again will help us to see where it was. The _Tail_ added before is actually _Head_ so I decided to add both.

I think having both would be good for debugging in such weird cases. WDYT?

Also, on the additional topic I brought, I think it is meaningless to keep  

_@flaky(max_runs=1)_, either we should consider there was a mistake and 2 was aimed or we can remove it to prevent further confusion. WDYT?

 ;;;","06/May/21 04:46;bereng;Hi [~e.dimitrova] thx for looking into this. I was buried yesterday and couldn't look much but I hope to do so today. Yes the 'flaky' annotation will either be removed or moved to '2' once we reach a conclusion.;;;","07/May/21 09:52;bereng;[~e.dimitrova] I have been testing this with diff timeouts and they are either too short or too long so the failure can't be repro'd like that unfortunately. So I looked at your patch and I think it is the right thing to do indeed to get some more info. I can't explain why you didn't repro bc you have the same exact code I would have produced :shrug: Would you mind running it again? maybe this time we'll be lucky. Otherwise we'll ask Andres which is in good terms with the bug repro Gods and see if he can with your patch.;;;","07/May/21 13:45;e.dimitrova;I suggest we commit the debug patch and next time it appears if it appears we can think about it, then we will have the exact view what was read from the log. 
This is a test/infra issue and also it appears very rarely. It is also for experimental feature. WDYT? ;;;","07/May/21 13:48;bereng;Why wait if we can trigger it? give it one more try imo. It's just a couple clicks if I am not missing anything?;;;","10/May/21 07:05;bereng;I went ahead and gave the multiplexer one more go. I got plenty of [failures|https://app.circleci.com/pipelines/github/bereng/cassandra/281/workflows/2afcd87f-ce10-4495-9153-a362e198d3cc/jobs/2691/artifacts] but the ones I could look at were legit. We can see [here|https://circle-production-customer-artifacts.s3.amazonaws.com/picard/5e9576564660060baefcf188/6098c61a1823b752f1333400-0-build/artifacts/dtest/stdout.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210510T064321Z&X-Amz-SignedHeaders=host&X-Amz-Expires=60&X-Amz-Credential=AKIAJR3Q6CR467H7Z55A%2F20210510%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=f108cc3b72f8eb9728c8c703b518ea0fed001a39ef1a8f3537be43c4e80b3396] the failure from {{2021-05-10 05:39:37,970}} it's indeed missing the message when you track down the log [file|https://circle-production-customer-artifacts.s3.amazonaws.com/picard/5e9576564660060baefcf188/6098c61a1823b752f1333400-0-build/artifacts/dtest_logs/1620625235394_test_move_backwards_and_cleanup%5B2-10%5D/node4.log?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210510T064822Z&X-Amz-SignedHeaders=host&X-Amz-Expires=59&X-Amz-Credential=AKIAJR3Q6CR467H7Z55A%2F20210510%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=6915219122fd8bd306dc0ae23ecac80f9ae1193254d97a2d51b9e04c9220c64c]. So I am going to increase timeout and see if I can get some good failures.;;;","10/May/21 08:13;bereng;Tail patch wasn't producing anything. But seems that just by increasing the timeout the thing runs [clean|https://app.circleci.com/pipelines/github/bereng/cassandra/282/workflows/793a0963-d319-4667-acaf-a74ec3e8b84f/jobs/2697]. It still irks me we're not bottoming out on this thing... Proposed PR [here|https://github.com/apache/cassandra-dtest/pull/135] but I would remove the ccm from Ekaterina.;;;","10/May/21 12:21;e.dimitrova;I pushed it on Friday with different timeout values and got a time when it fails but I wanted to try today with the final version of the multiplexer so I can easily track down the logs. ([~adelapena] added that option to easily find the logs you need)

I am fine to remove the ccm patch but at least rename correctly the tail to head. I will let you know if I find anything new in the logs

 ;;;","11/May/21 02:35;e.dimitrova;I fixed the CCM patch [here|https://github.com/ekaterinadimitrova2/ccm/commit/60515b59cc59dd4ac500321f6b6b3a8818ed7f88], I had a small mistake due to which the TAIL was always empty. Now it is fine, you can see where the method stopped reading from the log.

You can see in the latest [runs|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/808/workflows/737073ba-0e24-4a1f-9cdb-fffbef041a73/jobs/4568/tests#failed-test-0] I submitted with lower timeout, the message we look for is in the log but _watch_log_for_ method doesn't find the message; we just reached the timeout earlier before reaching the message in the log which we read line by line.

I am +1 on the raised timeout plus updated CCM debug message.;;;","11/May/21 16:37;e.dimitrova;I just realized... +1 also on the @flaky removal, let's not leave it not serving its goal and only bringing confusion. Thanks!

 ;;;","12/May/21 04:35;bereng;The flaky was already [removed|https://github.com/apache/cassandra-dtest/pull/135/files#diff-bea9d3b0d863b1adc1bfe294ec6af0fb32c07b8869bde21c5f9c71f9bf4ad968L229] Can you please confirm we're talking about the same flaky and this is ready to commit with?
- CCM [PR|https://github.com/ekaterinadimitrova2/ccm/commit/60515b59cc59dd4ac500321f6b6b3a8818ed7f88]
- C* OSS [PR|https://github.com/apache/cassandra-dtest/pull/135/files] (minus the requirements.txt change);;;","12/May/21 08:44;bereng;Looking at jenkins CI failures and logs today I have the impression other tests, maybe bc of the recent docker parallelization changes, are starting to hit timeouts. I am thinking of just generally raising for all tests those 90s to 120s or 180s. Wdyt?

EDIT: I am also wondering about raising cql cmds [timeouts|https://github.com/apache/cassandra-dtest/blob/trunk/dtest_setup.py#L224]...;;;","12/May/21 13:39;e.dimitrova;bq. Can you please confirm we're talking about the same flaky and this is ready to commit with?

I left a few comments in GitHub, most important, please, return the riptano/ccm repo. I used mine in requirements.txt only for test purposes. Thanks

bq.  I am thinking of just generally raising for all tests those 90s to 120s or 180s. Wdyt?

-1. We have only a few new flaky tests and raising the timeout for the whole suite doesn't seem right to me. This will lead to even longer CI runs in case of failures. I suggest we first look at those few ones and the reason for flakiness and start from there.;;;","12/May/21 13:53;bereng;The requirements.txt change I already mentioned it goes out. Good.

On the timeout issue they seem to be coming up a bit more [now|https://ci-cassandra.apache.org/job/Cassandra-4.0/38/testReport/junit/dtest-novnode.transient_replication_ring_test/TestTransientReplicationRing/test_move_forwards_and_cleanup/]. But we can go one at a time. Good.

Yep I can remove the other 'flaky' mentions in the class. Good;;;","12/May/21 14:31;e.dimitrova;bq. _The requirements.txt change I already mentioned it goes out. Good._
 My bad, I missed it, apologize

bq. _On the timeout issue they seem to be coming up a bit more now. But we can go one at a time. Good._

The link points to a failure of this test but I looked at the last 5 runs in Jenkins and there are less than 10 failures per run, some of them already known. Did I miss something else you wanted to point out to me? Just double checking myself.;;;","13/May/21 05:34;bereng;[~e.dimitrova] so if you peruse the latest runs you will notice [here|https://ci-cassandra.apache.org/job/Cassandra-4.0/38/testReport/junit/dtest-offheap.repair_tests.incremental_repair_test/TestIncRepair/test_multiple_repair/] and [here|https://ci-cassandra.apache.org/job/Cassandra-4.0/38/testReport/junit/dtest-novnode.transient_replication_ring_test/TestTransientReplicationRing/test_move_forwards_and_cleanup/] dtests timeouts on common operations like cql queries or node/cluster starts. Some for this test class but different test method, some for other tests. This lead me to speculate we probably have low generic timeouts now for jenkins hence my proposal to raise them. Of course we can do as you suggested and go one by one instead. I.e. I included a fix for CASSANDRA-16667 here for convinience.

So:
- I updated the [PR|https://github.com/apache/cassandra-dtest/pull/135] to it's final version + the 16667 fix
- CCM [PR|https://github.com/ekaterinadimitrova2/ccm/commit/60515b59cc59dd4ac500321f6b6b3a8818ed7f88] stays the same
- If you +1 I run a final CI and commit.;;;","13/May/21 12:34;e.dimitrova;Assuming you tested 16667 with the new ccm logging and you see the same issue, I am +1.

Let's run the multiplexer again for both tests to confirm the issue is solved and commit. Thank you!
{quote}This lead me to speculate we probably have low generic timeouts now for jenkins hence my proposal to raise them.
{quote}
I suggest we open an umbrella ticket to look at those classes/tests. In another ticket the solution was to move two test classes to long run tests. While I see what you mean, the number of failures we see is still just a few tests and not enough justification for me to raise the time for the thousands of tests we have which will lead to significant CI run time increase in case of failures. ;;;","14/May/21 07:43;bereng;I did a last multiplex CI run and it [lgtm|https://app.circleci.com/pipelines/github/bereng/cassandra/287/workflows/7d1e15b7-9d2d-4347-80ee-ab8cb1166155/jobs/2723]

Timeouts imo are not related to having expanded the test so now it better fits into some other 'long' category as it was your case. I just think we're close to the timeouts but time will tell. We don't have to decide that now. If you're +1 I'll revert the requirements.txt change and then we can commit.

EDIT: Let me run the whole dtests suite on MID with the ccm patch just to be extra sure... [j11|https://app.circleci.com/pipelines/github/bereng/cassandra/289/workflows/6e7f5171-2403-4318-be44-cc177655240c] and [j8|https://app.circleci.com/pipelines/github/bereng/cassandra/289/workflows/9c82de81-ffac-4db3-b044-75c7294aa7f7] lgtm;;;","14/May/21 12:44;e.dimitrova;When I mentioned the long tests, I didn't mean that this is the case here but I wanted to give an example of another class where there was different solution to timeout problems and we should verify those we see now why they appear and start from there.

Thank you, everything looks good to me!;;;","17/May/21 09:08;bereng;[~e.dimitrova] I committed the dtest change as that is independent of the ccm change. The ccm change I noticed there are changes in ccm master not tagged as cassandra-test yet. Hence I am gathering info on whether this is intentional or not. Once I know that I will commit the ccm change, I hope that is ok with you but I am being extra cautious here. ;;;","17/May/21 13:33;e.dimitrova;Absolutely, good catch! Thank you! ;;;",,,,,,,,,,,,,,,,,,,,,,,
ALTER TABLE: mixing counter and non-counter columns in one table ,CASSANDRA-16643,13375915,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aholmber,ArtemChebotko,ArtemChebotko,29/Apr/21 21:48,06/May/21 12:52,13/Jul/23 08:40,06/May/21 12:52,4.0,4.0-rc2,,,,,,CQL/Semantics,,,,0,,,"{{CREATE TABLE}} does not allow mixing counter and non-counter columns in the same table. However, this can be done with {{ALTER TABLE}}:
* {{ALTER TABLE}} can add non-counter columns to a table with counter columns; 
* {{ALTER TABLE}} can add counter columns to a table with non-counter columns.

Tested in cassandra-4.0-rc1 (also in cassandra-4.0-beta2):

{code:sql}
CREATE TABLE test1 (
  id UUID,
  my_counter COUNTER,
  PRIMARY KEY ((id))
);

ALTER TABLE test1 ADD my_text TEXT;

UPDATE test1 
SET my_counter = my_counter + 10,
    my_text = 'Test 1' 
WHERE id = 5069cc15-4300-4595-ae77-381c3af5dc5e;

SELECT * FROM test1;

 id                                   | my_counter | my_text
--------------------------------------+------------+---------
 5069cc15-4300-4595-ae77-381c3af5dc5e |         10 |  Test 1
{code}
 
{code:sql}
CREATE TABLE test2 (
  id UUID,
  my_text TEXT,
  PRIMARY KEY ((id))
);

ALTER TABLE test2 ADD my_counter COUNTER;

UPDATE test2 
SET my_counter = my_counter + 20,
    my_text = 'Test 2' 
WHERE id = 5069cc15-4300-4595-ae77-381c3af5dc5e;

SELECT * FROM test2;

 id                                   | my_counter | my_text
--------------------------------------+------------+---------
 5069cc15-4300-4595-ae77-381c3af5dc5e |         20 |  Test 2
{code}
 
{code:sql}
CREATE TABLE test3 (
  id UUID,
  my_counter COUNTER,
  my_text TEXT,
  PRIMARY KEY ((id))
);

InvalidRequest: Error from server: code=2200 [Invalid query] message=""Cannot mix counter and non counter columns in the same table""
{code}",,aholmber,ArtemChebotko,blerer,brandon.williams,e.dimitrova,jeromatron,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,aholmber,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu May 06 12:52:39 UTC 2021,,,,,,,All,,,,"0|z0qll4:",9223372036854775807,,,,blerer,e.dimitrova,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/a867abf0304439182a7225a751145e4d1d4b07c7,,,,,,,,,new unit test added,,,,,"05/May/21 20:05;aholmber;It seems some validation was omitted during some refactoring for 4.0. Proposed patch adds metadata validation to AlterTableStatement, and a small unit test.

[patch|https://github.com/aholmberg/cassandra/pull/59]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16643];;;","05/May/21 20:34;aholmber;I'm passing this along with python dtests blown up by something else. CI shows java unit and dtests in good shape.;;;","05/May/21 20:38;e.dimitrova;I also have all python dtests and cqlsh tests failing. Not sure whether it is related to the latest patch 5 hours ago. I will test it now;;;","05/May/21 21:11;e.dimitrova;Seems it is just Circle CI issue, I am pushing CI run to Jenkins while we fix the Circle issue:

https://jenkins-cm4.apache.org/job/Cassandra-devbranch/732/

 

 ;;;","05/May/21 21:22;aholmber;Thanks, but looks like that one failed on github clone.;;;","05/May/21 21:47;e.dimitrova;Thanks for the heads up. Seems like there was issue with my token maybe.

I just submitted it again [here|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/733/console] and it seems that now it worked;;;","06/May/21 09:52;blerer;The patch looks good to me. ;;;","06/May/21 11:54;e.dimitrova;+1 from me too. All dtests failed but I believe this is related to the work in progress around the new branching. There is issue with the manifest file which I believe will be handled in CASSANDRA-16642.

Shall we backport the new test to 3.11? ;;;","06/May/21 12:07;blerer;{quote}Shall we backport the new test to 3.11? {quote}

I think we can skip that part. The risk of having a regression on that area of the code in 3.0 and 3.11, is pretty low.

I will commit.;;;","06/May/21 12:52;blerer;Committed into cassandra-4.0 at a867abf0304439182a7225a751145e4d1d4b07c7 and merged into trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cqlsh completion test fails sometimes,CASSANDRA-16639,13375671,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aholmber,aholmber,aholmber,28/Apr/21 18:38,28/Apr/21 20:35,13/Jul/23 08:40,28/Apr/21 20:35,4.0,4.0-rc2,,,,,,Test/unit,,,,0,,,"{noformat}
'F EXISTS cqlshtests_9exbnsy_;' != 'F EXISTS cqlshtests_9exbnsy_ ;'
- F EXISTS cqlshtests_9exbnsy_;
+ F EXISTS cqlshtests_9exbnsy_ ;
?                             +
 : cqlsh completed 'F EXISTS cqlshtests_9exbnsy_;', but we expected 'F EXISTS cqlshtests_9exbnsy_ ;'
    """"""Fail immediately, with the given message.""""""
>>  raise self.failureException(""'F EXISTS cqlshtests_9exbnsy_;' != 'F EXISTS cqlshtests_9exbnsy_ ;'\n- F EXISTS cqlshtests_9exbnsy_;\n+ F EXISTS cqlshtests_9exbnsy_ ;\n?                             +\n : cqlsh completed 'F EXISTS cqlshtests_9exbnsy_;', but we expected 'F EXISTS cqlshtests_9exbnsy_ ;'"")
{noformat}

https://ci-cassandra.apache.org/job/Cassandra-trunk/453/testReport/junit/cqlshlib.python3.jdk8.cython.test.test_cqlsh_completion/TestCqlshCompletion/test_complete_in_drop_keyspace/",,aholmber,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,aholmber,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Apr 28 20:35:35 UTC 2021,,,,,,,All,,,,"0|z0qk2w:",9223372036854775807,,,,brandon.williams,,,,Low,,NA,,https://github.com/apache/cassandra/commit/132c01e57011dc611ab8864de1e3e2cbd861acee,,,,,,,,,"Run existing tests.

Spun out another ticket to finish missing completion tests: https://issues.apache.org/jira/browse/CASSANDRA-16640",,,,,"28/Apr/21 19:47;aholmber;This happens when the [tempfile generated for keyspace name|https://github.com/apache/cassandra/blob/10a1d65eb09a93aee32948b46b4f1a0fbc2defe0/pylib/cqlshlib/test/cassconnect.py#L43-L44] contains a non-alphanumeric character as the last -- [spacing changes|https://github.com/apache/cassandra/blob/10a1d65eb09a93aee32948b46b4f1a0fbc2defe0/pylib/cqlshlib/cqlhandling.py#L221-L224].

I'm proposing to change the keyspace name to be more predictable:
[patch|https://github.com/aholmberg/cassandra/pull/56]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16639];;;","28/Apr/21 20:35;brandon.williams;Committed, thanks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
compactions/repairs hangs (backport CASSANDRA-16552),CASSANDRA-16638,13375631,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,easyoups,easyoups,28/Apr/21 15:51,30/Apr/21 05:37,13/Jul/23 08:40,30/Apr/21 05:37,3.11.11,,,,,,,Consistency/Repair,Local/Compaction,,,0,,,"Hi

We meet an issue during repairs (but more probably compaction issue in fact) since we upgraded from 3.11.1 to 3.11.10.

We are using reaper, but the issue doesn't seem to come from it (according to [~adejanovski@hotmail.com] ). When the problem happens, repairs driven by reaper are blocked.

Basically reaper hangs with the message ""All nodes are busy or have too many pending compactions for the remaining candidate segments."" and indeed one node has a lot of compaction pending tasks :

 
{code:java}
$ nodetool compactionstats
pending tasks: 95
- mt_metrics.metric_32: 95 
{code}
Errors in log are :

 
{code:java}
WARN [CompactionExecutor:12909] 2021-04-28 08:59:51,241 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/var/lib/cassandra/d
....
WARN [CompactionExecutor:12909] 2021-04-28 09:00:19,484 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/var/lib/cassandra/d
....
WARN [CompactionExecutor:12908] 2021-04-28 09:00:51,241 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/var/lib/cassandra/d
....
WARN [CompactionExecutor:12907] 2021-04-28 08:58:51,097 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350757-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350755-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350738-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350759-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350761-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350740-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350751-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/
.... 
{code}

The error happened several times in few weeks and up to now always concerns LCS tables.

a.dejanoski mentioned me https://issues.apache.org/jira/browse/CASSANDRA-15242 but I have no trace of messages like ""disk boundaries are out of date for keyspacename.tablename"" or ""Refreshing disk boundary cache for keyspacename.tablename"".

The workaround is simple : just restart the node once it is identified. Pending compactions tasks rerun well.

We have the issue on 2 of our clusters on 3.11.10.
Does someone else met the issue ?",,brandon.williams,easyoups,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16552,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Apr 30 05:37:19 UTC 2021,,,,,,,All,,,,"0|z0qju0:",9223372036854775807,,,,,,,,Normal,,,,,,,,,,,,,,,,,,"28/Apr/21 16:09;brandon.williams;Are there any symptoms outside of reaper?;;;","28/Apr/21 17:10;marcuse;doh, seems I missed backporting CASSANDRA-16552 to 3.11, will get that fixed tomorrow

[~easyoups] you could probably workaround this issue by setting {{sstable_preemptive_open_interval_in_mb: -1}};;;","28/Apr/21 18:33;easyoups;Thanks [~marcuse] 
I will try it... Issue happens almost each week. If after 2 or 3 weeks, reaper works without hanging then the workaround works. I keep you in touch...;;;","28/Apr/21 18:35;easyoups;Hi [~brandon.williams]

Symptons outside of reaper are :
- pending tasks that do not start on 1 node (detected with nodetool compactionstats)
- the warning I reported in the description of the issue

That's all I found...

 ;;;","29/Apr/21 08:18;marcuse;mostly clean backport (test conflicts and removed some code not needed in 3.11)
https://github.com/krummas/cassandra/commits/marcuse/16552-3.11
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16552-3.11

could you sanity check [~brandon.williams]?;;;","29/Apr/21 13:18;brandon.williams;LGTM, +1;;;","30/Apr/21 05:37;marcuse;committed as https://github.com/apache/cassandra/commit/4b018b5bf4117d2377a67a495a40a7d7e49b30f5 - thanks;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Garbagecollect should not output all tables to L0 with LeveledCompactionStrategy,CASSANDRA-16634,13375174,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,scottcarey,scottcarey,scottcarey,26/Apr/21 22:25,29/Jun/21 13:41,13/Jul/23 08:40,27/Apr/21 07:43,3.11.11,4.0,4.0-rc2,,,,,Local/Compaction,,,,0,,,"nodetool garbagecollect always outputs to L0 with LeveledCompactionStrategy.

This is awful.  On a large LCS table, this means that at the end of the garbagecollect process, all data is in L0.

 

This results in an awful sequence of useless temporary space usage and write amplification:
 # L0 is repeatedly size-tiered compacted until it doesn't have too many SSTables.  If the original LCS table had 2000 tables... this takes a long time
 # L0 is compacted to L1 in one to a couple very very large compactions
 # L1 is compacted to L2, L3 to L4, etc.  Write amplification galore

Due to the above, 'nodetool garbagecollect' is close to worthless for large LCS tables.  A full compaction is always less write amplification and similar temp disk space required.  The only exception is if you can use 'nodetool garbagecolect' part-way, and then use 'nodetool stop' to cancel it before L0 is too large.  In this case if you are lucky, and the order that it chose to process SSTables coincides with tables that have the most  disk space to clear, you might free up enough disk space to succeed in your original goal.

 

However, from what I can tell, there is no good reason to move the output to L0.  Leaving the output table in the same SSTableLevel as the source table does not violate any of the LeveledCompactionStrategy placement rules, as the output by definition has a token range equal to or smaller than the source.

The only drawback is if the size of the output files is significantly smaller than the source, in which case the source level would be under-sized.   But that seems like a problem that LCS has to handle, not garbagecollect.

LCS could have a ""pull up"" operation where it does something like the following.   Assume a table has L4 as the max level, and L3 and L4 are both 'under-sized'.  L3 can attempt to 'pull up' any tables from L4 that do not overlap with the token ranges of the L3 tables.  After that, it can choose to do some compactions that mix L3 and L4 to pull up data into L3 if it is still significantly under-sized.

From what I can tell, garbagecollect should just re-write tables in place, and leave the compaction strategy to deal with any consequences.

Moving to L0 is a bad idea.  In addition to the extra write amplification and extreme increase in temporary disk space required, I observed the following:

A 'nodetool garbagecollect' was placing a lot of pressure on a L0 of a node.  We stopped it about 20% through the process, and it managed to compact down the top couple levels.  So we tried to run 'garbagecollect' again, but the first tables it chose to operate on were in L1, not the 'leafs' in L5!   This was because the order of SSTables chosen currently does not consider the level, and instead looks purely at the max timestamp in the  file.  But because we moved _very old_ data from L5 into L0 as a result of the prior gabagecollect, manytables in L1 and L2 now had very wide ranges between their min and max timestamps – essentially some of the oldest and newest data all in one table.    This breaks the usual structure of an LCS table where the oldest data is at the high levels.

 

I hope that others agree that this is a bug, and deserving of a fix.

I have a very simple patch for this that I will be creating a PR for soon.  3 lines for the code change, 70 lines for a new unit test.

 ",,brandon.williams,e.dimitrova,marcuse,scottcarey,,,,,,,,,,,,"scottcarey opened a new pull request #986:
URL: https://github.com/apache/cassandra/pull/986


   
     Before this change, garbagecollect would write all output in L0,
     causing a great deal of write amplification and temporary disk
     space use.
     This change causes the output SSTableLevel to match the input,
     making 'nodetool garbagecollect' viable on large LCS tables when
     disk space is tight, and significantly reduces overall resources
     used to complete the operation.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;26/Apr/21 22:59;githubbot;600","scottcarey closed pull request #986:
URL: https://github.com/apache/cassandra/pull/986


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Jun/21 18:05;githubbot;600","scottcarey commented on pull request #986:
URL: https://github.com/apache/cassandra/pull/986#issuecomment-869903373


   merged via commit a68a7c5181


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Jun/21 18:07;githubbot;600","scottcarey commented on pull request #986:
URL: https://github.com/apache/cassandra/pull/986#issuecomment-869903373


   merged via commit a68a7c5181


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jun/21 13:37;githubbot;600","scottcarey closed pull request #986:
URL: https://github.com/apache/cassandra/pull/986


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jun/21 13:41;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,3000,,,0,3000,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,scottcarey,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Apr 28 05:09:44 UTC 2021,,,,,,,All,,,,"0|z0qh0g:",9223372036854775807,,,,marcuse,,,,Normal,,3.10,,https://github.com/apache/cassandra/commit/a68a7c5181930053f9b513672391b45088e590c4,,,,,,,,,test included,,,,,"26/Apr/21 22:40;scottcarey;I need some minor guidance on the process.  Documentation is all over the place – some says that we must not use pull requests and must attach a patch, but it looks like PRs are utilized now?    I also don't know what the earliest branch that this should apply to is.

 

I am an Apache member.  My github account is linked to the apache org.

For now I will open a PR that can be viewed with my suggested fix.  We can correct whatever errors I've made process wise after that.;;;","26/Apr/21 22:43;brandon.williams;Opening a PR is fine and you can base your work on any branch but I would recommend trunk and then backporting can be figured out later if necessary.;;;","26/Apr/21 23:00;scottcarey;[https://github.com/apache/cassandra/pull/986]

 

Its based on the 3.11 branch, but applies cleanly to trunk as well.;;;","26/Apr/21 23:05;brandon.williams;[~marcuse] can you take a look?;;;","27/Apr/21 00:02;e.dimitrova;Hey [~scottcarey],

Thank you for the patch. I was trying to find you on Slack to say hi and help you to clear some misunderstanding from our docs, but I didn't find you in the ASF Slack. (You might want to check the #cassandra-dev channel and the dev mailing list - https://cassandra.apache.org/community/).  If you drop a question in the #cassandra-dev channel there are high chances of getting a fast response as we have contributors to the project all over the world and people are willing to help when they have a bit of time. 

Both patch and pull request submission work but you are right that pull requests are easier to handle and almost everyone use them on the project nowadays. We don't open pull requests to the Apache/cassandra repo though. Most people just have their fork where they work on things. I would suggest you to check this page (if you haven't) -https://cassandra.apache.org/doc/latest/development/patches.html?highlight=contributing.  

Also, we normally try to run some preliminary tests at least. More information on how to run tests locally or setup CI can be found here - [https://cassandra.apache.org/doc/latest/development/testing.html?highlight=testing]

Unfortunately, at this point the official Jenkins CI is available only for committers and PMC members but anyone of us will be happy to submit a CI run for you. Circle CI free tier is also an option, just bear in mind that you will see Python dtests failing  due to not enough resources available, that is expected. ;;;","27/Apr/21 05:45;marcuse;+1, running tests here before committing: https://app.circleci.com/pipelines/github/krummas/cassandra?branch=bug%2FCASSANDRA-16634;;;","27/Apr/21 06:11;marcuse;bq. The only drawback is if the size of the output files is significantly smaller than the source, in which case the source level would be under-sized.
we have CASSANDRA-7414 for this case;;;","27/Apr/21 07:43;marcuse;committed, test failures look unrelated;;;","28/Apr/21 05:09;scottcarey;Excellent.  Thanks!

 

 ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Only include versioned files in rat-report,CASSANDRA-16633,13375144,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,samt,samt,samt,26/Apr/21 18:46,17/Jun/21 17:03,13/Jul/23 08:40,27/Apr/21 08:38,2.2.20,3.0.25,3.11.11,4.0,4.0-rc2,,,Build,,,,0,,,"Recent changes to the ant build.xml file to include running the Apache Rat reporting tool break the build when there are unversioned files in the source tree.
We could modify the build to only include versioned files in the Rat report.
",,benedict,brandon.williams,mck,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16727,,,,,CASSANDRA-16558,,,,,,,,,,,,,,,,,,,0.0,samt,,,,,,,,,,,,,Degradation -> Other Exception,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 27 11:03:14 UTC 2021,,,,,,,All,,,,"0|z0qgts:",9223372036854775807,,,,benedict,mck,,,Normal,,4.0-rc1,,https://github.com/apache/cassandra/commit/5be6d7e6b1ecaaa74d394922afb57c37a132827d https://github.com/apache/cassandra/commit/26163bb12aac590289aab6deabc21fe86371e22a,,,,,,,,,Manually tested running ant rat-check with untracked files in the source tree.,,,,,"26/Apr/21 19:05;samt;Fixed in trunk, then cherry-picked to earlier branches. Some files weren't being included in the rat report due to typos in the previous {{includes}} specificiation and a handful of those had non-compliant or missing licence headers, so I've added fixes for those where necessary.

|Branch||
|[16633-2.2|https://github.com/apache/cassandra/compare/cassandra-2.2...beobal:16633-2.2]|
|[16633-3.0|https://github.com/apache/cassandra/compare/cassandra-3.0...beobal:16633-3.0?expand=1]|
|[16633-3.11|https://github.com/apache/cassandra/compare/cassandra-3.11...beobal:16633-3.11?expand=1]|
|[16633-trunk|https://github.com/apache/cassandra/compare/trunk...beobal:16633-trunk?expand=1]|;;;","26/Apr/21 19:22;benedict;Awesome. +1;;;","27/Apr/21 07:43;mck;Thanks [~samt] for this!

A small comment on [this commit page|https://github.com/apache/cassandra/commit/93f67ebbe180219b490cc872ab9a8642fd051987].;;;","27/Apr/21 08:38;samt;Thanks both, committed with [~mck]'s suggestions to 2.2 in {{5be6d7e6b1ecaaa74d394922afb57c37a132827d}} and merged up.;;;","27/Apr/21 10:15;samt;Pushed a small follow up with a couple of fixes for CI [here|https://github.com/beobal/cassandra/commit/26163bb12aac590289aab6deabc21fe86371e22a] (2.2 only, I'll merge to other branches on commit)
;;;","27/Apr/21 10:30;mck;[!https://ci-cassandra.apache.org/job/Cassandra-devbranch-artifacts/691/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-artifacts/691/];;;","27/Apr/21 10:45;mck;bq. Pushed a small follow up with a couple of fixes for CI here (2.2 only, I'll merge to other branches on commit)


+1;;;","27/Apr/21 11:03;samt;Thanks, pushed the follow up in {{26163bb12aac590289aab6deabc21fe86371e22a}} and merged to trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Logging bug during the node replacement and token assignment,CASSANDRA-16628,13374717,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,jaid,jaid,23/Apr/21 18:44,23/Apr/21 20:12,13/Jul/23 08:40,23/Apr/21 20:12,3.0.25,3.11.11,4.0-rc2,,,,,Local/Other,,,,0,,,"Hello Team,

 

I noticed a minor logging issue when a Cassandra node is trying to boot-up with a new IP address but the existing data directory. The IP address and Token fields are inter-changed.

 

*Sample Log:* 

{{WARN [GossipStage:1] 2021-04-23 18:24:06,348 StorageService.java:2425 - Not updating host ID 27031833-5141-46e0-b032-bef67137ae49 for /10.24.3.9 because it's mine}}
{{INFO [GossipStage:1] 2021-04-23 18:24:06,349 StorageService.java:2356 - Nodes () and /10.24.3.9 have the same token /10.24.3.10. Ignoring -1124147225848710462}}
{{INFO [GossipStage:1] 2021-04-23 18:24:06,350 StorageService.java:2356 - Nodes () and /10.24.3.9 have the same token /10.24.3.10. Ignoring -1239985462983206335}}

*Steps to Reproduce:*

Replace a Cassandra node with the a new IP address with the same data directory and the logs should show the messages.

*Cassandra Version*: 3.11.6

 

Please let me know if you need more details",,jaid,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Apr 23 20:12:13 UTC 2021,,,,,,,All,,,,"0|z0qe74:",9223372036854775807,,,,brandon.williams,,,,Low,,NA,,https://github.com/apache/cassandra/commit/8fd046f2557e4d50e80986b813bc904dce625e6a,,,,,,,,,not needed,,,,,"23/Apr/21 20:12;brandon.williams;Thanks! Fixed in 8fd046f2557e4d50e80986b813bc904dce625e6a;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace spinAsserts code with Awaitility code,CASSANDRA-16621,13374024,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,djanand,bereng,bereng,21/Apr/21 06:16,16/Mar/22 16:19,13/Jul/23 08:40,31/Aug/21 05:28,4.0.1,,,,,,,Test/unit,,,,0,low-hanging-fruit,,Currently spinAsserts does a similar thing to Awaitility which is being used more and more. We have now 2 ways of doing the same thing so it would be good to consolidate,,adelapena,bereng,djanand,e.dimitrova,,,,,,,,,,,,"smiklosovic closed pull request #1089:
URL: https://github.com/apache/cassandra/pull/1089


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 16:19;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,djanand,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Sep 03 05:51:54 UTC 2021,,,,,,,All,,,,"0|z0q9xk:",9223372036854775807,,,,adelapena,bereng,,,Low,,4.0,,https://github.com/apache/cassandra/commit/78c6279658d5c18a8704a8e1ab1bc5200b8b1e0b,,,,,,,,,"Test utility improvement, CI should continue passing",,,,,"29/Jun/21 03:12;djanand;The change seems reasonable and attaching a PR. Can someone please review ?;;;","29/Jun/21 03:37;bereng;Hi [~djanand],

your PR has base {{trunk}} but if you intend to fix from 4.0.x upwards you'd need to make {{4.0}} the base. Also can you include some CI please?;;;","02/Jul/21 06:42;djanand;thanks [~bereng] for taking a look. Attached the PR with 4.0 as base. 

||[CircleCi|https://app.circleci.com/pipelines/github/djanand/cassandra/1/workflows/395a1c77-b7d9-4ad3-8641-7ce353e7d90f]||[CircleCi|https://app.circleci.com/pipelines/github/djanand/cassandra/1/workflows/29b1c542-e954-4695-8f2c-7872e62a0d46]||

I think these tests would take a while. Please guide, if you think I need to run some more CI tests as I'm not super familiar with the ecosystem.;;;","05/Jul/21 05:22;bereng;[~djanand] you seem to have a few failures. I would suggest investigating them locally. Once the 'basic' tests pass I can fire for you CI with all the heavy and long tests.;;;","06/Jul/21 19:49;djanand;[~bereng] - thanks! yeah there are some failures. When I run the failed tests locally ie ViewComplexLivenessTest and ViewFilteringClustering1Test they succeed on every run. 
 The exception that I get on the [circle-ci|https://circleci.com/api/v1.1/project/github/djanand/cassandra/3/output/104/0?file=true&allocation-id=60deafb9c3492162b60b9b5e-0-build%2F58BCD97C] tests is:
{code:java}
com.datastax.driver.core.exceptions.ProtocolError: An unexpected protocol error occurred on host localhost/127.0.0.1:36945. This is a bug in this library, please report: Must not send frame with WARNING flag for native protocol version < 4
[junit-timeout] 	at com.datastax.driver.core.exceptions.ProtocolError.copy(ProtocolError.java:66)
[junit-timeout] 	at com.datastax.driver.core.exceptions.ProtocolError.copy(ProtocolError.java:27)
[junit-timeout] 	at com.datastax.driver.core.DriverThrowables.propagateCause(DriverThrowables.java:35)
[junit-timeout] 	at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:293)
{code}
-When debugging locally, I see that DriverThrowables class loads from cassandra-driver-core-3.11.0-shaded.jar which has no line:35 in it.-
 -This leads me to believe that the build on circle-ci is using a different version of driver than local.-

ps: I'm using the default .circleci/config.yml;;;","08/Jul/21 05:19;bereng;[~djanand] I am trying to run your branch on a different CI. It just needs some time to complete and the 1st attempt failed. Let's see what it does there...;;;","09/Jul/21 05:01;bereng;Run [#903|https://ci-cassandra.apache.org/job/Cassandra-devbranch/903/#showFailuresLink] failed on upgrade tests, which iirc was a thing a few days ago so it could be you only need a rebase. Atm we have 4.0 upgrade tests broken again since yesterday. I think we've just had unlucky timing. Let's wait for these to get fixed, I'll rebase then and re-run CI.;;;","09/Jul/21 07:24;djanand;[~bereng] - thanks! I have also been trying out some changes (unrelated to the awaitility fix for this ticket) to fix the failing tests. Looks like something similar was mentioned in CASSANDRA-16670. Regardless, will let keep you posted if I get those tests working.;;;","09/Jul/21 08:06;bereng;Those failing tests are weird as they never have failed before. But there could be a bug lurking you never know...;;;","09/Jul/21 08:57;bereng;We're having problems with tests given we're cutting a 4.0.0 release and some code changes need to go through. I want to wait for things to stabilize. Apologies fro the noise, sthg that should be simple it's turning into sthg a bit more involved... Murphy...;;;","13/Jul/21 05:16;bereng;I'm not forgetting about this. I am just waiting on the 4.0.0 cut test upgrade issues to resolve. Thx for your patience.;;;","13/Jul/21 06:21;djanand;[~bereng] - thanks! that's very considerate of you :)  Yeah I have been following the email updates on 4.0.0 release. :) ;;;","14/Jul/21 15:54;adelapena;This doesn't change that we still have to decide whether to use {{spinAssertEquals}} or {{Awaitility}}, but it's nice to use the same implementation for both methods. I guess that the criteria would be using {{spinAssertEquals}} when possible, and reserve the direct call to {{Awaitility}} for those cases in which more flexibility is required?

Regarding the poll interval, even though 1ms is probably the most similar thing to the original implementation, I wonder whether it would be too low. Perhaps we could use Awaitility's default interval of 100ms and then add an optimistic poll delay of zero?;;;","15/Jul/21 03:56;bereng;{quote}spinAssertEquals when possible, and reserve the direct call to Awaitility for those cases in which more flexibility is required?{quote}

+1. I wouldn't replace all spinAssert calls just it's implementation to use Awaitility. And you can call that one directly when needed

{quote}I wonder whether it would be too low{quote}

A thread.yield is probably less that that. But moving to 100ms would might even make more sense to avoid spinning the CPU on yields. I wonder what Awaitility does under the covers though..;;;","15/Jul/21 06:25;djanand;{quote}
Regarding the poll interval, even though 1ms is probably the most similar thing to the original implementation, I wonder whether it would be too low. Perhaps we could use Awaitility's default interval of 100ms and then add an optimistic poll delay of zero?{quote}

{quote}But moving to 100ms would might even make more sense to avoid spinning the CPU on yields{quote}

Agree that 1ms is too low. 100ms sgtm. I also think fibonacci polling interval might also be a good option. Thoughts?

{code:java}
.pollInterval(fibonacci(TimeUnit.MILLISECONDS))
{code}
;;;","15/Jul/21 09:31;bereng;Seems 4.0 is getting cleared of upgrade errors and some jenkins cleaning is undergoing. Let's wait the latest run, rebase and rerun CI on this 4.0 and trunk.

Fibonacci is always welcomed here...;;;","15/Jul/21 17:17;adelapena;Fibonacci polling with milliseconds is a great idea, +1;;;","15/Jul/21 18:56;adelapena;Actually, maybe Fibonacci polling might not be such a good fit for us. Unless I'm missing something, Awaitabilty doesn't try to check the condition right before timing out. For example, if we have a timeout of 10000ms, the last polling will be done at 6765ms, and there won't be any further polling until 10946ms, when the waiting will have already timed out. So, the intended timeout of 10000ms will be actually become a timeout of 6765ms, which is significantly shorter. Another example, this produces a possibly surprising timeout:
{code:java}
long start = System.currentTimeMillis();
Awaitility.await()
          .pollInterval(fibonacci(TimeUnit.MILLISECONDS))
          .atMost(10000, TimeUnit.MILLISECONDS)
          .until(() -> System.currentTimeMillis() - start >= 7000);
{code}
Unless there is a way to check the condition right before the timeout, I think it would be less surprising for the users of {{spinAssertEquals}} to just use a fixed poll interval of ~100ms. wdyt?;;;","15/Jul/21 23:43;djanand;+1 [~adelapena] - It does seem that fibonacci wouldn't work here. I implicitly assumed that Awaitility would check the condition right before timeout, but that's clearly not the case. 
Updated to use a fixed poll interval of ~100ms in the PR. 
Thanks [~bereng] for sharing.  ;;;","16/Jul/21 10:16;bereng;I went for a 4.0 rebase and lgtm: [j11|https://app.circleci.com/pipelines/github/bereng/cassandra/381/workflows/0a811695-3a11-4ae1-94be-ef3c78fd0b88] & [j8|https://app.circleci.com/pipelines/github/bereng/cassandra/381/workflows/af3b3208-9b73-47cd-bf1a-b75b8c5ea9cf]. {{ConnectionTest}} is a known offender so no worries there I would say.

You want to rebase and run 4.0 and trunk CI or do you prefer I do it for you while I am at it?;;;","16/Jul/21 22:25;djanand;That's nice. thanks! I would prefer to do it. Yeah, I did rebase the PR on 4.0. Also, updated the changes for trunk CI.
||branch || CI ||
|CI 4.0 || [j11|https://app.circleci.com/pipelines/github/djanand/cassandra/11/workflows/40ae1eb3-5292-4637-ac17-271cac1738e6] & [j8|https://app.circleci.com/pipelines/github/djanand/cassandra/11/workflows/a730dc81-11bb-413c-adaa-584ca9de8e37]|
|CI trunk || [j11|https://app.circleci.com/pipelines/github/djanand/cassandra/12/workflows/abe8f0c5-f98d-448f-828a-092af41f02db] & [j8|https://app.circleci.com/pipelines/github/djanand/cassandra/12/workflows/abe8f0c5-f98d-448f-828a-092af41f02db]|
Tracking both runs. I wonder what fixed the errors that we were getting earlier ;;;","17/Jul/21 02:28;djanand;[~bereng] - running into some of the same failures that I encountered before even after rebase. Unsure. Would you mind?;;;","19/Jul/21 06:18;bereng;How weird. I compared your & my code and they are identical. Why would you get such errors and I wouldn't? Everything seems to start with this error which makes little sense to me atm:

{noformat}
[junit-timeout] Testcase: testRangeDeletionWithoutFlush[0](org.apache.cassandra.cql3.ViewComplexDeletionsTest):	Caused an ERROR
[junit-timeout] An unexpected protocol error occurred on host localhost/127.0.0.1:34141. This is a bug in this library, please report: Must not send frame with WARNING flag for native protocol version < 4
[junit-timeout] com.datastax.driver.core.exceptions.ProtocolError: An unexpected protocol error occurred on host localhost/127.0.0.1:34141. This is a bug in this library, please report: Must not send frame with WARNING flag for native protocol version < 4
[junit-timeout] 	at com.datastax.driver.core.exceptions.ProtocolError.copy(ProtocolError.java:66)
[junit-timeout] 	at com.datastax.driver.core.exceptions.ProtocolError.copy(ProtocolError.java:27)
[junit-timeout] 	at com.datastax.driver.core.DriverThrowables.propagateCause(DriverThrowables.java:35)
[junit-timeout] 	at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:293)
[junit-timeout] 	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:58)
[junit-timeout] 	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:45)
[junit-timeout] 	at org.apache.cassandra.cql3.CQLTester.executeNet(CQLTester.java:972)
[junit-timeout] 	at org.apache.cassandra.cql3.ViewComplexTest.createView(ViewComplexTest.java:109)
[junit-timeout] 	at org.apache.cassandra.cql3.ViewComplexDeletionsTest.testRangeDeletion(ViewComplexDeletionsTest.java:247)
[junit-timeout] 	at org.apache.cassandra.cql3.ViewComplexDeletionsTest.testRangeDeletionWithoutFlush(ViewComplexDeletionsTest.java:236)
[junit-timeout] Caused by: com.datastax.driver.core.exceptions.ProtocolError: An unexpected protocol error occurred on host localhost/127.0.0.1:34141. This is a bug in this library, please report: Must not send frame with WARNING flag for native protocol version < 4
[junit-timeout] 	at com.datastax.driver.core.Responses$Error.asException(Responses.java:154)
[junit-timeout] 	at com.datastax.driver.core.DefaultResultSetFuture.onSet(DefaultResultSetFuture.java:215)
[junit-timeout] 	at com.datastax.driver.core.RequestHandler.setFinalResult(RequestHandler.java:235)
[junit-timeout] 	at com.datastax.driver.core.RequestHandler.access$2600(RequestHandler.java:61)
[junit-timeout] 	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.setFinalResult(RequestHandler.java:1011)
[junit-timeout] 	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:814)
[junit-timeout] 	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1290)
[junit-timeout] 	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1208)
[junit-timeout] 	at com.datastax.shaded.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:356)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:342)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:335)
[junit-timeout] 	at com.datastax.shaded.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:356)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:342)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:335)
[junit-timeout] 	at com.datastax.shaded.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:356)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:342)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:335)
[junit-timeout] 	at com.datastax.shaded.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:312)
[junit-timeout] 	at com.datastax.shaded.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:286)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:356)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:342)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:335)
[junit-timeout] 	at com.datastax.shaded.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
[junit-timeout] 	at com.datastax.driver.core.InboundTrafficMeter.channelRead(InboundTrafficMeter.java:38)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:356)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:342)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:335)
[junit-timeout] 	at com.datastax.shaded.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1304)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:356)
[junit-timeout] 	at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:342)
[junit-timeout] 	at com.datastax.shaded.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:921)
[junit-timeout] 	at com.datastax.shaded.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:135)
[junit-timeout] 	at com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:646)
[junit-timeout] 	at com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:581)
[junit-timeout] 	at com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:498)
[junit-timeout] 	at com.datastax.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
[junit-timeout] 	at com.datastax.shaded.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
[junit-timeout] 	at com.datastax.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[junit-timeout] 	at java.lang.Thread.run(Thread.java:748)
{noformat}

[~adelapena] does it ring a bell by any chance?

Edit: I get different failures which imo are ok: [j11|https://app.circleci.com/pipelines/github/bereng/cassandra/382/workflows/fde387d2-69b8-4213-9fbd-598203089a7f] & [j8|https://app.circleci.com/pipelines/github/bereng/cassandra/382/workflows/0a7ff153-0343-436b-ada1-2f5e7ab7c0a6];;;","19/Jul/21 16:25;adelapena;Here are some additional runs with LOWRES and HIGHRES:

||branch||resources||CI||
|4.0|LOW|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/674/workflows/b35679ab-ea54-42e5-bbca-fa2c12a290d7] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/674/workflows/57707052-cfc2-47b7-875f-520801f44bb2]|
|4.0|HIGH|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/676/workflows/5214df3b-75dc-4893-a41d-4ff2fe7a36ab] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/676/workflows/f44f558d-65e9-46ed-a697-31af338d5018]|
|trunk|LOW|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/675/workflows/d4fa9c8a-f3e4-46f3-ba33-cc4484b3b20a] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/675/workflows/9fef38c1-4727-4eff-ada6-8b782609daa5]|
|trunk|HIGH|[j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/677/workflows/5a411db9-3567-42ed-9a09-3dd1e299a27d] [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/677/workflows/649833f3-7226-4103-b96f-dcbe7ff16d5a]|

I have added some multiplexed runs {{ViewFilteringTest}} because it's one the tests failing with the {{ProtocolError}}/{{AlreadyExistsException}} errors, although I'm not finding them anymore.

What seems to be consistently failing due to the changes is {{ThreadPoolMetricsTest}}. The failure seems to be caused by the increased poll interval. We could reduce it again, but it might be better to directly use {{Awaitility}} in {{ThreadPoolMetricsTest.spinAssertEquals}} with a lower interval or, even better, try to use a better concurrency control in the test.;;;","19/Jul/21 17:28;adelapena;I'm not totally sure about how the poll interval affects {{ThreadPoolMetricsTest.testJMXEnabledThreadPoolMetricsWithBlockedThread}}, but I think that [the failing assert|https://github.com/apache/cassandra/blob/a9abf5accb2265c6394bf8134dc5496c5505375c/test/unit/org/apache/cassandra/metrics/ThreadPoolMetricsTest.java#L162] is wrong. The tasks {{task5}} and {{task6}} are asynchronously submitted to the the executor, so they can be executed in any order. I think that the test should consider that they can be submitted in any order, [this way|https://github.com/adelapena/cassandra/commit/4a47cb2f3e6267cd307d5ac907e8a45b9d6b8468]. As soon as we make this change the test seems to consistently pass independently of the poll interval ([j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/678/workflows/29642061-8a38-4c59-9e63-b1cb3f4d66eb/jobs/6885] and [j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/678/workflows/29642061-8a38-4c59-9e63-b1cb3f4d66eb/jobs/6883]). 

Also, as mentioned before, I think it could be useful to have an optimistic poll delay of zero, independent of the poll interval, so tests like this one can have better execution times. For example, {{ThreadPoolMetricsTest}} with a poll delay of zero and poll interval of 100 passes in less than half a second, while with only the poll interval it needs around five seconds to finish.;;;","20/Jul/21 06:03;bereng;- +1 to {{ThreadPoolMetricsTest}} fixes
- +1 to the optimistic poll. Also the {{ConnectionTest}} should fail the test case whereas it is timming out so that needs some tunning as well.
- The v4 protocol thing seems to be sthg that only happens to Jogesh. I need to dig a bit more...;;;","09/Aug/21 07:46;bereng;Hi [~djanand] I am back from my break. Now that 4.0 is out everything, including CI, is more stable. Do you need some help with getting the latest changes done? I can carry it across the finish line for you if you prefer so.;;;","18/Aug/21 09:54;bereng;Rebased and included latest suggestions [here|https://github.com/apache/cassandra/pull/1153]. CI is running but so far lgtm [j8|https://app.circleci.com/pipelines/github/bereng/cassandra/394/workflows/72850a48-4ba7-41ee-a08a-b21dbca0aa82] & [j11|https://app.circleci.com/pipelines/github/bereng/cassandra/394/workflows/b24e1126-767e-49c6-96a1-f283be90bd43];;;","18/Aug/21 12:22;adelapena;CI looks good to me.

[~bereng] the only changes from [~djanand]'s patch are the fixes in {{ThreadPoolMetricsTest}} suggested [here|https://github.com/adelapena/cassandra/commit/4a47cb2f3e6267cd307d5ac907e8a45b9d6b8468] and the poll delay mentioned above, right? I think that's ready to commit.;;;","18/Aug/21 14:05;bereng;Yep I included your latest suggestions. I will merge tomorrow in case he is around and wants to drop a comment or sthg.;;;","18/Aug/21 17:10;djanand;[~bereng] & [~adelapena] +1. thanks so much and lgtm. (y);;;","19/Aug/21 07:16;bereng;I just thought we didn't run we didn't run compression, long, etc junits. Let me run a jenkins ci first to be on the safe side. Also next week I am OOO so I might commit when I am back preferably unless Andres beats me to it.

Edit: compression & long tests lgtm on circle. But stress and other I'll wait for jenkins to be up again, it's down for maintenance now.;;;","20/Aug/21 06:31;bereng;Ci on jenkins 4.0 lgtm: https://ci-cassandra.apache.org/job/Cassandra-devbranch/1045/
CI on trunk lgtm: https://ci-cassandra.apache.org/job/Cassandra-devbranch/1046/

I'll commit when I am back from OOO. I know if I merge now Murphy is going to do his thing and I will have to be fixing stuff during my OOO otherwise...;;;","31/Aug/21 05:29;bereng;[~djanand] thx for your work here and apologies you hit a window where we super busy and CI didn't want to collaborate. Any other ticket you fancy should be much smoother.;;;","03/Sep/21 00:36;djanand;[~bereng] - (y) thanks for the great communication and help on this. There goes the commit to trunk and 4.0. :)  Yeah, I did hit the CI bottleneck but found quick help from you and Andres. I would be happy to look into some other tickets as well. I see we have other low-hanging fruits but many don't have details on the ticket. Would rather comment on those for additional info. ;;;","03/Sep/21 05:51;bereng;Feel free to ping me on the tickets you fancy nosing around and I'll see if it's some I can help with.;;;",,,,,,,,,,,,,,,,,
Loss of commit log data possible after sstable ingest,CASSANDRA-16619,13373819,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,20/Apr/21 10:17,26/Apr/22 19:47,13/Jul/23 08:40,17/May/21 08:47,3.0.25,3.11.11,4.0,4.0-rc2,,,,Local/Commit Log,,,,0,,,"SSTable metadata contains commit log positions of the sstable. These positions are used to filter out mutations from the commit log on restart and only make sense for the node on which the data was flushed.

If an SSTable is moved between nodes they may cover regions that the receiving node has not yet flushed, and result in valid data being lost should these sections of the commit log need to be replayed.

Solution:
The chosen solution introduces a new sstable metadata (StatsMetadata) - originatingHostId (UUID), which is the local host id of the node on which the sstable was created, or null if not known. Commit log intervals from an sstable are taken into account during Commit Log replay only when the originatingHostId of the sstable matches the local node's hostId.

For new sstables the originatingHostId is set according to StorageService's local hostId.
For compacted sstables the originatingHostId set according to StorageService's local hostId, and only commit log intervals from local sstables is preserved in the resulting sstable.

discovered by [~jakubzytka]
",,aholmber,blambov,blerer,brandon.williams,dcapwell,douglasawh,e.dimitrova,jeromatron,jjordan,jlewandowski,smiklosovic,tsteinmaurer,yifanc,,,"jacek-lewandowski opened a new pull request #976:
URL: https://github.com/apache/cassandra/pull/976


   Co-authored-by: Jakub Zytka <jakub.zytka@datastax.com>
   Co-authored-by: Jacek Lewandowski <jacek.lewandowski@datastax.com>


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Apr/21 12:00;githubbot;600","jacek-lewandowski opened a new pull request #977:
URL: https://github.com/apache/cassandra/pull/977


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Apr/21 12:38;githubbot;600","jacek-lewandowski opened a new pull request #978:
URL: https://github.com/apache/cassandra/pull/978


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Apr/21 20:49;githubbot;600","jacek-lewandowski opened a new pull request #1007:
URL: https://github.com/apache/cassandra/pull/1007


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/May/21 10:27;githubbot;600","blerer closed pull request #976:
URL: https://github.com/apache/cassandra/pull/976


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 08:59;githubbot;600","blerer commented on pull request #976:
URL: https://github.com/apache/cassandra/pull/976#issuecomment-851957244


   Merged manually


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 08:59;githubbot;600","blerer closed pull request #977:
URL: https://github.com/apache/cassandra/pull/977


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 08:59;githubbot;600","blerer commented on pull request #977:
URL: https://github.com/apache/cassandra/pull/977#issuecomment-851957486


   Merged manually


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 08:59;githubbot;600","blerer commented on pull request #978:
URL: https://github.com/apache/cassandra/pull/978#issuecomment-851957840


   Merged manually


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 09:00;githubbot;600","blerer closed pull request #978:
URL: https://github.com/apache/cassandra/pull/978


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Jun/21 09:00;githubbot;600","blerer closed pull request #1007:
URL: https://github.com/apache/cassandra/pull/1007


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:35;githubbot;600","blerer commented on pull request #1007:
URL: https://github.com/apache/cassandra/pull/1007#issuecomment-859669358


   Merged manually


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:38;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,7200,,,0,7200,,,,,,,,,,,,,,CASSANDRA-17042,,,,,,,,,,,,,,,,,,,,,,,,0.0,jlewandowski,,,,,,,,,,,,,Correctness -> Recoverable Corruption / Loss,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 26 19:44:18 UTC 2022,,,,,,,All,,,,"0|z0q8o0:",9223372036854775807,,,,blambov,blerer,,,Normal,,0.3,,https://github.com/apache/cassandra/commit/d84c6e98106e7b0c205f019ee24d416d0bb65f37,,,,,,,,,run regression tests,,,,,"20/Apr/21 16:17;dcapwell;bq. If an SSTable is moved between nodes

What method are you using to ""move"" SSTables?  Streaming and nodetool import are expected to remove this info; can you elaborate?;;;","21/Apr/21 20:24;jlewandowski;[~dcapwell] - how the streaming is expected to remove this info? I can see that zero copy streaming moves the whole files between the nodes and there is no transformation which removes that information.;;;","21/Apr/21 20:33;dcapwell;that sounds like a bug in zero-copy streaming then, ideally we should strip that info out before adding the SSTables;;;","21/Apr/21 20:42;dcapwell;Looking at importer I don't see it cleaning up https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/SSTableImporter.java#L365-L380. Ideally we should drop it, and ancestors (also missing);;;","21/Apr/21 20:43;yifanc;ZCS streams a file as-is and w/o loading it into memory, hence fast. To remove a field metadata, a node needs to load the file into memory when receiving from remote. 

I think it is an expected behavior with ZCS. 

To distinguish, adding the original hostID in the metadata sounds valid.

-- edit --

Talked with [~dcapwell] on slack. In the case of ZCS, the sstable metadata is updated after flushing the bytes. See [here.|https://github.com/apache/cassandra/blob/0fd8f0a52fbd69c47d073373abfe7d2437bbd9ca/src/java/org/apache/cassandra/db/streaming/CassandraEntireSSTableStreamReader.java#L142] Currently, it does not reset the commitLogInterval. But it is possible to just add a step to reset, and avoid updating the sstable format, i.e. add a new field. ;;;","21/Apr/21 20:58;dcapwell;bq. a node needs to load the file into memory when receiving from remote

we would already when we open the file, so can strip this out still;;;","21/Apr/21 21:03;jjordan;[~dcapwell] this isn't just about ZCS.  Any backup/restore process that copied an SSTable around is also affected.  If a given node did not create the CommitLogPosition information then it needs to be ignored when loading the sstable.  Hence the proposal to store the hostid in the metadata.  If the hostid in the sstable doesn't match the hostid of the current node, then you can just ignore that erroneous information.  This affects 3.x clusters as well, not just 4.x with ZCS.;;;","21/Apr/21 21:30;dcapwell;A backup/restore process which bypasses nodetool import and directly dumps the files in the CF directory makes sense to hit this, but if you go through import I would hope we strip out all the metadata which is no longer relevant (which we are trying to do in import as commit log position isn't the only thing we need to deal with).  If we special case commit log, what do we do with other things such as repair, ancestry, level, etc?  

Since the cases which load SStables from external writers are few and well known, I feel it makes the most sense to make sure each strips the metadata the same way. Adding a method to MetadataSerializer such as resetCommitLogPosition and calling it in the places which import files would handle this without requiring a format change (import allows more flexibility in what we strip out, which backup/restore processes can use.  So nice to have this method rather than a resetNonLocalMetadata method).;;;","22/Apr/21 07:09;blambov;{quote}what do we do with other things such as repair, ancestry, level, etc?
{quote}
With this ticket, we _have_ the originating host id, so we have the means to ignore non-relevant information, whether it is in commit log, compaction or anywhere.

There's some room to make the interface more generic, i.e. have a mechanism to mark fields as local so that they can be properly combined when doing compaction (which can easily be done in a separate ticket), but this IMHO is a better solution to the problem as it handles all manners of transfer and also allows correcting errors caused by tables already transferred by the time a bug with local metadata is uncovered.;;;","22/Apr/21 19:14;blerer;One problem with a new SSTable version is that if you hit an issue after upgrading you might not be able to downgrade your cluster without losing some data. I agree that the current solution is probably better, nevertheless introducing a new SSTable version is not without consequence until we introduce a mechanism as the one descripbe by [~cscotta] in the roadmap discussion.
Would it makes sense to use another approach for now and introduce the change later on (either when we have other reasons to introduce a new SSTable format or when we have a safety mechanism) ? ;;;","23/Apr/21 01:47;jjordan;Actually new minor sstable versions that only add new metadata fields are fine. If you downgrade the previous version should still be able to read the files.;;;","23/Apr/21 01:49;jjordan;There is only a downgrade issue for major version bumps of sstables.;;;","23/Apr/21 09:37;jlewandowski;I've started CI builds:

https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/703/
https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/704/
https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/705/;;;","26/Apr/21 15:04;blerer;As {{4.0-rc1}} has been released we need to provide forward compatibility for data. I do not think it is the case with the current patch. Users using {{4.0-rc1}} will have an {{na}} format *without* hostID whereas when they will deploy {{4.0-rc2}} they will have an {{na}} format *with* hostID which will fail to read the {{na}} SSTables from the {{4.0-rc1}}. To fix that I think that we need to introduce a new {{nb}} version.

Regarding the patches, we should refactor the {{MetadataSerializerTest.testXReadY}} tests to ensure that they test all the possible combinations not only some of them.;;;","27/Apr/21 11:29;jlewandowski;Thanks you [~blerer], I'll apply the requested changes;;;","30/Apr/21 11:50;jlewandowski;Started CI tests:
https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/728/ (4.0) - eventually looks good I guess

https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/729/ (3.11)
https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/724/ (3.0);;;","05/May/21 09:18;blerer;+1 Thanks for all the hard work [~jlewandowski];;;","06/May/21 09:57;blerer;Committed into 3.0 at d84c6e98106e7b0c205f019ee24d416d0bb65f37 and merged into cassandra-3.11, cassandra-4.0 and trunk;;;","06/May/21 18:37;jlewandowski;thank you [~blerer];;;","13/May/21 13:29;jlewandowski;Unfortunately I missed moving the originating host id to the end in 4.0 PR
here is the fix: https://github.com/apache/cassandra/pull/1007
;;;","13/May/21 15:54;e.dimitrova;Thank you [~jlewandowski], CircleCI run submitted:
[Java 8 | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/821/workflows/a53aac7b-ecee-4597-9d27-66a9d6b9ab90] | [Java 11 | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/821/workflows/02eba6a1-5601-45f1-9743-16b3f04beaf8];;;","13/May/21 16:07;e.dimitrova;Jenkins run also submitted [here|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/773/];;;","14/May/21 10:25;jlewandowski;[~e.dimitrova] I've missed regenerating {{nb}} in legacy sstables after the change - fixed that and rerun the tests: https://jenkins-cm4.apache.org/view/patches/job/Cassandra-devbranch-test/524/
;;;","14/May/21 23:12;e.dimitrova;Thank you [~jlewandowski], I will review the patch on Monday;;;","17/May/21 08:19;blerer;The patch looks good to me. Sorry, for missing that part in the review.
I will commit
;;;","17/May/21 08:46;blerer;Committed into cassandra 4.0 at d35f36cd055419f5ba5b82f2efc047348c71b530 and merged into trunk.;;;","10/Nov/21 06:55;tsteinmaurer;Regarding the WARN log, which got introduced by that ticket, e.g.:
{noformat}
WARN  [main] 2021-11-08 21:54:06,826 CommitLogReplayer.java:253 - Origin of 1 sstables is unknown or doesn't match the local node; commitLogIntervals for them were ignored
{noformat}

While I understand the intention to ensure / avoid things when SSTables have been copied around (or e.g. due to a restore), the WARN log also seems to happen when Cassandra 3.11.11 reads pre-""*me*"" SSTables, thus e.g. from 3.11.10. I understand that the WARN log will go away eventually on its own resp. for sure (I guess?) after running ""nodetool upgradesstables"".

These sort of WARN log has produced quite some confusion and customer interaction for on-premise customer installations.
* Would it be possible to WARN only if we are in context of a ""me"" SSTable to avoid confusion after upgrading from pre-3.11.11?
* Would it be possible to mention a SSTable minor upgrade in e.g. {{NEWS.txt}} (or perhaps I missed it), as there might be tooling out there which counts number of SSTables per ""format"" via file name

Many thanks.;;;","26/Nov/21 14:45;smiklosovic;How am I supposed to do a point-in-time restoration using a commit log from the other node when it gets skipped as shown in the previous comment? That is by means of pointing Cassandra to dir with logs and modifying commitlog_archiving.properties.;;;","29/Nov/21 09:10;smiklosovic;I think this feature is broken on the scenario when I have a commit log I want to replay for a completely diffent / new node which has UUID not matching the one in the commit log. The way how to workaround this will be in 4.1 as done in https://issues.apache.org/jira/browse/CASSANDRA-14582 however I am afraid that point in time restoration of all other Cassandra versions, since this patch was introduced, is broken. ;;;","29/Nov/21 10:31;blambov;[~tsteinmaurer], could you please open a separate ticket with your suggestions, so that the fix can be tracked correctly?
{quote} How am I supposed to do a point-in-time restoration using a commit log from the other node when it gets skipped as shown in the previous comment? 
{quote}
The patch ensures that the commit log will _not_ be skipped, even if it matches spans that sstables already cover. The problem you are describing is not a correctness one – the node will ignore intervals and hence replay all commit log data that it finds. Since mutations are idempotent, this will work correctly, albeit slower than before. The difference is that it will not mess up if the wrong sstable ended up in the restore set for whatever reason.;;;","29/Nov/21 10:48;smiklosovic;No, I think I am still right in what I wrote. It breaks point-in-time restoration. If you set property ""restore_point_in_time"" in commitlog_archiving.properties, with this patch it is just ignored and all is replayed. So you do not have any possibility to replay to some point in time for a completely new node. I still consider this to be a regression.

Lets say you have a cluster of 5 nodes you are taking snapshots of regularly as well as all commit logs in between and all this stuff is uploaded to some backup storage.

Then on restore, you want to regenerate the cluster as it was, point-in-time precision. With backup, I have also backed up the information about tokens so I set initial_tokens field in yaml etc.

So when I put it all in place, SSTables will match the nodes (because tokens have not changed) and I want to replay the commit logs, but since host ids are generated and I cant set them up on my own as shown in the other ticket I linked, for previous versions, pit restore will stop to work properly even my tokens and all that stuff is just completely fine and I know what I do.

This was all possible to do previously. Now I end up with all data being replayed even I do not want that.;;;","29/Nov/21 13:14;blambov;Could you elaborate why this change would cause the restore point to be ignored?;;;","29/Nov/21 13:50;smiklosovic;Maybe my wording was not precise enough so let me fix and reiterate on that.

As you said, when it detects that the commit log was not created on the node we try to replay it on, it will effectively replay all mutations. I have a unit test for this and I noticed that when I created 6 mutations and I took a snapshot of that and I created two more mutations but I have not made a snapshot of that but I backed up a commit log, when I replayed commit logs in such a way that I was expecting 7 mutations to be present (6 from sstables + 1 from logs), I was still getting 8 mutations and after looking into the logs I discovered that message which lead me to this ticket.

So in that sense - ""restore_point_in_time"" is effectively ignored in cases when I want to restore to a completely new node because its host id will be generated in such a way that it will not match the host id of the commit log I want to replay - so it will replay all mutations - but I do not want that.;;;","29/Nov/21 14:02;brandon.williams;I think we can just add a flag to disable to get around this.;;;","29/Nov/21 14:15;smiklosovic;Ok I am reading this: [https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLogReplayer.java#L290-L313]

After closer look it seems that it relates to SSTables, not commit logs. So basically it will replay all ""commitLogIntervals"", whatever it means, I am not familiar with this code, and it does not have anything in common with restore_point_in_time setting or anything related to that replay path. It is just because SSTables were created on the other node, host ids do not match, so it will replay all commit log intervals and these commit log intervals are maybe covering all intervals of commit logs I want to replay, right? Because, clearly, there is less mutations, physically, in these sstables then in sstables + commit logs so when I see all mutations being replayed, the stuff this patch introduced will somehow replay it all ...;;;","29/Nov/21 14:29;jlewandowski;[~smiklosovic] you mentioned you have some test to demonstrates the problem - could you share it?;;;","29/Nov/21 14:32;blambov;Rechecking the code, the point in time in restores is applied in {{MutationInitiator.initiateMutation}} [here|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLogReplayer.java#L247]. What this patch may change is the filtering by commit log position done [later in the same method|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLogReplayer.java#L265].

I still do not see any evidence that this patch is affecting PIT restore in any way, other than making replay slower because it could be needlessly replaying mutations that are already present in sstables. Granted, the latter is an issue and may warrant risking correctness by flagging this out, but reusing the same ID through porting CASSANDRA-14582 to earlier versions is most probably a better solution.;;;","29/Nov/21 18:04;jjordan;I would expect someone to see more data replayed, because the intervals would not be ignored, but the end result data wise should be the same. The data in the commitlogs should be idempotent so it is safe to replay even if it is already in a given sstable.;;;","29/Nov/21 18:10;smiklosovic;I ll keep an eye on this, I was trying to reproduce it but I cant :D But I am absolutely sure I was getting this, multiple times in a row. I could not wrap my head around this. I am not sure if it is happening non-deterministically or what.;;;","26/Apr/22 19:44;douglasawh;oops, I was wanting to do a search for things since 3.11.9 but I changed this bug. I clearly need more coffee. going to see if I can figure out what it was.

UPDATE: Unfortunately, this is not on Wayback...digging.

UPDATE: History tab to the rescue;;;",,,,,,,,,,,,,
IntelliJ configuration is broken after recent changes in build.xml,CASSANDRA-16618,13373772,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,20/Apr/21 07:16,19/Nov/21 06:50,13/Jul/23 08:40,22/Apr/21 21:41,4.0,4.0-rc2,,,,,,Build,,,,0,,,"IntelliJ configuration is broken after recent changes in build.xml

In particular, it does not resolve {{build/test/lib/jars}} as library folder

 !screenshot-1.png! ",,e.dimitrova,jlewandowski,mck,,,,,,,,,,,,,"jacek-lewandowski opened a new pull request #973:
URL: https://github.com/apache/cassandra/pull/973


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 07:36;githubbot;600","michaelsembwever commented on a change in pull request #973:
URL: https://github.com/apache/cassandra/pull/973#discussion_r616533296



##########
File path: ide/idea-iml-file.xml
##########
@@ -49,25 +49,27 @@
         <orderEntry type=""module-library"">
             <library>
                 <CLASSES>
-                    <root url=""file://$MODULE_DIR$/lib"" />
+                    <root url=""file://$MODULE_DIR$/build/lib/jars"" />
                 </CLASSES>

Review comment:
       do we need both `<CLASSES>` sections? (only jar files are found in `build/lib/jars` and `build/test/lib/jars`)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 09:59;githubbot;600","jacek-lewandowski commented on a change in pull request #973:
URL: https://github.com/apache/cassandra/pull/973#discussion_r616537421



##########
File path: ide/idea-iml-file.xml
##########
@@ -49,25 +49,27 @@
         <orderEntry type=""module-library"">
             <library>
                 <CLASSES>
-                    <root url=""file://$MODULE_DIR$/lib"" />
+                    <root url=""file://$MODULE_DIR$/build/lib/jars"" />
                 </CLASSES>

Review comment:
       perhaps we do not, I've just taken the file generated by IntelliJ and those entries were there. I'll try if we can safely remove them




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 10:05;githubbot;600","jacek-lewandowski commented on a change in pull request #973:
URL: https://github.com/apache/cassandra/pull/973#discussion_r616556077



##########
File path: ide/idea-iml-file.xml
##########
@@ -49,25 +49,27 @@
         <orderEntry type=""module-library"">
             <library>
                 <CLASSES>
-                    <root url=""file://$MODULE_DIR$/lib"" />
+                    <root url=""file://$MODULE_DIR$/build/lib/jars"" />
                 </CLASSES>

Review comment:
       ok, unfortunately we cannot remove `CLASSES` entries, IntelliJ would recognise it as an empty library :(




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 10:29;githubbot;600","alex-ninja commented on pull request #973:
URL: https://github.com/apache/cassandra/pull/973#issuecomment-851636787


   Looks like this PR has been merged and can be closed now.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/May/21 18:56;githubbot;600","jacek-lewandowski closed pull request #973:
URL: https://github.com/apache/cassandra/pull/973


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 06:50;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,3600,,,0,3600,,,,,,,,,,,,,,,CASSANDRA-16557,,,,,,,,,,,,,,,,,,"20/Apr/21 07:21;jlewandowski;screenshot-1.png;https://issues.apache.org/jira/secure/attachment/13024308/screenshot-1.png",,,,,1.0,jlewandowski,,,,,,,,,,,,,Packaging,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Apr 22 21:40:47 UTC 2021,,,,,,,All,,,,"0|z0q8dk:",9223372036854775807,,,,e.dimitrova,mck,,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/26bf07890e4d91cbf7c6219295f69d6907019eab,,,,,,,,,manual testing,,,,,"22/Apr/21 17:05;mck;+1;;;","22/Apr/21 17:30;e.dimitrova;+1, I will commit it later today, thanks;;;","22/Apr/21 21:40;e.dimitrova;Committed [here|https://github.com/apache/cassandra/commit/26bf07890e4d91cbf7c6219295f69d6907019eab], thank you!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Harden internode message resource limit accounting against serialization failures,CASSANDRA-16616,13373706,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jmeredithco,jmeredithco,jmeredithco,19/Apr/21 21:26,16/Mar/22 15:40,13/Jul/23 08:40,20/Apr/21 17:27,4.0,4.0-rc1,,,,,,Messaging/Internode,,,,0,,,"If the internode messaging exception recovery code fails and is unable to correctly adjust the resource limits for an OutboundConnection, it affects the other connection types sharing the same OutboundConnections so that any of the connections could hit {{assert using >= 0;}} in
{{org.apache.cassandra.net.ResourceLimits.Concurrent#release}}.

While it is possible to modify all of the outbound connection code to re-initialize all of the connections with a correct limit, the effort to test and maintain the recovery code seems too high for something that should ""never happen"" (except it did once, which is why it needs hardening).  The safer option is to kill the JVM and have whatever external monitoring is in place restart the instance in a known good state.

Additionally, the logging for dropping outbound messages that have expired or are unserializable messages takes place after the recovery handling logic. If there are problems with the recovery logic that throw an exception, the message is never logged for future diagnosis. Logging should take place first, and then releasing capacity/handling the expiration/serialization.

Discovered on a branch modified for testing that threw an exception in the Verb.serializeSize method.",,blerer,dcapwell,jmeredithco,yifanc,,,,,,,,,,,,"jonmeredith opened a new pull request #972:
URL: https://github.com/apache/cassandra/pull/972


   See [CASSANDRA-16616](https://issues.apache.org/jira/browse/CASSANDRA-16616).
   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 21:33;githubbot;600","smiklosovic closed pull request #972:
URL: https://github.com/apache/cassandra/pull/972


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:40;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jmeredithco,,,,,,,,,,,,,Degradation -> Other Exception,,,,,,,,Normal,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 20 16:53:28 UTC 2021,,,,,,,All,,,,"0|z0q7yw:",9223372036854775807,,,,blerer,dcapwell,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/3918a67e67d2de8064dc98beb5166a5491c80b1e,,,,,,,,,"[Branch|https://github.com/jonmeredith/cassandra/tree/C16616]
[PR|https://github.com/apache/cassandra/pull/972]
[CircleCI|https://app.circleci.com/pipelines/github/jonmeredith/cassandra?branch=C16616]",,,,,"20/Apr/21 09:33;blerer;The patch looks good to me +1.;;;","20/Apr/21 16:12;dcapwell;+1;;;","20/Apr/21 16:22;jmeredithco;Thanks for the speedy reviews.;;;","20/Apr/21 16:53;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16616-trunk-82FED7F5-8760-4D6D-95B0-84E9D9393B22]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16616-trunk-82FED7F5-8760-4D6D-95B0-84E9D9393B22]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/688/]|
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky test_pending_range,CASSANDRA-16614,13373531,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,bereng,bereng,19/Apr/21 07:57,13/May/21 06:39,13/Jul/23 08:40,26/Apr/21 11:29,4.0-rc2,,,,,,,Test/dtest/python,,,,0,,,"Flaky [test_pending_range|https://ci-cassandra.apache.org/job/Cassandra-trunk/445/testReport/junit/dtest-large-novnode.pending_range_test/TestPendingRangeMovements/test_pending_range/]

{noformat}
Error Message

AssertionError: assert None is not None  +  where None = <function search at 0x7f29dfa83b80>('127\\.0\\.0\\.1.*?Down.*?Moving', '\nDatacenter: datacenter1\n==========\nAddress         Rack        Status State   Load            Owns               ...   rack1       Up     Normal  90.86 KiB       40.00%              5534023222112865484                         \n\n\n  ')  +    where <function search at 0x7f29dfa83b80> = re.search
{noformat}
",,adelapena,bereng,,,,,,,,,,,,,,"bereng opened a new pull request #132:
URL: https://github.com/apache/cassandra-dtest/pull/132


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 08:10;githubbot;600","bereng closed pull request #132:
URL: https://github.com/apache/cassandra-dtest/pull/132


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/May/21 06:39;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,bereng,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Apr 26 11:27:02 UTC 2021,,,,,,,All,,,,"0|z0q6w0:",9223372036854775807,,,,adelapena,bereng,,,Normal,,2.1.13,,https://github.com/apache/cassandra-dtest/commit/2032cb8503d9a3e90822de72458a09dd07d30b7e,,,,,,,,,See comments,,,,,"20/Apr/21 08:41;bereng;The window of opportunity for the test to check the node is Down/Moving on {{nodetool}} is too small. It may have already gone to Down/Normal by the time we check. So better check all nodes saw the node moving in the logs instead.

Logs of failed run [here|https://nightlies.apache.org/cassandra/trunk/Cassandra-trunk-dtest-large-novnode/148/Cassandra-trunk-dtest-large-novnode/label=cassandra-dtest-large,split=3/].;;;","20/Apr/21 10:16;bereng;Multiplexing locally seems to work ok

{noformat}
pytest --count 30 -rP --cassandra-dir=../16614 pending_range_test.py::TestPendingRangeMovements::test_pending_range
30 passed in 2353.96 seconds
{noformat};;;","22/Apr/21 11:51;adelapena;The failure can be consistently reproduced by inserting a sleep of a few seconds [right before killing the node|https://github.com/apache/cassandra-dtest/blob/trunk/pending_range_test.py#L67], simulating a slow CI environment. That makes the other nodes to see the down node as not moving, reproducing the reported failure.

The proposed patch replaces the check that verifies that the other nodes see the node as {{MOVING}} by verifying that the nodes have seen the movement, which is true either if it's still {{MOVING}} or if has gone back to {{NORMAL}}. However, the original purpose of the test was testing the {{MOVING}} scenario, since the original bug didn't affect the case where the down node has gone back to {{NORMAL}}. In other words, we want to test while the node is moving, not when it has moved.

This problem can be seen if we add the aforementioned sleep to simulate a slow CI environment and we run the modified test against a Cassandra version that contains the bug fixed by CASSANDRA-10887, for example 3.0.2 ({{--cassandra-version=3.0.2}}). In this case the test will always pass without detecting the bug that it's meant to detect.

I think we should fix the test to make sure that the down node is always seen as {{MOVING}} by the other nodes. We could do that by killing the node while it is sleeping for {{ring_delay_ms}} before actually moving the data. That time window is 30 seconds, which seems more than enough time to do the log checks and kill the node. We can even further increase the value of {{ring_delay_ms}} to be totally sure that we have enough time to kill the node while it's still moving. Since {{nodetool move}} waits for the stream/fetch phase, the test can simply call {{nodetool move}} asynchronously and wait for the log entries reporting the {{MOVING}} status before killing the node, as it's done in [this commit|https://github.com/adelapena/cassandra-dtest/commit/e7aa346c0fe94d26e9a1ce4e607caec3353059dd]. This seems to pass even if we add a sleep before killing the node, and it still detects the original bug if we use a pre-CASSANDRA-10887 Cassandra version.

wdyt?;;;","23/Apr/21 06:34;bereng;[~adelapena] excellent analysis. My patch would be testing sometimes while in MOVING state and sometimes when the node had already moved back to NORMAL, which is what I had seen perusing the logs. That is not correct and your patch is the right choice. I think you should take this ticket as you pinned it down.

I multiplexed it locally a bit to make sure and LGTM so I am +1 on your patch

{noformat}
pytest --count 30 -rP --cassandra-dir=~/work/repos/bdpWS/16614 pending_range_test.py::TestPendingRangeMovements::test_pending_range
30 passed in 1558.32 seconds
{noformat}


Also ins the spirit of CASSANDRA-16625 and just bc it is super useful would you be ok we add dtest-repeat to requirements.txt? It is what I used to multiplex locally your dtest commit. Feel free to decline ofc

{noformat}
diff --git a/requirements.txt b/requirements.txt
index 8e7ac0a9..cf618d50 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -14,6 +14,7 @@ flaky
 mock
 pytest==3.6.4
 pytest-timeout
+pytest-repeat
 parse
 pycodestyle
 psutil
{noformat};;;","23/Apr/21 11:35;adelapena;bq. Also ins the spirit of CASSANDRA-16625 and just bc it is super useful would you be ok we add dtest-repeat to requirements.txt?

Very good idea, I'm +100 on anything encouraging to run tests repeatedly and indeed {{pytest-repeat}} is very useful. I have also added a brief note in README.md about how to repeatedly run specific tests.

I'm running CI for dtests, if it looks good and you agree to the changes I think we'll be ready to commit.

* [3.0|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/625/]
* [3.11|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/626/]
* [trunk|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/627/];;;","26/Apr/21 05:10;bereng;LGTM. It's nice to see such blue-ish runs :-);;;","26/Apr/21 06:35;bereng;[~adelapena] I was about to commit it for you but given you have it in a branch of yours, I can't tell if that's the branch you really want to commit, squash, etc It'll be best you commit it yourself I am afraid.;;;","26/Apr/21 11:27;adelapena;[~bereng] great, thanks. I'm setting you as co-author since I wrote the patch on top of your changes and findings. Committed as [2032cb8503d9a3e90822de72458a09dd07d30b7e|https://github.com/apache/cassandra-dtest/commit/2032cb8503d9a3e90822de72458a09dd07d30b7e].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ProtocolVersion.V4 is still used in places in the code,CASSANDRA-16613,13373253,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,18/Apr/21 00:16,27/May/22 19:25,13/Jul/23 08:40,08/May/21 14:21,4.0,4.0-rc2,4.1,4.1-alpha1,,,,,,,,0,,,"While working on CASSANDRA-16567, [~adelapena] observed that _ProtocolVersion.V4_ is used in _ViewTest_.

I decided to do a quick grep and observed a list of places where we still refer to V4 and it seems at least in many of the tests that was left not intentionally.

This ticket is to verify the usage of _ProtocolVersion.V4_ in the codebase and bump it to V5 or  default version, similar to what was done in CASSANDRA-16567, wherever there is a need. ",,adelapena,e.dimitrova,samt,slachiewicz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-14973,CASSANDRA-15299,,,CASSANDRA-16642,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sat May 08 14:18:15 UTC 2021,,,,,,,All,,,,"0|z0q568:",9223372036854775807,,,,samt,,,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/62e1d74701bcb59437aeb1c778ba7a81aac84741,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16613?focusedCommentId=17335087&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17335087,,,,,"27/Apr/21 20:03;e.dimitrova;Work in progress [here|https://github.com/apache/cassandra/commit/d99f056cb8189c157dd76110542817e0981397dd]

Seems to me only the tests need update. 

I am wondering about a few things though:
 * DriverBurnTest contains perf tests for V4 and V5 (it was actually testing current beta which is already V6) so I changed the tests to test V4, V5, V6 but then I observed that the perf method calls BurnTestUtil#generateQueryMessage for [version 4|https://github.com/apache/cassandra/commit/d99f056cb8189c157dd76110542817e0981397dd#diff-df33e55e1def1329f9f1c37173fd1af732a6fb636545097f65ce0344079a05f7L81]... So I am wondering which versions we want to leave and I guess I have to update also BurnTestUtil#generateQueryMessage.
 * I added additional test for version 5 in PagingStateTest, not sure whether mixed versions serialize/deserialize should be added too.
 * ClientWarningsTest - I decided to leave it to test latest current version instead of 4

[~samt], do you mind to take a look, please, when you have a bit of time? Thanks in advance!;;;","28/Apr/21 07:41;samt;{quote}[~samt], do you mind to take a look, please


{quote}
Sure, will do ASAP;;;","28/Apr/21 12:35;samt;Hi [~e.dimitrova] , thanks for picking this up, I should really have caught all of these uses in either CASSANDRA-15299 or CASSANDRA-14973. It all looks generally good to me, I just have a few minor comments/suggestions:
h3. {{DriverBurnTest}} et al

I wonder if we should a version param to {{BurnTestUtil::generateQueryMessage}}, rather than hardcoding it. When called from {{SimpleClient(Perf|Burn)Test}} it can be derived from {{SimpleClient.connection.getVersion()}}. {{DriverBurnTest}} is a bit more of a pain, but there I think we'd need to add a parameter to {{perfTest}} and pass the version for each test explicitly.
h3. {{QueryPagerTest}}

In the tests you already changed, could we loop over {{ProtocolVersion.SUPPORTED}} rather than specifying the versions directly?
h3. {{ClientWarningsTest}}

For this (and I think for {{ViewFilteringTest}} & {{ViewLongTest}}) we could make them {{@RunWith(Parameterized.class)}} to exercise all the relevant versions. I did this in {{ClientRequestSizeMetricsTest}}, but I've overlooked these other version-dependent tests sorry.
h3. {{PagingStateTest}}

The new test LGTM and also sufficient. The paging state format went through some (undocumented) changes between V3 and V4, hence the need for the mixed version tests. There's been no such change for V5 so we should be good here.;;;","28/Apr/21 17:53;e.dimitrova;Thank you [~samt] for the quick response. 

I will accommodate all your suggestions.

I was wondering whether we always want to loop all supported versions or in some cases we need only latest one or as in the case with the _PagingStateTest_ - a few older ones and special mixed cases, etc. So you just gave me that answer. 

Thanks one more time for looking into it, I will submit a patch for review later today.;;;","29/Apr/21 01:15;e.dimitrova;Hey Sam,

I applied the changes you suggested plus had a few more findings. Latest work can be found [here|https://github.com/ekaterinadimitrova2/cassandra/pull/109]

Now two other questions popped up on my mind:

1) The in-jvm tests were using V4 [here|https://github.com/ekaterinadimitrova2/cassandra/pull/109/commits/d99f056cb8189c157dd76110542817e0981397dd#diff-34798e91d93d9e49dbb896c4e25f7f803ce9c9229a6397961cd5ff6d7b902c82L110]. I changed it to testing with the CURRENT version, not sure that this is enough. WDYT?

2) I am going also to inspect the Python DTests tomorrow as it seems at least in [dtest.py|https://github.com/apache/cassandra-dtest/blob/trunk/dtest.py#L279] we don't list the new beta version 6.

Java 8 CI run  [here|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/780/workflows/86279a12-e844-4af0-a6a3-79a2cdb45597]

Java 11 CI run [here|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/780/workflows/096f6d5e-ce0a-4ec7-98df-6a76d729f19b]

I ran the shorter tests locally successfully.

CircleCI is still running

 ;;;","29/Apr/21 22:18;e.dimitrova;There are some Junit timeouts which can be solved by raising the timeout [here|https://github.com/apache/cassandra/blob/trunk/build.xml#L96].

I am wondering whether there is a better way to handle this issue.

On the dtests side I saw actually that those were handled as part of this  [commit|https://github.com/apache/cassandra-dtest/commit/c6d226254f105b4530072c09699cb0422374e54c].

[~samt] do you mind to review? Also, any opinion on the timeout raise and the In-JVM tests?;;;","05/May/21 07:49;samt;+1 LGTM. If I remember right, {{ViewComplexTest}} has long been flaky due to timeouts on anything less than the XLarge plan. It would be nice if it wasn't necessary, but raising the timeout is the most pragmatic solution so I'm fine with it. Also +1 to changing the in-jvm dtests to use {{CURRENT}}, I can't think of any reason that isn't the right thing to do.;;;","05/May/21 23:39;e.dimitrova;Thank you [~samt]!
I rebased my branch. There is some issue in CircleCI not related to this ticket but preventing us from getting the right picture, I just submitted Jenkins run [here|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/734/]

 

 ;;;","06/May/21 14:54;e.dimitrova;DTests all failed, known issue from CASSANDRA-16642. We didn't change anything to affect those so I think it is safe to skip them this time. 

_org.apache.cassandra.cql3.ViewComplexTest.testCommutativeRowDeletionFlush[3]_ - I will add a few more seconds as there is one test, one run that still timed out

_PreviewRepairCoordinatorFastTest -_ seems like a concurrent issue or something but not related to this ticket. I will spin it on a multiplexer and probably raise a ticket. 

To be on the safe side, I will push one more run with the adjusted timeout to confirm we don't have more timeouts before commit. ;;;","06/May/21 19:22;e.dimitrova;I was still thinking about the timeout and after a quick chat with [~mck], I returned the old value of the timeout in build.xml and added a rule for longer timeout only to the _ViewComplexTest_ class [here|https://github.com/ekaterinadimitrova2/cassandra/commit/172364ee9ca89a149a08df0874ac383244df5b6c#diff-cef8420dc7657c07527b9c586be0c1da5ea43c826304142a74d27116324ae301R60-R61].

Submitted final Jenkins CI runs here:

[4.0 patch|https://github.com/ekaterinadimitrova2/cassandra/commit/172364ee9ca89a149a08df0874ac383244df5b6c] | [CI run|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/749/]
 [trunk patch|https://github.com/ekaterinadimitrova2/cassandra/tree/16613-trunk] | [CI run|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/750/];;;","08/May/21 13:46;e.dimitrova;Seems like adding only a rule to the class is not enough, it is replaced by the build.xml timeout.

In a quick [Slack discussion|https://the-asf.slack.com/archives/CK23JSY2K/p1620403646401500] I was given the idea to move those two tests that now run longer to the long tests so I don't have to raise the timeout for many classes because of two. 

I just did it and final CI runs are here:
[4.0 patch|https://github.com/ekaterinadimitrova2/cassandra/tree/16613-4.0] | [CI run|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/755/#showFailuresLink]
[trunk patch|https://github.com/ekaterinadimitrova2/cassandra/tree/16613-trunk] | [CI run|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/754/#showFailuresLink]
One of the View tests is marked as failed but when I open the link it says passed and it passes locally so I think it should be fine.

I will commit it soon.;;;","08/May/21 14:18;e.dimitrova;Committed to 4.0 and trunk:
fb76baa608..62e1d74701  cassandra-4.0 -> cassandra-4.0
   2c3c3e639a..8975a4f031  trunk -> trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RingTest has inconsistent assertion,CASSANDRA-16612,13373141,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,jlewandowski,jlewandowski,17/Apr/21 04:39,17/Feb/22 08:19,13/Jul/23 08:40,09/Aug/21 16:09,4.0.1,,,,,,,Test/unit,,,,0,,,"There is an assertion for the node current load like:

{noformat}
assertThat(hostRing, matchesPattern("".*\\d+\\.\\d+ KiB.*""));
{noformat}

while we are formatting that value with {{#.##}}. Therefore if we say have 46 KiB, it will be formatted as 46 KiB rather than 46.00 KiB which is expected by the test. We need to either change this assertion or change the format string to {{#0.00}}
",,adelapena,brandon.williams,e.dimitrova,jlewandowski,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16283,,,,,,CASSANDRA-16708,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Aug 09 16:08:22 UTC 2021,,,,,,,All,,,,"0|z0q4hc:",9223372036854775807,,,,adelapena,,,,Low,,,,https://github.com/apache/cassandra/commit/b7c4271b16801acff77c020ebf2daf82b1592184,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16612?focusedCommentId=17363208&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17363208,,,,,"14/Jun/21 17:15;e.dimitrova;Hi [~jlewandowski],

Thank you for the report. This seems to be the same issue I fixed for another test a few weeks ago in CASSANDRA-16708.

I just did a quick grep and I think RingTest and StatusTest are the only places we can see this issue.

Do you mind if I port the [fix|https://github.com/apache/cassandra/commit/31c1bbe87f8e376f353df2a16881124122045936#diff-c8bb82ece7f986d0011448db420b024f4cca570e96082d78f4ae4902de882190R91]? ;;;","14/Jun/21 20:12;jlewandowski;go ahead!;;;","14/Jun/21 21:06;e.dimitrova;[PR |https://github.com/ekaterinadimitrova2/cassandra/pull/146] | [CI |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=16612-4.0.0];;;","15/Jun/21 13:16;adelapena;I think that the unpatched test is never going to fail because it always has a load of {{45.84 KiB}}. [Here|https://app.circleci.com/pipelines/github/adelapena/cassandra/597/workflows/974af381-2c2d-4dc4-a203-4671a1caba64] are 10K multiplexer rounds showing how at least 4.0.0 seems to be unaffected. Nevertheless I agree that the regex is incorrect and we should fix it, although I'm not sure that we need to do it in 4.0.0.

As for the patch, it seems that it contains the cosmetic changes but I think that [the relevant change|https://github.com/apache/cassandra/blob/31c1bbe87f8e376f353df2a16881124122045936/test/unit/org/apache/cassandra/tools/nodetool/StatusTest.java#L91] in the regex is missed.;;;","15/Jun/21 14:09;e.dimitrova;Yes, seems I didn't commit that change. :( All valid points, I suggest a quick commit only to trunk;;;","07/Aug/21 17:40;e.dimitrova;The test class was cleaned as part of CASSANDRA-16629. 

So after a rebase I applied only the relevant change. [~adelapena], do you mind to look at this again, please? :)
||Patch||CI||
|[trunk|https://github.com/ekaterinadimitrova2/cassandra/pull/161]|[CircleCI |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=16612-trunk]|
I think it almost qualifies for a ninja fix :-) ;;;","09/Aug/21 15:54;adelapena;Looks good to me, +1, 10000 runs can't be wrong :);;;","09/Aug/21 16:08;e.dimitrova;Committed to trunk, thank you!
To https://github.com/apache/cassandra.git
   6fbe736bc2..b7c4271b16  trunk -> trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Nodetool verify fixes,CASSANDRA-16608,13372809,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,16/Apr/21 06:00,22/Apr/21 11:19,13/Jul/23 08:40,22/Apr/21 11:19,4.0,4.0-rc1,,,,,,Local/Other,,,,0,,,"A few issues with nodetool verify:
* Include cause exception when it fails verifying an sstable
* Don't try to check if the node owns tokens from localpartitioner sstables
* Don't try to deserialise non-existing bloom filter file",,jmeredithco,maedhroz,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Degradation -> Other Exception,,,,,,,,Low Hanging Fruit,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Apr 22 11:19:36 UTC 2021,,,,,,,All,,,,"0|z0q2fk:",9223372036854775807,,,,jmeredithco,maedhroz,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/2bd07ecab6121ebfc8a192243c5c6fb41eb85515,,,,,,,,,cci run,,,,,"16/Apr/21 06:05;marcuse;https://github.com/krummas/cassandra/commits/marcuse/16608 (last 3 non-cci commits)
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16608;;;","16/Apr/21 13:46;jmeredithco;+1, thanks for the fix.;;;","19/Apr/21 19:47;maedhroz;LGTM

We've already got CASSANDRA-16598 to track the problems in {{StreamingMetricsTest}}.;;;","19/Apr/21 21:00;maedhroz;...oh, and we might want to give the Python dtests a spin, at least to see how {{offline_tools_test.py}} fares ;);;;","22/Apr/21 11:19;marcuse;and committed, thanks;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky test testRequestResponse – org.apache.cassandra.net.MockMessagingServiceTest,CASSANDRA-16607,13372721,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,dcapwell,dcapwell,15/Apr/21 19:00,27/May/21 15:47,13/Jul/23 08:40,20/Apr/21 17:59,3.11.11,4.0,4.0-rc1,,,,,Test/unit,,,,0,,,"https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/659/tests/

{code}
Error
expected:<1> but was:<0>
Stacktrace
junit.framework.AssertionFailedError: expected:<1> but was:<0>
	at org.apache.cassandra.net.MockMessagingServiceTest.testRequestResponse(MockMessagingServiceTest.java:81)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Standard Output
INFO  [main] 2021-04-15 08:22:46,838 YamlConfigurationLoader.java:93 - Configuration location: file:/home/cassandra/cassandra/test/conf/cassandra.yaml
DEBUG [main] 2021-04-15 08:22:46,840 YamlConfigurationLoader.java:112 - Loading settings from file:/home/cassandra/cassandra/test/conf/cassandra.yaml
DEBUG [main] 2021-04-15 08:22:46,899 InternalLoggerFactory.java:63 - Using SLF4J as the default logging framework
DEBUG [main] 2021-04-15 08:22:46,911 PlatformDependent0.java:417 - -Dio.netty.noUnsaf
...[truncated 61235 chars]...
te NORMAL, token [a57d4b7f61f49471614b7ac41f16477e]
DEBUG [main] 2021-04-15 08:22:49,840 StorageService.java:2674 - New node /127.0.0.1:7069 at token a57d4b7f61f49471614b7ac41f16477e
DEBUG [main] 2021-04-15 08:22:49,848 StorageService.java:2727 - Node /127.0.0.1:7069 state NORMAL, token [a57d4b7f61f49471614b7ac41f16477e]
INFO  [main] 2021-04-15 08:22:49,848 StorageService.java:2730 - Node /127.0.0.1:7069 state jump to NORMAL
DEBUG [main] 2021-04-15 08:22:49,849 StorageService.java:1619 - NORMAL
{code}",,adelapena,blerer,dcapwell,,,,,,,,,,,,,"adelapena opened a new pull request #969:
URL: https://github.com/apache/cassandra/pull/969


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Apr/21 16:38;githubbot;600","adelapena opened a new pull request #970:
URL: https://github.com/apache/cassandra/pull/970


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Apr/21 16:38;githubbot;600","adelapena closed pull request #969:
URL: https://github.com/apache/cassandra/pull/969


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/May/21 15:47;githubbot;600","adelapena closed pull request #970:
URL: https://github.com/apache/cassandra/pull/970


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/May/21 15:47;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,2400,,,0,2400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 20 17:57:56 UTC 2021,,,,,,,All,,,,"0|z0q1w0:",9223372036854775807,,,,blerer,,,,Normal,,3.11.0,,https://github.com/apache/cassandra/commit/60cf948f8bfdc23e1f718967fdd365fc3da7919d,,,,,,,,,Flaky test fix,,,,,"16/Apr/21 16:55;adelapena;It seems that the problem is that since CASSANDRA-12653 {{MockMessagingSpy#mockedMessageResponses}} is increased asynchronously by [this thread|https://github.com/apache/cassandra/blob/trunk/test/unit/org/apache/cassandra/net/MatcherResponse.java#L185-L198]. Because of this the value of {{mockedMessageResponses}} can be checked before it has been increased by the thread, causing the reported failure. While the test doesn't fail very often, the failure can be easily reproduced by manually adding a sleep in the aforementioned thread.

The proposed PRs simply use {{spinAssertEquals}} to wait for the writer thread. Also, I think there could be thread safety issues when increasing {{mockedMessageResponses}} from different threads, so I'm making it an {{AtomicInteger}}.

CI for 3.11:
 * [CircleCI|https://app.circleci.com/pipelines/github/adelapena/cassandra/275/workflows/8be80b18-c168-478d-ae1d-7cb5c04d4b9d]
 * [Multiplexer MockMessagingServiceTest|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/805/]
 * [Multiplexer ShadowRoundTest|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/807/]

CI for trunk:
 * [CircleCI j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/276/workflows/f95f3503-1471-492a-ab86-13b7cd9fded2]
 * [CircleCI j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/275/workflows/8be80b18-c168-478d-ae1d-7cb5c04d4b9d]
 * [Multiplexer MockMessagingServiceTest|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/806/]
 * [Multiplexer ShadowRoundTest|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/808/];;;","20/Apr/21 09:29;blerer;The patches look good to me. I would simply also make {{MockMessagingSpy.messagesIntercepted}} an {{AtomicInteger}} for extra safety in the case we have some changes in the future that allow reads and writes with different threads but that change can be done on commit.;;;","20/Apr/21 12:20;adelapena;Thanks for the review, I'm running a final CI round with the {{AtomicInteger}} {{MockMessagingSpy.messagesIntercepted}}:

CI for 3.11:
* [CircleCI|https://app.circleci.com/pipelines/github/adelapena/cassandra/280/workflows/f808ffb1-4c06-4092-b891-212aad5c173b]
* [Jenkins|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/686/pipeline]

CI for trunk:
* [CircleCI j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/281/workflows/5d55912d-c9fc-44ae-bdd5-06343b2d7ee9]
* [CircleCI j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/281/workflows/88f596ba-4308-498d-8835-a50f6b659f0d]
* [Jenkins|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/687/pipeline];;;","20/Apr/21 17:57;adelapena;Committed to 3.11 as [60cf948f8bfdc23e1f718967fdd365fc3da7919d|https://github.com/apache/cassandra/commit/60cf948f8bfdc23e1f718967fdd365fc3da7919d] and [merged into trunk|https://github.com/apache/cassandra/commit/4e5bd273c640eb79c4947b22d56a68784b039c52].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Revise the metrics docs in the website,CASSANDRA-16602,13372478,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,yifanc,yifanc,yifanc,14/Apr/21 18:57,16/Mar/22 15:39,13/Jul/23 08:40,21/Apr/21 20:26,4.0,4.0-rc1,,,,,,Legacy/Documentation and Website,,,,0,,,"While inspecting the metrics code, I realized that the metrics docs (at https://cassandra.apache.org/doc/latest/operating/metrics.html) has several errors, e.g.

1.	JMX MBean names have incorrect format. They should be separated with commas, but the doc has space separated values. Cassandra users referring to this docs will not get it working. 
2.	The MBean name for Keyspace metrics is wrong. In the code, we have `keyspace=<Keyspace>`, instead of `scope=<Keyspace>`, which is listed in the docs page. 
3.	There are outdated fields. For instance, the `SyncTime` has been renamed to `RepairSyncTime` under the TableMetrics. 

To avoid frustrating and confusing the users that refer to the metrics page, the docs need to be revised.",,e.dimitrova,yifanc,,,,,,,,,,,,,,"yifan-c opened a new pull request #968:
URL: https://github.com/apache/cassandra/pull/968


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Apr/21 22:49;githubbot;600","smiklosovic closed pull request #968:
URL: https://github.com/apache/cassandra/pull/968


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:39;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,yifanc,,,,,,,,,,,,,Documentation,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Apr 21 20:26:17 UTC 2021,,,,,,,All,,,,"0|z0q0e0:",9223372036854775807,,,,brandon.williams,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/0fd8f0a52fbd69c47d073373abfe7d2437bbd9ca,,,,,,,,,build the docs and inspect,,,,,"14/Apr/21 19:27;brandon.williams;/cc [~lorina@datastax.com];;;","14/Apr/21 22:52;yifanc;PR: https://github.com/apache/cassandra/pull/968

* Fixed the MBean name format.
* Fixed the outdated metrics names in TableMetrics
* Fixed the KeyspaceMetrics MBean name
* Added missing metrics, including ReadRepairMetrics, MessagingMeetrics, InternodeOutboundConnectionMetrics, InternodeInboundConnectionMetrics. 
* Sorted the metrics rows in the tables alphabetically (for readability). ;;;","15/Apr/21 00:12;brandon.williams;Typo (which was also already there) in 'WriteFailedIdeaCL' but otherwise lgtm, +1.;;;","15/Apr/21 06:06;yifanc;Good catch! Typo corrected. ;;;","21/Apr/21 20:09;yifanc;Hi [~e.dimitrova], just to check if you are still going to review the doc changes. 

No hurry as it is not blocking anything.;;;","21/Apr/21 20:13;e.dimitrova;OMG I didn't see I am still assigned reviewer and I was even wondering why this one is still not closed as there are two committers involved already. :(

Feel free to commit it, we definitely trust [~brandon.williams] and you on this one, apologize!;;;","21/Apr/21 20:16;brandon.williams;+1;;;","21/Apr/21 20:26;yifanc;Committed as [0fd8f0a|https://github.com/apache/cassandra/commit/0fd8f0a52fbd69c47d073373abfe7d2437bbd9ca];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky CassandraIndexTest,CASSANDRA-16601,13372238,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,14/Apr/21 08:26,01/Aug/21 11:08,13/Jul/23 08:40,22/Apr/21 06:06,3.11.11,4.0,4.0-rc1,,,,,Test/unit,,,,0,,,"See failure [here|https://ci-cassandra.apache.org/job/Cassandra-trunk/436/testReport/junit/org.apache.cassandra.index.internal/CassandraIndexTest/indexCorrectlyMarkedAsBuildAndRemoved_cdc/]


{noformat}
Error Message

expected:<1> but was:<0>

Stacktrace

junit.framework.AssertionFailedError: expected:<1> but was:<0>
	at org.apache.cassandra.index.internal.CassandraIndexTest.indexCorrectlyMarkedAsBuildAndRemoved(CassandraIndexTest.java:588)
{noformat}

",,adelapena,bereng,,,,,,,,,,,,,,"bereng opened a new pull request #966:
URL: https://github.com/apache/cassandra/pull/966


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Apr/21 09:18;githubbot;600","bereng commented on pull request #966:
URL: https://github.com/apache/cassandra/pull/966#issuecomment-819417674


   - CI [j11](https://app.circleci.com/pipelines/github/bereng/cassandra/250/workflows/6da983ee-dc33-4c9b-bcad-7e793e8cc946) unrelated failures
   - CI [j8](https://app.circleci.com/pipelines/github/bereng/cassandra/250/workflows/79e5becb-40d6-47d1-9b6d-7f2b0c7b6008) unrelated failures
   - 100 multiplexer runs successful


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Apr/21 10:37;githubbot;600","adelapena commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r614749297



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -561,6 +562,20 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete

Review comment:
       Maybe we could add a note about parallel runners, in case they come back in the future?
   ```suggestion
           // Wait for any background index clearing tasks to complete,
           // knowing that there aren't any other tests running parallely
   ```

##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -561,6 +562,20 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete
+        Util.spinAssertEquals(0, () -> {
+            try
+            {
+                return execute(selectBuiltIndexesQuery).size();
+            }
+            catch(Throwable e)
+            {
+                fail(e.getMessage());
+            }
+            return -1;
+        }, 60);

Review comment:
       We can use the briefer and more flexible `Awaitility.await()` method, that doesn't require the try-catch block and allows us to specify a poll delay:
   ```suggestion
           await().atMost(1, MINUTES)
                  .pollDelay(1, SECONDS)
                  .untilAsserted(() -> assertRows(execute(selectBuiltIndexesQuery)));
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Apr/21 11:21;githubbot;600","bereng commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r615545520



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -561,6 +562,20 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete

Review comment:
       I'm sort of -1. Junit test methods _by definition_ should be 100% isolated. Junit itself goes to great lenghts to make sure each test case is isolated as much as possible. CASSANDRA-16595 is actually solving _a bug_ where we broke junit rules. I can add for completeness but I'll reword it.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 05:08;githubbot;600","bereng commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r615545520



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -561,6 +562,20 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete

Review comment:
       I'm sort of -1. Junit test methods _by definition_ should be 100% isolated. Junit itself goes to great lenghts to make sure each test case is isolated as much as possible. CASSANDRA-16595 is actually solving _a bug_ where we broke junit rules. I can it add for completeness but I'll reword it.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 05:12;githubbot;600","bereng commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r615547298



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -561,6 +562,20 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete
+        Util.spinAssertEquals(0, () -> {
+            try
+            {
+                return execute(selectBuiltIndexesQuery).size();
+            }
+            catch(Throwable e)
+            {
+                fail(e.getMessage());
+            }
+            return -1;
+        }, 60);

Review comment:
       So what's the point of having 2 methods that do the same? Is it bc one uses Thread.yield()?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 05:16;githubbot;600","adelapena commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r615731001



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -561,6 +562,20 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete
+        Util.spinAssertEquals(0, () -> {
+            try
+            {
+                return execute(selectBuiltIndexesQuery).size();
+            }
+            catch(Throwable e)
+            {
+                fail(e.getMessage());
+            }
+            return -1;
+        }, 60);

Review comment:
       I don't know, I think the dependency for the more sophisticated `Awaitability` was added quite recently by CASSANDRA-15677. Maybe it was because `spinAssertEquals` is not visible from dtests? Perhaps we should consider getting rid of one of them in a separate ticket?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 10:31;githubbot;600","adelapena commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r615735441



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -558,9 +561,17 @@ public void indexStatementsWithConditions() throws Throwable
     @Test
     public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
     {
-        String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
+        String selectBuiltIndexesQuery = String.format(""SELECT table_name, index_name FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete. Warn: When we used to run tests in parallel there
+        // could also be cross test class talk and have other indices pop up here.
+        Awaitility.await()
+                  .atMost(1, TimeUnit.MINUTES)
+                  .pollDelay(1, TimeUnit.SECONDS)
+                  .untilAsserted(() -> assertRows(execute(selectBuiltIndexesQuery)));
+
         UntypedResultSet rs = execute(selectBuiltIndexesQuery);

Review comment:
       Saving the `initialSize` is part of the fix introduced by CASSANDRA-15565 that we can get rid of. The checks after dropping the int can be simplified to just verifying that the `IndexInfo` table is empty, as suggested [here](https://github.com/adelapena/cassandra/blob/8cf7145b8437f616e8085169cc3829197961031c/test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java#L567-L584).




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 10:39;githubbot;600","bereng commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r615737739



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -561,6 +562,20 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete
+        Util.spinAssertEquals(0, () -> {
+            try
+            {
+                return execute(selectBuiltIndexesQuery).size();
+            }
+            catch(Throwable e)
+            {
+                fail(e.getMessage());
+            }
+            return -1;
+        }, 60);

Review comment:
       That's what I was thinking. Unless Thread.yield() provides some advantage bc it's more aggressive we could just replace that method contents with Awaitility...




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 10:42;githubbot;600","adelapena commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r615742631



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -558,9 +561,17 @@ public void indexStatementsWithConditions() throws Throwable
     @Test
     public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
     {
-        String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
+        String selectBuiltIndexesQuery = String.format(""SELECT table_name, index_name FROM %s.\""%s\"""",

Review comment:
       I'd say that checking that the index build doesn't write the legacy `IndexInfo.value` column had some value, but I'm not against the simplification if you prefer it this way.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 10:50;githubbot;600","adelapena commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r615735441



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -558,9 +561,17 @@ public void indexStatementsWithConditions() throws Throwable
     @Test
     public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
     {
-        String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
+        String selectBuiltIndexesQuery = String.format(""SELECT table_name, index_name FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete. Warn: When we used to run tests in parallel there
+        // could also be cross test class talk and have other indices pop up here.
+        Awaitility.await()
+                  .atMost(1, TimeUnit.MINUTES)
+                  .pollDelay(1, TimeUnit.SECONDS)
+                  .untilAsserted(() -> assertRows(execute(selectBuiltIndexesQuery)));
+
         UntypedResultSet rs = execute(selectBuiltIndexesQuery);

Review comment:
       Saving the `initialSize` is part of the fix introduced by CASSANDRA-15565 that we can get rid of. The checks after dropping the index can be simplified to just verifying that the `IndexInfo` table is empty, as suggested [here](https://github.com/adelapena/cassandra/blob/8cf7145b8437f616e8085169cc3829197961031c/test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java#L567-L584).




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 10:52;githubbot;600","bereng commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r616342454



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -558,9 +561,17 @@ public void indexStatementsWithConditions() throws Throwable
     @Test
     public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
     {
-        String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
+        String selectBuiltIndexesQuery = String.format(""SELECT table_name, index_name FROM %s.\""%s\"""",

Review comment:
       Nah I see your point. +1.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 04:53;githubbot;600","bereng commented on pull request #966:
URL: https://github.com/apache/cassandra/pull/966#issuecomment-823072166


   Latest done and 200 runs ok @adelapena 


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 08:08;githubbot;600","adelapena commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r616596846



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -561,33 +564,35 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete. Warn: When we used to run tests in parallel there
+        // could also be cross test class talk and have other indices pop up here.
+        Awaitility.await()
+                  .atMost(1, TimeUnit.MINUTES)
+                  .pollDelay(1, TimeUnit.SECONDS)
+                  .untilAsserted(() -> assertRows(execute(selectBuiltIndexesQuery)));
+
         UntypedResultSet rs = execute(selectBuiltIndexesQuery);

Review comment:
       Nit: this is not used




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 11:30;githubbot;600","adelapena commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r616597100



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -561,33 +564,35 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete. Warn: When we used to run tests in parallel there
+        // could also be cross test class talk and have other indices pop up here.
+        Awaitility.await()
+                  .atMost(1, TimeUnit.MINUTES)
+                  .pollDelay(1, TimeUnit.SECONDS)
+                  .untilAsserted(() -> assertRows(execute(selectBuiltIndexesQuery)));
+
         UntypedResultSet rs = execute(selectBuiltIndexesQuery);
-        int initialSize = rs.size();
 
         String indexName = ""build_remove_test_idx"";
         String tableName = createTable(""CREATE TABLE %s (a int, b int, c int, PRIMARY KEY (a, b))"");
         createIndex(String.format(""CREATE INDEX %s ON %%s(c)"", indexName));
         waitForIndex(KEYSPACE, tableName, indexName);
+
         // check that there are no other rows in the built indexes table
-        rs = execute(selectBuiltIndexesQuery);
-        int sizeAfterBuild = rs.size();
-        assertRowsIgnoringOrderAndExtra(rs, row(KEYSPACE, indexName, null));
+        assertRows(execute(selectBuiltIndexesQuery), row(KEYSPACE, indexName, null));
 
         // rebuild the index and verify the built status table
         getCurrentColumnFamilyStore().rebuildSecondaryIndex(indexName);
         waitForIndex(KEYSPACE, tableName, indexName);
 
         // check that there are no other rows in the built indexes table
-        rs = execute(selectBuiltIndexesQuery);
-        assertEquals(sizeAfterBuild, rs.size());
-        assertRowsIgnoringOrderAndExtra(rs, row(KEYSPACE, indexName, null));
+        assertRows(execute(selectBuiltIndexesQuery), row(KEYSPACE, indexName, null));
 
         // check that dropping the index removes it from the built indexes table
         dropIndex(""DROP INDEX %s."" + indexName);
         rs = execute(selectBuiltIndexesQuery);

Review comment:
       Nit: not needed




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 11:31;githubbot;600","adelapena commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r616599979



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -26,6 +27,7 @@
 import com.google.common.collect.*;
 import org.junit.Test;
 
+import org.apache.cassandra.Util;

Review comment:
       Nit: unused import




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 11:36;githubbot;600","bereng commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r616710887



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -561,33 +564,35 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete. Warn: When we used to run tests in parallel there
+        // could also be cross test class talk and have other indices pop up here.
+        Awaitility.await()
+                  .atMost(1, TimeUnit.MINUTES)
+                  .pollDelay(1, TimeUnit.SECONDS)
+                  .untilAsserted(() -> assertRows(execute(selectBuiltIndexesQuery)));
+
         UntypedResultSet rs = execute(selectBuiltIndexesQuery);

Review comment:
       Right. I missed that warning apologies.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 13:59;githubbot;600","adelapena commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r616731871



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -26,6 +27,7 @@
 import com.google.common.collect.*;
 import org.junit.Test;
 
+import org.apache.cassandra.Util;

Review comment:
       Nit: this unused import is still around, it can be removed during commit




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 14:21;githubbot;600","bereng commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r616816158



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -26,6 +27,7 @@
 import com.google.common.collect.*;
 import org.junit.Test;
 
+import org.apache.cassandra.Util;

Review comment:
       I _did_ delete that guy :thinking: I'll push along with 3.11 later




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 15:47;githubbot;600","bereng commented on a change in pull request #966:
URL: https://github.com/apache/cassandra/pull/966#discussion_r617229578



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -561,6 +562,20 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
+
+        // Wait for any background index clearing tasks to complete
+        Util.spinAssertEquals(0, () -> {
+            try
+            {
+                return execute(selectBuiltIndexesQuery).size();
+            }
+            catch(Throwable e)
+            {
+                fail(e.getMessage());
+            }
+            return -1;
+        }, 60);

Review comment:
       https://issues.apache.org/jira/browse/CASSANDRA-16621




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Apr/21 06:17;githubbot;600","bereng opened a new pull request #975:
URL: https://github.com/apache/cassandra/pull/975


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Apr/21 06:43;githubbot;600","adelapena commented on a change in pull request #975:
URL: https://github.com/apache/cassandra/pull/975#discussion_r617441332



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -570,33 +570,39 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
-        UntypedResultSet rs = execute(selectBuiltIndexesQuery);
-        int initialSize = rs.size();
+
+        // Wait for any background index clearing tasks to complete. Warn: When we used to run tests in parallel there
+        // could also be cross test class talk and have other indices pop up here.
+        Util.spinAssertEquals(0, () -> {
+            try
+            {
+                return execute(selectBuiltIndexesQuery).size();
+            }
+            catch(Throwable e)
+            {
+                fail(e.getMessage());
+            }
+            return -1;

Review comment:
       Nit: I think that `return -1;` will never be reached, it probably can be slightly simplified by just directly throwing an assertion error:
   ```suggestion
                   throw new AssertionError(e);
               }
   ```

##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -570,33 +570,39 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
-        UntypedResultSet rs = execute(selectBuiltIndexesQuery);
-        int initialSize = rs.size();
+
+        // Wait for any background index clearing tasks to complete. Warn: When we used to run tests in parallel there
+        // could also be cross test class talk and have other indices pop up here.
+        Util.spinAssertEquals(0, () -> {
+            try
+            {
+                return execute(selectBuiltIndexesQuery).size();
+            }
+            catch(Throwable e)

Review comment:
       Super nit: missed whitespace
   ```suggestion
               catch (Throwable e)
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Apr/21 11:16;githubbot;600","bereng commented on a change in pull request #975:
URL: https://github.com/apache/cassandra/pull/975#discussion_r617459746



##########
File path: test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java
##########
@@ -570,33 +570,39 @@ public void indexCorrectlyMarkedAsBuildAndRemoved() throws Throwable
         String selectBuiltIndexesQuery = String.format(""SELECT * FROM %s.\""%s\"""",
                                                        SchemaConstants.SYSTEM_KEYSPACE_NAME,
                                                        SystemKeyspace.BUILT_INDEXES);
-        UntypedResultSet rs = execute(selectBuiltIndexesQuery);
-        int initialSize = rs.size();
+
+        // Wait for any background index clearing tasks to complete. Warn: When we used to run tests in parallel there
+        // could also be cross test class talk and have other indices pop up here.
+        Util.spinAssertEquals(0, () -> {
+            try
+            {
+                return execute(selectBuiltIndexesQuery).size();
+            }
+            catch(Throwable e)
+            {
+                fail(e.getMessage());
+            }
+            return -1;

Review comment:
       I'll be happy to take these and I'll commit.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Apr/21 11:45;githubbot;600","bereng commented on pull request #966:
URL: https://github.com/apache/cassandra/pull/966#issuecomment-824545243


   - CI [j11](https://app.circleci.com/pipelines/github/bereng/cassandra/257/workflows/63da7c04-7116-45e0-9986-3ccb94980fee)
   - CI [j8](https://app.circleci.com/pipelines/github/bereng/cassandra/257/workflows/121e09d4-e2b8-4320-a373-f7fed5a95ece)


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Apr/21 05:17;githubbot;600","bereng commented on pull request #975:
URL: https://github.com/apache/cassandra/pull/975#issuecomment-824552470


   CI [here](https://app.circleci.com/pipelines/github/bereng/cassandra/260/workflows/b35ae7c1-a080-495f-bf2b-c486ae1ee842)


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Apr/21 05:36;githubbot;600","bereng closed pull request #966:
URL: https://github.com/apache/cassandra/pull/966


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Apr/21 08:53;githubbot;600","bereng closed pull request #975:
URL: https://github.com/apache/cassandra/pull/975


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Apr/21 08:54;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,16200,,,0,16200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 20 14:28:21 UTC 2021,,,,,,,All,,,,"0|z0pywo:",9223372036854775807,,,,adelapena,,,,Normal,,3.11.x,,"[3.11|https://github.com/apache/cassandra/commit/4bfe68717d9a419ab6a0b3a681478b39117dee80] and [trunk|https://github.com/apache/cassandra/commit/b2e897f6a92b931f6f8595a2c0c8d12b04aaf601]",,,,,,,,,See PR,,,,,"14/Apr/21 10:09;bereng;Impossible to repro. It happened only once so the fix is based more on intuition than actual deterministic reproduction.;;;","15/Apr/21 11:32;adelapena;I have managed to reproduce the failure running the entire test class in our internal multiplexer, with 22 failures in 200 runs ([here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/789/]). Indeed the problem is that the other tests also write entries in the {{system.IndexInfo}} table and, since {{CQLTester.afterTest}} cleanup is asynchronous, that table can change in any moment. CASSANDRA-15565 solved the problem of having indexes from previous tests in the table by taking note of how many indexes were in the table at the beginning of the test. The missed part was that {{CQLTester.afterTest}} can remove them in the middle of the test.

The proposed PR indeed avoids that risk by just checking the specific entry for the tested index, but I think it defeats part of the purpose of the test, which aims to verify that creating, rebuilding and dropping an index doesn't create unexpected entries in {{system.IndexInfo}}. If we wish to not do this check, we should probably get rid of the calls to {{assertRowsIgnoringOrderAndExtra}}, the picking of the initial query size (which is always zero), and the comments of the form {{""check that there are no other rows in the built indexes table""}}.

Alternatively, if we want to keep checking that no unexpected entries are added to {{system.IndexInfo}}, we should make sure that no other test writes in that table while we do our checks. The simplest way I can think of is making the test a dtest, since those use a dedicated cluster. I gave it a go [here|https://github.com/adelapena/cassandra/commit/1efcc5781bdfebc39692da6ea49bfbde7e49f866].

Also, now that we are probably going to get rid of parallel test execution, we could add a method in {{CQLTester}} to wait for the cleanup tasks of previous tests, which should guarantee us an empty {{system.IndexInfo}}, as it's done [here|https://github.com/adelapena/cassandra/commit/8cf7145b8437f616e8085169cc3829197961031c]. That method could also be helpful for other similar tests, and will allow us to restore the simpler pre-15565 shape of the test.

wdyt?;;;","15/Apr/21 13:12;bereng;Ah good I didn't manage to repro that repeatedly. What about a spinAssert for {{IndexInfo}} to be empty at the beginning of the test? :thinking:...;;;","15/Apr/21 13:29;adelapena;Good idea, {{spinAssert}} can also do the trick more easily that waiting for the cleanup tasks, although perhaps it's less reusable than {{waitForSchemaCleanups}}. Anyway, I think both approaches assume that there aren't other tests running parallely in the same JVM, and we are still discussing in the mail list whether to remove that. I'm not sure whether we should add this test to the ones that don't work with parallel runners or use the slower but safer dtest approach.;;;","16/Apr/21 04:45;bereng;I think removal of parallelization is already happening with CASSANDRA-16595 and the follow up tickets. So let me push a {{spinAssert}} and multiplex 200 times.;;;","16/Apr/21 10:32;bereng;Took ages to complete but yep, {{spinAssert}} +200 runs seems to work :-);;;","16/Apr/21 11:22;adelapena;Great, with CASSANDRA-16595 merged we can happily wait for the cleanup tasks. Probably {{spinAssertEquals}} can be replaced by {{Awaitabilty.await()}} to specify a poll delay and save us the try-catch block. Also I still think we should remove most of the changes introduced by CASSANDRA-15565 since they are not needed anymore, as it's done [here|https://github.com/adelapena/cassandra/blob/8cf7145b8437f616e8085169cc3829197961031c/test/unit/org/apache/cassandra/index/internal/CassandraIndexTest.java#L567-L584].;;;","19/Apr/21 07:42;bereng;Latest review comments addressed and 200 runs where ok :-);;;","20/Apr/21 14:28;adelapena;Last changes look good to me, +1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky test testMetricsWithRepairAndStreamingFromTwoNodes - org.apache.cassandra.distributed.test.metrics.StreamingMetricsTest,CASSANDRA-16598,13372113,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,dcapwell,dcapwell,13/Apr/21 19:12,14/Jun/21 07:21,13/Jul/23 08:40,11/Jun/21 08:08,4.0,4.0-rc2,,,,,,CI,Test/dtest/java,,,0,,,"https://app.circleci.com/pipelines/github/dcapwell/cassandra/882/workflows/8e34d09d-5908-495f-baac-5402e0c8e6ee/jobs/5276

{code}
junit.framework.AssertionFailedError: expected:<[0]> but was:<[2]>
	at org.apache.cassandra.distributed.test.metrics.StreamingMetricsTest.testMetricsWithStreamingFromTwoNodes(StreamingMetricsTest.java:88)
	at org.apache.cassandra.distributed.test.metrics.StreamingMetricsTest.testMetricsWithRepairAndStreamingFromTwoNodes(StreamingMetricsTest.java:48)
{code}",,adelapena,bereng,blerer,dcapwell,e.dimitrova,,,,,,,,,,,"blerer opened a new pull request #1053:
URL: https://github.com/apache/cassandra/pull/1053


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jun/21 13:02;githubbot;600","blerer closed pull request #1053:
URL: https://github.com/apache/cassandra/pull/1053


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:14;githubbot;600","blerer commented on pull request #1053:
URL: https://github.com/apache/cassandra/pull/1053#issuecomment-859668196


   Merged manually


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Jun/21 07:21;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,CASSANDRA-16646,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jun 11 08:08:44 UTC 2021,,,,,,,All,,,,"0|z0py4w:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0-rc1,,https://github.com/apache/cassandra/commit/14fd0ad4e3102ec626af22e5007663526fbebbbe,,,,,,,,,The patch is a fix for flaky tests,,,,,"13/Apr/21 20:48;e.dimitrova;I see also some of the other StreamingMetrics tests being flaky in Jenkins:

[https://jenkins-cm4.apache.org/job/Cassandra-trunk/436/testReport/org.apache.cassandra.distributed.test.metrics/StreamingMetricsTest/]

While reviewing CASSANDRA-16190 I looped the tests and they were fine back then...

I can try to take a look tomorrow.;;;","14/Apr/21 23:47;e.dimitrova;Different type of [failure|https://ci-cassandra.apache.org/job/Cassandra-trunk/435/testReport/junit/org.apache.cassandra.distributed.test.metrics/StreamingMetricsTest/testMetricsWithRepairAndStreamingFromTwoNodes/]  for the same test _testMetricsWithRepairAndStreamingFromTwoNodes_ in Jenkins:
{code:java}
junit.framework.AssertionFailedError: [The amount of data received by node1 from node3 is not the expected one. [expected: 0, actual: 62]] expected:<[0]L> but was:<[62]L>
 at org.apache.cassandra.distributed.test.metrics.StreamingMetricsTest.lambda$checkDataReceived$e7abd6ea$1(StreamingMetricsTest.java:350)
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
 at java.util.concurrent.FutureTask.run(FutureTask.java:266)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 at java.lang.Thread.run(Thread.java:748){code};;;","15/Apr/21 03:14;dcapwell;found another case, and several of the tests failed here: https://app.circleci.com/pipelines/github/dcapwell/cassandra/886/workflows/3bc0b75e-0dfa-45f6-b5d2-50377a067473/jobs/5304;;;","15/Apr/21 13:05;e.dimitrova;I was looping them overnight and didn't manage to reproduce anything on my machine;;;","20/Apr/21 10:21;bereng;[~adelapena] did you manage to repro and you're onto sthg or should I give it a try?;;;","20/Apr/21 10:53;adelapena;[~bereng] I haven't being able to repro either locally or in the multiplexer. Of the two mentioned failures the one in line 88 is quite puzzling since it's just checking that rows haven't made it into a node that has been stopped while the others were being written, with hints disabled. I think [~blerer] was also looking into this, I'm unassigning myself to let you guys give it a go.;;;","04/May/21 11:40;adelapena;The CircleCi-based test multiplexer proposed in CASSANDRA-16625 has managed to reproduce the failure  in [this run|https://app.circleci.com/pipelines/github/adelapena/cassandra/373/workflows/f1612e92-8a59-483b-bc79-d6f29a7f5766/jobs/3260]. There are failures for {{StreamingMetricsTest#testMetricsWithRepairAndStreamingToTwoNodes}} too.;;;","10/Jun/21 15:12;blerer;The problem seems to be linked to the In-JVM framework. The nodes seems to still receive some updates after shutdown.
I pushed a [PR|https://github.com/apache/cassandra/pull/1053] to fix the problem by using filter instead of shutting down nodes.
I ran the tests 100 times on CI using the multiplexer without any failures. The result can be found [here|https://app.circleci.com/pipelines/github/blerer/cassandra/145/workflows/e6e5e51b-5047-42a1-ac77-60bcdaf64b9c];;;","10/Jun/21 15:17;e.dimitrova;{quote}The problem seems to be linked to the In-JVM framework. The nodes seems to still receive some updates after shutdown.
{quote}
I confirm this is a known issue from CASSANDRA-16679

I will take a look at the patch itself later today. Thank you!;;;","10/Jun/21 23:27;e.dimitrova;That should work, the proposed solution is used already also for other tests and proved as a good workaround of the mentioned issue.

+1, thanks a lot!;;;","11/Jun/21 08:08;blerer;Committed into 4.0.0 at 14fd0ad4e3102ec626af22e5007663526fbebbbe and merged into 4.0 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test org.apache.cassandra.net.AsyncPromiseTest FAILED,CASSANDRA-16596,13372055,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aholmber,e.dimitrova,e.dimitrova,13/Apr/21 13:47,23/Apr/21 16:18,13/Jul/23 08:40,23/Apr/21 16:18,4.0,4.0-rc2,,,,,,CI,,,,0,,,"Not seen in Jenkins but reported a few times from CircleCI so it seems legit problem:

[Test org.apache.cassandra.net.AsyncPromiseTest FAILED|https://jenkins-cm4.apache.org/job/Cassandra-trunk/434/testReport/org.apache.cassandra.net/AsyncPromiseTest/]
CircleCI [failiure|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/743/workflows/35cea1fd-6f38-4f09-9d7f-4673c34a9851/jobs/4104/parallel-runs/17]

{noformat}
Testcase: testFailure(org.apache.cassandra.net.AsyncPromiseTest):   FAILED
8
junit.framework.AssertionFailedError: 8
    at org.apache.cassandra.net.TestAbstractPromise$Async.verify(TestAbstractPromise.java:53)
    at org.apache.cassandra.net.TestAbstractAsyncPromise.testOneFailure(TestAbstractAsyncPromise.java:178)
    at org.apache.cassandra.net.AsyncPromiseTest.testFailure(AsyncPromiseTest.java:54)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Caused by: java.util.concurrent.TimeoutException
    at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
    at org.apache.cassandra.net.TestAbstractPromise$Async.verify(TestAbstractPromise.java:49)


Test org.apache.cassandra.net.AsyncPromiseTest FAILED
{noformat}


Also Caleb mentioned he is seeing it in another CI infra too

CC [~maedhroz]",,aholmber,dcapwell,e.dimitrova,maedhroz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,aholmber,,,,,,,,,,,,,Degradation,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Apr 23 16:18:03 UTC 2021,,,,,,,All,,,,"0|z0pxs8:",9223372036854775807,,,,dcapwell,maedhroz,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/3b1d7c36d18ce4b314b007ef439f860dd2ef7460,,,,,,,,,"Reproduced.
Modified existing unit test.
Left spinning for millions of iterations.",,,,,"22/Apr/21 21:38;aholmber;I believe this is nothing more interesting than an actual timeout. I could reproduce this occasionally on a resource-constrained VM. I raised the timeout and it never reproduced. Meanwhile I did some static analysis looking for races around the async completions, but didn't see anything suspicious.

Brace yourself for this earth-shattering patch:

[patch|https://github.com/aholmberg/cassandra/pull/55]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16596]

;;;","22/Apr/21 21:59;maedhroz;LGTM

The J11 failure in {{MemtableSizeTest}} doesn't look like it has anything to do with your patch, although it is new.;;;","22/Apr/21 22:57;dcapwell;+1;;;","22/Apr/21 23:07;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16596-trunk-D4D8D8C9-979A-42AE-9496-9D07B4080327]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16596-trunk-D4D8D8C9-979A-42AE-9496-9D07B4080327]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/699/]|
;;;","23/Apr/21 15:01;aholmber;Thanks.

bq. MemtableSizeTest doesn't look like it has anything to do with your patch, although it is new

I'll look into it later today.;;;","23/Apr/21 16:18;dcapwell;Thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky org.apache.cassandra.service.ActiveRepairServiceTest,CASSANDRA-16593,13371801,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,brandon.williams,brandon.williams,12/Apr/21 13:19,31/Jul/21 21:35,13/Jul/23 08:40,22/Apr/21 13:10,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/612/tests

{noformat}
junit.framework.AssertionFailedError: expected:<2> but was:<1>
	at org.apache.cassandra.service.ActiveRepairServiceTest.testQueueWhenPoolFullStrategy(ActiveRepairServiceTest.java:435)


Standard Output
INFO  [main] 2021-04-10 17:37:25,869 YamlConfigurationLoader.java:93 - Configuration location: file:////home/cassandra/cassandra/build/test/cassandra.compressed.yaml
DEBUG [main] 2021-04-10 17:37:25,872 YamlConfigurationLoader.java:112 - Loading settings from file:////home/cassandra/cassandra/build/test/cassandra.compressed.yaml
DEBUG [main] 2021-04-10 17:37:25,950 InternalLoggerFactory.java:63 - Using SLF4J as the default logging framework
DEBUG [main] 2021-04-10 17:37:25,968 PlatformDependent0
...[truncated 88170 chars]...
build/test/cassandra/data:62/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6c2ddd10-9a23-11eb-9207-35733cfe3fbb.log 
DEBUG [MemtableFlushWriter:1] 2021-04-10 17:37:29,454 ColumnFamilyStore.java:1197 - Flushed to [BigTableReader(path='/home/cassandra/cassandra/build/test/cassandra/data:62/system/local-7ad54392bcdd35a684174e047860b377/na-15-big-Data.db')] (1 sstables, 4.943KiB), biggest 4.943KiB, smallest 4.943KiB
DEBUG [main] 2021-04-10 17:37:29,456 StorageService.java:1617 - NORMAL
{noformat}",,bereng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,Code,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Apr 22 13:10:45 UTC 2021,,,,,,,All,,,,"0|z0pw7s:",9223372036854775807,,,,,,,,Normal,,,,,,,,,,,,,,,,,,"21/Apr/21 14:46;brandon.williams;Unable to repro and I don't see any recent failures, so perhaps another victim of concurrency.;;;","22/Apr/21 06:24;bereng;Looks [indeed|https://ci-cassandra.apache.org/job/Cassandra-trunk/457/testReport/org.apache.cassandra.service/ActiveRepairServiceTest/history/] that could be it. I say we close and reopen if needed?;;;","22/Apr/21 13:10;brandon.williams;Let's do that, we can always reopen.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE getting host_id in Gossiper.isSafeForStartup,CASSANDRA-16588,13370832,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,10/Apr/21 16:17,24/Jun/21 21:19,13/Jul/23 08:40,21/Apr/21 22:31,3.11.11,4.0,4.0-rc2,,,,,Cluster/Gossip,,,,0,,,"As seen here: https://ci-cassandra.apache.org/job/Cassandra-devbranch/604/testReport/junit/org.apache.cassandra.distributed.upgrade/MixedModeGossipTest/testStatusFieldShouldExistInOldVersionNodesEdgeCase/

{noformat}
java.lang.NullPointerException
	at org.apache.cassandra.gms.Gossiper.isSafeForStartup(Gossiper.java:952)
	at org.apache.cassandra.service.StorageService.checkForEndpointCollision(StorageService.java:657)
	at org.apache.cassandra.service.StorageService.prepareToJoin(StorageService.java:933)
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:784)
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:729)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:541)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
{noformat}

I believe what is happening is a GossipDigestAck has been queued to ack the shutdown state from the node on the seed, but isn't actually sent until the node has restarted and gone into shadow.  Since the ack contains the node's IP, it assumes a host_id will be there but since this is not an actual shadow response, it is not.",,aholmber,e.dimitrova,mfleming,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16632,,,,,CASSANDRA-14155,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Availability,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Apr 21 22:31:14 UTC 2021,,,,,,,All,,,,"0|z0pqx4:",9223372036854775807,,,,samt,,,,Normal,,NA,,https://github.com/apache/cassandra/commit/f6d19512c4d79f800371da1e54dfe01cae5d894e,,,,,,,,,includes test,,,,,"14/Apr/21 19:08;brandon.williams;
||patch||CI||
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16588]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/656/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/656/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16588-trunk]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/657/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/657/pipeline]|
;;;","15/Apr/21 11:20;samt;This is a dupe of CASSANDRA-14155 and your diagnosis corresponds with Ariel's there. IDK why that stalled, but his proposal is essentially the same as yours:

bq. it seems to me that we should be able to ignore messages received during the shadow round that don't have the information we are looking for without erroring out.

Rather than checking on the number of epstates returned, I'd go for verifying that the states we do require for the collision check are present. I've pushed a couple of commits which do that, wdyt?

||patch||CI||Circle||
|[3.11|https://github.com/beobal/cassandra/tree/CASSANDRA-16588]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/661/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/661/pipeline]|[pipeline|https://app.circleci.com/pipelines/github/beobal/cassandra?branch=CASSANDRA-16588]|
|[trunk|https://github.com/beobal/cassandra/tree/CASSANDRA-16588-trunk]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/660/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/660/pipeline]|[pipeline|https://app.circleci.com/pipelines/github/beobal/cassandra?branch=CASSANDRA-16588-trunk]|

;;;","15/Apr/21 14:11;samt;I realised I'd made a mistake in those last patches by ANDing when I should've ORed. Pushed and restarted CI.

||patch||CI||Circle||
|[3.11|https://github.com/beobal/cassandra/tree/CASSANDRA-16588]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/662/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/662/pipeline]|[pipeline|https://app.circleci.com/pipelines/github/beobal/cassandra?branch=CASSANDRA-16588]|
|[trunk|https://github.com/beobal/cassandra/tree/CASSANDRA-16588-trunk]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/663/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/663/pipeline]|[pipeline|https://app.circleci.com/pipelines/github/beobal/cassandra?branch=CASSANDRA-16588-trunk]|


;;;","15/Apr/21 16:52;brandon.williams;Your 3.11 build aborted for some reason, I started it again. 
[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/677/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/677/pipeline]

I was a bit concerned that we could get a valid shadow ack where our own IP was somehow missing HOST_ID, causing us to stay in shadow forever and fail startup.  In fact, our empty state from CASSANDRA-16561 would do this if not for the fact that since the generation and version are zero, the seed will filter sending the empty state out (by luck of neither generation nor version being perceived as changed.) So I opted for detecting the bad ack as specifically as possible.

That said, there may be other unintentional bad responses possible here that your patch would catch and prevent the NPE.  I'm not sure which route is best.

*EDIT*: it looks like other states can be sent with this ACK, so I'm +1 on your version.  Restarted CI for 3.11.



;;;","16/Apr/21 16:06;mfleming;I think the patch from Sam is a bit too aggressive and will incorrectly think that gossip data for the local node that contains dead states (""left"", ""removing"", ""hibernate"", etc) is the bad ACK that we're trying to detect to avoid the NPE in isSafeForStartup. You should be able to trigger this by assassinating a non-seed node in a cluster.

We should probably filter out deadStates because they won't trigger the NPE.

Something like this https://github.com/mfleming/cassandra/commit/e68602ae300e6a2567e1b59efa4229ff3456e521;;;","16/Apr/21 19:38;brandon.williams;||Patch||CI||
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16588]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/680/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/680/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16588-trunk]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/681/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/681/pipeline]|;;;","19/Apr/21 13:04;brandon.williams;It look like this broke ShadowRoundTest.testDelayedResponse, I will post an update.;;;","19/Apr/21 13:52;brandon.williams;||Patch||CI||
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16588]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/682/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/682/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16588-trunk]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/683/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/683/pipeline]|
;;;","19/Apr/21 18:20;brandon.williams;This appears to be a problem in the MockMessagingService infrastructure as the number of syns varies between either 3 or zero depending on whether the test is run in isolation or the suite.  I thought perhaps the same issue that is causing CASSANDRA-16607 was at fault here, but applying Andres' patch doesn't change anything here. :(;;;","20/Apr/21 17:53;brandon.williams;||Patch|CI||
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16588]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/693/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/691/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16588-trunk]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/694/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/692/pipeline]|

We have to be careful in the test not to let StorageService get too far in joining the ring otherwise all kinds of things start up that are not easily restartable, so instead we can test checkForEndpointCollision directly.
;;;","20/Apr/21 18:36;samt;bq. We should probably filter out deadStates because they won't trigger the NPE.
 
Thanks, good catch!

The patches look good with [~mfleming]'s fix and the new tests. 
+1 from me if CI looks healthy.;;;","21/Apr/21 22:31;brandon.williams;No related failures, committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky test testAvailabilityV30ToV4 - org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityV30Test,CASSANDRA-16586,13370760,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aholmber,dcapwell,dcapwell,10/Apr/21 01:10,25/Apr/21 11:32,13/Jul/23 08:40,20/Apr/21 15:51,4.0,4.0-rc1,,,,,,CI,,,,0,,,"https://app.circleci.com/pipelines/github/dcapwell/cassandra/881/workflows/8e477260-ac6a-4eab-b4be-cbc048199565/jobs/5269

testAvailabilityV30ToV4 - org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityV30Test

{code}
junit.framework.AssertionFailedError: Unexpected error in case QUORUM-QUORUM with not upgraded coordinator and 1 nodes down
	at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase$Tester.test(MixedModeAvailabilityTestBase.java:127)
	at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase.lambda$testAvailability$2(MixedModeAvailabilityTestBase.java:79)
	at org.apache.cassandra.distributed.upgrade.UpgradeTestBase$TestCase.run(UpgradeTestBase.java:186)
	at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase.testAvailability(MixedModeAvailabilityTestBase.java:81)
	at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase.testAvailability(MixedModeAvailabilityTestBase.java:53)
	at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityV30Test.testAvailabilityV30ToV4(MixedModeAvailabilityV30Test.java:39)
Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.ReadTimeoutException: Operation timed out - received only 1 responses.
	at org.apache.cassandra.distributed.impl.IsolatedExecutor.waitOn(IsolatedExecutor.java:209)
	at org.apache.cassandra.distributed.impl.IsolatedExecutor.lambda$sync$5(IsolatedExecutor.java:109)
	at org.apache.cassandra.distributed.impl.Coordinator.executeWithResult(Coordinator.java:69)
	at org.apache.cassandra.distributed.api.ICoordinator.execute(ICoordinator.java:32)
	at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase$Tester.lambda$test$1(MixedModeAvailabilityTestBase.java:120)
	at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase$Tester.maybeFail(MixedModeAvailabilityTestBase.java:139)
	at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase$Tester.test(MixedModeAvailabilityTestBase.java:119)
Caused by: org.apache.cassandra.exceptions.ReadTimeoutException: Operation timed out - received only 1 responses.
	at org.apache.cassandra.service.ReadCallback.awaitResults(ReadCallback.java:136)
	at org.apache.cassandra.service.ReadCallback.get(ReadCallback.java:142)
	at org.apache.cassandra.service.AbstractReadExecutor.get(AbstractReadExecutor.java:145)
	at org.apache.cassandra.service.StorageProxy$SinglePartitionReadLifecycle.awaitResultsAndRetryOnDigestMismatch(StorageProxy.java:1831)
	at org.apache.cassandra.service.StorageProxy.fetchRows(StorageProxy.java:1780)
	at org.apache.cassandra.service.StorageProxy.readRegular(StorageProxy.java:1718)
	at org.apache.cassandra.service.StorageProxy.read(StorageProxy.java:1627)
	at org.apache.cassandra.db.SinglePartitionReadCommand$Group.execute(SinglePartitionReadCommand.java:1162)
	at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:302)
	at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:263)
	at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:115)
	at org.apache.cassandra.distributed.impl.Coordinator.executeInternal(Coordinator.java:107)
	at org.apache.cassandra.distributed.impl.Coordinator.lambda$executeWithResult$0(Coordinator.java:69)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:83)
	at java.lang.Thread.run(Thread.java:748)

{code}",,aholmber,blerer,dcapwell,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,aholmber,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 20 15:51:59 UTC 2021,,,,,,,All,,,,"0|z0pqh4:",9223372036854775807,,,,blerer,e.dimitrova,,,Normal,,4.0-rc1,,https://github.com/apache/cassandra/commit/27f1bdee5ecf37eda3dde6ea61a439bdda41ea0a,,,,,,,,,"JVM upgrade test modified, run",,,,,"12/Apr/21 21:03;aholmber;The failure is easily reproduced. Aside from the timeout error in the description, I'm also occasionally seeing it fail with the following:

{noformat}
[junit-timeout] Unexpected error in case ALL-ONE with upgraded coordinator and 2 nodes down
[junit-timeout] junit.framework.AssertionFailedError: Unexpected error in case ALL-ONE with upgraded coordinator and 2 nodes down
[junit-timeout]     at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase$Tester.test(MixedModeAvailabilityTestBase.java:127)
[junit-timeout]     at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase.lambda$testAvailability$2(MixedModeAvailabilityTestBase.java:79)
[junit-timeout]     at org.apache.cassandra.distributed.upgrade.UpgradeTestBase$TestCase.run(UpgradeTestBase.java:187)
[junit-timeout]     at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase.testAvailability(MixedModeAvailabilityTestBase.java:81)
[junit-timeout]     at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase.testAvailability(MixedModeAvailabilityTestBase.java:52)
[junit-timeout]     at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityV30Test.testAvailabilityV30ToV4(MixedModeAvailabilityV30Test.java:39)
[junit-timeout]     at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase$Tester.maybeFail(MixedModeAvailabilityTestBase.java:150)
[junit-timeout]     at org.apache.cassandra.distributed.upgrade.MixedModeAvailabilityTestBase$Tester.test(MixedModeAvailabilityTestBase.java:113)
{noformat};;;","13/Apr/21 21:49;aholmber;As shown in the error in the description,  we're occasionally bumping into coordinator timeouts, which are [set to a smaller value|https://github.com/apache/cassandra/blob/6665fc29b33abcc26aad4cecbfee88225b0a7225/test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeAvailabilityTestBase.java#L64-L65] by the test. I assume they were set lower to make the test timeout faster when we are [expecting a failure|https://github.com/apache/cassandra/blob/6665fc29b33abcc26aad4cecbfee88225b0a7225/test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeAvailabilityTestBase.java#L113]. However, simply raising them then causes the test to occasionally fail in a different way ({{Failure}} instead of {{Timeout}}) if the node shutdown occurs mid-request.

I'm pushing a potential patch that makes sure the coordinator sees the node as down, then expects an {{UnavailableException}}. I'm not sure if/why the {{Timeout}} exception would be essential to this test, but if that is preferred we could look at another technique of inducing the timeout deterministically without making it cause flakiness.

[patch|https://github.com/aholmberg/cassandra/pull/54]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16586];;;","14/Apr/21 01:54;aholmber;CI says I broke the other availability upgrade tests, so sitting on this until I can get back into it.;;;","16/Apr/21 18:50;aholmber;I ran into trouble getting the shutdown approach working with some of the earlier versions. Instead I pushed a simplified version that
1.) extends the request timeout by a second to get away from false negatives
2.) uses message filtering to effect timeouts to nodes when ""down""

test run [here|https://app.circleci.com/pipelines/github/aholmberg/cassandra/250/workflows/c139a296-8b51-4e33-881f-ff811dbec0d3/jobs/2998/parallel-runs/0?filterBy=ALL];;;","20/Apr/21 02:20;e.dimitrova;One nit, otherwise LGTM, thanks!
We need second reviewer, maybe [~adelapena] or [~dcapwell] will volunteer? Does anyone of you have a bit of time?;;;","20/Apr/21 15:48;blerer;The patch look good to me.;;;","20/Apr/21 15:51;blerer;Committed into trunk at 27f1bdee5ecf37eda3dde6ea61a439bdda41ea0a;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Periodic failures in *RepairCoordinator*Test caused by race condition with nodetool repair,CASSANDRA-16585,13370748,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,09/Apr/21 22:31,16/Mar/22 15:41,13/Jul/23 08:40,13/Apr/21 18:48,4.0,4.0-rc1,,,,,,CI,Consistency/Repair,Test/dtest/java,,0,,,"Periodic failures in *RepairCoordinator*Test cause errors such as

FullRepairCoordinatorNeighbourDownTest#validationParticipentCrashesAndComesBack[DATACENTER_AWARE/true] 

{code}
nodetool command [repair, distributed_test_keyspace, validationparticipentcrashesandcomesback_full_datacenter_aware_true, --dc-parallel, --full] Error message 'Some repair failed' does not contain any of [/127.0.0.2:7012 died]
stdout:
[2021-04-07 22:45:24,887] Starting repair command #10 (f129cb60-97f2-11eb-9316-794aa6ab8411), repairing keyspace distributed_test_keyspace with repair options (parallelism: dc_parallel, primary range: false, incremental: false, job threads: 1, ColumnFamilies: [validationparticipentcrashesandcomesback_full_datacenter_aware_true], dataCenters: [], hosts: [], previewKind: NONE, # of ranges: 2, pull repair: false, force repair: false, optimise streams: false, ignore unreplicated keyspaces: false)
[2021-04-07 22:45:32,864] Repair command #10 failed with error Repair session f1342ba0-97f2-11eb-9316-794aa6ab8411 for range [(-1,9223372036854775805], (9223372036854775805,-1]] failed with error Endpoint /127.0.0.2:7012 died
[2021-04-07 22:45:32,887] After waiting for poll interval of 1 seconds queried for parent session status and discovered repair failed.
[2021-04-07 22:45:32,887] Repair command #10 finished with error
[2021-04-07 22:45:32,887] Some repair failed
[2021-04-07 22:45:32,888] Repair command #10 finished with error

stderr:
error: Some repair failed
-- StackTrace --
java.io.IOException: Some repair failed
at org.apache.cassandra.tools.RepairRunner.queryForCompletedRepair(RepairRunner.java:167)
at org.apache.cassandra.tools.RepairRunner.run(RepairRunner.java:72)
at org.apache.cassandra.tools.NodeProbe.repairAsync(NodeProbe.java:431)
at org.apache.cassandra.tools.nodetool.Repair.execute(Repair.java:171)
at org.apache.cassandra.tools.NodeTool$NodeToolCmd.runInternal(NodeTool.java:358)
at org.apache.cassandra.tools.NodeTool$NodeToolCmd.run(NodeTool.java:343)
at org.apache.cassandra.tools.NodeTool.execute(NodeTool.java:246)
at org.apache.cassandra.distributed.impl.Instance$DTestNodeTool.execute(Instance.java:836)
at org.apache.cassandra.distributed.impl.Instance.lambda$nodetoolResult$38(Instance.java:746)
at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base/java.lang.Thread.run(Thread.java:834)


Notifications:
Notification{type=START, src=repair:10, message=Starting repair command #10 (f129cb60-97f2-11eb-9316-794aa6ab8411), repairing keyspace distributed_test_keyspace with repair options (parallelism: dc_parallel, primary range: false, incremental: false, job threads: 1, ColumnFamilies: [validationparticipentcrashesandcomesback_full_datacenter_aware_true], dataCenters: [], hosts: [], previewKind: NONE, # of ranges: 2, pull repair: false, force repair: false, optimise streams: false, ignore unreplicated keyspaces: false)}
Notification{type=ERROR, src=repair:10, message=Repair command #10 failed with error Repair session f1342ba0-97f2-11eb-9316-794aa6ab8411 for range [(-1,9223372036854775805], (9223372036854775805,-1]] failed with error Endpoint /127.0.0.2:7012 died}
Notification{type=COMPLETE, src=repair:10, message=Repair command #10 finished with error}
Error:
java.io.IOException: Some repair failed
at org.apache.cassandra.tools.RepairRunner.queryForCompletedRepair(RepairRunner.java:167)
at org.apache.cassandra.tools.RepairRunner.run(RepairRunner.java:72)
at org.apache.cassandra.tools.NodeProbe.repairAsync(NodeProbe.java:431)
at org.apache.cassandra.tools.nodetool.Repair.execute(Repair.java:171)
at org.apache.cassandra.tools.NodeTool$NodeToolCmd.runInternal(NodeTool.java:358)
at org.apache.cassandra.tools.NodeTool$NodeToolCmd.run(NodeTool.java:343)
at org.apache.cassandra.tools.NodeTool.execute(NodeTool.java:246)
at org.apache.cassandra.distributed.impl.Instance$DTestNodeTool.execute(Instance.java:836)
at org.apache.cassandra.distributed.impl.Instance.lambda$nodetoolResult$38(Instance.java:746)
at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base/java.lang.Thread.run(Thread.java:834)
{code}

Seems there is a race condition in nodetool repair where we query the error state before we get the notification, then we throw a generic error rather than the specific error.",,dcapwell,maedhroz,marcuse,,,,,,,,,,,,,"dcapwell opened a new pull request #959:
URL: https://github.com/apache/cassandra/pull/959


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Apr/21 23:02;githubbot;600","smiklosovic closed pull request #959:
URL: https://github.com/apache/cassandra/pull/959


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:41;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Correctness -> Transient Incorrect Response,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 13 16:55:40 UTC 2021,,,,,,,All,,,,"0|z0pqeg:",9223372036854775807,,,,marcuse,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/5cbdb2e58e870535af61204898a1e2bbf6cb5f64,,,,,,,,,added tests,,,,,"13/Apr/21 08:29;marcuse;+1;;;","13/Apr/21 16:55;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16585-trunk-FAA5CE7A-C333-46EE-99DA-6E208404FAB8]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16585-trunk-FAA5CE7A-C333-46EE-99DA-6E208404FAB8]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/646/]|
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Groupby queries trigger ArrayIndexOutOfBoundsException on mixed version cluster,CASSANDRA-16582,13370514,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aholmber,jwjwyoung,jwjwyoung,09/Apr/21 01:46,16/Mar/22 15:38,13/Jul/23 08:40,12/Apr/21 13:42,4.0,4.0-rc1,,,,,,Messaging/Internode,,,,0,,,"When I have a mixed cluster with C*3.10 and C*4.0-beta4, issuing GROUP BY query to 3.10 will trigger `java.lang.ArrayIndexOutOfBoundsException`. 

Reproduce:

having a mixed cluster 3.10 and 4.0-beta4

 
{code:java}
// create keyspace and db
cqlsh> CREATE KEYSPACE test WITH replication = {'class':'SimpleStrategy', 'replication_factor' : 1};
cqlsh> use test;
cqlsh:test> create table login_log ( user_id int, application_name text, primary key (user_id, application_name) ) with clustering order by (application_name asc);
cqlsh:test> insert into login_log (user_id, application_name) VALUES(1, 'bash');cqlsh:test> insert into login_log (user_id, application_name) VALUES(1, 'chrome');
// issue GROUP BY QUERY
cqlsh:test> select user_id, application_name from login_log group by user_id, application_name;{code}
 

The reason why the bug happens is that the Kind enum in DataLimits has changed from 6 values to 4 values: 

 
{code:java}
[THRIFT_LIMIT, SUPER_COLUMN_COUNTING_LIMIT, CQL_GROUP_BY_LIMIT, CQL_GROUP_BY_PAGING_LIMIT]{code}
{code:java}
[CQL_LIMIT, CQL_PAGING_LIMIT, CQL_GROUP_BY_LIMIT, CQL_GROUP_BY_PAGING_LIMIT]    
{code}
Thus when node 3.10 forwards the read command with CQL_GROUP_BY_LIMIT to node 4.0, it tries to read the value of index 4 in Kind which has only 4 elements, causing ArrayIndexOutOfBoundsException

Log details:
{code:java}
ERROR [Messaging-EventLoop-3-5] 2021-04-09 00:27:14,899 InboundMessageHandler.java:334 - /251.250.238.1:7000->/251.250.238.2:7000-LEGACY_MESSAGES-c356fde1 unexpected exception caught while deserializing a message
java.lang.ArrayIndexOutOfBoundsException: 4
        at org.apache.cassandra.db.filter.DataLimits$Serializer.deserialize(DataLimits.java:1172)
        at org.apache.cassandra.db.ReadCommand$Serializer.deserialize(ReadCommand.java:1006)
        at org.apache.cassandra.db.ReadCommand$Serializer.deserialize(ReadCommand.java:909)
        at org.apache.cassandra.net.Message$Serializer.deserializePayloadPre40(Message.java:966)
        at org.apache.cassandra.net.Message$Serializer.deserializePre40(Message.java:947)
        at org.apache.cassandra.net.Message$Serializer.deserializePre40(Message.java:935)
        at org.apache.cassandra.net.Message$Serializer.deserialize(Message.java:635)
        at org.apache.cassandra.net.InboundMessageHandler.processSmallMessage(InboundMessageHandler.java:320)
        at org.apache.cassandra.net.InboundMessageHandler.processOneContainedMessage(InboundMessageHandler.java:303)
        at org.apache.cassandra.net.InboundMessageHandler.processFrameOfContainedMessages(InboundMessageHandler.java:270)
        at org.apache.cassandra.net.InboundMessageHandler.processIntactFrame(InboundMessageHandler.java:255)
        at org.apache.cassandra.net.InboundMessageHandler.process(InboundMessageHandler.java:246)
        at org.apache.cassandra.net.FrameDecoder.deliver(FrameDecoder.java:320)
        at org.apache.cassandra.net.FrameDecoder.channelRead(FrameDecoder.java:284)
        at org.apache.cassandra.net.FrameDecoder.channelRead(FrameDecoder.java:268)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
        at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:792)
        at io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe$1.run(AbstractEpollChannel.java:387)
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
        at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:384)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)`
{code}
 

 ",,aholmber,brandon.williams,jwjwyoung,mck,,,,,,,,,,,,"blerer opened a new pull request #958:
URL: https://github.com/apache/cassandra/pull/958


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Apr/21 14:56;githubbot;600","smiklosovic closed pull request #958:
URL: https://github.com/apache/cassandra/pull/958


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:38;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,aholmber,blerer,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu May 06 15:30:36 UTC 2021,,,,,,,All,,,,"0|z0poyg:",9223372036854775807,,,,brandon.williams,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/d9e5dd2ff9be17b1ac32aa53a612117e63c40876,,,,,,,,,New jvm upgrade test is added.,,,,,"09/Apr/21 13:09;brandon.williams;Perhaps we should have padded this enum out, the way we do in ApplicationState to avoid these kinds of errors in mixed versions.;;;","09/Apr/21 20:52;aholmber;Benjamin was working on this and had to end the week while working through some test issues. I built on his work and updated the test here:

[patch|https://github.com/aholmberg/cassandra/pull/53]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16582] (started);;;","09/Apr/21 20:59;brandon.williams;[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/612/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/612/pipeline]
;;;","10/Apr/21 00:50;aholmber;Circle ran well with one apparently unrelated timeout failure.;;;","12/Apr/21 13:42;brandon.williams;CI looks good, opened CASSANDRA-16593 for the new failing test.   Committed, thank you.;;;","05/May/21 21:04;jwjwyoung;[~brandon.williams] Based on this, we found there are several other enums using orders to conduct serialization/deserialization, such as:
TraceType in cassandra/src/java/org/apache/cassandra/tracing/Tracing.java
Kind in cassandra/src/java/org/apache/cassandra/db/filter/ColumnSubselection.java. 

Current TraceType and Kind hasn't been changed for a while, but I believe a comments stating that ""their order is used in serialization, and don't change it"" will be helpful for further code practice. 
;;;","06/May/21 15:30;brandon.williams;Thanks [~jwjwyoung], I've added comments in 4e370c7e883.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failure to execute queries should emit a KPI other than read timeout/unavailable so it can be alerted/tracked,CASSANDRA-16581,13370493,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,dcapwell,dcapwell,dcapwell,08/Apr/21 22:15,04/Jun/21 11:01,13/Jul/23 08:40,02/Jun/21 03:56,3.0.25,3.11.11,4.0,4.0-rc2,,,,Messaging/Client,Observability/Metrics,,,0,,,When we are unable to parse a message we do not have a way to detect this from a monitoring point of view so can get into situations where we believe the database is fine but the clients are on-fire.  This case popped up in the 2.1 to 3.0 upgrade as paging state wasn’t mixed-mode safe.,,dcapwell,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Availability -> Unavailable,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Jun 01 23:38:38 UTC 2021,,,,,,,All,,,,"0|z0pots:",9223372036854775807,,,,samt,,,,Normal,,NA,,https://github.com/apache/cassandra/commit/9c50b1f9a12a95b55851cc52d4b66440f9fafaea,,,,,,,,,added tests,,,,,"08/Apr/21 22:38;dcapwell;Removed comment about upgrading to 4.0 as CASSANDRA-15193 fixed it in 3.0.19 (tested in version without that patch);;;","09/Apr/21 17:24;dcapwell;Spoke with Sam and we need to review a few things first:

1) ProtocolException doesn't distinguish between a simple user error (bad CL), and corrupt message (the test added has frame version v84... which doesn't exist).  Reconnects are not free, so this lack of clarity on the exception can be problematic when closing the socket; this problem exists cross 3.x and 4.x lines
2) v5 protocol can have multiple streams on the same frame, and client might not be able to map stream to frame, so a frame level issue (such as checkpointing) can become a problem; this problem is localized to 4.x;;;","27/Apr/21 14:37;samt;Currently, catching a {{ProtocolException}} in by the pipeline's exception handler is supposed to close the channel, forcing the client to reconnect. For v5, this is {{o.a.c.t.ExceptionHandlers.ExceptionHandler}} and for v4 and lower, {{o.a.c.t.PreV5Handlers.ExceptionHandler}} in trunk and {{o.a.c.t.Message.ExceptionHandler}} in prior versions. ) 

{code}
// On protocol exception, close the channel as soon as the message have been sent
if (cause instanceof ProtocolException)
    future.addListener((ChannelFutureListener) f -> ctx.close());

{code}

However, many if not most instances of {{ProtocolException}} are actually contained in a {{WrappedException}} at this point, so not many actually trigger this condition. This is changed by David's patches, but we spoke offline and agreed that this should be reverted for v4- in 3.0, 3.11 and trunk as reconnections can be expensive, especially on the server side when auth is enabled. 

As David mentioned, this is also a slightly more tricky in v5 as a frame can contain envelopes for multiple streams. In the case of a fatal error (one which renders the entire frame unusable), the server is not able to notify the client of the stream ids present in the frame. To avoid causing a wave of client side timeouts, we decided to fail fast and close the client connection if any protocol error is detected.

{quote}
From a client point of view, a dropped frame will result in request timeouts. We have no way of providing a better error, since the stream ids of the failed requests are in the corrupt payload. I'm wondering if it might not be better to drop the connection all the time: at least the client gets immediate feedback (we could try to propagate a cause), instead of a bunch of requests timing out for no apparent reason.
 [1|https://issues.apache.org/jira/browse/CASSANDRA-15299?focusedCommentId=17099447&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17099447]. 
{quote}

However, many protocol errors are not fatal; examples include invalid consistency levels, illegal statements in a BATCH, incorrect opcode. In these cases, the server _may_ be able to respond appropriately to the invalid envelope and continue processing the remainder of the frame.  

I've pushed a couple of v5 specific commits [here|https://github.com/beobal/cassandra/tree/16581-trunk-v5]. The general idea is to attempt to differentiate between so-called protocol errors from which the server can recover and those from which it can't. With this in mind, the message processor will return an error response the first time it encountered a protocol exception, but only terminate the connection if it immediately encounters a second error on the very next envelope in the frame. The reason for failing only on consecutive errors is that any individual error may be recoverable. For instance, a client could send a Frame with 100 envelopes and every other one might have some recoverable corruption. A run of consecutive errors in the same frame is a heuristic for identifying non-recoverable corruption, and while not perfect, it seems fairly reasonable to me. 

An exception to this rule is if the body length advertised in the envelope header is invalid (i.e. < 0). In this case, the message processor is unable to even attempt to skip over the message, so it throws and closes the connection immediately.
;;;","03/May/21 23:57;dcapwell;[~samt] merged in your patch and made the <= v4 logic to do the same as before (error instanceOf ProtocolException) as we don't know if its a recoverable error or not in <= v4

Tests are passing (sending patch, the trunk fork broke a test);;;","14/May/21 17:58;dcapwell;the python details are failing now that we no longer fall back to highest supported protocol version when an unknown protocol version is seen...

{code}
Unexpected error found in node logs (see stdout for full details). Errors: [WARN  [epollEventLoopGroup-5-5] 2021-05-14 16:59:18,418 NoSpamLogger.java:95 - Protocol exception with client networking: org.apache.cassandra.transport.ProtocolException: Invalid or unsupported protocol version (66); supported versions are (3/v3, 4/v4, 5/v5, 6/v6-beta), WARN  [epollEventLoopGroup-5-6] 2021-05-14 16:59:18,418 NoSpamLogger.java:95 - Protocol exception with client networking: org.apache.cassandra.transport.ProtocolException: Invalid or unsupported protocol version (65); supported versions are (3/v3, 4/v4, 5/v5, 6/v6-beta), WARN  [epollEventLoopGroup-5-5] 2021-05-14 16:59:18,418 NoSpamLogger.java:95 - Protocol exception with client networking: org.apache.cassandra.transport.ProtocolException: Invalid or unsupported protocol version (66); supported versions are (3/v3, 4/v4, 5/v5, 6/v6-beta)]
{code}

I can replicate this when the following is done

{code}
$ ./bin/cqlsh
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 4.1-SNAPSHOT | CQL spec 3.4.5 | Native protocol v5]
Use HELP for help.
cqlsh>
{code}

{code}
WARN  [nioEventLoopGroup-5-10] 2021-05-14 10:56:18,366 NoSpamLogger.java:95 - Protocol exception with client networking: org.apache.cassandra.transport.ProtocolException: Invalid or unsupported protocol version (65); supported versions are (3/v3, 4/v4, 5/v5, 6/v6-beta)
{code}

but this doesn't happen when I specify a specific version

{code}
$ ./bin/cqlsh --protocol-version 1
Connection error: ('Unable to connect to any servers', {'127.0.0.1:9042': DriverException('ProtocolError returned from server while using explicitly set client protocol_version 1')})
$ ./bin/cqlsh --protocol-version 2
Connection error: ('Unable to connect to any servers', {'127.0.0.1:9042': DriverException('ProtocolError returned from server while using explicitly set client protocol_version 2')})
$ ./bin/cqlsh --protocol-version 3
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 4.1-SNAPSHOT | CQL spec 3.4.5 | Native protocol v3]
Use HELP for help.
cqlsh>
$ ./bin/cqlsh --protocol-version 4
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 4.1-SNAPSHOT | CQL spec 3.4.5 | Native protocol v4]
Use HELP for help.
cqlsh>
$ ./bin/cqlsh --protocol-version 5
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 4.1-SNAPSHOT | CQL spec 3.4.5 | Native protocol v5]
Use HELP for help.
cqlsh>
$ ./bin/cqlsh --protocol-version 6
Connection error: ('Unable to connect to any servers', {'127.0.0.1:9042': <Error from server: code=000a [Protocol error] message=""Beta version of the protocol used (6/v6-beta), but USE_BETA flag is unset"">})
{code}

{code}
WARN  [nioEventLoopGroup-5-13] 2021-05-14 10:57:27,019 NoSpamLogger.java:95 - Protocol exception with client networking: org.apache.cassandra.transport.ProtocolException: Invalid or unsupported protocol version (1); supported versions are (3/v3, 4/v4, 5/v5, 6/v6-beta)
WARN  [nioEventLoopGroup-5-14] 2021-05-14 10:57:30,967 NoSpamLogger.java:95 - Protocol exception with client networking: org.apache.cassandra.transport.ProtocolException: Invalid or unsupported protocol version (2); supported versions are (3/v3, 4/v4, 5/v5, 6/v6-beta)
WARN  [nioEventLoopGroup-5-21] 2021-05-14 10:57:42,520 NoSpamLogger.java:95 - Protocol exception with client networking: org.apache.cassandra.transport.ProtocolException: Beta version of the protocol used (6/v6-beta), but USE_BETA flag is unset
{code};;;","14/May/21 18:08;dcapwell;What I see is org.apache.cassandra.transport.InitialConnectionHandler#decode gets ""firstByte"" to be 66, and applying the PROTOCOL_VERSION_MASK doesn't change the value.

When I run 

{code}
./bin/cqlsh --protocol-version 4
{code}

the first byte is 4 and versionNum is also 4 (the same is true with --protocol-version 3, but first byte is 3)

This looks like cqlsh is missing this?;;;","14/May/21 18:14;dcapwell;testing java

{code}
try (Cluster cluster = Cluster.builder().addContactPoint(""127.0.0.1"").withoutJMXReporting().build();
             Session session = cluster.newSession())
        {
            for (Row row : session.execute(""select * from system.local""))
            {
                System.out.println(row);
            }
        }
{code}

I see that the first byte is 5 and works as expected without any logs;;;","14/May/21 18:17;dcapwell;What I see is the first message is 65 or 66 (changes some times) and that after our error is sent back the client resends with v5 and the connection moves forward just fine.;;;","14/May/21 18:22;dcapwell;Found the root cause https://github.com/datastax/python-driver/blob/15d715f4e686032b02ce785eca1d176d2b25e32b/cassandra/cluster.py#L614

The default version tried is ProtocolVersion.DSE_V2, then falls back to V1

{code}
    DSE_V1 = 0x41
    """"""
    DSE private protocol v1, supported in DSE 5.1+
    """"""

    DSE_V2 = 0x42
    """"""
    DSE private protocol v2, supported in DSE 6.0+
    """"""

    SUPPORTED_VERSIONS = (DSE_V2, DSE_V1, V6, V5, V4, V3, V2, V1)
    """"""
    A tuple of all supported protocol versions
    """"""
{code}

0x42 = 66, 0x41 = 65;;;","14/May/21 20:30;dcapwell;Looking into this and talking to [~aholmber] it turns out Server can not reply back with a preferred version(s), instead client keeps trying but ""downgrades"" the version to the next in a list... for this reason there isn't something I can really do to avoid this other than avoid logging when the version is DSE. 

Given that adding a ""handshake"" is out of scope (and too late at this point of a release) the only solution I can think of is to avoid logging in these cases.;;;","14/May/21 22:06;dcapwell;tests are passing, but seems our SSL tests are failing as the ""unknown"" log added is showing the following

{code}
Caused by: javax.net.ssl.SSLHandshakeException: error:100000f7:SSL routines:OPENSSL_internal:WRONG_VERSION_NUMBER
	at io.netty.handler.ssl.ReferenceCountedOpenSslEngine.sslReadErrorResult(ReferenceCountedOpenSslEngine.java:1309)
	at io.netty.handler.ssl.ReferenceCountedOpenSslEngine.unwrap(ReferenceCountedOpenSslEngine.java:1270)
	at io.netty.handler.ssl.ReferenceCountedOpenSslEngine.unwrap(ReferenceCountedOpenSslEngine.java:1346)
	at io.netty.handler.ssl.ReferenceCountedOpenSslEngine.unwrap(ReferenceCountedOpenSslEngine.java:1389)
	at io.netty.handler.ssl.SslHandler$SslEngineType$1.unwrap(SslHandler.java:206)
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1387)
	at io.netty.handler.ssl.SslHandler.decodeNonJdkCompatible(SslHandler.java:1294)
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1331)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:508)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:447)
	... 15 common frames omitted]
{code};;;","14/May/21 22:55;dcapwell;added patch for python dtest to ignore those errors;;;","15/May/21 00:12;dcapwell;[~samt] tests are stable now with the latest commit and python dtest changes; will work on back porting the changes;;;","19/May/21 12:35;samt;Thanks, looks good to me except for a couple of minor things.


h3. ProtocolVersion

I'd suggest renaming {{DSE_VERSIONS}} to something like {{KNOWN_INVALID_VERSIONS}}

h3. FrameEncoder

This change seems wrong, if we receive anything other than a {{Payload}} here, it's an error. Is this some leftover debugging perhaps? ;;;","19/May/21 20:57;dcapwell;[~samt]

FrameEncoder change is

{code}
     public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception
     {
         if (!(msg instanceof Payload))
-            throw new IllegalStateException(""Unexpected type: "" + msg);
+        {
+            ctx.write(msg, promise);
+            return;
+        }
{code}

This isn't a leftover from debugging, its from the fact that we no longer support it as the v5 logic uses the more lower level APIs (such as ChannelInboundHandlerAdapter); the higher level APIs pass through objects which do not match the type.  Here is an example from v4 

{code}
public static class ProtocolEncoder extends MessageToMessageEncoder<Message>
{code}

MessageToMessageEncoder has the following https://github.com/netty/netty/blob/4.1/codec/src/main/java/io/netty/handler/codec/MessageToMessageEncoder.java#L84-L100

{code}
            if (acceptOutboundMessage(msg)) {
                ...
            } else {
                ctx.write(msg, promise);
            }
{code}

I use this in the simple client to send arbitrary payloads to validate server behavior.

ProtocolVersion - made the change
;;;","20/May/21 18:47;samt;Oh, I totally missed that in {{SimpleClient}}, sorry. In that case, I definitely think we need to revisit how the test is
 implemented. That assertion in {{FrameEncoder}} is important, not only for the client protocol, but for internode which
 shares the class.

There's quite a lot of machinery in {{CQLConnectionTest}} to give control over the exact bytes that the v5 pipeline
 classes have to deal with. Unfortunately, retro fitting that to support v4 and earlier is not a trivial task. I've
 pushed an alternative reworking of the test [here|https://github.com/beobal/cassandra/tree/CASSANDRA-16581-4.0].

Instead of changing the encoders/decoders this adds a test implementation of {{Message.Request}} which we can prime with some garbage bytes, so that when it's decoded, a \{{ProtocolError}} is guaranteed. This required a tiny bit of refactoring in {{Envelope}} to make the v4 encoding ask-dont-tell like v5, but it gives the test code control over the actual bytes that get decoded on the server rather than having to bypass the checks in the outbound pipeline.

A nice side effect of this is that the v5 test is now exercising the CQL protocol decoding, rather than hitting the CRC
 errors in the framing layer. There are quite a few tests in {{CQLConnectionTest}} which do verify that, so we should be
 good there. This also means that the channel-closing behaviour is the same between the v4 & v5 tests.

Now the message pipelines and failure behaviours are aligned across versions, we don't need {{WrappedSimpleClient}} any
 more and because the test cases are identical, I've made the test {{@Parameterized}} so it will automatically cover all
 supported versions.;;;","21/May/21 00:08;dcapwell;thanks [~samt], I changed to use your patch on trunk (after review is done will backport to 4.0); for the 3.x line I left things alone.

Given this new framework, I now updated to add a second test; one which corrupts the body.;;;","01/Jun/21 11:45;samt;sorry for the holdup, the trunk fix LGTM now except that the change to {{FrameEncoder::write}} hasn't been reverted yet. Aside from that, I think this good to go once the 4.0 branch is updated. Thanks!;;;","01/Jun/21 22:27;dcapwell;Starting commit

CI Results (pending):
||Branch||Source||Circle CI||Jenkins||
|cassandra-3.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16581-cassandra-3.0-BF76A26D-BA05-43FF-A67E-0330068556C3]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16581-cassandra-3.0-BF76A26D-BA05-43FF-A67E-0330068556C3]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/833/]|
|cassandra-3.11|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16581-cassandra-3.11-BF76A26D-BA05-43FF-A67E-0330068556C3]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16581-cassandra-3.11-BF76A26D-BA05-43FF-A67E-0330068556C3]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/834/]|
|cassandra-4.0|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16581-cassandra-4.0-BF76A26D-BA05-43FF-A67E-0330068556C3]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16581-cassandra-4.0-BF76A26D-BA05-43FF-A67E-0330068556C3]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/835/]|
|trunk|[branch|https://github.com/dcapwell/cassandra/tree/commit_remote_branch/CASSANDRA-16581-trunk-BF76A26D-BA05-43FF-A67E-0330068556C3]|[build|https://app.circleci.com/pipelines/github/dcapwell/cassandra?branch=commit_remote_branch%2FCASSANDRA-16581-trunk-BF76A26D-BA05-43FF-A67E-0330068556C3]|[build|https://ci-cassandra.apache.org/job/Cassandra-devbranch/836/]|
;;;","01/Jun/21 23:38;dcapwell;4.x is stable, but 3.x python dtests are failing; looking into them.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NativeLibrary#getProcessID() does not handle `UnsatisfiedLinkError`,CASSANDRA-16578,13370459,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,drohrer,drohrer,drohrer,08/Apr/21 18:30,30/Jul/21 12:06,13/Jul/23 08:40,30/Jul/21 12:05,3.0.26,3.11.12,4.0.1,,,,,Local/Other,,,,0,,,"NativeLibrary#getProcessID() does not handle `UnsatisfiedLinkError` (derived from Error, not Exception) as the other native methods do. Therefore, it can never return -1 when it fails for this reason, and can break callers that would otherwise be able to handle the situation gracefully. Most other methods in the class do this, but this one is missing the handling of this error.",,blerer,dcapwell,drohrer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Apr/21 18:33;drohrer;native-library-fix.patch;https://issues.apache.org/jira/secure/attachment/13023572/native-library-fix.patch",,,,,1.0,drohrer,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jul 30 12:06:08 UTC 2021,,,,,,,All,,,,"0|z0pom8:",9223372036854775807,,,,blerer,dcapwell,,,Normal,,3.0.0,,https://github.com/apache/cassandra/commit/e399dea95916646acde6770ced18fedcc5359913,,,,,,,,,testing in environment where JNA doesn't work,,,,,"08/Apr/21 18:45;dcapwell;+1;;;","30/Jul/21 10:27;blerer;The patch look good to me.;;;","30/Jul/21 12:05;blerer;Committed into 3.0 at e399dea95916646acde6770ced18fedcc5359913 and merged into 3.11, 4.0 and trunk;;;","30/Jul/21 12:06;blerer;Thank you for the patch [~drohrer] and sorry for the delay.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node waits for schema agreement on removed nodes,CASSANDRA-16577,13370382,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,Jan Karlsson,Jan Karlsson,08/Apr/21 12:56,30/Apr/21 06:42,13/Jul/23 08:40,13/Apr/21 13:04,3.0.25,3.11.11,4.0,4.0-rc1,,,,Cluster/Gossip,Consistency/Bootstrap and Decommission,,,0,,,"CASSANDRA-15158 might have introduced a bug where bootstrapping nodes wait for schema agreement from nodes that have been removed if token allocation for keyspace is enabled.

 

It is fairly easy to reproduce with the following steps:
{noformat}
// Create 3 node cluster
ccm create test --vnodes -n 3 -s -v 3.11.10

// Remove two nodes
ccm node2 decommission
ccm node3 decommission
ccm node2 remove
ccm node3 remove

// Create keyspace to change the schema. It works if the schema never changes.
ccm node1 cqlsh -x ""CREATE KEYSPACE k WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};""

// Add allocate parameter
ccm updateconf 'allocate_tokens_for_keyspace: k'

// Add node2 again to cluster
ccm add node2 -i 127.0.0.2 -j 7200 -r 2200
ccm node2 start{noformat}
 

This will cause node2 to throw exception on startup:
{noformat}
WARN  [main] 2021-04-08 14:10:53,272 StorageService.java:941 - There are nodes in the cluster with a different schema version than us we did not merged schemas from, our version : (a5da47ec-ffe3-3111-b2f3-325f771f1539), outstanding versions -> endpoints : {8e9ec79e-5ed2-3949-8ac8-794abfee3837=[/127.0.0.3]}
ERROR [main] 2021-04-08 14:10:53,274 CassandraDaemon.java:803 - Exception encountered during startup
java.lang.RuntimeException: Didn't receive schemas for all known versions within the timeout
        at org.apache.cassandra.service.StorageService.waitForSchema(StorageService.java:947) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.dht.BootStrapper.allocateTokens(BootStrapper.java:206) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.dht.BootStrapper.getBootstrapTokens(BootStrapper.java:177) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:1073) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.StorageService.initServer(StorageService.java:753) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.StorageService.initServer(StorageService.java:687) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:395) [apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:633) [apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:786) [apache-cassandra-3.11.10.jar:3.11.10]
INFO  [StorageServiceShutdownHook] 2021-04-08 14:10:53,279 HintsService.java:209 - Paused hints dispatch
WARN  [StorageServiceShutdownHook] 2021-04-08 14:10:53,280 Gossiper.java:1670 - No local state, state is in silent shutdown, or node hasn't joined, not announcing shutdown
INFO  [StorageServiceShutdownHook] 2021-04-08 14:10:53,280 MessagingService.java:985 - Waiting for messaging service to quiesce
INFO  [ACCEPT-/127.0.0.2] 2021-04-08 14:10:53,281 MessagingService.java:1346 - MessagingService has terminated the accept() thread
INFO  [StorageServiceShutdownHook] 2021-04-08 14:10:53,416 HintsService.java:209 - Paused hints dispatch{noformat}
 

 

 ",,adelapena,bdeggleston,e.dimitrova,Jan Karlsson,mck,tommy_s,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Availability,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 13 13:04:36 UTC 2021,,,,,,,All,,,,"0|z0po54:",9223372036854775807,,,,adelapena,aholmber,bdeggleston,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/4164313f926b605a24395a8ca920e8bea0691204,,,,,,,,,add dtest,,,,,"08/Apr/21 14:42;brandon.williams;dtest to repro [here|https://github.com/driftx/cassandra-dtest/tree/CASSANDRA-16577].;;;","08/Apr/21 16:00;brandon.williams;I started making a patch to remove the endpoints from MigrationCoordinator on node removal, but I think there are larger problems here.  At least another is that MC isn't taking into account whether nodes are up or down, if a schema changed is performed with a node down you can't bootstrap until it comes back up.

/cc [~bdeggleston];;;","08/Apr/21 16:18;bdeggleston;That's by design. It's possible the down node has a table with data the new node should replicate, and coming up without its schema would lose data. Since C* can't determine if the unreachable schema is newer than the other schemas we have, the operator needs to skip the schema check on bootstrap by setting {{-Dcassandra.skip_schema_check=true}}, which we should include in the log message. It might also be good to add config options for skipping specific schema versions / endpoints.;;;","08/Apr/21 17:00;brandon.williams;bq. It's possible the down node has a table with data the new node should replicate

It's possible that node then gets removed, too.  Is the correct solution for this ticket to also skip the schema check?;;;","08/Apr/21 21:47;brandon.williams;[Patch|https://github.com/driftx/cassandra/tree/CASSANDRA-16577] takes the approach of removing the node from versions when it's removed from the cluster.  Also removes what I believe is an errant call in onJoin that should already be handled in the onChange call just above it which filters dead states, where this one does not.

[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/594/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/594/pipeline]
;;;","09/Apr/21 12:18;Jan Karlsson;Tried to reproduce with your patch. It worked both on 4.0-rc1-SNAPSHOT and 3.11.11-SNAPSHOT.

As for the code, LGTM. One nit would be to include the ignore log message into the exception instead of the warning.;;;","09/Apr/21 12:48;brandon.williams;This broke some dtests, will post a new revision soon, and fix your nit.;;;","09/Apr/21 13:24;adelapena;Confirmed that the dtest nicely reproduces the failure for trunk, but I think that for 3.0 and 3.11 it fails earlier than expected due to the usage of {{--force}} in the call to {{nodetool decomission}}. This option doesn't exist in those branches, since it was added only for 4.0 by CASSANDRA-12510. Also, we could add a {{@jira_ticket}} reference to this ticket in the docstring for the new dtest. I'm still looking at the fix itself and the affected dtests.;;;","09/Apr/21 13:41;brandon.williams;Updated [dtest|https://github.com/driftx/cassandra-dtest/tree/CASSANDRA-16577] and [patch|https://github.com/driftx/cassandra/tree/CASSANDRA-16577].

[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/599/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/599/pipeline]
;;;","09/Apr/21 16:31;adelapena;Looks good to me assuming CI looks good, +1.;;;","09/Apr/21 17:08;bdeggleston;Fix looks good, although it would be good to add a test to {{MigrationCoordinatorTest}} exercising {{removeVersionInfoForEndpoint}}. I think you could just add a variant of {{versionsAreSignaledWhenDeleted}}:

{code}
    /**
     * If an endpoint is removed and no other endpoints are reporting its
     * schema version, the version should be removed and, we should signal 
     * anyone waiting on that version
     */
    @Test
    public void versionsAreSignaledWhenEndpointsRemoved()
    {
        InstrumentedCoordinator coordinator = new InstrumentedCoordinator();

        coordinator.reportEndpointVersion(EP1, V1);
        WaitQueue.Signal signal = coordinator.getVersionInfoUnsafe(V1).register();
        Assert.assertFalse(signal.isSignalled());

        coordinator.removeVersionInfoForEndpoint(EP1);
        Assert.assertNull(coordinator.getVersionInfoUnsafe(V1));

        Assert.assertTrue(signal.isSignalled());
    }


{code};;;","09/Apr/21 17:16;brandon.williams;[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/635/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/635/pipeline]
 
Nits addressed, Blake's test added. Will commit if this run is good.;;;","09/Apr/21 21:23;brandon.williams;Same [patch|https://github.com/driftx/cassandra/tree/CASSANDRA-16577-3.0] but slightly different location for 3.0/3.11.

[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/637/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/637/pipeline]
;;;","12/Apr/21 12:25;adelapena;It seems there is a compile error in the patch for 3.0, the new {{MigrationCoordinator#removeVersionInfoForEndpoint}} method should probably have an {{InetAddress}} argument, instead of the {{InetAddressAndPort}} used in {{trunk}}.;;;","13/Apr/21 13:04;brandon.williams;No failures look related, committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
jflex NPE (StateSetEnumerator.reset(…)) on arm64 and jdk11,CASSANDRA-16576,13370335,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,mck,mck,08/Apr/21 09:40,11/Apr/21 19:25,13/Jul/23 08:40,11/Apr/21 19:25,4.0,4.0-rc1,,,,,,Build,,,,0,,,"NPE thrown from `ant generate-jflex-java` on jdk11 and arm64.

Upstream: https://github.com/jflex-de/jflex/issues/910 
{code}
 java.lang.NullPointerException
 	at jflex.StateSetEnumerator.reset(StateSetEnumerator.java:40)
 	at jflex.NFA.containsFinal(NFA.java:295)
 	at jflex.NFA.getDFA(NFA.java:539)
 	at jflex.Main.generate(Main.java:80)
 	at jflex.anttask.JFlexTask.execute(JFlexTask.java:65)
 	at org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:292)
 	at jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
 	at org.apache.tools.ant.dispatch.DispatchUtils.execute(DispatchUtils.java:99)
 	at org.apache.tools.ant.Task.perform(Task.java:350)
 	at org.apache.tools.ant.Target.execute(Target.java:449)
 	at org.apache.tools.ant.Target.performTasks(Target.java:470)
 	at org.apache.tools.ant.Project.executeSortedTargets(Project.java:1388)
 	at org.apache.tools.ant.Project.executeTarget(Project.java:1361)
 	at org.apache.tools.ant.helper.DefaultExecutor.executeTargets(DefaultExecutor.java:41)
 	at org.apache.tools.ant.Project.executeTargets(Project.java:1251)
 	at org.apache.tools.ant.Main.runBuild(Main.java:834)
 	at org.apache.tools.ant.Main.startAnt(Main.java:223)
 	at org.apache.tools.ant.launch.Launcher.run(Launcher.java:284)
 	at org.apache.tools.ant.launch.Launcher.main(Launcher.java:101)
{code}

Failures
- https://ci-cassandra.apache.org/view/Cassandra%204.0/job/Cassandra-trunk-artifacts/jdk=jdk_11_latest,label=cassandra-arm64/505/consoleFull
- https://ci-cassandra.apache.org/view/Cassandra%204.0/job/Cassandra-trunk-artifacts/501/jdk=jdk_11_latest,label=cassandra-arm64/console
- https://ci-cassandra.apache.org/view/Cassandra%204.0/job/Cassandra-trunk-artifacts/497/jdk=jdk_11_latest,label=cassandra-arm64/console",,bereng,ganeshraju,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,Packaging -> All,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sun Apr 11 19:25:59 UTC 2021,,,,,,,ARM,,,,"0|z0pnuo:",9223372036854775807,,,,brandon.williams,,,,Normal,,3.4,,https://github.com/apache/cassandra/commit/e848d47ed171f20ccd8cf5e20d9e188ede85c17c,,,,,,,,,CI,,,,,"11/Apr/21 07:51;mck;An upgrade to jflex 1.8.2 appears to have fixed the issue.

In trunk it was failing ~20-30% of the time.

This [patch|https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/16576/trunk] was run 30 times in a loop without any failure here: [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-artifacts/jdk=jdk_11_latest,label=cassandra-arm64/590//badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-artifacts/jdk=jdk_11_latest,label=cassandra-arm64/590/];;;","11/Apr/21 16:06;brandon.williams;+1;;;","11/Apr/21 17:57;mck;Full pipeline [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/632/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/632/pipeline/];;;","11/Apr/21 19:25;mck;Committed as [e848d47ed171f20ccd8cf5e20d9e188ede85c17c|https://github.com/apache/cassandra/commit/e848d47ed171f20ccd8cf5e20d9e188ede85c17c].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""compression"" configuration in unit tests is incorrect",CASSANDRA-16575,13370317,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,08/Apr/21 08:31,19/Nov/21 06:56,13/Jul/23 08:40,28/Apr/21 08:51,4.0,4.0-rc2,,,,,,Test/unit,,,,0,,,"When running unit tests with ""compression"" configuration, we use non-default Snappy compressor.

There is a misleading fragment of {{build.xml}}:
{code}
      <property name=""compressed_yaml"" value=""${build.test.dir}/cassandra.compressed.yaml""/>
      <concat destfile=""${compressed_yaml}"">
          <fileset file=""${test.conf}/cassandra.yaml""/>
          <fileset file=""${test.conf}/commitlog_compression.yaml""/>
      </concat>
{code}

{{cassandra.compressed.yaml}} has been replaced in CASSANDRA-14482 by two files {{commitlog_compression_LZ4.yaml}} and {{commitlog_compression_Zstd.yaml}} without changing build configuration.

All in all we could fix that but I doubt it makes any sense since {{cdc}} configuration already uses compressed commit log anyway so it feels redundant to test compression alone for each CI run. 

",,e.dimitrova,jlewandowski,mck,,,,,,,,,,,,,"jacek-lewandowski opened a new pull request #957:
URL: https://github.com/apache/cassandra/pull/957


   Instead of predefined test, test-compression, test-cdc, test-system-keyspace-directory, have the ability to specify a properties file, which may include extra-java-opts property. That property contains extra JVM options to be added to a forked JVM for testing.
   
   This way, instead of:
   
   ant test-compression
   
   we have:
   ant -Dprops=test/conf/unit-with-sstable-compression.properties test
   
   We can easily create new configurations or modify existing without touching the build itself
   
   Also changes the compressor used in compression configuration from snappy to lz4


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Apr/21 12:24;githubbot;600","michaelsembwever commented on a change in pull request #957:
URL: https://github.com/apache/cassandra/pull/957#discussion_r610713357



##########
File path: build.xml
##########
@@ -1444,75 +1447,6 @@
     </sequential>
   </macrodef>
 
-  <!-- Will not generate a junit report or fail on error since it is called in parallel for test-compression
-       That is taken care of by testparallel -->
-  <macrodef name=""testlist-compression"">
-    <attribute name=""test.file.list"" />
-    <attribute name=""testlist.offset"" />
-    <sequential>
-      <property name=""compressed_yaml"" value=""${build.test.dir}/cassandra.compressed.yaml""/>
-      <concat destfile=""${compressed_yaml}"">
-          <fileset file=""${test.conf}/cassandra.yaml""/>
-          <fileset file=""${test.conf}/commitlog_compression.yaml""/>
-      </concat>
-      <testmacrohelper inputdir=""${test.unit.src}"" filelist=""@{test.file.list}"" poffset=""@{testlist.offset}""
-                       exclude=""**/*.java"" timeout=""${test.timeout}"" testtag=""compression"">
-        <jvmarg value=""-Dlegacy-sstable-root=${test.data}/legacy-sstables""/>
-        <jvmarg value=""-Dinvalid-legacy-sstable-root=${test.data}/invalid-legacy-sstables""/>
-        <jvmarg value=""-Dcassandra.test.compression=true""/>
-        <jvmarg value=""-Dcassandra.ring_delay_ms=1000""/>
-        <jvmarg value=""-Dcassandra.tolerate_sstable_size=true""/>
-        <jvmarg value=""-Dcassandra.config=file:///${compressed_yaml}""/>
-        <jvmarg value=""-Dcassandra.skip_sync=true"" />
-        <jvmarg value=""-Dcassandra.config.loader=org.apache.cassandra.OffsetAwareConfigurationLoader""/>
-      </testmacrohelper>
-    </sequential>
-  </macrodef>
-
-  <macrodef name=""testlist-cdc"">
-    <attribute name=""test.file.list"" />
-    <attribute name=""testlist.offset"" />
-    <sequential>
-      <property name=""cdc_yaml"" value=""${build.test.dir}/cassandra.cdc.yaml""/>
-      <concat destfile=""${cdc_yaml}"">
-        <fileset file=""${test.conf}/cassandra.yaml""/>
-        <fileset file=""${test.conf}/cdc.yaml""/>

Review comment:
       is there any way of maintaining this feature?  it is cumbersome to keep all the different test cassandra.yaml's up to date… 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Apr/21 15:21;githubbot;600","michaelsembwever commented on a change in pull request #957:
URL: https://github.com/apache/cassandra/pull/957#discussion_r615449193



##########
File path: build.xml
##########
@@ -69,6 +69,8 @@
     <property name=""test.driver.read_timeout_ms"" value=""12000""/>
     <property name=""dist.dir"" value=""${build.dir}/dist""/>
     <property name=""tmp.dir"" value=""${java.io.tmpdir}""/>
+    <property file=""${props}""/>
+    <property name=""extra-java-opts"" value=""""/>

Review comment:
       would it be possible to encapsulate these just related test targets?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Apr/21 20:24;githubbot;600","michaelsembwever commented on a change in pull request #957:
URL: https://github.com/apache/cassandra/pull/957#discussion_r610713357



##########
File path: build.xml
##########
@@ -1444,75 +1447,6 @@
     </sequential>
   </macrodef>
 
-  <!-- Will not generate a junit report or fail on error since it is called in parallel for test-compression
-       That is taken care of by testparallel -->
-  <macrodef name=""testlist-compression"">
-    <attribute name=""test.file.list"" />
-    <attribute name=""testlist.offset"" />
-    <sequential>
-      <property name=""compressed_yaml"" value=""${build.test.dir}/cassandra.compressed.yaml""/>
-      <concat destfile=""${compressed_yaml}"">
-          <fileset file=""${test.conf}/cassandra.yaml""/>
-          <fileset file=""${test.conf}/commitlog_compression.yaml""/>
-      </concat>
-      <testmacrohelper inputdir=""${test.unit.src}"" filelist=""@{test.file.list}"" poffset=""@{testlist.offset}""
-                       exclude=""**/*.java"" timeout=""${test.timeout}"" testtag=""compression"">
-        <jvmarg value=""-Dlegacy-sstable-root=${test.data}/legacy-sstables""/>
-        <jvmarg value=""-Dinvalid-legacy-sstable-root=${test.data}/invalid-legacy-sstables""/>
-        <jvmarg value=""-Dcassandra.test.compression=true""/>
-        <jvmarg value=""-Dcassandra.ring_delay_ms=1000""/>
-        <jvmarg value=""-Dcassandra.tolerate_sstable_size=true""/>
-        <jvmarg value=""-Dcassandra.config=file:///${compressed_yaml}""/>
-        <jvmarg value=""-Dcassandra.skip_sync=true"" />
-        <jvmarg value=""-Dcassandra.config.loader=org.apache.cassandra.OffsetAwareConfigurationLoader""/>
-      </testmacrohelper>
-    </sequential>
-  </macrodef>
-
-  <macrodef name=""testlist-cdc"">
-    <attribute name=""test.file.list"" />
-    <attribute name=""testlist.offset"" />
-    <sequential>
-      <property name=""cdc_yaml"" value=""${build.test.dir}/cassandra.cdc.yaml""/>
-      <concat destfile=""${cdc_yaml}"">
-        <fileset file=""${test.conf}/cassandra.yaml""/>
-        <fileset file=""${test.conf}/cdc.yaml""/>

Review comment:
       is there any way of maintaining this feature?  it is cumbersome (and error-prone) to keep all the different test cassandra.yaml's up to date… 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Apr/21 20:25;githubbot;600","michaelsembwever commented on a change in pull request #957:
URL: https://github.com/apache/cassandra/pull/957#discussion_r615449359



##########
File path: test/conf/commitlog_compression_Zstd.yaml
##########
@@ -1,2 +0,0 @@
-commitlog_compression:
-    - class_name: ZstdCompressor

Review comment:
       this should be maintained. compression tests should enable both sstable and commitlog compression.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Apr/21 20:25;githubbot;600","michaelsembwever commented on pull request #957:
URL: https://github.com/apache/cassandra/pull/957#issuecomment-822055833


   A few small comments added.
   
   Compatibility over branches is also a concern here. We currently have one [build script](https://github.com/apache/cassandra-builds/blob/trunk/build-scripts/cassandra-test.sh#L93-L104) that kicks off the ant command line for the different test targets, that runs regardless of the cassandra branch.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Apr/21 20:28;githubbot;600","michaelsembwever commented on a change in pull request #957:
URL: https://github.com/apache/cassandra/pull/957#discussion_r619515534



##########
File path: test/unit/org/apache/cassandra/SchemaLoader.java
##########
@@ -751,4 +747,26 @@ public static void cleanupSavedCaches()
     {
         ServerTestUtils.cleanupSavedCaches();
     }
+
+    private static CompressionParams compressionParams(int chunkLength)
+    {
+        String algo = System.getProperty(""test.compression_algo"", ""lz4"").toLowerCase();

Review comment:
       ```suggestion
           String algo = System.getProperty(""cassandra.test.compression.algo"", ""lz4"").toLowerCase();
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Apr/21 21:58;githubbot;600","michaelsembwever commented on pull request #957:
URL: https://github.com/apache/cassandra/pull/957#issuecomment-828276723


   merged with https://github.com/apache/cassandra/commit/10a1d65eb09a93aee32948b46b4f1a0fbc2defe0


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Apr/21 08:51;githubbot;600","michaelsembwever closed pull request #957:
URL: https://github.com/apache/cassandra/pull/957


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Apr/21 08:51;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,5400,,,0,5400,,,,,,,,,,,,,,,,,,,CASSANDRA-47,,,,,,,,,,,,,,,,,,,0.0,jlewandowski,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Low Hanging Fruit,User Report,,false,CASSANDRA-15536,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Apr 28 08:51:39 UTC 2021,,,,,,,All,,,,"0|z0pnqo:",9223372036854775807,,,,mck,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/10a1d65eb09a93aee32948b46b4f1a0fbc2defe0,,,,,,,,,CI,,,,,"08/Apr/21 08:53;mck;{quote}
I vote for removing compression configuration and actually allow to manually specify yaml file to be used for testing as a test property, as well as allow to manually specify extra system properties to be passed to the test. That would make the build more flexible and remove a bit of redundant code.
{quote}
+1

I think we should (at least try to) track down the devs who added the {{test-compression}} variant to CI to find out why it was important at the time. Some info on the {{test-cdc}} was provided [here|https://lists.apache.org/thread.html/re6a7f30348fd81fccec1714cb3e78bc6ec1de5568eac997ee04e5c24%40%3Cdev.cassandra.apache.org%3E] by [~JoshuaMcKenzie];;;","08/Apr/21 15:58;jlewandowski;My plan is to allow configuring the build with properties or properties file, this way we can have predefined configurations stored as properties files in {{test/conf}} and choose them to have the repeated runs, wdyt ?;;;","08/Apr/21 16:25;mck;bq. predefined configurations stored as properties files in test/conf

+1

There's a lot of configuration combinations we are not testing. Our default CI pipeline needs to be minimised, but a configuration set could be used in less frequent CI runs (like once a week).;;;","09/Apr/21 09:10;jlewandowski;I was wrong, the compression tests are aimed to test sstable compression which is explicitly disabled when running just {{unit}} tests. SchemaLoader forces no compression for each table that is created through that utility in tests; Also when compression is enabled, it forces snappy compressor to be used for those tables. All other tables are created with the default LZ4. 

Therefore it seems like the compression configuration has nothing to do with commit log compression and the only thing we should consider to use the current default compressor LZ4 instead of Snappy and remove the misleading fragment of the build. 

I'm still thinking that we should allow for passing test configuration without the need to modify the build.
;;;","09/Apr/21 12:24;jlewandowski;This is my proposal: https://github.com/apache/cassandra/pull/957
;;;","23/Apr/21 09:35;mck;[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/706/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/706/pipeline/];;;","23/Apr/21 18:26;mck;and https://ci-cassandra.apache.org/job/Cassandra-devbranch-test-compression/422/;;;","28/Apr/21 08:51;mck;Committed as [10a1d65eb09a93aee32948b46b4f1a0fbc2defe0|https://github.com/apache/cassandra/commit/10a1d65eb09a93aee32948b46b4f1a0fbc2defe0].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
j8_dtest_jars_build is broken in CI,CASSANDRA-16572,13370203,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,yifanc,yifanc,07/Apr/21 20:16,25/Apr/21 11:32,13/Jul/23 08:40,08/Apr/21 22:35,3.0.25,3.11.11,4.0,4.0-rc1,,,,Build,CI,,,0,,,"j8_dtest_jars_build is broken. It constantly fails at building the dtest jar from the target branch after building the trunk. 

One example, https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/741/workflows/c3de5483-85b0-48a4-b1fa-1c52f89680c7/jobs/4063

It seems to be caused by the recent ant build changes. The lib dir contains the jars leftover from the build output of trunk.
",,brandon.williams,e.dimitrova,mck,yifanc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16391,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,mck,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Apr 08 22:33:01 UTC 2021,,,,,,,All,,,,"0|z0pn1c:",9223372036854775807,,,,e.dimitrova,,,,Normal,,,,https://github.com/apache/cassandra/commit/4795e23c82b26fddf1dbfb10447aa9f7eeb26d87,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16572?focusedCommentId=17317502&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17317502,,,,,"07/Apr/21 20:40;brandon.williams;Until the build changes are also added to the other branches a quick workaround is to `git clean -fd lib` after switching branches, or use git worktrees.;;;","07/Apr/21 20:43;e.dimitrova;I confirm I saw the issue on all three branches 3.0, 3.11, 4.0. 

CC [~mck] - [~yifanc] found the right steps to reproduce it locally pointed  [here |#comment-17316634]

"" It fails with this build sequence, 1) build the trunk, 2) then build the target branch. "";;;","07/Apr/21 20:45;e.dimitrova;One comment on my end, this happens after ant real clean but seems [~brandon.williams]'s workaround helps;;;","07/Apr/21 20:52;yifanc;Yeah. The {{realclean}} task in the other branches only deletes the build directory according to the script. https://github.com/apache/cassandra/blob/cassandra-3.11/build.xml#L210-L212;;;","07/Apr/21 20:54;mck;Side note, ci-cassandra.a.o doesn't suffer this problem because it builds the older branches first and trunk last.
ref: https://github.com/apache/cassandra-builds/blob/trunk/build-scripts/cassandra-test.sh#L34 ;;;","08/Apr/21 14:09;e.dimitrova;Is anyone working on this one or should I assign and try to tackle it?

 ;;;","08/Apr/21 14:16;brandon.williams;The only way to fix this properly that I see is to complete CASSANDRA-16557;;;","08/Apr/21 18:42;e.dimitrova;[~mck] fixed it at least for circle similar to Jenkins.

[3.0 | https://github.com/ekaterinadimitrova2/cassandra/commit/83e302daa01dfe5600649df0e57d9dd2463b686b] |  [CI | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/757/workflows/9989f570-16d4-4293-a500-117e14e1b998/jobs/4180]

[3.11 | https://github.com/ekaterinadimitrova2/cassandra/commit/713d207eb6f6da8b079bb882906964039ace9fa1] | [CI | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/758/workflows/14b3e4d5-3d80-4221-aad0-fbe5eee79720/jobs/4179]

Unfortunately, this fix didn't solve the issue in trunk:

[turnk | https://github.com/ekaterinadimitrova2/cassandra/commit/4fa98f35cc6ad015a7096473e42bbf1316c8fdfd ] | [CI | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/760/workflows/d8faa21d-7b01-4f91-ad99-334205eb5916/jobs/4194]

So long story short, we have fix for Circle 3.0 and 3.11 but I still have to think about trunk more. 


 ;;;","08/Apr/21 18:46;brandon.williams;Does the git clean trick not help there?;;;","08/Apr/21 19:03;e.dimitrova;We thought that [this|https://github.com/apache/cassandra/blob/trunk/build.xml#L378] should be enough but it seems it is not;;;","08/Apr/21 19:08;brandon.williams;If you git clean -fd then it will guarantee the tree is clean.;;;","08/Apr/21 20:10;e.dimitrova;Adding [this | https://github.com/ekaterinadimitrova2/cassandra/commit/88e083e8f7aab80ee39b69f86cf5ee9ef33c6bb5] doesn't solve the issue;;;","08/Apr/21 20:13;brandon.williams;You need to do it after the checkout of the branch to build.;;;","08/Apr/21 20:53;e.dimitrova;Yes, you are right, but unfortunately [this | https://github.com/ekaterinadimitrova2/cassandra/commit/be2039b46e75fed6773a252e1ba59bb25124d451]  still didn't work.;;;","08/Apr/21 21:29;e.dimitrova;My mistake, it works, I didn't test it right, my fault.

So now we have patches for circle ci for all three branches.
[3.0 | https://github.com/ekaterinadimitrova2/cassandra/commit/83e302daa01dfe5600649df0e57d9dd2463b686b] |  [CI | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/757/workflows/9989f570-16d4-4293-a500-117e14e1b998/jobs/4180]

[3.11 | https://github.com/ekaterinadimitrova2/cassandra/commit/713d207eb6f6da8b079bb882906964039ace9fa1] | [CI | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/758/workflows/14b3e4d5-3d80-4221-aad0-fbe5eee79720/jobs/4179]

[trunk patch | https://github.com/ekaterinadimitrova2/cassandra/commit/69352ba4be02458c24c3b42acb26c458e6baf70a] | [CI | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/769/workflows/c9dbca29-2c53-4cdb-bcb0-554f9e7d6e35];;;","08/Apr/21 21:31;e.dimitrova;I am +1 on your patch, being tester and reviewer :) ;;;","08/Apr/21 21:46;brandon.williams;To keep things simple, I don't see why the trunk patch shouldn't work on 3.0 and 3.11 as well.;;;","08/Apr/21 21:55;e.dimitrova;Fair, considering the Slack chat I assume the three of us are on the same page now so I  will commit it ;;;","08/Apr/21 22:33;e.dimitrova;Committed:

3edacd632c..1ecf5d0e8e  cassandra-3.0 -> cassandra-3.0

7b10f9cb03..80beb83cf9  cassandra-3.11 -> cassandra-3.11

29e4612e88..4795e23c82  trunk -> trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""multiple versions of ant detected in path for junit"" printed for every junit test case spawned by ""ant test""",CASSANDRA-16571,13370185,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,e.dimitrova,e.dimitrova,07/Apr/21 18:53,27/Jun/21 09:26,13/Jul/23 08:40,08/Apr/21 21:44,4.0,4.0-rc1,,,,,,Build,,,,0,,,"I saw this warning for the first time after CASSANDRA-16391. To be confirmed that it wasn't there with some of the previous patches.

The same warning was taken care of  in CASSANDRA-13232

Seems to me that the issue is similar but the fix will be different. ",,e.dimitrova,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16557,,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,Thu Apr 08 21:44:18 UTC 2021,,,,,,,All,,,,"0|z0pmxc:",9223372036854775807,,,,brandon.williams,mck,,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/29e4612e887439466868c88b9097b149f8c0192f,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16571?focusedCommentId=17316708&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17316708,,,,,"07/Apr/21 21:12;mck;I think all that is required is this:
{noformat}
diff --git a/build.xml b/build.xml
index dc44066b89..50e9d21d5d 100644
--- a/build.xml
+++ b/build.xml
@@ -718,7 +718,6 @@
         <dependency groupId=""org.openjdk.jmh"" artifactId=""jmh-core"" scope=""test""/>
         <dependency groupId=""org.openjdk.jmh"" artifactId=""jmh-generator-annprocess"" scope=""test""/>
         <dependency groupId=""net.ju-n.compile-command-annotations"" artifactId=""compile-command-annotations"" scope=""test""/>
-        <dependency groupId=""org.apache.ant"" artifactId=""ant-junit"" version=""1.9.7"" scope=""test""/>
         <!-- adding this dependency is necessary for assertj. When updating assertj, need to also update the version of
              this that the new assertj's `assertj-parent-pom` depends on. -->
         <dependency groupId=""org.junit"" artifactId=""junit-bom"" type=""pom"" scope=""test""/>
{noformat};;;","07/Apr/21 21:30;brandon.williams;Hmm, even with a little extra effort:
{noformat}
diff --git a/build.xml b/build.xml
index 15f3219..2a0b7fd 100644
--- a/build.xml
+++ b/build.xml
@@ -267,15 +267,18 @@
         <pathelement location=""${build.classes.main}"" />
         <fileset dir=""${build.dir.lib}"">
             <include name=""**/*.jar"" />
+           <exclude name=""**/ant-*.jar""/>
         </fileset>
     </path>
     <path id=""cassandra.classpath.test"">
         <file file=""${build.dir}/${final.name}.jar""/> <!-- we need the jar for tests and benchmarks (multi-version jar) -->
         <fileset dir=""${build.dir.lib}"">
             <include name=""**/*.jar"" />
+           <exclude name=""**/ant-*.jar""/>
         </fileset>
         <fileset dir=""${test.lib}/jars"">
             <include name=""**/*.jar"" />
+           <exclude name=""**/ant-*.jar""/>
         </fileset>
     </path>
 
@@ -718,7 +721,6 @@
         <dependency groupId=""org.openjdk.jmh"" artifactId=""jmh-core"" scope=""test""/>
         <dependency groupId=""org.openjdk.jmh"" artifactId=""jmh-generator-annprocess"" scope=""test""/>
         <dependency groupId=""net.ju-n.compile-command-annotations"" artifactId=""compile-command-annotations"" scope=""test""/>
-        <dependency groupId=""org.apache.ant"" artifactId=""ant-junit"" version=""1.9.7"" scope=""test""/>
         <!-- adding this dependency is necessary for assertj. When updating assertj, need to also update the version of
              this that the new assertj's `assertj-parent-pom` depends on. -->
         <dependency groupId=""org.junit"" artifactId=""junit-bom"" type=""pom"" scope=""test""/>
{noformat}

I still get:

{noformat}
[junit-timeout] WARNING: multiple versions of ant detected in path for junit 
[junit-timeout]          jar:file:/usr/share/ant/lib/ant.jar!/org/apache/tools/ant/Project.class
[junit-timeout]      and jar:file:/home/ubuntu/cassandra/build/test/lib/jars/ant-1.9.7.jar!/org/apache/tools/ant/Project.class
{noformat};;;","07/Apr/21 21:36;mck;[~brandon.williams], with my patch above, the file {{/home/ubuntu/cassandra/build/test/lib/jars/ant-1.9.7.jar}} should not exist.;;;","07/Apr/21 21:38;e.dimitrova;I have a patch... give me a few minutes :) ;;;","07/Apr/21 21:41;e.dimitrova;[PR|https://github.com/ekaterinadimitrova2/cassandra/pull/104] | [CI|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=CASSANDRA-16571-trunk];;;","07/Apr/21 21:42;e.dimitrova;Locally I don't see anymore the issue, in circle too (it is still running but before the warning was before every test and we don't see it now);;;","07/Apr/21 21:44;brandon.williams;bq. Brandon Williams, with my patch above, the file /home/ubuntu/cassandra/build/test/lib/jars/ant-1.9.7.jar should not exist.

Oops, yeah, I needed to clean.  With your ant-junit removal everything is good. +1 to that over the excludes.;;;","07/Apr/21 21:52;e.dimitrova;+1, thanks [~mck], I will commit it on your name;;;","07/Apr/21 21:59;e.dimitrova;[Patch | https://github.com/ekaterinadimitrova2/cassandra/pull/105] | [CI | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra?branch=CASSANDRA-16571]

For completeness I will commit it on green CI;;;","08/Apr/21 09:18;mck;i realised late, my patch is wrong, as it is going to break compilation in our IDEs, as we have test classes that compile against the ant libraries…

e.g.
{code}rg ""org.apache.tools.ant"" test/{code};;;","08/Apr/21 13:02;brandon.williams;Doh.  +1 to Ekaterina's exclusion patch, then.;;;","08/Apr/21 19:31;e.dimitrova;Confirmed in Intellij, removing ant-unit is breaking the build which is not the case with the exclusion patch.

[Patch | https://github.com/apache/cassandra/commit/e3e11686990889aabbb4b9837f4e1cb6f82ba407] | [CI | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/761/workflows/73ef5cfd-7568-4d04-9e59-02c8ae69279f];;;","08/Apr/21 21:21;mck;two lines are not needed. otherwise +1. thanks [~e.dimitrova].;;;","08/Apr/21 21:44;e.dimitrova;Committed [here|https://github.com/apache/cassandra/commit/29e4612e887439466868c88b9097b149f8c0192f], thanks;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky StorageServiceServerTest,CASSANDRA-16569,13369983,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,07/Apr/21 07:47,31/Jul/21 21:28,13/Jul/23 08:40,13/Apr/21 09:34,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"Failing on [ci-cass|https://ci-cassandra.apache.org/job/Cassandra-trunk/411/testReport/junit/org.apache.cassandra.service/StorageServiceServerTest/testLocalPrimaryRangeForEndpointWithNetworkTopologyStrategy_compression/]",,bereng,mck,,,,,,,,,,,,,,"bereng opened a new pull request #955:
URL: https://github.com/apache/cassandra/pull/955


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Apr/21 07:56;githubbot;600","bereng commented on pull request #955:
URL: https://github.com/apache/cassandra/pull/955#issuecomment-818566695


   The PR basically replaces `assert`s with the more junit debug friendly `assertThat`


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Apr/21 08:49;githubbot;600","bereng commented on pull request #955:
URL: https://github.com/apache/cassandra/pull/955#issuecomment-818574432


   CI [j11](https://app.circleci.com/pipelines/github/bereng/cassandra/247/workflows/556e0f2a-c817-4e43-90f6-530b0cb12919) Unrelated failures
   
   CI [j8](https://app.circleci.com/pipelines/github/bereng/cassandra/247/workflows/6cfdadd6-388a-4d23-ba74-66e120908632) Unrelated failures


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Apr/21 09:01;githubbot;600","bereng closed pull request #955:
URL: https://github.com/apache/cassandra/pull/955


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/May/21 06:01;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,2400,,,0,2400,,,,,,,CASSANDRA-16595,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 13 09:08:40 UTC 2021,,,,,,,All,,,,"0|z0plog:",9223372036854775807,,,,mck,,,,Normal,,4.0-rc,,https://github.com/apache/cassandra/commit/44f5b8adf53f31c793a35387004f26f87c8b936d,,,,,,,,,See PR,,,,,"07/Apr/21 08:31;bereng;Mmmmm doesn't repro in multiplexer, locally, looping up to 1M times or on a slow env so far.;;;","08/Apr/21 11:00;bereng;So far it won't repro. But investigation is making me suspicious this could be related to the env. Given the recent junit splits and that the test seems to fail only sometimes. I tried to see if it would fail always on the same server in case it was a specific server the culprit but it wasn't so. Now I am trying to repro with the same jenkins scripts and docker under slow envs etc.;;;","09/Apr/21 08:06;bereng;I haven't managed to repro neither find a thread I could start pulling from. I am leaving here steps to run the test under a docker container such as in jenkins for completion:

{noformat}
To run the test under the sh jenkins uses run this line. 6/8 tells it what split to run which you'll have to find by trial and error
./cassandra-builds/build-scripts/cassandra-test.sh test-compression 6/8

To run the test under a docker container so it is exactly as in jenkins:
./cassandra-builds/build-scripts/cassandra-test-docker.sh apache trunk https://github.com/apache/cassandra-builds.git trunk apache/cassandra-testing-ubuntu2004-java11 test 6/8
{noformat}

Despite running it under the jenkins/docker script on a severely downgraded machine where execution went from 3m to 2h it would still not repro. So I am attaching a PR with verbose asserts I am proposing to merge and next time it fails see if it provides something to go on from.;;;","11/Apr/21 14:03;mck;This looks to be related to running with multiple runners…  (similar issue to CASSANDRA-16587)

To reproduce…
{code}
ant build-test
sed -i '' 's/target name=""test"" depends=""eclipse-warnings,build-test,get-cores,get-mem""/target name=""test""/' build.xml

ant test -Dtest.name=StorageServiceServerTest & ant test -Dtest.name=StorageServiceServerTest
{code};;;","13/Apr/21 08:47;bereng;After extensive discussion in CASSANDRA-16587 looks we're going to be moving to parallelizing under docker. Still I don't want to drop the verbose asserts in the PR which are an improvement nevertheless. I will amend the PR and move into review.;;;","13/Apr/21 09:08;mck;bq. So I am attaching a PR with verbose asserts I am proposing to merge and next time it fails see if it provides something to go on from.

+1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix test testCompoundPartitionKey - org.apache.cassandra.cql3.ViewTest,CASSANDRA-16567,13369923,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,dcapwell,dcapwell,07/Apr/21 02:37,21/Sep/21 11:00,13/Jul/23 08:40,23/Apr/21 18:48,3.0.25,3.11.11,4.0,4.0-rc2,,,,CI,Test/unit,,,0,,,"https://app.circleci.com/pipelines/github/dcapwell/cassandra/874/workflows/0b0a1e36-107a-43c7-815f-bf8e61d3028d/jobs/5227/tests

{code}
junit.framework.AssertionFailedError: Got more rows than expected. Expected 0 but got 1.
	at org.apache.cassandra.cql3.CQLTester.assertRows(CQLTester.java:1185)
	at org.apache.cassandra.cql3.ViewTest.testCompoundPartitionKey(ViewTest.java:817)
{code}",,adelapena,dcapwell,e.dimitrova,,,,,,,,,,,,,"adelapena opened a new pull request #967:
URL: https://github.com/apache/cassandra/pull/967


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;14/Apr/21 13:45;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r615048451



##########
File path: src/java/org/apache/cassandra/db/view/TableViews.java
##########
@@ -93,6 +93,11 @@ public boolean add(View view)
         return Iterables.transform(views, view -> keyspace.getColumnFamilyStore(view.getDefinition().name()));
     }
 
+    public void stopBuild()
+    {
+        views.forEach(View::stopBuild);

Review comment:
       Should we revise the debug log messages? WDYT?
   https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/view/View.java#L223
   

##########
File path: test/unit/org/apache/cassandra/cql3/ViewTest.java
##########
@@ -50,11 +51,12 @@
 import org.apache.cassandra.service.ClientWarn;
 import org.apache.cassandra.transport.ProtocolVersion;
 import org.apache.cassandra.utils.FBUtilities;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
 
-
+@RunWith(BMUnitRunner.class)
 public class ViewTest extends CQLTester
 {
-    ProtocolVersion protocolVersion = ProtocolVersion.V4;

Review comment:
       Good catch, thanks for fixing it and making it impossible to be missed again.

##########
File path: test/unit/org/apache/cassandra/cql3/ViewTest.java
##########
@@ -1469,4 +1460,32 @@ public void testQuotedIdentifiersInWhereClause() throws Throwable
                    row(""\""theKey\"" IS NOT NULL AND (\""theClustering_1\"", \""theClustering_2\"") = (1, 2) AND \""theValue\"" IS NOT NULL""),
                    row(""token(\""theKey\"") > token(1) AND \""theClustering_1\"" = 1 AND \""theClustering_2\"" > 2 AND \""theValue\"" IS NOT NULL""));
     }
+
+    /**
+     * Tests that truncating a table stops the ongoing builds of its materialized views,
+     * so they don't write into the MV data that has been truncated in the base table.
+     *
+     * See CASSANDRA-16567 for further details.
+     */
+    @Test
+    @BMRule(name = ""Delay materialized view mutations"",
+    targetClass = ""StorageProxy"",
+    targetMethod = ""mutateMV"",
+    action = ""Thread.sleep(4000);"")
+    public void testTruncateWhileBuilding() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (k int, c int, v int, PRIMARY KEY(k, c))"");
+        execute(""USE "" + keyspace());
+        executeNet(""USE "" + keyspace());
+        updateView(""INSERT INTO %s (k, c, v) VALUES (?, ?, ?)"", 0, 0, 0);

Review comment:
       updateView before createView?
   

##########
File path: test/unit/org/apache/cassandra/cql3/ViewTest.java
##########
@@ -1469,4 +1460,32 @@ public void testQuotedIdentifiersInWhereClause() throws Throwable
                    row(""\""theKey\"" IS NOT NULL AND (\""theClustering_1\"", \""theClustering_2\"") = (1, 2) AND \""theValue\"" IS NOT NULL""),
                    row(""token(\""theKey\"") > token(1) AND \""theClustering_1\"" = 1 AND \""theClustering_2\"" > 2 AND \""theValue\"" IS NOT NULL""));
     }
+
+    /**
+     * Tests that truncating a table stops the ongoing builds of its materialized views,
+     * so they don't write into the MV data that has been truncated in the base table.
+     *
+     * See CASSANDRA-16567 for further details.
+     */
+    @Test
+    @BMRule(name = ""Delay materialized view mutations"",
+    targetClass = ""StorageProxy"",
+    targetMethod = ""mutateMV"",
+    action = ""Thread.sleep(4000);"")
+    public void testTruncateWhileBuilding() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (k int, c int, v int, PRIMARY KEY(k, c))"");
+        execute(""USE "" + keyspace());
+        executeNet(""USE "" + keyspace());
+        updateView(""INSERT INTO %s (k, c, v) VALUES (?, ?, ?)"", 0, 0, 0);
+        createView(""mv"",
+                   ""CREATE MATERIALIZED VIEW %s AS SELECT * FROM %%s "" +
+                   ""WHERE k IS NOT NULL AND c IS NOT NULL AND v IS NOT NULL "" +
+                   ""PRIMARY KEY (v, c, k)"");
+        Thread.sleep(2000); // wait for the creation of MV build tasks

Review comment:
       I hope these sleeps survive our CIs, I have bad feeling when we rely on timing but I guess it should be fine, you also pushed it on the multiplexer :-) 

##########
File path: test/unit/org/apache/cassandra/cql3/ViewTest.java
##########
@@ -1469,4 +1460,32 @@ public void testQuotedIdentifiersInWhereClause() throws Throwable
                    row(""\""theKey\"" IS NOT NULL AND (\""theClustering_1\"", \""theClustering_2\"") = (1, 2) AND \""theValue\"" IS NOT NULL""),
                    row(""token(\""theKey\"") > token(1) AND \""theClustering_1\"" = 1 AND \""theClustering_2\"" > 2 AND \""theValue\"" IS NOT NULL""));
     }
+
+    /**
+     * Tests that truncating a table stops the ongoing builds of its materialized views,
+     * so they don't write into the MV data that has been truncated in the base table.
+     *
+     * See CASSANDRA-16567 for further details.
+     */
+    @Test
+    @BMRule(name = ""Delay materialized view mutations"",
+    targetClass = ""StorageProxy"",
+    targetMethod = ""mutateMV"",
+    action = ""Thread.sleep(4000);"")

Review comment:
       I guess 4000 came based on testing

##########
File path: test/unit/org/apache/cassandra/cql3/ViewTest.java
##########
@@ -1469,4 +1460,32 @@ public void testQuotedIdentifiersInWhereClause() throws Throwable
                    row(""\""theKey\"" IS NOT NULL AND (\""theClustering_1\"", \""theClustering_2\"") = (1, 2) AND \""theValue\"" IS NOT NULL""),
                    row(""token(\""theKey\"") > token(1) AND \""theClustering_1\"" = 1 AND \""theClustering_2\"" > 2 AND \""theValue\"" IS NOT NULL""));
     }
+
+    /**
+     * Tests that truncating a table stops the ongoing builds of its materialized views,
+     * so they don't write into the MV data that has been truncated in the base table.
+     *
+     * See CASSANDRA-16567 for further details.
+     */
+    @Test
+    @BMRule(name = ""Delay materialized view mutations"",
+    targetClass = ""StorageProxy"",
+    targetMethod = ""mutateMV"",
+    action = ""Thread.sleep(4000);"")
+    public void testTruncateWhileBuilding() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (k int, c int, v int, PRIMARY KEY(k, c))"");
+        execute(""USE "" + keyspace());
+        executeNet(""USE "" + keyspace());
+        updateView(""INSERT INTO %s (k, c, v) VALUES (?, ?, ?)"", 0, 0, 0);
+        createView(""mv"",
+                   ""CREATE MATERIALIZED VIEW %s AS SELECT * FROM %%s "" +
+                   ""WHERE k IS NOT NULL AND c IS NOT NULL AND v IS NOT NULL "" +
+                   ""PRIMARY KEY (v, c, k)"");
+        Thread.sleep(2000); // wait for the creation of MV build tasks

Review comment:
       I would also probably add one more `assertRows(execute(""SELECT * FROM mv WHERE v = ? and c = ?"", 0, 0));` before `TRUNCATE`




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Apr/21 00:05;githubbot;600","adelapena commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r615968613



##########
File path: src/java/org/apache/cassandra/db/view/TableViews.java
##########
@@ -93,6 +93,11 @@ public boolean add(View view)
         return Iterables.transform(views, view -> keyspace.getColumnFamilyStore(view.getDefinition().name()));
     }
 
+    public void stopBuild()
+    {
+        views.forEach(View::stopBuild);

Review comment:
       I think we don't have an easy way to check log messages in unit tests. We have some checks for that type of messages in [materialized_views_test.py](https://github.com/apache/cassandra-dtest/blob/trunk/materialized_views_test.py), and probably we should add some additional tests for truncate there. However, some of those dtests are skipped due to being flaky, and indeed the entire class is marked as flaky. It's my understanding that fixing those will be part of the post-4.0 MV hardening effort, wdyt?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 15:51;githubbot;600","adelapena commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r615969298



##########
File path: test/unit/org/apache/cassandra/cql3/ViewTest.java
##########
@@ -1469,4 +1460,32 @@ public void testQuotedIdentifiersInWhereClause() throws Throwable
                    row(""\""theKey\"" IS NOT NULL AND (\""theClustering_1\"", \""theClustering_2\"") = (1, 2) AND \""theValue\"" IS NOT NULL""),
                    row(""token(\""theKey\"") > token(1) AND \""theClustering_1\"" = 1 AND \""theClustering_2\"" > 2 AND \""theValue\"" IS NOT NULL""));
     }
+
+    /**
+     * Tests that truncating a table stops the ongoing builds of its materialized views,
+     * so they don't write into the MV data that has been truncated in the base table.
+     *
+     * See CASSANDRA-16567 for further details.
+     */
+    @Test
+    @BMRule(name = ""Delay materialized view mutations"",
+    targetClass = ""StorageProxy"",
+    targetMethod = ""mutateMV"",
+    action = ""Thread.sleep(4000);"")
+    public void testTruncateWhileBuilding() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (k int, c int, v int, PRIMARY KEY(k, c))"");
+        execute(""USE "" + keyspace());
+        executeNet(""USE "" + keyspace());
+        updateView(""INSERT INTO %s (k, c, v) VALUES (?, ?, ?)"", 0, 0, 0);

Review comment:
       Good catch, we don't need `updateView` at all, replaced by a regular `execute`.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 15:51;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r615975007



##########
File path: src/java/org/apache/cassandra/db/view/TableViews.java
##########
@@ -93,6 +93,11 @@ public boolean add(View view)
         return Iterables.transform(views, view -> keyspace.getColumnFamilyStore(view.getDefinition().name()));
     }
 
+    public void stopBuild()
+    {
+        views.forEach(View::stopBuild);

Review comment:
       I meant the message I pointed to will be the same even if it is for truncation now. Might be confusing for users. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 15:58;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r615975528



##########
File path: src/java/org/apache/cassandra/db/view/TableViews.java
##########
@@ -93,6 +93,11 @@ public boolean add(View view)
         return Iterables.transform(views, view -> keyspace.getColumnFamilyStore(view.getDefinition().name()));
     }
 
+    public void stopBuild()
+    {
+        views.forEach(View::stopBuild);

Review comment:
       I didn't mean to improve the tests which I agree we should do in post 4.0, absolutely




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 15:59;githubbot;600","adelapena commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r615976421



##########
File path: test/unit/org/apache/cassandra/cql3/ViewTest.java
##########
@@ -1469,4 +1460,32 @@ public void testQuotedIdentifiersInWhereClause() throws Throwable
                    row(""\""theKey\"" IS NOT NULL AND (\""theClustering_1\"", \""theClustering_2\"") = (1, 2) AND \""theValue\"" IS NOT NULL""),
                    row(""token(\""theKey\"") > token(1) AND \""theClustering_1\"" = 1 AND \""theClustering_2\"" > 2 AND \""theValue\"" IS NOT NULL""));
     }
+
+    /**
+     * Tests that truncating a table stops the ongoing builds of its materialized views,
+     * so they don't write into the MV data that has been truncated in the base table.
+     *
+     * See CASSANDRA-16567 for further details.
+     */
+    @Test
+    @BMRule(name = ""Delay materialized view mutations"",
+    targetClass = ""StorageProxy"",
+    targetMethod = ""mutateMV"",
+    action = ""Thread.sleep(4000);"")
+    public void testTruncateWhileBuilding() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (k int, c int, v int, PRIMARY KEY(k, c))"");
+        execute(""USE "" + keyspace());
+        executeNet(""USE "" + keyspace());
+        updateView(""INSERT INTO %s (k, c, v) VALUES (?, ?, ?)"", 0, 0, 0);
+        createView(""mv"",
+                   ""CREATE MATERIALIZED VIEW %s AS SELECT * FROM %%s "" +
+                   ""WHERE k IS NOT NULL AND c IS NOT NULL AND v IS NOT NULL "" +
+                   ""PRIMARY KEY (v, c, k)"");
+        Thread.sleep(2000); // wait for the creation of MV build tasks

Review comment:
       I have replaced the sleeps by a `CountDownLatch` manipulated by a couple of Byteman rules. One rule blocks the view builder tasks on the latch, and the other rule unblocks them when the truncation starts. That seems enough to consistently reproduce the bug when we don't stop the build on `truncateBlocking`. I'll give it a few runs in the multiplexer just in case. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 16:00;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r615976613



##########
File path: src/java/org/apache/cassandra/db/view/TableViews.java
##########
@@ -93,6 +93,11 @@ public boolean add(View view)
         return Iterables.transform(views, view -> keyspace.getColumnFamilyStore(view.getDefinition().name()));
     }
 
+    public void stopBuild()
+    {
+        views.forEach(View::stopBuild);

Review comment:
       I had to say ""improve"" instead of ""revise"", my bad, sorry for the confusion. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 16:00;githubbot;600","adelapena commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r615980232



##########
File path: src/java/org/apache/cassandra/db/view/TableViews.java
##########
@@ -93,6 +93,11 @@ public boolean add(View view)
         return Iterables.transform(views, view -> keyspace.getColumnFamilyStore(view.getDefinition().name()));
     }
 
+    public void stopBuild()
+    {
+        views.forEach(View::stopBuild);

Review comment:
       As an alternative to log checks I have added a couple of assertions on the number of MV builders tasks running on the view build executor.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 16:05;githubbot;600","adelapena commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r615982046



##########
File path: src/java/org/apache/cassandra/db/view/TableViews.java
##########
@@ -93,6 +93,11 @@ public boolean add(View view)
         return Iterables.transform(views, view -> keyspace.getColumnFamilyStore(view.getDefinition().name()));
     }
 
+    public void stopBuild()
+    {
+        views.forEach(View::stopBuild);

Review comment:
       Ah, I understand, good catch, I'll change it.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 16:08;githubbot;600","adelapena commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r616010985



##########
File path: src/java/org/apache/cassandra/db/view/TableViews.java
##########
@@ -93,6 +93,11 @@ public boolean add(View view)
         return Iterables.transform(views, view -> keyspace.getColumnFamilyStore(view.getDefinition().name()));
     }
 
+    public void stopBuild()
+    {
+        views.forEach(View::stopBuild);

Review comment:
       I have opted for changing the debug message to a simple `Stopping current view builder due to schema change or truncate`. Perhaps we could pass an argument to the method about the specific cause, although being a debug message I guess that the specific cause will be also logged around, wdyt?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 16:44;githubbot;600","adelapena commented on pull request #967:
URL: https://github.com/apache/cassandra/pull/967#issuecomment-822650536


   CI:
   * [CircleCI j8](https://app.circleci.com/pipelines/github/adelapena/cassandra/278/workflows/ebd918cf-6259-4726-9b54-5f2a6e43b2e1)
   * [CircleCI j11](https://app.circleci.com/pipelines/github/adelapena/cassandra/278/workflows/bdbf9cb9-8be7-4527-8a55-fac9c5bb42c8)
   * [Jenkins](https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/684/pipeline/)
   * [Multiplexer](https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/810/)


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 17:38;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r616115176



##########
File path: src/java/org/apache/cassandra/db/view/TableViews.java
##########
@@ -93,6 +93,11 @@ public boolean add(View view)
         return Iterables.transform(views, view -> keyspace.getColumnFamilyStore(view.getDefinition().name()));
     }
 
+    public void stopBuild()
+    {
+        views.forEach(View::stopBuild);

Review comment:
       I think this should be enough (`Stopping current view builder due to schema change or truncate`). Thank you




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Apr/21 19:19;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r616287328



##########
File path: test/unit/org/apache/cassandra/cql3/ViewTest.java
##########
@@ -1468,24 +1476,44 @@ public void testQuotedIdentifiersInWhereClause() throws Throwable
      * See CASSANDRA-16567 for further details.
      */
     @Test
-    @BMRule(name = ""Delay materialized view mutations"",
-    targetClass = ""StorageProxy"",
-    targetMethod = ""mutateMV"",
-    action = ""Thread.sleep(4000);"")
+    @BMRules(rules = {
+    @BMRule(name = ""Block view builder tasks"",
+    targetClass = ""ViewBuilderTask"",
+    targetMethod = ""buildKey"",
+    action = ""com.google.common.util.concurrent.Uninterruptibles.awaitUninterruptibly"" +
+             ""(org.apache.cassandra.cql3.ViewTest.blockViewBuild);""),
+    @BMRule(name = ""Unblock view builder tasks"",
+    targetClass = ""ColumnFamilyStore"",
+    targetMethod = ""truncateBlocking"",
+    action = ""org.apache.cassandra.cql3.ViewTest.blockViewBuild.countDown();"")
+    })
     public void testTruncateWhileBuilding() throws Throwable
     {
         createTable(""CREATE TABLE %s (k int, c int, v int, PRIMARY KEY(k, c))"");
         execute(""USE "" + keyspace());
         executeNet(""USE "" + keyspace());
-        updateView(""INSERT INTO %s (k, c, v) VALUES (?, ?, ?)"", 0, 0, 0);
+        execute(""INSERT INTO %s (k, c, v) VALUES (?, ?, ?)"", 0, 0, 0);
         createView(""mv"",
                    ""CREATE MATERIALIZED VIEW %s AS SELECT * FROM %%s "" +
                    ""WHERE k IS NOT NULL AND c IS NOT NULL AND v IS NOT NULL "" +
                    ""PRIMARY KEY (v, c, k)"");
-        Thread.sleep(2000); // wait for the creation of MV build tasks
+
+        // check that the delayed view builder tasks are running and they haven't written anything yet
+        assertThat(runningViewBuilds()).isPositive();

Review comment:
       From the comment it seems you check only active tasks, but it contains also pending ones




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 01:51;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r616288202



##########
File path: test/unit/org/apache/cassandra/cql3/ViewTest.java
##########
@@ -1469,4 +1460,32 @@ public void testQuotedIdentifiersInWhereClause() throws Throwable
                    row(""\""theKey\"" IS NOT NULL AND (\""theClustering_1\"", \""theClustering_2\"") = (1, 2) AND \""theValue\"" IS NOT NULL""),
                    row(""token(\""theKey\"") > token(1) AND \""theClustering_1\"" = 1 AND \""theClustering_2\"" > 2 AND \""theValue\"" IS NOT NULL""));
     }
+
+    /**
+     * Tests that truncating a table stops the ongoing builds of its materialized views,
+     * so they don't write into the MV data that has been truncated in the base table.
+     *
+     * See CASSANDRA-16567 for further details.
+     */
+    @Test
+    @BMRule(name = ""Delay materialized view mutations"",
+    targetClass = ""StorageProxy"",
+    targetMethod = ""mutateMV"",
+    action = ""Thread.sleep(4000);"")
+    public void testTruncateWhileBuilding() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (k int, c int, v int, PRIMARY KEY(k, c))"");
+        execute(""USE "" + keyspace());
+        executeNet(""USE "" + keyspace());
+        updateView(""INSERT INTO %s (k, c, v) VALUES (?, ?, ?)"", 0, 0, 0);
+        createView(""mv"",
+                   ""CREATE MATERIALIZED VIEW %s AS SELECT * FROM %%s "" +
+                   ""WHERE k IS NOT NULL AND c IS NOT NULL AND v IS NOT NULL "" +
+                   ""PRIMARY KEY (v, c, k)"");
+        Thread.sleep(2000); // wait for the creation of MV build tasks

Review comment:
       Looks quite good, thanks




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 01:54;githubbot;600","adelapena commented on pull request #967:
URL: https://github.com/apache/cassandra/pull/967#issuecomment-823190585


   I have realized that, since we are stopping the build at the beginning of truncate, the view never gets marked as built in the system tables. To fix this I'm just running a new view build at the end of truncate. We could also directly mark the views as built instead of running a builder assuming that the view is going to be empty. However it feels safer to just reuse the regular MV lifecycle, in case new sstables appear in the meantime.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 11:14;githubbot;600","adelapena commented on pull request #967:
URL: https://github.com/apache/cassandra/pull/967#issuecomment-823193070


   CI:
   * [CircleCI j8](https://app.circleci.com/pipelines/github/adelapena/cassandra/279/workflows/7a4f495b-ed8e-4aec-91c6-c34f16d8cc2e)
   * [CircleCI j11](https://app.circleci.com/pipelines/github/adelapena/cassandra/279/workflows/29b4ae05-ac9e-4d53-82e0-3757cf6cf2f0)
   * [ci-cassandra](https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/685/pipeline)
   * [Multiplexer](https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/812/)


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Apr/21 11:18;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r617093122



##########
File path: src/java/org/apache/cassandra/db/ColumnFamilyStore.java
##########
@@ -2290,14 +2290,15 @@ public void run()
             indexManager.truncateAllIndexesBlocking(truncatedAt);
             viewManager.truncateBlocking(replayAfter, truncatedAt);
 
-                SystemKeyspace.saveTruncationRecord(ColumnFamilyStore.this, truncatedAt, replayAfter);
-                logger.trace(""cleaning out row cache"");
-                invalidateCaches();
-
-            }
+            SystemKeyspace.saveTruncationRecord(ColumnFamilyStore.this, truncatedAt, replayAfter);
+            logger.trace(""cleaning out row cache"");
+            invalidateCaches();
         };
 
         runWithCompactionsDisabled(Executors.callable(truncateRunnable), true, true);
+
+        viewManager.build();

Review comment:
       that is something I was thinking about last night and now it clicks... good catch
   Can we also test the viewManager after truncate?

##########
File path: src/java/org/apache/cassandra/db/ColumnFamilyStore.java
##########
@@ -2290,14 +2290,15 @@ public void run()
             indexManager.truncateAllIndexesBlocking(truncatedAt);
             viewManager.truncateBlocking(replayAfter, truncatedAt);
 
-                SystemKeyspace.saveTruncationRecord(ColumnFamilyStore.this, truncatedAt, replayAfter);
-                logger.trace(""cleaning out row cache"");
-                invalidateCaches();
-
-            }
+            SystemKeyspace.saveTruncationRecord(ColumnFamilyStore.this, truncatedAt, replayAfter);
+            logger.trace(""cleaning out row cache"");
+            invalidateCaches();
         };
 
         runWithCompactionsDisabled(Executors.callable(truncateRunnable), true, true);
+
+        viewManager.build();

Review comment:
       I am a bit confused actually...did you mean build or start? From your comment it sounded more as you meant to call viewManager.start?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Apr/21 02:40;githubbot;600","adelapena commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r618356292



##########
File path: src/java/org/apache/cassandra/db/ColumnFamilyStore.java
##########
@@ -2290,14 +2290,15 @@ public void run()
             indexManager.truncateAllIndexesBlocking(truncatedAt);
             viewManager.truncateBlocking(replayAfter, truncatedAt);
 
-                SystemKeyspace.saveTruncationRecord(ColumnFamilyStore.this, truncatedAt, replayAfter);
-                logger.trace(""cleaning out row cache"");
-                invalidateCaches();
-
-            }
+            SystemKeyspace.saveTruncationRecord(ColumnFamilyStore.this, truncatedAt, replayAfter);
+            logger.trace(""cleaning out row cache"");
+            invalidateCaches();
         };
 
         runWithCompactionsDisabled(Executors.callable(truncateRunnable), true, true);
+
+        viewManager.build();

Review comment:
       > Can we also test the viewManager after truncate?
   
   I don't understand this, the new `testTruncateWhileBuilding` waits for this second view build and verifies that it marks the view as built in the `system.built_views` table and that the MV is still empty. What else should we test? Maybe trying to write some data to the truncated view?
   
   > I am a bit confused actually...did you mean build or start? From your comment it sounded more as you meant to call viewManager.start?
   
   I don't see a `viewManager.start` method, do you mean renaming the method `TableViews#build()` to `TableViews#start()`? By the way, it's a bit confusing that `ColumnFamilyStore#viewManager` is a `TableViews` object, and not an actual `ViewManager`, I guess this is done so for the sake of symmetry with `ColumnFamilyStore#indexManager`.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Apr/21 12:30;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #967:
URL: https://github.com/apache/cassandra/pull/967#discussion_r618364926



##########
File path: src/java/org/apache/cassandra/db/ColumnFamilyStore.java
##########
@@ -2290,14 +2290,15 @@ public void run()
             indexManager.truncateAllIndexesBlocking(truncatedAt);
             viewManager.truncateBlocking(replayAfter, truncatedAt);
 
-                SystemKeyspace.saveTruncationRecord(ColumnFamilyStore.this, truncatedAt, replayAfter);
-                logger.trace(""cleaning out row cache"");
-                invalidateCaches();
-
-            }
+            SystemKeyspace.saveTruncationRecord(ColumnFamilyStore.this, truncatedAt, replayAfter);
+            logger.trace(""cleaning out row cache"");
+            invalidateCaches();
         };
 
         runWithCompactionsDisabled(Executors.callable(truncateRunnable), true, true);
+
+        viewManager.build();

Review comment:
       _I don't see a viewManager.start method, do you mean renaming the method TableViews#build() to TableViews#start()? By the way, it's a bit confusing that ColumnFamilyStore#viewManager is a TableViews object, and not an actual ViewManager, I guess this is done so for the sake of symmetry with ColumnFamilyStore#indexManager._
   
   Yes, my bad It seems I switched again to the ViewManager class at some point. I. was thinking of changing the ViewManager name to reduce the confusion but not sure whether this will be appreciated now. 
   I agree with all your points and double-checked the test. 
   I think we are ready to commit this one, thank you!




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Apr/21 12:42;githubbot;600","adelapena opened a new pull request #980:
URL: https://github.com/apache/cassandra/pull/980


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Apr/21 17:52;githubbot;600","adelapena opened a new pull request #981:
URL: https://github.com/apache/cassandra/pull/981


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Apr/21 17:52;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #980:
URL: https://github.com/apache/cassandra/pull/980#discussion_r618842591



##########
File path: src/java/org/apache/cassandra/db/view/View.java
##########
@@ -206,15 +206,20 @@ public ReadQuery getReadQuery()
 
     public synchronized void build()
     {
-        if (this.builder != null)

Review comment:
       I am not sure I understand correctly why you remove this check?

##########
File path: src/java/org/apache/cassandra/db/view/ViewBuilder.java
##########
@@ -209,4 +206,16 @@ public boolean isGlobal()
     {
         return false;
     }
+
+    public void waitForCompletion()

Review comment:
       I think this method can be `protected` and not `public`?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Apr/21 00:59;githubbot;600","adelapena commented on a change in pull request #980:
URL: https://github.com/apache/cassandra/pull/980#discussion_r619087948



##########
File path: src/java/org/apache/cassandra/db/view/View.java
##########
@@ -206,15 +206,20 @@ public ReadQuery getReadQuery()
 
     public synchronized void build()
     {
-        if (this.builder != null)

Review comment:
       The check is right below, in the `stopBuild()` method. I have just moved the entire `if` block to that separate method to be able to call it separately from `ColumnFamilyStore#truncateBlocking()` via `TableViews#stopBuild()`.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Apr/21 09:44;githubbot;600","adelapena commented on a change in pull request #980:
URL: https://github.com/apache/cassandra/pull/980#discussion_r619090676



##########
File path: src/java/org/apache/cassandra/db/view/ViewBuilder.java
##########
@@ -209,4 +206,16 @@ public boolean isGlobal()
     {
         return false;
     }
+
+    public void waitForCompletion()

Review comment:
       Right, it can even have default/package visibility since we don't extend the class. Done [here](https://github.com/apache/cassandra/pull/980/commits/0f0edd0bb916a9864a25f698187c53aab09891bf).




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Apr/21 09:48;githubbot;600","adelapena closed pull request #980:
URL: https://github.com/apache/cassandra/pull/980


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Apr/21 18:49;githubbot;600","adelapena closed pull request #967:
URL: https://github.com/apache/cassandra/pull/967


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Apr/21 18:49;githubbot;600","adelapena closed pull request #981:
URL: https://github.com/apache/cassandra/pull/981


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Apr/21 18:49;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,16800,,,0,16800,,,,,,,,,,,,,,,,,,,CASSANDRA-16972,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Sep 16 16:19:29 UTC 2021,,,,,,,All,,,,"0|z0plb4:",9223372036854775807,,,,e.dimitrova,,,,Normal,,3.0.0,,https://github.com/apache/cassandra/commit/ca40e770a5bbdeed69700ae498866f940782864b,,,,,,,,,The PR includes a new test that consistently creates the scenario that I think is making {{testCompoundPartitionKey}} fail in rare occasions.,,,,,"08/Apr/21 12:00;adelapena;I think that this test is not failing in regular cassandra-ci jobs, at leat [not recently|https://ci-cassandra.apache.org/job/Cassandra-trunk/416/testReport/org.apache.cassandra.cql3/ViewTest/].

I haven't been able to reproduce it locally with 2000 rounds. Our internal Jenkins-based multiplexer hasn't been able to reproduce it with 600 runs for the {{testCompoundPartitionKey}} method, nor with another 600 rounds for the entire {{ViewTest}} class.

Since we don't have an analogous multiplexer for ci-cassandra nor CircleCI, I have created [this ugly test|https://github.com/adelapena/cassandra/commit/d37ba480a0006cc1eeffa4c9f402f85bb7d0fae0] that just repeats {{testCompoundPartitionKey}} 100 times, so we can try to reproduce the failure on our CI envs. This test passes multiple times both locally and on ci-cassandra, whereas it relatively easily reproduces the investigated failure on CircleCI.

So it seems that by now this is looking like a CircleCI-only failure.;;;","14/Apr/21 14:09;adelapena;I think that the failure happens because the truncation of a table doesn't stop the asynchronous builders of its materialized views. As a result, it's possible that, after truncating a table, still running MV builders insert pre-truncate rows into the MV. The proposed PR simply makes sure to stop any ongoing MV builds when a table is truncated, [this way|https://github.com/apache/cassandra/pull/967/commits/3e3a6fd699c819c3642a810074f5fcbe174cda64]. Also, the PR adds [a simple test|https://github.com/apache/cassandra/pull/967/commits/c5eea8d0311c9aba8e223072cd600a87c86dec6d] reproducing the problematic scenario more consistently than {{testCompoundPartitionKey}}.

Also, although it's not related to the failure, I've noticed that {{ViewTest}} still uses {{ProtocolVersion.V4}} instead of the current one. I think this is not intentional so I've also [changed|https://github.com/apache/cassandra/pull/967/commits/f30007a990b16e5f9c1c151051c1a21ccb689030] the test to use {{CQLTester.getDefaultVersion}} instead.

CI runs:
 * [CircleCI j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/269/workflows/9e5b7540-b8aa-4ecb-97e7-476f88c01a59]
 * [CircleCI j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/269/workflows/50b4e9c0-151e-42fe-84a3-7953030637b2]
 * [Jenkins|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/653/pipeline]
 * [Internal multiplexer|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/788/];;;","22/Apr/21 12:49;e.dimitrova;The latest version LGTM, +1. Thank you! Also, CASSANDRA-16613 was opened and I am already fixing other places where we need to consider the new protocol version, too. Fortunately, for now I think we had that only in some tests and testing with V5 didn't produce any failures to the tests I worked on up to now.
I will post a patch later today;;;","22/Apr/21 18:04;adelapena;CI for the three branches:

 3.0
 * [CircleCI|https://app.circleci.com/pipelines/github/adelapena/cassandra/284/workflows/ab3142b3-e135-4561-bca6-a3b4c52aa58c]
 * [ci-cassandra|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/698/pipeline]

3.11
 * [CircleCI|https://app.circleci.com/pipelines/github/adelapena/cassandra/283/workflows/8f6ee0f9-8f0f-456b-a522-c48b5d191808]
 * [ci-cassandra|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/696/pipeline]

trunk
 * [CircleCI j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/285/workflows/ca47738e-cffb-4fe6-998c-d9759452d7dd]
 * [CircleCI j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/285/workflows/81c42289-2620-4f2a-b5e5-227dd11c5c7d]
 * [ci-cassandra|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/697/pipeline]

The most notable differences between 3.0/3.11 and trunk are that only trunk has the parallelized MV builder introduced by CASSANDRA-12245, and that 3.0/3.11 don't wait for the finalization of the builders when stopping them. The latter is necessary when truncating a table, so I have added a small mechanism to allow waiting for it.;;;","23/Apr/21 14:47;e.dimitrova;+1

The failing tests don't seem related.

I am curious why the dtests jars are failing again on 3.0 and 3.11 as they were fixed and your branches seem rebased but that is topic for another conversation, not related to this patch.;;;","23/Apr/21 18:47;adelapena;I also think that those are not related. It seems that the CI builds for 3.0 and 3.11 have been failing lately, we'll have to look into that.

Committed to 3.0 as [ca40e770a5bbdeed69700ae498866f940782864b|https://github.com/apache/cassandra/commit/ca40e770a5bbdeed69700ae498866f940782864b] and merged up to [3.11|https://github.com/apache/cassandra/commit/d9cdf2d6d95d0f19b12af68d21f7beee22b43264] and [trunk|https://github.com/apache/cassandra/commit/2c11dfcb5bc2dc25390a4b312911b8401d4a46e6].

Thanks for the review.;;;","16/Sep/21 16:19;e.dimitrova;-Unfortunately, I just found it failing in Jenkins [here|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1119/testReport/junit/org.apache.cassandra.cql3/ViewTest/testTruncateWhileBuilding/]-

-I can open a new ticket or we can reopen this one.- 

Wrong ticket sorry. Please ignore;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"When behind a firewall trunk is not buildable, need to allow overriding URLs",CASSANDRA-16563,13369836,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,dcapwell,dcapwell,dcapwell,06/Apr/21 17:03,16/Mar/22 15:40,13/Jul/23 08:40,07/Apr/21 18:15,4.0,4.0-rc1,,,,,,Build,CI,,,0,,,"When building behind a firewall which doesn’t allow external sites the build is no longer able to build; this is caused by 7 <get> tags in the build doing custom resolution. To work around this we should allow these paths to be overridable to allow building behind a firewall",,dcapwell,jmeredithco,mck,,,,,,,,,,,,,"dcapwell opened a new pull request #953:
URL: https://github.com/apache/cassandra/pull/953


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;06/Apr/21 17:19;githubbot;600","michaelsembwever commented on a change in pull request #953:
URL: https://github.com/apache/cassandra/pull/953#discussion_r608422692



##########
File path: .build/build-resolver.xml
##########
@@ -67,44 +73,69 @@
             <remoterepo id=""resolver-apache"" url=""${artifact.remoteRepository.apache}""/>
         </resolver:remoterepos>
 
-        <resolver:resolve>
-            <remoterepos refid=""all""/>
+        <!-- resolve doesn't really retry, so need to explicitly add extra retries to get stable -->
+        <macrodef name=""resolve"">
+            <!--
+              Address retries and defaults repos while setting up a resolver:resolve block
+            -->
+            <attribute name=""failonmissingattachments"" default=""true""/>
+            <element name=""elements"" implicit=""yes""/>
+            <sequential>
+                <retry retrycount=""3"">

Review comment:
       i like it! This is going to strength CI too where I've seen a download fail… 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;07/Apr/21 07:52;githubbot;600","michaelsembwever commented on a change in pull request #953:
URL: https://github.com/apache/cassandra/pull/953#discussion_r608422692



##########
File path: .build/build-resolver.xml
##########
@@ -67,44 +73,69 @@
             <remoterepo id=""resolver-apache"" url=""${artifact.remoteRepository.apache}""/>
         </resolver:remoterepos>
 
-        <resolver:resolve>
-            <remoterepos refid=""all""/>
+        <!-- resolve doesn't really retry, so need to explicitly add extra retries to get stable -->
+        <macrodef name=""resolve"">
+            <!--
+              Address retries and defaults repos while setting up a resolver:resolve block
+            -->
+            <attribute name=""failonmissingattachments"" default=""true""/>
+            <element name=""elements"" implicit=""yes""/>
+            <sequential>
+                <retry retrycount=""3"">

Review comment:
       i like it! This is going to strength CI too where I've seen downloads often fail… 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;07/Apr/21 08:02;githubbot;600","michaelsembwever commented on a change in pull request #953:
URL: https://github.com/apache/cassandra/pull/953#discussion_r608422692



##########
File path: .build/build-resolver.xml
##########
@@ -67,44 +73,69 @@
             <remoterepo id=""resolver-apache"" url=""${artifact.remoteRepository.apache}""/>
         </resolver:remoterepos>
 
-        <resolver:resolve>
-            <remoterepos refid=""all""/>
+        <!-- resolve doesn't really retry, so need to explicitly add extra retries to get stable -->
+        <macrodef name=""resolve"">
+            <!--
+              Address retries and defaults repos while setting up a resolver:resolve block
+            -->
+            <attribute name=""failonmissingattachments"" default=""true""/>
+            <element name=""elements"" implicit=""yes""/>
+            <sequential>
+                <retry retrycount=""3"">

Review comment:
       i like it! This is going to strengthen CI too where I've seen downloads often fail… 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;07/Apr/21 08:05;githubbot;600","dcapwell commented on a change in pull request #953:
URL: https://github.com/apache/cassandra/pull/953#discussion_r608866013



##########
File path: .build/build-resolver.xml
##########
@@ -30,8 +30,14 @@
         <available file=""${resolver-ant-tasks.local}"" />
     </condition>
 
-    <!-- version of lib/ downloads -->
+    <property name=""artifact.python.pypi"" value=""https://files.pythonhosted.org/packages"" />
+    <property name=""artifact.github.release"" value=""https://github.com"" />
+
+    <!-- some artifacts are fetched from github as blobs; these are all in the cassandra project, but in an older commit -->
     <property name=""lib.download.sha"" value=""1371883db3d8bf7d7c54e0baaca89c6c2d2a5abe""/>
+    <property name=""lib.download.address"" value=""raw.githubusercontent.com"" />

Review comment:
       I forgot to remove this, will drop before merge




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;07/Apr/21 17:46;githubbot;600","smiklosovic closed pull request #953:
URL: https://github.com/apache/cassandra/pull/953


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:40;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,3600,,,0,3600,,,,,,,,,,,,,CASSANDRA-16391,,,,,,,,,,,,,,,,,,,,,,,,,0.0,dcapwell,,,,,,,,,,,,,Availability -> Unavailable,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Apr 07 17:55:14 UTC 2021,,,,,,,All,,,,"0|z0pkrs:",9223372036854775807,,,,brandon.williams,jmeredithco,mck,,Critical,,4.0-rc1,,https://github.com/apache/cassandra/commit/93ffd111a429cb45b2360e4004812e9d2bf6866e,,,,,,,,,Testing behind a firewall,,,,,"07/Apr/21 08:26;mck;
[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/591/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/591/pipeline];;;","07/Apr/21 12:45;mck;+1;;;","07/Apr/21 17:55;jmeredithco;+1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update IDE and Eclipse classpaths for tests (after migration to resolver-ant-tasks),CASSANDRA-16560,13369557,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,mck,mck,05/Apr/21 09:27,27/Jun/21 09:26,13/Jul/23 08:40,08/Apr/21 09:15,4.0,4.0-rc1,,,,,,Build,,,,0,,,CASSANDRA-16391 broke being able to compile the project in IDE (and Eclipse?) as the test dependency jar files are no longer placed under {{build/lib/jar/}}. They are now found under {{build/test/lib/jar/}}.,,bereng,e.dimitrova,mck,yifanc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16391,,CASSANDRA-16557,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,mck,,,,,,,,,,,,Availability -> Unavailable,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Apr 08 09:15:26 UTC 2021,,,,,,,All,,,,"0|z0pj1s:",9223372036854775807,,,,bereng,e.dimitrova,mck,,Critical,,4.0-rc1,,https://github.com/apache/cassandra/commit/c65500e8a1213f194531bbfc77f37f0d7bf270df,,,,,,,,,manual,,,,,"05/Apr/21 09:31;mck;Attempt at a patch in https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/16560/trunk ;;;","05/Apr/21 13:53;e.dimitrova;I tried to run a unit test after compiling from that branch and I get in Idea:

java: package org.junit does not exist

I will try to look at what is going on, not familiar with all the work you do but I will give it a shot and I might ask you questions;;;","07/Apr/21 05:11;bereng;It is in fact impossible to even open the project in Eclipse and the attached fix is not working for me.

{noformat}
ant generate-eclipse-files

BUILD FAILED
/tmp/test/build.xml:2161: java.lang.ClassNotFoundException: org.apache.commons.io.FilenameUtils.getBaseName
	at jdk.nashorn.internal.runtime.NativeJavaPackage.classNotFound(NativeJavaPackage.java:162)
	at jdk.nashorn.internal.scripts.Script$7$\^eval\_.:program(<eval>:8)
	at jdk.nashorn.internal.runtime.ScriptFunctionData.invoke(ScriptFunctionData.java:637)
	at jdk.nashorn.internal.runtime.ScriptFunction.invoke(ScriptFunction.java:494)
	at jdk.nashorn.internal.runtime.ScriptRuntime.apply(ScriptRuntime.java:393)
	at jdk.nashorn.api.scripting.NashornScriptEngine.evalImpl(NashornScriptEngine.java:449)
	at jdk.nashorn.api.scripting.NashornScriptEngine.evalImpl(NashornScriptEngine.java:406)
	at jdk.nashorn.api.scripting.NashornScriptEngine.evalImpl(NashornScriptEngine.java:402)
	at jdk.nashorn.api.scripting.NashornScriptEngine.eval(NashornScriptEngine.java:155)
	at javax.script.AbstractScriptEngine.eval(AbstractScriptEngine.java:264)
	at org.apache.tools.ant.util.optional.JavaxScriptRunner.evaluateScript(JavaxScriptRunner.java:150)
	at org.apache.tools.ant.util.optional.JavaxScriptRunner.executeScript(JavaxScriptRunner.java:82)
	at org.apache.tools.ant.taskdefs.optional.Script.execute(Script.java:53)
	at org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:292)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.tools.ant.dispatch.DispatchUtils.execute(DispatchUtils.java:99)
	at org.apache.tools.ant.Task.perform(Task.java:350)
	at org.apache.tools.ant.Target.execute(Target.java:449)
	at org.apache.tools.ant.Target.performTasks(Target.java:470)
	at org.apache.tools.ant.Project.executeSortedTargets(Project.java:1391)
	at org.apache.tools.ant.Project.executeTarget(Project.java:1364)
	at org.apache.tools.ant.helper.DefaultExecutor.executeTargets(DefaultExecutor.java:41)
	at org.apache.tools.ant.Project.executeTargets(Project.java:1254)
	at org.apache.tools.ant.Main.runBuild(Main.java:830)
	at org.apache.tools.ant.Main.startAnt(Main.java:223)
	at org.apache.tools.ant.launch.Launcher.run(Launcher.java:284)
	at org.apache.tools.ant.launch.Launcher.main(Launcher.java:101)
{noformat};;;","07/Apr/21 06:04;bereng;Seems this solves the first hurdle

{noformat}
-       <script language=""javascript"" classpathref=""cassandra.classpath""> <![CDATA[
+       <script language=""javascript"">
+<classpath>
+<path refid=""cassandra.classpath""/>
+<path refid=""cassandra.classpath.test""/>
+</classpath>
{noformat};;;","07/Apr/21 07:12;bereng;Generating eclipse files working

{noformat}
diff --git a/build.xml b/build.xml
index 15f3219122..cb5b207b1e 100644
--- a/build.xml
+++ b/build.xml
@@ -2156,9 +2156,17 @@
         <fileset dir=""build/lib/jars"">
            <include name=""**/*.jar"" />
         </fileset>
+        <fileset dir=""build/test/lib/jars"">
+           <include name=""**/*.jar"" />
+        </fileset>
        </path>
        <property name=""eclipse-project-libs"" refid=""eclipse-project-libs-path""/>
-       <script language=""javascript"" classpathref=""cassandra.classpath""> <![CDATA[
+       <script language=""javascript"">
+          <classpath>
+            <path refid=""cassandra.classpath""/>
+            <path refid=""cassandra.classpath.test""/>
+          </classpath>
+          <![CDATA[
                var File = java.io.File;
                var FilenameUtils = Packages.org.apache.commons.io.FilenameUtils;
                jars = project.getProperty(""eclipse-project-libs"").split(project.getProperty(""path.separator""));
@@ -2166,9 +2174,8 @@
                cp = """";
            for (i=0; i< jars.length; i++) {
               srcjar = FilenameUtils.getBaseName(jars[i]) + '-sources.jar';
-                  srcdir = FilenameUtils.concat(project.getProperty(""build.dir.lib""), 'sources');
+                   srcdir = FilenameUtils.concat(project.getProperty(""build.test.dir""), 'sources');
                   srcfile = new File(FilenameUtils.concat(srcdir, srcjar));
-
                   cp += ' <classpathentry kind=""lib"" path=""' + jars[i] + '""';
                   if (srcfile.exists()) {
                      cp += ' sourcepath=""' + srcfile.getAbsolutePath() + '""';
{noformat};;;","07/Apr/21 09:15;bereng;Do you guys mind reviewing my patch and then we can at least commit the fix for eclipse?;;;","07/Apr/21 12:44;mck;[~bereng], I've added your changes to https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/16560/trunk

Could you test please? ;;;","07/Apr/21 13:01;bereng;I think [this|https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/16560/trunk#diff-766797f233c18114f9499750cf1ffbf3829aeea50283850619c01bd173132021R2169] line should be removed? Seems to work for me with that line removed.;;;","07/Apr/21 13:05;mck;bq. I think this line should be removed? Seems to work for me with that line removed.

done 👍;;;","07/Apr/21 15:54;e.dimitrova;Thanks to [~adelapena] I figured out issue with my IDE.

I can confirm that I can build in Intellij successfully with the latest patch.

For the record in case someone else is having issues as me:

Go check Project Structure -> Libraries and add your test jars there. I had broken stuff there to remove, now I have only the jars and everything works well. 

I am +1 on this one;;;","08/Apr/21 04:22;bereng;[~mck] your branch works for me generating eclipse files thx!;;;","08/Apr/21 09:15;mck;Committed as [c65500e8a1213f194531bbfc77f37f0d7bf270df|https://github.com/apache/cassandra/commit/c65500e8a1213f194531bbfc77f37f0d7bf270df].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Race between secondary index building and active compactions tracking,CASSANDRA-16554,13368972,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,yifanc,yifanc,yifanc,31/Mar/21 23:24,16/Mar/22 15:33,13/Jul/23 08:40,06/Apr/21 16:57,4.0,4.0-rc1,,,,,,Feature/2i Index,Local/Other,,,0,,,"There is a race condition between the secondary index build compaction task and the active compactions tracking, especially when incremental repair is running. 
It could result into 2 exceptions. 


{code:java}
Caused by: java.util.NoSuchElementException
	at org.apache.cassandra.utils.AbstractIterator.next(AbstractIterator.java:64)
	at org.apache.cassandra.io.sstable.ReducingKeyIterator.next(ReducingKeyIterator.java:117)
	at org.apache.cassandra.index.internal.CollatedViewIndexBuilder.build(CollatedViewIndexBuilder.java:74)
	at org.apache.cassandra.db.compaction.CompactionManager$14.run(CompactionManager.java:1688)
{code}


{code:java}
Caused by: java.io.EOFException
	at org.apache.cassandra.io.util.RebufferingInputStream.readByte(RebufferingInputStream.java:180)
	at org.apache.cassandra.utils.vint.VIntCoding.readUnsignedVInt(VIntCoding.java:68)
	at org.apache.cassandra.io.util.RebufferingInputStream.readUnsignedVInt(RebufferingInputStream.java:243)
	at org.apache.cassandra.db.RowIndexEntry$Serializer.readPosition(RowIndexEntry.java:364)
	at org.apache.cassandra.db.RowIndexEntry$Serializer.skip(RowIndexEntry.java:369)
	at org.apache.cassandra.io.sstable.KeyIterator.computeNext(KeyIterator.java:110)
{code}

In the first exception, the iterator returns true for the call of `hasNext`, but the following call of `next` throws. 
In the second exception, the file wrapper object returns false for the call of `isEOF`, but the following call that reads from it throws EOFException. 
The exceptions can be constantly reproduced by the test in the patch. 

The root cause of the exception is from the thread-unsafe lazy initialization found in `ReducingKeyIterator` and `KeyIterator`. When the `maybeInit` methods of both classes are called from multiple threads, it is likely to instantiate 2 instances and mess up the internal state. Those iterators might not be considered being used in a multiple thread environment when being added to the codebase initially. However, the `CollatedViewIndexBuilder` contains the reference to those 2 iterator, and it, as a `CompactionInfo.Holder`, is added to active compactions to be accessed from other threads, e.g. by calling `ActiveCompactions#getCompactionsForSSTable`. The implementation of `getCompactionInfo` in `CollatedViewIndexBuilder` publishes the reference to the `ReducingKeyIterator` and transitively `KeyIterator` to the other threads. Therefore, the other threads can possibly race. 

For the instance of NSEE, thread 1 calls the `hasNext` on the `ReducingKeyIterator`, it initialize the internal merge iterator. The call returns true. Right after, there is a thread 2 that calls `ActiveCompactions#getCompactionsForSSTable` and it sees the instance of `ReducingKeyIterator` is not initialized yet, so run `maybeInit` again. The reference of `iter` is replaced with the second instance. Now, thread 1 calls `next` using the new instance that does not has the correct state (expecting HAS_NEXT). So it again calls `hasNext`, which fetches the next element from the merged iterator. Those 2 `ReducingKeyIterator` share the same instances of `KeyIterator`. If the key iterators are already at the end, calling `hasNext` returns false and we get the NSEE. 

Besides the explicit NSEE exception, with the above reasoning, it is also possible to have the unexpected behavior that skips one item from the merge iterator. It leads to no 2i is built for that missing partition. Such case is totally hidden since no exception is ever thrown. 

To fix the unexpected behaviors, we need to correctly lazy initialize the iterators. 

Looking at the implementations of `CompactionInfo.Holder`, `ScrubInfo` and `VerifyInfo` also publishes the non-thread-safe `RandomAccessReader` when creating the compaction info object. According to the code inspection, there is a rare chance that a thread is calling `getFilePointer` from the file object and another thread closes the file, which can produce a NPE. When closing the file, the internal states, e.g. buffer is set to null. I did not add the fix in this patch, as it is never spotted. ",,adelapena,e.dimitrova,jmeredithco,yifanc,,,,,,,,,,,,"yifan-c opened a new pull request #946:
URL: https://github.com/apache/cassandra/pull/946


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Apr/21 00:36;githubbot;600","adelapena commented on a change in pull request #946:
URL: https://github.com/apache/cassandra/pull/946#discussion_r606654598



##########
File path: src/java/org/apache/cassandra/io/sstable/ReducingKeyIterator.java
##########
@@ -44,28 +44,34 @@ public ReducingKeyIterator(Collection<SSTableReader> sstables)
 
     private void maybeInit()
     {
-        if (mi == null)
+        if (mi != null)
+            return;
+
+        synchronized (this)
         {
-            mi = MergeIterator.get(iters, DecoratedKey.comparator, new MergeIterator.Reducer<DecoratedKey,DecoratedKey>()
+            if (mi == null)
             {
-                DecoratedKey reduced = null;
-
-                @Override
-                public boolean trivialReduceIsTrivial()
-                {
-                    return true;
-                }
-
-                public void reduce(int idx, DecoratedKey current)
-                {
-                    reduced = current;
-                }
-
-                protected DecoratedKey getReduced()
+                mi = MergeIterator.get(iters, DecoratedKey.comparator, new MergeIterator.Reducer<DecoratedKey,DecoratedKey>()

Review comment:
       Nit: missing whitespace
   ```suggestion
                   mi = MergeIterator.get(iters, DecoratedKey.comparator, new MergeIterator.Reducer<DecoratedKey, DecoratedKey>()
   ```
   ```suggestion
                   mi = MergeIterator.get(iters, DecoratedKey.comparator, new MergeIterator.Reducer<DecoratedKey,DecoratedKey>()
   ```

##########
File path: test/unit/org/apache/cassandra/db/compaction/ActiveCompactionsTest.java
##########
@@ -51,6 +58,50 @@
 
 public class ActiveCompactionsTest extends CQLTester
 {
+    @Test
+    public void testActiveCompactionTrackingRaceWithIndexBuilder() throws Throwable
+    {
+        createTable(""CREATE TABLE %s (pk int, ck int, a int, b int, PRIMARY KEY (pk, ck))"");
+        String idxName = createIndex(""CREATE INDEX on %s(a)"");
+        getCurrentColumnFamilyStore().disableAutoCompaction();
+        for (int i = 0; i < 5; i++)
+        {
+            execute(""INSERT INTO %s (pk, ck, a, b) VALUES (""+i+"", 2, 3, 4)"");

Review comment:
       Nit: missed whitespaces
   ```suggestion
               execute(""INSERT INTO %s (pk, ck, a, b) VALUES ("" + i + "", 2, 3, 4)"");
   ```
   ```suggestion
               execute(""INSERT INTO %s (pk, ck, a, b) VALUES (""+i+"", 2, 3, 4)"");
   ```

##########
File path: src/java/org/apache/cassandra/io/sstable/ReducingKeyIterator.java
##########
@@ -33,7 +33,7 @@
 public class ReducingKeyIterator implements CloseableIterator<DecoratedKey>
 {
     private final ArrayList<KeyIterator> iters;
-    private IMergeIterator<DecoratedKey,DecoratedKey> mi;
+    private volatile IMergeIterator<DecoratedKey,DecoratedKey> mi;

Review comment:
       Nit: missed whitespace
   ```suggestion
       private volatile IMergeIterator<DecoratedKey, DecoratedKey> mi;
   ```
   ```suggestion
       private volatile IMergeIterator<DecoratedKey,DecoratedKey> mi;
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Apr/21 12:13;githubbot;600","smiklosovic closed pull request #946:
URL: https://github.com/apache/cassandra/pull/946


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:33;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,yifanc,,,,,,,,,,,,,Correctness -> Recoverable Corruption / Loss,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 06 16:57:42 UTC 2021,,,,,,,All,,,,"0|z0pffs:",9223372036854775807,,,,adelapena,jmeredithco,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/a1285ac92ded45ab6e9f6c7c98917daf14a4a320,,,,,,,,,"unit test; ci",,,,,"01/Apr/21 00:37;yifanc;PR: https://github.com/apache/cassandra/pull/946
CI: https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=CASSANDRA-16554%2Ftrunk

The patch contains a test that reproduces the race condition, and the fix that lazy-initialize the iterators correctly. ;;;","01/Apr/21 16:53;yifanc;In case the description was not clear, the `CompactionInfo.Holder#getCompactionInfo` method can publish the non-thread-safe internal state to other threads, if the internal state is used in the method to create the compaction info. ;;;","01/Apr/21 17:08;jmeredithco;+1 thanks for diagnosing and getting it fixed.;;;","01/Apr/21 17:33;adelapena;Looks good to me too, it's a nice finding, +1 assuming CI looks good. 

Is there a ticket for the publication of {{RandomAccessReader}} by {{ScrubInfo}} and {{VerifyInfo}}?;;;","01/Apr/21 21:27;yifanc;bq. Is there a ticket for the publication of RandomAccessReader by ScrubInfo and VerifyInfo?

I have not created it. 

The PR (https://github.com/apache/cassandra/pull/946) fixes the lazy initialization. But the `CompactionInfo.Holder#getCompactionInfo` method still unsafely publish the internal state (e.g. RandomAccessReader) to the other threads, which I am not quite comfortable with. 

Here is an alternative patch that contains the necessary synchronization when access the RandomAccessReader in addition to the original patch. It also adds the lock for Scrubber and Verifier when closing the RandomAccessReader and creating compaction info objects. 
https://github.com/yifan-c/cassandra/tree/CASSANDRA-16554/trunk-2 
Please take a look if the alternative is preferred. ;;;","02/Apr/21 00:38;jmeredithco;The changes to Scurbber/Verifier look reasonable.

I'm a bit more worried about the {{KeyIterator}} change.  The {{computeNext}} method calls both {{isEOF}} and {{getFilePointer}} which both call {{maybeInit}} and then both synchronize, so this adds a bit.

As an alternative, could you replace {{in}} with an anonymous object on {{close()}} that's safe to call after {{close()}} without needing to synchronize?;;;","02/Apr/21 14:01;jmeredithco;Marked as 4.0-beta due to potential correctness issue.  The race flagged can cause keys to be skipped during iteration and omitted from the index, making them unsearchable.;;;","02/Apr/21 17:51;yifanc;Thank you. I updated the {{KeyIterator}} change to use the same read/write lock pattern used in {{Scrubber/Verifier}}.;;;","03/Apr/21 00:06;jmeredithco;The {{trunk-2}} branch looks good to me. +1.;;;","03/Apr/21 12:27;adelapena;The extended fix in {{trunk-2}} also looks to me. Perhaps we could add a comment about thread safety in {{RandomAccessReader}}, or marking it with {{@NotThreadSafe}}? Also it might be helpful to add a brief comment in {{KeyIterator::getTotalBytes}} about why we don't need to use the locks to use {{RandomAccessReader::length}}, wdyt?

I have found [these|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=CASSANDRA-16554%2Ftrunk-2] CircleCI rounds for the branch, could you please start the jobs for Python dtests, JVM upgrade dtests and j11 utests?;;;","05/Apr/21 06:26;yifanc;[~adelapena], ran the jobs as you suggested. There were 2 failures from the unit test suites. They do not seem to be related with the change. 
CI: https://app.circleci.com/pipelines/github/yifan-c/cassandra/225/workflows/3e26511b-d03a-4d01-a846-e739d3cc8fed;;;","05/Apr/21 10:58;adelapena;Great, thanks. Looks good to me, +1. I think we are ready to commit.;;;","05/Apr/21 17:30;yifanc;Starting commit

CI Results (pending):
|| Branch || Source || Circle CI || Jenkins ||
|trunk|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16554-trunk-38A075FB-7C9E-44C8-A992-BE94320FAB05]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16554-trunk-38A075FB-7C9E-44C8-A992-BE94320FAB05]|[build|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/581/pipeline]|;;;","05/Apr/21 21:11;yifanc;The Jenkins build has some test failures from {{StorageServiceServerTest}}, {{HintedHandoffAddRemoveNodesTest}}, {{AntiCompactionBytemanTest}}, etc. I am not able to reproduce the failures by rerunning locally. And the failures do not look related with the change. The failures from {{AntiCompactionBytemanTest}} are all connection reset.
[~adelapena], wdyt? ;;;","06/Apr/21 14:43;adelapena;[~yifanc] I haven't been able to reproduce {{StorageServiceServerTest}} locally nor with 400 runs in an internal test multiplexer, although {{#testLocalPrimaryRangeForEndpointWithNetworkTopologyStrategy}} seems to have been failing before on Jenkins. The failure in {{HintedHandoffAddRemoveNodesTest}} seems the one addressed by CASSANDRA-16495, and the failure in {{ScrubTest}} has just been solved by CASSANDRA-16532.

I also think that the failures are not related, so probably we are ready to go.;;;","06/Apr/21 16:57;yifanc;Thanks for checking! 
The patch is committed into trunk as [6115a02|https://github.com/apache/cassandra/commit/a1285ac92ded45ab6e9f6c7c98917daf14a4a320].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve LICENSE/NOTICE compliance with ASF guidance ,CASSANDRA-16550,13368765,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,benbromhead,benbromhead,benbromhead,31/Mar/21 03:52,04/May/21 08:32,13/Jul/23 08:40,31/Mar/21 19:17,4.0,4.0-rc1,,,,,,Dependencies,,,,0,,,"PRs on GitHub:

[https://github.com/apache/cassandra/pull/943]

[https://github.com/apache/cassandra/pull/944] 

 

A number of issues were identified with our LICENSE.txt and NOTICE.txt files (https://lists.apache.org/thread.html/r66496e495c96efeb31c6531eb748ec739bfb734d5c115077d925ebac%40%3Cdev.cassandra.apache.org%3E), specifically related to identifing bundled source and their respective licenses in accordance with ASF guidance ([https://infra.apache.org/licensing-howto.html]).

 

*LICENSE.txt*

We don't specifically identify the licenses of a number of bundled components included with the source distro of Apache Cassandra in our License file in accordance with ([https://infra.apache.org/licensing-howto.html]). Specifically:
 # src/java/org/apache/cassandra/index/sasi/utils/AbstractIterator.java
 # src/java/org/apache/cassandra/utils/LongTimSort.java
 # src/java/org/apache/cassandra/index/sasi/utils/trie/Cursor.java
 # test/resources/tokenization/adventures_of_huckleberry_finn_mark_twain.txt
 # content in doc/source/data_modeling/

Note: src/java/org/apache/cassandra/utils/vint/VIntCoding.java makes reference of borrowing ideas from Google Protocol Buffers.

I'm not sure if this is code, concepts or a reference to the concepts in the documentation for an understanding of the idea. I've included it as its a compatible licenses to be on the safe side.

I've also removed the reference to the lib/ folder as this license (as I understand) currently applies to the source release rather than convenience binaries.

 

*NOTICE.txt*

Removing references for dependencies that are not bundled (e.g. pulled in dynamically).

Bundled dep src/java/org/apache/cassandra/utils/LongTimSort.java uses ALv2 but is not owned by ASF so providing attribution.

 ",,aholmber,Anthony Grasso,benbromhead,jmclean,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16551,,,,CASSANDRA-16553,,,,,,,,,,,,,,,,,,,0.0,benbromhead,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Mar 31 19:17:54 UTC 2021,,,,,,,All,,,,"0|z0pe6g:",9223372036854775807,,,,brandon.williams,mck,,,Normal,,NA,,https://github.com/apache/cassandra/commit/d42087a63309178b96909c012dd0073fe0b6ea11,,,,,,,,,review,,,,,"31/Mar/21 04:17;jmclean;Looks good to me. For completeness you could also include a copy of the text of the BSD and CC0 licenses mentioned in LICENSE.

I also come across mention of creative commons licensed content in [1]. I think in this case it's OK but do note that the Creative Commons Attribution 4.0 is not actually compatible with the Apache License version 2 and you cannot include it in a source release. [2]

1. ./src/java/org/apache/cassandra/net/Crc.java
2. https://apache.org/legal/resolved.html#cc-by 
;;;","31/Mar/21 04:42;Anthony Grasso;[~benbromhead] thank you for tackling this and making the updates to LICENSE.txt and NOTICE.txt. I noticed two minor changes we should consider making in the LICENCE.txt pull request [#943|http://example.com/].;;;","31/Mar/21 05:47;benbromhead;Thanks [~Anthony Grasso], addressed. 

I think this can get merged and I can address [~jmclean]'s completeness comments in a seperate ticket.

Otherwise if the ticket is still open tomorrow I'll update here.;;;","31/Mar/21 16:22;brandon.williams;I am +1 on these PRs.;;;","31/Mar/21 16:30;mck;+1 on both PRs.

It would be good to follow this up with a doc update, that provides clear instructions on when and how these files are to be updated. As it is not common knowledge (unfortunately).;;;","31/Mar/21 16:48;brandon.williams;Created CASSANDRA-16551 for doc follow up, and committed these to trunk in the interest of time.  Versions for other branches _probably_ just need some things removed, but I'll leave this open for that.;;;","31/Mar/21 19:17;brandon.williams;Created CASSANDRA-16553 for backporting.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky testRecoverOverflowedExpirationWithSSTableScrub,CASSANDRA-16546,13368545,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,30/Mar/21 07:19,25/Apr/21 11:32,13/Jul/23 08:40,31/Mar/21 20:19,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"See [here|https://ci-cassandra.apache.org/job/Cassandra-trunk-test/627/jdk=jdk_11_latest,label=cassandra,split=4/testReport/junit/org.apache.cassandra.cql3.validation.operations/TTLTest/testRecoverOverflowedExpirationWithSSTableScrub/]",,adelapena,bereng,,,,,,,,,,,,,,"bereng opened a new pull request #945:
URL: https://github.com/apache/cassandra/pull/945


   …crub


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Mar/21 08:32;githubbot;600","bereng commented on a change in pull request #945:
URL: https://github.com/apache/cassandra/pull/945#discussion_r604700818



##########
File path: test/unit/org/apache/cassandra/cql3/validation/operations/TTLTest.java
##########
@@ -422,18 +422,29 @@ public void testRecoverOverflowedExpirationWithScrub(boolean simple, boolean clu
                 else
                     tool = ToolRunner.invokeClass(StandaloneScrubber.class, KEYSPACE, cfs.name);
 
+                tool.assertOnCleanExit();

Review comment:
       Moving it here bc on failure it gives info on error code and sdterr which clues on what is wrong. Otherwise you get an empty stdout which servers little purpose to debug.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Mar/21 08:34;githubbot;600","bereng commented on pull request #945:
URL: https://github.com/apache/cassandra/pull/945#issuecomment-810902820


   - CI [j8](https://app.circleci.com/pipelines/github/bereng/cassandra/242/workflows/3a55b0b6-76c4-4750-a317-00db07bb36e3/jobs/2478)
   - CI [j11](https://app.circleci.com/pipelines/github/bereng/cassandra/242/workflows/cab1075a-34b2-44ea-ac71-991e2f6e2f67/jobs/2480)


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Mar/21 09:01;githubbot;600","adelapena commented on a change in pull request #945:
URL: https://github.com/apache/cassandra/pull/945#discussion_r604850593



##########
File path: test/unit/org/apache/cassandra/cql3/validation/operations/TTLTest.java
##########
@@ -422,18 +422,29 @@ public void testRecoverOverflowedExpirationWithScrub(boolean simple, boolean clu
                 else
                     tool = ToolRunner.invokeClass(StandaloneScrubber.class, KEYSPACE, cfs.name);
 
+                tool.assertOnCleanExit();
                 Assertions.assertThat(tool.getStdout()).contains(""Pre-scrub sstables snapshotted into"");
                 if (reinsertOverflowedTTL)
                     Assertions.assertThat(tool.getStdout()).contains(""Fixed 2 rows with overflowed local deletion time."");
                 else
                     Assertions.assertThat(tool.getStdout()).contains(""Unable to recover 2 rows that were skipped."");
-                tool.assertOnCleanExit();
             }
             finally
             {
                 System.clearProperty(org.apache.cassandra.tools.Util.ALLOW_TOOL_REINIT_FOR_TEST);
             }
         }
+
+        try
+        {
+            dropTable(""DROP TABLE %s"");
+        }
+        catch(Throwable e)
+        {
+            // StandaloneScrubber.class should be ran as a tool with a stable env. In a test env there are things moving
+            // under it's feet such as the async CQLTester.afterTest() operations. We try to sync cleanup of tables here

Review comment:
       ```suggestion
               // under its feet such as the async CQLTester.afterTest() operations. We try to sync cleanup of tables here
   ```

##########
File path: test/unit/org/apache/cassandra/cql3/validation/operations/TTLTest.java
##########
@@ -422,18 +422,29 @@ public void testRecoverOverflowedExpirationWithScrub(boolean simple, boolean clu
                 else
                     tool = ToolRunner.invokeClass(StandaloneScrubber.class, KEYSPACE, cfs.name);
 
+                tool.assertOnCleanExit();

Review comment:
       Good idea

##########
File path: test/unit/org/apache/cassandra/cql3/validation/operations/TTLTest.java
##########
@@ -422,18 +422,29 @@ public void testRecoverOverflowedExpirationWithScrub(boolean simple, boolean clu
                 else
                     tool = ToolRunner.invokeClass(StandaloneScrubber.class, KEYSPACE, cfs.name);
 
+                tool.assertOnCleanExit();
                 Assertions.assertThat(tool.getStdout()).contains(""Pre-scrub sstables snapshotted into"");
                 if (reinsertOverflowedTTL)
                     Assertions.assertThat(tool.getStdout()).contains(""Fixed 2 rows with overflowed local deletion time."");
                 else
                     Assertions.assertThat(tool.getStdout()).contains(""Unable to recover 2 rows that were skipped."");
-                tool.assertOnCleanExit();
             }
             finally
             {
                 System.clearProperty(org.apache.cassandra.tools.Util.ALLOW_TOOL_REINIT_FOR_TEST);
             }
         }
+
+        try
+        {
+            dropTable(""DROP TABLE %s"");
+        }
+        catch(Throwable e)

Review comment:
       Super nit:
   ```suggestion
           catch (Throwable e)
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Mar/21 12:27;githubbot;600","bereng closed pull request #945:
URL: https://github.com/apache/cassandra/pull/945


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Apr/21 04:32;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,3000,,,0,3000,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Mar 31 20:16:41 UTC 2021,,,,,,,All,,,,"0|z0pctk:",9223372036854775807,,,,adelapena,,,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/a70253124681d006c865441b194d76d8e3058d64,,,,,,,,,See PR,,,,,"31/Mar/21 08:40;bereng;Difficult to repro either locally and won't repro on the multiplexer. I manged to do it on a slow virtual env and only seldom yet.

The problem was that the test class expects to be ran as a tool with a stable env under it's feet. On a test class there are other async things happening such as test method cleanup logic. We can see the failure was the tool being ran for a specific ks.cf but complaining on a different one i.e.

{noformat}
[junit-timeout] Testcase: testRecoverOverflowedExpirationWithSSTableScrub(org.apache.cassandra.cql3.validation.operations.TTLTest):     FAILED
[junit-timeout] [org.apache.cassandra.tools.StandaloneScrubber,
[junit-timeout]     cql_test_keyspace,
[junit-timeout]     table_39]
[junit-timeout] exited with code 1
[junit-timeout] stderr:
[junit-timeout] Columns not found in schema table for cql_test_keyspace.table_26
[junit-timeout]
[junit-timeout] stdout:
[junit-timeout]
[junit-timeout] junit.framework.AssertionFailedError: [org.apache.cassandra.tools.StandaloneScrubber,
[junit-timeout]     cql_test_keyspace,
[junit-timeout]     table_39]
[junit-timeout] exited with code 1
[junit-timeout] stderr:
[junit-timeout] Columns not found in schema table for cql_test_keyspace.table_26
{noformat}

This came from the tool loading schema on startup from disk

{noformat}
ERROR [main] 2021-03-31 09:26:18,340 cql_test_keyspace:table_24 not found in the schema definitions keyspace.
java.lang.Exception: null
        at org.apache.cassandra.schema.SchemaKeyspace.fetchTable(SchemaKeyspace.java:956)
        at org.apache.cassandra.schema.SchemaKeyspace.fetchTables(SchemaKeyspace.java:921)
        at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspace(SchemaKeyspace.java:880)
        at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspacesWithout(SchemaKeyspace.java:871)
        at org.apache.cassandra.schema.SchemaKeyspace.fetchNonSystemKeyspaces(SchemaKeyspace.java:859)
        at org.apache.cassandra.schema.Schema.loadFromDisk(Schema.java:101)
        at org.apache.cassandra.tools.StandaloneScrubber.main(StandaloneScrubber.java:88)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.cassandra.tools.ToolRunner.runClassAsTool(ToolRunner.java:82)
        at org.apache.cassandra.tools.ToolRunner$2.get(ToolRunner.java:249)
        at org.apache.cassandra.tools.ToolRunner$2.get(ToolRunner.java:245)
        at org.apache.cassandra.tools.ToolRunner.invokeSupplier(ToolRunner.java:305)
        at org.apache.cassandra.tools.ToolRunner.invokeClass(ToolRunner.java:253)
        at org.apache.cassandra.tools.ToolRunner.invokeClass(ToolRunner.java:235)
        at org.apache.cassandra.cql3.validation.operations.TTLTest.testRecoverOverflowedExpirationWithScrub(TTLTest.java:424)
        at org.apache.cassandra.cql3.validation.operations.TTLTest.baseTestRecoverOverflowedExpiration(TTLTest.java:304)
        at org.apache.cassandra.cql3.validation.operations.TTLTest.testRecoverOverflowedExpirationWithSSTableScrub(TTLTest.java:227)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
        at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:38)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:534)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1196)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:1041)
{noformat}

The proposed solution is to force drop tables in-between such tests and it doesn't repro anymore.;;;","31/Mar/21 10:36;bereng;CI looks ok and 200 runs on the private multiplexer passed.;;;","31/Mar/21 12:31;adelapena;Looks good to me, +1. I had previously managed to reproduce the problem in the private multiplexer ([here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/751/]). I have run it 400 extra times with the proposed fix and it doesn't reproduce anymore.;;;","31/Mar/21 12:36;adelapena;ci-cassandra running [here|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/542/pipeline], I think that it it looks good we'll be ready to commit.;;;","31/Mar/21 12:59;bereng;Ahhhh it's super good you managed to repro. I pushed and squashed the typo/extra space you lynxed eyed reviewer!;;;","31/Mar/21 20:16;adelapena;Great, thanks, committed to trunk as [a70253124681d006c865441b194d76d8e3058d64|https://github.com/apache/cassandra/commit/a70253124681d006c865441b194d76d8e3058d64].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cluster topology change may produce false unavailable for queries,CASSANDRA-16545,13368477,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,yifanc,yifanc,yifanc,29/Mar/21 23:09,16/Mar/22 15:37,13/Jul/23 08:40,15/Apr/21 15:56,4.0,4.0-rc1,,,,,,Consistency/Coordination,,,,0,,,"When the coordinator processes a query, it first gets the {{ReplicationStrategy}} (RS) from the keyspace to decide the peers to contact. Again, it gets the RS to perform the liveness check for the requested CL. 

The RS is a volatile filed in Keyspace, and it is possible that those 2 getter calls return different RS values in the presence of cluster topology changes, e.g. add a node, etc. 

In such scenario, the check at the second step can throw an unexpected unavailable. From the perspective of the query, the cluster can satisfy the CL. 

We should use a consistent view of RS during the peer selection and CL liveness check. In other word, both steps should reference to the same RS object. It is also more clear and easier to reason about to the clients. Such queries are made before the topology change. ",,adelapena,aleksey,mck,yifanc,,,,,,,,,,,,"yifan-c opened a new pull request #954:
URL: https://github.com/apache/cassandra/pull/954


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;06/Apr/21 21:41;githubbot;600","adelapena commented on a change in pull request #954:
URL: https://github.com/apache/cassandra/pull/954#discussion_r609747844



##########
File path: src/java/org/apache/cassandra/db/ConsistencyLevel.java
##########
@@ -189,9 +188,9 @@ public int blockForWrite(Keyspace keyspace, Endpoints<?> pending)
      * Determine if this consistency level meets or exceeds the consistency requirements of the given cl for the given keyspace
      * WARNING: this is not locality aware; you cannot safely use this with mixed locality consistency levels (e.g. LOCAL_QUORUM and QUORUM)
      */
-    public boolean satisfies(ConsistencyLevel other, Keyspace keyspace)
+    public boolean satisfies(ConsistencyLevel other, AbstractReplicationStrategy replicationStrategy)

Review comment:
       Maybe we could also pass `AbstractReplicationStrategy` instead of keyspace name to `validateForCasCommit` and `requiereNetworkTopologyStrategy`?

##########
File path: src/java/org/apache/cassandra/locator/ReplicaPlan.java
##########
@@ -92,14 +98,14 @@ public String toString()
 
     public static class ForTokenRead extends ForRead<EndpointsForToken>
     {
-        public ForTokenRead(Keyspace keyspace, ConsistencyLevel consistencyLevel, EndpointsForToken candidates, EndpointsForToken contact)
+        public ForTokenRead(Keyspace keyspace, AbstractReplicationStrategy replicationStrategy, ConsistencyLevel consistencyLevel, EndpointsForToken candidates, EndpointsForToken contacts)

Review comment:
       Nit: the list of arguments in the constructors is starting to be quite long, perhaps we could break it
   ```suggestion
           public ForTokenRead(Keyspace keyspace,
                               AbstractReplicationStrategy replicationStrategy,
                               ConsistencyLevel consistencyLevel,
                               EndpointsForToken candidates,
                               EndpointsForToken contacts)
   ```

##########
File path: test/unit/org/apache/cassandra/locator/AssureSufficientLiveNodesTest.java
##########
@@ -0,0 +1,317 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.locator;
+
+import java.util.Arrays;
+import java.util.List;
+import java.util.UUID;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.function.Consumer;
+import java.util.function.Supplier;
+
+import com.google.common.collect.ImmutableList;
+import com.google.common.util.concurrent.Uninterruptibles;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import org.apache.cassandra.SchemaLoader;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.dht.Murmur3Partitioner;
+import org.apache.cassandra.dht.Token;
+import org.apache.cassandra.exceptions.UnavailableException;
+import org.apache.cassandra.schema.KeyspaceMetadata;
+import org.apache.cassandra.schema.KeyspaceParams;
+import org.apache.cassandra.schema.MigrationManager;
+import org.apache.cassandra.schema.Tables;
+import org.apache.cassandra.service.StorageService;
+import org.apache.cassandra.service.reads.NeverSpeculativeRetryPolicy;
+import org.apache.cassandra.utils.FBUtilities;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
+
+import static org.apache.cassandra.db.ConsistencyLevel.EACH_QUORUM;
+import static org.apache.cassandra.db.ConsistencyLevel.LOCAL_QUORUM;
+import static org.apache.cassandra.db.ConsistencyLevel.QUORUM;
+import static org.assertj.core.api.Assertions.assertThatThrownBy;
+
+@RunWith(BMUnitRunner.class)

Review comment:
       Nit: Could we add a brief description and reference to the JIRA ticket?

##########
File path: test/unit/org/apache/cassandra/locator/AssureSufficientLiveNodesTest.java
##########
@@ -0,0 +1,317 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.locator;
+
+import java.util.Arrays;
+import java.util.List;
+import java.util.UUID;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.function.Consumer;
+import java.util.function.Supplier;
+
+import com.google.common.collect.ImmutableList;
+import com.google.common.util.concurrent.Uninterruptibles;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import org.apache.cassandra.SchemaLoader;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.dht.Murmur3Partitioner;
+import org.apache.cassandra.dht.Token;
+import org.apache.cassandra.exceptions.UnavailableException;
+import org.apache.cassandra.schema.KeyspaceMetadata;
+import org.apache.cassandra.schema.KeyspaceParams;
+import org.apache.cassandra.schema.MigrationManager;
+import org.apache.cassandra.schema.Tables;
+import org.apache.cassandra.service.StorageService;
+import org.apache.cassandra.service.reads.NeverSpeculativeRetryPolicy;
+import org.apache.cassandra.utils.FBUtilities;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
+
+import static org.apache.cassandra.db.ConsistencyLevel.EACH_QUORUM;
+import static org.apache.cassandra.db.ConsistencyLevel.LOCAL_QUORUM;
+import static org.apache.cassandra.db.ConsistencyLevel.QUORUM;
+import static org.assertj.core.api.Assertions.assertThatThrownBy;
+
+@RunWith(BMUnitRunner.class)
+@BMRule(name = ""FailureDecector sees all nodes as live"", // applies to all test cases in the class
+        targetClass = ""FailureDetector"",
+        targetMethod = ""isAlive"",
+        action = ""return true;"")
+public class AssureSufficientLiveNodesTest
+{
+    private static final AtomicInteger testIdGen = new AtomicInteger(0);
+    private static final Supplier<String> keyspaceNameGen = () -> ""race_"" + testIdGen.getAndIncrement();
+    private static final String DC1 = ""datacenter1"";
+    private static final String DC2 = ""datacenter2"";
+    private static final String DC3 = ""datacenter3"";
+    private static final int RACE_TEST_LOOPS = 100;
+    private static final Token tk = new Murmur3Partitioner.LongToken(0);
+
+    @BeforeClass
+    public static void setUpClass() throws Throwable
+    {
+        SchemaLoader.loadSchema();
+        // Register peers with expected DC for NetworkTopologyStrategy.
+        TokenMetadata metadata = StorageService.instance.getTokenMetadata();
+        metadata.clearUnsafe();
+
+        DatabaseDescriptor.setEndpointSnitch(new AbstractNetworkTopologySnitch()
+        {
+            public String getRack(InetAddressAndPort endpoint)
+            {
+                byte[] address = endpoint.addressBytes;
+                return ""rake"" + address[1];
+            }
+
+            public String getDatacenter(InetAddressAndPort endpoint)
+            {
+                byte[] address = endpoint.addressBytes;
+                return ""datacenter"" + address[1];
+            }
+        });
+
+        List<InetAddressAndPort> instances = ImmutableList.of(
+            // datacenter 1
+            InetAddressAndPort.getByName(""127.1.0.255""), InetAddressAndPort.getByName(""127.1.0.254""), InetAddressAndPort.getByName(""127.1.0.253""),
+            // datacenter 2
+            InetAddressAndPort.getByName(""127.2.0.255""), InetAddressAndPort.getByName(""127.2.0.254""), InetAddressAndPort.getByName(""127.2.0.253""),
+            // datacenter 3
+            InetAddressAndPort.getByName(""127.3.0.255""), InetAddressAndPort.getByName(""127.3.0.254""), InetAddressAndPort.getByName(""127.3.0.253""));
+
+        for (int i = 0; i < instances.size(); i++)
+        {
+            InetAddressAndPort ip = instances.get(i);
+            metadata.updateHostId(UUID.randomUUID(), ip);
+            metadata.updateNormalToken(new Murmur3Partitioner.LongToken(i), ip);
+        }
+    }
+
+    @Test
+    public void insufficientLiveNodesTest()
+    {
+        final KeyspaceParams largeRF = KeyspaceParams.nts(""datacenter1"", 6);
+        // Not a race in fact. It is just testing the Unavailable can be correctly thrown.
+        assertThatThrownBy(() -> {
+            raceOfReplicationStrategyTest(largeRF, largeRF, 1,
+                                          keyspace -> ReplicaPlans.forWrite(keyspace, QUORUM, tk, ReplicaPlans.writeNormal));
+        }).as(""Unavailable should be thrown given 3 live nodes is less than a quorum of 6"")
+          .isInstanceOf(UnavailableException.class)
+          .hasMessageContaining(""Cannot achieve consistency level QUORUM"");
+    }
+
+    @Test
+    public void addDatacenterShouldNotCausesUnavailableWithEachQuorumTest() throws Throwable
+    {
+        // write
+        raceOfReplicationStrategyTest(
+            // init
+            KeyspaceParams.nts(DC1, 3),
+            // alter to
+            KeyspaceParams.nts(DC1, 3, DC2, 3),
+            // test
+            keyspace -> {
+                ReplicaPlans.forWrite(keyspace, EACH_QUORUM, tk, ReplicaPlans.writeNormal);
+            }

Review comment:
       Nit: we don't need the braces
   ```suggestion
               keyspace -> ReplicaPlans.forWrite(keyspace, EACH_QUORUM, tk, ReplicaPlans.writeNormal)
   ```

##########
File path: test/unit/org/apache/cassandra/locator/AssureSufficientLiveNodesTest.java
##########
@@ -0,0 +1,317 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.locator;
+
+import java.util.Arrays;
+import java.util.List;
+import java.util.UUID;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.function.Consumer;
+import java.util.function.Supplier;
+
+import com.google.common.collect.ImmutableList;
+import com.google.common.util.concurrent.Uninterruptibles;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import org.apache.cassandra.SchemaLoader;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.dht.Murmur3Partitioner;
+import org.apache.cassandra.dht.Token;
+import org.apache.cassandra.exceptions.UnavailableException;
+import org.apache.cassandra.schema.KeyspaceMetadata;
+import org.apache.cassandra.schema.KeyspaceParams;
+import org.apache.cassandra.schema.MigrationManager;
+import org.apache.cassandra.schema.Tables;
+import org.apache.cassandra.service.StorageService;
+import org.apache.cassandra.service.reads.NeverSpeculativeRetryPolicy;
+import org.apache.cassandra.utils.FBUtilities;
+import org.jboss.byteman.contrib.bmunit.BMRule;
+import org.jboss.byteman.contrib.bmunit.BMUnitRunner;
+
+import static org.apache.cassandra.db.ConsistencyLevel.EACH_QUORUM;
+import static org.apache.cassandra.db.ConsistencyLevel.LOCAL_QUORUM;
+import static org.apache.cassandra.db.ConsistencyLevel.QUORUM;
+import static org.assertj.core.api.Assertions.assertThatThrownBy;
+
+@RunWith(BMUnitRunner.class)
+@BMRule(name = ""FailureDecector sees all nodes as live"", // applies to all test cases in the class
+        targetClass = ""FailureDetector"",
+        targetMethod = ""isAlive"",
+        action = ""return true;"")
+public class AssureSufficientLiveNodesTest
+{
+    private static final AtomicInteger testIdGen = new AtomicInteger(0);
+    private static final Supplier<String> keyspaceNameGen = () -> ""race_"" + testIdGen.getAndIncrement();
+    private static final String DC1 = ""datacenter1"";
+    private static final String DC2 = ""datacenter2"";
+    private static final String DC3 = ""datacenter3"";
+    private static final int RACE_TEST_LOOPS = 100;
+    private static final Token tk = new Murmur3Partitioner.LongToken(0);
+
+    @BeforeClass
+    public static void setUpClass() throws Throwable
+    {
+        SchemaLoader.loadSchema();
+        // Register peers with expected DC for NetworkTopologyStrategy.
+        TokenMetadata metadata = StorageService.instance.getTokenMetadata();
+        metadata.clearUnsafe();
+
+        DatabaseDescriptor.setEndpointSnitch(new AbstractNetworkTopologySnitch()
+        {
+            public String getRack(InetAddressAndPort endpoint)
+            {
+                byte[] address = endpoint.addressBytes;
+                return ""rake"" + address[1];
+            }
+
+            public String getDatacenter(InetAddressAndPort endpoint)
+            {
+                byte[] address = endpoint.addressBytes;
+                return ""datacenter"" + address[1];
+            }
+        });
+
+        List<InetAddressAndPort> instances = ImmutableList.of(
+            // datacenter 1
+            InetAddressAndPort.getByName(""127.1.0.255""), InetAddressAndPort.getByName(""127.1.0.254""), InetAddressAndPort.getByName(""127.1.0.253""),
+            // datacenter 2
+            InetAddressAndPort.getByName(""127.2.0.255""), InetAddressAndPort.getByName(""127.2.0.254""), InetAddressAndPort.getByName(""127.2.0.253""),
+            // datacenter 3
+            InetAddressAndPort.getByName(""127.3.0.255""), InetAddressAndPort.getByName(""127.3.0.254""), InetAddressAndPort.getByName(""127.3.0.253""));
+
+        for (int i = 0; i < instances.size(); i++)
+        {
+            InetAddressAndPort ip = instances.get(i);
+            metadata.updateHostId(UUID.randomUUID(), ip);
+            metadata.updateNormalToken(new Murmur3Partitioner.LongToken(i), ip);
+        }
+    }
+
+    @Test
+    public void insufficientLiveNodesTest()
+    {
+        final KeyspaceParams largeRF = KeyspaceParams.nts(""datacenter1"", 6);
+        // Not a race in fact. It is just testing the Unavailable can be correctly thrown.
+        assertThatThrownBy(() -> {
+            raceOfReplicationStrategyTest(largeRF, largeRF, 1,
+                                          keyspace -> ReplicaPlans.forWrite(keyspace, QUORUM, tk, ReplicaPlans.writeNormal));
+        }).as(""Unavailable should be thrown given 3 live nodes is less than a quorum of 6"")
+          .isInstanceOf(UnavailableException.class)
+          .hasMessageContaining(""Cannot achieve consistency level QUORUM"");
+    }
+
+    @Test
+    public void addDatacenterShouldNotCausesUnavailableWithEachQuorumTest() throws Throwable
+    {
+        // write
+        raceOfReplicationStrategyTest(
+            // init
+            KeyspaceParams.nts(DC1, 3),
+            // alter to
+            KeyspaceParams.nts(DC1, 3, DC2, 3),
+            // test
+            keyspace -> {
+                ReplicaPlans.forWrite(keyspace, EACH_QUORUM, tk, ReplicaPlans.writeNormal);
+            }
+        );
+        // read
+        raceOfReplicationStrategyTest(
+            // init
+            KeyspaceParams.nts(DC1, 3),
+            // alter to
+            KeyspaceParams.nts(DC1, 3, DC2, 3),
+            // test
+            keyspace -> {
+                ReplicaPlans.forRead(keyspace, tk, EACH_QUORUM, NeverSpeculativeRetryPolicy.INSTANCE);
+            }
+        );
+    }
+
+
+    @Test
+    public void addDatacenterShouldNotCausesUnavailableWithQuorumTest() throws Throwable
+    {
+        // write
+        raceOfReplicationStrategyTest(
+            // init. The # of live endpoints is 3.
+            KeyspaceParams.nts(DC1, 3),
+            // alter to. (3 + 3) / 2 + 1 > 3
+            KeyspaceParams.nts(DC1, 3, DC2, 3),
+            // test
+            keyspace -> {
+                ReplicaPlans.forWrite(keyspace, QUORUM, tk, ReplicaPlans.writeNormal);
+            }
+        );
+        raceOfReplicationStrategyTest(
+            // init. The # of live endpoints is 3 = 2 + 1
+            KeyspaceParams.nts(DC1, 2, DC2, 1),
+            // alter to. (3 + 3) / 2 + 1 > 3
+            KeyspaceParams.nts(DC1, 2, DC2, 1, DC3, 3),
+            // test
+            keyspace -> {
+                ReplicaPlans.forWrite(keyspace, QUORUM, tk, ReplicaPlans.writeNormal);
+            }
+        );
+
+        // read
+        raceOfReplicationStrategyTest(
+            // init
+            KeyspaceParams.nts(DC1, 3),
+            // alter to
+            KeyspaceParams.nts(DC1, 3, DC2, 3),
+            // test
+            keyspace -> {
+                ReplicaPlans.forRead(keyspace, tk, QUORUM, NeverSpeculativeRetryPolicy.INSTANCE);
+            }
+        );
+        raceOfReplicationStrategyTest(
+            // init. The # of live endpoints is 3 = 2 + 1
+            KeyspaceParams.nts(DC1, 2, DC2, 1),
+            // alter to. (3 + 3) / 2 + 1 > 3
+            KeyspaceParams.nts(DC1, 2, DC2, 1, DC3, 3),
+            // test
+            keyspace -> {
+                ReplicaPlans.forRead(keyspace, tk, QUORUM, NeverSpeculativeRetryPolicy.INSTANCE);
+            }
+        );
+    }
+
+    @Test
+    public void raceOnRemoveDatacenterNotCausesUnavailable() throws Throwable
+    {
+        // write
+        raceOfReplicationStrategyTest(
+            // init
+            KeyspaceParams.nts(DC1, 3, DC2, 3),
+            // alter to
+            KeyspaceParams.nts(DC1, 3),
+            // test
+            keyspace -> {
+                ReplicaPlans.forWrite(keyspace, EACH_QUORUM, tk, ReplicaPlans.writeNormal);
+            }
+        );
+
+        // read
+        raceOfReplicationStrategyTest(
+            // init
+            KeyspaceParams.nts(DC1, 3, DC2, 3),
+            // alter to
+            KeyspaceParams.nts(DC1, 3),
+            // test
+            keyspace -> {
+                ReplicaPlans.forRead(keyspace, tk, EACH_QUORUM, NeverSpeculativeRetryPolicy.INSTANCE);
+            }
+        );
+    }
+
+    @Test
+    public void increaseReplicationFactorShouldNotCausesUnavailableTest() throws Throwable
+    {
+        // write
+        raceOfReplicationStrategyTest(
+            // init
+            KeyspaceParams.nts(DC1, 1),
+            // alter to
+            KeyspaceParams.nts(DC1, 3),
+            // test
+            keyspace -> {
+                ReplicaPlans.forWrite(keyspace, LOCAL_QUORUM, tk, ReplicaPlans.writeNormal);
+            }
+        );
+
+        // read
+        raceOfReplicationStrategyTest(
+            // init
+            KeyspaceParams.nts(DC1, 1),
+            // alter to
+            KeyspaceParams.nts(DC1, 3),
+            // test
+            keyspace -> {
+                ReplicaPlans.forRead(keyspace, tk, LOCAL_QUORUM, NeverSpeculativeRetryPolicy.INSTANCE);
+            }
+        );
+    }
+
+    /**
+     * A test runner that runs the `test` while changing the ReplicationStrategy of the raced keyspace.
+     * It loops at most for RACE_TEST_LOOPS time if unable to produce the race or any exception.
+     */
+    private void raceOfReplicationStrategyTest(KeyspaceParams init,

Review comment:
       Nit: both versions of `raceOfReplicationStrategyTest` could be `static`.

##########
File path: src/java/org/apache/cassandra/locator/ReplicaPlan.java
##########
@@ -41,10 +45,11 @@
     //      ==> live.all()  (if consistencyLevel.isDCLocal(), then .filter(consistencyLevel.isLocal))
     private final E contacts;
 
-    ReplicaPlan(Keyspace keyspace, ConsistencyLevel consistencyLevel, E contacts)
+    ReplicaPlan(Keyspace keyspace, AbstractReplicationStrategy replicationStrategy, ConsistencyLevel consistencyLevel, E contacts)

Review comment:
       I wonder whether it would make sense to try to manage the strategy snapshotting inside the `ReplicaPlan`, instead of delegating it to the callers. We could try to do that with some additional per-implementation constructors doing the snapshot, keeping the ones with the `AbstractReplicationStrategy` argument private, [this way](https://github.com/adelapena/cassandra/commit/1b978976593c539097c06128264962555cc71ca7). wdyt?

##########
File path: src/java/org/apache/cassandra/locator/ReplicaPlans.java
##########
@@ -333,32 +331,37 @@ static void assureSufficientLiveReplicas(Keyspace keyspace, ConsistencyLevel con
     @VisibleForTesting
     public static ReplicaPlan.ForTokenWrite forWrite(Keyspace keyspace, ConsistencyLevel consistencyLevel, EndpointsForToken natural, EndpointsForToken pending, Predicate<Replica> isAlive, Selector selector) throws UnavailableException
     {
-        return forWrite(keyspace, consistencyLevel, ReplicaLayout.forTokenWrite(natural, pending), isAlive, selector);
+        return forWrite(keyspace, consistencyLevel, ReplicaLayout.forTokenWrite(keyspace.getReplicationStrategy(), natural, pending), isAlive, selector);

Review comment:
       It seems that `ReadRepairTest.createRepairHandler` is calling this with a null keyspace, producing the NPE test failures that can be seen in the provided CI results. This can be fixed by using `readPlan.keyspace()` instead of `ks` in `AbstractReadRepairTest#repairPlan(ReplicaPlan.ForRangeRead, EndpointsForRange)`.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;08/Apr/21 16:17;githubbot;600","adelapena commented on a change in pull request #954:
URL: https://github.com/apache/cassandra/pull/954#discussion_r609865746



##########
File path: src/java/org/apache/cassandra/locator/ReplicaPlans.java
##########
@@ -333,32 +331,37 @@ static void assureSufficientLiveReplicas(Keyspace keyspace, ConsistencyLevel con
     @VisibleForTesting
     public static ReplicaPlan.ForTokenWrite forWrite(Keyspace keyspace, ConsistencyLevel consistencyLevel, EndpointsForToken natural, EndpointsForToken pending, Predicate<Replica> isAlive, Selector selector) throws UnavailableException
     {
-        return forWrite(keyspace, consistencyLevel, ReplicaLayout.forTokenWrite(natural, pending), isAlive, selector);
+        return forWrite(keyspace, consistencyLevel, ReplicaLayout.forTokenWrite(keyspace.getReplicationStrategy(), natural, pending), isAlive, selector);

Review comment:
       It seems that `ReadRepairTest.createRepairHandler` is calling this with a null keyspace, producing the NPE test failures that can be seen in the provided CI results. This can be fixed by using `readPlan.keyspace()` instead of `ks` in `AbstractReadRepairTest#repairPlan(ReplicaPlan.ForRangeRead, EndpointsForRange)`, as it's done in [this commit](https://github.com/adelapena/cassandra/commit/bbc29452ee3524d47dc88ad22e2a838e0795acb2).




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Apr/21 10:27;githubbot;600","yifan-c commented on a change in pull request #954:
URL: https://github.com/apache/cassandra/pull/954#discussion_r611308786



##########
File path: src/java/org/apache/cassandra/locator/ReplicaPlan.java
##########
@@ -41,10 +45,11 @@
     //      ==> live.all()  (if consistencyLevel.isDCLocal(), then .filter(consistencyLevel.isLocal))
     private final E contacts;
 
-    ReplicaPlan(Keyspace keyspace, ConsistencyLevel consistencyLevel, E contacts)
+    ReplicaPlan(Keyspace keyspace, AbstractReplicationStrategy replicationStrategy, ConsistencyLevel consistencyLevel, E contacts)

Review comment:
       Some call-sites require to pass the `ReplicationStrategy` snapshot explicit, as it uses the snapshot to select the peers to contact, e.g. `org.apache.cassandra.locator.ReplicaPlans#forRead`
   The other call-sites can safely and implicitly just pass the `keyspace` and get the latest RS in the constructor. 
   
   One approach is to provide the both public constructor overrides. 
   
   I tried it earlier, but it is confusing to users, IMO. Because it hides the side effect (i.e. calling the wrong constructor can lead to race). I'd favor explicitness. The client might need to write a bit more code, but easier for later maintenance. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Apr/21 03:40;githubbot;600","yifan-c commented on pull request #954:
URL: https://github.com/apache/cassandra/pull/954#issuecomment-817464899


   Thanks @adelapena for reviewing! Pushed a new commit to address the comments. 


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Apr/21 04:12;githubbot;600","adelapena commented on a change in pull request #954:
URL: https://github.com/apache/cassandra/pull/954#discussion_r611527521



##########
File path: src/java/org/apache/cassandra/locator/ReplicaPlan.java
##########
@@ -41,10 +45,11 @@
     //      ==> live.all()  (if consistencyLevel.isDCLocal(), then .filter(consistencyLevel.isLocal))
     private final E contacts;
 
-    ReplicaPlan(Keyspace keyspace, ConsistencyLevel consistencyLevel, E contacts)
+    ReplicaPlan(Keyspace keyspace, AbstractReplicationStrategy replicationStrategy, ConsistencyLevel consistencyLevel, E contacts)

Review comment:
       Fair enough :+1:




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Apr/21 10:56;githubbot;600","smiklosovic closed pull request #954:
URL: https://github.com/apache/cassandra/pull/954


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:37;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,4200,,,0,4200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,yifanc,,,,,,,,,,,,,Availability -> Unavailable,,,,,,,,Normal,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Apr 15 15:56:57 UTC 2021,,,,,,,All,,,,"0|z0pceg:",9223372036854775807,,,,adelapena,aleksey,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/b915688ea878aaa284f5cedeb799c5f797c4d824,,,,,,,,,"unit test; ci",,,,,"06/Apr/21 21:54;yifanc;PR: https://github.com/apache/cassandra/pull/954
CI: https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=CASSANDRA-16545%2Ftrunk

The patch is largely a refactor to pass the same {{ReplicationStrategy}} object to build replicaLayout, replicaPlan and CL liveness validation. 
A test is added to prove that the false unavailable can be thrown when creating the replicaPlan. (in the [first commit|https://github.com/apache/cassandra/pull/954/commits/8d921c5d311c6e97d1f757af64a2e65a84b419ef])
The [second commit|https://github.com/apache/cassandra/pull/954/commits/1b935280e09869736f334f67a72ed778ccfcdec7] makes sure the same RS object is used for peer selection and CL liveness check to avoid race. 
However, {{blockFor}} calculation can still use a different RS object, leading to that the coordinator blocks for a different condition as it originally calculated for. The rest 2 commits address the problem. 

The highlights of the patch:
* ReplicaLayout and ReplicaPlan now keep a reference to the replication strategy snapshot. The snapshot is now used for peer selection, liveness validation and blockFor calculation. 
* The usage of Keyspace to validate CL liveness is fully eliminated to avoid potential race. It uses replication strategy instead. 

cc: [~aleksey][~cnlwsu];;;","08/Apr/21 16:25;adelapena;[~yifanc] overall the approach looks good to me, I have left some comments in the PR. The CI failures in {{ReadRepairTest}} can be fixed [this way|https://github.com/apache/cassandra/pull/954#discussion_r609865746]. I have also run the new {{AssureSufficientLiveNodesTest}} (which is a nice test) is our internal test multiplexer some few hundred times.;;;","12/Apr/21 11:00;adelapena;The last changes look good to me, +1 assuming CI looks good. I have started a ci-cassandra round [here|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/634/pipeline].;;;","13/Apr/21 09:52;mck;
That CI run looked good, with the exception of the [dtest-upgrade|https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/202/] which fell over for an unrelated reason. 

Just that job has been restarted here: [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/209/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/209/]



;;;","13/Apr/21 20:24;aleksey;+1;;;","14/Apr/21 20:11;yifanc;Starting commit

CI Results:
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16545-trunk-A70927C8-3771-4980-809D-C36119B6B351]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16545-trunk-A70927C8-3771-4980-809D-C36119B6B351]|[build|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/658/pipeline]|

CI and Jenkins has a few unrelated failures. ;;;","15/Apr/21 15:56;yifanc;Committed to trunk as [b915688|https://github.com/apache/cassandra/commit/b915688ea878aaa284f5cedeb799c5f797c4d824];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4.0 node sending a repair prepare message to a 3.x node breaks the connection on 4.0 side,CASSANDRA-16542,13367969,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aleksey,aleksey,aleksey,26/Mar/21 16:12,25/Apr/21 11:32,13/Jul/23 08:40,26/Mar/21 17:49,4.0,4.0-rc1,,,,,,Messaging/Internode,,,,0,,,An {{AssertionError}} is thrown in {{PrepareMessage#serializedSize()}} method that causes internode connections to be repeatedly torn down until affected instances are restarted.,,aholmber,aleksey,brandon.williams,marcuse,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,aleksey,,,,,,,,,,,,,Degradation -> Performance Bug/Regression,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Mar 26 17:49:38 UTC 2021,,,,,,,All,,,,"0|z0p9ag:",9223372036854775807,,,,marcuse,,,,Low,,4.0-alpha1,,"[efe830e1f7e3f2b4dfb6c401326a06f2518c66b3|https://github.com/apache/cassandra/commit/efe830e1f7e3f2b4dfb6c401326a06f2518c66b3]",,,,,,,,,N/A,,,,,"26/Mar/21 17:15;aleksey;Branch with a trivial one-line patch: https://github.com/iamaleksey/cassandra/commits/16542;;;","26/Mar/21 17:36;marcuse;+1;;;","26/Mar/21 17:49;aleksey;Cheers, committed as [efe830e1f7e3f2b4dfb6c401326a06f2518c66b3|https://github.com/apache/cassandra/commit/efe830e1f7e3f2b4dfb6c401326a06f2518c66b3] to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cqlsh encoding error with unicode in multi-line statement,CASSANDRA-16539,13367709,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aholmber,aholmber,aholmber,25/Mar/21 20:53,27/May/22 19:25,13/Jul/23 08:40,06/May/21 21:33,4.0,4.0-rc2,4.1,4.1-alpha1,,,,Tool/cqlsh,,,,0,,,"{noformat}
CREATE TABLE test.users (
    user_id int PRIMARY KEY,
    name text,
    state text
)
{noformat}

Multiline cql with unicode characters will fail with an encoding error:
{noformat}
cqlsh> insert into test.users ( user_id, name, state ) values (
   ... 6,
   ... 'Bonne',
   ... 'Année');
'ascii' codec can't encode character u'\xe9' in position 74: ordinal not in range(128)
{noformat}

This is only when running Python 2.7 and when python3 is not present in the environment.",,aholmber,brandon.williams,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16400,,,,,,,0.0,aholmber,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu May 06 21:32:59 UTC 2021,,,,,,,All,,,,"0|z0p7p4:",9223372036854775807,,,,brandon.williams,,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/288bb9d9021d297611eb6ce27143de15a10b119d,,,,,,,,,added new unit tests,,,,,"01/Apr/21 19:10;aholmber;Proposing a small tweak to cqlsh and adding a few quick tests that can be run in both python2 and 3.

[patch|https://github.com/aholmberg/cassandra/pull/51/files]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16539];;;","04/May/21 13:55;brandon.williams;Committed, thanks.;;;","04/May/21 20:50;e.dimitrova;Unfortunately, one of the tests failed in Jenkins on python 3. I will reopen the ticket to check them. 
https://jenkins-cm4.apache.org/job/Cassandra-4.0/4/;;;","04/May/21 21:13;brandon.williams;-I fixed some weirdness in d2fcdacfa1-

Nevermind.  Not sure what's going on here.;;;","06/May/21 21:32;aholmber;I think we reopened the wrong one here. I'm going to close this and reopen the other fix that built on this change.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The two tests in  NetstatsBootstrapWithEntireSSTablesCompressionStreamingTest are flaky,CASSANDRA-16533,13367070,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adutra,e.dimitrova,e.dimitrova,23/Mar/21 18:02,25/Apr/21 11:23,13/Jul/23 08:40,30/Mar/21 00:06,4.0,4.0-rc1,,,,,,CI,,,,0,,,"The issue is when there are interleaving logs, then the filter [here|https://github.com/apache/cassandra/blob/trunk/test/distributed/org/apache/cassandra/distributed/test/AbstractNetstatsStreaming.java#L142-L148] doesn't help.

I managed to reproduce the issue only once. 

But I found logs from old CircleCI [run|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/705/workflows/c3534f6a-071e-428c-9a4d-0a1e08f23257/jobs/3866/artifacts]. Please see [logs/org.apache.cassandra.distributed.test.NetstatsBootstrapWithoutEntireSSTablesCompressionStreamingTest/<main>/<main>/system.log|https://3866-218559411-gh.circle-artifacts.com/0/logs/org.apache.cassandra.distributed.test.NetstatsBootstrapWithoutEntireSSTablesCompressionStreamingTest/%3Cmain%3E/%3Cmain%3E/system.log]

The excerpt that shows what I am talking about:

 
{code:java}
DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1] node1 2021-03-17 22:41:21,057 CassandraCompressedStreamWriter.java:102 - [Stream #e3d93810-8771-11eb-a0f1-f756ef192fe7] Finished streaming file /tmp/dtests9118120876279144235/node1/data1/netstats_test/test_table-c0f7eda0877111ebbfc147ef604f6105/na-11-big-Data.db to /127.0.0.2:7012, bytesTransferred = 66.646KiB, totalSize = 66.646KiB
Bootstrap e3d93810-8771-11eb-a0f1-f756ef192fe7
 /127.0.0.2
 Sending 15 files, 1339433 bytes total. Already sent 3 files (20.00%), 197286 bytes total (14.73%)
DEBUG [Stream-Deserializer-/127.0.0.1:7012-2bcb5810] node2 2021-03-17 22:41:21,057 StreamingInboundHandler.java:187 - [Stream #e3d93810-8771-11eb-a0f1-f756ef192fe7 channel: 2bcb5810] Received IncomingStreamMessage{header=Header (tableId: c0f7eda0-8771-11eb-bfc1-47ef604f6105, #1, repairedAt: 0, pendingRepair: null, sendByFollower: true), stream=CassandraIncomingFile{sstable=netstats_test/test_table}}
DEBUG [Stream-Deserializer-/127.0.0.1:7012-2bcb5810] node2 2021-03-17 22:41:21,058 NettyStreamingMessageSender.java:258 - [Stream #e3d93810-8771-11eb-a0f1-f756ef192fe7 channel: 09fdf87e] Sending Received (c0f7eda0-8771-11eb-bfc1-47ef604f6105, #1)
 /tmp/dtests9118120876279144235/node1/data1/system_auth/roles-5bc52802de2535edaeab188eecebb090/na-2-big-Data.db 102/102 bytes (100%) sent to idx:0/127.0.0.2
 /tmp/dtests9118120876279144235/node1/data1/netstats_test/test_table-c0f7eda0877111ebbfc147ef604f6105/na-11-big-Data.db 65536/68246 bytes (96%) sent to idx:0/127.0.0.2
 /tmp/dtests9118120876279144235/node1/data1/netstats_test/test_table-c0f7eda0877111ebbfc147ef604f6105/na-20-big-Data.db 62836/62836 bytes (100%) sent to idx:0/127.0.0.2
 /tmp/dtests9118120876279144235/node1/data1/netstats_test/test_table-c0f7eda0877111ebbfc147ef604f6105/na-17-big-Data.db 68812/68812 bytes (100%) sent to idx:0/127.0.0.2
Read Repair Statistics:
Attempted: 0
Mismatch (Blocking): 0
Mismatch (Background): 0
Pool Name DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1] node1 2021-03-17 22:41:21,058 CassandraCompressedStreamWriter.java:64 - [Stream #e3d93810-8771-11eb-a0f1-f756ef192fe7] Start streaming file /tmp/dtests9118120876279144235/node1/data1/netstats_test/test_table-c0f7eda0877111ebbfc147ef604f6105/na-8-big-Data.db to /127.0.0.2:7012, repairedAt = 0, totalSize = 67504
 Active PendingDEBUG [Stream-Deserializer-/127.0.0.1:7012-2bcb5810] node2 2021-03-17 22:41:21,058 StreamReceiveTask.java:88 - received 2 of 14 total files, 131648 of total bytes 68812
 Completed Dropped
Large messages n/a 0 0 0
Small messages n/a 0 1 0
DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1] node1 2021-03-17 22:41:21,058 CassandraCompressedStreamWriter.java:81 - [Stream #e3d93810-8771-11eb-a0f1-f756ef192fe7] Writing section 0 with length 67504 to stream.
Gossip messages n/a 0 54 0
INFO [pool-2-thread-2] <main> 2021-03-17 22:41:21,567 /127.0.0.1:7012 Mode: NORMAL
 
{code}
The line _Pool Name  Active Pending  Completed Dropped_ is split into three parts due to DEBUG logs interleaving and the filter doesn't remove _Completed Dropped_ which is added to the results [here|https://github.com/apache/cassandra/blob/trunk/test/distributed/org/apache/cassandra/distributed/test/AbstractNetstatsStreaming.java#L179] which leads to the following  [exception |https://github.com/apache/cassandra/blob/d656f8ac012f4577d22ed7bd3db94c15ae8eb5a9/test/distributed/org/apache/cassandra/distributed/test/AbstractNetstatsStreaming.java#L46]

CC [~yifanc] as he was working on CASSANDRA-16057

and [~stefan.miklosovic] as the original author of these tests, if you guys know something I am missing here

 ",,adutra,e.dimitrova,stefan.miklosovic,yifanc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adutra,,,,,,,,,,,,,Code,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 30 00:05:28 UTC 2021,,,,,,,All,,,,"0|z0p3r4:",9223372036854775807,,,,e.dimitrova,yifanc,,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/efa25fc8d10bbfcefe14fc6f2a623b6a8b73b5cd,,,,,,,,,https://github.com/adutra/cassandra/pull/3,,,,,"24/Mar/21 05:21;yifanc;[~e.dimitrova], thanks for the heads up.
I do not think {{AbstractNetstatsStreaming}} uses CASSANDRA-16057 to capture the nodetool output. It is using {{NodetoolUtils#nodetool()}} that redirects the stdout and stderr from nodetool invocation within the instance. 

The implementation of CASSANDRA-16057 does not use the redirection trick. Instead, it passes dedicated {{PrintStream}} to accept and only the outputs from nodetool command. ;;;","26/Mar/21 17:23;adutra;I just started investigating this issue.

One thing that strikes me in {{NodetoolUtils#nodetool()}} is that we are briefly reassigning {{System.out}} and {{System.err}}, see [here|https://github.com/apache/cassandra/blob/83e1e9e45193322f18f57aa7cc4ad31d9d5a152d/test/distributed/org/apache/cassandra/distributed/util/NodetoolUtils.java#L57-L58].

This is inherently racy. IMO if another thread writes to {{System.out}} or {{System.err}} while the current thread is executing the nodetool command between lines 57 and 67, then the output will be garbled.

[~stefan.miklosovic] do you remember why we need to reassign {{System.out}} and {{System.err}} in {{NodetoolUtils}}? With the changes introduced by [~yifanc] my understanding is that this is not necessary anymore, as we are passing the {{PrintStream}} directly to {{Instance.DTestNodeTool}}. In which case, this could be an easy fix :) .;;;","26/Mar/21 17:35;brandon.williams;CASSANDRA-16057 wasn't completed when CASSANDRA-15406 was done, so I think it's going to be a simple one :);;;","26/Mar/21 18:26;adutra;If that's all it takes, then the PR is ready.

CircleCI doesn't love me much (and likewise) but I think I've got the jobs running here:
 * [CircleCI java8|https://app.circleci.com/pipelines/github/adutra/cassandra/6/workflows/ff748295-a629-473f-8658-a6327ec9023a]
 * [CircleCI java11|https://app.circleci.com/pipelines/github/adutra/cassandra/6/workflows/5ef9459f-387c-4488-a06c-80f4a06c36ee];;;","26/Mar/21 19:10;stefan.miklosovic;[~adutra] unfortunately that ticket was done before changes of Yifan were introduced  ... 

I think one reason for not doing it differently was need to release new dtest-api which I did not wanted to do because of delays etc and willingness of other people do release it and so we just ended up with this.

EDIT: or after? I am not completely sure ... But definitely that part smells, I was discussing this with Ekaterina privately already.;;;","26/Mar/21 20:51;adutra;Yeah in the meanwhile Yifan suggested to refactor {{NodetoolUtils}} and get rid of it. Which I did, and it does seem that we don't need it anymore after 16057.;;;","26/Mar/21 21:08;e.dimitrova;Thank you all for valuable input and thanks [~adutra] for the patch.

It looks good to me.

I just triggered a CI run [here |https://jenkins-cm4.apache.org/job/Cassandra-devbranch/511/];;;","26/Mar/21 21:12;yifanc;+1 on the patch. 
Thanks for triggering the CI run. ;;;","29/Mar/21 16:48;e.dimitrova;I just triggered a new CI run [here |https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/527/] as there was some unrelated issue with the test splits in Jenkins which led to more than 600 failures. The issue is already fixed.;;;","29/Mar/21 23:52;e.dimitrova;CI run has unrelated failures.

Starting preparation for commit;;;","30/Mar/21 00:05;e.dimitrova;Committed [here |https://github.com/apache/cassandra/commit/efa25fc8d10bbfcefe14fc6f2a623b6a8b73b5cd], thank you!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky testSkipScrubCorruptedCounterRowWithTool,CASSANDRA-16532,13366921,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,23/Mar/21 08:23,10/Nov/21 15:42,13/Jul/23 08:40,06/Apr/21 13:03,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"Fix flaky [testSkipScrubCorruptedCounterRowWithTool|https://ci-cassandra.apache.org/job/Cassandra-trunk/365/testReport/junit/org.apache.cassandra.db/ScrubTest/testSkipScrubCorruptedCounterRowWithTool_compression/]",,adelapena,aholmber,bereng,,,,,,,,,,,,,"bereng opened a new pull request #940:
URL: https://github.com/apache/cassandra/pull/940


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Mar/21 08:25;githubbot;600","bereng commented on pull request #940:
URL: https://github.com/apache/cassandra/pull/940#issuecomment-804755288


   CI [j11](https://app.circleci.com/pipelines/github/bereng/cassandra/236/workflows/5e69db7e-7a70-4466-9669-4b8952957d28)
   CI [j8](https://app.circleci.com/pipelines/github/bereng/cassandra/236/workflows/9dedf210-1ea4-4e15-88a0-2ffd63a090f3)


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Mar/21 09:33;githubbot;600","adelapena commented on a change in pull request #940:
URL: https://github.com/apache/cassandra/pull/940#discussion_r600459449



##########
File path: test/unit/org/apache/cassandra/db/ScrubTest.java
##########
@@ -838,42 +853,117 @@ public void testNoCheckScrubMultiRowWithTool()
     }
 
     @Test
-    public void testHeaderFixWithTool()
+    public void testHeaderFixValidateOnlyWithTool()
     {
+        String ksName = Thread.currentThread().getStackTrace()[1].getMethodName();
+        toolTestingSetup(ksName);
+
         CompactionManager.instance.disableAutoCompaction();
-        Keyspace keyspace = Keyspace.open(KEYSPACE2);
+        Keyspace keyspace = Keyspace.open(ksName);
         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
         cfs.clearUnsafe();
 
         fillCF(cfs, 1);
         assertOrderedAll(cfs, 1);
 
-        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate_only"", KEYSPACE2, CF3);
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate_only"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Not continuing with scrub, since '--header-fix validate-only' was specified."");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
+
+    @Test
+    public void testHeaderFixValidateWithTool()
+    {
+        String ksName = Thread.currentThread().getStackTrace()[1].getMethodName();
+        toolTestingSetup(ksName);
+
+        CompactionManager.instance.disableAutoCompaction();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate"", KEYSPACE2, CF3);
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Pre-scrub sstables snapshotted into"");
         Assertions.assertThat(tool.getStdout()).contains(""1 rows in new sstable and 0 empty"");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
+
+    @Test
+    public void testHeaderFixFixOnlyWithTool()
+    {
+        String ksName = Thread.currentThread().getStackTrace()[1].getMethodName();
+        toolTestingSetup(ksName);
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix-only"", KEYSPACE2, CF3);
+        CompactionManager.instance.disableAutoCompaction();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
+
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix-only"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Not continuing with scrub, since '--header-fix fix-only' was specified."");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
+
+    @Test
+    public void testHeaderFixWithTool()
+    {
+        String ksName = Thread.currentThread().getStackTrace()[1].getMethodName();
+        toolTestingSetup(ksName);
+
+        CompactionManager.instance.disableAutoCompaction();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix"", KEYSPACE2, CF3);
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Pre-scrub sstables snapshotted into"");
         Assertions.assertThat(tool.getStdout()).contains(""1 rows in new sstable and 0 empty"");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
+
+    @Test
+    public void testHeaderFixNoChecksWithTool()
+    {
+        String ksName = Thread.currentThread().getStackTrace()[1].getMethodName();
+        toolTestingSetup(ksName);
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""off"", KEYSPACE2, CF3);
+        CompactionManager.instance.disableAutoCompaction();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
+
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""off"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Pre-scrub sstables snapshotted into"");
         Assertions.assertThat(tool.getStdout()).contains(""1 rows in new sstable and 0 empty"");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
     }
+
+    private void toolTestingSetup(String ksName)

Review comment:
       We could create the keyspace name here, and possibly also disable autocompaction, so we reduce duplication in the callers:
   ```java
   private String toolTestingSetup()
   {
       System.setProperty(org.apache.cassandra.tools.Util.ALLOW_TOOL_REINIT_FOR_TEST, ""true""); // Necessary for testing
       CompactionManager.instance.disableAutoCompaction();
   
       String ksName = Thread.currentThread().getStackTrace()[2].getMethodName();
       createKeyspace(ksName,
                      KeyspaceParams.simple(1),
                      standardCFMD(ksName, CF),
                      standardCFMD(ksName, CF2),
                      standardCFMD(ksName, CF3),
                      standardCFMD(ksName, CF4),
                      counterCFMD(ksName, COUNTER_CF));
   
       return ksName;
   }
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Mar/21 13:08;githubbot;600","adelapena commented on a change in pull request #940:
URL: https://github.com/apache/cassandra/pull/940#discussion_r600680011



##########
File path: test/unit/org/apache/cassandra/db/ScrubTest.java
##########
@@ -747,33 +746,19 @@ public void testFilterOutDuplicates() throws Exception
         assertEquals(0, rs.size());
     }
 
-    @Test
-    public void testToolTestingEnvSetup()
-    {
-        createKeyspace(KEYSPACE2,
-                       KeyspaceParams.simple(1),
-                       standardCFMD(KEYSPACE2, CF),
-                       standardCFMD(KEYSPACE2, CF2),
-                       standardCFMD(KEYSPACE2, CF3),
-                       standardCFMD(KEYSPACE2, CF4),
-                       counterCFMD(KEYSPACE2, COUNTER_CF));
-
-        System.setProperty(org.apache.cassandra.tools.Util.ALLOW_TOOL_REINIT_FOR_TEST, ""true""); // Necessary for testing
-    }
-
     @Test
     public void testScrubOneRowWithTool()
     {
-        CompactionManager.instance.disableAutoCompaction();
-        Keyspace keyspace = Keyspace.open(KEYSPACE2);
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);
         cfs.clearUnsafe();

Review comment:
       Do we still need the calls to {{clearUnsafe}} in the tool tests now that they are using a dedicated keyspace?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Mar/21 16:58;githubbot;600","adelapena commented on a change in pull request #940:
URL: https://github.com/apache/cassandra/pull/940#discussion_r600680011



##########
File path: test/unit/org/apache/cassandra/db/ScrubTest.java
##########
@@ -747,33 +746,19 @@ public void testFilterOutDuplicates() throws Exception
         assertEquals(0, rs.size());
     }
 
-    @Test
-    public void testToolTestingEnvSetup()
-    {
-        createKeyspace(KEYSPACE2,
-                       KeyspaceParams.simple(1),
-                       standardCFMD(KEYSPACE2, CF),
-                       standardCFMD(KEYSPACE2, CF2),
-                       standardCFMD(KEYSPACE2, CF3),
-                       standardCFMD(KEYSPACE2, CF4),
-                       counterCFMD(KEYSPACE2, COUNTER_CF));
-
-        System.setProperty(org.apache.cassandra.tools.Util.ALLOW_TOOL_REINIT_FOR_TEST, ""true""); // Necessary for testing
-    }
-
     @Test
     public void testScrubOneRowWithTool()
     {
-        CompactionManager.instance.disableAutoCompaction();
-        Keyspace keyspace = Keyspace.open(KEYSPACE2);
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);
         cfs.clearUnsafe();

Review comment:
       Do we still need the calls to `clearUnsafe` in the tool tests now that they are using a dedicated keyspace?
   
   Also, for the other tests not using the standalone scrubber and depending on `defineSchema` perhaps we could place the call to `clearUnsafe` in an `@After` method:
   ```
   @After
   public void clearColumnFamilyStores()
   {
       Keyspace.open(KEYSPACE).getColumnFamilyStores().forEach(ColumnFamilyStore::clearUnsafe);
   }
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Mar/21 17:06;githubbot;600","adelapena commented on a change in pull request #940:
URL: https://github.com/apache/cassandra/pull/940#discussion_r600688080



##########
File path: test/unit/org/apache/cassandra/db/ScrubTest.java
##########
@@ -838,42 +839,106 @@ public void testNoCheckScrubMultiRowWithTool()
     }
 
     @Test
-    public void testHeaderFixWithTool()
+    public void testHeaderFixValidateOnlyWithTool()
     {
-        CompactionManager.instance.disableAutoCompaction();
-        Keyspace keyspace = Keyspace.open(KEYSPACE2);
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
         cfs.clearUnsafe();
 
         fillCF(cfs, 1);
         assertOrderedAll(cfs, 1);
 
-        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate_only"", KEYSPACE2, CF3);
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate_only"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Not continuing with scrub, since '--header-fix validate-only' was specified."");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate"", KEYSPACE2, CF3);
+    @Test
+    public void testHeaderFixValidateWithTool()
+    {
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
+
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Pre-scrub sstables snapshotted into"");
         Assertions.assertThat(tool.getStdout()).contains(""1 rows in new sstable and 0 empty"");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix-only"", KEYSPACE2, CF3);
+    @Test
+    public void testHeaderFixFixOnlyWithTool()
+    {
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
+
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix-only"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Not continuing with scrub, since '--header-fix fix-only' was specified."");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix"", KEYSPACE2, CF3);
+    @Test
+    public void testHeaderFixWithTool()
+    {
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
+
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Pre-scrub sstables snapshotted into"");
         Assertions.assertThat(tool.getStdout()).contains(""1 rows in new sstable and 0 empty"");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
+
+    @Test
+    public void testHeaderFixNoChecksWithTool()
+    {
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""off"", KEYSPACE2, CF3);
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""off"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Pre-scrub sstables snapshotted into"");
         Assertions.assertThat(tool.getStdout()).contains(""1 rows in new sstable and 0 empty"");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
     }
+
+    private String toolTestingSetup()
+    {
+        System.setProperty(org.apache.cassandra.tools.Util.ALLOW_TOOL_REINIT_FOR_TEST, ""true""); // Necessary for testing
+        CompactionManager.instance.disableAutoCompaction();

Review comment:
       I think every single test is disabling autocompaction. We could put this call in `defineSchema()` and remove the other calls.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Mar/21 17:09;githubbot;600","bereng commented on a change in pull request #940:
URL: https://github.com/apache/cassandra/pull/940#discussion_r601094411



##########
File path: test/unit/org/apache/cassandra/db/ScrubTest.java
##########
@@ -838,42 +839,106 @@ public void testNoCheckScrubMultiRowWithTool()
     }
 
     @Test
-    public void testHeaderFixWithTool()
+    public void testHeaderFixValidateOnlyWithTool()
     {
-        CompactionManager.instance.disableAutoCompaction();
-        Keyspace keyspace = Keyspace.open(KEYSPACE2);
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
         cfs.clearUnsafe();
 
         fillCF(cfs, 1);
         assertOrderedAll(cfs, 1);
 
-        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate_only"", KEYSPACE2, CF3);
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate_only"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Not continuing with scrub, since '--header-fix validate-only' was specified."");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate"", KEYSPACE2, CF3);
+    @Test
+    public void testHeaderFixValidateWithTool()
+    {
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
+
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""validate"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Pre-scrub sstables snapshotted into"");
         Assertions.assertThat(tool.getStdout()).contains(""1 rows in new sstable and 0 empty"");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix-only"", KEYSPACE2, CF3);
+    @Test
+    public void testHeaderFixFixOnlyWithTool()
+    {
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
+
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix-only"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Not continuing with scrub, since '--header-fix fix-only' was specified."");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix"", KEYSPACE2, CF3);
+    @Test
+    public void testHeaderFixWithTool()
+    {
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
+
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""fix"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Pre-scrub sstables snapshotted into"");
         Assertions.assertThat(tool.getStdout()).contains(""1 rows in new sstable and 0 empty"");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
+    }
+
+    @Test
+    public void testHeaderFixNoChecksWithTool()
+    {
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
+        ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF3);
+        cfs.clearUnsafe();
+
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
 
-        tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""off"", KEYSPACE2, CF3);
+        ToolResult tool = ToolRunner.invokeClass(StandaloneScrubber.class, ""-e"", ""off"", ksName, CF3);
         Assertions.assertThat(tool.getStdout()).contains(""Pre-scrub sstables snapshotted into"");
         Assertions.assertThat(tool.getStdout()).contains(""1 rows in new sstable and 0 empty"");
         tool.assertOnCleanExit();
         assertOrderedAll(cfs, 1);
     }
+
+    private String toolTestingSetup()
+    {
+        System.setProperty(org.apache.cassandra.tools.Util.ALLOW_TOOL_REINIT_FOR_TEST, ""true""); // Necessary for testing
+        CompactionManager.instance.disableAutoCompaction();

Review comment:
       Mmmm I see tests that don't such as `testScrubColumnValidation()`




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Mar/21 06:25;githubbot;600","bereng commented on a change in pull request #940:
URL: https://github.com/apache/cassandra/pull/940#discussion_r601098808



##########
File path: test/unit/org/apache/cassandra/db/ScrubTest.java
##########
@@ -747,33 +746,19 @@ public void testFilterOutDuplicates() throws Exception
         assertEquals(0, rs.size());
     }
 
-    @Test
-    public void testToolTestingEnvSetup()
-    {
-        createKeyspace(KEYSPACE2,
-                       KeyspaceParams.simple(1),
-                       standardCFMD(KEYSPACE2, CF),
-                       standardCFMD(KEYSPACE2, CF2),
-                       standardCFMD(KEYSPACE2, CF3),
-                       standardCFMD(KEYSPACE2, CF4),
-                       counterCFMD(KEYSPACE2, COUNTER_CF));
-
-        System.setProperty(org.apache.cassandra.tools.Util.ALLOW_TOOL_REINIT_FOR_TEST, ""true""); // Necessary for testing
-    }
-
     @Test
     public void testScrubOneRowWithTool()
     {
-        CompactionManager.instance.disableAutoCompaction();
-        Keyspace keyspace = Keyspace.open(KEYSPACE2);
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);
         cfs.clearUnsafe();

Review comment:
       Some don't call clearUnsafe(), some call it mid-method, etc I remove the calls from the tool based tests, left the rest alone and triggered a run in the multiplexer. Hope it's ok.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Mar/21 06:32;githubbot;600","bereng commented on a change in pull request #940:
URL: https://github.com/apache/cassandra/pull/940#discussion_r601180901



##########
File path: test/unit/org/apache/cassandra/db/ScrubTest.java
##########
@@ -747,33 +746,19 @@ public void testFilterOutDuplicates() throws Exception
         assertEquals(0, rs.size());
     }
 
-    @Test
-    public void testToolTestingEnvSetup()
-    {
-        createKeyspace(KEYSPACE2,
-                       KeyspaceParams.simple(1),
-                       standardCFMD(KEYSPACE2, CF),
-                       standardCFMD(KEYSPACE2, CF2),
-                       standardCFMD(KEYSPACE2, CF3),
-                       standardCFMD(KEYSPACE2, CF4),
-                       counterCFMD(KEYSPACE2, COUNTER_CF));
-
-        System.setProperty(org.apache.cassandra.tools.Util.ALLOW_TOOL_REINIT_FOR_TEST, ""true""); // Necessary for testing
-    }
-
     @Test
     public void testScrubOneRowWithTool()
     {
-        CompactionManager.instance.disableAutoCompaction();
-        Keyspace keyspace = Keyspace.open(KEYSPACE2);
+        String ksName = toolTestingSetup();
+        Keyspace keyspace = Keyspace.open(ksName);
         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);
         cfs.clearUnsafe();

Review comment:
       The multiplexer run looks ok.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Mar/21 08:16;githubbot;600","bereng commented on pull request #940:
URL: https://github.com/apache/cassandra/pull/940#issuecomment-810807685


   - CI [j11](https://app.circleci.com/pipelines/github/bereng/cassandra/241/workflows/fa465882-074e-4a9f-b55e-b18b5774c811/jobs/2468)


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Mar/21 06:27;githubbot;600","bereng edited a comment on pull request #940:
URL: https://github.com/apache/cassandra/pull/940#issuecomment-810807685


   - CI [j11](https://app.circleci.com/pipelines/github/bereng/cassandra/241/workflows/fa465882-074e-4a9f-b55e-b18b5774c811/jobs/2468)
   - CI [j8](https://app.circleci.com/pipelines/github/bereng/cassandra/241/workflows/81cbc56d-384c-435d-813e-2adf50d33b77/jobs/2471)


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Mar/21 06:28;githubbot;600","adelapena opened a new pull request #947:
URL: https://github.com/apache/cassandra/pull/947


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Apr/21 11:46;githubbot;600","adelapena opened a new pull request #948:
URL: https://github.com/apache/cassandra/pull/948


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Apr/21 11:46;githubbot;600","bereng closed pull request #940:
URL: https://github.com/apache/cassandra/pull/940


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;07/Apr/21 07:30;githubbot;600","adelapena closed pull request #948:
URL: https://github.com/apache/cassandra/pull/948


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/May/21 15:48;githubbot;600","adelapena closed pull request #947:
URL: https://github.com/apache/cassandra/pull/947


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/May/21 15:48;githubbot;600","adelapena closed pull request #1254:
URL: https://github.com/apache/cassandra/pull/1254


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:42;githubbot;600","adelapena closed pull request #1253:
URL: https://github.com/apache/cassandra/pull/1253


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Nov/21 15:42;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,10800,,,0,10800,,,,,,,,,,,,,,,CASSANDRA-16562,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,bereng,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 06 14:11:59 UTC 2021,,,,,,,All,,,,"0|z0p2u0:",9223372036854775807,,,,adelapena,bereng,,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/6115a02021c86028c0cc5a510452454cc8b4d2c2,,,,,,,,,See PR,,,,,"23/Mar/21 08:28;bereng;Trying to run the failing test in a loop I noticed it wasn't cleaning the env properly opening the door to test method cross-talk. [~aholmber] I think you managed to repro locally so could you doublecheck my PR and see if it doesn't repro anymore please?;;;","23/Mar/21 15:59;aholmber;Unfortunately I am still seeing [this|https://ci-cassandra.apache.org/job/Cassandra-trunk/362/testReport/junit/org.apache.cassandra.db/ScrubTest/testSkipScrubCorruptedCounterRowWithTool_compression/] failure when looping on this branch. With a bit of instrumentation, I can see that the scrubber is hitting this when it fails in this way:

{noformat}
 Scrubbing BigTableReader(path='/home/vagrant/cassandra/build/test/cassandra/data/Keyspace2/Counter1-949374d48be711eb9202f742d2eeefb4/na-1-big-Data.db') (64.289KiB)
 WARNING: Error reading row org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /home/vagrant/cassandra/build/test/cassandra/data/Keyspace2/Counter1-949374d48be711eb9202f742d2eeefb4/na-1-big-Data.db
     at org.apache.cassandra.io.sstable.SSTableIdentityIterator.hasNext(SSTableIdentityIterator.java:138)
     at org.apache.cassandra.db.compaction.Scrubber$RowMergingSSTableIterator.hasNext(Scrubber.java:541)
     at org.apache.cassandra.db.compaction.Scrubber$OrderCheckerIterator.computeNext(Scrubber.java:654)
     at org.apache.cassandra.db.compaction.Scrubber$OrderCheckerIterator.computeNext(Scrubber.java:574)
     at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
     at org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:133)
     at org.apache.cassandra.db.transform.UnfilteredRows.isEmpty(UnfilteredRows.java:74)
     at org.apache.cassandra.io.sstable.format.big.BigTableWriter.append(BigTableWriter.java:205)
     at org.apache.cassandra.io.sstable.SSTableRewriter.append(SSTableRewriter.java:125)
     at org.apache.cassandra.io.sstable.SSTableRewriter.tryAppend(SSTableRewriter.java:149)
     at org.apache.cassandra.db.compaction.Scrubber.tryAppend(Scrubber.java:343)
     at org.apache.cassandra.db.compaction.Scrubber.scrub(Scrubber.java:233)
     at org.apache.cassandra.tools.StandaloneScrubber.main(StandaloneScrubber.java:225)
     at org.apache.cassandra.tools.ToolRunner.runClassAsTool(ToolRunner.java:82)
     at org.apache.cassandra.tools.ToolRunner$2.get(ToolRunner.java:249)
     at org.apache.cassandra.tools.ToolRunner$2.get(ToolRunner.java:245)
     at org.apache.cassandra.tools.ToolRunner.invokeSupplier(ToolRunner.java:305)
     at org.apache.cassandra.tools.ToolRunner.invokeClass(ToolRunner.java:253)
     at org.apache.cassandra.tools.ToolRunner.invokeClass(ToolRunner.java:235)
     at org.apache.cassandra.db.ScrubTest.testSkipScrubCorruptedCounterRowWithTool(ScrubTest.java:811)
 Caused by: java.io.IOException: Error building row with data deserialized from RandomAccessReader:CachingRebufferer:CompressedChunkReader.Mmap(/home/vagrant/cassandra/build/test/cassandra/data/Keyspace2/Counter1-949374d48be711eb9202f742d2eeefb4/na-1-big-Data.db - SnappyCompressor, chunk length 16384, data length 65832)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeRowBody(UnfilteredSerializer.java:646)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeOne(UnfilteredSerializer.java:487)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.deserialize(UnfilteredSerializer.java:443)
     at org.apache.cassandra.io.sstable.SSTableSimpleIterator$CurrentFormatIterator.computeNext(SSTableSimpleIterator.java:84)
     at org.apache.cassandra.io.sstable.SSTableSimpleIterator$CurrentFormatIterator.computeNext(SSTableSimpleIterator.java:62)
     at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
     at org.apache.cassandra.io.sstable.SSTableIdentityIterator.hasNext(SSTableIdentityIterator.java:126)
 Caused by: java.lang.AssertionError
     at org.apache.cassandra.cache.ChunkCache$Buffer.buffer(ChunkCache.java:122)
     at org.apache.cassandra.io.util.RandomAccessReader.reBufferAt(RandomAccessReader.java:66)
     at org.apache.cassandra.io.util.RandomAccessReader.reBuffer(RandomAccessReader.java:59)
     at org.apache.cassandra.io.util.RebufferingInputStream.read(RebufferingInputStream.java:90)
     at org.apache.cassandra.io.util.RebufferingInputStream.readFully(RebufferingInputStream.java:68)
     at org.apache.cassandra.io.util.RebufferingInputStream.readFully(RebufferingInputStream.java:62)
     at org.apache.cassandra.db.marshal.ByteArrayAccessor.read(ByteArrayAccessor.java:101)
     at org.apache.cassandra.db.marshal.ByteArrayAccessor.read(ByteArrayAccessor.java:38)
     at org.apache.cassandra.db.marshal.AbstractType.read(AbstractType.java:490)
     at org.apache.cassandra.db.rows.Cell$Serializer.deserialize(Cell.java:268)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.readSimpleColumn(UnfilteredSerializer.java:655)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.lambda$deserializeRowBody$2(UnfilteredSerializer.java:620)
     at org.apache.cassandra.utils.btree.BTree.applyValue(BTree.java:1294)
     at org.apache.cassandra.utils.btree.BTree.applyLeaf(BTree.java:1302)
     at org.apache.cassandra.utils.btree.BTree.apply(BTree.java:1317)
     at org.apache.cassandra.utils.btree.BTree.apply(BTree.java:1343)
     at org.apache.cassandra.db.Columns.apply(Columns.java:390)
     at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeRowBody(UnfilteredSerializer.java:612)
{noformat}

It only happens when compression is enabled, and when the whole test class is run (i.e.; not just one or a handful of methods).;;;","23/Mar/21 16:40;aholmber;Attempted to bisect flakiness, but found this error is encountered as far back as test introduction.

https://github.com/apache/cassandra/commit/a04ccf3297839febed68c314704db4d920b64413;;;","23/Mar/21 21:18;aholmber;I think I see what's happening. Reference counting for ChunkCache buffer is [allowed to go below zero|https://github.com/apache/cassandra/blob/bf96367f4d55692017e144980cf17963e31df127/src/java/org/apache/cassandra/cache/ChunkCache.java#L135]. Then, it is possible to [find a non-zero refCount, return a non-null reference incrementing from -1 --> 0, and arrive at {{buffer}} finding references is now zero|https://github.com/apache/cassandra/blob/bf96367f4d55692017e144980cf17963e31df127/src/java/org/apache/cassandra/cache/ChunkCache.java#L111-L122].


We're getting in this state while racing with an async task which is currently closing the file:

The file is being closed as part of the tidy task:
{noformat}
[junit-timeout] 	at org.apache.cassandra.cache.ChunkCache$Buffer.release(ChunkCache.java:158)
[junit-timeout] 	at org.apache.cassandra.cache.ChunkCache.onRemoval(ChunkCache.java:187)
[junit-timeout] 	at org.apache.cassandra.cache.ChunkCache.onRemoval(ChunkCache.java:41)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$notifyRemoval$1(BoundedLocalCache.java:286)
[junit-timeout] 	at com.google.common.util.concurrent.DirectExecutor.execute(DirectExecutor.java:30)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.BoundedLocalCache.notifyRemoval(BoundedLocalCache.java:292)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.BoundedLocalCache.removeNoWriter(BoundedLocalCache.java:1731)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.BoundedLocalCache.remove(BoundedLocalCache.java:1695)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.LocalCache.invalidateAll(LocalCache.java:126)
[junit-timeout] 	at com.github.benmanes.caffeine.cache.LocalManualCache.invalidateAll(LocalManualCache.java:79)
[junit-timeout] 	at org.apache.cassandra.cache.ChunkCache.invalidateFile(ChunkCache.java:218)
[junit-timeout] 	at org.apache.cassandra.io.util.FileHandle$Cleanup.lambda$tidy$0(FileHandle.java:208)
[junit-timeout] 	at java.util.Optional.ifPresent(Optional.java:159)
[junit-timeout] 	at org.apache.cassandra.io.util.FileHandle$Cleanup.tidy(FileHandle.java:208)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref$GlobalState.release(Ref.java:325)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref$State.ensureReleased(Ref.java:203)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref.ensureReleased(Ref.java:128)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.SharedCloseableImpl.close(SharedCloseableImpl.java:45)
[junit-timeout] 	at org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier$1.run(SSTableReader.java:2058)
[junit-timeout] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
{noformat}

Which was scheduled by the previous scrub test:
{noformat}
[junit-timeout] 	at org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier.tidy(SSTableReader.java:2020)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref$GlobalState.release(Ref.java:325)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref$State.release(Ref.java:224)
[junit-timeout] 	at org.apache.cassandra.utils.concurrent.Ref.release(Ref.java:118)
[junit-timeout] 	at org.apache.cassandra.db.compaction.Scrubber.lambda$scrub$0(Scrubber.java:303)
[junit-timeout] 	at java.util.ArrayList.forEach(ArrayList.java:1257)
[junit-timeout] 	at org.apache.cassandra.db.compaction.Scrubber.scrub(Scrubber.java:303)
[junit-timeout] 	at org.apache.cassandra.tools.StandaloneScrubber.main(StandaloneScrubber.java:226)
[junit-timeout] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[junit-timeout] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[junit-timeout] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[junit-timeout] 	at java.lang.reflect.Method.invoke(Method.java:498)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner.runClassAsTool(ToolRunner.java:82)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner$2.get(ToolRunner.java:249)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner$2.get(ToolRunner.java:245)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner.invokeSupplier(ToolRunner.java:305)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner.invokeClass(ToolRunner.java:253)
[junit-timeout] 	at org.apache.cassandra.tools.ToolRunner.invokeClass(ToolRunner.java:235)
[junit-timeout] 	at org.apache.cassandra.db.ScrubTest.testHeaderFixWithTool(ScrubTest.java:874)
{noformat}

I had hoped it would be sufficient to disallow negative numbers for the ref count, but at first blush that is revealing other issues. The work goes on.;;;","24/Mar/21 09:44;bereng;Ok so the problem probably stems from the fact that {{StandaloneScrubber}} is to be used as a tool. That should be executed in it's own process hence all tidying would complete on exit with no possible races between calls.

I haven't managed to repro locally but with an internal multiplexing tool. The new push seems to solve that problem by using a different KS on each tool call hence there won't be any file races. Can you confirm if you can still repro or if it has been fixed?

Latest review comments pushed + I did trigger a new multiplexing run.;;;","24/Mar/21 13:29;adelapena;I'm still digging into it, but it seems that with the new commit I'm not able to reproduce the problem locally with compression enabled, as described by Adam (I was able before). I'm also running it in our internal multiplexer [here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/725/], using [these changes|https://github.com/adelapena/cassandra/commit/4bf0c8424b4b3f8d5c85a001f28cb61c03a252bd] in {{ant testsome}} to use compression.;;;","24/Mar/21 14:43;aholmber;Yes, I see your point about the tool. After bisecting I made the mistake of going back to trunk so I was possibly diagnosing a problem that was already addressed by your changes. Back on this branch I'm still seeing fairly regular fails, not always with an AssertionError. I'll look into it a littler more, but maybe it's not worth holding this patch since I'm the only one getting failures and it's not corroborated in the multiplexer.;;;","24/Mar/21 14:47;bereng;You are seeing fails like in the test run failing? or are you seeing exceptions around? bear in mind the test plays with corrupt sstables and does all sorts of things. So exceptions are ok, test failures are not.

[~adelapena] you can use ant target `test-compression` to the same effect and spare the build.xml changes #collaborating.;;;","24/Mar/21 15:23;bereng;Latest review comment addressed and multiplexing again just in case;;;","24/Mar/21 15:30;aholmber;{quote}You are seeing fails like in the test run failing? or are you seeing exceptions around?
{quote}
I get actual failures. Since I seem to be the only one I don't want to hold things up here.;;;","24/Mar/21 16:57;adelapena;I'm afraid there are some {{assertNotReleased}} failures of {{testScrubOutOfOrder}} in the both the multiplexer run mentioned above and in [this other run|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/729/] using {{test-compression}}.;;;","25/Mar/21 06:17;bereng;Yep I had noticed the {{testScrubOutOfOrder}} failures both in this branch _and_ in trunk. But notice how the failure for this ticket has gone away. I'd vote to merge this one and open a new ticket for {{testScrubOutOfOrder}}. I want to start merging fixes asap to see if ci-cass has indeed a problem of misreporting failures. If this failure goes away but the new one pops up then that'd be an indication it is so. Sounds ok?;;;","25/Mar/21 13:25;aholmber;On my part, I agree that merging known fixes and spinning out a different ticket is a good approach.;;;","25/Mar/21 15:38;adelapena;I suspect that those failures with {{testScrubOutOfOrder}} and compression are also related to the tests reusing the tables and calling {{clearUnsafe}}.

[In this commit|https://github.com/adelapena/cassandra/commit/b19711ac8d6f163113ba8f49762e2959996adfd7] I have tried to unify the two coexistent initialization methods ({{defineSchema}} and {{toolTestingSetup}}) into a single method annotated with JUnit's {{@Begin}}. This way every test uses its own dedicated keyspace and we don't need the calls to {{clearUnsafe}}. I have also done some minor cleaning to reduce the number of tables per keyspace and to get rid of most of the warnings across {{ScrubTest}}.

With these changes it seems that the test suite passes 400 runs in the multiplexer with compression ([here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/737/] and [here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/737/]), and 200 more runs without compression ([here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/739/]).;;;","26/Mar/21 05:25;bereng;Aha, good catch. So we just had the same problem in the other test cases as well: cross-talk at ks.cf level. I am +1 to merge everything in here specially after the 1000 runs!;;;","30/Mar/21 05:32;bereng;[~adelapena] maybe we could merge this one before rc-1 is out?;;;","30/Mar/21 10:52;adelapena;[~Bereng] I guess we can, are you going to add my [last suggested commit|https://github.com/adelapena/cassandra/commit/b19711ac8d6f163113ba8f49762e2959996adfd7] into the PR? Also, I think we could move the calls to {{disableAutocompaction}} and the setting of {{ALLOW_TOOL_REINIT_FOR_TEST}} to the {{@BeforeClass}} method, as it's done [here|https://github.com/adelapena/cassandra/commit/f8a8e8c5c3fe66270bb49100cf86620392d9e7da]. Once we have all together we can rebase and run CI one last time before committing, wdyt? ;;;","31/Mar/21 06:30;bereng;[~adelapena] I have squashed and rebased with your latest suggested commit. Unfortunately that removed your authorship info so add it back upon commit please. The multiplexing 200 runs returned green and CI runs are attached to the PR.

I have not changed location of {{disableAutocompaction}} or {{ALLOW_TOOL_REINIT_FOR_TEST}} as not all tests need it. Let me know wdyt.;;;","31/Mar/21 11:20;adelapena;{quote}I have not changed location of {{disableAutocompaction}} or {{ALLOW_TOOL_REINIT_FOR_TEST}} as not all tests need it. Let me know wdyt.
{quote}
I think there isn't a big difference between setting {{ALLOW_TOOL_REINIT_FOR_TEST}} before every test with {{@Begin}}, as it's currently done, or just once with {{@BeginClass}}. In both cases the property is set for all the tests, and not only for those tests that need it. I find using {{@BeginClass}} preferable because it saves some calls and it pairs more clearly with the {{@AfterClass}} method that resets it. If we wanted to set the property only for the tests that need it, we could restore the original {{testToolTestingEnvSetup}} initalization method [this way|https://github.com/adelapena/cassandra/commit/1db00fed784453a181ba42e09deb19686dbcafd5]. However, I think that setting it at the beginning of the class for all the tests is easier to read and it doesn't damage the tests that don't need it. Nevertheless, I don't think this is a very important detail and I'll be happy with the approach you prefer.;;;","31/Mar/21 12:54;bereng;[~adelapena] scratch that. I was referring to a previous comment of yours about moving the per-test init of those 2 params to the {{Before}} which I was against as I preferred the per-test approach. Now I have re read your latest comment about moving them to {{BeforeClass}} I think we're splitting hairs: you can argue you need a {{Before/After}} pair if any test would alter those in between, you can argue {{BeforeClass/AfterClass}} are better bc no test is doing so _yet_, you can argue a per test approach is better as it doesn't add noise to the other tests that don't need it,... pick your poison lol.

I prefer the per test approach but I don't feel strongly about it. I'd say we merge as it is or I can do the {{BeforeClass}} one if you prefer.;;;","31/Mar/21 13:52;adelapena;[~Bereng] works for me as it is. [Here|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/543/pipeline] is a final CI round in ci-cassandra before committing, just in case. Can you commit once it finishes, or should I? ;;;","31/Mar/21 14:54;bereng;I can't commit yet. I guess my iCLA will take some time to process being easter holidays :shrug:;;;","01/Apr/21 04:36;bereng;Latest CI LGTM.;;;","01/Apr/21 11:56;adelapena;CI results look good to me too. I have prepared PRs for 3.0 and 3.11 since they are affected by the flakiness problems caused by reusing tables and {{clearUnsafe}}:
 * [3.0|https://github.com/apache/cassandra/pull/947] [(CI)|https://app.circleci.com/pipelines/github/adelapena/cassandra/248/workflows/bfa3c0d3-5f3b-4508-8d75-580ce634e62c]
 * [3.11|https://github.com/apache/cassandra/pull/948] [(CI)|https://app.circleci.com/pipelines/github/adelapena/cassandra/249/workflows/26407bc5-3fb2-4aba-a3d2-e702a505e933]

If these PRs look good to you I'll proceed to commit.
  ;;;","01/Apr/21 12:19;bereng;LGTM no failures. You should have asked me and I would have done it for you :-);;;","01/Apr/21 13:20;adelapena;No worries, porting back the patch has been pretty straightforward. It seems that CI for {{ScrubTest.testScrubCorruptedCounterRow}} fails on 3.0 with compression, although that one was already marked as [72% flaky|https://ci-cassandra.apache.org/job/Cassandra-3.0/lastCompletedBuild/testReport/junit/org.apache.cassandra.db/ScrubTest/testScrubCorruptedCounterRow/] so my guess is that it fails due to a different reason, wdyt?;;;","01/Apr/21 13:26;bereng;Mmm did you start that job later than the others? That failure wasn't there first time I looked. TBH being the only failure in 3K I would like to drill a bit more see if it repros without the fix... But I'll be off tomorrow & Monday. I guess it can wait.;;;","01/Apr/21 14:55;adelapena;{quote}Mmm did you start that job later than the others? That failure wasn't there first time I looked.
{quote}
Yes, I forgot to approve the job for {{utests_compression}} so it was paused.

{{ScrubTest.testScrubCorruptedCounterRow}} with compression doesn't work locally for me in 3.0, with and without the patch. It can also be seen failing [in CI|https://ci-cassandra.apache.org/job/Cassandra-3.0/lastCompletedBuild/testReport/junit/org.apache.cassandra.db/ScrubTest/testScrubCorruptedCounterRow/] without the fix. I suspect that's probably a different problem to what we have dealt with in this ticket, specific to 3.0, so I'll be fine if we address it here or in a separate ticket to not block 4.0, as you think it's best.;;;","06/Apr/21 06:57;bereng;Hi [~adelapena] I agree with your assessment. I see the same. In any case I see that as a diff issue for a new ticket and I'd favor merging this one into 4.0 to get good CI on 4.0 asap to ease the rc work there atm. Wdyt? if you agree I can try commit this one to test my new commit permissions.;;;","06/Apr/21 10:10;adelapena;[~bereng] works for me. We probably should also create a follow up ticket for porting back the fix to 3.0 and 3.11, so we can fix the flakiness in those branches later. Alternatively we could also apply the patch here to 3.11 and trunk and let the investigation about 3.0 for the followup ticket, as you prefer. Let me know if you need any help with the commit procedure.;;;","06/Apr/21 13:10;bereng;So... given I was testing the push privileges I went for the easy option and did 4.0 only. I opened CASSANDRA-16562. I owe you a few loc bc upon commit I forgot to add you as an author, sorry, so you can take the locs for 16562 under your name as compensation lol! :-);;;","06/Apr/21 14:11;adelapena;Great, thanks for committing and creating the followup ticket. We can investigate there the additional failures in 3.0, which seem to happen with and without the patch so probably they have a different cause. Don't worry about the authorship, I feel recognised enough as reviewer :);;;",,,,,,,,,,,,,,,,,,,,,
Fix flaky test_ttl_deletions,CASSANDRA-16530,13366700,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,22/Mar/21 10:36,31/Mar/21 05:17,13/Jul/23 08:40,24/Mar/21 15:51,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"Flaky test in slow environments. See [here|https://ci-cassandra.apache.org/job/Cassandra-trunk/362/testReport/junit/dtest-novnode.paging_test/TestPagingWithDeletions/test_ttl_deletions/]",,adelapena,bereng,e.dimitrova,,,,,,,,,,,,,"bereng opened a new pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Mar/21 10:43;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r598777702



##########
File path: paging_test.py
##########
@@ -3189,7 +3189,7 @@ def check_all_paging_results(self, expected_data, pagecount, num_page_results):
                                range(0, len(expected_data), page_size)]
 
         pf = self.get_page_fetcher()
-        pf.request_all()
+        pf.request_all(timeout=60)

Review comment:
       Why did you decide to change this one?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Mar/21 14:42;githubbot;600","bereng commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r599281371



##########
File path: paging_test.py
##########
@@ -3189,7 +3189,7 @@ def check_all_paging_results(self, expected_data, pagecount, num_page_results):
                                range(0, len(expected_data), page_size)]
 
         pf = self.get_page_fetcher()
-        pf.request_all()
+        pf.request_all(timeout=60)

Review comment:
       The default timeout is 5s. In a super slow env I managed to make it fail here but only once out of many runs. The original TTL was 3s which is too close to 5s etc. So better put some distance between all timeouts as well.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Mar/21 05:33;githubbot;600","adelapena commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r599547568



##########
File path: paging_test.py
##########
@@ -3406,15 +3406,15 @@ def test_ttl_deletions(self):
         # Set TTL to all row
         for row in data:
             s = (""insert into paging_test (id, mytext, col1, col2, col3) ""
-                 ""values ({}, '{}', {}, {}, {}) using ttl 3;"").format(
+                 ""values ({}, '{}', {}, {}, {}) using ttl 15;"").format(
                 row['id'], row['mytext'], row['col1'],
                 row['col2'], row['col3'])
             self.session.execute(
                 SimpleStatement(s, consistency_level=CL.ALL)
             )
         self.check_all_paging_results(data, 8,
                                       [25, 25, 25, 25, 25, 25, 25, 25])
-        time.sleep(5)
+        time.sleep(15)

Review comment:
       Besides incrementing the time, I like the idea of waiting exactly the TTL time. Perhaps we could make that more obvious by putting the TTL in a var, to be used both in the queries and in the sleep:
   ```python
   ttl_seconds = 15
   for row in data:
       s = (""insert into paging_test (id, mytext, col1, col2, col3) ""
            ""values ({}, '{}', {}, {}, {}) using ttl {}"").format(
           row['id'], row['mytext'], row['col1'], row['col2'], row['col3'], ttl_seconds)
       self.session.execute(SimpleStatement(s, consistency_level=CL.ALL))
   self.check_all_paging_results(data, 8, [25, 25, 25, 25, 25, 25, 25, 25])
   time.sleep(ttl_seconds)
   self.check_all_paging_results([], 0, [])
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Mar/21 13:04;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r599547834



##########
File path: paging_test.py
##########
@@ -3189,7 +3189,7 @@ def check_all_paging_results(self, expected_data, pagecount, num_page_results):
                                range(0, len(expected_data), page_size)]
 
         pf = self.get_page_fetcher()
-        pf.request_all()
+        pf.request_all(timeout=60)

Review comment:
       I don't see this one being default 5s? What do I miss? The other one is clear
   
       ```
   def request_all(self, timeout=None):
           """"""
           Requests any remaining pages.
   
           If the future is exhausted, this is a no-op.
           @param timeout Time, in seconds, to wait for all pages.    def request_all(self, timeout=None):
           """"""
           Requests any remaining pages.
   
           If the future is exhausted, this is a no-op.
           @param timeout Time, in seconds, to wait for all pages.
   ```




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Mar/21 13:04;githubbot;600","adelapena commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r599554788



##########
File path: paging_test.py
##########
@@ -3189,7 +3189,7 @@ def check_all_paging_results(self, expected_data, pagecount, num_page_results):
                                range(0, len(expected_data), page_size)]
 
         pf = self.get_page_fetcher()
-        pf.request_all()
+        pf.request_all(timeout=60)

Review comment:
       @ekaterinadimitrova2 I think the 5s default is [here](https://github.com/apache/cassandra-dtest/blob/trunk/tools/paging.py#L106), although it's not very clear nor documented, and possibly it would be preferable to use Python defaults.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Mar/21 13:14;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r599559345



##########
File path: paging_test.py
##########
@@ -3189,7 +3189,7 @@ def check_all_paging_results(self, expected_data, pagecount, num_page_results):
                                range(0, len(expected_data), page_size)]
 
         pf = self.get_page_fetcher()
-        pf.request_all()
+        pf.request_all(timeout=60)

Review comment:
       Oh I see; thank you for pointing it to me. Yes, it sounds a bit weird; I would probably just change the None to 5s default or use Python defaults as you mentioned. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Mar/21 13:19;githubbot;600","adelapena commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r599564934



##########
File path: paging_test.py
##########
@@ -3189,7 +3189,7 @@ def check_all_paging_results(self, expected_data, pagecount, num_page_results):
                                range(0, len(expected_data), page_size)]
 
         pf = self.get_page_fetcher()
-        pf.request_all()
+        pf.request_all(timeout=60)

Review comment:
       If the new query timeout is 60s, it might happen that the first query requesting the rows before waiting for the TTL gets them after they have expired. So perhaps it would make sense to use a TTL that is greater than the first query timeout, possibly adding a timeout argument to `check_all_paging_results`, wdyt?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Mar/21 13:26;githubbot;600","adelapena commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r599564934



##########
File path: paging_test.py
##########
@@ -3189,7 +3189,7 @@ def check_all_paging_results(self, expected_data, pagecount, num_page_results):
                                range(0, len(expected_data), page_size)]
 
         pf = self.get_page_fetcher()
-        pf.request_all()
+        pf.request_all(timeout=60)

Review comment:
       If the new query timeout is 60s, it might happen that the first query requesting the rows before waiting for the TTL gets them after they have expired. So perhaps it would make sense to use a TTL that is greater or equal than the first query timeout, possibly adding a timeout argument to `check_all_paging_results` which value in `test_ttl_deletions` could be the TTL, wdyt?




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Mar/21 13:31;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r599622788



##########
File path: paging_test.py
##########
@@ -3189,7 +3189,7 @@ def check_all_paging_results(self, expected_data, pagecount, num_page_results):
                                range(0, len(expected_data), page_size)]
 
         pf = self.get_page_fetcher()
-        pf.request_all()
+        pf.request_all(timeout=60)

Review comment:
       Sounds reasonable to me




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Mar/21 14:31;githubbot;600","bereng commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r600185567



##########
File path: paging_test.py
##########
@@ -3406,15 +3406,15 @@ def test_ttl_deletions(self):
         # Set TTL to all row
         for row in data:
             s = (""insert into paging_test (id, mytext, col1, col2, col3) ""
-                 ""values ({}, '{}', {}, {}, {}) using ttl 3;"").format(
+                 ""values ({}, '{}', {}, {}, {}) using ttl 15;"").format(
                 row['id'], row['mytext'], row['col1'],
                 row['col2'], row['col3'])
             self.session.execute(
                 SimpleStatement(s, consistency_level=CL.ALL)
             )
         self.check_all_paging_results(data, 8,
                                       [25, 25, 25, 25, 25, 25, 25, 25])
-        time.sleep(5)
+        time.sleep(15)

Review comment:
       +1




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Mar/21 05:32;githubbot;600","bereng commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r600189705



##########
File path: paging_test.py
##########
@@ -3189,7 +3189,7 @@ def check_all_paging_results(self, expected_data, pagecount, num_page_results):
                                range(0, len(expected_data), page_size)]
 
         pf = self.get_page_fetcher()
-        pf.request_all()
+        pf.request_all(timeout=60)

Review comment:
       I'm not following fully. Ping me on Slack when you're online. I don't see a problem in returning a 'snapshot' of how things were _at query time_. If rows TTL mid-way through the query execution I don't care. I care about the time between insert and query being less than TTL.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Mar/21 05:45;githubbot;600","adelapena commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r600381026



##########
File path: paging_test.py
##########
@@ -3189,7 +3189,7 @@ def check_all_paging_results(self, expected_data, pagecount, num_page_results):
                                range(0, len(expected_data), page_size)]
 
         pf = self.get_page_fetcher()
-        pf.request_all()
+        pf.request_all(timeout=60)

Review comment:
       Just ignore me. I was wrong interpreting how pagination is done. I thought that the subqueries for each page in the first query were going to have its own timestamp, so for example a paged query with a timestamp=1 would generate subqueries with timestamp=1, timestamp=1+n, etc. This would lead to paging subqueries starting too late to be sure of getting the rows before the TTL expiration. Fortunately it seems that the pager implementation is much clever than that and it uses the same timestamp for all the subqueries in a paged query, so this is not a problem.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Mar/21 11:10;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131#discussion_r600459256



##########
File path: paging_test.py
##########
@@ -3189,7 +3189,7 @@ def check_all_paging_results(self, expected_data, pagecount, num_page_results):
                                range(0, len(expected_data), page_size)]
 
         pf = self.get_page_fetcher()
-        pf.request_all()
+        pf.request_all(timeout=60)

Review comment:
       :D Seems I made the same mistake 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;24/Mar/21 13:07;githubbot;600","bereng closed pull request #131:
URL: https://github.com/apache/cassandra-dtest/pull/131


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;31/Mar/21 05:17;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,9000,,,0,9000,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Mar 24 15:51:10 UTC 2021,,,,,,,All,,,,"0|z0p1gw:",9223372036854775807,,,,adelapena,e.dimitrova,,,Normal,,,,https://github.com/apache/cassandra-dtest/commit/49f46fce94c8f25f32e9b778ded8b14c30ad851e,,,,,,,,,Tested locally as repro'ing is only possible on slow enviroments,,,,,"22/Mar/21 10:45;bereng;The issue only reproduces on slow environments where fetching the results can miss some rows bc TTL has already kicked in. Increasing the TLL window fixes the issue.;;;","24/Mar/21 13:41;e.dimitrova;+1 from me, thank you;;;","24/Mar/21 14:11;adelapena;Looks good to me too, +1;;;","24/Mar/21 15:51;e.dimitrova;Patch committed [here|https://github.com/apache/cassandra-dtest/commit/49f46fce94c8f25f32e9b778ded8b14c30ad851e]. Thank you;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-stress fails when node with port specified,CASSANDRA-16529,13366403,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aholmber,aholmber,aholmber,19/Mar/21 17:06,31/Jul/21 21:35,13/Jul/23 08:40,19/Mar/21 20:28,4.0,4.0-rc1,,,,,,Tool/stress,,,,0,,,"When running {{cassandra-stress .... -node 127.0.0.1:53439}}

{noformat}
java.lang.RuntimeException: java.lang.IllegalArgumentException: Failed to add contact point: 127.0.0.1:53439
	at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:146)
	at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:114)
	at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpaces(SettingsSchema.java:66)
	at org.apache.cassandra.stress.settings.StressSettings.maybeCreateKeyspaces(StressSettings.java:154)
	at org.apache.cassandra.stress.StressAction.run(StressAction.java:56)
	at org.apache.cassandra.stress.Stress.run(Stress.java:155)
	at org.apache.cassandra.stress.Stress.main(Stress.java:63)
Caused by: java.lang.IllegalArgumentException: Failed to add contact point: 127.0.0.1:53439
	at com.datastax.driver.core.Cluster$Builder.addContactPoint(Cluster.java:943)
	at org.apache.cassandra.stress.util.JavaDriverClient.connect(JavaDriverClient.java:134)
	at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:137)
	... 6 more
Caused by: java.net.UnknownHostException: 127.0.0.1:53439: invalid IPv6 address
	at java.net.InetAddress.getAllByName(InetAddress.java:1170)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at com.datastax.driver.core.Cluster$Builder.addContactPoint(Cluster.java:939)
	... 8 more
{noformat}

It may work using {{-port native=53439}}, but that would not be suitable for {{-node ... whitelist}} when nodes are on different ports.

I'm not sure if {{host:port}} ever worked here, but {{ccm}} [seems to think it should|https://github.com/riptano/ccm/blob/6a519280e1775fe8777f93310b93b3ccb1ffd976/ccmlib/cluster.py#L645], and it's handled [elsewhere|https://github.com/apache/cassandra/blob/c591978f4d265e42d0132418005ba63a99278c75/tools/stress/src/org/apache/cassandra/stress/settings/SettingsNode.java#L102] in the tool.",,aholmber,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,aholmber,,,,,,,,,,,,,Correctness -> API / Semantic Implementation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Mar 19 21:04:36 UTC 2021,,,,,,,All,,,,"0|z0ozmw:",9223372036854775807,,,,brandon.williams,,,,Low,,4.0-alpha4,,https://github.com/apache/cassandra/commit/932b0a483eb9f7cfd23b29cb90b328e1825a02bc,,,,,,,,,unit test added,,,,,"19/Mar/21 18:39;aholmber;[patch|https://github.com/aholmberg/cassandra/pull/48]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16529]

And if this works out I have a [patch for ccm|https://github.com/aholmberg/ccm/commit/1b26d2e214ef1003bb9b395d149e132ea4fb79b0] that I would appreciate someone taking a look at (it's what led me to this in the first place). I haven't created a PR yet because I need this fix for ccm CI to pass.;;;","19/Mar/21 20:28;brandon.williams;Committed, thanks.;;;","19/Mar/21 21:04;aholmber;Thanks. 
ccm PR for your consideration: https://github.com/riptano/ccm/pull/731;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flaky ValidationExecutorTest,CASSANDRA-16527,13366280,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,19/Mar/21 08:41,19/May/21 06:01,13/Jul/23 08:40,26/Mar/21 10:51,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"Flaky ValidationExecutorTest see [here|https://ci-cassandra.apache.org/job/Cassandra-trunk/347/testReport/junit/org.apache.cassandra.db.compaction/ValidationExecutorTest/testQueueOnValidationSubmission_cdc/]",,adelapena,bereng,blerer,,,,,,,,,,,,,"bereng opened a new pull request #938:
URL: https://github.com/apache/cassandra/pull/938


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Mar/21 08:48;githubbot;600","bereng commented on pull request #938:
URL: https://github.com/apache/cassandra/pull/938#issuecomment-802726101


   CI [j11](https://app.circleci.com/pipelines/github/bereng/cassandra/233/workflows/0cdd8f63-dd07-4a7f-a8f8-21075ad51c08)
   CI [j8](https://app.circleci.com/pipelines/github/bereng/cassandra/233/workflows/f745e881-e832-4c30-b138-fcf79dc6441d)


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Mar/21 10:34;githubbot;600","blerer commented on a change in pull request #938:
URL: https://github.com/apache/cassandra/pull/938#discussion_r597599394



##########
File path: test/unit/org/apache/cassandra/db/compaction/ValidationExecutorTest.java
##########
@@ -79,7 +80,16 @@ public void testQueueOnValidationSubmission() throws InterruptedException
         while (threadsAvailable.get() > 0)
             TimeUnit.MILLISECONDS.sleep(10);
 
-        assertEquals(2, validationExecutor.getActiveTaskCount());
+        // getActiveTaskCount() relies on getActiveCount() which gives an approx number so we poll it
+        boolean activeTasksOk = false;
+        for (int i = 0; i < 100 && !activeTasksOk; i++)
+        {
+            TimeUnit.MILLISECONDS.sleep(10);
+            activeTasksOk = validationExecutor.getActiveTaskCount() == 2;
+        }
+        if (!activeTasksOk)
+            fail();
+

Review comment:
       The project as already an utility to perform that kind of check `Util.spinAssertEquals`. To see an example you can have a look into `ThreadPoolMetricsTest `




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Mar/21 11:17;githubbot;600","bereng commented on a change in pull request #938:
URL: https://github.com/apache/cassandra/pull/938#discussion_r597617766



##########
File path: test/unit/org/apache/cassandra/db/compaction/ValidationExecutorTest.java
##########
@@ -79,7 +80,16 @@ public void testQueueOnValidationSubmission() throws InterruptedException
         while (threadsAvailable.get() > 0)
             TimeUnit.MILLISECONDS.sleep(10);
 
-        assertEquals(2, validationExecutor.getActiveTaskCount());
+        // getActiveTaskCount() relies on getActiveCount() which gives an approx number so we poll it
+        boolean activeTasksOk = false;
+        for (int i = 0; i < 100 && !activeTasksOk; i++)
+        {
+            TimeUnit.MILLISECONDS.sleep(10);
+            activeTasksOk = validationExecutor.getActiveTaskCount() == 2;
+        }
+        if (!activeTasksOk)
+            fail();
+

Review comment:
       +1 TIL




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Mar/21 11:51;githubbot;600","bereng commented on a change in pull request #938:
URL: https://github.com/apache/cassandra/pull/938#discussion_r597617766



##########
File path: test/unit/org/apache/cassandra/db/compaction/ValidationExecutorTest.java
##########
@@ -79,7 +80,16 @@ public void testQueueOnValidationSubmission() throws InterruptedException
         while (threadsAvailable.get() > 0)
             TimeUnit.MILLISECONDS.sleep(10);
 
-        assertEquals(2, validationExecutor.getActiveTaskCount());
+        // getActiveTaskCount() relies on getActiveCount() which gives an approx number so we poll it
+        boolean activeTasksOk = false;
+        for (int i = 0; i < 100 && !activeTasksOk; i++)
+        {
+            TimeUnit.MILLISECONDS.sleep(10);
+            activeTasksOk = validationExecutor.getActiveTaskCount() == 2;
+        }
+        if (!activeTasksOk)
+            fail();
+

Review comment:
       +1 TIL. Passes 10K runs locally.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Mar/21 11:52;githubbot;600","adelapena commented on a change in pull request #938:
URL: https://github.com/apache/cassandra/pull/938#discussion_r597928288



##########
File path: test/unit/org/apache/cassandra/db/compaction/ValidationExecutorTest.java
##########
@@ -30,11 +30,13 @@
 import org.junit.Before;
 import org.junit.Test;
 
+import org.apache.cassandra.Util;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.utils.concurrent.SimpleCondition;
 
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.fail;

Review comment:
       Nit: unused import after using `spinAssertEquals`.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Mar/21 19:41;githubbot;600","bereng commented on a change in pull request #938:
URL: https://github.com/apache/cassandra/pull/938#discussion_r598440866



##########
File path: test/unit/org/apache/cassandra/db/compaction/ValidationExecutorTest.java
##########
@@ -30,11 +30,13 @@
 import org.junit.Before;
 import org.junit.Test;
 
+import org.apache.cassandra.Util;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.utils.concurrent.SimpleCondition;
 
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.fail;

Review comment:
       Pushed fixed imports thx!




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Mar/21 05:54;githubbot;600","bereng closed pull request #938:
URL: https://github.com/apache/cassandra/pull/938


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/May/21 06:01;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,4800,,,0,4800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Mar 26 10:51:37 UTC 2021,,,,,,,All,,,,"0|z0oyvk:",9223372036854775807,,,,adelapena,blerer,,,Normal,,4.0-beta1,,https://github.com/apache/cassandra/commit/453a763b6e3fc04f4d647e6c9a923875411f8007,,,,,,,,,See PR,,,,,"19/Mar/21 08:52;bereng;The problem was that the assert relied on a number which was an [approximation|https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html#getActiveCount--] of the value we needed. The fix is to either remove that assert or to poll the value. I chose the later for no particular reason and it passes locally now 10K runs whereas it would fail before.;;;","23/Mar/21 12:26;adelapena;Looks good to me, +1.

CI runs:
* [CircleCI j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/234/workflows/9af48036-87ac-4614-8510-0c636fd1d207]
* [CircleCI j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/234/workflows/c0fb5ead-bcf7-407b-9544-f8df89e62e1b]
* [Jenkins|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/506/pipeline]
 ;;;","26/Mar/21 06:23;bereng;I guess we can merge this now?;;;","26/Mar/21 10:29;blerer;I will take care of it.;;;","26/Mar/21 10:51;blerer;Committed into trunk at 453a763b6e3fc04f4d647e6c9a923875411f8007;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BinLogTest is flaky,CASSANDRA-16526,13366101,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,18/Mar/21 14:38,25/Apr/21 11:23,13/Jul/23 08:40,30/Mar/21 00:00,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"Probably due to increasing the runners:

{noformat}
java.lang.RuntimeException: java.lang.IllegalStateException: Expected file to exist for cycle: 1616021848, file: /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test-compression/jdk/jdk_11_latest/label/cassandra/tmp/foo17bar/20210317-225728T.cq4.
minCycle: 1616021850, maxCycle: 1616021852
Available files: [20210317-225730T.cq4, 20210317-225732T.cq4]
	at org.apache.cassandra.utils.binlog.BinLogTest.readBinLogRecords(BinLogTest.java:492)
	at org.apache.cassandra.utils.binlog.BinLogTest.lambda$testTrucationReleasesLogSpace$8(BinLogTest.java:444)
	at org.apache.cassandra.Util.spinAssertEquals(Util.java:605)
	at org.apache.cassandra.Util.spinAssertEquals(Util.java:595)
	at org.apache.cassandra.utils.binlog.BinLogTest.testTrucationReleasesLogSpace(BinLogTest.java:444)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Caused by: java.lang.IllegalStateException: Expected file to exist for cycle: 1616021848, file: /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test-compression/jdk/jdk_11_latest/label/cassandra/tmp/foo17bar/20210317-225728T.cq4.
minCycle: 1616021850, maxCycle: 1616021852
Available files: [20210317-225730T.cq4, 20210317-225732T.cq4]
	at net.openhft.chronicle.queue.impl.single.SingleChronicleQueue$StoreSupplier.nextCycle(SingleChronicleQueue.java:1157)
	at net.openhft.chronicle.queue.impl.WireStorePool.nextCycle(WireStorePool.java:66)
	at net.openhft.chronicle.queue.impl.single.SingleChronicleQueue.nextCycle(SingleChronicleQueue.java:507)
	at net.openhft.chronicle.queue.impl.single.StoreTailer.nextIndexWithNextAvailableCycle(StoreTailer.java:507)
	at net.openhft.chronicle.queue.impl.single.StoreTailer.endOfCycle(StoreTailer.java:323)
	at net.openhft.chronicle.queue.impl.single.StoreTailer.next0(StoreTailer.java:295)
	at net.openhft.chronicle.queue.impl.single.StoreTailer.readingDocument(StoreTailer.java:202)
	at net.openhft.chronicle.queue.impl.single.StoreTailer.readDocument(StoreTailer.java:108)
	at org.apache.cassandra.utils.binlog.BinLogTest.readBinLogRecords(BinLogTest.java:481)
{noformat}",,e.dimitrova,yifanc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Degradation,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 30 00:00:07 UTC 2021,,,,,,,All,,,,"0|z0oxrs:",9223372036854775807,,,,ycai,,,,Normal,,NA,,https://github.com/apache/cassandra/commit/d421e82ee0ffd66d3f382bfbe0b69b7b275edce3,,,,,,,,,run the test a lot,,,,,"22/Mar/21 18:29;brandon.williams;Though CI only has the [one failure|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/497/tests] it doesn't really have enough history to see what's happened here.  Hoping I could bisect, I tried to find a good revision, but even the fix for the last time it was flaky in CASSANDRA-15797 does not pass 100 iterations on either j11 or j8 on multiple machines with just a single test runner.  It doesn't seem like this could have been failing sporadically for this long and been lost in the noise each time, but I don't have any other explanation at this point.;;;","24/Mar/21 18:02;brandon.williams;Checking nightlies, there is one other failure from November 9th of last year:

{noformat}
      <testcase classname=""org.apache.cassandra.utils.binlog.BinLogTest"" name=""testTrucationReleasesLogSpace-cdc"" time=""5.043"">
          <failure message=""missing currentCycle, file=/home/jenkins/jenkins-slave/workspace/Cassandra-trunk-test-cdc/jdk/jdk_1.8_latest/label/cassandra/tmp/foo17bar/20201109-222009.cq4"" type=""junit.framework.A
ssertionFailedError"">junit.framework.AssertionFailedError: missing currentCycle, file=/home/jenkins/jenkins-slave/workspace/Cassandra-trunk-test-cdc/jdk/jdk_1.8_latest/label/cassandra/tmp/foo17bar/20201109-2220
09.cq4
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueue$StoreSupplier.nextCycle(SingleChronicleQueue.java:931)
        at net.openhft.chronicle.queue.impl.WireStorePool.nextCycle(WireStorePool.java:106)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueue.nextCycle(SingleChronicleQueue.java:412)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueExcerpts$StoreTailer.nextIndexWithNextAvailableCycle0(SingleChronicleQueueExcerpts.java:1509)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueExcerpts$StoreTailer.nextIndexWithNextAvailableCycle(SingleChronicleQueueExcerpts.java:1465)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueExcerpts$StoreTailer.endOfCycle(SingleChronicleQueueExcerpts.java:1255)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueExcerpts$StoreTailer.next0(SingleChronicleQueueExcerpts.java:1230)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueExcerpts$StoreTailer.readingDocument(SingleChronicleQueueExcerpts.java:1175)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueExcerpts$StoreTailer.readDocument(SingleChronicleQueueExcerpts.java:1096)
        at org.apache.cassandra.utils.binlog.BinLogTest.readBinLogRecords(BinLogTest.java:481)
        at org.apache.cassandra.utils.binlog.BinLogTest.lambda$testTrucationReleasesLogSpace$8(BinLogTest.java:444)
        at org.apache.cassandra.Util.spinAssertEquals(Util.java:599)
        at org.apache.cassandra.Util.spinAssertEquals(Util.java:589)
        at org.apache.cassandra.utils.binlog.BinLogTest.testTrucationReleasesLogSpace(BinLogTest.java:444)
</failure>
{noformat}
;;;","29/Mar/21 21:18;brandon.williams;What I've determined is that any of these tests can run together in the suite with no problem, as long as testPut and/or testOffer are not mixed with the truncation test, and even then most of time nothing fails.

But every once in a while, through no fault of their own, these tests seem to confuse Chronicle when it goes to read logs in testTrucationReleasesLogSpace, where it sometimes expects to see a file _that it deleted itself_.  Since these work fine in isolation and the failure is quite rare, I've taken the route of running it twice under the flakyTest handler so that a failure one time is tolerated.  The patch also modernizes the temporary directory creation and fixes the 'trucation' typo in the test name.

[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/530/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/530/pipeline]
;;;","29/Mar/21 22:43;yifanc;The approach is sensible.

+1

It is very hard to reproduce. I have loop'd the test for over 100 times but still failed to reproduce.

There is a shared {{QueueFileShrinkManager}} in the chronicle queue internal. Whenever the file rolls to the next cycle, it schedules an async shrinking task that often runs after the test is finished. Maybe it has something to do with the failed test. (I have not looked deep into it.) It is probably worthy to make the shrink task synchronized to run it as part of the test. However, with the change proposed, I need to increase the sleep time in the {{testTrucationReleasesLogSpace}} from 2 seconds to 4 seconds.;;;","30/Mar/21 00:00;brandon.williams;Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gossip STATUS can be either missing during upgrade or stale after upgrade,CASSANDRA-16525,13365655,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,yifanc,yifanc,yifanc,16/Mar/21 22:56,16/Mar/22 15:36,13/Jul/23 08:40,19/Mar/21 15:57,4.0,4.0-rc1,,,,,,Cluster/Gossip,,,,0,,,"In 4.0, new application states are added in Gossip and the corresponding old ones are deprecated, e.g. {{STATUS}} and the successor {{STATUS_WITH_PORT}}.

There are 2 issues discovered by the jvm (upgrade) dtest. First, the {{STATUS}} field of a peer in the lower version (e.g. 3.0) node can be missing. Second, it is possible the {{STATUS}} coexist with the new state {{STATUS_WITH_PORT}} in the 4.0 nodes after cluster is fully upgraded and the {{STATUS}} field can becomes stale as the 4.0 node filters out when applying new state.

The first issue can happen in this scenario. During upgrade, node1 and node2 are in v4, and node3 is still in v3. If node3 only gets the gossip info regarding node2 from node1, the {{STATUS}} field of node2 will be missing in node3's local state, which is unexpected. There could be many reasons that node3 does not exchange gossip with node2 directly, e.g. network issue between node2 and node3, or node2 simply does not select node3 when initiating the gossip round. Gossip should be resilient to it. I have a [jvm upgrade dtest|https://github.com/yifan-c/cassandra/blob/CASSANDRA-16525/trunk/test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeGossipTest.java#L81] to demonstrate the unexpected behavior.

The cause of the second issue is more subtle. Heartbeat update happens as part of the Gossip task and outside of the GossipStage. When node2 just update its local application state and received a {{SYN}} from node1, node 2 just replies its gossip state without updating the heartbeat version. When node1 receives it, it first filters out the legacy {{STATUS}} field, and only saves the new one. So far so good. However, node2 soon updates its heart beat, and node1 realizes that its local version is less than the remove (node2) version in the next gossip round. So node2 sends {{STATUS}} along to node1. Because it does not come together with the new field, node1 does not filter it out when receiving. Boo! Node1 now has the {{STATUS}} field from node2. Such field can become stale and diverge with its successor in a live cluster. The jvm upgrade test [testStatusFieldShouldExistInOldVersionNodes|https://github.com/yifan-c/cassandra/blob/CASSANDRA-16525/trunk/test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeGossipTest.java#L47] can fairly easy to reproduce it when the entire cluster is upgraded. And there is another jvm dtest (with source changes to help make deterministic result, see the attached Demonstrate-a-scenario-that-a-node-may-hold-the-stale-status.patch) that demonstrates the {{STATUS}} can be replicated to the peer and become stale.

The fix is to 
 1) retain the legacy fields if the cluster is still in mixed mode
 2) remove the legacy field when cluster is fully upgraded",,brandon.williams,mck,yifanc,,,,,,,,,,,,,"yifan-c opened a new pull request #932:
URL: https://github.com/apache/cassandra/pull/932


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 23:05;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r596190844



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -1459,6 +1469,11 @@ private static EndpointState removeRedundantApplicationStates(EndpointState remo
             return remoteState;
 
         Map<ApplicationState, VersionedValue> updatedStates = remoteState.states().stream().filter(entry -> {
+            if (Gossiper.instance.hasMajorVersion3Nodes())
+            {
+                return true;
+            }
+

Review comment:
       what about instead exiting the method immediately…
   ```
   
       private static EndpointState removeRedundantApplicationStates(EndpointState remoteState)
       {
           if (remoteState.states().isEmpty() || Gossiper.instance.hasMajorVersion3Nodes())
               return remoteState;
   
           Map<ApplicationState, VersionedValue> updatedStates = remoteState.states().stream().filter(entry -> {
               // Filter out pre-4.0 versions of data for more complete 4.0 versions
               switch (entry.getKey())
               {
                   case INTERNAL_IP:
                       return (null == remoteState.getApplicationState(ApplicationState.INTERNAL_ADDRESS_AND_PORT));
                   case STATUS:
                       return (null == remoteState.getApplicationState(ApplicationState.STATUS_WITH_PORT));
                   case RPC_ADDRESS:
                       return (null == remoteState.getApplicationState(ApplicationState.NATIVE_ADDRESS_AND_PORT));
                   default:
                       return true;
               }
           }).collect(Collectors.toMap(Entry::getKey, Entry::getValue));
   
           EndpointState updated = new EndpointState(remoteState.getHeartBeatState(), updatedStates);
           if (!remoteState.isAlive()) updated.markDead();
           return updated;
       }
   ```




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Mar/21 16:34;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r596190844



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -1459,6 +1469,11 @@ private static EndpointState removeRedundantApplicationStates(EndpointState remo
             return remoteState;
 
         Map<ApplicationState, VersionedValue> updatedStates = remoteState.states().stream().filter(entry -> {
+            if (Gossiper.instance.hasMajorVersion3Nodes())
+            {
+                return true;
+            }
+

Review comment:
       what about instead exiting the method immediately…
   ```
   
       private EndpointState removeRedundantApplicationStates(EndpointState remoteState)
       {
           if (remoteState.states().isEmpty() || hasMajorVersion3Nodes())
               return remoteState;
   
           Map<ApplicationState, VersionedValue> updatedStates = remoteState.states().stream().filter(entry -> {
               // Filter out pre-4.0 versions of data for more complete 4.0 versions
               switch (entry.getKey())
               {
                   case INTERNAL_IP:
                       return (null == remoteState.getApplicationState(ApplicationState.INTERNAL_ADDRESS_AND_PORT));
                   case STATUS:
                       return (null == remoteState.getApplicationState(ApplicationState.STATUS_WITH_PORT));
                   case RPC_ADDRESS:
                       return (null == remoteState.getApplicationState(ApplicationState.NATIVE_ADDRESS_AND_PORT));
                   default:
                       return true;
               }
           }).collect(Collectors.toMap(Entry::getKey, Entry::getValue));
   
           EndpointState updated = new EndpointState(remoteState.getHeartBeatState(), updatedStates);
           if (!remoteState.isAlive()) updated.markDead();
           return updated;
       }
   ```




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Mar/21 16:39;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r596190844



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -1459,6 +1469,11 @@ private static EndpointState removeRedundantApplicationStates(EndpointState remo
             return remoteState;
 
         Map<ApplicationState, VersionedValue> updatedStates = remoteState.states().stream().filter(entry -> {
+            if (Gossiper.instance.hasMajorVersion3Nodes())
+            {
+                return true;
+            }
+

Review comment:
       what about instead exiting the method immediately, and making it non-static now…
   ```
   
       private EndpointState removeRedundantApplicationStates(EndpointState remoteState)
       {
           if (remoteState.states().isEmpty() || hasMajorVersion3Nodes())
               return remoteState;
   
           Map<ApplicationState, VersionedValue> updatedStates = remoteState.states().stream().filter(entry -> {
               // Filter out pre-4.0 versions of data for more complete 4.0 versions
               switch (entry.getKey())
               {
                   case INTERNAL_IP:
                       return (null == remoteState.getApplicationState(ApplicationState.INTERNAL_ADDRESS_AND_PORT));
                   case STATUS:
                       return (null == remoteState.getApplicationState(ApplicationState.STATUS_WITH_PORT));
                   case RPC_ADDRESS:
                       return (null == remoteState.getApplicationState(ApplicationState.NATIVE_ADDRESS_AND_PORT));
                   default:
                       return true;
               }
           }).collect(Collectors.toMap(Entry::getKey, Entry::getValue));
   
           EndpointState updated = new EndpointState(remoteState.getHeartBeatState(), updatedStates);
           if (!remoteState.isAlive()) updated.markDead();
           return updated;
       }
   ```




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Mar/21 16:39;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r596601435



##########
File path: src/java/org/apache/cassandra/gms/EndpointState.java
##########
@@ -114,6 +128,47 @@ public void addApplicationStates(Set<Map.Entry<ApplicationState, VersionedValue>
         }
     }
 
+    void removeMajorVersion3LegacyApplicationStates()
+    {
+        while (hasLegacyFields())
+        {
+            Map<ApplicationState, VersionedValue> orig = applicationState.get();
+            Map<ApplicationState, VersionedValue> updatedStates = filterMajorVersion3LegacyApplicationStates(orig);
+            // avoid updating if no state is removed
+            if (orig.size() == updatedStates.size()
+                || applicationState.compareAndSet(orig, updatedStates))

Review comment:
       ```suggestion
               assert orig.size() != updatedStates.size();
               if (applicationState.compareAndSet(orig, updatedStates))
   ```




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 07:13;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r596603536



##########
File path: src/java/org/apache/cassandra/gms/EndpointState.java
##########
@@ -20,17 +20,26 @@
 import java.io.*;
 import java.util.*;
 import java.util.concurrent.atomic.AtomicReference;
+import java.util.stream.Collectors;
 
 import javax.annotation.Nullable;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
+
 import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
 import org.apache.cassandra.utils.CassandraVersion;
 
+import static org.apache.cassandra.gms.ApplicationState.INTERNAL_ADDRESS_AND_PORT;
+import static org.apache.cassandra.gms.ApplicationState.INTERNAL_IP;
+import static org.apache.cassandra.gms.ApplicationState.NATIVE_ADDRESS_AND_PORT;
+import static org.apache.cassandra.gms.ApplicationState.RPC_ADDRESS;
+import static org.apache.cassandra.gms.ApplicationState.STATUS;
+import static org.apache.cassandra.gms.ApplicationState.STATUS_WITH_PORT;

Review comment:
       can we not do this please. it makes the patch bigger than it needs to be, changing the style of the class unnecessarily.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 07:17;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r596603859



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -65,6 +65,12 @@
 import org.apache.cassandra.utils.JVMStabilityInspector;
 
 import static org.apache.cassandra.config.CassandraRelevantProperties.GOSSIPER_QUARANTINE_DELAY;
+import static org.apache.cassandra.gms.ApplicationState.INTERNAL_ADDRESS_AND_PORT;
+import static org.apache.cassandra.gms.ApplicationState.INTERNAL_IP;
+import static org.apache.cassandra.gms.ApplicationState.NATIVE_ADDRESS_AND_PORT;
+import static org.apache.cassandra.gms.ApplicationState.RPC_ADDRESS;
+import static org.apache.cassandra.gms.ApplicationState.STATUS;
+import static org.apache.cassandra.gms.ApplicationState.STATUS_WITH_PORT;

Review comment:
       can we not do this please. it makes the patch bigger than it needs to be, changing the style of the class unnecessarily. (i'd rather the few long lines)




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 07:18;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r596603536



##########
File path: src/java/org/apache/cassandra/gms/EndpointState.java
##########
@@ -20,17 +20,26 @@
 import java.io.*;
 import java.util.*;
 import java.util.concurrent.atomic.AtomicReference;
+import java.util.stream.Collectors;
 
 import javax.annotation.Nullable;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
+
 import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
 import org.apache.cassandra.utils.CassandraVersion;
 
+import static org.apache.cassandra.gms.ApplicationState.INTERNAL_ADDRESS_AND_PORT;
+import static org.apache.cassandra.gms.ApplicationState.INTERNAL_IP;
+import static org.apache.cassandra.gms.ApplicationState.NATIVE_ADDRESS_AND_PORT;
+import static org.apache.cassandra.gms.ApplicationState.RPC_ADDRESS;
+import static org.apache.cassandra.gms.ApplicationState.STATUS;
+import static org.apache.cassandra.gms.ApplicationState.STATUS_WITH_PORT;

Review comment:
       can we not do this please. it makes the patch bigger than it needs to be, changing the style of the class unnecessarily.  (i'd rather the few long lines)




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 07:18;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r596605116



##########
File path: src/java/org/apache/cassandra/gms/EndpointState.java
##########
@@ -114,6 +128,47 @@ public void addApplicationStates(Set<Map.Entry<ApplicationState, VersionedValue>
         }
     }
 
+    void removeMajorVersion3LegacyApplicationStates()
+    {
+        while (hasLegacyFields())
+        {
+            Map<ApplicationState, VersionedValue> orig = applicationState.get();
+            Map<ApplicationState, VersionedValue> updatedStates = filterMajorVersion3LegacyApplicationStates(orig);
+            // avoid updating if no state is removed
+            if (orig.size() == updatedStates.size()
+                || applicationState.compareAndSet(orig, updatedStates))
+                return;
+        }
+    }
+
+    private boolean hasLegacyFields()
+    {
+        Set<ApplicationState> statesPresent = applicationState.get().keySet();
+        if (statesPresent.isEmpty())
+            return false;
+        return (statesPresent.contains(STATUS) && statesPresent.contains(STATUS_WITH_PORT))
+               || (statesPresent.contains(INTERNAL_IP) && statesPresent.contains(INTERNAL_ADDRESS_AND_PORT))
+               || (statesPresent.contains(RPC_ADDRESS) && statesPresent.contains(NATIVE_ADDRESS_AND_PORT));
+    }
+
+    private Map<ApplicationState, VersionedValue> filterMajorVersion3LegacyApplicationStates(Map<ApplicationState, VersionedValue> states)

Review comment:
       ```suggestion
       private static Map<ApplicationState, VersionedValue> filterMajorVersion3LegacyApplicationStates(Map<ApplicationState, VersionedValue> states)
   ```




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 07:20;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r597021693



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -1506,8 +1496,20 @@ private void applyNewStates(InetAddressAndPort addr, EndpointState localState, E
         }
         localState.addApplicationStates(updatedStates);
 
+        // get rid of legacy fields once the cluster is not in mixed mode
+        if (!hasMajorVersion3Nodes())
+            localState.removeMajorVersion3LegacyApplicationStates();
+
         for (Entry<ApplicationState, VersionedValue> updatedEntry : updatedStates)
+        {
+            // filters out legacy change notifications
+            // only if local state already indicates that the peer has the new fields
+            if ((INTERNAL_IP == updatedEntry.getKey() && localState.containsApplicationState(INTERNAL_ADDRESS_AND_PORT))
+                ||(STATUS == updatedEntry.getKey() && localState.containsApplicationState(STATUS_WITH_PORT))
+                || (RPC_ADDRESS == updatedEntry.getKey() && localState.containsApplicationState(NATIVE_ADDRESS_AND_PORT)))
+                continue;

Review comment:
       i think this needs to be checks against the remoteState
   ```suggestion
               // filters out duplicated legacy change notifications to avoid deadlock of the OutboundConnection event loop thread
               if (hasMajorVersion3Nodes() && (INTERNAL_IP == updatedEntry.getKey() && remoteState.containsApplicationState(INTERNAL_ADDRESS_AND_PORT))
                   ||(STATUS == updatedEntry.getKey() && remoteState.containsApplicationState(STATUS_WITH_PORT))
                   || (RPC_ADDRESS == updatedEntry.getKey() && remoteState.containsApplicationState(NATIVE_ADDRESS_AND_PORT)))
                   continue;
   ```
   
   ""deadlock of the OutboundConnection event loop thread"" is described [here](https://issues.apache.org/jira/browse/CASSANDRA-16381?focusedCommentId=17288680&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17288680).




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 16:09;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r596603536



##########
File path: src/java/org/apache/cassandra/gms/EndpointState.java
##########
@@ -20,17 +20,26 @@
 import java.io.*;
 import java.util.*;
 import java.util.concurrent.atomic.AtomicReference;
+import java.util.stream.Collectors;
 
 import javax.annotation.Nullable;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
+
 import org.apache.cassandra.db.TypeSizes;
 import org.apache.cassandra.io.IVersionedSerializer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
 import org.apache.cassandra.utils.CassandraVersion;
 
+import static org.apache.cassandra.gms.ApplicationState.INTERNAL_ADDRESS_AND_PORT;
+import static org.apache.cassandra.gms.ApplicationState.INTERNAL_IP;
+import static org.apache.cassandra.gms.ApplicationState.NATIVE_ADDRESS_AND_PORT;
+import static org.apache.cassandra.gms.ApplicationState.RPC_ADDRESS;
+import static org.apache.cassandra.gms.ApplicationState.STATUS;
+import static org.apache.cassandra.gms.ApplicationState.STATUS_WITH_PORT;

Review comment:
       can we not do this please. it makes the patch bigger than it needs to be, changing the style of the class unnecessarily.  (i'd rather the few long lines).
   
   rationale: we don't have ""explicit static field imports"" as a stated code style rule (i.e. the next patch could just as easily change it all back bc that person thought that was better…) and i don't see a general precedence for this style in the codebase (though it's awkward to quantify this). so i guess it falls to what is the precedence in just the class: and that is here to not use the explicit static imports.
   
   (it would be great to raise this on the dev ML so we could establish a code style rule)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 16:13;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r596603859



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -65,6 +65,12 @@
 import org.apache.cassandra.utils.JVMStabilityInspector;
 
 import static org.apache.cassandra.config.CassandraRelevantProperties.GOSSIPER_QUARANTINE_DELAY;
+import static org.apache.cassandra.gms.ApplicationState.INTERNAL_ADDRESS_AND_PORT;
+import static org.apache.cassandra.gms.ApplicationState.INTERNAL_IP;
+import static org.apache.cassandra.gms.ApplicationState.NATIVE_ADDRESS_AND_PORT;
+import static org.apache.cassandra.gms.ApplicationState.RPC_ADDRESS;
+import static org.apache.cassandra.gms.ApplicationState.STATUS;
+import static org.apache.cassandra.gms.ApplicationState.STATUS_WITH_PORT;

Review comment:
       can we not do this please. it makes the patch bigger than it needs to be, changing the style of the class unnecessarily.  (i'd rather the few long lines).
   
   rationale: we don't have ""explicit static field imports"" as a stated code style rule (i.e. the next patch could just as easily change it all back bc that person thought that was better…) and i don't see a general precedence for this style in the codebase (though it's awkward to quantify this). so i guess it falls to what is the precedence in just the class: and that is here to not use the explicit static imports.
   
   (it would be great to raise this on the dev ML so we could establish a code style rule)




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 16:14;githubbot;600","yifan-c commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r597128085



##########
File path: src/java/org/apache/cassandra/gms/EndpointState.java
##########
@@ -114,6 +128,47 @@ public void addApplicationStates(Set<Map.Entry<ApplicationState, VersionedValue>
         }
     }
 
+    void removeMajorVersion3LegacyApplicationStates()
+    {
+        while (hasLegacyFields())
+        {
+            Map<ApplicationState, VersionedValue> orig = applicationState.get();
+            Map<ApplicationState, VersionedValue> updatedStates = filterMajorVersion3LegacyApplicationStates(orig);
+            // avoid updating if no state is removed
+            if (orig.size() == updatedStates.size()
+                || applicationState.compareAndSet(orig, updatedStates))
+                return;
+        }
+    }
+
+    private boolean hasLegacyFields()
+    {
+        Set<ApplicationState> statesPresent = applicationState.get().keySet();
+        if (statesPresent.isEmpty())
+            return false;
+        return (statesPresent.contains(STATUS) && statesPresent.contains(STATUS_WITH_PORT))
+               || (statesPresent.contains(INTERNAL_IP) && statesPresent.contains(INTERNAL_ADDRESS_AND_PORT))
+               || (statesPresent.contains(RPC_ADDRESS) && statesPresent.contains(NATIVE_ADDRESS_AND_PORT));
+    }
+
+    private Map<ApplicationState, VersionedValue> filterMajorVersion3LegacyApplicationStates(Map<ApplicationState, VersionedValue> states)

Review comment:
       Is the motivation of making it `static` to not pass `this` reference and not able to access instance fields? make sense...




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 18:14;githubbot;600","yifan-c commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r597136803



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -1506,8 +1496,20 @@ private void applyNewStates(InetAddressAndPort addr, EndpointState localState, E
         }
         localState.addApplicationStates(updatedStates);
 
+        // get rid of legacy fields once the cluster is not in mixed mode
+        if (!hasMajorVersion3Nodes())
+            localState.removeMajorVersion3LegacyApplicationStates();
+
         for (Entry<ApplicationState, VersionedValue> updatedEntry : updatedStates)
+        {
+            // filters out legacy change notifications
+            // only if local state already indicates that the peer has the new fields
+            if ((INTERNAL_IP == updatedEntry.getKey() && localState.containsApplicationState(INTERNAL_ADDRESS_AND_PORT))
+                ||(STATUS == updatedEntry.getKey() && localState.containsApplicationState(STATUS_WITH_PORT))
+                || (RPC_ADDRESS == updatedEntry.getKey() && localState.containsApplicationState(NATIVE_ADDRESS_AND_PORT)))
+                continue;

Review comment:
       I do not think the suggested change is necessary. 
   
   At the point of firing notifications. 
   The `remoteState` has been merged with `localState`. 
   The legacy fields has been removed if possible. 
   So checking against the new fields in the `localState` has the same effect but it no longer needs to check if it is in mixed mode again. 
   
   I have also added `org.apache.cassandra.gms.GossiperTest#testNotFireDuplicatedNotificationsWithUpdateContainsOldAndNewState` to verify the behavior. 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 18:26;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r597158981



##########
File path: src/java/org/apache/cassandra/gms/EndpointState.java
##########
@@ -114,6 +128,47 @@ public void addApplicationStates(Set<Map.Entry<ApplicationState, VersionedValue>
         }
     }
 
+    void removeMajorVersion3LegacyApplicationStates()
+    {
+        while (hasLegacyFields())
+        {
+            Map<ApplicationState, VersionedValue> orig = applicationState.get();
+            Map<ApplicationState, VersionedValue> updatedStates = filterMajorVersion3LegacyApplicationStates(orig);
+            // avoid updating if no state is removed
+            if (orig.size() == updatedStates.size()
+                || applicationState.compareAndSet(orig, updatedStates))
+                return;
+        }
+    }
+
+    private boolean hasLegacyFields()
+    {
+        Set<ApplicationState> statesPresent = applicationState.get().keySet();
+        if (statesPresent.isEmpty())
+            return false;
+        return (statesPresent.contains(STATUS) && statesPresent.contains(STATUS_WITH_PORT))
+               || (statesPresent.contains(INTERNAL_IP) && statesPresent.contains(INTERNAL_ADDRESS_AND_PORT))
+               || (statesPresent.contains(RPC_ADDRESS) && statesPresent.contains(NATIVE_ADDRESS_AND_PORT));
+    }
+
+    private Map<ApplicationState, VersionedValue> filterMajorVersion3LegacyApplicationStates(Map<ApplicationState, VersionedValue> states)

Review comment:
       yes. for the reader it's a optimisation: the following code has nothing to do with any instance fields. nothing more than that here.




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 18:59;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r597162043



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -1506,8 +1496,20 @@ private void applyNewStates(InetAddressAndPort addr, EndpointState localState, E
         }
         localState.addApplicationStates(updatedStates);
 
+        // get rid of legacy fields once the cluster is not in mixed mode
+        if (!hasMajorVersion3Nodes())
+            localState.removeMajorVersion3LegacyApplicationStates();
+
         for (Entry<ApplicationState, VersionedValue> updatedEntry : updatedStates)
+        {
+            // filters out legacy change notifications
+            // only if local state already indicates that the peer has the new fields
+            if ((INTERNAL_IP == updatedEntry.getKey() && localState.containsApplicationState(INTERNAL_ADDRESS_AND_PORT))
+                ||(STATUS == updatedEntry.getKey() && localState.containsApplicationState(STATUS_WITH_PORT))
+                || (RPC_ADDRESS == updatedEntry.getKey() && localState.containsApplicationState(NATIVE_ADDRESS_AND_PORT)))
+                continue;

Review comment:
       you are absolutely right :) 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 19:04;githubbot;600","michaelsembwever commented on a change in pull request #932:
URL: https://github.com/apache/cassandra/pull/932#discussion_r597190374



##########
File path: test/unit/org/apache/cassandra/gms/GossiperTest.java
##########
@@ -352,6 +350,107 @@ public void testReloadSeeds() throws UnknownHostException
             assertTrue(gossiper.getSeeds().contains(a.toString()));
     }
 
+    @Test
+    public void testNotFireDuplicatedNotificationsWithUpdateContainsOldAndNewState() throws UnknownHostException
+    {
+        VersionedValue.VersionedValueFactory valueFactory =
+            new VersionedValue.VersionedValueFactory(DatabaseDescriptor.getPartitioner());
+
+        Util.createInitialRing(ss, partitioner, endpointTokens, keyTokens, hosts, hostIds, 2);
+        SimpleStateChangeListener stateChangeListener = null;
+        try
+        {
+            InetAddressAndPort remoteHostAddress = hosts.get(1);
+            EndpointState initialRemoteState = Gossiper.instance.getEndpointStateForEndpoint(remoteHostAddress);
+            HeartBeatState initialRemoteHeartBeat = initialRemoteState.getHeartBeatState();
+            //Util.createInitialRing should have initialized remoteHost's HeartBeatState's generation to 1
+            assertEquals(initialRemoteHeartBeat.getGeneration(), 1);
+
+            // Test begins
+            AtomicInteger notificationCount = new AtomicInteger(0);
+            HeartBeatState proposedRemoteHeartBeat = new HeartBeatState(initialRemoteHeartBeat.getGeneration());
+            EndpointState proposedRemoteState = new EndpointState(proposedRemoteHeartBeat);
+            final Token token = DatabaseDescriptor.getPartitioner().getRandomToken();
+            proposedRemoteState.addApplicationState(ApplicationState.STATUS, valueFactory.normal(Collections.singletonList(token)));
+
+            stateChangeListener = new SimpleStateChangeListener();
+            Gossiper.instance.register(stateChangeListener);
+
+            // STEP 1. register verifier and apply state with just STATUS
+            // simulate applying gossip state from a v3 peer
+            stateChangeListener.setOnChangeVerifier(onChangeParams -> {
+                notificationCount.getAndIncrement();
+                assertEquals(""It should fire notification for STATUS when gossiper local state not yet has STATUS_WITH_PORT"",
+                             ApplicationState.STATUS, onChangeParams.state);
+            });
+            Gossiper.instance.applyStateLocally(ImmutableMap.of(remoteHostAddress, proposedRemoteState));
+
+            // STEP 2. includes both STATUS and STATUS_WITH_PORT. The gossiper knows that the remote peer is now in v4
+            // update verifier and apply state again
+            proposedRemoteState.addApplicationState(ApplicationState.STATUS_WITH_PORT, valueFactory.normal(Collections.singletonList(token)));
+            stateChangeListener.setOnChangeVerifier(onChangeParams -> {
+                notificationCount.getAndIncrement();
+                assertEquals(""It should only fire notification for STATUS_WITH_PORT"",
+                             ApplicationState.STATUS_WITH_PORT, onChangeParams.state);
+            });
+            Gossiper.instance.applyStateLocally(ImmutableMap.of(remoteHostAddress, proposedRemoteState));
+
+            // STEP 3. somehow, the peer send only the STATUS in the update.
+            proposedRemoteState = new EndpointState(proposedRemoteHeartBeat);
+            proposedRemoteState.addApplicationState(ApplicationState.STATUS, valueFactory.normal(Collections.singletonList(token)));
+            stateChangeListener.setOnChangeVerifier(onChangeParams -> {
+                notificationCount.getAndIncrement();
+                fail(""It should not fire notification for STATUS"");
+            });
+
+            assertEquals(""Expect exact 2 notifications with the test setup"",
+                         2, notificationCount.get());
+        }
+        finally
+        {
+            // clean up the gossip states
+            Gossiper.instance.endpointStateMap.clear();
+            if (stateChangeListener != null)
+                Gossiper.instance.unregister(stateChangeListener);
+        }
+    }

Review comment:
       👍 




-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Mar/21 19:40;githubbot;600","smiklosovic closed pull request #932:
URL: https://github.com/apache/cassandra/pull/932


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:36;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,10800,,,0,10800,,,,,,,,,,,,,CASSANDRA-16381,,,,,,,,,,,,,,,,,,,,"16/Mar/21 22:52;yifanc;Demonstrate-a-scenario-that-a-node-may-hold-the-stale-status.patch;https://issues.apache.org/jira/secure/attachment/13022423/Demonstrate-a-scenario-that-a-node-may-hold-the-stale-status.patch",,,,,1.0,yifanc,,,,,,,,,,,,,Correctness -> Recoverable Corruption / Loss,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sun Mar 21 08:56:25 UTC 2021,,,,,,,All,,,,"0|z0ov0w:",9223372036854775807,,,,mck,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/c591978f4d265e42d0132418005ba63a99278c75 https://github.com/apache/cassandra/commit/1ca5769c9adfd2e8bad3b7eea83112ad14cb05b2,,,,,,,,,jvm upgrade dtest,,,,,"16/Mar/21 23:16;yifanc;The patch that implements the fix mentioned in the description: https://github.com/apache/cassandra/pull/932
CI: https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=CASSANDRA-16525%2Ftrunk

A noticeable change of the patch is that it introduces the removal of legacy fields during applyNewState. Prior the patch, a gossiper may only get rid of the peers' states during major state changes. 

[~samt], would you like to review? 

cc: [~mck], as the patch adds a change on top of your recent patch for CASSANDRA-16381. ;;;","17/Mar/21 13:09;mck;Thanks for catching this [~yifanc], definitely should have been caught during 16381 :(

[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/491/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/491/pipeline];;;","18/Mar/21 00:29;yifanc;Thanks [~mck]. I have updated the PR with test fixes and your suggestions.

The gossiper test to check duplication notification filtering is also included. ;;;","18/Mar/21 14:24;brandon.williams;There were a lot of lwt-related failures in that run, I've rerun it here which should have the latest changes pulled:

[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/498/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/498/pipeline]
;;;","18/Mar/21 19:53;mck;+1 on the patch.

The CI [failures|https://ci-cassandra.apache.org/job/Cassandra-devbranch-test/324/jdk=jdk_1.8_latest,label=cassandra/testReport/junit/org.apache.cassandra.gms/GossiperTest/testDuplicatedStateUpdate/] have been [fixed|https://github.com/apache/cassandra/pull/932/commits/5c562614cd038e82cc2d67f70d10c65fafe8db9f].

Running again just the unit tests. 
[!https://ci-cassandra.apache.org/job/Cassandra-devbranch-test/325//badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-test/325/];;;","19/Mar/21 13:28;brandon.williams;+1;;;","19/Mar/21 15:57;mck;Committed as [c591978f4d265e42d0132418005ba63a99278c75|https://github.com/apache/cassandra/commit/c591978f4d265e42d0132418005ba63a99278c75].;;;","20/Mar/21 21:03;mck;This broke [MixedModeReadTest.mixedModeReadColumnSubsetDigestCheck|https://ci-cassandra.apache.org/job/Cassandra-trunk/348/]. It had failed in the above [CI runs|https://ci-cassandra.apache.org/job/Cassandra-devbranch/498/] as well.

Proposed [patch|https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/trunk/16525_test-fix] to fix, and CI [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/314/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-jvm-dtest-upgrade/314/];;;","21/Mar/21 00:12;yifanc;Thank you for the quick fix!

+1

Here is the cause of the test regression. [c591978f4|https://github.com/apache/cassandra/commit/c591978f4d265e42d0132418005ba63a99278c75] changed the cluster version checker in the gossiper to only start when the Gossiper is started. The failed test was not configured to start gossiper (no Feature.GOSSIP), so the checker always returns false. The checker updates every 60 seconds, so increasing the attempts from 30 to 90 makes sense.;;;","21/Mar/21 08:56;mck;Committed as [1ca5769c9adfd2e8bad3b7eea83112ad14cb05b2|https://github.com/apache/cassandra/commit/1ca5769c9adfd2e8bad3b7eea83112ad14cb05b2].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrading SSL enabled Cassandra cluster from 3.11.10 to 4.0-beta4 failing with javax.net.ssl.SSLException: java.lang.IndexOutOfBoundsException,CASSANDRA-16524,13365514,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gianluca,abarochia,abarochia,16/Mar/21 13:23,21/Apr/21 12:49,13/Jul/23 08:40,21/Apr/21 12:49,4.0,4.0-rc1,,,,,,Feature/Encryption,,,,0,,,"Hi,

We have SSL enabled cluster running on Apache Cassandra 3.11.10 and we are trying to upgrade it to 4.0-beta4 as a part of testing.

Cluster size is 3x3 and deployed on Azure IaaS.
{noformat}
[cassandra@cass-521828978-1-1189299202 ~]$ nodetool status
Datacenter: southcentral
========================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address      Load       Tokens       Owns (effective)  Host ID                               Rack
UN  10.12.74.31  85.61 KiB  16           32.2%             6db7a7ef-3490-4823-9ff3-c60a32165124  2
UN  10.12.74.42  263.27 KiB  16           27.6%             7ad99ecf-7c7d-4780-872b-7c68b6b19849  1
UN  10.12.74.34  85.61 KiB  16           37.8%             41ce16b7-2ab2-44ea-a810-8391f7f3caf2  0
Datacenter: westus
==================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address      Load       Tokens       Owns (effective)  Host ID                               Rack
UN  10.12.90.11  90.63 KiB  16           38.9%             8d4cdb65-ff66-4bcd-8d4b-a4a0e893a728  2
UN  10.12.90.6   85.61 KiB  16           34.5%             4f8007e9-fa3e-4e99-a9f9-f99997bf9625  1
UN  10.12.89.80  94.1 KiB   16           28.9%             11f86cb0-c86b-440e-848f-b160118f43d5  0
{noformat}
We placed a new 4.0-beta4 binary on the first seed node (10.12.74.310) and starting Cassandra.

It started throwing the below error:
{noformat}
ERROR [Messaging-EventLoop-3-11] 2021-03-15 22:10:05,188 InboundConnectionInitiator.java:342 - Failed to properly handshake with peer /10.12.74.42:52356. Closing the channel.
io.netty.handler.codec.DecoderException: javax.net.ssl.SSLException: java.lang.IndexOutOfBoundsException: writerIndex(8560) + minWritableBytes(1977) exceeds maxCapacity(10240): BufferPoolAllocator$Wrapped(ridx: 0, widx: 8560, cap: 10240/10240)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:471)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:795)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:480)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: javax.net.ssl.SSLException: java.lang.IndexOutOfBoundsException: writerIndex(8560) + minWritableBytes(1977) exceeds maxCapacity(10240): BufferPoolAllocator$Wrapped(ridx: 0, widx: 8560, cap: 10240/10240)
	at io.netty.handler.ssl.OpenSslKeyMaterialManager.setKeyMaterial(OpenSslKeyMaterialManager.java:115)
	at io.netty.handler.ssl.OpenSslKeyMaterialManager.setKeyMaterialServerSide(OpenSslKeyMaterialManager.java:84)
	at io.netty.handler.ssl.ReferenceCountedOpenSslServerContext$OpenSslServerCertificateCallback.handle(ReferenceCountedOpenSslServerContext.java:229)
	at io.netty.internal.tcnative.SSL.readFromSSL(Native Method)
	at io.netty.handler.ssl.ReferenceCountedOpenSslEngine.readPlaintextData(ReferenceCountedOpenSslEngine.java:596)
	at io.netty.handler.ssl.ReferenceCountedOpenSslEngine.unwrap(ReferenceCountedOpenSslEngine.java:1203)
	at io.netty.handler.ssl.ReferenceCountedOpenSslEngine.unwrap(ReferenceCountedOpenSslEngine.java:1325)
	at io.netty.handler.ssl.ReferenceCountedOpenSslEngine.unwrap(ReferenceCountedOpenSslEngine.java:1368)
	at io.netty.handler.ssl.SslHandler$SslEngineType$1.unwrap(SslHandler.java:206)
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1387)
	at io.netty.handler.ssl.SslHandler.decodeNonJdkCompatible(SslHandler.java:1294)
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1331)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:440)
	... 15 common frames omitted
{noformat}
 I have also used the below parameter under {{server_encryption_options}} as suggested at : [https://cassandra.apache.org/doc/latest/configuration/cass_yaml_file.html#server-encryption-options] but still getting the same error.
{noformat}
enable_legacy_ssl_storage_port: true
{noformat}
 
 I am attaching the system.log file here for your review.

It is working fine with Cassandra 3.11.10 and it looks like some bug in 4.0-beta4.

Let me know if you need any more details.

Thanks,
 Alaykumar Barochia",,abarochia,aholmber,aleksey,benedict,bereng,blerer,brandon.williams,e.dimitrova,gianluca,ifesdjeen,jasonstack,jmeredithco,maedhroz,mck,patrickclee0207@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Mar/21 13:22;abarochia;system.log.ssl-error.txt;https://issues.apache.org/jira/secure/attachment/13022384/system.log.ssl-error.txt",,,,,1.0,gianluca,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Apr 21 12:49:19 UTC 2021,,,,,,,All,,,,"0|z0ou5k:",9223372036854775807,,,,bereng,e.dimitrova,jasonstack,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/27cc2fc3e275f56f1fa1df7285c389d5491acc8c,,,,,,,,,"Patch available at:

[https://github.com/grighetto/cassandra/pull/6]

Added unit tests:

[https://github.com/grighetto/cassandra/blob/ecc8e3fc82769229231e4142857b88fce1d2263b/test/unit/org/apache/cassandra/net/BufferAllocatorTest.java]

[https://github.com/grighetto/cassandra/blob/ecc8e3fc82769229231e4142857b88fce1d2263b/test/unit/org/apache/cassandra/utils/memory/BufferPoolTest.java]

JDK 8 tests results:

[https://app.circleci.com/pipelines/github/grighetto/cassandra/57/workflows/0a2fa3ee-d502-4b4f-b311-b30d24a31465]

JDK 11 test results:
[https://app.circleci.com/pipelines/github/grighetto/cassandra/57/workflows/717987da-4226-40ec-8522-770dc9791129]",,,,,"16/Mar/21 19:00;aholmber;Thanks for the report. Is {{enable_legacy_ssl_storage_port}} the only thing you're changing in yaml? 

I'm not sure it will matter, but which Java runtime are you running?;;;","16/Mar/21 21:52;aholmber;This scenario is supported and should be covered in {{[test_rolling_upgrade_with_internode_ssl|https://github.com/apache/cassandra-dtest/blob/trunk/upgrade_tests/upgrade_through_versions_test.py#L328-L333]}}.

I tried reproducing locally in ccm with these exact versions:

{noformat}
keytool -genkeypair -alias ccm_node -keyalg RSA -validity 365 -keystore keystore.jks -storepass cassandra -dname ""cn=Cassandra Node,ou=CCMnode,o=DataStax,c=US"" -keypass cassandra
keytool -export -rfc -alias ccm_node -keystore keystore.jks -file ccm_node.cer -storepass cassandra
ccm create -n 3 -v 3.11.10 --node-ssl `pwd` c16258 -s
ccm node1 cqlsh -e 'select release_version from system.local'
ccm node1 showlog | grep -i exception
ccm node1 stop
ccm node1 setdir -v 4.0-beta4
ccm node1 updateconf 'server_encryption_options.enable_legacy_ssl_storage_port: true'
ccm node1 start
ccm node1 nodetool status
ccm node2 nodetool status
ccm node1 cqlsh -e 'select release_version from system.local'
ccm node1 showlog | grep -i exception
{noformat}

I did not reproduce the error with either 4.0-beta4 or trunk. 

We may need more information from troubleshooting your deployment, although I don't have anything more specific to ask for at this point.;;;","17/Mar/21 09:44;abarochia;We added only {{enable_legacy_ssl_storage_port}} parameter in cassandra.yaml file while upgrading to Cassandra 4.

Below is our Java version:

{noformat}
[abaroch@cass-521828978-1-1189299202 ~]$ java -version
openjdk version ""1.8.0_241""
OpenJDK Runtime Environment (Zulu 8.43.0.6-SA-linux64) (build 1.8.0_241-b08)
OpenJDK 64-Bit Server VM (Zulu 8.43.0.6-SA-linux64) (build 25.241-b08, mixed mode)
{noformat}
;;;","26/Mar/21 00:18;jmeredithco;Do you have larger than usual key sizes or perhaps an openssl configuration that's being picked up on the host? It seems to be failing when adding the key material.;;;","26/Mar/21 13:42;abarochia;How can we check the key sizes? ;;;","26/Mar/21 23:42;jmeredithco;You may be able to get the info using


{code}
 keytool -list -v -keystore keystore.jks
 keytool -list -v -keystore truststore.jks
{code}

Look for anything containing ""bit"", for example

{code}
Subject Public Key Algorithm: 2048-bit RSA key
{code};;;","30/Mar/21 17:39;gianluca;I can programmatically reproduce the exception reported in this ticket with the following piece of code:

{code}
	public static void main(String[] args) throws CertificateEncodingException
    	{
		X509Certificate[] chain = new X509Certificate[5];
		Random rand = new Random();
		DatabaseDescriptor.clientInitialization();
		for (int i = 0; i < chain.length; i++) {
		    byte[] bytes = new byte[i % 2 == 0 ? 1024 : 4096];
		    rand.nextBytes(bytes);
		    OpenSslX509Certificate certificate = new OpenSslX509Certificate(bytes);
		    chain[i] = certificate;
		}
		PemX509Certificate.toPEM(GlobalBufferPoolAllocator.instance, true, chain);
	}
 {code}

Note: this test code has to live in io.netty.hadler.ssl because `toPEM` is package-protected.
What it does is creating a chain of certificates (just random bytes for testing purposes) with different sizes (1024 and 4096 bits).

The issue is that netty allocates a buffer that's proportional in size to the size of the first certificate in the chain, so if the certificates vary in length and the first one is shorter than the rest, the buffer size estimate will be off:

https://github.com/netty/netty/blob/netty-4.1.58.Final/handler/src/main/java/io/netty/handler/ssl/PemX509Certificate.java#L135

In general, that shouldn't be a problem because netty's default allocator, ByteBufAllocator.DEFAULT, will increase the max buffer capacity. But in C* 4.0, we can see from the attached stacktrace that it's using BufferPoolAllocator, which does not increase:

https://github.com/apache/cassandra/blob/cassandra-4.0-beta4/src/java/org/apache/cassandra/net/BufferPoolAllocator.java#L59

In the sample code above, if I switch from {{GlobalBufferPoolAllocator.instance}} to {{ByteBufAllocator.DEFAULT}}, it throws no exception.
In C* 3.11.10 as far as I can tell it's using netty's default implementation.;;;","01/Apr/21 14:38;gianluca;As I hinted above, this seems to be more of a general buffer allocation problem than SSL specific.
In C* 4.0, a buffer is initialized with its max capacity equal to its initial capacity, for example, the following piece of code fails in C* 4.0:

{code}
ByteBuf myBuffer = GlobalBufferPoolAllocator.instance.buffer(100);
byte[] toWrite = new byte[2000];
myBuffer.writeBytes(toWrite);
{code}

So when netty tries to read a PEM certificate chain larger than what it originally estimated, it will fail.
If we want to restore a similar behavior of 3.11.10 and allow for increasing the max buffer capacity up to Integer.MAX_VALUE (netty's [default value|https://github.com/netty/netty/blob/netty-4.1.58.Final/buffer/src/main/java/io/netty/buffer/AbstractByteBufAllocator.java#L31]), I have the following patch:

https://github.com/grighetto/cassandra/pull/5

CI build still pending, but I wanted to raise this for an early review/discussion. [~jasonstack] Would you mind taking a look?;;;","02/Apr/21 15:16;jasonstack;[~gianluca] thanks for the reproduction test. the fix looks good to me, left some minor nits.  [~aleksey] do you mind having a look as well?;;;","05/Apr/21 15:59;gianluca;[~jasonstack] Thanks for the review. PR comments addressed.
Left a follow-up question: https://github.com/grighetto/cassandra/pull/5/files#r607168291;;;","06/Apr/21 09:50;bereng;[~gianluca] can you please run the j11 tests under the j8 link? I can't trigger them for you unfortunately.;;;","06/Apr/21 15:08;gianluca;Pushed new change as the result of the follow-up question above.
Running new builds in CI.;;;","06/Apr/21 17:31;gianluca;[~jasonstack] [~bereng] Latest change looks good on CI.
Test result links updated in the ticket.;;;","06/Apr/21 18:10;benedict;I suspect there may be a bug if you don't at least look at overriding {{capacity(int)}};;;","12/Apr/21 13:37;gianluca;{{BufferPoolAllocator.Wrapped#capacity(int)}} is now overridden to ensure the original ByteBuffer will be returned to the pool when the buffer is resized.
I also added unit tests for {{adopt()}} and various other scenarios of resizing.

Tests passed in CircleCI and result links have been updated in the issue description.

[~benedict] Would you mind taking another look?;;;","14/Apr/21 15:10;bereng;[~gianluca] I think we are just waiting for another +1 from either [~benedict], [~jasonstack] or some other committer right?;;;","15/Apr/21 02:30;gianluca;[~bereng] Right, I'm not anticipating additional changes, just waiting for the final review.;;;","16/Apr/21 02:50;jasonstack;bq. BufferPoolAllocator.Wrapped#capacity(int) is now overridden to ensure the original ByteBuffer will be returned to the pool when the buffer is resized.

Left a comment on whether to get rid of `super.capacity(int)` which allocated outside of pool.. https://github.com/grighetto/cassandra/pull/5/files#r614524653  [~e.dimitrova][~bereng][~gianluca] wdyt?;;;","16/Apr/21 04:33;gianluca;[~jasonstack] I went that route initially, but there's a problem with that approach, we pass the initial buffer to the constructor of UnpooledUnsafeDirectByteBuf and it keeps a reference to that internally:

https://github.com/netty/netty/blob/netty-4.1.58.Final/buffer/src/main/java/io/netty/buffer/UnpooledDirectByteBuf.java#L42

We would have to call setByteBuffer to replace that object, but it is not public:

https://github.com/netty/netty/blob/netty-4.1.58.Final/buffer/src/main/java/io/netty/buffer/UnpooledDirectByteBuf.java#L114

If we don't replace that internal buffer, there will be mismatches because some internal functions use it.
{{super.capacity(newCapacity)}} already does the right things, creates a new buffer, copies over the bytes, releases the old one and replaces that reference.

{quote}
So we don't have to keep track of returnToPool which defeats the purpose of reducing fragmented buffer allocation
{quote}

Right, I thought about that too and I agree, but for most cases it will behave as before (it has been working with fixed-length buffers up until now). Increasing the buffer capacity should be an edge case as the one reported in the ticket.;;;","16/Apr/21 13:29;e.dimitrova;Thanks [~gianluca] for all the work and bearing with me in Slack to confirm details. 

I just submitted my pass of review with just small comments. I have only two questions. 
 - Do we really need to use the new capacity function for max ?

I want to align this with 3.11 and have the least hurdle. Does 3.11 always use the Netty [DEFAULT_MAX_CAPACITY|https://github.com/netty/netty/blob/netty-4.1.58.Final/buffer/src/main/java/io/netty/buffer/AbstractByteBufAllocator.java#L31]? 

 - resizing happens in the same way it happens in 3.11 now?

Also, [~aholmber], as you were working on the upgrade tests, do you think there is another one we can add to cover this case and show the smooth upgrade after this patch or it is overkill? ;;;","16/Apr/21 17:21;aholmber;I understand that this was found during upgrade, but imo an upgrade test is fairly abstract characterization of this fix. [~gianluca] said creating the cert chain was fairly involved. Do you think it's worth codifying that in an integration test?  I had been thinking that the new unit tests were sufficient.;;;","19/Apr/21 04:56;bereng;The root cause has nothing to do with an upgrade or SSL. But it's just a generic BB resizing problem we have. So the unit tests should suffice and are the right fix imo if I am not missing anything.;;;","19/Apr/21 13:00;e.dimitrova;bq. The root cause has nothing to do with an upgrade or SSL. But it's just a generic BB resizing problem we have.
I didn't say anything different I think? As I mentioned ""to simulate the smooth upgrade"" but probably only the unit tests are enough here. Ignore me :-) 

I am hesitant whether we want to keep the current behavior during resizing or get back to using DEFAULT_MAX_CAPACITY, similar to what we do in 3.11. (I asked Gianluca on Friday and he verified it is  DEFAULT_MAX_CAPACITY in 3.11)


;;;","20/Apr/21 04:39;bereng;bq. I didn't say anything different I think?

Ah no, I was just thinking loud about the update thing.;;;","20/Apr/21 19:13;e.dimitrova;Jenkins is running [here|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/690/] for the latest version of the patch.
;;;","20/Apr/21 23:07;e.dimitrova;Jenkins finished with three failures which seem to me unrelated to the patch:

[https://jenkins-cm4.apache.org/job/Cassandra-devbranch/690/testReport/]

Two of the tests seem flaky and have failed with the same issue before:

[https://ci-cassandra.apache.org/job/Cassandra-trunk/446/testReport/junit/org.apache.cassandra.net/AsyncPromiseTest/testFailure_cdc/]

[https://ci-cassandra.apache.org/job/Cassandra-trunk/447/testReport/junit/org.apache.cass[…]ctionStrategyCQLTest/stressTestCompactionStrategyManager/|https://ci-cassandra.apache.org/job/Cassandra-trunk/447/testReport/junit/org.apache.cassandra.db.compaction/LongLeveledCompactionStrategyCQLTest/stressTestCompactionStrategyManager/]

 

The third one looks to me as a CI env issue, WDYT?:

[https://jenkins-cm4.apache.org/job/Cassandra-devbranch/690/testReport/junit.framework/Te[…]sandra_distributed_test_PreviewRepairCoordinatorFastTest/|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/690/testReport/junit.framework/TestSuite/org_apache_cassandra_distributed_test_PreviewRepairCoordinatorFastTest/]

 
{code:java}
ERROR 20:56:36 Repair e500b3d0-a21a-11eb-882f-cd9857e77aff failed:
java.lang.IllegalArgumentException: Unknown host specified thisreally.should.not.exist.apache.org
 at org.apache.cassandra.service.ActiveRepairService.getNeighbors(ActiveRepairService.java:478)
 at org.apache.cassandra.repair.RepairRunnable.getNeighborsAndRanges(RepairRunnable.java:326)
 at org.apache.cassandra.repair.RepairRunnable.runMayThrow(RepairRunnable.java:265)
 at org.apache.cassandra.repair.RepairRunnable.run(RepairRunnable.java:241)
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
 at java.util.concurrent.FutureTask.run(FutureTask.java:266)
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
 at java.util.concurrent.FutureTask.run(FutureTask.java:266)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.UnknownHostException: thisreally.should.not.exist.apache.org: Name or service not known
 at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
 at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929)
 at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324)
 at java.net.InetAddress.getAllByName0(InetAddress.java:1277)
 at java.net.InetAddress.getAllByName(InetAddress.java:1193)
 at java.net.InetAddress.getAllByName(InetAddress.java:1127)
 at java.net.InetAddress.getByName(InetAddress.java:1077)
 at org.apache.cassandra.locator.InetAddressAndPort.getByNameOverrideDefaults(InetAddressAndPort.java:228)
 at org.apache.cassandra.locator.InetAddressAndPort.getByName(InetAddressAndPort.java:213)
 at org.apache.cassandra.service.ActiveRepairService.getNeighbors(ActiveRepairService.java:472)
 ... 11 common frames omitted{code}
 ;;;","20/Apr/21 23:53;gianluca;[~e.dimitrova] The third test recently failed on trunk too: [https://jenkins-cm4.apache.org/job/Cassandra-trunk/451/]

I agree they look unrelated to the patch.;;;","20/Apr/21 23:53;e.dimitrova;[~gianluca] just shared with me that the same test just failed again in the latest trunk build actually:

https://jenkins-cm4.apache.org/job/Cassandra-trunk/451/testReport/junit/junit.framework/TestSuite/org_apache_cassandra_distributed_test_PreviewRepairCoordinatorFastTest/;;;","20/Apr/21 23:54;e.dimitrova;I think our messages crashed :D ;;;","21/Apr/21 00:17;e.dimitrova;I am +1 on the latest version of the patch.

We were brainstorming with [~gianluca] around the usage of  DEFAULT_MAX_CAPACITY, and after looking at the whole testing done around that part of the code in 4.0 (with huge clusters and a lot of data), I think it sounds probably reasonable to keep the current limit/behavior.

[~jasonstack] already approved the latest [PR|https://github.com/grighetto/cassandra/pull/6/files] in GitHub. I will leave the patch not committed until tomorrow morning if [~jasonstack] or [~bereng](or anyone else) has something to add, based on CI or some of my statements or anything and I think tomorrow morning I can commit it (if they don't do it and there is nothing else to be added here)

 ;;;","21/Apr/21 07:53;bereng;If I followed the code correctly I _think_ we're not checking, neither is Netty, for {{BuffePool.memoryUsageThreshold}}. In this case that'd be {{NETWORKING_MEMORY_USAGE_THRESHOLD}} coming from [here|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/utils/memory/BufferPools.java#L45]. That is being honored in reads i.e. but I think it'd be nice to do the same on resizing. At least I would add a unit test that tries to violate the buffer pool's memory threshold as future proofing. ;;;","21/Apr/21 10:44;blerer;The patch has been approved by [~e.dimitrova] and [~jasonstack]. CI looks good.
I will fix 1 formatting issue and rename the test class as suggested by [~e.dimitrova] and commit.;;;","21/Apr/21 12:26;blerer;Sorry, [~bereng], I missed your comment.
When {{Wrapped.capacity(int newCapacity)}} is called it calls {{super.capacity(int newCapacity)}} that call back {{Wrapped.allocateDirect}} that take care of using the BufferPool instead of allocating the buffer itself.
I checked the test and they trigger that path before checking that the changes have updated correctly the {{BufferPool}}.;;;","21/Apr/21 12:37;bereng;So we cleared these doubts with [~blerer] on Slack. {{allocateDirect()}} being overridden is the key here. Upon resizing it gets called by Netty and that will prevent going over the threshold. That also makes current tests already have that check implicit.

+1;;;","21/Apr/21 12:47;blerer;A big thank you to [~gianluca], [~bereng], [~e.dimitrova] and [~jasonstack] for the patch and the reviews. Great job!;;;","21/Apr/21 12:49;blerer;Committed into trunk at 27cc2fc3e275f56f1fa1df7285c389d5491acc8c;;;",,,,,,,,,,,,,,,,,
Improve handling of unflushed hint files,CASSANDRA-16523,13365235,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,15/Mar/21 12:42,18/Mar/21 08:47,13/Jul/23 08:40,18/Mar/21 08:47,3.0.25,3.11.11,4.0,4.0-rc1,,,,Consistency/Hints,,,,0,,,In some situations hint files can have a run of trailing zeros at the end - for example when hard-rebooting machines. These zeros can be safely ignored and we should avoid invoking the disk failure policy in these cases.,,aleksey,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Low Hanging Fruit,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Mar 18 08:47:15 UTC 2021,,,,,,,All,,,,"0|z0osfk:",9223372036854775807,,,,aleksey,,,,Normal,,3.0 alpha 1,,https://github.com/apache/cassandra/commit/32394e9d0ee86c66b7b21a9e9832ab6671b00f6e,,,,,,,,,cci runs,,,,,"15/Mar/21 12:48;marcuse;[3.0 patch|https://github.com/krummas/cassandra/commits/marcuse/corrupt_hints_3.0], [cci|https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2Fcorrupt_hints_3.0]
[3.11 patch|https://github.com/krummas/cassandra/commits/marcuse/corrupt_hints_3.11], [cci|https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2Fcorrupt_hints_3.11]
[trunk patch|https://github.com/krummas/cassandra/commits/marcuse/corrupt_hints_trunk], [cci|https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2Fcorrupt_hints_trunk];;;","15/Mar/21 15:10;aleksey;LGTM;;;","18/Mar/21 08:47;marcuse;committed to 3.0 and merged up, thanks;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ClientRequestSizeMetricsTest is flaky,CASSANDRA-16522,13365230,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,15/Mar/21 12:33,19/Nov/21 06:48,13/Jul/23 08:40,16/Mar/21 20:49,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"I don't know if it was reported but we can see it fail sometimes. 

The reason is that it checks the metrics before issuing and query and after. It expects that the executed operation between subsequent metrics checks is the only operation during that time. However the driver sometimes may refresh the schema in the middle and pollute the results. It is perfectly enough to slow down the execution a bit and the test starts to fail consistently rather than sporadically because we always hit schema refresh.

Patch at https://github.com/apache/cassandra/pull/930 ",,jlewandowski,mck,,,,,,,,,,,,,,"jacek-lewandowski opened a new pull request #930:
URL: https://github.com/apache/cassandra/pull/930


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Mar/21 13:36;githubbot;600","michaelsembwever commented on a change in pull request #930:
URL: https://github.com/apache/cassandra/pull/930#discussion_r594979049



##########
File path: test/unit/org/apache/cassandra/Util.java
##########
@@ -819,4 +820,38 @@ public static void setUpgradeFromVersion(String version)
                                                    VersionedValue.unsafeMakeVersionedValue(version, v + 1));
         Gossiper.instance.expireUpgradeFromVersion();
     }
+
+    public interface ThrowingRunnable
+    {
+        void run() throws Throwable;
+    }
+
+    @SuppressWarnings(""ConstantConditions"")
+    public static void retry(ThrowingRunnable runnable, Predicate<Throwable> canRetry, int maxRetries, long delay) throws Throwable

Review comment:
       very much like Awaitability.
   
   can we get a more informative method name please.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 09:06;githubbot;600","michaelsembwever commented on a change in pull request #930:
URL: https://github.com/apache/cassandra/pull/930#discussion_r594979049



##########
File path: test/unit/org/apache/cassandra/Util.java
##########
@@ -819,4 +820,38 @@ public static void setUpgradeFromVersion(String version)
                                                    VersionedValue.unsafeMakeVersionedValue(version, v + 1));
         Gossiper.instance.expireUpgradeFromVersion();
     }
+
+    public interface ThrowingRunnable
+    {
+        void run() throws Throwable;
+    }
+
+    @SuppressWarnings(""ConstantConditions"")
+    public static void retry(ThrowingRunnable runnable, Predicate<Throwable> canRetry, int maxRetries, long delay) throws Throwable

Review comment:
       very much like [Awaitability](http://www.awaitility.org/).
   
   can we get a more informative method name please.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 09:08;githubbot;600","michaelsembwever commented on a change in pull request #930:
URL: https://github.com/apache/cassandra/pull/930#discussion_r594979049



##########
File path: test/unit/org/apache/cassandra/Util.java
##########
@@ -819,4 +820,38 @@ public static void setUpgradeFromVersion(String version)
                                                    VersionedValue.unsafeMakeVersionedValue(version, v + 1));
         Gossiper.instance.expireUpgradeFromVersion();
     }
+
+    public interface ThrowingRunnable
+    {
+        void run() throws Throwable;
+    }
+
+    @SuppressWarnings(""ConstantConditions"")
+    public static void retry(ThrowingRunnable runnable, Predicate<Throwable> canRetry, int maxRetries, long delay) throws Throwable

Review comment:
       very much like [Awaitility](http://www.awaitility.org/).
   
   can we get a more informative method name please.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 09:09;githubbot;600","michaelsembwever commented on a change in pull request #930:
URL: https://github.com/apache/cassandra/pull/930#discussion_r594979049



##########
File path: test/unit/org/apache/cassandra/Util.java
##########
@@ -819,4 +820,38 @@ public static void setUpgradeFromVersion(String version)
                                                    VersionedValue.unsafeMakeVersionedValue(version, v + 1));
         Gossiper.instance.expireUpgradeFromVersion();
     }
+
+    public interface ThrowingRunnable
+    {
+        void run() throws Throwable;
+    }
+
+    @SuppressWarnings(""ConstantConditions"")
+    public static void retry(ThrowingRunnable runnable, Predicate<Throwable> canRetry, int maxRetries, long delay) throws Throwable

Review comment:
       very much like [Awaitility](http://www.awaitility.org/). (which is used in the project already)
   
   can we get a more informative method name please.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 09:17;githubbot;600","michaelsembwever commented on a change in pull request #930:
URL: https://github.com/apache/cassandra/pull/930#discussion_r594979049



##########
File path: test/unit/org/apache/cassandra/Util.java
##########
@@ -819,4 +820,38 @@ public static void setUpgradeFromVersion(String version)
                                                    VersionedValue.unsafeMakeVersionedValue(version, v + 1));
         Gossiper.instance.expireUpgradeFromVersion();
     }
+
+    public interface ThrowingRunnable
+    {
+        void run() throws Throwable;
+    }
+
+    @SuppressWarnings(""ConstantConditions"")
+    public static void retry(ThrowingRunnable runnable, Predicate<Throwable> canRetry, int maxRetries, long delay) throws Throwable

Review comment:
       very much like [Awaitility](http://www.awaitility.org/). (which is used in the project already)
   
   if Awaitility is not applicable, can we get a more informative method name please.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 09:17;githubbot;600","jacek-lewandowski commented on pull request #930:
URL: https://github.com/apache/cassandra/pull/930#issuecomment-800104246


   @blerer which driver version has that method?


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 09:36;githubbot;600","jacek-lewandowski commented on a change in pull request #930:
URL: https://github.com/apache/cassandra/pull/930#discussion_r595001948



##########
File path: test/unit/org/apache/cassandra/Util.java
##########
@@ -819,4 +820,38 @@ public static void setUpgradeFromVersion(String version)
                                                    VersionedValue.unsafeMakeVersionedValue(version, v + 1));
         Gossiper.instance.expireUpgradeFromVersion();
     }
+
+    public interface ThrowingRunnable
+    {
+        void run() throws Throwable;
+    }
+
+    @SuppressWarnings(""ConstantConditions"")
+    public static void retry(ThrowingRunnable runnable, Predicate<Throwable> canRetry, int maxRetries, long delay) throws Throwable

Review comment:
       It is perfectly applicable...




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 09:37;githubbot;600","blerer commented on pull request #930:
URL: https://github.com/apache/cassandra/pull/930#issuecomment-800115306


   Sorry, I was looking at the wrong doc. In our case we should use  `session.getCluster().getConfiguration().getQueryOptions().setMetadataEnabled(false)`


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 09:54;githubbot;600","JeremiahDJordan commented on a change in pull request #930:
URL: https://github.com/apache/cassandra/pull/930#discussion_r595477659



##########
File path: test/unit/org/apache/cassandra/metrics/ClientRequestSizeMetricsTest.java
##########
@@ -65,24 +65,34 @@ public static void setUp()
     @Test
     public void testReadAndWriteMetricsAreRecordedDuringNativeRequests() throws Throwable
     {
-        // We want to ignore all the messages sent by the driver upon connection as well as
-        // the event sent upon schema updates
-        clearMetrics();
-
-        executeNet(version, ""SELECT * from system.peers"");
-
-        long requestLength = ClientMessageSizeMetrics.bytesReceived.getCount();
-        long responseLength = ClientMessageSizeMetrics.bytesSent.getCount();
-
-        assertThat(requestLength).isGreaterThan(0);
-        assertThat(responseLength).isGreaterThan(0);
-
-        checkMetrics(1, requestLength, responseLength);
-
-        // Let's fire the same request again and test that the changes are the same that previously
-        executeNet(version, ""SELECT * from system.peers"");
-
-        checkMetrics(2, requestLength, responseLength);
+        // It may happen that the schema refreshment is done in the middle of the test which can pollute the results
+        // We will retry if we collect more then expected messages hoping that it was due that

Review comment:
       comment was not updated when switching to using setMetadataEnabled




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 19:25;githubbot;600","adelapena commented on a change in pull request #930:
URL: https://github.com/apache/cassandra/pull/930#discussion_r595452503



##########
File path: test/unit/org/apache/cassandra/metrics/ClientRequestSizeMetricsTest.java
##########
@@ -65,24 +65,34 @@ public static void setUp()
     @Test
     public void testReadAndWriteMetricsAreRecordedDuringNativeRequests() throws Throwable
     {
-        // We want to ignore all the messages sent by the driver upon connection as well as
-        // the event sent upon schema updates
-        clearMetrics();
-
-        executeNet(version, ""SELECT * from system.peers"");
-
-        long requestLength = ClientMessageSizeMetrics.bytesReceived.getCount();
-        long responseLength = ClientMessageSizeMetrics.bytesSent.getCount();
-
-        assertThat(requestLength).isGreaterThan(0);
-        assertThat(responseLength).isGreaterThan(0);
-
-        checkMetrics(1, requestLength, responseLength);
-
-        // Let's fire the same request again and test that the changes are the same that previously
-        executeNet(version, ""SELECT * from system.peers"");
-
-        checkMetrics(2, requestLength, responseLength);
+        // It may happen that the schema refreshment is done in the middle of the test which can pollute the results
+        // We will retry if we collect more then expected messages hoping that it was due that

Review comment:
       Does this comment about retrying come from a previous approach?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 19:41;githubbot;600","michaelsembwever commented on a change in pull request #930:
URL: https://github.com/apache/cassandra/pull/930#discussion_r595519642



##########
File path: test/unit/org/apache/cassandra/metrics/ClientRequestSizeMetricsTest.java
##########
@@ -65,24 +65,34 @@ public static void setUp()
     @Test
     public void testReadAndWriteMetricsAreRecordedDuringNativeRequests() throws Throwable
     {
-        // We want to ignore all the messages sent by the driver upon connection as well as
-        // the event sent upon schema updates
-        clearMetrics();
-
-        executeNet(version, ""SELECT * from system.peers"");
-
-        long requestLength = ClientMessageSizeMetrics.bytesReceived.getCount();
-        long responseLength = ClientMessageSizeMetrics.bytesSent.getCount();
-
-        assertThat(requestLength).isGreaterThan(0);
-        assertThat(responseLength).isGreaterThan(0);
-
-        checkMetrics(1, requestLength, responseLength);
-
-        // Let's fire the same request again and test that the changes are the same that previously
-        executeNet(version, ""SELECT * from system.peers"");
-
-        checkMetrics(2, requestLength, responseLength);
+        // It may happen that the schema refreshment is done in the middle of the test which can pollute the results
+        // We will retry if we collect more then expected messages hoping that it was due that

Review comment:
       It was. I'm going to remove it and commit.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 20:32;githubbot;600","jacek-lewandowski opened a new pull request #934:
URL: https://github.com/apache/cassandra/pull/934


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Mar/21 08:33;githubbot;600","jacek-lewandowski closed pull request #934:
URL: https://github.com/apache/cassandra/pull/934


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Mar/21 08:33;githubbot;600","jacek-lewandowski closed pull request #930:
URL: https://github.com/apache/cassandra/pull/930


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 06:48;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,9000,,,0,9000,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jlewandowski,,,,,,,,,,,,,Code,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 16 20:49:19 UTC 2021,,,,,,,All,,,,"0|z0oseg:",9223372036854775807,,,,adelapena,blerer,jjordan,mck,Low,,4.0-beta3,,https://github.com/apache/cassandra/commit/ecc7c2fc393568076c30243b48a26045d61d03f3,,,,,,,,,run unit tests,,,,,"16/Mar/21 05:08;jlewandowski;https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-test/313/;;;","16/Mar/21 18:26;mck;[!https://ci-cassandra.apache.org/job/Cassandra-devbranch-test/317/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-test/317/];;;","16/Mar/21 20:31;mck;+1;;;","16/Mar/21 20:49;mck;Committed as [ecc7c2fc393568076c30243b48a26045d61d03f3|https://github.com/apache/cassandra/commit/ecc7c2fc393568076c30243b48a26045d61d03f3].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Apply CASSANDRA-16515 for other view tests,CASSANDRA-16520,13365210,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,15/Mar/21 10:48,19/Nov/21 06:55,13/Jul/23 08:40,16/Mar/21 13:07,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"CASSANDRA-16515 unfortunately fixes only on view test class, but there are also other classes which may suffer from the same issue:
- ViewComplextTest,
- ViewLongTest,
- ViewSchemaTest
- ViewTest
",,e.dimitrova,jlewandowski,,,,,,,,,,,,,,"jacek-lewandowski opened a new pull request #931:
URL: https://github.com/apache/cassandra/pull/931


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 04:47;githubbot;600","jacek-lewandowski closed pull request #931:
URL: https://github.com/apache/cassandra/pull/931


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 06:55;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jlewandowski,,,,,,,,,,,,,Code,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 16 13:07:45 UTC 2021,,,,,,,All,,,,"0|z0osa0:",9223372036854775807,,,,brandon.williams,,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/d048efccd6bcab37da33d614c802cf84bbeb62c7,,,,,,,,,run unit tests,,,,,"16/Mar/21 04:53;jlewandowski;[~brandon.williams] - would you review also this one? The fix is identical as for CASSANDRA-16515;;;","16/Mar/21 04:53;jlewandowski;https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-test/312/;;;","16/Mar/21 13:07;brandon.williams;Committed, thank you for the patch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Node restart during joining sets protocol version to V3,CASSANDRA-16518,13365108,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stefan.miklosovic,JosephClay,JosephClay,15/Mar/21 02:18,13/Mar/22 19:06,13/Jul/23 08:40,08/Mar/22 22:44,3.0.27,3.11.13,,,,,,Messaging/Client,,,,3,,,"While joining nodes to a cluster, an old node crashed. The old node was recovered however clients (datastax java) refused to connect to it.

The driver error:
{noformat}
Detected added or restarted Cassandra host /<ip>:<port> but ignoring it since it does not support the version V4 of the native protocol which is currently in use.{noformat}

In the recovered node cassandra logs:
{noformat}
INFO  o.a.c.transport.ConfiguredLimit Detected peers which do not fully support protocol V4. Capping max negotiable version to V3{noformat}

I confirmed that ALL the nodes in the cluster, joining or otherwise, were apache-cassandra-3.11.6 so that error message was rather confusing.

 Eventually after digging through the code we got to the bottom of the issue:

https://issues.apache.org/jira/browse/CASSANDRA-15193 adds a check for node version, which reverts the protocol version to V3 if any peer fails the version check. Joining nodes have NULL for their version in the peers table, which fails the version check.

 ",,jaid,JosephClay,mck,pedro_gordo,samt,smiklosovic,stefan.miklosovic,,,,,,,,,"smiklosovic opened a new pull request #1465:
URL: https://github.com/apache/cassandra/pull/1465


   this is WIP


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Feb/22 14:37;githubbot;600","smiklosovic closed pull request #1465:
URL: https://github.com/apache/cassandra/pull/1465


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Mar/22 19:06;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,smiklosovic,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,Clients,,Tue Mar 08 22:41:25 UTC 2022,,,,,,,All,,,,"0|z0ornc:",9223372036854775807,,,,brandon.williams,samt,,,Normal,,3.0.19,,https://github.com/apache/cassandra/commit/4a15c5ad5a1a6b29be9aac6a8133f4dd936e1379,,,,,,,,,manual test,,,,,"15/Mar/21 02:26;JosephClay;To work around the issue:
Adding the following to jvm opts in the cassandra-env
-Dcassandra.disable_max_protocol_auto_override=true
Works fine to get the node back up on v4;;;","15/Mar/21 15:08;brandon.williams;Without digging into this, it seems to me the bug is having the bootstrapping (ie, non-member) node listed in the peers table before it has become a full member of the ring.;;;","21/Jun/21 15:09;stefan.miklosovic;I was not able to reproduce this on 3.11.10, if you check the source of these messages, it is here in DynamicLimit which extends ConfiguredLimit in its private method ""maybeUpdateVersion"":
{code:java}
        private void maybeUpdateVersion(boolean allowLowering)
        {
            boolean enforceV3Cap = SystemKeyspace.loadPeerVersions()
                                                 .values()
                                                 .stream()
                                                 .anyMatch(v -> v.compareTo(MIN_VERSION_FOR_V4) < 0);

            if (!enforceV3Cap)
            {
                maxVersion = ProtocolVersion.MAX_SUPPORTED_VERSION;
                return;
            }

            if (ProtocolVersion.V3.isSmallerThan(maxVersion) && !allowLowering)
            {
                logger.info(""Detected peers which do not fully support protocol V4, but V4 was previously negotiable. "" +
                            ""Not enforcing cap as this can cause issues for older client versions. After the next "" +
                            ""restart the server will apply the cap"");
                return;
            }

            logger.info(""Detected peers which do not fully support protocol V4. Capping max negotiable version to V3"");
            maxVersion = ProtocolVersion.V3;
        }
    }
{code}
So in order to get to the places where the first message is logged, ""enforceV3Cap"" has to be true so if (!enforceV3Cap) is false and it is skipped. Then, allowLowering has to be false. That means that maybeUpdateVersion accepts allowLowering as false. That is ever happening in DynamicLimit's method
{code:java}
        public void updateMaxSupportedVersion()
        {
            maybeUpdateVersion(false);
        }
{code}
updateMaxSupportedVersion is ever called only in NativeTransportService:
{code:java}
    public void refreshMaxNegotiableProtocolVersion()
    {
        // lowering the max negotiable protocol version is only safe if we haven't already
        // allowed clients to connect with a higher version. This still allows the max
        // version to be raised, as that is safe.
        if (initialized)
            protocolVersionLimit.updateMaxSupportedVersion();
    }
{code}
That is called in CassandraDaemon:
{code:java}
    public void refreshMaxNativeProtocolVersion()
    {
        if (nativeTransportService != null)
            nativeTransportService.refreshMaxNegotiableProtocolVersion();
    }
{code}
That is called in StorageService:
{code:java}
    private void refreshMaxNativeProtocolVersion()
    {
        if (daemon != null)
        {
            daemon.refreshMaxNativeProtocolVersion();
        }
    }
{code}
Now this is finally called at two places:

1) In StorageService#onChange where a respective node gets info from Gossip or so:
{code:java}
    case RELEASE_VERSION:
        SystemKeyspace.updatePeerReleaseVersion(endpoint, value.value, this::refreshMaxNativeProtocolVersion, executor);
{code}
The other place is in StorageService#updatePeerInfo which is called from StorageService#handleStateNormal so that treats the case when a node enters NORMAL state.

When you take the first place into account for now, lets see what it is doing:
{code:java}
    public static void updatePeerReleaseVersion(final InetAddress ep, final Object value, Runnable postUpdateTask, ExecutorService executorService)
    {
        if (ep.equals(FBUtilities.getBroadcastAddress()))
            return;

        String req = ""INSERT INTO system.%s (peer, release_version) VALUES (?, ?)"";
        executorService.execute(() -> {
            executeInternal(String.format(req, PEERS), ep, value);
            postUpdateTask.run();
        });
    }
{code}
So, if the peer is not myself, insert the release version of that peer into system.peers AND AFTER THAT run the post update task, which happens to be our refreshMaxNativeProtocolVersion method.

So as I said before, the fact that it would get so far to actually log that first message means that enforceV3Cap has to be true in the first place, so the result of this has to be true:
{code:java}
    boolean enforceV3Cap = SystemKeyspace.loadPeerVersions()
        .values()
        .stream()
        .anyMatch(v -> v.compareTo(MIN_VERSION_FOR_V4) < 0);
{code}
Hence this clearly means that some version found in peers table has to be lower than MIN_VERSION_FOR_V4 which is:

static final CassandraVersion MIN_VERSION_FOR_V4 = new CassandraVersion(""3.0.0"");

But I wonder how is that even possible you get that version (hypothetically lower than 3.0.0) because you said that you are running on a cluster which has all nodes of same version, so lets dig deeper a bit:
{code:java}
    /**
     * Return a map of IP address to C* version. If an invalid version string, or no version
     * at all is stored for a given peer IP, then NULL_VERSION will be reported for that peer
     */
    public static Map<InetAddress, CassandraVersion> loadPeerVersions()
    {
        Map<InetAddress, CassandraVersion> releaseVersionMap = new HashMap<>();
        for (UntypedResultSet.Row row : executeInternal(""SELECT peer, release_version FROM system."" + PEERS))
        {
            InetAddress peer = row.getInetAddress(""peer"");
            if (row.has(""release_version""))
            {
                try
                {
                    releaseVersionMap.put(peer, new CassandraVersion(row.getString(""release_version"")));
                }
                catch (IllegalArgumentException e)
                {
                    logger.info(""Invalid version string found for {}"", peer);
                    releaseVersionMap.put(peer, NULL_VERSION);
                }
            }
            else
            {
                logger.info(""No version string found for {}"", peer);
                releaseVersionMap.put(peer, NULL_VERSION);
            }
        }
        return releaseVersionMap;
    }
{code}
So if all nodes are of a bigger release than 3.0.0, the only place where we would get versoin lower than 3.0.0 is, as you debugged, the returned NULL_VERSION.

But I am failing to see how is that possible because if we recall what updatePeerReleaseVersion does:
{code:java}
        executorService.execute(() -> {
            executeInternal(String.format(req, PEERS), ep, value);
            postUpdateTask.run();
        });
{code}
So we insert the record into system.peers but we fail to read it back? How is that possible? Any ideas?

This might eventually mean that we insert NULL into DB, right ... so it means that onChange was invoked with RELEASE_VERSION state but its VersionedValue.value returns null which is even more interesting.

To get the second log message (logger.info(""Detected peers which do not fully support protocol V4. Capping max negotiable version to V3"");), for that, allowFiltering has to be true and that is called only in DynamicLimit's constructor which is initialised when a node starts - hence likely upon its start and it does not receive any state changes from the other nodes so system.peers has to contain that invalid value already.

Hence it _seems_ like a joining node propagates is release version with null when it is joining or a restarted node upon its start receives a RELEASE_VERSION which is null while a node is joining.

 

Edit 1) I was not able to see that there is NULL in system.peers. In 3.11.10, there are only peers which are joined. During whole joining, all nodes already participating in the ring were containing only other nodes, not the nodes which were about to join yet.;;;","21/Jun/21 15:10;stefan.miklosovic;[~brandon.williams] maybe you could proofread my thinking here? Thanks in advance.;;;","21/Jun/21 15:11;stefan.miklosovic;[~samt] looping you in as you wrote that feature.;;;","21/Jun/21 15:45;stefan.miklosovic;Few more observations to consider for [~JosephClay]

If you check what StorgeService#prepareToJoin does:
{code:java}
            getTokenMetadata().updateHostId(localHostId, FBUtilities.getBroadcastAddress());
            appStates.put(ApplicationState.NET_VERSION, valueFactory.networkVersion());
            appStates.put(ApplicationState.HOST_ID, valueFactory.hostId(localHostId));
            appStates.put(ApplicationState.RPC_ADDRESS, valueFactory.rpcaddress(FBUtilities.getBroadcastRpcAddress()));
            appStates.put(ApplicationState.RELEASE_VERSION, valueFactory.releaseVersion());
{code}
Release version is populated from FBUtilities.getReleaseVersionString():
{code:java}
    public static String getReleaseVersionString()
    {
        try (InputStream in = FBUtilities.class.getClassLoader().getResourceAsStream(""org/apache/cassandra/config/version.properties""))
        {
            if (in == null)
            {
                return System.getProperty(""cassandra.releaseVersion"", UNKNOWN_RELEASE_VERSION);
            }
            Properties props = new Properties();
            props.load(in);
            return props.getProperty(""CassandraVersion"");
        }
        catch (Exception e)
        {
            JVMStabilityInspector.inspectThrowable(e);
            logger.warn(""Unable to load version.properties"", e);
            return ""debug version"";
        }
    }
{code}
Are you sure that you have this file present? Also, are you sure that the version string is indeed 3.11.6? It might be different if you are building your own Cassandra distribution so it might have some unpredictable consequencies when there is some abritrary version in it and you gossip it to other nodes and so on. Does it strictly follow major.minor.patch format? If that resource is not found, as you see, it will default to system property and if that one is not set either, it will return ""Unknown"".

Then the Gossip is started:
{code:java}
Gossiper.instance.start(SystemKeyspace.incrementAndGetGeneration(), appStates); // needed for node-ring gathering.
{code}
Check what incrementAndGetGeneration is doing, if that node is starting, system.local is empty so it will generate its own generation but that generation is ignored in case it is lower than the generations of other nodes which might happen when time is ""behind"" on the joining node. Are you sure the time is same on all nodes?;;;","22/Jun/21 01:04;JosephClay;[~stefan.miklosovic] 
We are building cassandra ourselves, the version is actually 3.11.6.1, the last .1 is our build number, i.e. first build (in case we ever need to differentiate multiple builds). I definitely saw NULL for version in system.peers for the joining node, do you think the custom version number causes this? For all UN nodes the version is properly populated.

Regarding gossip and time, all nodes have NTP which i'm reasonably sure was working correctly at the time.;;;","22/Jun/21 04:23;stefan.miklosovic;3.11.6.1 should be parsed by CassandraVersion just fine. I ll try couple more times and I might downgrade to 3.11.6 to be exactly on par.;;;","22/Jun/21 17:32;stefan.miklosovic;I am sorry [~JosephClay], I can not reproduce this.;;;","07/Oct/21 07:07;JosephClay;I was finally able to reproduce. So the issue only reproduces if you configure cassandra so that it uses preferred_ip. You need to set cassandra so that it has two ip address per node and broadcast address a different ip to listen address.

Here is how i reproduced it in CCM:
{noformat}
# Set ccm directory here
CCM_DIR=~/.ccm

# create cluster but don't start it
ccm create test -v 3.11.11 -n 3

# Configure cluster to use GossipingPropertyFileSnitch with prefer_local and different ips for broadcast and listen addresses
rm $CCM_DIR/test/node*/conf/cassandra-topology.properties
sed -i 's/# prefer_local=true/prefer_local=true/' $CCM_DIR/test/node*/conf/cassandra-rackdc.properties
sed -i 's/endpoint_snitch.*/endpoint_snitch: GossipingPropertyFileSnitch/' $CCM_DIR/test/node*/conf/cassandra.yaml
sed -i 's/  - seeds:.*/  - seeds: 127.0.1.1/' $CCM_DIR/test/node*/conf/cassandra.yaml
echo 'broadcast_address: 127.0.1.1' >> $CCM_DIR/test/node1/conf/cassandra.yaml
echo 'broadcast_address: 127.0.1.2' >> $CCM_DIR/test/node2/conf/cassandra.yaml
echo 'broadcast_address: 127.0.1.3' >> $CCM_DIR/test/node3/conf/cassandra.yaml
echo 'listen_on_broadcast_address: true' >> $CCM_DIR/test/node1/conf/cassandra.yaml
echo 'listen_on_broadcast_address: true' >> $CCM_DIR/test/node2/conf/cassandra.yaml
echo 'listen_on_broadcast_address: true' >> $CCM_DIR/test/node3/conf/cassandra.yaml

# Start nodes1 and 2 need to skip wait as the above config breaks it
ccm node1 start --skip-wait-other-notice
ccm node2 start --skip-wait-other-notice

# Wait for both nodes to be UN then put roughly a GB of data into the cluster
ccm stress write n=5000000

# Slow down streaming so joining takes long enough to see issue then start 3rd node
ccm node1 nodetool setstreamthroughput 1
ccm node2 nodetool setstreamthroughput 1
sed -i 's/auto_bootstrap.*/auto_bootstrap: true/' $CCM_DIR/test/node3/conf/cassandra.yaml
ccm node3 start --skip-wait-other-notice

# Wait for streaming to start then check which node that node3 is streaming off
ccm node3 nodetool netstats
# On my cluster node1 was streaming so i stop & started node 2
ccm node2 stop
ccm node2 start --skip-wait-other-notice{noformat}
After that the restarted node logged this:
INFO [main] 2021-10-07 17:54:40,637 ConfiguredLimit.java:108 - Detected peers which do not fully support protocol V4. Capping max negotiable version to V3

Also if you tried to cqlsh to the restarted node:
Connection error: ('Unable to connect to any servers', \{'127.0.0.2:9042': DriverException('ProtocolError returned from server while using explicitly set client protocol_version 4')})

Errors in the node logs corresponding to attempted connection:
WARN [epollEventLoopGroup-2-6] 2021-10-07 17:56:04,822 NoSpamLogger.java:94 - Protocol exception with client networking: org.apache.cassandra.transport.ProtocolException: Invalid or unsupported protocol version (4); supported versions are (3/v3, 4/v4, 5/v5-beta)

You can cqlsh if you force the protocol version: cqlsh 127.0.0.2 --protocol-version=3

Peers table:
{noformat}
 peer      | data_center | host_id                              | preferred_ip | rack  | release_version | rpc_address | schema_version                       | tokens
-----------+-------------+--------------------------------------+--------------+-------+-----------------+-------------+--------------------------------------+--------------------------
 127.0.1.1 |         dc1 | d4d86d82-d12b-4bae-a1a4-7f0ded9d9b79 |    127.0.0.1 | rack1 |         3.11.11 |   127.0.0.1 | d25c2da9-b17e-3aba-8682-6cf063aaca51 | {'-9223372036854775808'}

 127.0.1.3 |        null |                                 null |    127.0.0.3 |  null |            null |        null |                                 null |                     null{noformat}
As you can see node3 the joining node has all nulls except for peer and preferred_ip columns. I believe the null in the release_version column causes the version check to fail.

 

 ;;;","07/Oct/21 14:31;brandon.williams;Your analysis looks spot on to me.  I believe the check from CASSANDRA-15193 is seeing the unknown version and capping the protocol. One possible way to solve this may be to get of preferred_ip altogether, an idea I've floated on CASSANDRA-16718, which is another problem regarding it. [~samt] wdyt?;;;","24/Feb/22 12:17;smiklosovic;After my analysis I think it is enough if we just filter out versions which are null from here

{code}
         boolean enforceV3Cap = SystemKeyspace.loadPeerVersions()
                                                 .values()
                                                 .stream()
                                                 .anyMatch(v -> v.compareTo(MIN_VERSION_FOR_V4) < 0);
{code}

I have tried it manually and it will not hit that bug again.

This should be done for 3.0 and 3.11. I ll provide patch soon.;;;","01/Mar/22 15:43;smiklosovic;PR: [https://github.com/apache/cassandra/pull/1465]

build: [https://app.circleci.com/pipelines/github/instaclustr/cassandra/769/workflows/c3892242-fe82-449f-85e5-0e6bcdaae5c3]

[~brandon.williams]  would you mind to review?;;;","01/Mar/22 16:29;brandon.williams;I think the real issue here is that we've allowed a null release_version that never gets resolved, and this patch works around that by ignoring unset versions.  That said, we've released versions that do this, so working around it seems like the only solution.  Can we add a test for this?;;;","01/Mar/22 17:20;smiklosovic;I've already tested this as well my colleagues and they are saying it just works as expected. Given how complex the test is going to be, I am admitting I am quite hesitant to spend too much time on this. Additioanlly, I am not completely sure what test I should write, in-jvm dtest or python one? There is a lot of moving parts here and I am afraid I am going to introduce another flaky eventually.

Or maybe I could narrow down the scope of the test to test just stuff around ConfigLimit? What is your opinion on the scope the test should cover here?;;;","07/Mar/22 16:24;brandon.williams;I guess you're right, this is a little tricky to test since you really need to be able to control gossip states to reproduce and then check the client protocol.  I'd still like [~samt] to take a look, but I'm +1.;;;","07/Mar/22 20:49;smiklosovic;I think the ultimate explanation why this is happening is like this (maybe handy for future readers / for reference)

In Gossipper#applyStateLocally, it gets to:
{code:java}
for (IEndpointStateChangeSubscriber subscriber : subscribers)
    subscriber.onJoin(ep, epState);
{code}
One of subscribers is ReconnectableSnitchHelper, which will eventually call ""SystemKeyspace.updatePreferredIP"" which will write only peer and preferred ip. So for a joining node, it will insert only peer and preferred ip hence all other fields are null.

Then, we kind of assume that the node will join, all is streamed etc. Once / upon it is fully joined, all other fields are populated so when another subscriber is triggered calling its onJoin again, the capping logic where it currently fails is called and it will do all the happy path with version populated and so on.

However, if we stop the node while some other node is joining a cluster, once we restart it, we hit this bug, because only the first subscriber has managed to be called so other subscriber with capping logic will see nulls because nothing has updated them - because we just stopped it while other node was joining.

Basically, we introduced nulls, never managed to fill the columns with non-nulls and the node crashed so restarted node sees nulls again and the capping logic will go south because it expects all stuff to be fully populated, which didnt happen, due to the node's failure.;;;","08/Mar/22 11:13;samt;Yeah, I don't really see another way around this bug in the short term, so I'm +1 on the proposed patch.;;;","08/Mar/22 22:41;smiklosovic;3.0 [https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1481/]

3.11 [https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/1480/];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ValueAccessorTest.testSlice is flaky,CASSANDRA-16516,13364713,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,brandon.williams,brandon.williams,12/Mar/21 19:52,17/Mar/21 06:07,13/Jul/23 08:40,16/Mar/21 13:23,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"https://ci-cassandra.apache.org/job/Cassandra-devbranch/479/testReport/junit/org.apache.cassandra.db.marshal/ValueAccessorTest/testSlice/

Probably fairly rare, but the potential is there:


{quote}
Regression

org.apache.cassandra.db.marshal.ValueAccessorTest.testSlice
Failing for the past 1 build (Since In progress#479 )
Took 25 ms.
Error Message

Gave up after finding only 59 example(s) matching the assumptions

Stacktrace

java.lang.IllegalStateException: Gave up after finding only 59 example(s) matching the assumptions
{quote}",,adelapena,bereng,blerer,,,,,,,,,,,,,"bereng opened a new pull request #929:
URL: https://github.com/apache/cassandra/pull/929


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Mar/21 10:07;githubbot;600","bereng commented on pull request #929:
URL: https://github.com/apache/cassandra/pull/929#issuecomment-799307444


   - CI [j8](https://app.circleci.com/pipelines/github/bereng/cassandra/227/workflows/f12049c3-4359-452b-84be-ea0ea154a58b)
   - CI [j11](https://app.circleci.com/pipelines/github/bereng/cassandra/227/workflows/d5e49255-3047-4f85-847a-abffb35f9747)


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Mar/21 10:30;githubbot;600","bereng edited a comment on pull request #929:
URL: https://github.com/apache/cassandra/pull/929#issuecomment-799307444


   - CI [j8](https://app.circleci.com/pipelines/github/bereng/cassandra/227/workflows/f12049c3-4359-452b-84be-ea0ea154a58b)
   - CI [j11](https://app.circleci.com/pipelines/github/bereng/cassandra/227/workflows/d5e49255-3047-4f85-847a-abffb35f9747)
   
   Unrelated failures. LGTM.


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Mar/21 10:43;githubbot;600","bereng closed pull request #929:
URL: https://github.com/apache/cassandra/pull/929


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Mar/21 06:07;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,2400,,,0,2400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Code,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 16 13:23:50 UTC 2021,,,,,,,All,,,,"0|z0op7k:",9223372036854775807,,,,adelapena,bereng,blerer,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/d0cfd0d9d93b77718e7403c3372e27b25e955e60,,,,,,,,,See PR,,,,,"14/Mar/21 16:35;brandon.williams;Perhaps less rare than I originally anticipated:

bq. java.lang.IllegalStateException: Gave up after finding only 400 example(s) matching the assumptions;;;","15/Mar/21 10:21;bereng;I don't think it's a test failure/flakiness issue in the strict sense. Reading about [qt|https://github.com/quicktheories/QuickTheories#assumptions] it mentions qt's assumptions that pass less than 10% of the generated values will render that error.

Test used to fail quickly locally, now it passes 10K runs locally.;;;","15/Mar/21 13:15;blerer;I think that we can also fix it in a different way: https://github.com/apache/cassandra/compare/trunk...blerer:CASSANDRA-16516-review?expand=1
The approach ensure that we do not generate invalid slides instead of rejecting them after the validation.
I ran it for 10,000 runs several time and did not hit the problem anymore.
[~Bereng] What do you think?  ;;;","16/Mar/21 05:45;bereng;LGTM. You are generating valid data in the first place by generating Slices instead of the individual variables that form one. +1 pending CI.;;;","16/Mar/21 13:07;adelapena;The patch generating the slices according to the generated byte array looks good to me, that way we don't miss any of the generated examples.

Maybe the method {{ValueAccessor#slices}} could be {{private}} and return directly, without declaring and immediately return {{gen}}:
{code:java}
private static Gen<ByteArraySlice> slices(Gen<byte[]> arrayGen)
{
    return td -> {
{code}
I have also successfully run the test locally a few thousand times. [Here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/706/] are 1000 runs of the method in our multiplexer, and [here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/707/] are 100 runs of the full suite.;;;","16/Mar/21 13:11;blerer;The [CI results|https://app.circleci.com/pipelines/github/blerer/cassandra?branch=CASSANDRA-16516-review] look good. The failing tests are not related to the change.;;;","16/Mar/21 13:21;blerer;[~adelapena] Thanks for your review. I applied your suggestions before committing.;;;","16/Mar/21 13:23;blerer;Merged into trunk at d0cfd0d9d93b77718e7403c3372e27b25e955e60;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Don't fail all ViewFilteringTest cases because one case timed out,CASSANDRA-16515,13364080,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,12/Mar/21 09:21,19/Nov/21 06:55,13/Jul/23 08:40,12/Mar/21 20:00,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"When {{ViewFilteringTest}} creates a view, it is added to the list of created views. Those views are removed after each test cases. If creating a view fail, it is not added to the list of views to be dropped because the assumption is that when the command fails, the view should not be created. This is ok in general however it is not a valid assumption when we get operation timed out because we cannot say anything about its real result. This way, it is possible that the view gets created, the driver throws time out and we do not remove the created view. All other test cases which tries to create that view will fail because the view already exists. 

While it seems very improbable, we actually hit this a couple of times on our infrastructure

 !screenshot-1.png! 

 !screenshot-2.png! 

 !screenshot-3.png! ",,jlewandowski,mck,,,,,,,,,,,,,,"jacek-lewandowski opened a new pull request #927:
URL: https://github.com/apache/cassandra/pull/927


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Mar/21 09:23;githubbot;600","bereng opened a new pull request #928:
URL: https://github.com/apache/cassandra/pull/928


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Mar/21 10:04;githubbot;600","bereng closed pull request #928:
URL: https://github.com/apache/cassandra/pull/928


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Mar/21 10:05;githubbot;600","jacek-lewandowski closed pull request #927:
URL: https://github.com/apache/cassandra/pull/927


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 06:55;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,2400,,,0,2400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Mar/21 09:58;jlewandowski;screenshot-1.png;https://issues.apache.org/jira/secure/attachment/13022169/screenshot-1.png","12/Mar/21 09:58;jlewandowski;screenshot-2.png;https://issues.apache.org/jira/secure/attachment/13022170/screenshot-2.png","12/Mar/21 09:59;jlewandowski;screenshot-3.png;https://issues.apache.org/jira/secure/attachment/13022171/screenshot-3.png",,,3.0,jlewandowski,,,,,,,,,,,,,Code,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Mar 12 20:01:26 UTC 2021,,,,,,,All,,,,"0|z0olew:",9223372036854775807,,,,brandon.williams,,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/7ae0fcecd207af14e35d171642b8d21feb6e543a,,,,,,,,,run regression tests (just unit tests),,,,,"12/Mar/21 14:22;brandon.williams;[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/479/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/479/pipeline]

LGTM if CI is happy, +1.;;;","12/Mar/21 20:01;brandon.williams;Committed, thanks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SinglePartitionSliceCommandTest.testPartitionDeletionRangeDeletionTie is flaky,CASSANDRA-16512,13363919,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,jlewandowski,jlewandowski,11/Mar/21 18:10,21/Mar/22 11:12,13/Jul/23 08:40,16/Mar/21 00:07,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"Although we cannot see that in regular CI, this test is flaky and I can see that in our private test runs. The problem is that it assumes two consecutive queries are executed in the exact same second. A similar test case {{testPartitionDeletionRowDeletionTie}} has been already fixed in CASSANDRA-16443. We need almost identical fix for this one as well.",,bereng,blerer,e.dimitrova,jlewandowski,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-17458,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 16 00:06:52 UTC 2021,,,,,,,All,,,,"0|z0okf4:",9223372036854775807,,,,bereng,blerer,jlewandowski,,Low,,4.0-beta4,,https://github.com/apache/cassandra/commit/0a4b997337aafcc81396d27ac5de2a682283152f,,,,,,,,,https://github.com/ekaterinadimitrova2/cassandra/commit/fa5b947823edd66d19e9ef8e33311c1f91e96966,,,,,"11/Mar/21 22:24;e.dimitrova;I didn't manage to reproduce it locally and in private multiplexer but code inspection shows me that we can hit the same issue as in CASSANDRA-16443.

[~jlewandowski], is it possible to try [the patch |https://github.com/ekaterinadimitrova2/cassandra/commit/fa5b947823edd66d19e9ef8e33311c1f91e96966] in your environment to confirm the fix?

[~blerer], may I ask you for review as you fixed the other one? Thank you in advance :) 

 ;;;","12/Mar/21 15:35;e.dimitrova;Additional comment added [here| https://github.com/ekaterinadimitrova2/cassandra/commit/b0bcb4a8e9ea93e6625d3322653006cfe3a55ee5] as per the review discussion

CI run [JAVA 8|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/698/workflows/39db0e69-c4fb-443e-885c-9cad34cb2052] and [JAVA 11|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/698/workflows/fb5f621b-aacd-41a2-abcf-512a811dcd6d]
;;;","15/Mar/21 05:34;bereng;j11 unit tests didn't run #justfyi;;;","15/Mar/21 09:58;blerer;+1 if everything looks good with the j11 unit tests;;;","16/Mar/21 00:06;e.dimitrova;Circle CI was crashing on Friday so it seems as a result Java 11 didn't have a run.


 Clean CI [here|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/698/workflows/fb5f621b-aacd-41a2-abcf-512a811dcd6d/jobs/3859/parallel-runs/1]
 Patch committed [here|https://github.com/apache/cassandra/commit/0a4b997337aafcc81396d27ac5de2a682283152f]. I see Jacek also approved the patch on GitHub. Thank you all;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Running tests in parallel can sometimes result in port collision,CASSANDRA-16511,13363859,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,11/Mar/21 14:20,19/Nov/21 06:49,13/Jul/23 08:40,12/Mar/21 20:42,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"When running unit tests with parallel execution we may sometimes notice the port collision. In this mode, test classes from the list get consecutive offsets which are added to native transport port, storage port and ssl storage port ( {{OffsetAwareConfigurationLoader}} ). However we add to the ports configured in {{test/conf/cassandra.yaml}} we as we can see we have the following default config:
{code:java}
storage_port: 7012
ssl_storage_port: 7011 {code}
This results in the situation that thread n has the same storage port as thread n+1 has ssl storage port. There are not much such tests, but we can see {{ConnectionTests}} failing frequently because of that. 

The other problem is that {{OffsetAwareConfigurationLoader}} does not adjust native transport ssl port.

 !screenshot-1.png! 
 

Patch at https://github.com/apache/cassandra/pull/925",,brandon.williams,jlewandowski,mck,yifanc,,,,,,,,,,,,"jacek-lewandowski opened a new pull request #925:
URL: https://github.com/apache/cassandra/pull/925


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Mar/21 08:33;githubbot;600","jacek-lewandowski closed pull request #925:
URL: https://github.com/apache/cassandra/pull/925


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 06:49;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Mar/21 10:01;jlewandowski;screenshot-1.png;https://issues.apache.org/jira/secure/attachment/13022173/screenshot-1.png",,,,,1.0,jlewandowski,,,,,,,,,,,,,Code,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 13 18:39:25 UTC 2021,,,,,,,All,,,,"0|z0ok1s:",9223372036854775807,,,,brandon.williams,mck,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/11d069a766a4a9a5db534a86de0175128431526f https://github.com/apache/cassandra-builds/commit/34d9592dda05ab313efac9d04e565f593fa40b37  https://github.com/apache/cassandra/commit/1f7700cf8bd6364f49138472b47676e46c0,,,,,,,,,Try to reproduce using the provided steps,,,,,"11/Mar/21 15:06;brandon.williams;Worth noting there are also some in-jvm dtests that can't run in parallel as they require absolute port numbers.;;;","11/Mar/21 15:11;jlewandowski;:(

But that is probably a different problem (more serious) and has a different fix

 ;;;","11/Mar/21 15:13;jlewandowski;I can reproduce it nearly consistently by running:

{noformat}
ant testclasslist -Dtest.runners=4
{noformat}

given {{testlist.txt}} is:

{noformat}
org/apache/cassandra/metrics/ClientRequestSizeMetricsTest.java
org/apache/cassandra/locator/ReplicaPlansTest.java
org/apache/cassandra/service/reads/ReadExecutorTest.java
org/apache/cassandra/net/proxy/ProxyHandlerTest.java
org/apache/cassandra/net/ConnectionTest.java
org/apache/cassandra/db/ClusteringBoundTest.java
org/apache/cassandra/cql3/functions/OperationFctsTest.java
org/apache/cassandra/db/marshal/BytesTypeTest.java
org/apache/cassandra/db/compaction/TTLExpiryTest.java
org/apache/cassandra/cql3/validation/operations/SelectSingleColumnRelationTest.java
org/apache/cassandra/repair/RepairSessionTest.java
{noformat}
;;;","12/Mar/21 14:06;mck;CI
- patch as-is :: https://ci-cassandra.apache.org/job/Cassandra-devbranch-test/303/
- patch w/ runners enabled :: https://ci-cassandra.apache.org/job/Cassandra-devbranch-test/304/

With runners, ci-cassandra went with two runners:
{code}
…
13:52:30 get-cores:
13:52:30      [echo] Number of cores: 8
13:52:30 
13:52:30 get-mem:
13:52:30      [echo] Mem size : 33675816960
13:52:30 
13:52:30 testclasslist:
13:52:30      [echo] Number of test runners: 2
…
{code}

And to [expectation|https://issues.apache.org/jira/browse/CASSANDRA-13078], this halved the build time, from ~2 hours to ~1 hour.
And no failures.

+1 (with the inclusion of enabling runners);;;","12/Mar/21 14:30;brandon.williams;+1;;;","12/Mar/21 14:35;mck;Additional patch [here|https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/trunk_16511].;;;","12/Mar/21 14:42;brandon.williams;+1 (though the first one was actually for this, since that is what ran on CI);;;","12/Mar/21 14:53;mck;Committed as [11d069a766a4a9a5db534a86de0175128431526f|https://github.com/apache/cassandra/commit/11d069a766a4a9a5db534a86de0175128431526f].;;;","12/Mar/21 18:59;mck;bq. Worth noting there are also some in-jvm dtests that can't run in parallel as they require absolute port numbers.

Oops. `ant testclasslist` is re-used here. Working on a fix…;;;","12/Mar/21 19:08;mck;Patches:
 - https://github.com/apache/cassandra-builds/compare/trunk...thelastpickle:mck/16511
 - https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/trunk_16511_circleci;;;","12/Mar/21 19:24;brandon.williams;+1 but I think we need to edit config-2_1.yml too to persist this through a run of generate.sh;;;","12/Mar/21 19:50;mck;bq. +1 but I think we need to edit config-2_1.yml too to persist this through a run of generate.sh

done.

CI
 - https://app.circleci.com/pipelines/github/michaelsembwever/cassandra/12/workflows/c5e7cd60-17a9-4c3c-a875-f8932547218c;;;","12/Mar/21 19:52;mck;cassandra-builds committed as [34d9592dda05ab313efac9d04e565f593fa40b37|https://github.com/apache/cassandra-builds/commit/34d9592dda05ab313efac9d04e565f593fa40b37].;;;","12/Mar/21 20:41;mck;Committed as [1f7700cf8bd6364f49138472b47676e46c023825|https://github.com/apache/cassandra/commit/1f7700cf8bd6364f49138472b47676e46c023825].;;;","13/Apr/21 18:36;yifanc;It looks like with the commit ([11d069a|https://github.com/apache/cassandra/commit/11d069a766a4a9a5db534a86de0175128431526f]), the CircleCI j8 unit test always starts with multiple runners and the test becomes flaky since then, when using highRes (I did not try the other resource types). 

https://app.circleci.com/pipelines/github/yifan-c/cassandra/228/workflows/8a1cf6d9-d5d3-47ad-be62-6e563907a0a6/jobs/1370/parallel-runs/35/steps/35-104

The test task now depends on {{get-cores}} and {{get-mem}} and it leads to the number of runners being calculated as 6. 
{code:java}
build-test:

_build-test:

get-cores:
     [echo] Number of cores: 36

get-mem:
     [echo] Mem size : 73757396992

testclasslist:
     [echo] Number of test runners: 6
{code}

The unit test opens ports too. One approach is to patch the circle CI config with {{-Dtest.runner=1}}. 

WDYT?;;;","13/Apr/21 18:39;brandon.williams;At this point perhaps we should just wait for CASSANDRA-16595 to remove all the parallelism from the build itself.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Running cqlsh against cassandra 3 throws error about beta flag not set,CASSANDRA-16508,13363378,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aholmber,jeffwidman,jeffwidman,09/Mar/21 21:40,16/Mar/21 19:43,13/Jul/23 08:40,16/Mar/21 19:43,4.0,4.0-rc1,,,,,,CQL/Interpreter,,,,0,,,"I just ran `cqlsh` from `trunk` commit 2aa22ba99dcc1dacb07b7af31b2664e7db839063 against a Cassandra 3.11.10 docker image.

I expected that the newer cqlsh would down-negotiate from the v5 protocol to the older v4 protocol.

Instead, I was surprised to get a server error about a beta protocol being used without `BETA_FLAG` being set. I unfortunately had to reboot my computer, so I lost the traceback but I can easily reproduce if needed.

I think what's happening is that this commit promoted v5 out of beta:
https://github.com/apache/cassandra/commit/c9d6c725dd0b4aa5693eb1c6d2221c28e9e99c6e#diff-9e4fe0cfd28004625a8006be8a0bdeab8cbdfb039449fb9501b15e8952577aaaL479

And then when it tries to contact the older cassandra version, the server complains that it received a request using the v5 protocol without this beta flag being set.

However, I was expecting that cqlsh would catch the error and down-negotiate to v4. Instead, it simply returns the error with no message about how to solve. As someone relatively new to `cqlsh`, I assumed at first there was no workaround except for downgrading my version of `cqlsh`. After some googling, I stumbled across a stackoverflow pointing toward the `--cqlversion` flag.

Given that this was the first cqlsh to support python 3, it means that anyone trying to use python 3 for cqlsh against cassandra 3.x will hit this weird error. There is no alternative if you want to use python 3.

My suggested fix is to catch the error and either prompt the user with something like _Perhaps you want to manually specify a different cql protocol version using the `--cqlversion` flag?_ or simply auto-down negotiate to version 4 (although I understand why auto-down-negotiating may not be the right move).",,aholmber,jeffwidman,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-14973,,,,,,,,,,,,,,,,,,,,,,,,,0.0,aholmber,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 16 19:43:50 UTC 2021,,,,,,,All,,,,"0|z0oh34:",9223372036854775807,,,,mck,,,,Normal,,4.0-rc1,,https://github.com/apache/cassandra/commit/b60acd5f6feca50491cffa675690dbbdda92685f,,,,,,,,,"Manually tested locally major version back through Cassandra version 2.1, ran all cqlsh and python dtests.",,,,,"15/Mar/21 20:17;aholmber;Proposing a very simple patch. It removes explicitly setting {{protocol_version}} in {{cqlsh}} and leaves downgrading to the driver.

The explicit set was only [added with some v5 work|https://github.com/apache/cassandra/commit/a7c4ba9eeecb365e7c4753d8eaab747edd9a632a#diff-9e4fe0cfd28004625a8006be8a0bdeab8cbdfb039449fb9501b15e8952577aaaR478], and I think was only necessary when v5 was in beta. It was later set to 5 after v5 was promoted out of beta, and that's when it would have stopped working with lesser C* versions.

I've tested locally with versions back through 2.1 and verified that it connects and arrives at the correct protocol version:
{noformat}
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 2.1.23-SNAPSHOT | CQL spec 3.2.1 | Native protocol v3]
{noformat}
{noformat}
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 2.2.20-SNAPSHOT | CQL spec 3.3.1 | Native protocol v4]
{noformat}
{noformat}
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 3.0.25-SNAPSHOT | CQL spec 3.4.0 | Native protocol v4]
{noformat}
{noformat}
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 3.11.11-SNAPSHOT | CQL spec 3.4.4 | Native protocol v4]
{noformat}
{noformat}
Connected to Test Cluster at 127.0.0.1:9042
[cqlsh 6.0.0 | Cassandra 4.0-beta5-SNAPSHOT | CQL spec 3.4.5 | Native protocol v5]
{noformat}

[patch|https://github.com/aholmberg/cassandra/pull/47]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16508]
;;;","16/Mar/21 18:35;mck;[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/486/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/486/pipeline];;;","16/Mar/21 18:41;jeffwidman;> Proposing a very simple patch. It removes explicitly setting protocol_version in cqlsh and leaves downgrading to the driver.

That sounds like a very clean solution, and appropriate given the historical context of why this was even added in the first place.;;;","16/Mar/21 19:42;mck;+1;;;","16/Mar/21 19:43;mck;Committed as [b60acd5f6feca50491cffa675690dbbdda92685f|https://github.com/apache/cassandra/commit/b60acd5f6feca50491cffa675690dbbdda92685f].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missing validation in AbstractType.writeValue():,CASSANDRA-16500,13362983,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adutra,blerer,blerer,08/Mar/21 11:01,16/Mar/22 15:33,13/Jul/23 08:40,25/Mar/21 19:59,4.0,4.0-rc1,,,,,,Local/Other,,,,0,,,"Some validation checks present in {{AbstractType.writeValue()}} in {{cassandra-3.11}} are not there in {{trunk}}.
In 3.11 the checks used assertion. It would make sense to use {{IOExceptions}} instead as used in   {{AbstractType.readValue()}}.",,adelapena,adutra,bereng,blerer,e.dimitrova,,,,,,,,,,,"adutra opened a new pull request #924:
URL: https://github.com/apache/cassandra/pull/924


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Mar/21 10:04;githubbot;600","bereng commented on a change in pull request #924:
URL: https://github.com/apache/cassandra/pull/924#discussion_r592139195



##########
File path: src/java/org/apache/cassandra/db/marshal/AbstractType.java
##########
@@ -435,11 +435,21 @@ public void writeValue(ByteBuffer value, DataOutputPlus out) throws IOException
     // This assumes that no empty values are passed
     public  <V> void writeValue(V value, ValueAccessor<V> accessor, DataOutputPlus out) throws IOException
     {
-        assert !accessor.isEmpty(value);
-        if (valueLengthIfFixed() >= 0)
-            accessor.write(value, out);
+        assert !accessor.isEmpty(value) : ""bytes should not be empty for type "" + this;
+        int expectedValueLength = valueLengthIfFixed();
+        if (expectedValueLength >= 0)
+        {
+            int actualValueLength = accessor.size(value);
+            if (actualValueLength == expectedValueLength)
+                accessor.write(value, out);
+             else

Review comment:
       Bad indent?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Mar/21 08:01;githubbot;600","bereng commented on pull request #924:
URL: https://github.com/apache/cassandra/pull/924#issuecomment-796550808


   LGTM +1


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Mar/21 08:08;githubbot;600","adelapena commented on a change in pull request #924:
URL: https://github.com/apache/cassandra/pull/924#discussion_r592348731



##########
File path: src/java/org/apache/cassandra/db/marshal/AbstractType.java
##########
@@ -435,11 +435,21 @@ public void writeValue(ByteBuffer value, DataOutputPlus out) throws IOException
     // This assumes that no empty values are passed
     public  <V> void writeValue(V value, ValueAccessor<V> accessor, DataOutputPlus out) throws IOException
     {
-        assert !accessor.isEmpty(value);
-        if (valueLengthIfFixed() >= 0)
-            accessor.write(value, out);
+        assert !accessor.isEmpty(value) : ""bytes should not be empty for type "" + this;
+        int expectedValueLength = valueLengthIfFixed();
+        if (expectedValueLength >= 0)
+        {
+            int actualValueLength = accessor.size(value);
+            if (actualValueLength == expectedValueLength)
+                accessor.write(value, out);
+             else
+                 throw new IOException(String.format(""Expected exactly %d bytes, but was %d"",

Review comment:
       Not sure about whether `AssertionError` or `IOException` makes more sense, since we seem to be mixing both types of exceptions across the `marshal` package for similar cases, probably being `AssertionError` more common. If we decide to use `IOException` maybe we could also use it in the first check for empty values:
   ```java
   int actualValueLength = accessor.size(value);
   if (actualValueLength == 0)
       throw new IOException(""bytes should not be empty for type "" + this);
   ```
   And perhaps we could also use `IOException` in `EmptyValue#writeValue`, which overrides this method, wdyt?

##########
File path: test/unit/org/apache/cassandra/db/marshal/TypeValidationTest.java
##########
@@ -19,16 +19,19 @@
 package org.apache.cassandra.db.marshal;
 
 import org.apache.cassandra.Util;
+import org.apache.cassandra.io.util.DataOutputPlus;

Review comment:
       Not related to the changes, but we could fix the license header to be a block comment instead of JavaDoc, replacing `/**` by `/*` in the very first line of the file.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Mar/21 14:00;githubbot;600","adutra commented on a change in pull request #924:
URL: https://github.com/apache/cassandra/pull/924#discussion_r593312909



##########
File path: test/unit/org/apache/cassandra/db/marshal/TypeValidationTest.java
##########
@@ -19,16 +19,19 @@
 package org.apache.cassandra.db.marshal;
 
 import org.apache.cassandra.Util;
+import org.apache.cassandra.io.util.DataOutputPlus;

Review comment:
       Good idea, done.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Mar/21 16:45;githubbot;600","adutra commented on a change in pull request #924:
URL: https://github.com/apache/cassandra/pull/924#discussion_r593313713



##########
File path: src/java/org/apache/cassandra/db/marshal/AbstractType.java
##########
@@ -435,11 +435,21 @@ public void writeValue(ByteBuffer value, DataOutputPlus out) throws IOException
     // This assumes that no empty values are passed
     public  <V> void writeValue(V value, ValueAccessor<V> accessor, DataOutputPlus out) throws IOException
     {
-        assert !accessor.isEmpty(value);
-        if (valueLengthIfFixed() >= 0)
-            accessor.write(value, out);
+        assert !accessor.isEmpty(value) : ""bytes should not be empty for type "" + this;
+        int expectedValueLength = valueLengthIfFixed();
+        if (expectedValueLength >= 0)
+        {
+            int actualValueLength = accessor.size(value);
+            if (actualValueLength == expectedValueLength)
+                accessor.write(value, out);
+             else

Review comment:
       You are lynx-eyed! Fixed, thanks.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Mar/21 16:47;githubbot;600","adutra commented on a change in pull request #924:
URL: https://github.com/apache/cassandra/pull/924#discussion_r593345250



##########
File path: src/java/org/apache/cassandra/db/marshal/AbstractType.java
##########
@@ -435,11 +435,21 @@ public void writeValue(ByteBuffer value, DataOutputPlus out) throws IOException
     // This assumes that no empty values are passed
     public  <V> void writeValue(V value, ValueAccessor<V> accessor, DataOutputPlus out) throws IOException
     {
-        assert !accessor.isEmpty(value);
-        if (valueLengthIfFixed() >= 0)
-            accessor.write(value, out);
+        assert !accessor.isEmpty(value) : ""bytes should not be empty for type "" + this;
+        int expectedValueLength = valueLengthIfFixed();
+        if (expectedValueLength >= 0)
+        {
+            int actualValueLength = accessor.size(value);
+            if (actualValueLength == expectedValueLength)
+                accessor.write(value, out);
+             else
+                 throw new IOException(String.format(""Expected exactly %d bytes, but was %d"",

Review comment:
       > Not sure about whether AssertionError or IOException makes more sense
   
   I guess the real question is: do we consider an invalid length as a violation of the class invariants (in which case `AssertionError` is the appropriate error), or is it an exceptional state that we need to deal with (in which case we would go with `IOException`)?
   
   I did a small research in the `marshal` package:
   
   `AssertionError` or `assert` is used mostly to detect violations of:
   * Empty / non-empty type expectations
   * ASCII / UTF-8 encoding expectations
   * Single / Multi cell expectations
   * UUID length expectations
   
   `IOException` is in fact very rare. It is declared to be thrown in various methods, but it is only actually thrown in
   `AbtractType.read()`. Otherwise, most IOEs come from the methods in `ValueAccessor`.
   
   There is also `MarshalException`. It is being thrown for validation errors and string parsing errors mostly.
   
   With the above in mind, and considering my limited knowledge of Cassandra internals, I would say that invalid lengths could very well happen IRL, and therefore I wouldn't consider them as invariants to be expressed as assertions. IOW `IOException` doesn't look like an awkward choice in the present case.
   
   As an example of when and how this could happen, maybe you recall [this test](https://github.com/adutra/cassandra/blob/576cb2b8a4267467b507cb88e841462314d2aaee/test/unit/org/apache/cassandra/index/sasi/SASIIndexTest.java#L1186)? It manages to violate the buffer length expectation in question. Granted, to get there, it needs to fake a pretty serious condition: one mutation is created with the wrong type for one of the cells. I don't know if the system can be put in such an inconsistent state by user intervention, but it does seem possible, at least, to violate the expectation with just a few lines of code.
   
   > maybe we could also use it in the first check for empty values
   
   I am not sure. Buffer emptiness, on the other hand, does look like a breakage in the class invariants. We have `EmptyType` that deals with empty buffers, so using any other instance of `AbstractType` for that seems to me like an impossible situation. But again, I might be misinterpreting all this.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Mar/21 17:35;githubbot;600","adelapena commented on a change in pull request #924:
URL: https://github.com/apache/cassandra/pull/924#discussion_r595088878



##########
File path: src/java/org/apache/cassandra/db/marshal/AbstractType.java
##########
@@ -435,11 +435,21 @@ public void writeValue(ByteBuffer value, DataOutputPlus out) throws IOException
     // This assumes that no empty values are passed
     public  <V> void writeValue(V value, ValueAccessor<V> accessor, DataOutputPlus out) throws IOException
     {
-        assert !accessor.isEmpty(value);
-        if (valueLengthIfFixed() >= 0)
-            accessor.write(value, out);
+        assert !accessor.isEmpty(value) : ""bytes should not be empty for type "" + this;
+        int expectedValueLength = valueLengthIfFixed();
+        if (expectedValueLength >= 0)
+        {
+            int actualValueLength = accessor.size(value);
+            if (actualValueLength == expectedValueLength)
+                accessor.write(value, out);
+             else
+                 throw new IOException(String.format(""Expected exactly %d bytes, but was %d"",

Review comment:
       Makes, sense, using `IOException` is fine by me.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/21 11:39;githubbot;600","smiklosovic closed pull request #924:
URL: https://github.com/apache/cassandra/pull/924


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:33;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,5400,,,0,5400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adutra,,,,,,,,,,,,,Code,,,,,,,,Low Hanging Fruit,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Mar 26 05:29:14 UTC 2021,,,,,,,All,,,,"0|z0oenk:",9223372036854775807,,,,adelapena,bereng,,,Low,,4.0-beta4,,https://github.com/apache/cassandra/commit/eb68380866c9d96592580fefbc1b79a497a674bf,,,,,,,,,PR: https://github.com/apache/cassandra/pull/924,,,,,"11/Mar/21 14:12;adelapena;Overall looks good to me, I have left a couple of comments on the PR. Do we have CirceCI runs for the patch?;;;","12/Mar/21 05:19;bereng;+1 to missing CI runs;;;","16/Mar/21 11:42;adelapena;Last changes look good to me. [Here|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/487/pipeline] is a ci-cassandra run, it would be good to have a CircleCI run as well.;;;","16/Mar/21 13:11;bereng;meh... Some error and it failed. Maybe a rebase is needed?;;;","16/Mar/21 17:18;adelapena;I have copied the branch in [my repo|https://github.com/adelapena/cassandra/tree/CASSANDRA-16500-trunk], rebased and added the MIDRES CircleCI config myself. CircleCI is running for [j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/226/workflows/f4c62d22-1436-4736-8360-58a196286ad6] and [j11,|https://app.circleci.com/pipelines/github/adelapena/cassandra/226/workflows/498123c3-a580-4c64-b95f-5b94499b72aa] and Jenkins is running again [here|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/489/pipeline].;;;","16/Mar/21 17:43;adelapena;It seems that [ScrubTest.testScrubColumnValidation|https://github.com/apache/cassandra/blob/47b9887ee2a3ce20d207472cbdd814b9852eb68b/test/unit/org/apache/cassandra/db/ScrubTest.java#L551] fails due to the new validation. The [patch|https://github.com/apache/cassandra/commit/c4064dd80e427aec7c04e8e2e1e4630d6c8087b6] that introduced this validation for 3.0 and 3.11 in CASSANDRA-15778 contains the (trivial) fix.;;;","16/Mar/21 22:33;adutra;Thank you both for the thorough reviews. I cherry-picked Andrés' commit and also fixed {{ScrubTest.testScrubColumnValidation}} manually (it wasn't possible to cherry-pick). Let's see how this goes with CI.;;;","17/Mar/21 11:37;adelapena;[~adutra] do you have a CircleCI project for Cassandra? I guess it would be [here|https://app.circleci.com/pipelines/github/adutra/cassandra?branch=CASSANDRA-16500-trunk].;;;","17/Mar/21 12:39;adelapena;Running CI:

* [CircleCi j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/227/workflows/837e54e1-c870-4312-900a-f0a83a83d615]
* [CircleCi j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/227/workflows/edbfdb49-c60e-42ea-aa9b-bb55d558f75f]
* [Jenkins|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/490/pipeline];;;","18/Mar/21 14:05;adutra;I just set up my CircleCI project for Cassandra, however I might not have enough permissions because the only branch I can build is trunk. 

Anyways, you've run the jobs for me, thank you. I don't think the failures are related to this change, wdyt?;;;","19/Mar/21 16:09;adelapena;I'd say the CI failures are not related, [~Bereng] wdyt?

Here is an additionally CI run, just in case:
* [CircleCI j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/229/workflows/55655699-590e-47fd-b124-3fefec9deacd]
* [CircleCI j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/229/workflows/f84403e8-cb57-4170-9797-659fa5404e6d]
* [Jenkins|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/501/pipeline];;;","22/Mar/21 06:04;bereng;I'd say +1 and that they are not related bc most are timeouts which probably relate to CASSANDRA-16493. But:

-  dtest-upgrade.upgrade_tests.compatibility_flag_test.TestCompatibilityFlag.test__compatibility_flag_off_3014
- org.apache.cassandra.distributed.test.NetstatsRepairStreamingTest.testWithCompressionDisabled

annoy me. If you're OCD like me I'd rebase now that was merged and run an extra CI. ;;;","22/Mar/21 14:50;adelapena;Here goes a new CI round:
* [CircleCI j8 |https://app.circleci.com/pipelines/github/adelapena/cassandra/231/workflows/9a3abb64-968f-4159-afad-f6e71ed538b7]
* [CircleCI j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/231/workflows/c2c86374-e720-4528-92f8-e0f1f1ad588a]
* [Jenkins     |https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/504/pipeline];;;","23/Mar/21 05:44;bereng;LGTM;;;","23/Mar/21 10:48;adelapena;Looks good to me too, +1. I think we still need a second committer approval, [~blerer] would you have time to take a look?;;;","25/Mar/21 19:38;e.dimitrova;I think you already have a second committer review +1 (congrats one more time [~Bereng]) so in order to speed up the CI cleaning I will commit this now. :) ;;;","25/Mar/21 19:59;e.dimitrova;Committed [here |https://github.com/apache/cassandra/commit/eb68380866c9d96592580fefbc1b79a497a674bf] and a CHANGES.txt ninja fix [here |https://github.com/apache/cassandra/commit/866844743ec3cd23451b0158a7841a026e2e68d6]

Thank you all!;;;","26/Mar/21 05:29;bereng;LOL! thx...;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Python upgrade DTests fail in CircleCI,CASSANDRA-16498,13362743,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,samt,e.dimitrova,e.dimitrova,06/Mar/21 02:29,09/Mar/21 16:33,13/Jul/23 08:40,09/Mar/21 08:14,4.0,4.0-rc1,,,,,,CI,,,,0,,,"[https://app.circleci.com/pipelines/github/adelapena/cassandra/210/workflows/48230e6d-9fe0-4321-92b0-3709c86c5e16/jobs/1722]

It seems at some point in time JAVA8_HOME got lost from the CircleCI configuration. Upgrade Tests are not always run so that was missed. 

I tried just to ninja fix JAVA8_HOME by adding it back as part of the default variables as it was there before but then the build fails for Java 11 HIGHRES for missing Jars. It doesn't fail for Java 11 in MIDRES.

I have to check it further next week. ",,e.dimitrova,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,samt,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 09 08:14:00 UTC 2021,,,,,,,All,,,,"0|z0od68:",9223372036854775807,,,,e.dimitrova,,,,Low,,4.0-beta4,,https://github.com/apache/cassandra/commit/79f73c2e39619717953deec5a46764df3a6e27af,,,,,,,,,Run python and java tests for JDK8 & JDK11.,,,,,"08/Mar/21 16:38;samt;It looks like it was [this commit|https://github.com/apache/cassandra-builds/commit/29dccda73cec1c80ffa838a3109c8bef68f162ee] for CASSANDRA-16428 and subsequent rebuild of the docker testing images that broke things. The patch removes the {{ENV}} directives which set {{JAVA8_HOME/JAVA11_HOME}} in from the dockerfile and instead echoes the values out to {{.bashrc}}. Circle doesn't source {{.bashrc}} though, so the vars stopped being available to the running steps. 

We could restore them to the dockerfile and republish images, but in the meantime I'm taking a look at why adding them to the default env vars in {{config-2.1.yaml}} is a problem. They were originally present there, but a trunk only commit wiped them out (hence why {{JAVA8_HOME}} is still present on the 3.11/3.0 branches.;;;","08/Mar/21 21:46;samt;I added the fix to the CASSANDRA-16489 branch and Circle looks good again now. See [this comment|https://issues.apache.org/jira/browse/CASSANDRA-16489?focusedCommentId=17297717&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17297717] for details.;;;","09/Mar/21 03:28;e.dimitrova;LGTM, thank you!;;;","09/Mar/21 08:14;samt;Thanks for the review, committed to trunk in {{79f73c2e39619717953deec5a46764df3a6e27af}};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution broken,CASSANDRA-16497,13362722,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mck,aholmber,aholmber,05/Mar/21 22:25,19/Nov/21 06:56,13/Jul/23 08:40,22/Mar/21 16:23,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"{noformat}
junit.framework.AssertionFailedError
	at org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution(LongSharedExecutorPoolTest.java:169)
	at org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution(LongSharedExecutorPoolTest.java:102)
{noformat}

https://ci-cassandra.apache.org/job/Cassandra-trunk/308/testReport/org.apache.cassandra.concurrent/LongSharedExecutorPoolTest/testPromptnessOfExecution/",,aholmber,bereng,blerer,brandon.williams,e.dimitrova,jlewandowski,mck,,,,,,,,,"jacek-lewandowski opened a new pull request #956:
URL: https://github.com/apache/cassandra/pull/956


   There were two problems in this test. First is that what is called 'timeout' has a 'deadline'
   semantics which means that it is a point in time rather than a duration. However in one place
   it was used as a timeout, thus everything got confused at some point and the actual deadlines
   turned out to be negative.
   
   The other problem was that with some probability we choose a deadline as Long.MAX_VALUE.
   After that, we call Future.get with the corresponding timeout - the timeout is calculated by
   subtracting System.nanotime from our deadline (which is Long.MAX_VALUE). However, Future.get
   internally adds back System.nanotime to the timeout and passed that to some internal method
   await. The problem is that, between subtracting System.nanotime and adding it back, some
   time elapses and the second call to System.nanotime returns a larger value, thus the deadline
   calculated internally in Future.get overflows the long domain.


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Apr/21 09:17;githubbot;600","jacek-lewandowski closed pull request #956:
URL: https://github.com/apache/cassandra/pull/956


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 06:56;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,CASSANDRA-16382,,,,,CASSANDRA-16993,,,,,,,,,,,,,,,,,,,,,,,0.0,mck,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Sep 24 17:17:23 UTC 2021,,,,,,,All,,,,"0|z0od1k:",9223372036854775807,,,,e.dimitrova,,,,Normal,,3.0.24,,https://github.com/apache/cassandra/commit/86a3cfe2fa7d8dcf070fd8d3297cdabffe410934,,,,,,,,,CI,,,,,"07/Mar/21 17:23;brandon.williams;This is actually different from the flakiness and is 100% broken here.  We have two problems :(;;;","08/Mar/21 15:39;brandon.williams;I'm not going to repeat myself, but if someone else wants to mark this as duplicate again, please read my previous comment.;;;","08/Mar/21 16:18;brandon.williams;Specifcally, failing like this fairly quickly:

{quote}
[junit-timeout] Testcase: testPromptnessOfExecution(org.apache.cassandra.concurrent.LongSharedExecutorPoolTest):        FAILED
[junit-timeout] null
[junit-timeout] junit.framework.AssertionFailedError
[junit-timeout]         at org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution(LongSharedExecutorPoolTest.java:169)
{quote}

I took quick look here and CI says the first build was 303: https://ci-cassandra.apache.org/job/Cassandra-trunk/303/testReport/junit/org.apache.cassandra.concurrent/LongSharedExecutorPoolTest/testPromptnessOfExecution/history/ but that was where I upgraded jackson, which doesn't make sense.  I tried the commit before that and it failed the same way, so it's not that.;;;","09/Mar/21 06:22;bereng;Mmmm all good locally, doesn't fail quickly.

{noformat}
[junit-timeout] Testsuite: org.apache.cassandra.concurrent.LongSharedExecutorPoolTest
[junit-timeout] Testsuite: org.apache.cassandra.concurrent.LongSharedExecutorPoolTest Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 480.285 sec
{noformat};;;","21/Mar/21 20:51;mck;I can reproduce this locally.

Using this [patch|https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/trunk/16497_experiment], the timed-out uncompleted result is often less than a millisecond away from finishing.

I'm curious as to why the value of 100ms is added, and the general calculation, is taken [here|https://github.com/apache/cassandra/blob/trunk/test/burn/org/apache/cassandra/concurrent/LongSharedExecutorPoolTest.java#L209-L210]. Bumping the value up prevents the failures.;;;","22/Mar/21 12:20;mck;[~benedict], this test failure is currently the biggest blocker we have to 4.0-rc1, as it is pretty much consistently failing in CI.

I can think of a few ways forward here, but am not sure which is best…
 - bump the [timeout|https://github.com/apache/cassandra/blob/trunk/test/burn/org/apache/cassandra/concurrent/LongSharedExecutorPoolTest.java#L209-L210] from 100ms to 1s
 - replace the [assertion|https://github.com/apache/cassandra/blob/trunk/test/burn/org/apache/cassandra/concurrent/LongSharedExecutorPoolTest.java#L169] with just a system.out line
 - rewrite the test to jmh
 -  just remove the test;;;","22/Mar/21 13:10;blerer;My understanding is that the goal of this test was to check the SEPThreadpool throughput. As such it does not make a lot of sense to me to simply bump the timeout or replace the assertion.
In my opinion, we should simply remove the test and plan for the next release to introduce some proper automated performance testing that allow us to catch performance regressions.  ;;;","22/Mar/21 14:12;mck;+1 to removing it, and revisiting it post 4.0.;;;","22/Mar/21 15:28;mck;Patch at https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/trunk/16497 

CI [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-test-burn/302//badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-test-burn/302//];;;","22/Mar/21 15:45;e.dimitrova;+1 on the patch, assuming everything is alright with the CI run which is still ongoing. Thanks;;;","22/Mar/21 16:23;mck;Committed as [86a3cfe2fa7d8dcf070fd8d3297cdabffe410934|https://github.com/apache/cassandra/commit/86a3cfe2fa7d8dcf070fd8d3297cdabffe410934].;;;","09/Apr/21 07:30;jlewandowski;I know what is broken in this test and I can fix it

There were two problems in this test. First is that what is called 'timeout' has a 'deadline'
semantics which means that it is a point in time rather than a duration. However in one place
it was used as a timeout, thus everything got confused at some point and the actual deadlines
turned out to be negative.

The other problem was that with some probability we choose a deadline as Long.MAX_VALUE.
After that, we call Future.get with the corresponding timeout - the timeout is calculated by
subtracting System.nanotime from our deadline (which is Long.MAX_VALUE). However, Future.get
internally adds back System.nanotime to the timeout and passed that to some internal method
await. The problem is that, between subtracting System.nanotime and adding it back, some
time elapses and the second call to System.nanotime returns a larger value, thus the deadline
calculated internally in Future.get overflows the long domain.

I can fix it if you like;;;","09/Apr/21 08:29;blerer;[~jlewandowski] I do not recall exactly all the problems I found when I looked at the test. I definetly fixed the second one. Not sure for the first problem. I found also that in my environment there was a reordering occuring depending on the way task were scheduled on the threads. Overall, I managed to improve the number of runs that I was able to do but I never managed to make it pass in my environment. Some people had the test failing constantly in their environment other not.
Feel free to have a go at it. You might be more successfull than me :-)  ;;;","09/Apr/21 09:17;jlewandowski;[~blerer] my patch is here: https://github.com/apache/cassandra/pull/956
;;;","09/Apr/21 09:19;jlewandowski;The first problem is in https://github.com/apache/cassandra/pull/956/files?diff=unified&w=1#diff-0fae2f0ba0b0832a5608edbff166a3b81d35dbb795ddef6e7a92ec0f086f61f2L151;;;","24/Sep/21 17:17;e.dimitrova;CASSANDRA-16993 was opened to revisit/rewrite this test.

FIY - with the last patch provided the test still fails in my environment. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Scheduled (Delayed) Schema Pull Tasks May Run After MIGRATION Stage Shutdown During Decommission,CASSANDRA-16495,13362712,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,e.dimitrova,maedhroz,maedhroz,05/Mar/21 21:48,25/Apr/21 11:32,13/Jul/23 08:40,07/Apr/21 20:06,3.0.25,3.11.11,4.0,4.0-rc1,,,,Local/Startup and Shutdown,,,,0,,,"A new test added in CASSANDRA-16181 stumbled across this, although it doesn’t happen consistently. When [failure occurs|https://app.circleci.com/pipelines/github/maedhroz/cassandra/235/workflows/eb8133ce-9373-4136-b404-ceca167353f6/jobs/1355/tests], it appears to be because a delayed schema pull happens after decommission shuts down the MIGRATION stage’s thread pool.

{noformat}
ERROR [node1_isolatedExecutor:1] node1 2021-02-15 19:35:36,284 CassandraDaemon.java:579 - Exception in thread Thread[node1_NonPeriodicTasks:1,5,node1] java.util.concurrent.RejectedExecutionException: ThreadPoolExecutor has shut down at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:72) 
at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825) 
at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355) 
at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.execute(DebuggableThreadPoolExecutor.java:176) 
at java.base/java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:118) at org.apache.cassandra.concurrent.Stage.submit(Stage.java:129) 
at org.apache.cassandra.schema.MigrationCoordinator.lambda$scheduleSchemaPull$2(MigrationCoordinator.java:362) 
at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) 
at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) 
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) 
at java.base/java.lang.Thread.run(Thread.java:834)
{noformat}

A fix might be as simple as shutting down ScheduledExecutors.nonPeriodicTasks in StorageService#decommission(). See the original discussion [here|https://issues.apache.org/jira/browse/CASSANDRA-16181?focusedCommentId=17293329&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17293329].",,e.dimitrova,maedhroz,yifanc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16181,CASSANDRA-16568,,,,,,,,,,,,,,,,,,,,,,0.0,e.dimitrova,,,,,,,,,,,,,Correctness -> API / Semantic Implementation,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Apr 07 20:17:00 UTC 2021,,,,,,,All,,,,"0|z0oczc:",9223372036854775807,,,,maedhroz,yifanc,,,Low,,,,https://github.com/apache/cassandra/commit/f2ff96eeaf0f481ebd1fd7314f4caef5a0f75ca9,,,,,,,,,https://issues.apache.org/jira/browse/CASSANDRA-16495?focusedCommentId=17308927&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17308927,,,,,"05/Mar/21 21:54;maedhroz;This has only been observed on 4.0, although the basic problem appears to exist in the 3.x branches as well.;;;","25/Mar/21 19:33;e.dimitrova;I just submitted a patch [here|https://github.com/ekaterinadimitrova2/cassandra/commit/99840c80523a571182abaef495f4ad55223c2291]  for trunk. Jenkins CI triggered [here|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/507/]

I can't really reproduce it and the patch is based only on code analysis, but from what I see I agree with you [~maedhroz]

Wondering whether to port it also to 3.0 and 3.11;;;","26/Mar/21 14:57;maedhroz;As long as we agree on the analysis, better stability of {{HintedHandoffAddRemoveTest}} over time here will be good enough proof for me. I'll review shortly. In terms of 3.0 and 3.11, I'd favor fixing it there as well, assuming it merges cleanly (and given how small the change is).;;;","26/Mar/21 15:33;maedhroz;[~e.dimitrova] I left a couple [minor suggestions|https://github.com/ekaterinadimitrova2/cassandra/commit/99840c80523a571182abaef495f4ad55223c2291], but overall, LGTM;;;","26/Mar/21 21:00;e.dimitrova;Thanks [~maedhroz], all valid points.

[PR|https://github.com/ekaterinadimitrova2/cassandra/pull/] updated.

New CI triggered [here |https://jenkins-cm4.apache.org/job/Cassandra-devbranch/510/]

And I think we need one more committer to review it too.;;;","29/Mar/21 23:51;e.dimitrova;As suggested, I also set _executeExistingDelayedTasksAfterShutdown_ to _false_ and pushed a new CI run [here |https://jenkins-cm4.apache.org/job/Cassandra-devbranch/531/]. ;;;","30/Mar/21 22:36;maedhroz;+1 on where we ended up after today's discussion inline in the PR;;;","05/Apr/21 17:16;yifanc;+1 on the patch. Appreciate the fix and the efforts to address the comments.;;;","05/Apr/21 19:43;e.dimitrova;Thank you both!

I just squashed the commits; pushed patches and submitted CI runs for 3.0, 3.11 and 4.0. The only difference is that Stage class was refactored in 4.0 but this doesn't affect a lot the patch.

[3.0 patch|https://github.com/ekaterinadimitrova2/cassandra/commit/71d06d9b45d907687cef7e1cc6d6210f1b2079c9] | [CI run |https://jenkins-cm4.apache.org/job/Cassandra-devbranch/583/]

[3.11 patch|https://github.com/ekaterinadimitrova2/cassandra/commit/74a6cbd82bfd3c7177f4067bf63e96114dc0ba85] | [CI run |https://jenkins-cm4.apache.org/job/Cassandra-devbranch/584/]

[trunk patch|https://github.com/ekaterinadimitrova2/cassandra/pull/] | [CI run |https://jenkins-cm4.apache.org/job/Cassandra-devbranch/585/];;;","06/Apr/21 14:36;e.dimitrova;The CI looks bad but I think it was due to full disks again so many tests failed. I will submit Circle CI runs too. ;;;","06/Apr/21 21:55;e.dimitrova;j8_dtests_jars_build fails on all branches plus on latest trunk both locally and in CircleCI so it is not related to this patch. I will try to investigate it separately.

trunk: [JAVA 8 CI|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/743/workflows/0fb184bb-1852-4ef5-abb9-bb52bae17091] | [JAVA 11 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/743/workflows/35cea1fd-6f38-4f09-9d7f-4673c34a9851]
 _test_describe - cqlsh_tests.test_cqlsh.TestCqlsh_ - failing in both Java11; seems unrelated?
 _org.apache.cassandra.net.AsyncPromiseTest_ - failing in both Java11; seems unrelated?

3.11: [CI run |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/741/workflows/c3de5483-85b0-48a4-b1fa-1c52f89680c7]
 _test_multiple_repair - repair_tests.incremental_repair_test.TestIncRepair_ - -known failure;- no failures in Jenkins, I was mistaken but seems unrelated timeout
 _test_closing_connections - thrift_hsha_test.TestThriftHSHA - I think it is known failure; I've seen it regularly in Circle_

3.0: [CI run |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/740/workflows/02ad5584-60de-48c3-ba11-565732ac3dea]
 _test_closing_connections - thrift_hsha_test.TestThriftHSHA_ - I think it is known failure

I see also the following warning which needs to be fixed separately and it is unrelated to this patch:
{code:java}
 WARNING: multiple versions of ant detected in path for junit
jar:file:/usr/share/ant/lib/ant.jar!/org/apache/tools/ant/Project.class
and jar:file:/tmp/cassandra/build/test/lib/jars/ant-1.9.7.jar!/org/apache/tools/ant/Project.class
{code};;;","07/Apr/21 16:12;e.dimitrova;[~yifanc], [~maedhroz] any objections or should I move on with commit to all branches?;;;","07/Apr/21 17:32;yifanc;* The failure of {{j8_dtests_jars_build}} is caused by unable to build the dtest jar from -cassandra 2.2- [3.11-CASSANDRA-16495|https://github.com/ekaterinadimitrova2/cassandra/tree/3.11-CASSANDRA-16495]. I checked out the branch and run the same build command locally. It builds successfully. There might be a dependency issue in CI. So not related with this patch. 
 * _test_describe - cqlsh_tests.test_cqlsh.TestCqlsh_ failed at dropping the table, which is a bit suspicious. The change should only kick in when decommissioning, which is not part of the failed test. So it looks unrelated. _test_multiple_repair - repair_tests.incremental_repair_test.TestIncRepair_ is unrelated for the same reason.
 * _org.apache.cassandra.net.AsyncPromiseTest_ should be unrelated.
 * _ test_closing_connections - thrift_hsha_test.TestThriftHSHA_, agree that it is not related.

I think it is good to commit. Please file a ticket for the multiple versions of ant if not exist yet.;;;","07/Apr/21 18:31;maedhroz;No objections to committing.;;;","07/Apr/21 19:01;e.dimitrova;Ticket CASSANDRA-16571 opened for the ant related warnings.

Starting commit. Thanks;;;","07/Apr/21 20:04;e.dimitrova;Committed, thank you

35114d5fcc..3edacd632c  cassandra-3.0 -> cassandra-3.0

6edd7db751..7b10f9cb03  cassandra-3.11 -> cassandra-3.11

51e762c5db..f2ff96eeaf  trunk -> trunk;;;","07/Apr/21 20:17;yifanc;I am able to reproduce the {{j8_dtests_jars_build}} failure on my local. It fails with this build sequence, 1) build the trunk, 2) then build the target branch. Filed a ticket at CASSANDRA-16572;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
IPMembershipTest.sameIPFailWithoutReplace fails with timeout,CASSANDRA-16493,13362685,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,samt,aholmber,aholmber,05/Mar/21 19:37,19/Mar/21 21:40,13/Jul/23 08:40,19/Mar/21 21:40,4.0,4.0-rc1,,,,,,Test/dtest/java,,,,0,,,"https://ci-cassandra.apache.org/job/Cassandra-trunk/307/testReport/junit/org.apache.cassandra.distributed.test/IPMembershipTest/sameIPFailWithoutReplace/

{noformat}
java.lang.RuntimeException: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: localhost/0:0:0:0:0:0:0:1:9042 (com.datastax.driver.core.exceptions.TransportException: [localhost/0:0:0:0:0:0:0:1:9042] Cannot connect), localhost/127.0.0.1:9042 (com.datastax.driver.core.exceptions.OperationTimedOutException: [localhost/127.0.0.1:9042] Operation timed out))
	at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:146)
	at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:114)
	at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpaces(SettingsSchema.java:66)
	at org.apache.cassandra.stress.settings.StressSettings.maybeCreateKeyspaces(StressSettings.java:154)
	at org.apache.cassandra.stress.StressAction.run(StressAction.java:56)
	at org.apache.cassandra.stress.Stress.run(Stress.java:155)
	at org.apache.cassandra.stress.Stress.main(Stress.java:63)
{noformat}",,adutra,aholmber,bereng,brandon.williams,e.dimitrova,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16494,,,,,,,,,,,,,,,,,,,,,,,"09/Mar/21 14:56;brandon.williams;ci-failures.png;https://issues.apache.org/jira/secure/attachment/13021935/ci-failures.png",,,,,1.0,samt,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Mar 19 21:40:56 UTC 2021,,,,,,,All,,,,"0|z0octc:",9223372036854775807,,,,bereng,brandon.williams,e.dimitrova,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/dd6c261119d29208f68c5037741e6390347f5c64,,,,,,,,,Ensure all existing tests are stable,,,,,"09/Mar/21 07:55;bereng;The test repro'es the failure if you run it under j11

{noformat}
java.lang.OutOfMemoryError: Direct buffer memory
[junit-timeout] 	at java.base/java.nio.Bits.reserveMemory(Bits.java:175)
[junit-timeout] 	at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118)
[junit-timeout] 	at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317)
[junit-timeout] 	at io.netty.buffer.PoolArena$DirectArena.allocateDirect(PoolArena.java:645)
[junit-timeout] 	at io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:621)
[junit-timeout] 	at io.netty.buffer.PoolArena.allocateNormal(PoolArena.java:204)
[junit-timeout] 	at io.netty.buffer.PoolArena.tcacheAllocateSmall(PoolArena.java:174)
[junit-timeout] 	at io.netty.buffer.PoolArena.allocate(PoolArena.java:136)
[junit-timeout] 	at io.netty.buffer.PoolArena.allocate(PoolArena.java:128)
[junit-timeout] 	at io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:378)
[junit-timeout] 	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:187)
[junit-timeout] 	at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:178)
[junit-timeout] 	at io.netty.buffer.AbstractByteBufAllocator.ioBuffer(AbstractByteBufAllocator.java:139)
[junit-timeout] 	at io.netty.channel.DefaultMaxMessagesRecvByteBufAllocator$MaxMessageHandle.allocate(DefaultMaxMessagesRecvByteBufAllocator.java:114)
[junit-timeout] 	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:150)
[junit-timeout] 	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
[junit-timeout] 	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
[junit-timeout] 	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
[junit-timeout] 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
[junit-timeout] 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
[junit-timeout] 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[junit-timeout] 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[junit-timeout] 	at java.base/java.lang.Thread.run(Thread.java:834)
{noformat};;;","09/Mar/21 14:33;brandon.williams;Do you have more details on that?  I've got thousands of runs on java11 without issue.  This does look environmentally related though.;;;","09/Mar/21 15:00;brandon.williams;Doing some CI history trawling, it looks like the first commit where this started to fail consistently was c9d6c725dd0b4aa5693eb1c6d2221c28e9e99c6e which was promoting the v5 protocol from beta. Screenshot from private tracking tool attached.  Unfortunately CI is only showing the stress output, which isn't useful but it's probably safe to assume this is always the DirectMemory OOM.  It is worth noting that o.a.c.distributed.test.hostreplacement.HostReplacemenTest does a lot of the same stuff this test does, but does not invoke stress.;;;","09/Mar/21 15:30;samt;[~brandon.williams], are those CI jobs running JDK11?;;;","09/Mar/21 15:33;brandon.williams;I think so? https://ci-cassandra.apache.org/job/Cassandra-trunk/287;;;","09/Mar/21 15:49;samt;Oh sorry, I didn't realise it was just the tracking that was private, I thought you meant an internal CI system.;;;","10/Mar/21 07:10;bereng;Yep confirmed the v5 protocol is the issue. It passes locally on f32475a839e01e4eea3989871d293d70e8a360d7 which is the immediate prior to c9d6c725dd0b4aa5693eb1c6d2221c28e9e99c6e (v5 protocol) where it fails.;;;","10/Mar/21 14:36;e.dimitrova;I feel [these failures|https://issues.apache.org/jira/browse/CASSANDRA-16494?focusedCommentId=17297810&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17297810] might be useful to know about. The tests were run locally on my Mac, Java 8

The assertion error rooted in the V5 switch;;;","10/Mar/21 15:04;samt;Thanks, that issue is known (and fixed) in [https://datastax-oss.atlassian.net/browse/JAVA-2922.] 
I believe a release of the java-driver is imminent, at which point I'll update the bundled lib for CASSANDRA-13951;;;","17/Mar/21 14:56;samt;With Java versions >= 9, Netty requires a system property to be set to enable the use of unsafe (i.e. without a {{Cleaner}}) direct buffer creation. Without this set, Netty buffer pools, which are currently still used for CQL Message encoding in both v4 and v5, fall back to using {{ByteBuffer.allocateDirect(int)}} which has inferior performance and can lead to OOMs as seen here if we attempt to allocate more than the permitted maximum. In this case, multiple instances are being started in the same JVM and each has its own PooledByteBufAllocator. Coupling this with the switch to protocol v5, which uses C*'s own buffer pool for the outer frame buffers causes the direct memory allocation to exceed the limit when running this test. 

Setting the system property {{io.netty.tryReflectionSetAccessible=true}} reverts to the same buffer creation method as java 8, after which I don't see any OOMs when running the test. I've also inspected heap dumps taken while running the test under several configurations which confirm this analysis. 


|Patch| [here|https://github.com/apache/cassandra/compare/trunk...beobal:16493-trunk]|
|Circle CI| [here|https://app.circleci.com/pipelines/github/beobal/cassandra?branch=16493-trunk]|
|Apache CI| [here|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/492/]|
;;;","18/Mar/21 05:36;bereng;^ That is 100% correct. I knew about this property in CASSANDRA-16413 and I'd swear I had tested it here but it didn't fix it for me. So I probably got sthg wrong in the process. +1 doesn't OOM for me now, but I'm no committer.;;;","19/Mar/21 20:24;brandon.williams;+1;;;","19/Mar/21 21:07;e.dimitrova;Thank you [~samt], I am +1 on the patch. 

For the broader audience, I reached out to [~samt] on Slack as I was wondering how this affected only this test and not others, like the other one in the same class. He provided broad analysis he did as he had the same questions himself. The answer is not completely obvious immediately and it was backed up by testing. I will leave the details to him to share if he feels like adding some of his notes.

Thanks! ;;;","19/Mar/21 21:40;e.dimitrova;Committed [here |https://github.com/apache/cassandra/commit/dd6c261119d29208f68c5037741e6390347f5c64];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nodetool bootstrap resume returns success even if there is an error during bootstrap,CASSANDRA-16491,13362678,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,lmtrombone,maedhroz,maedhroz,05/Mar/21 18:50,28/Oct/22 22:45,13/Jul/23 08:40,28/Oct/22 22:45,5.0,,,,,,,Tool/nodetool,,,,0,,,"""nodetool bootstrap resume” prints a relevant error message if the operation fails, but it then proceeds to return a normal error code. It ignores the ProgressEventType.ERROR message that arrives before COMPLETE. This also happens when we handle failed connections. BootstrapMonitor should at least track whether or not it has seen an error, which would allow us to throw when one occurs after signaling, and therefore to inform callers.

Trunk PR: [https://github.com/apache/cassandra/pull/1949]",,aleksey,lmtrombone,maedhroz,,,,,,,,,,,,,"lmtrombone opened a new pull request, #1949:
URL: https://github.com/apache/cassandra/pull/1949

   There is some issue where the `nodetool bootstrap resume` command returns success successfully even when some error happens during the operation.  To address that, we now keep track of the errors when they occur in `BootstrapMonitor` and now throw them after signaling.  Also as part of this MR, I made a change so we don't send a `ProgressEventType.COMPLETE` event anymore when we see an error as that seems to be a bit misleading.
   
   To reproduce a scenario, I killed one of the nodes involved in the bootstrap resume process and checked if errors were thrown in the terminal.


;25/Oct/22 05:34;githubbot;600","maedhroz commented on code in PR #1949:
URL: https://github.com/apache/cassandra/pull/1949#discussion_r1005181203


##########
src/java/org/apache/cassandra/tools/BootstrapMonitor.java:
##########
@@ -34,6 +34,7 @@ public class BootstrapMonitor extends JMXNotificationProgressListener
     private final SimpleDateFormat format = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss,SSS"");
     private final PrintStream out;
     private final Condition condition = newOneTimeCondition();
+    private Exception error;

Review Comment:
   I think this is going to need to be `volatile`, as it's written by one thread and accessed by another.



;26/Oct/22 03:31;githubbot;600","maedhroz commented on code in PR #1949:
URL: https://github.com/apache/cassandra/pull/1949#discussion_r1005193092


##########
src/java/org/apache/cassandra/service/StorageService.java:
##########
@@ -2074,7 +2074,6 @@ public void onFailure(Throwable e)
                     }
                     logger.error(message, e);
                     progressSupport.progress(""bootstrap"", new ProgressEvent(ProgressEventType.ERROR, 1, 1, message));
-                    progressSupport.progress(""bootstrap"", new ProgressEvent(ProgressEventType.COMPLETE, 1, 1, ""Resume bootstrap complete""));

Review Comment:
   The thing that worries me about this is that it will hang older versions of `nodetool` when an error occurs. They will be waiting for a `COMPLETE` that will never arrive after printing the error message. The fact that we're changing the behavior of `nodetool` itself on error in this Jira probably means that we only need to patch trunk, but it's probably not worth it to remove the `COMPLETE` here.



;26/Oct/22 03:56;githubbot;600","maedhroz commented on code in PR #1949:
URL: https://github.com/apache/cassandra/pull/1949#discussion_r1005195717


##########
src/java/org/apache/cassandra/tools/NodeProbe.java:
##########
@@ -1992,6 +1992,8 @@ public void resumeBootstrap(PrintStream out) throws IOException
             {
                 out.println(""Resuming bootstrap"");
                 monitor.awaitCompletion();
+                if (monitor.getError() != null)
+                    throw monitor.getError();

Review Comment:
   This is obviously going to change the return contract for `resume`, but it's really just a bug fix. I don't see it requiring a `NEWS.txt` entry. (Just `CHANGES.txt`.)



;26/Oct/22 03:59;githubbot;600","lmtrombone commented on code in PR #1949:
URL: https://github.com/apache/cassandra/pull/1949#discussion_r1006468044


##########
src/java/org/apache/cassandra/tools/BootstrapMonitor.java:
##########
@@ -82,9 +83,19 @@ public void progress(String tag, ProgressEvent event)
             message = message + "" (progress: "" + (int)event.getProgressPercentage() + ""%)"";
         }
         out.println(message);
+        if (type == ProgressEventType.ERROR)
+        {
+            error = new RuntimeException(String.format(""Bootstrap resume has failed with error: %s"", message));
+            condition.signalAll();

Review Comment:
   @maedhroz Since I reverted my changes where I removed the `ProgressEventType.COMPLETE` event that was being sent, I assume we can just rely on the logic below (lines 91-94) where it already calls `condition.signalAll();`?   When we encounter an issue, I noticed that we always both `ProgressEventType.ERROR` and `ProgressEventType.COMPLETE` events so it seems a little redundant and unnecessary now.



;27/Oct/22 06:55;githubbot;600","maedhroz commented on code in PR #1949:
URL: https://github.com/apache/cassandra/pull/1949#discussion_r1007119006


##########
CHANGES.txt:
##########
@@ -68,6 +68,7 @@
  * Add new CQL function maxWritetime (CASSANDRA-17425)
  * Add guardrail for ALTER TABLE ADD / DROP / REMOVE column operations (CASSANDRA-17495)
  * Rename DisableFlag class to EnableFlag on guardrails (CASSANDRA-17544)
+ * Nodetool bootstrap resume will now return an error if the operation fails (CASSANDRA-16491)

Review Comment:
   Committer can fix this up on commit too, but make sure CHANGES bits go a the top of the appropriate section, not the bottom. (For a hint, look at the date progression of the `git blame` annotation in your IDE, etc.)



;27/Oct/22 16:29;githubbot;600","maedhroz commented on code in PR #1949:
URL: https://github.com/apache/cassandra/pull/1949#discussion_r1007268481


##########
src/java/org/apache/cassandra/tools/BootstrapMonitor.java:
##########
@@ -82,9 +83,19 @@ public void progress(String tag, ProgressEvent event)
             message = message + "" (progress: "" + (int)event.getProgressPercentage() + ""%)"";
         }
         out.println(message);
+        if (type == ProgressEventType.ERROR)
+        {
+            error = new RuntimeException(String.format(""Bootstrap resume has failed with error: %s"", message));
+            condition.signalAll();

Review Comment:
   I definitely wouldn't do it this way from scratch, but it's probably just not worth the compatibility headache. What we have now LGTM



;27/Oct/22 19:13;githubbot;600","maedhroz commented on PR #1949:
URL: https://github.com/apache/cassandra/pull/1949#issuecomment-1293963983

   https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16491-circle


;27/Oct/22 19:22;githubbot;600","maedhroz commented on PR #1949:
URL: https://github.com/apache/cassandra/pull/1949#issuecomment-1295586988

   Committed in https://github.com/apache/cassandra/commit/8ec04361b9e098430023e4776baf1941be958475


;28/Oct/22 22:44;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,5400,,,0,5400,,,,,,,,,,CASSANDRA-16490,CASSANDRA-16492,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,lmtrombone,,,,,,,,,,,,,Correctness -> API / Semantic Implementation,,,,,,,,Low Hanging Fruit,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Oct 28 20:35:01 UTC 2022,,,,,,,All,,,,"0|z0ocrs:",9223372036854775807,,,,aleksey,maedhroz,,,Low,,3.11.0,,https://github.com/apache/cassandra/commit/8ec04361b9e098430023e4776baf1941be958475,,,,,,,,,"Test locally using ccm, `nodetool bootstrap resume`, and JConsole, additions to {{BootstrapBinaryDisabledTest}}",,,,,"26/Oct/22 04:23;maedhroz;Thanks for the patch. I've made a pass at review and left a few comments in the PR. Once we resolve that feedback, I can create a branch to run the CircleCI tests with appropriate hardware.;;;","27/Oct/22 07:16;lmtrombone;Thanks [~maedhroz] .  I just addressed the comments in the PR.  I did have a follow-up question that I left on the PR though.  But if that doesn't warrant additional changes then I think we should be good to go.;;;","27/Oct/22 19:13;maedhroz;+1

Just need to find a second committer to review now. Also, I'll start a CircleCI run w/ a clone of your branch shortly...;;;","28/Oct/22 11:41;aleksey;+1;;;","28/Oct/22 16:05;maedhroz;[~lmtrombone] If you don't mind squashing to single commit and rebasing your PR, I can commit it later today. Thanks!;;;","28/Oct/22 20:35;lmtrombone;[~maedhroz] Merge conflicts has been resolved, PR has been squashed, and commit message has been updated so it should be good to go whenever you have time.   Thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add utest_system_keyspace_directory to CircleCI config template,CASSANDRA-16489,13362655,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,samt,samt,samt,05/Mar/21 17:08,09/Mar/21 16:33,13/Jul/23 08:40,09/Mar/21 08:12,4.0,4.0-rc1,,,,,,CI,,,,0,,,"In CASSANDRA-14793 a new circle job config was added directly to the CircleCI base, LOWRES, MIDRES and HIGHRES config files, but not to the template file. When the config was regenerated for CASSANDRA-16474, the new job was lost. We should restore it and add it to the config template to avoid any reoccurrence.",,e.dimitrova,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,samt,,,,,,,,,,,,,Degradation -> Other Exception,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 09 08:12:48 UTC 2021,,,,,,,All,,,,"0|z0ocmo:",9223372036854775807,,,,e.dimitrova,,,,Low,,4.0-beta4,,https://github.com/apache/cassandra/commit/9943d4b3035c2c69cd28001254b743b5c494ab01,,,,,,,,,n/a,,,,,"05/Mar/21 17:15;samt;I've added the missing job to the template & regenerated the low, mid and high resource files. I've also copied {{config.yml.LOWRES}} to {{config.yml}}, which I should've done in CASSANDRA-16474. 

[patch|https://github.com/apache/cassandra/compare/trunk...beobal:16489-trunk?expand=1];;;","05/Mar/21 18:21;e.dimitrova;Thanks [~samt], I made a pass and I have only one question, we don't have to patch utests_system_keyspace_directory for higher resources, they are fine with medium resources? I mean for LOWRES and MIIDRES probably we are good as that is how the tests were added initially. But I wasn't sure whether you guys want them on HIGHRES on your end?

Maybe it is a good idea to trigger one clean run?;;;","06/Mar/21 01:13;e.dimitrova;I ended up running CI as I was trying to fix one more issue which we thought it is a matter of line but it turned out it is not so I am going to open a new ticket for that one.

 CI runs look similar to Jenkins:
MIDRES - [JAVA8 | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/668/workflows/fdc790c1-86ed-4132-9bd7-8f514e7d9574] | [JAVA11 | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/667/workflows/ace464c4-41eb-4ca5-8814-508e130a88b1]
HIGHRES - [JAVA8 | https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/668/workflows/fdc790c1-86ed-4132-9bd7-8f514e7d9574] | [JAVA11 |https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/668/workflows/6f361605-0da3-40e3-ba49-fd9eb0c6d324 ];;;","06/Mar/21 02:15;e.dimitrova;I was thinking to commit the patch tonight but there is one thing I just saw.

_utest_system_keyspace_directory_ turns out to need approval to be started not only by _utest_system_keyspace_directory_ but also by _utests_fqltool_

For reference, please, check the line connections in the diagram from the  [JAVA8|https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/668/workflows/fdc790c1-86ed-4132-9bd7-8f514e7d957] CI run

I know this was set during the initial addition of the tests but I think it is wrong, we should be able to start them as unit tests in their own group. I don't think those have anything in common with the FQLtool. (CC [~blerer] as an author to correct me in case I am wrong :));;;","08/Mar/21 09:03;samt;Sorry, that's a bad copy pasta from me. I've pushed fixed versions and I'll run through CI now.;;;","08/Mar/21 21:45;samt;Added a fix for CASSANDRA-16498 to the [branch|https://github.com/apache/cassandra/compare/trunk...beobal:16489-trunk?expand=1] and re-ran Circle jobs. 

[JDK 8 |https://app.circleci.com/pipelines/github/beobal/cassandra/250/workflows/38d3199f-bc21-48da-97f6-479ca24d8dad] and [JDK 11|https://app.circleci.com/pipelines/github/beobal/cassandra/250/workflows/1962796c-ac14-4854-89d9-2c12a4830c27] both look good. Except for known failures from CASSANDRA-16483 & one flaky repair test, all python tests are now passing. ;;;","09/Mar/21 03:28;e.dimitrova;LGTM, thank you!;;;","09/Mar/21 08:12;samt;Thanks, committed to trunk in {{9943d4b3035c2c69cd28001254b743b5c494ab01}};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Audit consumption/removal of ApplicationState padding,CASSANDRA-16484,13362319,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,04/Mar/21 14:35,05/Mar/21 17:51,13/Jul/23 08:40,05/Mar/21 17:51,4.0,4.0-rc1,,,,,,Cluster/Gossip,,,,0,,,"It looks like some padding states, which should never be removed or changed, has occurred in ApplicationState.  This ticket will serve to correct that.",,blerer,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Mar 05 17:51:28 UTC 2021,,,,,,,All,,,,"0|z0oak8:",9223372036854775807,,,,blerer,e.dimitrova,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/78b13cd0e7a33d45c2081bb135e860bbaca7cbe5,,,,,,,,,unit test added,,,,,"04/Mar/21 14:49;brandon.williams;First, some explanation.  Since AS uses an enum, if a state outside of that is referenced, the enum is blown and the gossiper is toast.  This is unfixable without downtime since the now poisonous state is in the 'gossip ether.'  This is why X_11_PADDING exists in a special position, because we nearly made what I call 'gossipocalypse' happen around that timeframe, by adding too many states.  The other padding states were added about the same time, as a preventative measure for the future.  This is so that the enum has room for new states in a newer version that can be accessed without blowing the enum in lesser versions (even though the states are just padding to those machines, and thus useless.)

These are not intended to be consumed, as that would put a nonsensical limit on how many states we can ever add, where the intent is that the padding creates enough room to add the same amount of new states between versions.  Thus, new states should always be added, before the padding, and the padding left untouched so that the next version also has room to perform addition safely.;;;","04/Mar/21 16:57;brandon.williams;|Patch|CI|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16484]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/460/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/460/pipeline]|
;;;","04/Mar/21 17:04;brandon.williams;[~paulo] could you review?;;;","04/Mar/21 17:16;brandon.williams;Ordering was not broken so simply putting the padding back should be sufficient.  I also added a test so we can't even compile if these are removed in the future.;;;","05/Mar/21 17:17;blerer;The patch LGTM. +1;;;","05/Mar/21 17:22;e.dimitrova;I am also +1, and thanks for adding the test, that will definitely ensure less confusion and troubles in the future :);;;","05/Mar/21 17:51;brandon.williams;Committed, thank you all for the quick reviews!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ColumnFilter::toString doesn't return a valid CQL fragment,CASSANDRA-16483,13362289,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adelapena,samt,samt,04/Mar/21 12:16,11/Mar/21 12:50,13/Jul/23 08:40,10/Mar/21 17:46,3.0.25,3.11.11,4.0,4.0-rc1,,,,Observability/Logging,,,,0,,,"This was changed in CASSANDRA-16415 to include indications about queried vs fetched reagular & static columns. However, the result is used by {{AbstractReadQuery::toCQLString}}, which causes it to produce an illegal query string.

This breaks a couple of dtests because they're looking for CQL strings in logs, which are no longer found:
* {{upgrade_tests/paging_test.py::TestPagingWithDeletions::test_failure_threshold_deletions}}
* {{cql_test.py::TestCQLSlowQuery}} has a couple of failing tests, {{test_local_query/test_remote_query}}

We should also check audit and fql logs (and any other place where {{toCQLString}} is used.
",,adelapena,blerer,samt,yifanc,,,,,,,,,,,,"adelapena opened a new pull request #917:
URL: https://github.com/apache/cassandra/pull/917


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;05/Mar/21 17:56;githubbot;600","adelapena opened a new pull request #918:
URL: https://github.com/apache/cassandra/pull/918


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;05/Mar/21 17:56;githubbot;600","adelapena opened a new pull request #919:
URL: https://github.com/apache/cassandra/pull/919


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;05/Mar/21 17:56;githubbot;600","adelapena opened a new pull request #129:
URL: https://github.com/apache/cassandra-dtest/pull/129


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;05/Mar/21 17:58;githubbot;600","blerer commented on a change in pull request #917:
URL: https://github.com/apache/cassandra/pull/917#discussion_r589407135



##########
File path: src/java/org/apache/cassandra/db/ReadCommand.java
##########
@@ -595,8 +595,8 @@ public WithoutPurgeableTombstones()
     public String toCQLString()
     {
         StringBuilder sb = new StringBuilder();
-        sb.append(""SELECT "").append(columnFilter());
-        sb.append("" FROM "").append(metadata().ksName).append('.').append(metadata.cfName);
+        sb.append(""SELECT "").append(columnFilter().toCQLString());
+        sb.append("" FROM "").append(metadata().ksName).append('.').append(metadata().cfName);

Review comment:
       We do not quote keyspace and table names if needed.
   
   I am not sure how much we want to fix things in this patch. 




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;08/Mar/21 13:19;githubbot;600","adelapena closed pull request #919:
URL: https://github.com/apache/cassandra/pull/919


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Mar/21 12:49;githubbot;600","adelapena closed pull request #918:
URL: https://github.com/apache/cassandra/pull/918


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Mar/21 12:49;githubbot;600","adelapena closed pull request #917:
URL: https://github.com/apache/cassandra/pull/917


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Mar/21 12:49;githubbot;600","adelapena closed pull request #129:
URL: https://github.com/apache/cassandra-dtest/pull/129


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Mar/21 12:50;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,5400,,,0,5400,,,,,,,,,,,,,CASSANDRA-16415,,CASSANDRA-16510,,,,,,,,,,,,,,,,,,,,,,,0.0,adelapena,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Low Hanging Fruit,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Mar 10 17:43:40 UTC 2021,,,,,,,All,,,,"0|z0oadk:",9223372036854775807,,,,blerer,,,,Normal,,3.0.0,,https://github.com/apache/cassandra/commit/9c7b69e4229b6817b248bcf5270a783eed1f9930  https://github.com/apache/cassandra-dtest/commit/7d10bdd19765bc337ee7bbe516c3a1e76391f5c0,,,,,,,,,The proposed PRs include the new {{toCQLString}} method in {{ColumnFilterTest}}. Also the dtests for the slow query logger are extended to include column selections.,,,,,"05/Mar/21 00:07;yifanc;Sorry to see that we missed the implicit call of {{ColumnFilter::toString}} during review. 
If the coming patch is still going to use the result of {{ColumnFilter::toString}} to produce the cqlString, may I suggest to call the {{toString()}} method explicitly? In that case, the IDE is able to find the usage at least. ;;;","05/Mar/21 01:02;adelapena;[~yifanc] I'm working on a small patch adding a new {{ColumnFilter#toCQLString}} method to be called from {{AbstractReadQuery#toCQLString}}, so we can keep the current more informative {{ColumnFilter#toString}} for internal logging. Unfortunately converting a {{ColumnFilter}} back to the exact CQL that generated it isn't always possible, so I'm afraid it will be best effort, as it happens with other analogous {{toCQLString}} methods. I'm also extending the {{TestCQLSlowQuery}} dtests a little bit to include column selections.;;;","05/Mar/21 18:22;adelapena;As promised, the proposed patch adds a new {{ColumnFilter#toCQLString}} method, so we can keep the changes in {{ColumnFilter#toString}} that were introduced by CASSANDRA-16415. The behaviour of the new method is tested in {{ColumnFilterTest}}, and the {{TestCQLSlowQuery}} dtests are extended to include column selections.

As for producing valid CQL in {{AbstractReadQuery.toCQLString}}, I have replaced [the illegal strings|https://github.com/apache/cassandra/blob/b063f30f51e61d6298e79b43f7eb99b581bbec14/src/java/org/apache/cassandra/db/filter/ColumnFilter.java#L489-L494] that were produced before CASSANDRA-16415 by just {{*}}. This is not ideal but I guess it's acceptable since we can't know what primary key columns were selected by the original query, nor distinguish between queries asking for all columns and queries asking only for primary key columns. I've also included quoting for column names needing escaping.

It's worth mentioning that {{AbstractReadQuery.toCQLString}} can still produce illegal query strings for other parts of the query. For example, the {{WHERE}} keyword seems to be always included even if there isn't an expression following it. Also, the filtering expressions don't properly quote column names nor values. I think we should address those problems across several {{toCQLString}} implementations in a separate ticket, probably without blocking 4.0.;;;","05/Mar/21 18:26;adelapena;CI is running:

[CircleCI 3.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/212/workflows/dbccfe86-3c29-4905-ac98-ed7c1772d42f]
[CircleCI 3.11|https://app.circleci.com/pipelines/github/adelapena/cassandra/211/workflows/10856392-b01f-4c93-9df6-ccf4b2406c73]
[CircleCI trunk j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/210/workflows/48230e6d-9fe0-4321-92b0-3709c86c5e16]
[CircleCI trunk j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/210/workflows/d21c7f93-58a7-4522-a505-0844304de67f]
[ci-cassandra 3.0|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/462/pipeline]
[ci-cassandra 3.11|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/463/pipeline]
[ci-cassandra trunk|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/464/pipeline];;;","08/Mar/21 13:33;blerer;The patches look good to me. Thanks for all the new tests.
My only comment is about {{ReadCommand.toCQLString()}} where it seems that we do not quote the keyspace and table name if needed. I am just not sure if we should fix it in this patch or later on. May be we should address it with all the other problems you mentioned.;;;","08/Mar/21 14:09;adelapena;{quote}My only comment is about ReadCommand.toCQLString() where it seems that we do not quote the keyspace and table name if needed. I am just not sure if we should fix it in this patch or later on. May be we should address it with all the other problems you mentioned.
{quote}
Good catch, I missed that one. I think that for this ticket we can focus on {{ColumnFilter}} and the test failures introduced by CASSANDRA-16415. Then we could have other ticket for all the other {{toCQLString}} methods, adding a new exhaustive junit test suite instead of relying on {{TestCQLSlowQuery}} dtests. That test would make sure that the output of {{toCQLString}} is always parseable and, when parsed, it produces an equivalent command. Not sure whether we should block 4.0 for that ticket.

As for the CI results above, it seems that upgrade tests are not working on CircleCI for reasons not related to the patch. On ci-cassandra some of the above runs for upgrade tests have failed because they are upgrading from the development branches without the patch, so here are new runs with [an upgrade manifest|https://github.com/adelapena/cassandra-dtest/commits/16483-manifest] using the patched branches:
 [ci-cassandra 3.0|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest-upgrade/107/]
 [ci-cassandra 3.11|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest-upgrade/108/]
 [ci-cassandra trunk|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest-upgrade/109/];;;","08/Mar/21 14:14;blerer;{quote}Not sure whether we should block 4.0 for that ticket.{quote}
I do not think it makes sense to block 4.0 for that as the problem is already present in previous versions.;;;","09/Mar/21 17:21;adelapena;Makes sense to me. Here is an additional run of the patch for trunk rebased to include the last fixes in the CircleCI config file:
 * [CircleCI trunk j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/220/workflows/32bc2b90-68ed-45f0-a2cd-472e6c03a9c7]
 * [CircleCI trunk j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/220/workflows/12e1eb8b-4653-440e-814f-c0eb8d9163ca]

[~blerer] I think if the CI results look good and you agree with leaving the additional changes in {{toCQLString}} methods for that followup ticket we are ready to commit, wdyt?;;;","09/Mar/21 18:10;blerer;That sounds good to me.;;;","10/Mar/21 13:51;adelapena;Great, I have created CASSANDRA-16510 to deal with the problems in {{ReadCommand::toCQLString}}, so this ticket is focused on {{ColumnFilter::toCQLString}} and broken tests.;;;","10/Mar/21 17:43;adelapena;Committed to {{cassandra-3.0}} as [{{9c7b69e4229b6817b248bcf5270a783eed1f9930}}|https://github.com/apache/cassandra/commit/9c7b69e4229b6817b248bcf5270a783eed1f9930] and merged up to [{{cassandra-3.11}}|https://github.com/apache/cassandra/commit/dc82d481d94e38b41dc3de1a07eb18c77d34ad1e] and [{{trunk}}|https://github.com/apache/cassandra/commit/0e990d7231f6152e95d5c21a6660594fc9a507bb]. Dtest changes committed as [{{7d10bdd19765bc337ee7bbe516c3a1e76391f5c0}}|https://github.com/apache/cassandra-dtest/commit/7d10bdd19765bc337ee7bbe516c3a1e76391f5c0].

Thanks for the review.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CQL schema generated by DESCRIBE KEYSPACE fails to import with custom indexes,CASSANDRA-16482,13362166,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,mike_tr_adamson,mike_tr_adamson,03/Mar/21 18:17,16/Mar/22 15:32,13/Jul/23 08:40,04/Mar/21 16:59,4.0,4.0-rc1,,,,,,CQL/Syntax,,,,0,,,"The CQL schema generated by a DESCRIBE KEYSPACE on a keyspace with a table that contains a custom index cannot be reimported.

The reimport of the schema fails with:
{noformat}
InvalidRequest: Error from server: code=2200 [Invalid query] message=""Cannot specify class_name as a CUSTOM option""
{noformat}
The reason for this is that the custom index definition is created with {{class_name}} and {{target}} options added to it in it's {{WITH OPTIONS}} section. This is then picked up by the {{IndexAttributes.validate}} method that specifically rejects them.

Note: This only seems to happen if the custom index was created with options in the first place. So if the {{CREATE CUSTOM INDEX}} statement didn't originally have a {{WITH OPTIONS}} section then it won't have the {{class_name}} and {{target}} options added to it.

h3. Steps to reproduce
{noformat}
CREATE KEYSPACE test WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
CREATE TABLE test.test (id int PRIMARY KEY, value text);
CREATE CUSTOM INDEX ON test.test(value) USING 'org.apache.cassandra.index.sasi.SASIIndex' WITH OPTIONS = {'is_literal': 'false'};
DESCRIBE KEYSPACE test;
{noformat}
Trying to import the resultant schema will fail.",,blerer,brandon.williams,eribeiro,mike_tr_adamson,,,,,,,,,,,,"blerer opened a new pull request #915:
URL: https://github.com/apache/cassandra/pull/915


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Mar/21 12:56;githubbot;600","smiklosovic closed pull request #915:
URL: https://github.com/apache/cassandra/pull/915


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:32;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Apr 06 15:42:45 UTC 2021,,,,,,,All,,,,"0|z0o9m8:",9223372036854775807,,,,brandon.williams,,,,Normal,,4.0-beta1,,https://github.com/apache/cassandra/commit/87db9187c1cc56f0dcdcd4b1ae50a31f4191f580,,,,,,,,,The patch add additional unit tests to {{DescribeStatementTest}} and {{SchemaCQLHelperTest}},,,,,"04/Mar/21 13:01;blerer;The problem was due to the fact that the {{appendCqlTo}} method in {{IndexMetadata}} was not using the correct variable. I added some tests to check the fix for DESCRIBE statement and when we output the schema for the backups.

[PR|https://github.com/apache/cassandra/pull/915] and CI results: [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/109/workflows/3ce76197-3a65-40e6-b8d3-4f2c758b3696], [j11|https://app.circleci.com/pipelines/github/blerer/cassandra/109/workflows/e0a80b74-3c72-4d12-b4a2-e6e40f1eecd7]

;;;","04/Mar/21 14:09;brandon.williams;Good catch.  I'm +1 if CI doesn't horribly blow up, will try to check back later when it's all set.;;;","04/Mar/21 16:18;blerer;Some DTests are failing but it is unrelated to the change as they do not test that part of the code.;;;","04/Mar/21 16:20;brandon.williams;LGTM, +1.;;;","04/Mar/21 16:59;blerer;Committed into trunk at 87db9187c1cc56f0dcdcd4b1ae50a31f4191f580;;;","04/Mar/21 17:00;blerer;Thanks for the promt review [~brandon.williams];;;","04/Apr/21 14:49;eribeiro;[~blerer] Thanks for catch and fix this! Please, do you have any idea when 4.0-rc1 will be available at https://repo.maven.apache.org/maven2 ? ;;;","06/Apr/21 12:38;blerer;[~eribeiro] People are doing their best to release RC as soon as possible. I do not know how long it will take after that before it is available in the maven repo.;;;","06/Apr/21 15:42;eribeiro;No problem. Thanks again for the awesome work. The C* community really stands out. :) ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add version to website documentation,CASSANDRA-16481,13362162,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,dstathis,dstathis,03/Mar/21 17:53,04/Aug/21 19:15,13/Jul/23 08:40,04/Aug/21 19:15,,,,,,,,Documentation/Website,,,,0,,,"The docs for the start_native_transport config variable say that the default is true. In testing this, however, I found that when not set native transport was not started. Whereas when I set the variable to ""true"", native transport was started.",,dstathis,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16761,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,Documentation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Aug 04 19:15:08 UTC 2021,,,,,,,All,,,,"0|z0o9lc:",9223372036854775807,,,,,,,,Low,,,,,,,,,,,,,,,,,,"03/Mar/21 18:01;brandon.williams;Which document are you reading?  The native transport defaults to true in 4.0 but false before then.
/cc [~lorina@datastax.com];;;","03/Mar/21 18:05;dstathis;Thanks for the clarification. I was using version 3.

I was reading the docs on the cassandra website.

https://cassandra.apache.org/doc/latest/configuration/cass_yaml_file.html#native-transport-port

I would have thought those would apply to the stable version. Or at least an indicator of what version they are for.;;;","04/Aug/21 19:15;mck;Fixed in new version of website: CASSANDRA-16761;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-builds produce deb packages that require python 3.7,CASSANDRA-16480,13362125,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,adejanovski,adejanovski,03/Mar/21 14:56,28/Mar/21 20:53,13/Jul/23 08:40,05/Mar/21 14:30,4.0,4.0-rc1,,,,,,Packaging,,,,0,,,"Since the builds moved from depending on python 2 to  python 3, the packages that are produced by the [cassandra-builds project|https://github.com/apache/cassandra-builds] expect Python 3.7 to be installed on the target systems:
{noformat}
$ sudo dpkg -i cassandra_4.0~beta5-20210303gitd29dd643df_all.deb
(Reading database ... 117878 files and directories currently installed.)
Preparing to unpack cassandra_4.0~beta5-20210303gitd29dd643df_all.deb ...
Unpacking cassandra (4.0~beta5-20210303gitd29dd643df) over (4.0~beta5-20210303git25f3cf84f7) ...
dpkg: dependency problems prevent configuration of cassandra:
 cassandra depends on python3 (>= 3.7~); however:
  Version of python3 on system is 3.6.7-1~18.04.dpkg: error processing package cassandra (--install):
 dependency problems - leaving unconfigured
Processing triggers for systemd (237-3ubuntu10.38) ...
Processing triggers for ureadahead (0.100.0-21) ...
Errors were encountered while processing:
 cassandra{noformat}
The [test docker images|https://github.com/apache/cassandra-builds/blob/trunk/docker/testing/ubuntu1910_j11.docker#L35-L36] ship with both py36 and py38, which allows the install to pass nicely, but on a vanilla Ubuntu Bionic system, only Python 3.6 is installed.

We need to use debian buster images for builds that ship with python 3.6 so that the dependencies align with it. ",,adejanovski,brandon.williams,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Packaging,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Mar 05 14:30:28 UTC 2021,,,,,,,All,,,,"0|z0o9d4:",9223372036854775807,,,,adejanovski,,,,Normal,,NA,,{color:red}https://github.com/apache/cassandra/commit/2022cfe073af0a0ba311c80937e6f5c063412200{color},,,,,,,,,CI,,,,,"03/Mar/21 17:51;brandon.williams;So Debian [switched buster to python3.7|https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=913069] while Ubuntu bionic instead added python3.7 and python3.8 available as packages under those names.

Here are the possible solutions I see:

* Switch package building to build on bionic
* Remove ${python3:Depends} which while technically correct, introduces the 3.7 dependency when built against it.
* Make the minimum python version 3.7, and adjust the depends to allow the ""python3.7"" package name to satisfy the dependency and install 3.7 on Ubuntu.

Personally I think my vote is for the last option.  Python itself only supports 3.6 until the end of this year, and just barely at that: https://www.python.org/downloads/release/python-3610/ and 3.7 or greater should be available everywhere. We'll need to minorly revist CASSANDRA-16414, but this should be a longer term solution.

WDYT, [~mck], [~stefan.miklosovic]?

/cc [~aholmber];;;","03/Mar/21 18:29;adejanovski;Dropping support for 3.6 although it's still supported and is the default in Bionic (which will be supported until 2023) doesn't seem like the right move. It'll block folks from upgrading to 4.0 unless they upgrade their systems to Focal or install python 3.7 which is not that trivial for everyone, especially if they have a large fleet and other software that rely on 3.6.

I'd vote for option 1 or 2.;;;","03/Mar/21 18:34;brandon.williams;bq. upgrade their systems to Focal or install python 3.7 which is not that trivial

You'd simply install the package and the package management system would handle the rest.

bq. especially if they have a large fleet and other software that rely on 3.6

They're going to have much bigger fish to fry than cqlsh, given that 3.6.8 is the last bugfix release, and per my link:

bq. Security fix releases are source-only releases; binary installers are not provided.;;;","04/Mar/21 17:55;brandon.williams;Well, even if Bionic can install python37, we can't make it execute cqlsh with it without getting more invasive that would either be inappropriate (changing the system's python3) or undesirable (separate Ubuntu package with a patch to modify the shebang.)  I checked how they packaged apps that require > 3.6, and there aren't any, yet.  Bionic's going to have a weird time at some point in the future here.

So I guess we'll take the middle approach and remove the python3 depends clause, since that is producing version-specific artifacts against the version building them.  I checked the diff between using it and not:

{noformat}
 -rw-r--r-- root/root    210641 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-amd64-freebsd-6.cpython-36m-x86_64-linux-gnu.so
131d129
< -rw-r--r-- root/root    246605 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-amd64-linux.cpython-36m-x86_64-linux-gnu.so
133d130
< -rw-r--r-- root/root    251360 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-amd64-solaris.cpython-36m-x86_64-linux-gnu.so
136d132
< -rw-r--r-- root/root    494929 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-ia64-linux.cpython-36m-x86_64-linux-gnu.so
139d134
< -rw-r--r-- root/root    400925 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-ppc-aix-5.cpython-36m-x86_64-linux-gnu.so
141d135
< -rw-r--r-- root/root    258547 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-ppc-linux.cpython-36m-x86_64-linux-gnu.so
143d136
< -rw-r--r-- root/root    425077 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-ppc64-aix-5.cpython-36m-x86_64-linux-gnu.so
145d137
< -rw-r--r-- root/root    330767 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-ppc64-linux.cpython-36m-x86_64-linux-gnu.so
147d138
< -rw-r--r-- root/root    310792 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-ppc64le-linux.cpython-36m-x86_64-linux-gnu.so
149d139
< -rw-r--r-- root/root    269932 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-s390x-linux.cpython-36m-x86_64-linux-gnu.so
151d140
< -rw-r--r-- root/root    285004 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-sparc-solaris.cpython-36m-x86_64-linux-gnu.so
153d141
< -rw-r--r-- root/root    261896 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-sparc64-solaris.cpython-36m-x86_64-linux-gnu.so
157d144
< -rw-r--r-- root/root    179751 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-x86-freebsd-5.cpython-36m-x86_64-linux-gnu.so
159d145
< -rw-r--r-- root/root    179379 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-x86-freebsd-6.cpython-36m-x86_64-linux-gnu.so
161d146
< -rw-r--r-- root/root    233385 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-x86-linux.cpython-36m-x86_64-linux-gnu.so
163d147
< -rw-r--r-- root/root    242880 2020-12-18 17:32 ./usr/share/cassandra/lib/sigar-bin/libsigar-x86-solaris.cpython-36m-x86_64-linux-gnu.so
{noformat}

These are just extra libs, as we already have the sigar libs without any cython-specifics (for instance /usr/share/cassandra/lib/sigar-bin/libsigar-amd64-freebsd-6.cpython-36m-x86_64-linux-gnu.so is added with the depds, where /usr/share/cassandra/lib/sigar-bin/libsigar-amd64-freebsd-6.so already exists without.) And of course we don't even use sigar from python.

|Patch|CI|
|[3.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16480-3.0]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/455/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/455/pipeline]|
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16480-3.11]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/456/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/456/pipeline]|
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16480]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/457/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/457/pipeline]|;;;","05/Mar/21 12:53;adejanovski;Thanks [~brandon.williams]!

I've tested your branch by pushing [this commit|https://github.com/riptano/cassandra-rtest/commit/533b346584512133c782b39731d47c54fa1bb496] on previously failing 4.0 repair tests and [they passed successfully|https://app.circleci.com/pipelines/github/riptano/cassandra-rtest/118/workflows/0ccec847-e942-4486-ad38-750a825b2e7a].

LGTM (y);;;","05/Mar/21 14:30;brandon.williams;Committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Materialized Views: incorrect where clause reported for quoted identifiers,CASSANDRA-16479,13362104,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,adutra,adutra,03/Mar/21 13:45,11/Mar/21 17:21,13/Jul/23 08:40,11/Mar/21 16:54,4.0,4.0-rc1,,,,,,CQL/Syntax,Feature/Materialized Views,,,0,,,"I believe this is a regression from 3.11.

Given the following schema:

{noformat}
CREATE TABLE t1 (""theKey"" int, ""theClustering"" int, ""theValue"" int, PRIMARY KEY (""theKey"", ""theClustering""));

CREATE MATERIALIZED VIEW mv1 AS SELECT * FROM t1 WHERE ""theKey"" IS NOT NULL AND ""theClustering"" IS NOT NULL AND ""theValue"" IS NOT NULL  PRIMARY KEY (""theKey"", ""theClustering"");
{noformat}

And given the following query:

{noformat}
SELECT where_clause FROM system_schema.views ;
{noformat}

With 3.11, I get:

{noformat}
""theKey"" IS NOT NULL AND ""theClustering"" IS NOT NULL AND ""theValue"" IS NOT NULL
{noformat}

But with current trunk, I get:

{noformat}
theKey IS NOT NULL AND theClustering IS NOT NULL AND theValue IS NOT NULL
{noformat}

Note how column names appear in their internal format, not in quoted form.

Note: the DataStax drivers rely on this info to rebuild the view's DDL query client-side; generated CQL is currently broken with Cassandra 4.0-trunk.",,adelapena,adutra,blerer,,,,,,,,,,,,,"blerer opened a new pull request #916:
URL: https://github.com/apache/cassandra/pull/916


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;05/Mar/21 17:01;githubbot;600","blerer closed pull request #916:
URL: https://github.com/apache/cassandra/pull/916


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Mar/21 16:57;githubbot;600","blerer commented on pull request #916:
URL: https://github.com/apache/cassandra/pull/916#issuecomment-796886117


   Merged manually


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;11/Mar/21 16:57;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,,,,,CASSANDRA-16510,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Mar 11 16:55:01 UTC 2021,,,,,,,All,,,,"0|z0o98g:",9223372036854775807,,,,adelapena,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/92fe6a37fc79b9c545bccd75b93e5126fd1678e9,,,,,,,,,Add a new unit test to check that the problem is fixed for the different supported scenarios,,,,,"05/Mar/21 17:25;blerer;CASSANDRA-13426 changed the way the Materialized Views WHERE clause stored in {{system_schema.views}} was generated. The code used to generate the WHERE clause text was not relying on method quoting identifiers when needed.

[PR|https://github.com/apache/cassandra/pull/916] CI: [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/110/workflows/3fa3e242-3164-4757-b18f-14e4682f383f], [j11|https://app.circleci.com/pipelines/github/blerer/cassandra/110/workflows/9cd65e6d-24f5-455a-9431-815c37c4fab5]


;;;","09/Mar/21 13:53;adelapena;Overall the patch looks good to me, with a few comments:
 * Perhaps we could add a {{toCQLString}} method to both {{Relation}} and {{CustomIndexExpression}}. These {{toCQLString}} methods can be called by {{toString}}. Otherwise future changes can miss that the {{toString}} implementation is intended to return valid CQL, as it recently happened in CASSANDRA-16415. Also, calls to {{toCQLString}} should be explicit, whereas implicit calls to {{toString}} from other {{toCQLString}} methods are a bit easier to miss.
 * I think there are no tests for the changes in {{CustomIndexExpression}}/{{QualifiedName}}. Creating tests for custom indexes is tricky, so perhaps that's something we could do in the followup ticket for {{toCQLString}} methods mentioned in CASSANDRA-16483.
 * I'd say the CI results look good. I think [the failure in {{ViewTest}}|https://app.circleci.com/pipelines/github/blerer/cassandra/110/workflows/9cd65e6d-24f5-455a-9431-815c37c4fab5/jobs/967] is not related to the changes, and the upgrade tests have failed because the PR misses the last changes in CircleCI config. We could give it another run after rebasing.;;;","11/Mar/21 14:55;blerer;[~adelapena] I pushed the changes that you suggested [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/111/workflows/ccd213e5-d841-4318-a453-3103ed1827f6], [j11|https://app.circleci.com/pipelines/github/blerer/cassandra/111/workflows/3194f093-399a-4276-a443-25263316fcd9].

Regarding the {{CustomIndexExpression/QualifiedName}} I think it makes sense to test them in a followup ticket.;;;","11/Mar/21 15:34;adelapena;Changes look good to me, +1;;;","11/Mar/21 16:54;blerer;Committed into trunk at 92fe6a37fc79b9c545bccd75b93e5126fd1678e9;;;","11/Mar/21 16:55;blerer;Thanks for the review [~adelapena];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Debian packages are broken since py3 migration,CASSANDRA-16478,13362072,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adejanovski,adejanovski,adejanovski,03/Mar/21 10:29,05/Mar/21 14:58,13/Jul/23 08:40,03/Mar/21 13:40,4.0,4.0-rc1,,,,,,Packaging,,,,0,,,"[Repair tests|https://app.circleci.com/pipelines/github/riptano/cassandra-rtest?branch=alex%2Fupgrade-tlp-cluster-python3] started to fail after the builds moved to Python3 in CASSANDRA-16396 due to deb packages failing to install on Ubuntu Bionic:
{noformat}
$ sudo dpkg -i cassandra_4.0~beta5-20210303git64f54f9fb0_all.deb
Selecting previously unselected package cassandra.
(Reading database ... 117650 files and directories currently installed.)
Preparing to unpack cassandra_4.0~beta5-20210303git64f54f9fb0_all.deb ...
Unpacking cassandra (4.0~beta5-20210303git64f54f9fb0) ...
dpkg: dependency problems prevent configuration of cassandra:
 cassandra depends on python (>= 3.6); however:
  Package python is not installed.
 cassandra depends on python3 (>= 3.7~); however:
  Version of python3 on system is 3.6.7-1~18.04.{noformat}
It seems like the following requirements are not correct:
{noformat}
Depends: openjdk-8-jre-headless | java8-runtime, adduser, python (>= 3.6), ${misc:Depends}, ${python3:Depends}{noformat}
I've changed this line to the following and got the deb packages to install correctly:
{noformat}
Depends: openjdk-8-jre-headless | java8-runtime, adduser, python3 (>= 3.6), ${misc:Depends}{noformat}",,adejanovski,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,adejanovski,,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Mar 03 13:40:49 UTC 2021,,,,,,,All,,,,"0|z0o91c:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Mar/21 13:40;brandon.williams;Fixed in c775ea3fa77bb661f405d8ebba738546518ac18e;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multiple python dtest failures after promoting protocol v5 from beta,CASSANDRA-16474,13361910,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,samt,samt,samt,02/Mar/21 16:34,05/Mar/21 16:56,13/Jul/23 08:40,04/Mar/21 14:53,4.0,4.0-rc1,,,,,,Messaging/Client,,,,0,protocolv5,,"After making v5 the default for connections where a preferred protocol version is not specified, a number of python dtests are failing in CI environments.

The issue appears to be with how the driver handles cases where the bytes read from the client socket doesn't constitute a complete frame (or to be more specific, the read buffer is exhausted whilst in the middle of reading a frame).",,aholmber,brandon.williams,e.dimitrova,jjordan,maedhroz,mck,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,samt,,,,,,,,,,,,,Availability -> Response Crash,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Mar 05 16:25:47 UTC 2021,,,,,,,All,,,,"0|z0o81c:",9223372036854775807,,,,aholmber,,,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/bad17a891a6df23f1e7698dc1285d031d0900118,,,,,,,,,"Full CI runs completed, follow up with smaller test runs targetting cql/cqlsh.",,,,,"02/Mar/21 16:43;samt;Candidate driver patch has been produced, running CI now.
* [Circle JDK8|https://app.circleci.com/pipelines/github/beobal/cassandra/238/workflows/1e121554-3514-4840-a919-d785ee0484f5]
* [Circle JDK11|https://app.circleci.com/pipelines/github/beobal/cassandra/238/workflows/cfc78f97-0700-4e77-853c-411d90dbb11d]
* [ci-c.apache.org|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/445/];;;","03/Mar/21 12:20;samt;Both Circle and Apache CI look much better:
 * On the JDK 8 pipeline, all python tests are now green with the exception of one {{indev_3.x_to_indev_trunk}} upgrade test. Will check on this after merging and open a new JIRA if necessary.
 * On the JDK 8 pipeline, one in-jvm upgrade failure. Should be fixed by CASSANDRA-16415, which landed in the meantime.
 * On the JDK11 pipeline, one failing python dtest. Looks unrelated, I'll follow up with a new JIRA.

The [python driver PR|https://github.com/datastax/python-driver/pull/1100] has been merged and the {{cassandra-test}} branch updated, so python dtests in CI should start to pass again now. 
 However, we also need to rebuild the {{cassandra-testing}} docker images as the previously installed driver includes cython extension modules which don't get rebuilt when tests are run. These
 are causing some test failures as they don't include the latest driver fixes. I've opened a PR to exclude the cython extensions from the base image 
 I've rebundled the {{cassandra-driver-internal-only}} lib in C* and once the images are rebuilt & published, the last thing to do is to run a minimal set of python dtest/cqlsh tests.

*Patches*
 * [Cassandra Builds|https://github.com/apache/cassandra-builds/pull/37/files]
 * [Cassandra|https://github.com/beobal/cassandra/commit/4977bc44639dd8d3d7c1fc4b80b095076f2c5dbc] (trivial);;;","03/Mar/21 17:23;aholmber;Tiny take-it-or-leave-it comment on the docker file change.
+1 overall;;;","04/Mar/21 13:02;samt;New docker images have been published, so I've updated the circle config files. 

*Patches*
* [2.2|https://github.com/beobal/cassandra/tree/16474-2.2]
* [3.0|https://github.com/beobal/cassandra/tree/16474-3.0]
* [3.11|https://github.com/beobal/cassandra/tree/16474-3.11]
* [trunk|https://github.com/beobal/cassandra/tree/16474-trunk] (also includes driver update)


I've also opened CASSANDRA-16483 for the python upgrade test failure, along with a couple of python cql tests with the same proximate cause.;;;","04/Mar/21 14:53;samt;Thanks all, committed (the docker change only) to 2.2 in {{bad17a891a6df23f1e7698dc1285d031d0900118}} and merged upwards, adding the bundled driver update in trunk.;;;","05/Mar/21 15:35;e.dimitrova;Hey Sam, 

Thank you for taking care of CircleCI config, I was wondering whether this removal was intentional or broken merge:

[https://github.com/apache/cassandra/commit/2bcba44533ae1b9a67f1fda882c53e8a887656c5#diff-7f0a716b02445f43e77444f81a3a87f7101eda3668a0dd82f61822141d20e2bfL2186]

 

Also, FYI I will open a ticket to update also the midres in trunk. If you want me also to return those stuff, let me know and I can do everything at once later today :) ;;;","05/Mar/21 16:13;samt;Hey Ekaterina, sorry about that.

I updated the template and regenerated the specific yaml files as per the readme (I'm not sure if that's outdated now though). I looks like the {{utests_system_keyspace_directory}} job was added directly to the {{config.yml.XYZ}} files, so it got lost by my doing that. I completely overlooked the {{MIDRES}} file sorry. I'll take care of filing a jira and restoring things to how they were previously.;;;","05/Mar/21 16:25;e.dimitrova;No worries, thanks [~samt] for looking into it. Let me know if you want me to take care, I will be happy to help :) 

Yes, I think one issue is MIDRES is only on trunk and on the other hand people sometimes update directly the yaml because they miss the readme. It's a bit confusing;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-stress failed to connect over JMX,CASSANDRA-16473,13361736,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,molin,molin,02/Mar/21 03:35,05/Mar/21 14:58,13/Jul/23 08:40,03/Mar/21 15:36,4.0,4.0-rc1,,,,,,Tool/stress,,,,0,,,"cassandra version: 4.0-beta4

When I run command:
cassandra-stress write n = 100 -rate threads = 1 -node 127.0.0.1 -log level=verbose

I get the following exception:


{code:java}
Connected to cluster: Test Cluster, max pending requests per connection 128, max connections per host 8
Datacenter: datacenter1; Host: /127.0.0.1:9042; Rack: rack1
Created keyspaces. Sleeping 1s for propagation.
Sleeping 2s...
Warming up WRITE with 25 iterations...
java.lang.RuntimeException: java.io.IOException: Failed to retrieve RMIServer stub: javax.naming.ConfigurationException [Root exception is java.rmi.UnknownHostException: Unknown host: 127.0.0.1:9042; nested exception is:
	java.net.UnknownHostException: 127.0.0.1:9042]
	at org.apache.cassandra.stress.util.JmxCollector.connect(JmxCollector.java:99)
	at org.apache.cassandra.stress.util.JmxCollector.<init>(JmxCollector.java:85)
	at org.apache.cassandra.stress.report.StressMetrics.<init>(StressMetrics.java:108)
	at org.apache.cassandra.stress.StressAction.run(StressAction.java:228)
	at org.apache.cassandra.stress.StressAction.warmup(StressAction.java:124)
	at org.apache.cassandra.stress.StressAction.run(StressAction.java:69)
	at org.apache.cassandra.stress.Stress.run(Stress.java:155)
	at org.apache.cassandra.stress.Stress.main(Stress.java:63)
Caused by: java.io.IOException: Failed to retrieve RMIServer stub: javax.naming.ConfigurationException [Root exception is java.rmi.UnknownHostException: Unknown host: 127.0.0.1:9042; nested exception is:
	java.net.UnknownHostException: 127.0.0.1:9042]
	at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:369)
	at javax.management.remote.JMXConnectorFactory.connect(JMXConnectorFactory.java:270)
	at org.apache.cassandra.tools.NodeProbe.connect(NodeProbe.java:214)
	at org.apache.cassandra.tools.NodeProbe.<init>(NodeProbe.java:172)
	at org.apache.cassandra.stress.util.JmxCollector.connect(JmxCollector.java:95)
	... 7 more
Caused by: javax.naming.ConfigurationException [Root exception is java.rmi.UnknownHostException: Unknown host: 127.0.0.1:9042; nested exception is:
	java.net.UnknownHostException: 127.0.0.1:9042]
	at com.sun.jndi.rmi.registry.RegistryContext.lookup(RegistryContext.java:136)
	at com.sun.jndi.toolkit.url.GenericURLContext.lookup(GenericURLContext.java:205)
	at javax.naming.InitialContext.lookup(InitialContext.java:417)
	at javax.management.remote.rmi.RMIConnector.findRMIServerJNDI(RMIConnector.java:1955)
	at javax.management.remote.rmi.RMIConnector.findRMIServer(RMIConnector.java:1922)
	at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:287)
	... 11 more
Caused by: java.rmi.UnknownHostException: Unknown host: 127.0.0.1:9042; nested exception is:
	java.net.UnknownHostException: 127.0.0.1:9042
	at sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:620)
	at sun.rmi.transport.tcp.TCPChannel.createConnection(TCPChannel.java:216)
	at sun.rmi.transport.tcp.TCPChannel.newConnection(TCPChannel.java:202)
	at sun.rmi.server.UnicastRef.newCall(UnicastRef.java:342)
	at sun.rmi.registry.RegistryImpl_Stub.lookup(RegistryImpl_Stub.java:116)
	at com.sun.jndi.rmi.registry.RegistryContext.lookup(RegistryContext.java:132)
	... 16 more
Caused by: java.net.UnknownHostException: 127.0.0.1:9042
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:196)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:394)
	at java.net.Socket.connect(Socket.java:606)
	at java.net.Socket.connect(Socket.java:555)
	at java.net.Socket.<init>(Socket.java:451)
	at java.net.Socket.<init>(Socket.java:228)
	at sun.rmi.transport.proxy.RMIDirectSocketFactory.createSocket(RMIDirectSocketFactory.java:40)
	at sun.rmi.transport.proxy.RMIMasterSocketFactory.createSocket(RMIMasterSocketFactory.java:148)
	at sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:617)
	... 21 more
Failed to connect over JMX; not collecting these stats
Running WRITE with 1 threads for 100 iteration
java.lang.RuntimeException: java.io.IOException: Failed to retrieve RMIServer stub: javax.naming.ConfigurationException [Root exception is java.rmi.UnknownHostException: Unknown host: 127.0.0.1:9042; nested exception is:
	java.net.UnknownHostException: 127.0.0.1:9042]
	at org.apache.cassandra.stress.util.JmxCollector.connect(JmxCollector.java:99)
	at org.apache.cassandra.stress.util.JmxCollector.<init>(JmxCollector.java:85)
	at org.apache.cassandra.stress.report.StressMetrics.<init>(StressMetrics.java:108)
	at org.apache.cassandra.stress.StressAction.run(StressAction.java:228)
	at org.apache.cassandra.stress.StressAction.run(StressAction.java:88)
	at org.apache.cassandra.stress.Stress.run(Stress.java:155)
	at org.apache.cassandra.stress.Stress.main(Stress.java:63)
Caused by: java.io.IOException: Failed to retrieve RMIServer stub: javax.naming.ConfigurationException [Root exception is java.rmi.UnknownHostException: Unknown host: 127.0.0.1:9042; nested exception is:
	java.net.UnknownHostException: 127.0.0.1:9042]
	at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:369)
	at javax.management.remote.JMXConnectorFactory.connect(JMXConnectorFactory.java:270)
	at org.apache.cassandra.tools.NodeProbe.connect(NodeProbe.java:214)
	at org.apache.cassandra.tools.NodeProbe.<init>(NodeProbe.java:172)
	at org.apache.cassandra.stress.util.JmxCollector.connect(JmxCollector.java:95)
	... 6 more
Caused by: javax.naming.ConfigurationException [Root exception is java.rmi.UnknownHostException: Unknown host: 127.0.0.1:9042; nested exception is:
	java.net.UnknownHostException: 127.0.0.1:9042]
	at com.sun.jndi.rmi.registry.RegistryContext.lookup(RegistryContext.java:136)
	at com.sun.jndi.toolkit.url.GenericURLContext.lookup(GenericURLContext.java:205)
	at javax.naming.InitialContext.lookup(InitialContext.java:417)
	at javax.management.remote.rmi.RMIConnector.findRMIServerJNDI(RMIConnector.java:1955)
	at javax.management.remote.rmi.RMIConnector.findRMIServer(RMIConnector.java:1922)
	at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:287)
	... 10 more
Caused by: java.rmi.UnknownHostException: Unknown host: 127.0.0.1:9042; nested exception is:
	java.net.UnknownHostException: 127.0.0.1:9042
	at sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:620)
	at sun.rmi.transport.tcp.TCPChannel.createConnection(TCPChannel.java:216)
	at sun.rmi.transport.tcp.TCPChannel.newConnection(TCPChannel.java:202)
	at sun.rmi.server.UnicastRef.newCall(UnicastRef.java:342)
	at sun.rmi.registry.RegistryImpl_Stub.lookup(RegistryImpl_Stub.java:116)
	at com.sun.jndi.rmi.registry.RegistryContext.lookup(RegistryContext.java:132)
	... 15 more
Caused by: java.net.UnknownHostException: 127.0.0.1:9042
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:196)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:394)
	at java.net.Socket.connect(Socket.java:606)
	at java.net.Socket.connect(Socket.java:555)
	at java.net.Socket.<init>(Socket.java:451)
	at java.net.Socket.<init>(Socket.java:228)
	at sun.rmi.transport.proxy.RMIDirectSocketFactory.createSocket(RMIDirectSocketFactory.java:40)
	at sun.rmi.transport.proxy.RMIMasterSocketFactory.createSocket(RMIMasterSocketFactory.java:148)
	at sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:617)
	... 20 more
Failed to connect over JMX; not collecting these stats
type                                               total ops,    op/s,    pk/s,   row/s,    mean,     med,     .95,     .99,    .999,     max,   time,   stderr, errors,  gc: #,  max ms,  sum ms,  sdv ms,      mb
total,                                                    94,      94,      94,      94,     1.8,     1.7,     2.7,     4.3,     5.1,     5.1,    1.0,  0.00000,      0,      0,       0,       0,       0,       0
total,                                                   100,     381,     381,     381,     2.6,     1.6,     6.1,     6.1,     6.1,     6.1,    1.0,  0.52138,      0,      0,       0,       0,       0,       0


Results:
Op rate                   :       98 op/s  [WRITE: 98 op/s]
Partition rate            :       98 pk/s  [WRITE: 98 pk/s]
Row rate                  :       98 row/s [WRITE: 98 row/s]
Latency mean              :    1.9 ms [WRITE: 1.9 ms]
Latency median            :    1.7 ms [WRITE: 1.7 ms]
Latency 95th percentile   :    2.8 ms [WRITE: 2.8 ms]
Latency 99th percentile   :    5.1 ms [WRITE: 5.1 ms]
Latency 99.9th percentile :    6.1 ms [WRITE: 6.1 ms]
Latency max               :    6.1 ms [WRITE: 6.1 ms]
Total partitions          :        100 [WRITE: 100]
Total errors              :          0 [WRITE: 0]
Total GC count            : 0
Total GC memory           : 0.000 KiB
Total GC time             :    0.0 seconds
Avg GC time               :    NaN ms
StdDev GC time            :    0.0 ms
Total operation time      : 00:00:01

END
{code}
",,bereng,brandon.williams,molin,,,,,,,,,,,,,"bereng opened a new pull request #913:
URL: https://github.com/apache/cassandra/pull/913


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Mar/21 07:27;githubbot;600","bereng commented on pull request #913:
URL: https://github.com/apache/cassandra/pull/913#issuecomment-789524265


   - CI [j11](https://app.circleci.com/pipelines/github/bereng/cassandra/225/workflows/53caceb7-6c44-4c37-95df-beb10e19b081)
   - CI [j8](https://app.circleci.com/pipelines/github/bereng/cassandra/225/workflows/be27c049-9860-4885-9473-211693f7feb4)


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Mar/21 08:09;githubbot;600","bereng closed pull request #913:
URL: https://github.com/apache/cassandra/pull/913


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Mar/21 05:47;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Mar 03 15:36:41 UTC 2021,,,,,,,All,,,,"0|z0o6yw:",9223372036854775807,,,,brandon.williams,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/2d9d17894dab365df09f515e37b62b658bce6594,,,,,,,,,See PR,,,,,"03/Mar/21 08:11;bereng;Probably a side effect of the change in 4.0 where nodes now include the port as well. {{Stress}} is not being run on CI atm but you can test easily with:

{{ant stress-test-some -Dtest.name=org.apache.cassandra.stress.settings.StressSettingsTest}}

I have included a CI run in the PR anyway for completeness.;;;","03/Mar/21 15:36;brandon.williams;I suspected this would be the case, thanks! Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky TestDynamicEndpointSnitch.test_multidatacenter_local_quorum test,CASSANDRA-16472,13361689,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,01/Mar/21 20:38,25/Apr/21 11:32,13/Jul/23 08:40,16/Mar/21 19:19,4.0,4.0-rc1,,,,,,CI,,,,0,,,https://ci-cassandra.apache.org/job/Cassandra-devbranch/434/testReport/junit/dtest-large.snitch_test/TestDynamicEndpointSnitch/test_multidatacenter_local_quorum/history/ has gotten flaky in the somewhat recent past.,,bereng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 16 19:19:44 UTC 2021,,,,,,,All,,,,"0|z0o6og:",9223372036854775807,,,,bereng,brandon.williams,,,Normal,,NA,,https://github.com/apache/cassandra-dtest/commit/f5e32c7743154b87bc6398a25684c323ef129f2f,,,,,,,,,run dtest many times,,,,,"15/Mar/21 18:18;brandon.williams;One problem with this test is that it shortens the reset interval for testing, but then inserts/reads enough data that it can exceed the interval while doing so.  Even with less data though, on a slow enough machine it can still be reset, so the patch also allows the degraded reads to be off by exactly one so the snitch has a signal to stop reading from it and can get back on track.;;;","16/Mar/21 06:36;bereng;Allowing for 1 extra read in case it races with a reset makes sense to me. +1 pending CI.;;;","16/Mar/21 19:19;brandon.williams;CASSANDRA-13196 failed again here [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/488/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/488/pipeline]
 but I'll get to that next.  CI looks good otherwise. Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
replication_test.TestReplication.test_network_topology failure,CASSANDRA-16469,13360905,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,25/Feb/21 08:28,26/Feb/21 05:11,13/Jul/23 08:40,25/Feb/21 23:21,4.0,4.0-rc1,,,,,,Test/dtest/python,,,,0,,,replication_test.TestReplication.test_network_topology has been failing consistently and locally lately,,bereng,mck,,,,,,,,,,,,,,"bereng opened a new pull request #128:
URL: https://github.com/apache/cassandra-dtest/pull/128


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 09:59;githubbot;600","michaelsembwever commented on pull request #128:
URL: https://github.com/apache/cassandra-dtest/pull/128#issuecomment-786297065


   merged with https://github.com/apache/cassandra-dtest/commit/90585fe5add81d261f532fbf0c690eca9cc2f5ed 


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 23:19;githubbot;600","michaelsembwever closed pull request #128:
URL: https://github.com/apache/cassandra-dtest/pull/128


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 23:19;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,CASSANDRA-15163,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Feb 26 05:11:14 UTC 2021,,,,,,,All,,,,"0|z0o1u8:",9223372036854775807,,,,mck,,,,Normal,,4.0-alpha2,,https://github.com/apache/cassandra-dtest/commit/90585fe5add81d261f532fbf0c690eca9cc2f5ed,,,,,,,,,See PR,,,,,"25/Feb/21 10:18;bereng;Test passes locally both single and full class. Given dtests have many failures atm maybe we can merge by only running locally given it's a regexp thing? Otherwise a jenkins dtest run would be helpful but I can't trigger it.;;;","25/Feb/21 11:21;mck;[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/406/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/406/pipeline];;;","25/Feb/21 23:14;mck;Tested locally, and [passes|https://ci-cassandra.apache.org/job/Cassandra-devbranch/406/testReport/dtest-large-novnode.replication_test/TestReplication/test_network_topology/] in ci-cassandra.a.o;;;","25/Feb/21 23:21;mck;Committed as [90585fe5add81d261f532fbf0c690eca9cc2f5ed|https://github.com/apache/cassandra-dtest/commit/90585fe5add81d261f532fbf0c690eca9cc2f5ed].;;;","26/Feb/21 05:11;bereng;Thx for jumping in [~mck]!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"speculative retry should allow more friendly params, allowing upgrade from 2.x not to break",CASSANDRA-16467,13360432,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,sumanth.pasupuleti,sumanth.pasupuleti,sumanth.pasupuleti,23/Feb/21 20:07,15/Jul/21 20:18,13/Jul/23 08:40,15/Jul/21 20:18,3.0.25,3.11.11,,,,,,Local/Config,,,,0,,,"2.x speculative retry params are case insensitive, while 3.0 and 3.11 have added case sensitivity. As as result of this, one of our internal applications suffered an issue during 
C* upgrade from 2.x to 3.0.

This ticket is to propose making 3.0 and 3.11 speculative_retry params case insensitive as well (essentially a slightly modified backport of CASSANDRA-13876, but not to allow something like ""99p"" which 4.0 allows)",,adelapena,azotcsit,brandon.williams,e.dimitrova,maedhroz,sumanth.pasupuleti,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,sumanth.pasupuleti,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jul 15 20:18:21 UTC 2021,,,,,,,All,,,,"0|z0nzf4:",9223372036854775807,,,,e.dimitrova,maedhroz,,,Low,,3.0.0,,https://github.com/apache/cassandra/commit/e8f961f403a1a55a4837a576d744288599962d5a,,,,,,,,,existing test coverage,,,,,"23/Feb/21 20:18;sumanth.pasupuleti;*3.0.x*
[Patch|https://github.com/apache/cassandra/compare/cassandra-3.0...sumanth-pasupuleti:bugfix/30_speculative_retry_params_case]
[Passing UTs|https://app.circleci.com/pipelines/github/sumanth-pasupuleti/cassandra/53/workflows/3a0b4cdd-32c8-4b8a-83fa-34e6a78679d5]

*3.11.x*
[Patch|https://github.com/apache/cassandra/compare/cassandra-3.11...sumanth-pasupuleti:bugfix/311_speculative_retry_params_case]
[UTs|https://app.circleci.com/pipelines/github/sumanth-pasupuleti/cassandra/54/workflows/6241a82b-3dde-4599-9c72-7d11e39c7206] (one failing that seems unrelated);;;","11/Jul/21 19:59;azotcsit;Just curious - why did you decide to not include ""99p""?

The changes look good to me.

PS: 

I'm not a committer, just checking existing patches as per Benjamin's email seeking for reviewers.;;;","13/Jul/21 21:32;maedhroz;[~sumanth.pasupuleti] I'll make a pass at review, and then we would just need one more committer +1.;;;","13/Jul/21 22:19;maedhroz;+1 to both patches

The only minor nit I have is that in the 3.11 version, where we have Unit 4.12 available, I would use {{@Parameters(name=""\{0\}"")}} to make the test names a bit more descriptive. (i.e. If they fail, the input would be obvious.);;;","13/Jul/21 22:19;maedhroz;Now to find this a second reviewer and commit...;;;","14/Jul/21 15:18;e.dimitrova;The change moving from _toUpperCase_ to _toLowerCase_ was done as part of b31845c4a7982358a7c5bfd9bcf572fda6c1bfa9 (CASSANDRA-9712). I didn't find any reason for it, I suspect it was a mistake. 

About [~azotcsit]'s question around the ""99p"". I think the reason is that we fix here a bug/regression and that part was new in 4.0 ([~maedhroz] and [~sumanth.pasupuleti], please, correct me if I am wrong). 3.0 and 3.11 are only bug fixes. 

 [~sumanth.pasupuleti], do you mind to rebase and submit new CI run? 

+1 on green CI, thank you!;;;","14/Jul/21 20:30;maedhroz;bq. do you mind to rebase and submit new CI run?

[~sumanth.pasupuleti] I'll commit as soon as this is done. Thanks again!;;;","14/Jul/21 20:35;sumanth.pasupuleti;Thanks for the review [~azotcsit], [~maedhroz] and [~e.dimitrova]. I have rebased; CI runs are in progress - will update the ticket once the runs complete.;;;","14/Jul/21 21:18;sumanth.pasupuleti;Updated PRs (after rebase)
3.0.x
[Patch|https://github.com/apache/cassandra/compare/cassandra-3.0...sumanth-pasupuleti:bugfix/30_speculative_retry_params_case]
UTs and Dtests passing except for three DTests that seem unrelated to me (test_sstableverify, test_simple_rebuild and test_closing_connections)
[Circle CI run|https://app.circleci.com/pipelines/github/sumanth-pasupuleti/cassandra/79/workflows/b6f2cd11-d08d-46ef-acf8-6fd0ccf0d61e]

3.11.x
[Patch|https://github.com/apache/cassandra/compare/cassandra-3.11...sumanth-pasupuleti:bugfix/311_speculative_retry_params_case]
UTs and Dtests passing except for three DTests that seem unrelated to me (test_sstableverify, test_view_metadata_cleanup and test_closing_connections)
[Circle CI run|https://app.circleci.com/pipelines/github/sumanth-pasupuleti/cassandra/81/workflows/6c45519e-1120-4fa5-8a72-3e465a5467cb];;;","15/Jul/21 20:18;maedhroz;Committed to...
...3.0 as https://github.com/apache/cassandra/commit/e8f961f403a1a55a4837a576d744288599962d5a
...3.11 as https://github.com/apache/cassandra/commit/de1d7d76a1c7682dfcec63a3e24e37e19d683bef

Thanks again for the patch and tests!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hint messages are incorrectly re-serialized for filtering in in-jvm dtests,CASSANDRA-16457,13359265,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,ifesdjeen,ifesdjeen,ifesdjeen,18/Feb/21 10:18,16/Mar/22 15:30,13/Jul/23 08:40,25/Feb/21 13:12,3.0.25,3.11.11,4.0,4.0-rc1,,,,Test/dtest/java,,,,0,,,"Hint messages for dropped tables can still be dispatched, but they’re ignored on the receiving side all usual code paths. Since we’re attempting to re-serialize hint message for dropped table in in-jvm tests, we exercise path that is impossible in regular code, and for which there is no protocol specification. 


Stack trace: 

{code}
INFO  [AsyncAppender-Worker-ASYNC] 2021-02-17 18:50:13,759 SubstituteLogger.java:169 - ERROR [MutationStage-2] 2021-02-17 18:50:13,726 AbstractLocalAwareExecutorService.java:166 - Uncaught exception on thread Thread[MutationStage-2,5,node4]
java.lang.NullPointerException: null
	at org.apache.cassandra.hints.Hint$Serializer.serializedSize(Hint.java:150)
	at org.apache.cassandra.hints.HintMessage$Serializer.serializedSize(HintMessage.java:86)
	at org.apache.cassandra.hints.HintMessage$Serializer.serializedSize(HintMessage.java:77)
	at org.apache.cassandra.net.Message$Serializer.payloadSize(Message.java:1289)
	at org.apache.cassandra.net.Message$Serializer.access$1200(Message.java:607)
	at org.apache.cassandra.net.Message.payloadSize(Message.java:1341)
	at org.apache.cassandra.net.Message.access$900(Message.java:66)
	at org.apache.cassandra.net.Message$Serializer.serializePost40(Message.java:759)
	at org.apache.cassandra.net.Message$Serializer.serialize(Message.java:618)
	at org.apache.cassandra.distributed.impl.Instance.serializeMessage(Instance.java:322)
	at org.apache.cassandra.distributed.impl.Instance.lambda$registerInboundFilter$4(Instance.java:273)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:62)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:49)
	at org.apache.cassandra.net.InboundSink.accept(InboundSink.java:93)
	at org.apache.cassandra.distributed.impl.Instance.lambda$null$6(Instance.java:365)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162)
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:134)
	at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:119)
	at relocated.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
{code}",,aleksey,ifesdjeen,jmeredithco,,,,,,,,,,,,,"smiklosovic closed pull request #908:
URL: https://github.com/apache/cassandra/pull/908


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:30;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,ifesdjeen,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Low Hanging Fruit,Fuzz Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Feb 25 13:11:26 UTC 2021,,,,,,,All,,,,"0|z0nsdk:",9223372036854775807,,,,aleksey,jmeredithco,,,Low,,3.11.8,,https://github.com/apache/cassandra/commit/20a315099753ae5220b31f07e74dd3745d02d21b,,,,,,,,,Test included,,,,,"18/Feb/21 15:52;ifesdjeen;|[trunk patch|https://github.com/apache/cassandra/pull/908]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=16457-trunk]|;;;","18/Feb/21 16:31;jmeredithco;+1 from me with a small nit and reminder about making sure the REQUEST_RSP serializer doesn't get added back by mistake.;;;","18/Feb/21 17:10;aleksey;Seems reasonable.

That said, I would move this special-case serializer logic to tests folder, out of production code, keeping it clean.
Also, style-wise, would prefer to invoke vanilla serializer return early if hint != null in serialize()/serializedSize() implementations - to cut down on nesting.;;;","19/Feb/21 15:58;ifesdjeen;[~jmeredithco] [~aleksey] Thank you for the review. Addressed your comments, and made patches for 3.0 and 3.11: 

|[trunk patch|https://github.com/apache/cassandra/pull/908]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=16457-trunk]|
|[3.0 patch|https://github.com/apache/cassandra/compare/cassandra-3.0...ifesdjeen:16457-3.0]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=16457-3.0]|
|[3.11 patch|https://github.com/apache/cassandra/compare/cassandra-3.11...ifesdjeen:16457-3.11]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=16457-3.11]|

CI Pending.;;;","19/Feb/21 16:23;aleksey;LGTM;;;","25/Feb/21 13:11;ifesdjeen;Thank you for the review. 

Committed to 3.11 with [e675a74d7303f10694e571594538a0462002051f|https://github.com/apache/cassandra/commit/e675a74d7303f10694e571594538a0462002051f] and merged up to [3.11|https://github.com/apache/cassandra/commit/6dbf34b88773c988a205c74a18fdc05646b00798] and [trunk|https://github.com/apache/cassandra/commit/20a315099753ae5220b31f07e74dd3745d02d21b].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CVE-2020-17516 mitigation in 2.2.x branch,CASSANDRA-16455,13359098,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,mdenihan,mdenihan,17/Feb/21 15:49,15/Sep/21 07:11,13/Jul/23 08:40,15/Sep/21 07:11,2.2.20,,,,,,,Local/Other,,,,0,,,"As a Cassandra 2.2.x user
I would like to know if a fix is planned for CVE-2020-17516 in this branch

https://mail-archives.apache.org/mod_mbox/cassandra-user/202102.mbox/%3c6E4340A5-D7BE-4D33-9EC5-3B505A626D8D@apache.org%3e
{quote}CVE-2020-17516: Apache Cassandra doesn't enforce encryption setting on inbound internode connections

Severity:
Important

Vendor:
The Apache Software Foundation

Versions Affected:
Cassandra 2.1.0 to 2.1.22
Cassandra 2.2.0 to 2.2.19
Cassandra 3.0.0 to 3.0.23
Cassandra 3.11.0 to 3.11.9
....
....
....

Mitigation:
Users of ALL versions should switch from ‘dc’ or ‘rack’ to ‘all’ internode_encryption
setting, as they are inherently insecure
3.0.x users should additionally upgrade to 3.0.24
3.11.x users should additionally upgrade to 3.11.24
{quote}

I can't find any ticket tracking implementing this fix in 2.2.x or 2.1.x. ",,mck,mdenihan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,Security,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Sep 15 07:11:43 UTC 2021,,,,,,,All,,,,"0|z0nrcg:",9223372036854775807,,,,,,,,Normal,,,,,,,,,,,,,,,,,,"15/Sep/21 07:11;mck;2.2 is EOL, since the 4.0.0 release.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in Slice#make on RT + partition deletion reconciliation on timestamp tie,CASSANDRA-16453,13359017,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,ifesdjeen,ifesdjeen,ifesdjeen,17/Feb/21 09:15,10/Mar/21 10:49,13/Jul/23 08:40,10/Mar/21 10:33,4.0,4.0-rc1,,,,,,Consistency/Coordination,,,,0,,,"There’s an NPE in Slice#make on RT + partition deletion reconciliation.

Minimal repro:
{code:java}
    try (Cluster cluster = init(builder().withNodes(3).start()))
        {
            cluster.schemaChange(withKeyspace(""CREATE TABLE distributed_test_keyspace.table_0 (pk0 bigint,ck0 bigint,regular0 bigint,regular1 bigint,regular2 bigint, PRIMARY KEY (pk0, ck0)) WITH  CLUSTERING ORDER BY (ck0 ASC);""));
            long pk = 0L;
            cluster.coordinator(1).execute(""DELETE FROM distributed_test_keyspace.table_0 USING TIMESTAMP 100230 WHERE pk0=? AND ck0>?;"", ConsistencyLevel.ALL, pk, 2L);
            cluster.get(3).executeInternal(""DELETE FROM distributed_test_keyspace.table_0 USING TIMESTAMP 100230 WHERE pk0=?;"", pk);
            cluster.coordinator(1).execute(""SELECT * FROM distributed_test_keyspace.table_0 WHERE pk0=? AND ck0>=? AND ck0<?;"",
                                                     ConsistencyLevel.ALL, pk, 1L, 3L);
        }
{code}
Details:
{code:java}
java.lang.AssertionError: Error merging RTs on distributed_test_keyspace.table_0: merged=null, versions=[Marker EXCL_START_BOUND(2)@100230/1613500432, Marker EXCL_START_BOUND(2)@100230/1613500432, null], sources={[Full(/127.0.0.1:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.3:7012,(-3074457345618258603,3074457345618258601])]}, debug info:
 /127.0.0.1:7012 => [distributed_test_keyspace.table_0] key=0 partition_deletion=deletedAt=-9223372036854775808, localDeletion=2147483647 columns=[[] | [regular0 regular1 regular2]] repaired_digest= repaired_digest_conclusive==true
    Marker EXCL_START_BOUND(2)@100230/1613500432
    Marker EXCL_END_BOUND(3)@100230/1613500432,
/127.0.0.2:7012 => [distributed_test_keyspace.table_0] key=0 partition_deletion=deletedAt=-9223372036854775808, localDeletion=2147483647 columns=[[] | [regular0 regular1 regular2]] repaired_digest= repaired_digest_conclusive==true
    Marker EXCL_START_BOUND(2)@100230/1613500432
    Marker EXCL_END_BOUND(3)@100230/1613500432,
/127.0.0.3:7012 => [distributed_test_keyspace.table_0] key=0 partition_deletion=deletedAt=100230, localDeletion=1613500432 columns=[[] | [regular0 regular1 regular2]] repaired_digest= repaired_digest_conclusive==true
{code}
Exception:
{code:java}
java.lang.NullPointerException
	at org.apache.cassandra.db.Slice.make(Slice.java:74)
	at org.apache.cassandra.service.reads.repair.RowIteratorMergeListener.closeOpenMarker(RowIteratorMergeListener.java:351)
	at org.apache.cassandra.service.reads.repair.RowIteratorMergeListener.onMergedRangeTombstoneMarkers(RowIteratorMergeListener.java:315)
	at org.apache.cassandra.service.reads.DataResolver$2$1.onMergedRangeTombstoneMarkers(DataResolver.java:378)
	at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator$MergeReducer.getReduced(UnfilteredRowIterators.java:592)
	at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator$MergeReducer.getReduced(UnfilteredRowIterators.java:541)
	at org.apache.cassandra.utils.MergeIterator$ManyToOne.consume(MergeIterator.java:219)
	at org.apache.cassandra.utils.MergeIterator$ManyToOne.computeNext(MergeIterator.java:158)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator.computeNext(UnfilteredRowIterators.java:523)
	at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator.computeNext(UnfilteredRowIterators.java:391)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:133)
	at org.apache.cassandra.db.transform.FilteredRows.isEmpty(FilteredRows.java:50)
	at org.apache.cassandra.db.transform.EmptyPartitionsDiscarder.applyToPartition(EmptyPartitionsDiscarder.java:27)
	at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:97)
	at org.apache.cassandra.service.StorageProxy$6.hasNext(StorageProxy.java:1908)
	at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:93)
	at org.apache.cassandra.cql3.statements.SelectStatement.process(SelectStatement.java:777)
	at org.apache.cassandra.cql3.statements.SelectStatement.processResults(SelectStatement.java:425)
	at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:402)
	at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:250)
	at org.apache.cassandra.distributed.impl.Coordinator.lambda$executeWithPagingWithResult$2(Coordinator.java:162)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
{code}

This behaviour is new to 4.0 and was introduced in [CASSANDRA-15369]. The difference with 3.0 is that in 3.0 {{RangeTombstoneMarker merged}} would be {{null}}, so we would never be hitting the code path where some of the sources is opening/closing marker, and instead will fall through to opening/closing of deletions below. I've checked code in 15369 and it looks like this condition is a new edge case in otherwise correct code. Since the goal was to avoid generating range tombstones on ties with partition deletion, fix for this issue is also consistent with that goal. 

In other words, on 3.0 given
{code}
cluster.coordinator(1).execute(""INSERT INTO distributed_test_keyspace.tbl0 (pk, ck, value) VALUES (?,?,?) USING TIMESTAMP 1"", ConsistencyLevel.ALL, pk, 1L, 1L, 1L);
cluster.coordinator(1).execute(""DELETE FROM distributed_test_keyspace.tbl0 USING TIMESTAMP 2 WHERE pk=? AND ck>?;"", ConsistencyLevel.ALL, pk, 2L);            
{code}

We would RR:
{code}
Mutation(keyspace='distributed_test_keyspace', key='0000000000000000', modifications=[
  [distributed_test_keyspace.table_0] key=0 partition_deletion=deletedAt=-9223372036854775808, localDeletion=2147483647 columns=[[] | [regular0 regular1 regular2]]
    Marker EXCL_START_BOUND(2)@100230/1615295010
    Marker EXCL_END_BOUND(3)@100230/1615295010
])
mutation = Mutation(keyspace='distributed_test_keyspace', key='0000000000000000', modifications=[
  [distributed_test_keyspace.table_0] key=0 partition_deletion=deletedAt=100230, localDeletion=1615295010 columns=[[] | [regular0 regular1 regular2]]
    Marker EXCL_START_BOUND(2)@100230/1615295010
    Marker EXCL_END_BOUND(3)@100230/1615295010
])
Mutation(keyspace='distributed_test_keyspace', key='0000000000000000', modifications=[
  [distributed_test_keyspace.table_0] key=0 partition_deletion=deletedAt=100230, localDeletion=1615295010 columns=[[] | [regular0 regular1 regular2]]
])
{code}

And on 4.0: 
{code}
Mutation(keyspace='distributed_test_keyspace', key='0000000000000000', modifications=[
  [distributed_test_keyspace.tbl0] key=0 partition_deletion=deletedAt=2, localDeletion=1615295072 columns=[[] | [value]]
])
Mutation(keyspace='distributed_test_keyspace', key='0000000000000000', modifications=[
  [distributed_test_keyspace.tbl0] key=0 partition_deletion=deletedAt=2, localDeletion=1615295072 columns=[[] | [value]]
])
{code}",,aleksey,ifesdjeen,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,ifesdjeen,,,,,,,,,,,,,Availability -> Response Crash,,,,,,,,Normal,Fuzz Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Mar 10 10:33:22 UTC 2021,,,,,,,All,,,,"0|z0nqug:",9223372036854775807,,,,aleksey,marcuse,,,Critical,,4.0-beta4,,https://github.com/apache/cassandra/commit/6f13c864a02b32daa7696eca27431f5385a306df,,,,,,,,,"Tests included; fuzz tests are under way",,,,,"17/Feb/21 14:58;ifesdjeen;|[trunk patch|https://github.com/apache/cassandra/pull/904]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=16453-trunk]|;;;","03/Mar/21 12:35;marcuse;+1;;;","05/Mar/21 13:06;aleksey;+1d on GitHub a while ago. Duplicating here for visibility. Ship it.;;;","10/Mar/21 10:33;ifesdjeen;Thank you for review! Committed to trunk with [6f13c864a02b32daa7696eca27431f5385a306df|https://github.com/apache/cassandra/commit/6f13c864a02b32daa7696eca27431f5385a306df];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MigrationCoordinatorTest#testWeKeepSendingRequests() Failing Sporadically,CASSANDRA-16450,13358720,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,maedhroz,maedhroz,maedhroz,15/Feb/21 20:10,16/Mar/22 15:27,13/Jul/23 08:40,16/Feb/21 17:36,3.0.25,3.11.11,4.0,4.0-rc1,,,,Test/unit,,,,0,,,"This test has now failed at least on trunk and 3.11. Here are the data points we have:

*trunk*

https://ci-cassandra.apache.org/job/Cassandra-trunk/273/testReport/org.apache.cassandra.schema/MigrationCoordinatorTest/testWeKeepSendingRequests/

https://app.circleci.com/pipelines/github/adelapena/cassandra/181/workflows/84fa978e-6df6-455a-b9d0-8e1024e2657f/jobs/1390


*3.11*

https://app.circleci.com/pipelines/github/dcapwell/cassandra/801/workflows/34d9dd52-444a-465d-88ff-074db4a03132/jobs/4597

The only previous mention of this issue was [here|https://issues.apache.org/jira/browse/CASSANDRA-15158?focusedCommentId=17165619&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17165619]. In any case, that issue seems not to have resolved the problem.",,adelapena,maedhroz,,,,,,,,,,,,,,"maedhroz opened a new pull request #900:
URL: https://github.com/apache/cassandra/pull/900


   ensure that MigrationCoordinatorTest.testWeKeepSendingRequests waits for callback failure to complete before asserting that a new request has been sent


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Feb/21 21:31;githubbot;600","maedhroz commented on pull request #900:
URL: https://github.com/apache/cassandra/pull/900#issuecomment-779456526


   https://app.circleci.com/pipelines/github/maedhroz/cassandra/237/workflows/641cd945-f194-4a4f-bc0b-5cbed0c2061f


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Feb/21 21:31;githubbot;600","smiklosovic closed pull request #900:
URL: https://github.com/apache/cassandra/pull/900


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:27;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,maedhroz,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Feb 16 17:33:42 UTC 2021,,,,,,,All,,,,"0|z0np0g:",9223372036854775807,,,,adelapena,,,,Normal,,3.0.24,,https://github.com/apache/cassandra/commit/8d71e06c1c83df5ec29069e3be3352f1dcf1d1d2,,,,,,,,,"I've verified the fix locally, where it was quite easy to reproduce when run repeatedly.",,,,,"15/Feb/21 20:15;maedhroz;I should also note that this isn't very hard to reproduce locally if you run it enough, for instance w/ IDEA's multiple run apparatus. It does not appear to fail if run multiple times *by itself* though, so I'm leaning toward some inter-test state pollution...;;;","15/Feb/21 20:42;maedhroz;Got it to fail alone by jacking up the loop in {{testWeKeepSendingRequests()}} to run 1000 rather than 10 iterations, but I still only get about 2 failures in 100 runs.;;;","15/Feb/21 21:34;maedhroz;This should apply cleanly to 3.11 and trunk.

|3.0|[patch|https://github.com/apache/cassandra/pull/900]|[CircleCI|https://app.circleci.com/pipelines/github/maedhroz/cassandra/237/workflows/641cd945-f194-4a4f-bc0b-5cbed0c2061f]|;;;","16/Feb/21 13:46;adelapena;The failure can also be reproduced by running the entire {{MigrationCoordinatorTest}} suite, where 100 iterations in IDEA seem to be enough to see some failures. Confirmed that the patch fixes the problem, +1.;;;","16/Feb/21 17:33;adelapena;Committed to {{cassandra-3.0}} as [8d71e06c1c83df5ec29069e3be3352f1dcf1d1d2|https://github.com/apache/cassandra/commit/8d71e06c1c83df5ec29069e3be3352f1dcf1d1d2] and merged up to {{trunk}}. 

The only merge conflict was just that in {{trunk}} the modified {{MigrationCoordinatorTest}} has been moved from the {{service}} package to {{schema}}.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix class loading for UDF in in-jvm dtests ,CASSANDRA-16448,13358704,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,ifesdjeen,ifesdjeen,ifesdjeen,15/Feb/21 17:34,01/Mar/21 14:06,13/Jul/23 08:40,25/Feb/21 08:30,3.0.25,3.11.11,4.0,4.0-rc1,,,,Test/dtest/java,,,,0,,,"User defined functions can not be loaded into in-jvm dtests, since UDF picks up system class loader rather than instance class loader. 
",,ifesdjeen,marcuse,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,ifesdjeen,,,,,,,,,,,,,Availability -> Response Crash,,,,,,,,Low Hanging Fruit,Fuzz Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Feb 25 08:30:12 UTC 2021,,,,,,,All,,,,"0|z0noww:",9223372036854775807,,,,marcuse,,,,Low,,3.0.23,,https://github.com/apache/cassandra/commit/efb5d036113898186bbc8a0eb0626c9c37fab588,,,,,,,,,Group By tests included already.,,,,,"15/Feb/21 17:40;ifesdjeen;|[3.0 patch|https://github.com/apache/cassandra/pull/905]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=CASSANDRA-16448-3.0]|
|[3.11 patch|https://github.com/apache/cassandra/pull/906]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=CASSANDRA-16448-3.11]|
|[trunk patch|https://github.com/apache/cassandra/pull/899]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=CASSANDRA-16448-trunk]|;;;","16/Feb/21 10:21;marcuse;+1 assuming CI is good;;;","25/Feb/21 08:30;ifesdjeen;Thank you for the review. Committed to 3.0 with [efb5d036113898186bbc8a0eb0626c9c37fab588|https://github.com/apache/cassandra/commit/efb5d036113898186bbc8a0eb0626c9c37fab588] and merged up to [3.11|https://github.com/apache/cassandra/commit/24de8e4ed4b64a2027926343720da7c9ae10379a] and [trunk|https://github.com/apache/cassandra/commit/5e2a72d7cca2d0dcf4d415d43a2b2e32ca44c512].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Parent repair sessions leak may lead to node long pauses,CASSANDRA-16446,13358582,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,15/Feb/21 05:57,01/Dec/21 17:28,13/Jul/23 08:40,24/Feb/21 18:56,4.0,4.0-rc1,,,,,,Consistency/Repair,,,,0,,,"{{ActiveRepairService}} keeps  a map `parentRepairSessions`. If these sessions leak, that map can grow to a size when a node restarts {{ActiveRepairService.onRestart()}} triggers a cleanup of sessions that can pause nodes in a cluster for a long time.

The proposed solution is for repairs to cleanup these sessions on all nodes on completion by sending a CLEANUP message to involved nodes. Tests rely on a new {{parentRepairSessionsCount()}} method on the parent repair sessions MBean to keep track of these.",,adelapena,bereng,dcapwell,e.dimitrova,jtgrabowski,mck,,,,,,,,,,"bereng opened a new pull request #126:
URL: https://github.com/apache/cassandra-dtest/pull/126


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Feb/21 08:57;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #126:
URL: https://github.com/apache/cassandra-dtest/pull/126#discussion_r577269806



##########
File path: repair_tests/preview_repair_test.py
##########
@@ -18,6 +20,21 @@ def assert_no_repair_history(self, session):
         rows = session.execute(""select * from system_distributed.parent_repair_history"")
         assert rows.current_rows == []
 
+    @since('4.0')
+    def test_parent_repair_session_cleanup(self):
+        """"""
+        Calls incremental repair preview on 3 node cluster and verifies if all ParentRepairSession objects are cleaned
+        """"""
+        self.cluster.populate(3).start()
+        session = self.patient_cql_connection(self.cluster.nodelist()[0])
+        create_ks(session, 'ks', 2)

Review comment:
       why the replication should be 2 and not 1? 




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 01:52;githubbot;600","bereng commented on a change in pull request #126:
URL: https://github.com/apache/cassandra-dtest/pull/126#discussion_r577335085



##########
File path: repair_tests/preview_repair_test.py
##########
@@ -18,6 +20,21 @@ def assert_no_repair_history(self, session):
         rows = session.execute(""select * from system_distributed.parent_repair_history"")
         assert rows.current_rows == []
 
+    @since('4.0')
+    def test_parent_repair_session_cleanup(self):
+        """"""
+        Calls incremental repair preview on 3 node cluster and verifies if all ParentRepairSession objects are cleaned
+        """"""
+        self.cluster.populate(3).start()
+        session = self.patient_cql_connection(self.cluster.nodelist()[0])
+        create_ks(session, 'ks', 2)

Review comment:
       Bc otherwise we'd noop [here](https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/service/StorageService.java#L3981).




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 05:28;githubbot;600","adelapena commented on a change in pull request #126:
URL: https://github.com/apache/cassandra-dtest/pull/126#discussion_r580441674



##########
File path: repair_tests/preview_repair_test.py
##########
@@ -18,6 +20,21 @@ def assert_no_repair_history(self, session):
         rows = session.execute(""select * from system_distributed.parent_repair_history"")
         assert rows.current_rows == []
 
+    @since('4.0')
+    def test_parent_repair_session_cleanup(self):
+        """"""
+        Calls incremental repair preview on 3 node cluster and verifies if all ParentRepairSession objects are cleaned

Review comment:
       Nit: we could add a `@jira_ticket CASSANDRA-16446` annotation here.

##########
File path: repair_tests/repair_test.py
##########
@@ -160,6 +161,15 @@ def _repair_and_verify(self, sequential=True):
 
 class TestRepair(BaseRepairTest):
 
+    @since('4.0')
+    def test_parent_repair_session_cleanup(self):
+        """"""
+        Calls range_tombstone_digest with a sequential repair and verifies if
+        all ParentRepairSession objects are cleaned

Review comment:
       Nit: as before, we could add `@jira_ticket CASSANDRA-16446` here.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Feb/21 17:31;githubbot;600","bereng commented on pull request #126:
URL: https://github.com/apache/cassandra-dtest/pull/126#issuecomment-783931415


   Added jira tickets.


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Feb/21 05:58;githubbot;600","bereng closed pull request #126:
URL: https://github.com/apache/cassandra-dtest/pull/126


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 06:13;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,3600,,,0,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Dec 01 17:28:25 UTC 2021,,,,,,,All,,,,"0|z0no5s:",9223372036854775807,,,,adelapena,e.dimitrova,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/23512cf3da5e8206d8797841f2238cdd86c13d96 https://github.com/apache/cassandra-dtest/commit/c89dea0e8c38ed35ed40d59c975a07585584a637,,,,,,,,,See PR,,,,,"15/Feb/21 09:02;bereng;All praise and glory to [~jtgrabowski] for the original solution :-);;;","16/Feb/21 14:59;e.dimitrova;Just to confirm, this patch is ready for review, right? As I see the ticket still in status ""work in progress"";;;","16/Feb/21 15:46;bereng;Mmmm yes it is. Weird I must have missed moving the status forward. Apologies.;;;","16/Feb/21 15:53;e.dimitrova;No worries at all, just wanted to be sure you don't have in mind some new changes to add :) Thanks for confirming!;;;","17/Feb/21 01:57;e.dimitrova;I did a first pass, left a few small comments/questions but in general it looks good, I will check a few more things tomorrow.

We need second reviewer. [~adelapena], you were revising the testing for repair if I recall correctly, do you think you will have time to check this one, too, please? ;;;","17/Feb/21 21:16;e.dimitrova;Jenkins run pushed [here| https://jenkins-cm4.apache.org/job/Cassandra-devbranch/385/];;;","18/Feb/21 05:30;bereng;Ah it failed bc of the rename we did... A new jenkins run should be clean now.;;;","18/Feb/21 13:58;e.dimitrova;New Jenkins CI run submitted [here | https://jenkins-cm4.apache.org/job/Cassandra-devbranch/387/];;;","19/Feb/21 05:45;bereng;I'd say it lgtm. There are some timeouts and then the 16411 failures waiting to be merged in.;;;","23/Feb/21 05:59;bereng;All PRs approved. Added latest jira ticket comment.;;;","24/Feb/21 11:26;adelapena;Great, I'm running a final CI round [here|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/398/pipeline] after the rebase just in case, I can commit once it finishes.;;;","24/Feb/21 11:45;adelapena;I see that the PRs are not rebased, and CircleCI is pointing to a different dtest branch that seems identical except for the last {{@jira_ticket}} tags. I have rebased the branches (on my repo, [here|https://github.com/adelapena/cassandra/tree/CASSANDRA-16446-review] and [here|https://github.com/adelapena/cassandra-dtest/tree/CASSANDRA-16446-review]) and I'm running that final CI round:
 * [circle j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/193/workflows/15564af1-1247-4b27-99f8-bb04c38b3ae6]
 * [circle j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/193/workflows/75dbbd96-ade0-4ef0-82d1-96aab0e68fe4]
 * [jenkins|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/399/pipeline];;;","24/Feb/21 13:53;bereng;Ah yes I didn't rebase. I just added the @jira_ticket & the reformatted line. Apologies I didn't get it you wanted it rebased.;;;","24/Feb/21 18:55;adelapena;Committed to {{trunk}} as [23512cf3da5e8206d8797841f2238cdd86c13d96|https://github.com/apache/cassandra/commit/23512cf3da5e8206d8797841f2238cdd86c13d96].

Dtests committed as [c89dea0e8c38ed35ed40d59c975a07585584a637|https://github.com/apache/cassandra-dtest/commit/c89dea0e8c38ed35ed40d59c975a07585584a637].;;;","25/Feb/21 06:12;bereng;Thx for all the work :-);;;","25/Feb/21 07:07;jtgrabowski;Thank you [~Bereng]!;;;","30/Nov/21 18:29;dcapwell;I don't see conversation in JIRA or GH, was wondering why cleanup is success only and does not include failure?  Best I see is https://github.com/apache/cassandra/pull/896#discussion_r577334272

bq. Parent session is removed as part of the success() call path.

If a session is failed, we can't recover or really act on it...  Was the concern IR?;;;","01/Dec/21 05:47;bereng;[~dcapwell] I don't remember any specific reasons. Also reading the code diagonally I don't see a reason why we couldn't cleanup also on failures. But this is not a part of the code I know by heart so I guess the best is to give it a go and see what happens?;;;","01/Dec/21 17:28;dcapwell;Thanks, saw it while refactoring and wasn't sure if there was a good reason.  What I see now is that both FINALIZE_COMMIT and CLEANUP touch different maps, so I don't see a clear conflict with IR so makes sense to me to cleanup on failure.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky test testMultiExpressionQueriesWhereRowSplitBetweenSSTables - org.apache.cassandra.index.sasi.SASIIndexTest,CASSANDRA-16444,13358396,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adutra,dcapwell,dcapwell,12/Feb/21 18:29,08/Mar/21 11:02,13/Jul/23 08:40,08/Mar/21 10:54,3.11.11,4.0,4.0-rc1,,,,,Test/unit,,,,0,,,"https://app.circleci.com/pipelines/github/dcapwell/cassandra/862/workflows/d2b10373-5bd1-4895-a738-1c28587cae62/jobs/5136

{code}
junit.framework.AssertionFailedError: []
	at org.apache.cassandra.index.sasi.SASIIndexTest.testMultiExpressionQueriesWhereRowSplitBetweenSSTables(SASIIndexTest.java:589)
	at org.apache.cassandra.index.sasi.SASIIndexTest.testMultiExpressionQueriesWhereRowSplitBetweenSSTables(SASIIndexTest.java:468)
{code}",,adelapena,adutra,blerer,dcapwell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16390,CASSANDRA-15544,CASSANDRA-15974,CASSANDRA-15995,CASSANDRA-15881,CASSANDRA-15527,CASSANDRA-15526,CASSANDRA-15528,,,,,,,,,,,,0.0,adutra,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Mar 08 11:02:55 UTC 2021,,,,,,,All,,,,"0|z0nn0g:",9223372036854775807,,,,adelapena,blerer,,,Normal,,3.4,,https://github.com/apache/cassandra/commit/e3902bcdad79dcef43562a075d6a130c6a77d63d,,,,,,,,,"# [PR for trunk|https://github.com/adutra/cassandra/pull/1]
# [PR for 3.11 branch|https://github.com/adutra/cassandra/pull/2]",,,,,"17/Feb/21 18:01;adutra;I had some time to investigate this morning by running the tests hundreds of times in a row, individually and as part of the test class suite. Just in case, here are my findings. In SASIIndexTest class, we have a few issues actually:
 * testMultiExpressionQueriesWhereRowSplitBetweenSSTables: is indeed flaky, when run individually or as part of the test class suite. However it is only flaky for forceFlush = false. I couldn't make it fail when forceFlush = true.
 * testIndexRedistribution : also flaky, when run individually or as part of the test class suite.
 * testPagination: also flaky, but only when run as part of the class test suite (it is not flaky when run individually). Note: it is flaky for both forceFlush values.
 * testTruncate : also flaky, but only when run as part of the class test suite (it is not flaky when run individually).
 * testIndexMemtableSwitching: also flaky; seems sensitive to test ordering. Never fails when run individually, but fails 100% of time when run as part of the test class suite on my machine. I couldn't determine which other test is making this one fail.

Hope that helps.;;;","24/Feb/21 15:43;adutra;What I've got so far:
 # The usage of {{System.currentTimeMillis()}} to generate timestamps is error-prone. Some tests create and apply many mutations in sequence, but sometimes 2 successive mutations get the same timestamp, and the test fails. The following tests are potentially impacted by this:
 ## testCrossSSTableQueries
 ## testMultiExpressionQueriesWhereRowSplitBetweenSSTables
 ## testPagination
 ## testColumnNamesWithSlashes
 ## testInvalidate
 ## testIndexRedistribution
 ## testTruncate
 ## testSameKeyInMemtableAndSSTables
 ## testUnicodeSupport
 ## testUnicodeSuffixModeNoSplits
 ## testChinesePrefixSearch
 ## testLowerCaseAnalyzer
 ## testPrefixSSTableLookup
 ## testIndexMemtableSwitching
 # {{testIndexRedistribution}}: race condition. The test fails when a {{CompactionTask}} is running while {{getIndexed()}} is called. 
 ## Wrapping {{getIndexed()}} call within {{store.runWithCompactionsDisabled()}} solves the problem.
 ## _I am not expert enough to tell if this is hiding a broader problem with index redistribution in general._
 # {{testIndexMemtableSwitching}}: side-effect issue. The test fails only if {{testInsertingIncorrectValuesIntoAgeIndex}} is executed before:
 ## {{testInsertingIncorrectValuesIntoAgeIndex}} leaves the store in an inconsistent state due to an invalid mutation. 
 ## The next memtable flush task fails because of an invalid cell type created by the test.
 ## afaict, the memtable stays forever among the pending memtables list and will never be flushed or removed.
 ## Similarly, {{ColumnIndex}} never gets a notification that the parent memtable was flushed, and so {{ColumnIndex.pendingFlush}} is never cleared.
 ## {{testIndexMemtableSwitching}} verifies that {{ColumnIndex.pendingFlush}} is empty, and fails.
 ## _I am not expert enough to tell if this is hiding a broader problem with failed memtable flushes._

I am going to propose 3 distinct patches:
 # Replace all occurrences of {{System.currentTimeMillis()}} in {{SASIIndexTest}} by fixed timestamps.
 # Fix {{testIndexRedistribution}} by reading the index contents inside {{store.runWithCompactionsDisabled()}}. 
 # {{testIndexMemtableSwitching}}: manually clear the store memtables using {{store.clearUnsafe()}} and manually clean {{ColumnIndex.pendingFlush}} after {{testInsertingIncorrectValuesIntoAgeIndex}}, so as to leave the store in a consistent state.;;;","25/Feb/21 10:29;adutra;Update: {{testIndexRedistribution}} and {{testIndexMemtableSwitching}} are not flaky on trunk afaict. Fixing the timestamps issue on trunk is enough. ;;;","26/Feb/21 20:22;adutra;Please review PR for trunk first.
PR for 3.11 includes the same fixes + 2 additional commits that are only relevant for 3.11.;;;","01/Mar/21 11:20;blerer;Thanks for the patches and the deep analysis.

* I believe that even if it does not appear as a problem right now we should make the tests more robusts. 2 things that strike me are that the tables are not cleaned up between the tests and that {{forcedFlushes}} are used but the tests do not disable the automatic flushes.

I would change the {{cleanupData}} method into:
{code}
    private static void cleanupData()
    {
        stores().forEach(ColumnFamilyStore::truncateBlocking);
    }

    private static Stream<ColumnFamilyStore> stores()
    {
        Keyspace ks = Keyspace.open(KS_NAME);
        return ks.getMetadata().tables.stream().map(t -> ks.getColumnFamilyStore(t.name));
    }
{code}

and the {{cleanUp}} method into:
{code}
    @Before
    public void cleanUp()
    {
        cleanupData();
    }
{code} 
That would ensure that we clean all the tables between the different tests.

I would also add {{stores().forEach(ColumnFamilyStore::disableAutoCompaction);}} at the end of the {{loadSchema()}} method to ensure that there are no race condition with automatic compactions.

* Regarding the timestamp fix, would it not make sense to use some thing like:
{code}
    private static long timestamp = 0;

    private static long nextTimestamp()
    {
        timestamp += 1000;
        return timestamp;
    }
{code}
rather than specifying the timestamp for each call to {{loadData}}?

* Regarding {{testInsertingIncorrectValuesIntoAgeIndex}} problem in 3.11, it seems that the test has been changed as part of CASSANDRA-15867 and I am not convinced that this change was the correct one. If you roll back that change, do you still see the same issue?;;;","01/Mar/21 19:06;adelapena;[~adutra] this is a nice investigation on the causes of those failures. I've run our internal test multiplexer for {{SASIIndexTest}} with 200 iterations for the current 3.11 and trunk branches and for each corresponding patch:
||branch||job||failed tests||
|cassandra-3.11|[696|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/696/]|testPagination(200), testIndexRedistribution(200), testMultiExpressionQueriesWhereRowSplitBetweenSSTables(1)|
|trunk|[697|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/697/]|testMultiExpressionQueriesWhereRowSplitBetweenSSTables(5)|
|16444-3.11|[698|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/698/]|testTableRebuild(11), testIndexRebuild(11)|
|16444-trunk|[699|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/699/]|testMultiExpressionQueriesWhereRowSplitBetweenSSTables(1)|

So it seems that, if we trust the multiplexer, we still have some flakiness. And, as Benjamin mentioned, {{testIndexMemtableSwitching}} doesn't seem to be failing anymore.

Also, although it's not related to the patch, I think that perhaps we could clean here some of the many warnings in {{SASIIndexTest}}. The most frequent ones are unneeded uses of {{throws Exception}} and many calls of the form:
{code:java}
Assert.assertTrue(rows.toString(), Arrays.equals(new String[] { ""key1"", ""key2"", ""key3"", ""key4"" }, rows.toArray(new String[rows.size()])));
{code}
These could be simplified if we added a simple utility method like, for example:
{code:java}
assertRows(rows, ""key1"", ""key2"", ""key3"", ""key4"");
...
private static void assertRows(Set<String> actual, String... expected)
{
    Assert.assertArrayEquals(expected, Iterables.toArray(actual, String.class));
}
{code}
Not sure whether introducing these changes would be too distracting but I think they would easily increase the readability of the test class. I gave it a quick go [here|https://github.com/adelapena/cassandra/commit/7b6d460b63c48636d907e48e40fe1b64d8687ddc].;;;","02/Mar/21 10:28;blerer;I had a look to the failing tests: {{testTableRebuild}}, {{testIndexRebuild}}. They both use the {{CLUSTERING_CF_NAME_1}} table which is not cleaned between the tests.
I would suggest to add the improvements I proposed and re-run the multiplexer tests.
;;;","02/Mar/21 13:38;adelapena;Makes sense, I have started the multiplexer [here|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/700/] for [a 3.11-based branch|https://github.com/adutra/cassandra/compare/16444-3.11...adelapena:16444-3.11-review] with the {{cleanupData}} and {{timestamp}} suggestions. It should be finished in ~2h.;;;","02/Mar/21 13:51;adutra;Thank you [~blerer] and [~adelapena] for the thorough reviews.
{quote}I would change the cleanupData method
{quote}
Very good suggestion, done on both PRs.
{quote}I would also add stores().forEach(ColumnFamilyStore::disableAutoCompaction); at the end of the loadSchema() method
{quote}
Done on both PRs.
{quote}forcedFlushes are used but the tests do not disable the automatic flushes
{quote}
How would you do this? Should I play with {{memtable_flush_period_in_ms}} when creating the tables?
{quote}Regarding testIndexMemtableSwitching problem in 3.11, it seems that the test has been changed as part of CASSANDRA-15867 and I am not convinced that this change was the correct one. If you roll back that change, do you still see the same issue?
{quote}
I will try that next and let you know.
{quote}Regarding the timestamp fix, would it not make sense to use some thing like rather than specifying the timestamp for each call to loadData?
{quote}
I actually have a slight preference for fixed timestamps as they produce deterministic results. Using a counter means that you don't really control which timestamps are being used. Besides, at least one test requires very specific timestamps or it fails: {{testTruncate}}.
{quote}I think that perhaps we could clean here some of the many warnings in SASIIndexTest.
{quote}
Absolutely, I cherry-picked your commit on both PRs and indeed the test class looks much better.

At this point, I suggest that we re-run the multiplexer and see if at least {{testTableRebuild}} and {{testIndexRebuild}} are fixed.;;;","02/Mar/21 15:23;adutra;[~blerer] I investigated the change introduced by CASSANDRA-15867.

In fact, this change simply fixed a test that was failing for a while.

Doing a git bisect, I found that the commit that introduced the test regression is in fact c4064dd: [Allow recovery from the cases when CQL-created compact sense tables have bytes in EmptyType columns|https://github.com/apache/cassandra/commit/c4064dd80e427aec7c04e8e2e1e4630d6c8087b6#diff-0e5a142c13247885605175ace136c549391fb6c778877f91f589fd94131c241b].

This change introduced an assertion inside {{AbstractType.writeValue()}}:
{code:java}
        assert valueLengthIfFixed < 0 || value.remaining() == valueLengthIfFixed : String.format(""Expected exactly %d bytes, but was %d"",
                                                                                                 valueLengthIfFixed, value.remaining());
{code}
Without the assert, the incorrect 8-bytes value created by {{testInsertingIncorrectValuesIntoAgeIndex}} gets written; with the assertion, it doesn't, and the {{AssertionError}} bubbles up, messing up the store state. The author of CASSANDRA-15867 simply added a try-catch block around the test to avoid the test failure. But I wonder if we shouldn't simply disable this test, since it violates an invariant expressed by the new assertion.

Oddly enough, this assertion was not ported to trunk, which basically conserved the pre-c4064dd behavior. This is why this test ({{testInsertingIncorrectValuesIntoAgeIndex}}) is not dangerous on trunk: it passes normally and doesn't leave the store in an inconsistent state; therefore it doesn't need a try-catch block nor any ugly band-aid to fix the store state.;;;","02/Mar/21 15:40;blerer;{quote}forcedFlushes are used but the tests do not disable the automatic flushes

 How would you do this? Should I play with memtable_flush_period_in_ms when creating the tables{quote}

Ignore my comment. I think I mixed up several things in my mind when I wrote that comment. By default flushes are not triggered periodically.
 Sorry for that.;;;","02/Mar/21 17:10;blerer;[~adutra] {{testInsertingIncorrectValuesIntoAgeIndex}} is a pretty strange test to me. In my opinion we can remove it. ;;;","03/Mar/21 12:27;adutra;bq. testInsertingIncorrectValuesIntoAgeIndex is a pretty strange test to me. In my opinion we can remove it.

Agreed, done.

Also, we have 2 green builds with the multiplexer:

# [16444-trunk|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/701/]
# [16444-3.11|https://jenkins-dse.build.dsinternal.org/view/Parameterized/job/parameterized-testall/702/]

So it seems that with Benjamin's suggestions we finally got rid of all the flakiness.;;;","03/Mar/21 13:53;blerer;+1 Thanks for the patches [~adutra] ;;;","03/Mar/21 17:42;adelapena;{quote}Regarding the timestamp fix, would it not make sense to use some thing like rather than specifying the timestamp for each call to loadData?
{quote}
{quote}I actually have a slight preference for fixed timestamps as they produce deterministic results. Using a counter means that you don't really control which timestamps are being used. Besides, at least one test requires very specific timestamps or it fails: {{testTruncate}}.
{quote}
I liked the idea of increasing the timestamp inside of {{loadData}}. I think that, given that the tests are not run in parallel, that automatically increased timestamp would also be deterministic. As for the special case of {{testTruncate}} we can use the current behaviour overloading {{loadData}}. Also I think there is no need to use seconds, we can increase the timestamps one by one with a precision of milliseconds. I gave it a go [here|https://github.com/adelapena/cassandra/commit/fbcef9b9e0bd81a9101682e8bd1ffabe776cba5f]. Nevertheless this is just a detail so feel free to ignore if you don't agree.

Other than this nit, the changes look good to me, it's nice to see this test finally fixed.;;;","03/Mar/21 18:02;adutra;Fair enough, I cherry-picked your commits on both branches. I also started two more multiplexer builds, just in case.

Unrelated: regarding the assertion that was introduced in 3.11:

bq. Oddly enough, this assertion was not ported to trunk, which basically conserved the pre-c4064dd behavior.

Do we need to worry about it? From my (admittedly novice) standpoint, it seems that AbstractType has stricter validation rules in 3.11 than in 4.0...;;;","04/Mar/21 10:02;blerer;{quote}Do we need to worry about it? From my (admittedly novice) standpoint, it seems that AbstractType has stricter validation rules in 3.11 than in 4.0...{quote}

According to [~slebresne] [comment|https://issues.apache.org/jira/browse/CASSANDRA-15778?focusedCommentId=17117827&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17117827] the validation was only added because he believe that the new code could trigger this path.

In my opinion the validation make sense anyway so it might be good to put it also in 4.0. I would just use some proper IOException like in {{readValue}} rather than assertions.   ;;;","08/Mar/21 10:54;blerer;Committed into cassandra-3.11 at e3902bcdad79dcef43562a075d6a130c6a77d63d and merged into trunk;;;","08/Mar/21 11:02;blerer;Thanks for the patch [~adutra]. I opened CASSANDRA-16500 to address the missing validation issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky test org.apache.cassandra.db.SinglePartitionSliceCommandTest testPartitionDeletionRowDeletionTie,CASSANDRA-16443,13358393,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,blerer,dcapwell,dcapwell,12/Feb/21 18:08,16/Mar/22 15:28,13/Jul/23 08:40,23/Feb/21 23:12,4.0,4.0-rc1,,,,,,Test/unit,,,,0,,,"https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-test/225/jdk=jdk_11_latest,label=cassandra/testReport/junit/org.apache.cassandra.db/SinglePartitionSliceCommandTest/testPartitionDeletionRowDeletionTie/

{code}
Error Message
Expected [Row[info=[ts=11] ]: c=1 | [v=1 ts=11]] but got [Row[info=[ts=11] del=deletedAt=10, localDeletion=1613085925 ]: c=1 | [v=1 ts=11]] expected: java.util.ArrayList<[[[v=1 ts=11]]]> but was: java.util.ArrayList<[[[v=1 ts=11]]]>
Stacktrace
junit.framework.AssertionFailedError: Expected [Row[info=[ts=11] ]: c=1 | [v=1 ts=11]] but got [Row[info=[ts=11] del=deletedAt=10, localDeletion=1613085925 ]: c=1 | [v=1 ts=11]] expected: java.util.ArrayList<[[[v=1 ts=11]]]> but was: java.util.ArrayList<[[[v=1 ts=11]]]>
	at org.apache.cassandra.db.SinglePartitionSliceCommandTest.testPartitionDeletionRowDeletionTie(SinglePartitionSliceCommandTest.java:382)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Standard Output
INFO  [main] 2021-02-11 23:25:22,114 YamlConfigurationLoader.java:93 - Configuration location: file:/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/test/conf/cassandra.yaml
DEBUG [main] 2021-02-11 23:25:22,117 YamlConfigurationLoader.java:112 - Loading settings from file:/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/test/conf/cassandra.yaml
DEBUG [main] 2021-02-11 23:25:22,196 InternalLoggerFactory.java:63 - Using SLF4J as the default logging framework
DEBUG [main] 2021-02-11 23:25:22,211 PlatformDependent0.java:417 - -Dio.netty.noUnsafe: false
DEBUG [main] 2021-02-11 23:25:22,211 PlatformDependent0.java:897 - Java version: 11
DEBUG [main] 2021-02-11 23:25:22,213 PlatformDependent0.java:130 - sun.misc.Unsafe.theUnsafe: available
DEBUG [main] 2021-02-11 23:25:22,213 PlatformDependent0.java:154 - sun.misc.Unsafe.copyMemory: available
DEBUG [main] 2021-02-11 23:25:22,214 PlatformDependent0.java:192 - java.nio.Buffer.address: available
DEBUG [main] 2021-02-11 23:25:22,216 PlatformDependent0.java:266 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31)
	at io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:238)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:232)
	at io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:293)
	at io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92)
	at io.netty.handler.ssl.OpenSsl.<clinit>(OpenSsl.java:124)
	at org.apache.cassandra.security.SSLFactory.<clinit>(SSLFactory.java:100)
	at org.apache.cassandra.config.EncryptionOptions.<clinit>(EncryptionOptions.java:242)
	at org.apache.cassandra.config.Config.<init>(Config.java:280)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:330)
	at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:308)
	at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:301)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructMapping.construct(Constructor.java:167)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:331)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:219)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:173)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:157)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:472)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:466)
	at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:199)
	at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:129)
	at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:105)
	at org.apache.cassandra.OffsetAwareConfigurationLoader.loadConfig(OffsetAwareConfigurationLoader.java:55)
	at org.apache.cassandra.config.DatabaseDescriptor.loadConfig(DatabaseDescriptor.java:301)
	at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:177)
	at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:162)
	at org.apache.cassandra.db.SinglePartitionSliceCommandTest.defineSchema(SinglePartitionSliceCommandTest.java:96)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:38)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:534)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1196)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:1041)
DEBUG [main] 2021-02-11 23:25:22,216 PlatformDependent0.java:331 - java.nio.Bits.unaligned: available, true
DEBUG [main] 2021-02-11 23:25:22,218 PlatformDependent0.java:393 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): available
DEBUG [main] 2021-02-11 23:25:22,218 PlatformDependent0.java:403 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
DEBUG [main] 2021-02-11 23:25:22,218 PlatformDependent.java:1079 - sun.misc.Unsafe: available
DEBUG [main] 2021-02-11 23:25:22,231 PlatformDependent.java:1181 - maxDirectMemory: 1037959168 bytes (maybe)
DEBUG [main] 2021-02-11 23:25:22,231 PlatformDependent.java:1200 - -Dio.netty.tmpdir: /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/tmp (java.io.tmpdir)
DEBUG [main] 2021-02-11 23:25:22,231 PlatformDependent.java:1279 - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG [main] 2021-02-11 23:25:22,232 PlatformDependent.java:177 - -Dio.netty.maxDirectMemory: -1 bytes
DEBUG [main] 2021-02-11 23:25:22,232 PlatformDependent.java:184 - -Dio.netty.uninitializedArrayAllocationThreshold: 1024
DEBUG [main] 2021-02-11 23:25:22,233 CleanerJava9.java:71 - java.nio.ByteBuffer.cleaner(): available
DEBUG [main] 2021-02-11 23:25:22,233 PlatformDependent.java:204 - -Dio.netty.noPreferDirect: false
DEBUG [main] 2021-02-11 23:25:22,236 NativeLibraryLoader.java:73 - -Dio.netty.native.workdir: /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/tmp (io.netty.tmpdir)
DEBUG [main] 2021-02-11 23:25:22,237 NativeLibraryLoader.java:78 - -Dio.netty.native.deleteLibAfterLoading: true
DEBUG [main] 2021-02-11 23:25:22,237 NativeLibraryLoader.java:82 - -Dio.netty.native.tryPatchShadedId: true
DEBUG [main] 2021-02-11 23:25:22,238 NativeLibraryLoader.java:346 - Unable to load the library 'netty_tcnative_linux_x86_64', trying other loading mechanism.
java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_x86_64 in java.library.path: [/usr/java/packages/lib, /usr/lib64, /lib64, /lib, /usr/lib]
	at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2660)
	at java.base/java.lang.Runtime.loadLibrary0(Runtime.java:827)
	at java.base/java.lang.System.loadLibrary(System.java:1871)
	at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at io.netty.util.internal.NativeLibraryLoader$1.run(NativeLibraryLoader.java:385)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(NativeLibraryLoader.java:377)
	at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:341)
	at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:136)
	at io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(NativeLibraryLoader.java:96)
	at io.netty.handler.ssl.OpenSsl.loadTcNative(OpenSsl.java:592)
	at io.netty.handler.ssl.OpenSsl.<clinit>(OpenSsl.java:136)
	at org.apache.cassandra.security.SSLFactory.<clinit>(SSLFactory.java:100)
	at org.apache.cassandra.config.EncryptionOptions.<clinit>(EncryptionOptions.java:242)
	at org.apache.cassandra.config.Config.<init>(Config.java:280)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:330)
	at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:308)
	at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:301)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructMapping.construct(Constructor.java:167)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:331)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:219)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:173)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:157)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:472)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:466)
	at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:199)
	at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:129)
	at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:105)
	at org.apache.cassandra.OffsetAwareConfigurationLoader.loadConfig(OffsetAwareConfigurationLoader.java:55)
	at org.apache.cassandra.config.DatabaseDescriptor.loadConfig(DatabaseDescriptor.java:301)
	at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:177)
	at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:162)
	at org.apache.cassandra.db.SinglePartitionSliceCommandTest.defineSchema(SinglePartitionSliceCommandTest.java:96)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:38)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:534)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1196)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:1041)
DEBUG [main] 2021-02-11 23:25:22,238 NativeLibraryLoader.java:141 - netty_tcnative_linux_x86_64 cannot be loaded from java.library.path, now trying export to -Dio.netty.native.workdir: /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/tmp
java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_x86_64 in java.library.path: [/usr/java/packages/lib, /usr/lib64, /lib64, /lib, /usr/lib]
	at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2660)
	at java.base/java.lang.Runtime.loadLibrary0(Runtime.java:827)
	at java.base/java.lang.System.loadLibrary(System.java:1871)
	at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
	at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:351)
	at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:136)
	at io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(NativeLibraryLoader.java:96)
	at io.netty.handler.ssl.OpenSsl.loadTcNative(OpenSsl.java:592)
	at io.netty.handler.ssl.OpenSsl.<clinit>(OpenSsl.java:136)
	at org.apache.cassandra.security.SSLFactory.<clinit>(SSLFactory.java:100)
	at org.apache.cassandra.config.EncryptionOptions.<clinit>(EncryptionOptions.java:242)
	at org.apache.cassandra.config.Config.<init>(Config.java:280)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:330)
	at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:308)
	at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:301)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructMapping.construct(Constructor.java:167)
	at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:331)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:219)
	at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:173)
	at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:157)
	at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:472)
	at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:466)
	at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:199)
	at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:129)
	at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:105)
	at org.apache.cassandra.OffsetAwareConfigurationLoader.loadConfig(OffsetAwareConfigurationLoader.java:55)
	at org.apache.cassandra.config.DatabaseDescriptor.loadConfig(DatabaseDescriptor.java:301)
	at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:177)
	at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:162)
	at org.apache.cassandra.db.SinglePartitionSliceCommandTest.defineSchema(SinglePartitionSliceCommandTest.java:96)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:38)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:534)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1196)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:1041)
	Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_x86_64 in java.library.path: [/usr/java/packages/lib, /usr/lib64, /lib64, /lib, /usr/lib]
		at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2660)
		at java.base/java.lang.Runtime.loadLibrary0(Runtime.java:827)
		at java.base/java.lang.System.loadLibrary(System.java:1871)
		at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
		at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.base/java.lang.reflect.Method.invoke(Method.java:566)
		at io.netty.util.internal.NativeLibraryLoader$1.run(NativeLibraryLoader.java:385)
		at java.base/java.security.AccessController.doPrivileged(Native Method)
		at io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(NativeLibraryLoader.java:377)
		at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:341)
		... 43 common frames omitted
DEBUG [main] 2021-02-11 23:25:22,272 NativeLibraryLoader.java:342 - Successfully loaded the library /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/tmp/libnetty_tcnative_linux_x86_644195741983291477481.so
DEBUG [main] 2021-02-11 23:25:22,272 OpenSsl.java:149 - Initialize netty-tcnative using engine: 'default'
DEBUG [main] 2021-02-11 23:25:22,272 OpenSsl.java:174 - netty-tcnative using native library: BoringSSL
DEBUG [main] 2021-02-11 23:25:22,443 ResourceLeakDetector.java:129 - -Dio.netty.leakDetection.level: simple
DEBUG [main] 2021-02-11 23:25:22,443 ResourceLeakDetector.java:130 - -Dio.netty.leakDetection.targetRecords: 4
DEBUG [main] 2021-02-11 23:25:22,451 AbstractByteBuf.java:63 - -Dio.netty.buffer.checkAccessible: true
DEBUG [main] 2021-02-11 23:25:22,452 AbstractByteBuf.java:64 - -Dio.netty.buffer.checkBounds: true
DEBUG [main] 2021-02-11 23:25:22,453 ResourceLeakDetectorFactory.java:196 - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@61bcd567
DEBUG [main] 2021-02-11 23:25:22,474 InternalThreadLocalMap.java:83 - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG [main] 2021-02-11 23:25:22,474 InternalThreadLocalMap.java:86 - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG [main] 2021-02-11 23:25:22,476 PooledByteBufAllocator.java:154 - -Dio.netty.allocator.numHeapArenas: 10
DEBUG [main] 2021-02-11 23:25:22,477 PooledByteBufAllocator.java:155 - -Dio.netty.allocator.numDirectArenas: 10
DEBUG [main] 2021-02-11 23:25:22,477 PooledByteBufAllocator.java:157 - -Dio.netty.allocator.pageSize: 8192
DEBUG [main] 2021-02-11 23:25:22,477 PooledByteBufAllocator.java:162 - -Dio.netty.allocator.maxOrder: 11
DEBUG [main] 2021-02-11 23:25:22,477 PooledByteBufAllocator.java:166 - -Dio.netty.allocator.chunkSize: 16777216
DEBUG [main] 2021-02-11 23:25:22,477 PooledByteBufAllocator.java:167 - -Dio.netty.allocator.smallCacheSize: 256
DEBUG [main] 2021-02-11 23:25:22,477 PooledByteBufAllocator.java:168 - -Dio.netty.allocator.normalCacheSize: 64
DEBUG [main] 2021-02-11 23:25:22,477 PooledByteBufAllocator.java:169 - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG [main] 2021-02-11 23:25:22,477 PooledByteBufAllocator.java:170 - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG [main] 2021-02-11 23:25:22,477 PooledByteBufAllocator.java:171 - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
DEBUG [main] 2021-02-11 23:25:22,477 PooledByteBufAllocator.java:172 - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG [main] 2021-02-11 23:25:22,477 PooledByteBufAllocator.java:173 - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
DEBUG [main] 2021-02-11 23:25:22,486 ByteBufUtil.java:87 - -Dio.netty.allocator.type: pooled
DEBUG [main] 2021-02-11 23:25:22,486 ByteBufUtil.java:96 - -Dio.netty.threadLocalDirectBufferSize: 0
DEBUG [main] 2021-02-11 23:25:22,486 ByteBufUtil.java:99 - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG [main] 2021-02-11 23:25:22,489 ResourceLeakDetectorFactory.java:196 - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@4648ce9
DEBUG [main] 2021-02-11 23:25:22,495 Recycler.java:102 - -Dio.netty.recycler.maxCapacityPerThread: 4096
DEBUG [main] 2021-02-11 23:25:22,495 Recycler.java:103 - -Dio.netty.recycler.maxSharedCapacityFactor: 2
DEBUG [main] 2021-02-11 23:25:22,495 Recycler.java:104 - -Dio.netty.recycler.linkCapacity: 16
DEBUG [main] 2021-02-11 23:25:22,495 Recycler.java:105 - -Dio.netty.recycler.ratio: 8
DEBUG [main] 2021-02-11 23:25:22,495 Recycler.java:106 - -Dio.netty.recycler.delayedQueue.ratio: 8
DEBUG [main] 2021-02-11 23:25:22,517 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 => ECDHE-ECDSA-AES128-GCM-SHA256
DEBUG [main] 2021-02-11 23:25:22,517 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 => ECDHE-ECDSA-AES128-GCM-SHA256
DEBUG [main] 2021-02-11 23:25:22,517 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 => ECDHE-RSA-AES128-GCM-SHA256
DEBUG [main] 2021-02-11 23:25:22,517 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_RSA_WITH_AES_128_GCM_SHA256 => ECDHE-RSA-AES128-GCM-SHA256
DEBUG [main] 2021-02-11 23:25:22,518 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 => ECDHE-ECDSA-AES256-GCM-SHA384
DEBUG [main] 2021-02-11 23:25:22,518 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 => ECDHE-ECDSA-AES256-GCM-SHA384
DEBUG [main] 2021-02-11 23:25:22,518 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 => ECDHE-RSA-AES256-GCM-SHA384
DEBUG [main] 2021-02-11 23:25:22,518 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_RSA_WITH_AES_256_GCM_SHA384 => ECDHE-RSA-AES256-GCM-SHA384
DEBUG [main] 2021-02-11 23:25:22,518 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 => ECDHE-ECDSA-CHACHA20-POLY1305
DEBUG [main] 2021-02-11 23:25:22,518 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 => ECDHE-ECDSA-CHACHA20-POLY1305
DEBUG [main] 2021-02-11 23:25:22,518 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 => ECDHE-RSA-CHACHA20-POLY1305
DEBUG [main] 2021-02-11 23:25:22,518 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 => ECDHE-RSA-CHACHA20-POLY1305
DEBUG [main] 2021-02-11 23:25:22,518 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_PSK_WITH_CHACHA20_POLY1305_SHA256 => ECDHE-PSK-CHACHA20-POLY1305
DEBUG [main] 2021-02-11 23:25:22,519 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_PSK_WITH_CHACHA20_POLY1305_SHA256 => ECDHE-PSK-CHACHA20-POLY1305
DEBUG [main] 2021-02-11 23:25:22,519 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA => ECDHE-ECDSA-AES128-SHA
DEBUG [main] 2021-02-11 23:25:22,519 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_ECDSA_WITH_AES_128_CBC_SHA => ECDHE-ECDSA-AES128-SHA
DEBUG [main] 2021-02-11 23:25:22,519 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA => ECDHE-RSA-AES128-SHA
DEBUG [main] 2021-02-11 23:25:22,519 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_RSA_WITH_AES_128_CBC_SHA => ECDHE-RSA-AES128-SHA
DEBUG [main] 2021-02-11 23:25:22,519 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA => ECDHE-PSK-AES128-CBC-SHA
DEBUG [main] 2021-02-11 23:25:22,519 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_PSK_WITH_AES_128_CBC_SHA => ECDHE-PSK-AES128-CBC-SHA
DEBUG [main] 2021-02-11 23:25:22,519 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA => ECDHE-ECDSA-AES256-SHA
DEBUG [main] 2021-02-11 23:25:22,519 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_ECDSA_WITH_AES_256_CBC_SHA => ECDHE-ECDSA-AES256-SHA
DEBUG [main] 2021-02-11 23:25:22,520 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA => ECDHE-RSA-AES256-SHA
DEBUG [main] 2021-02-11 23:25:22,520 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_RSA_WITH_AES_256_CBC_SHA => ECDHE-RSA-AES256-SHA
DEBUG [main] 2021-02-11 23:25:22,520 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA => ECDHE-PSK-AES256-CBC-SHA
DEBUG [main] 2021-02-11 23:25:22,520 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_ECDHE_PSK_WITH_AES_256_CBC_SHA => ECDHE-PSK-AES256-CBC-SHA
DEBUG [main] 2021-02-11 23:25:22,520 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_RSA_WITH_AES_128_GCM_SHA256 => AES128-GCM-SHA256
DEBUG [main] 2021-02-11 23:25:22,520 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_RSA_WITH_AES_128_GCM_SHA256 => AES128-GCM-SHA256
DEBUG [main] 2021-02-11 23:25:22,520 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_RSA_WITH_AES_256_GCM_SHA384 => AES256-GCM-SHA384
DEBUG [main] 2021-02-11 23:25:22,520 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_RSA_WITH_AES_256_GCM_SHA384 => AES256-GCM-SHA384
DEBUG [main] 2021-02-11 23:25:22,520 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_RSA_WITH_AES_128_CBC_SHA => AES128-SHA
DEBUG [main] 2021-02-11 23:25:22,521 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_RSA_WITH_AES_128_CBC_SHA => AES128-SHA
DEBUG [main] 2021-02-11 23:25:22,521 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_PSK_WITH_AES_128_CBC_SHA => PSK-AES128-CBC-SHA
DEBUG [main] 2021-02-11 23:25:22,521 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_PSK_WITH_AES_128_CBC_SHA => PSK-AES128-CBC-SHA
DEBUG [main] 2021-02-11 23:25:22,521 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_RSA_WITH_AES_256_CBC_SHA => AES256-SHA
DEBUG [main] 2021-02-11 23:25:22,521 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_RSA_WITH_AES_256_CBC_SHA => AES256-SHA
DEBUG [main] 2021-02-11 23:25:22,521 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_PSK_WITH_AES_256_CBC_SHA => PSK-AES256-CBC-SHA
DEBUG [main] 2021-02-11 23:25:22,521 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_PSK_WITH_AES_256_CBC_SHA => PSK-AES256-CBC-SHA
DEBUG [main] 2021-02-11 23:25:22,521 CipherSuiteConverter.java:330 - Cipher suite mapping: TLS_RSA_WITH_3DES_EDE_CBC_SHA => DES-CBC3-SHA
DEBUG [main] 2021-02-11 23:25:22,521 CipherSuiteConverter.java:331 - Cipher suite mapping: SSL_RSA_WITH_3DES_EDE_CBC_SHA => DES-CBC3-SHA
DEBUG [main] 2021-02-11 23:25:22,522 OpenSsl.java:369 - Supported protocols (OpenSSL): [SSLv2Hello, TLSv1, TLSv1.1, TLSv1.2, TLSv1.3] 
DEBUG [main] 2021-02-11 23:25:22,522 OpenSsl.java:370 - Default cipher suites (OpenSSL): [TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_256_CBC_SHA, TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384, TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384]
INFO  [main] 2021-02-11 23:25:22,682 Config.java:687 - Node configuration:[allocate_tokens_for_keyspace=null; allocate_tokens_for_local_replication_factor=null; audit_logging_options=AuditLogOptions{enabled=false, logger='BinAuditLogger{}', included_keyspaces='', excluded_keyspaces='system,system_schema,system_virtual_schema', included_categories='', excluded_categories='', included_users='', excluded_users='', audit_logs_dir='./audit/', archive_command='', roll_cycle='HOURLY', block=true, max_queue_weight=268435456, max_log_size=17179869184}; authenticator=null; authorizer=null; auto_bootstrap=true; auto_optimise_full_repair_streams=false; auto_optimise_inc_repair_streams=false; auto_optimise_preview_repair_streams=false; auto_snapshot=true; autocompaction_on_startup_enabled=true; automatic_sstable_upgrade=false; back_pressure_enabled=false; back_pressure_strategy=null; batch_size_fail_threshold_in_kb=50; batch_size_warn_threshold_in_kb=5; batchlog_replay_throttle_in_kb=1024; block_for_peers_in_remote_dcs=false; block_for_peers_timeout_in_secs=10; broadcast_address=null; broadcast_rpc_address=null; buffer_pool_use_heap_if_exhausted=false; cas_contention_timeout_in_ms=1000; cdc_enabled=false; cdc_free_space_check_interval_ms=250; cdc_raw_directory=build/test/cassandra/cdc_raw:176; cdc_total_space_in_mb=0; check_for_duplicate_rows_during_compaction=true; check_for_duplicate_rows_during_reads=true; client_encryption_options=<REDACTED>; cluster_name=Test Cluster; column_index_cache_size_in_kb=2; column_index_size_in_kb=4; commit_failure_policy=stop; commitlog_compression=null; commitlog_directory=build/test/cassandra/commitlog:176; commitlog_max_compression_buffers_in_pool=3; commitlog_periodic_queue_size=-1; commitlog_segment_size_in_mb=5; commitlog_sync=batch; commitlog_sync_batch_window_in_ms=1.0; commitlog_sync_group_window_in_ms=NaN; commitlog_sync_period_in_ms=0; commitlog_total_space_in_mb=null; compaction_large_partition_warning_threshold_mb=100; compaction_throughput_mb_per_sec=0; concurrent_compactors=4; concurrent_counter_writes=32; concurrent_materialized_view_builders=1; concurrent_materialized_view_writes=32; concurrent_reads=32; concurrent_replicates=null; concurrent_validations=0; concurrent_writes=32; corrupted_tombstone_strategy=exception; counter_cache_keys_to_save=2147483647; counter_cache_save_period=7200; counter_cache_size_in_mb=null; counter_write_request_timeout_in_ms=5000; credentials_cache_max_entries=1000; credentials_update_interval_in_ms=-1; credentials_validity_in_ms=2000; cross_node_timeout=true; data_file_directories=[Ljava.lang.String;@21a5fd96; diagnostic_events_enabled=false; disk_access_mode=mmap; disk_failure_policy=ignore; disk_optimization_estimate_percentile=0.95; disk_optimization_page_cross_chance=0.1; disk_optimization_strategy=ssd; dynamic_snitch=true; dynamic_snitch_badness_threshold=1.0; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; enable_materialized_views=true; enable_sasi_indexes=true; enable_scripted_user_defined_functions=true; enable_transient_replication=false; enable_user_defined_functions=true; enable_user_defined_functions_threads=true; endpoint_snitch=org.apache.cassandra.locator.SimpleSnitch; file_cache_enabled=true; file_cache_round_up=null; file_cache_size_in_mb=null; flush_compression=fast; full_query_logging_options=FullQueryLoggerOptions{log_dir='', archive_command='', roll_cycle='HOURLY', block=true, max_queue_weight=268435456, max_log_size=17179869184}; gc_log_threshold_in_ms=200; gc_warn_threshold_in_ms=1000; hinted_handoff_disabled_datacenters=[]; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_compression=null; hints_directory=build/test/cassandra/hints:176; hints_flush_period_in_ms=10000; ideal_consistency_level=null; incremental_backups=true; index_summary_capacity_in_mb=null; index_summary_resize_interval_in_minutes=60; initial_range_tombstone_list_allocation_size=1; initial_token=null; inter_dc_stream_throughput_outbound_megabits_per_sec=200; inter_dc_tcp_nodelay=true; internode_application_receive_queue_capacity_in_bytes=4194304; internode_application_receive_queue_reserve_endpoint_capacity_in_bytes=134217728; internode_application_receive_queue_reserve_global_capacity_in_bytes=536870912; internode_application_send_queue_capacity_in_bytes=4194304; internode_application_send_queue_reserve_endpoint_capacity_in_bytes=134217728; internode_application_send_queue_reserve_global_capacity_in_bytes=536870912; internode_authenticator=null; internode_compression=none; internode_max_message_size_in_bytes=null; internode_socket_receive_buffer_size_in_bytes=0; internode_socket_send_buffer_size_in_bytes=0; internode_streaming_tcp_user_timeout_in_ms=300000; internode_tcp_connect_timeout_in_ms=2000; internode_tcp_user_timeout_in_ms=30000; key_cache_keys_to_save=2147483647; key_cache_migrate_during_compaction=true; key_cache_save_period=14400; key_cache_size_in_mb=null; keyspace_count_warn_threshold=40; listen_address=127.0.0.1; listen_interface=null; listen_interface_prefer_ipv6=false; listen_on_broadcast_address=false; local_system_data_file_directory=null; max_concurrent_automatic_sstable_upgrades=1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; max_hints_file_size_in_mb=128; max_mutation_size_in_kb=null; max_streaming_retries=3; max_value_size_in_mb=256; memtable_allocation_type=offheap_objects; memtable_cleanup_threshold=null; memtable_flush_writers=0; memtable_heap_space_in_mb=null; memtable_offheap_space_in_mb=null; min_free_space_per_drive_in_mb=50; native_transport_allow_older_protocols=true; native_transport_flush_in_batches_legacy=false; native_transport_idle_timeout_in_ms=0; native_transport_max_concurrent_connections=-1; native_transport_max_concurrent_connections_per_ip=-1; native_transport_max_concurrent_requests_in_bytes=-1; native_transport_max_concurrent_requests_in_bytes_per_ip=-1; native_transport_max_frame_size_in_mb=256; native_transport_max_negotiable_protocol_version=null; native_transport_max_threads=128; native_transport_port=9218; native_transport_port_ssl=null; native_transport_receive_queue_capacity_in_bytes=1048576; network_authorizer=null; networking_cache_size_in_mb=null; num_tokens=null; otc_coalescing_enough_coalesced_messages=8; otc_coalescing_strategy=DISABLED; otc_coalescing_window_us=200; partitioner=org.apache.cassandra.dht.ByteOrderedPartitioner; periodic_commitlog_sync_lag_block_in_ms=null; permissions_cache_max_entries=1000; permissions_update_interval_in_ms=-1; permissions_validity_in_ms=2000; phi_convict_threshold=8.0; prepared_statements_cache_size_mb=1; range_request_timeout_in_ms=10000; range_tombstone_list_growth_factor=1.5; read_request_timeout_in_ms=5000; reject_repair_compaction_threshold=2147483647; repair_command_pool_full_strategy=queue; repair_command_pool_size=0; repair_session_max_tree_depth=null; repair_session_space_in_mb=null; repaired_data_tracking_for_partition_reads_enabled=false; repaired_data_tracking_for_range_reads_enabled=false; report_unconfirmed_repaired_data_mismatches=false; request_timeout_in_ms=10000; role_manager=null; roles_cache_max_entries=1000; roles_update_interval_in_ms=-1; roles_validity_in_ms=2000; row_cache_class_name=org.apache.cassandra.cache.OHCProvider; row_cache_keys_to_save=2147483647; row_cache_save_period=0; row_cache_size_in_mb=16; rpc_address=null; rpc_interface=null; rpc_interface_prefer_ipv6=false; rpc_keepalive=true; saved_caches_directory=build/test/cassandra/saved_caches:176; seed_provider=org.apache.cassandra.locator.SimpleSeedProvider{seeds=127.0.0.1:7188}; server_encryption_options=<REDACTED>; slow_query_log_timeout_in_ms=500; snapshot_before_compaction=false; snapshot_links_per_second=0; snapshot_on_duplicate_row_detection=false; snapshot_on_repaired_data_mismatch=false; ssl_storage_port=7187; sstable_preemptive_open_interval_in_mb=50; start_native_transport=true; storage_port=7188; stream_entire_sstables=true; stream_throughput_outbound_megabits_per_sec=200000000; streaming_connections_per_host=1; streaming_keep_alive_period_in_secs=300; table_count_warn_threshold=150; tombstone_failure_threshold=100000; tombstone_warn_threshold=1000; tracetype_query_ttl=86400; tracetype_repair_ttl=604800; transparent_data_encryption_options=org.apache.cassandra.config.TransparentDataEncryptionOptions@5769e7ae; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; unlogged_batch_across_partitions_warn_threshold=10; use_offheap_merkle_trees=true; user_defined_function_fail_timeout=1500; user_defined_function_warn_timeout=500; user_function_timeout_policy=die; validation_preview_purge_head_start_in_sec=3600; windows_timer_interval=0; write_request_timeout_in_ms=2000]
DEBUG [main] 2021-02-11 23:25:22,682 DatabaseDescriptor.java:384 - Syncing log with batch mode
INFO  [main] 2021-02-11 23:25:22,682 DatabaseDescriptor.java:427 - DiskAccessMode is mmap, indexAccessMode is mmap
INFO  [main] 2021-02-11 23:25:22,682 DatabaseDescriptor.java:477 - Global memtable on-heap threshold is enabled at 247MB
INFO  [main] 2021-02-11 23:25:22,682 DatabaseDescriptor.java:481 - Global memtable off-heap threshold is enabled at 247MB
DEBUG [main] 2021-02-11 23:25:22,784 YamlConfigurationLoader.java:112 - Loading settings from file:/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/test/conf/cassandra.yaml
DEBUG [main] 2021-02-11 23:25:22,803 SSLFactory.java:384 - Initializing hot reloading SSLContext
INFO  [ScheduledTasks:1] 2021-02-11 23:25:22,831 StorageService.java:155 - Overriding RING_DELAY to 1000ms
INFO  [main] 2021-02-11 23:25:22,989 MonotonicClock.java:199 - Scheduling approximate time conversion task with an interval of 10000 milliseconds
INFO  [main] 2021-02-11 23:25:22,991 MonotonicClock.java:335 - Scheduling approximate time-check task with a precision of 2 milliseconds
INFO  [main] 2021-02-11 23:25:22,993 CommitLog.java:169 - No commitlog files found; skipping replay
INFO  [main] 2021-02-11 23:25:23,456 QueryProcessor.java:106 - Initialized prepared statement caches with 1 MB
INFO  [main] 2021-02-11 23:25:23,541 Keyspace.java:386 - Creating replication strategy system params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.LocalStrategy}}
DEBUG [main] 2021-02-11 23:25:23,553 Keyspace.java:390 - New replication settings for keyspace system - invalidating disk boundary caches
INFO  [main] 2021-02-11 23:25:23,604 ColumnFamilyStore.java:385 - Initializing system.IndexInfo
INFO  [main] 2021-02-11 23:25:23,709 ColumnFamilyStore.java:385 - Initializing system.batches
INFO  [main] 2021-02-11 23:25:23,721 ColumnFamilyStore.java:385 - Initializing system.paxos
INFO  [main] 2021-02-11 23:25:23,735 ColumnFamilyStore.java:385 - Initializing system.local
INFO  [main] 2021-02-11 23:25:23,743 ColumnFamilyStore.java:385 - Initializing system.peers_v2
INFO  [main] 2021-02-11 23:25:23,750 ColumnFamilyStore.java:385 - Initializing system.peers
INFO  [main] 2021-02-11 23:25:23,757 ColumnFamilyStore.java:385 - Initializing system.peer_events_v2
INFO  [main] 2021-02-11 23:25:23,764 ColumnFamilyStore.java:385 - Initializing system.peer_events
INFO  [main] 2021-02-11 23:25:23,770 ColumnFamilyStore.java:385 - Initializing system.compaction_history
INFO  [main] 2021-02-11 23:25:23,777 ColumnFamilyStore.java:385 - Initializing system.sstable_activity
INFO  [main] 2021-02-11 23:25:23,783 ColumnFamilyStore.java:385 - Initializing system.size_estimates
INFO  [main] 2021-02-11 23:25:23,789 ColumnFamilyStore.java:385 - Initializing system.table_estimates
INFO  [main] 2021-02-11 23:25:23,795 ColumnFamilyStore.java:385 - Initializing system.available_ranges_v2
INFO  [main] 2021-02-11 23:25:23,800 ColumnFamilyStore.java:385 - Initializing system.available_ranges
INFO  [main] 2021-02-11 23:25:23,806 ColumnFamilyStore.java:385 - Initializing system.transferred_ranges_v2
INFO  [main] 2021-02-11 23:25:23,812 ColumnFamilyStore.java:385 - Initializing system.transferred_ranges
INFO  [main] 2021-02-11 23:25:23,818 ColumnFamilyStore.java:385 - Initializing system.view_builds_in_progress
INFO  [main] 2021-02-11 23:25:23,824 ColumnFamilyStore.java:385 - Initializing system.built_views
INFO  [main] 2021-02-11 23:25:23,831 ColumnFamilyStore.java:385 - Initializing system.prepared_statements
INFO  [main] 2021-02-11 23:25:23,838 ColumnFamilyStore.java:385 - Initializing system.repairs
INFO  [COMMIT-LOG-WRITER] 2021-02-11 23:25:23,868 SyncUtil.java:95 - Skip fsync enabled due to property true and environment false
DEBUG [main] 2021-02-11 23:25:23,877 AuditLogManager.java:75 - Audit logging is disabled.
INFO  [main] 2021-02-11 23:25:23,882 MigrationManager.java:92 - Create new Keyspace: KeyspaceMetadata{name=ks, kind=REGULAR, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[ks.tbl, ks.tbl_slices], views=[], functions=[], types=[]}
INFO  [main] 2021-02-11 23:25:23,900 Keyspace.java:386 - Creating replication strategy system_schema params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.LocalStrategy}}
DEBUG [main] 2021-02-11 23:25:23,901 Keyspace.java:390 - New replication settings for keyspace system_schema - invalidating disk boundary caches
INFO  [main] 2021-02-11 23:25:23,903 ColumnFamilyStore.java:385 - Initializing system_schema.keyspaces
INFO  [main] 2021-02-11 23:25:23,910 ColumnFamilyStore.java:385 - Initializing system_schema.tables
INFO  [main] 2021-02-11 23:25:23,916 ColumnFamilyStore.java:385 - Initializing system_schema.columns
INFO  [main] 2021-02-11 23:25:23,923 ColumnFamilyStore.java:385 - Initializing system_schema.triggers
INFO  [main] 2021-02-11 23:25:23,930 ColumnFamilyStore.java:385 - Initializing system_schema.dropped_columns
INFO  [main] 2021-02-11 23:25:23,935 ColumnFamilyStore.java:385 - Initializing system_schema.views
INFO  [main] 2021-02-11 23:25:23,941 ColumnFamilyStore.java:385 - Initializing system_schema.types
INFO  [main] 2021-02-11 23:25:23,947 ColumnFamilyStore.java:385 - Initializing system_schema.functions
INFO  [main] 2021-02-11 23:25:23,952 ColumnFamilyStore.java:385 - Initializing system_schema.aggregates
INFO  [main] 2021-02-11 23:25:23,958 ColumnFamilyStore.java:385 - Initializing system_schema.indexes
INFO  [main] 2021-02-11 23:25:23,970 ColumnFamilyStore.java:857 - Enqueuing flush of columns: 2.169KiB (0%) on-heap, 1.134KiB (0%) off-heap
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:24,062 BufferPools.java:49 - Global buffer pool limit is 247.000MiB for chunk-cache and 61.000MiB for networking
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:24,095 Memtable.java:469 - Writing Memtable-columns@347123654(1.034KiB serialized bytes, 8 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:24,106 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/na-1-big-Data.db (0.379KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=2165)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:24,150 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/na_txn_flush_6a6a8ae0-6cc0-11eb-b66a-157691728e1b.log 
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:24,155 CacheService.java:100 - Initializing key cache with capacity of 24 MBs.
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:24,161 CacheService.java:122 - Initializing row cache with capacity of 16 MBs
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:24,172 Uns.java:164 - OHC using Java8 Unsafe API
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:24,172 Uns.java:193 - OHC using JNA OS native malloc/free
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:24,173 OHCacheLinkedImpl.java:136 - OHC linked instance with 32 segments and capacity of 16777216 created.
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:24,174 CacheService.java:151 - Initializing counter cache with capacity of 12 MBs
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:24,175 CacheService.java:162 - Scheduling counter cache save to every 7200 seconds (going to save all keys).
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:24,203 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/na-1-big-Data.db')] (1 sstables, 5.340KiB), biggest 5.340KiB, smallest 5.340KiB
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:24,208 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in dropped_columns
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:24,208 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in triggers
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:24,208 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in types
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:24,209 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in functions
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:24,209 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in aggregates
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:24,209 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in indexes
INFO  [main] 2021-02-11 23:25:24,210 ColumnFamilyStore.java:857 - Enqueuing flush of tables: 1.505KiB (0%) on-heap, 1.528KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:24,218 Memtable.java:469 - Writing Memtable-tables@641575466(1.372KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:24,221 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/na-1-big-Data.db (0.813KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=2165)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:24,230 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/na_txn_flush_6a8d7c30-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:24,234 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/na-1-big-Data.db')] (1 sstables, 6.846KiB), biggest 6.846KiB, smallest 6.846KiB
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:24,234 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in views
INFO  [main] 2021-02-11 23:25:24,235 ColumnFamilyStore.java:857 - Enqueuing flush of keyspaces: 0.419KiB (0%) on-heap, 0.137KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:24,242 Memtable.java:469 - Writing Memtable-keyspaces@520018471(0.146KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:24,243 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/na-1-big-Data.db (0.109KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=2165)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:24,256 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/na_txn_flush_6a9125b0-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:24,260 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/na-1-big-Data.db')] (1 sstables, 5.109KiB), biggest 5.109KiB, smallest 5.109KiB
INFO  [main] 2021-02-11 23:25:24,400 Keyspace.java:386 - Creating replication strategy ks params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}
DEBUG [main] 2021-02-11 23:25:24,400 Keyspace.java:390 - New replication settings for keyspace ks - invalidating disk boundary caches
INFO  [main] 2021-02-11 23:25:24,403 ColumnFamilyStore.java:385 - Initializing ks.tbl
INFO  [main] 2021-02-11 23:25:24,408 ColumnFamilyStore.java:385 - Initializing ks.tbl_slices
INFO  [main] 2021-02-11 23:25:24,433 ColumnFamilyStore.java:2221 - Truncating ks.tbl
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:24,434 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl
INFO 
...[truncated 96919 chars]...
:25:25,861 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/tbl-69c682b06cc011ebb66a157691728e1b/na-1-big-Data.db (0.024KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=12251)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:25,869 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/tbl-69c682b06cc011ebb66a157691728e1b/na_txn_flush_6b887e00-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:25,873 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/tbl-69c682b06cc011ebb66a157691728e1b/na-1-big-Data.db')] (1 sstables, 4.875KiB), biggest 4.875KiB, smallest 4.875KiB
INFO  [main] 2021-02-11 23:25:25,875 ColumnFamilyStore.java:2221 - Truncating ks.tbl
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:25,875 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl
INFO  [main] 2021-02-11 23:25:25,876 ColumnFamilyStore.java:2256 - Truncating ks.tbl with truncatedAt=1613085925876
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:25,876 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl
INFO  [main] 2021-02-11 23:25:25,878 ColumnFamilyStore.java:2705 - Truncation is dropping 1 sstables and keeping 0 due to sstable.maxDataAge > truncatedAt
INFO  [main] 2021-02-11 23:25:25,883 ColumnFamilyStore.java:857 - Enqueuing flush of local: 0.411KiB (0%) on-heap, 0.072KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:25,896 Memtable.java:469 - Writing Memtable-local@1002106852(0.091KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:25,897 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-27-big-Data.db (0.063KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=12362)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:25,905 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6b8cc3c0-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:25,909 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-27-big-Data.db')] (1 sstables, 4.975KiB), biggest 4.975KiB, smallest 4.975KiB
INFO  [main] 2021-02-11 23:25:25,910 ColumnFamilyStore.java:2280 - Truncate of ks.tbl is complete
INFO  [main] 2021-02-11 23:25:25,910 ColumnFamilyStore.java:2221 - Truncating ks.tbl_slices
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:25,910 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl_slices
INFO  [main] 2021-02-11 23:25:25,910 ColumnFamilyStore.java:2256 - Truncating ks.tbl_slices with truncatedAt=1613085925910
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:25,910 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl_slices
INFO  [main] 2021-02-11 23:25:25,912 ColumnFamilyStore.java:857 - Enqueuing flush of local: 0.411KiB (0%) on-heap, 0.072KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:25,917 Memtable.java:469 - Writing Memtable-local@2042417907(0.091KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:25,918 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-28-big-Data.db (0.063KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=12473)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:25,923 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6b913090-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:25,926 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-28-big-Data.db')] (1 sstables, 4.975KiB), biggest 4.975KiB, smallest 4.975KiB
INFO  [CompactionExecutor:3] 2021-02-11 23:25:25,927 CompactionTask.java:150 - Compacting (6b935370-6cc0-11eb-b66a-157691728e1b) [/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-27-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-28-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-26-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-25-big-Data.db:level=0, ]
INFO  [main] 2021-02-11 23:25:25,928 ColumnFamilyStore.java:2280 - Truncate of ks.tbl_slices is complete
INFO  [main] 2021-02-11 23:25:25,929 ColumnFamilyStore.java:857 - Enqueuing flush of tbl_slices: 0.614KiB (0%) on-heap, 0.005KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:25,933 Memtable.java:469 - Writing Memtable-tbl_slices@1281198511(0.008KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:25,934 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/tbl_slices-69ca53406cc011ebb66a157691728e1b/na-3-big-Data.db (0.041KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=12552)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:25,940 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/tbl_slices-69ca53406cc011ebb66a157691728e1b/na_txn_flush_6b93a190-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:25,944 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/tbl_slices-69ca53406cc011ebb66a157691728e1b/na-3-big-Data.db')] (1 sstables, 4.912KiB), biggest 4.912KiB, smallest 4.912KiB
INFO  [CompactionExecutor:3] 2021-02-11 23:25:25,944 CompactionTask.java:245 - Compacted (6b935370-6cc0-11eb-b66a-157691728e1b) 4 sstables to [/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-29-big,] to level=0.  0.518KiB to 0.310KiB (~59% of original) in 16ms.  Read Throughput = 32.118KiB/s, Write Throughput = 19.210KiB/s, Row Throughput = ~2/s.  4 total partitions merged to 1.  Partition merge counts were {4:1, }
INFO  [main] 2021-02-11 23:25:25,946 ColumnFamilyStore.java:2221 - Truncating ks.tbl
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:25,946 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl
INFO  [main] 2021-02-11 23:25:25,946 ColumnFamilyStore.java:2256 - Truncating ks.tbl with truncatedAt=1613085925946
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:25,946 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl
INFO  [main] 2021-02-11 23:25:25,948 ColumnFamilyStore.java:857 - Enqueuing flush of local: 0.411KiB (0%) on-heap, 0.072KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:25,952 Memtable.java:469 - Writing Memtable-local@438700757(0.091KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:25,953 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-30-big-Data.db (0.063KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=12877)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:25,958 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6b9687c0-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:25,961 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-30-big-Data.db')] (1 sstables, 4.975KiB), biggest 4.975KiB, smallest 4.975KiB
INFO  [main] 2021-02-11 23:25:25,962 ColumnFamilyStore.java:2280 - Truncate of ks.tbl is complete
INFO  [main] 2021-02-11 23:25:25,962 ColumnFamilyStore.java:2221 - Truncating ks.tbl_slices
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:25,962 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl_slices
INFO  [main] 2021-02-11 23:25:25,963 ColumnFamilyStore.java:2256 - Truncating ks.tbl_slices with truncatedAt=1613085925962
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:25,963 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl_slices
INFO  [main] 2021-02-11 23:25:25,965 ColumnFamilyStore.java:2705 - Truncation is dropping 1 sstables and keeping 0 due to sstable.maxDataAge > truncatedAt
INFO  [main] 2021-02-11 23:25:25,970 ColumnFamilyStore.java:857 - Enqueuing flush of local: 0.411KiB (0%) on-heap, 0.072KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:25,976 Memtable.java:469 - Writing Memtable-local@920388720(0.091KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:25,977 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-31-big-Data.db (0.063KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=12988)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:25,985 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6b99e320-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:25,988 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-31-big-Data.db')] (1 sstables, 4.975KiB), biggest 4.975KiB, smallest 4.975KiB
INFO  [main] 2021-02-11 23:25:25,990 ColumnFamilyStore.java:2280 - Truncate of ks.tbl_slices is complete
INFO  [MigrationStage:1] 2021-02-11 23:25:25,998 ColumnFamilyStore.java:857 - Enqueuing flush of columns: 1.216KiB (0%) on-heap, 0.637KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,003 Memtable.java:469 - Writing Memtable-columns@1439315649(0.588KiB serialized bytes, 4 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,004 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/na-6-big-Data.db (0.265KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=14250)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:26,013 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/na_txn_flush_6b9e28e0-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:26,016 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/na-6-big-Data.db')] (1 sstables, 5.310KiB), biggest 5.310KiB, smallest 5.310KiB
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,017 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in dropped_columns
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,017 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in triggers
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,017 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in types
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,017 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in functions
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,017 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in aggregates
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,017 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in indexes
INFO  [MigrationStage:1] 2021-02-11 23:25:26,018 ColumnFamilyStore.java:857 - Enqueuing flush of tables: 0.880KiB (0%) on-heap, 0.784KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,024 Memtable.java:469 - Writing Memtable-tables@447275433(0.707KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,025 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/na-6-big-Data.db (0.432KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=14250)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:26,032 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/na_txn_flush_6ba13620-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:26,035 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/na-6-big-Data.db')] (1 sstables, 6.864KiB), biggest 6.864KiB, smallest 6.864KiB
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,036 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in views
INFO  [MigrationStage:1] 2021-02-11 23:25:26,036 ColumnFamilyStore.java:857 - Enqueuing flush of keyspaces: 0.419KiB (0%) on-heap, 0.137KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,041 Memtable.java:469 - Writing Memtable-keyspaces@99069000(0.146KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,042 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/na-6-big-Data.db (0.109KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=14250)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:26,054 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/na_txn_flush_6ba3f540-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:26,056 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/na-6-big-Data.db')] (1 sstables, 5.109KiB), biggest 5.109KiB, smallest 5.109KiB
INFO  [MigrationStage:1] 2021-02-11 23:25:26,057 Keyspace.java:386 - Creating replication strategy ks params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}
INFO  [MigrationStage:1] 2021-02-11 23:25:26,058 ColumnFamilyStore.java:385 - Initializing ks.partition_range_deletion
INFO  [MigrationStage:1] 2021-02-11 23:25:26,061 ViewManager.java:125 - Not submitting build tasks for views in keyspace ks as storage service is not initialized
INFO  [main] 2021-02-11 23:25:26,077 ColumnFamilyStore.java:2221 - Truncating ks.partition_range_deletion
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,077 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in partition_range_deletion
INFO  [main] 2021-02-11 23:25:26,077 ColumnFamilyStore.java:2256 - Truncating ks.partition_range_deletion with truncatedAt=1613085926077
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,078 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in partition_range_deletion
INFO  [main] 2021-02-11 23:25:26,082 ColumnFamilyStore.java:857 - Enqueuing flush of local: 0.466KiB (0%) on-heap, 0.148KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,089 Memtable.java:469 - Writing Memtable-local@1979840727(0.122KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,089 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-32-big-Data.db (0.081KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=14451)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:26,099 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6baafa20-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:26,102 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-32-big-Data.db')] (1 sstables, 5.048KiB), biggest 5.048KiB, smallest 5.048KiB
INFO  [CompactionExecutor:2] 2021-02-11 23:25:26,102 CompactionTask.java:150 - Compacting (6bae0760-6cc0-11eb-b66a-157691728e1b) [/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-32-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-31-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-30-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-29-big-Data.db:level=0, ]
INFO  [main] 2021-02-11 23:25:26,105 ColumnFamilyStore.java:2280 - Truncate of ks.partition_range_deletion is complete
INFO  [main] 2021-02-11 23:25:26,111 ColumnFamilyStore.java:2221 - Truncating ks.partition_range_deletion
INFO  [main] 2021-02-11 23:25:26,111 ColumnFamilyStore.java:857 - Enqueuing flush of partition_range_deletion: 0.810KiB (0%) on-heap, 0.049KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,116 Memtable.java:469 - Writing Memtable-partition_range_deletion@441699661(0.056KiB serialized bytes, 3 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,118 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-1-big-Data.db (0.036KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=14670)
INFO  [CompactionExecutor:2] 2021-02-11 23:25:26,119 CompactionTask.java:245 - Compacted (6bae0760-6cc0-11eb-b66a-157691728e1b) 4 sstables to [/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-33-big,] to level=0.  0.536KiB to 0.329KiB (~61% of original) in 15ms.  Read Throughput = 34.106KiB/s, Write Throughput = 20.936KiB/s, Row Throughput = ~2/s.  4 total partitions merged to 1.  Partition merge counts were {4:1, }
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:26,126 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na_txn_flush_6baf8e00-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:26,129 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-1-big-Data.db')] (1 sstables, 4.978KiB), biggest 4.978KiB, smallest 4.978KiB
INFO  [main] 2021-02-11 23:25:26,129 ColumnFamilyStore.java:2256 - Truncating ks.partition_range_deletion with truncatedAt=1613085926129
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,129 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in partition_range_deletion
INFO  [main] 2021-02-11 23:25:26,132 ColumnFamilyStore.java:2705 - Truncation is dropping 1 sstables and keeping 0 due to sstable.maxDataAge > truncatedAt
INFO  [main] 2021-02-11 23:25:26,138 ColumnFamilyStore.java:857 - Enqueuing flush of local: 0.411KiB (0%) on-heap, 0.072KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,143 Memtable.java:469 - Writing Memtable-local@1446053705(0.091KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,143 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-34-big-Data.db (0.063KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=14995)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:26,151 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6bb385a0-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:26,154 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-34-big-Data.db')] (1 sstables, 4.974KiB), biggest 4.974KiB, smallest 4.974KiB
INFO  [main] 2021-02-11 23:25:26,156 ColumnFamilyStore.java:2280 - Truncate of ks.partition_range_deletion is complete
INFO  [main] 2021-02-11 23:25:26,158 ColumnFamilyStore.java:857 - Enqueuing flush of partition_range_deletion: 0.638KiB (0%) on-heap, 0.008KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,163 Memtable.java:469 - Writing Memtable-partition_range_deletion@814287984(0.008KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,164 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-2-big-Data.db (0.019KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=15139)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:26,172 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na_txn_flush_6bb6b9f0-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:26,175 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-2-big-Data.db')] (1 sstables, 4.898KiB), biggest 4.898KiB, smallest 4.898KiB
INFO  [main] 2021-02-11 23:25:26,177 ColumnFamilyStore.java:857 - Enqueuing flush of partition_range_deletion: 0.388KiB (0%) on-heap, 0.049KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,181 Memtable.java:469 - Writing Memtable-partition_range_deletion@1599099(0.056KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,182 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-3-big-Data.db (0.036KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=15214)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:26,190 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na_txn_flush_6bb97910-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:26,192 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-3-big-Data.db')] (1 sstables, 4.958KiB), biggest 4.958KiB, smallest 4.958KiB
INFO  [CompactionExecutor:1] 2021-02-11 23:25:26,194 CompactionTask.java:150 - Compacting (6bbbea10-6cc0-11eb-b66a-157691728e1b) [/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-3-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-2-big-Data.db:level=0, ]
INFO  [CompactionExecutor:1] 2021-02-11 23:25:26,209 CompactionTask.java:245 - Compacted (6bbbea10-6cc0-11eb-b66a-157691728e1b) 2 sstables to [/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-4-big,] to level=0.  0.068KiB to 0.040KiB (~58% of original) in 14ms.  Read Throughput = 4.824KiB/s, Write Throughput = 2.825KiB/s, Row Throughput = ~2/s.  2 total partitions merged to 1.  Partition merge counts were {2:1, }
INFO  [main] 2021-02-11 23:25:26,211 ColumnFamilyStore.java:2221 - Truncating ks.partition_range_deletion
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,212 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in partition_range_deletion
INFO  [main] 2021-02-11 23:25:26,212 ColumnFamilyStore.java:2256 - Truncating ks.partition_range_deletion with truncatedAt=1613085926212
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,212 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in partition_range_deletion
INFO  [main] 2021-02-11 23:25:26,214 ColumnFamilyStore.java:2705 - Truncation is dropping 1 sstables and keeping 0 due to sstable.maxDataAge > truncatedAt
INFO  [main] 2021-02-11 23:25:26,220 ColumnFamilyStore.java:857 - Enqueuing flush of local: 0.411KiB (0%) on-heap, 0.072KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,224 Memtable.java:469 - Writing Memtable-local@888227998(0.091KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,225 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-35-big-Data.db (0.063KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=15554)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:26,232 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6bc008c0-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:26,235 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-35-big-Data.db')] (1 sstables, 4.975KiB), biggest 4.975KiB, smallest 4.975KiB
INFO  [main] 2021-02-11 23:25:26,237 ColumnFamilyStore.java:2280 - Truncate of ks.partition_range_deletion is complete
INFO  [main] 2021-02-11 23:25:26,238 ColumnFamilyStore.java:857 - Enqueuing flush of partition_range_deletion: 0.263KiB (0%) on-heap, 0.008KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,243 Memtable.java:469 - Writing Memtable-partition_range_deletion@1566599800(0.008KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,244 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-5-big-Data.db (0.019KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=15616)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:26,254 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na_txn_flush_6bc2eef0-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:26,259 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-5-big-Data.db')] (1 sstables, 4.898KiB), biggest 4.898KiB, smallest 4.898KiB
INFO  [main] 2021-02-11 23:25:26,261 ColumnFamilyStore.java:857 - Enqueuing flush of partition_range_deletion: 0.614KiB (0%) on-heap, 0.008KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,267 Memtable.java:469 - Writing Memtable-partition_range_deletion@206317476(0.008KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,267 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-6-big-Data.db (0.044KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=15698)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:26,276 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na_txn_flush_6bc67160-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:26,280 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-6-big-Data.db')] (1 sstables, 4.928KiB), biggest 4.928KiB, smallest 4.928KiB
INFO  [main] 2021-02-11 23:25:26,282 ColumnFamilyStore.java:857 - Enqueuing flush of partition_range_deletion: 0.388KiB (0%) on-heap, 0.049KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,287 Memtable.java:469 - Writing Memtable-partition_range_deletion@610203203(0.056KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,287 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-7-big-Data.db (0.036KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=15773)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:26,297 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na_txn_flush_6bc97ea0-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:26,299 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-7-big-Data.db')] (1 sstables, 4.958KiB), biggest 4.958KiB, smallest 4.958KiB
INFO  [CompactionExecutor:2] 2021-02-11 23:25:26,301 CompactionTask.java:150 - Compacting (6bcc3dc0-6cc0-11eb-b66a-157691728e1b) [/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-5-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-6-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-7-big-Data.db:level=0, ]
INFO  [CompactionExecutor:2] 2021-02-11 23:25:26,319 CompactionTask.java:245 - Compacted (6bcc3dc0-6cc0-11eb-b66a-157691728e1b) 3 sstables to [/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/partition_range_deletion-6b9d17706cc011ebb66a157691728e1b/na-8-big,] to level=0.  0.113KiB to 0.040KiB (~35% of original) in 17ms.  Read Throughput = 6.643KiB/s, Write Throughput = 2.348KiB/s, Row Throughput = ~2/s.  3 total partitions merged to 1.  Partition merge counts were {3:1, }
INFO  [main] 2021-02-11 23:25:26,323 ColumnFamilyStore.java:2221 - Truncating ks.tbl
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,323 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl
INFO  [main] 2021-02-11 23:25:26,324 ColumnFamilyStore.java:2256 - Truncating ks.tbl with truncatedAt=1613085926323
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,324 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl
INFO  [main] 2021-02-11 23:25:26,326 ColumnFamilyStore.java:857 - Enqueuing flush of local: 0.411KiB (0%) on-heap, 0.072KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,331 Memtable.java:469 - Writing Memtable-local@141671109(0.091KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,332 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-36-big-Data.db (0.063KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=16113)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:26,340 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6bd03560-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:26,343 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-36-big-Data.db')] (1 sstables, 4.975KiB), biggest 4.975KiB, smallest 4.975KiB
INFO  [CompactionExecutor:3] 2021-02-11 23:25:26,344 CompactionTask.java:150 - Compacting (6bd2cd70-6cc0-11eb-b66a-157691728e1b) [/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-34-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-33-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-35-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-36-big-Data.db:level=0, ]
INFO  [main] 2021-02-11 23:25:26,344 ColumnFamilyStore.java:2280 - Truncate of ks.tbl is complete
INFO  [main] 2021-02-11 23:25:26,344 ColumnFamilyStore.java:2221 - Truncating ks.tbl_slices
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,345 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl_slices
INFO  [main] 2021-02-11 23:25:26,345 ColumnFamilyStore.java:2256 - Truncating ks.tbl_slices with truncatedAt=1613085926345
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,345 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl_slices
INFO  [main] 2021-02-11 23:25:26,347 ColumnFamilyStore.java:857 - Enqueuing flush of local: 0.411KiB (0%) on-heap, 0.072KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,353 Memtable.java:469 - Writing Memtable-local@2047588046(0.091KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,354 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-37-big-Data.db (0.063KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=16224)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:26,363 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6bd390c0-6cc0-11eb-b66a-157691728e1b.log 
INFO  [CompactionExecutor:3] 2021-02-11 23:25:26,366 CompactionTask.java:245 - Compacted (6bd2cd70-6cc0-11eb-b66a-157691728e1b) 4 sstables to [/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-38-big,] to level=0.  0.537KiB to 0.330KiB (~61% of original) in 20ms.  Read Throughput = 26.729KiB/s, Write Throughput = 16.427KiB/s, Row Throughput = ~2/s.  4 total partitions merged to 1.  Partition merge counts were {4:1, }
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:26,366 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-37-big-Data.db')] (1 sstables, 4.974KiB), biggest 4.974KiB, smallest 4.974KiB
INFO  [main] 2021-02-11 23:25:26,368 ColumnFamilyStore.java:2280 - Truncate of ks.tbl_slices is complete
INFO  [main] 2021-02-11 23:25:26,371 ColumnFamilyStore.java:2221 - Truncating ks.tbl
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,372 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl
INFO  [main] 2021-02-11 23:25:26,372 ColumnFamilyStore.java:2256 - Truncating ks.tbl with truncatedAt=1613085926372
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,372 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl
INFO  [main] 2021-02-11 23:25:26,374 ColumnFamilyStore.java:857 - Enqueuing flush of local: 0.411KiB (0%) on-heap, 0.072KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,379 Memtable.java:469 - Writing Memtable-local@1893981495(0.091KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,380 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-39-big-Data.db (0.063KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=16628)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:26,386 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6bd7af70-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:26,389 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-39-big-Data.db')] (1 sstables, 4.975KiB), biggest 4.975KiB, smallest 4.975KiB
INFO  [main] 2021-02-11 23:25:26,391 ColumnFamilyStore.java:2280 - Truncate of ks.tbl is complete
INFO  [main] 2021-02-11 23:25:26,391 ColumnFamilyStore.java:2221 - Truncating ks.tbl_slices
INFO  [main] 2021-02-11 23:25:26,391 ColumnFamilyStore.java:857 - Enqueuing flush of tbl_slices: 0.614KiB (0%) on-heap, 0.005KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,402 Memtable.java:469 - Writing Memtable-tbl_slices@971189322(0.008KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:2] 2021-02-11 23:25:26,403 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/tbl_slices-69ca53406cc011ebb66a157691728e1b/na-4-big-Data.db (0.041KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=16628)
INFO  [MemtableFlushWriter:2] 2021-02-11 23:25:26,408 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/tbl_slices-69ca53406cc011ebb66a157691728e1b/na_txn_flush_6bda2070-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:2] 2021-02-11 23:25:26,411 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/ks/tbl_slices-69ca53406cc011ebb66a157691728e1b/na-4-big-Data.db')] (1 sstables, 4.912KiB), biggest 4.912KiB, smallest 4.912KiB
INFO  [main] 2021-02-11 23:25:26,411 ColumnFamilyStore.java:2256 - Truncating ks.tbl_slices with truncatedAt=1613085926411
DEBUG [MemtablePostFlush:1] 2021-02-11 23:25:26,411 ColumnFamilyStore.java:912 - forceFlush requested but everything is clean in tbl_slices
INFO  [main] 2021-02-11 23:25:26,414 ColumnFamilyStore.java:2705 - Truncation is dropping 1 sstables and keeping 0 due to sstable.maxDataAge > truncatedAt
INFO  [main] 2021-02-11 23:25:26,418 ColumnFamilyStore.java:857 - Enqueuing flush of local: 0.411KiB (0%) on-heap, 0.072KiB (0%) off-heap
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,424 Memtable.java:469 - Writing Memtable-local@1323884045(0.091KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
INFO  [PerDiskMemtableFlushWriter_0:1] 2021-02-11 23:25:26,424 Memtable.java:498 - Completed flushing /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-40-big-Data.db (0.063KiB) for commitlog position CommitLogPosition(segmentId=1613085922972, position=16739)
INFO  [MemtableFlushWriter:1] 2021-02-11 23:25:26,437 LogTransaction.java:240 - Unfinished transaction log, deleting /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na_txn_flush_6bde6630-6cc0-11eb-b66a-157691728e1b.log 
DEBUG [MemtableFlushWriter:1] 2021-02-11 23:25:26,439 ColumnFamilyStore.java:1176 - Flushed to [BigTableReader(path='/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-40-big-Data.db')] (1 sstables, 4.975KiB), biggest 4.975KiB, smallest 4.975KiB
INFO  [CompactionExecutor:1] 2021-02-11 23:25:26,441 CompactionTask.java:150 - Compacting (6be19a80-6cc0-11eb-b66a-157691728e1b) [/home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-39-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-40-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-38-big-Data.db:level=0, /home/jenkins/jenkins-slave/workspace/Cassandra-devbranch-test/jdk/jdk_11_latest/label/cassandra/build/test/cassandra/data:176/system/local-7ad54392bcdd35a684174e047860b377/na-37-big-Data.db:level=0, ]
INFO  [main] 2021-02-11 23:25:26,441 ColumnFamilyStore.java:2280 - Truncate of ks.tbl_slices is complete

{code}",,bereng,blerer,dcapwell,e.dimitrova,,,,,,,,,,,,"blerer opened a new pull request #910:
URL: https://github.com/apache/cassandra/pull/910


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Feb/21 17:04;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #910:
URL: https://github.com/apache/cassandra/pull/910#discussion_r580545673



##########
File path: test/unit/org/apache/cassandra/db/SinglePartitionSliceCommandTest.java
##########
@@ -343,10 +343,18 @@ public void testPartitionDeletionRowDeletionTie()
         BiFunction<Boolean, Boolean, List<Unfiltered>> tester = (flush, multiSSTable)->
         {
             cfs.truncateBlocking();
-            QueryProcessor.executeOnceInternal(""DELETE FROM ks.partition_row_deletion USING TIMESTAMP 10 WHERE k=1"");
+
+            final long timestamp = System.currentTimeMillis() * 1000;

Review comment:
       I believe this is actually `FBUtiliies.timestampMicros()`




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Feb/21 01:12;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #910:
URL: https://github.com/apache/cassandra/pull/910#discussion_r581454422



##########
File path: test/unit/org/apache/cassandra/db/SinglePartitionSliceCommandTest.java
##########
@@ -343,10 +343,18 @@ public void testPartitionDeletionRowDeletionTie()
         BiFunction<Boolean, Boolean, List<Unfiltered>> tester = (flush, multiSSTable)->
         {
             cfs.truncateBlocking();
-            QueryProcessor.executeOnceInternal(""DELETE FROM ks.partition_row_deletion USING TIMESTAMP 10 WHERE k=1"");
+
+            final long timestamp = System.currentTimeMillis() * 1000;

Review comment:
       I'll change it on commit, thanks. Hope you don't mind, I decided to act ask for pardon, not for permission in this case :-) 




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Feb/21 23:05;githubbot;600","smiklosovic closed pull request #910:
URL: https://github.com/apache/cassandra/pull/910


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:28;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,2400,,,0,2400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,blerer,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Feb 23 13:56:02 UTC 2021,,,,,,,All,,,,"0|z0nmzs:",9223372036854775807,,,,bereng,e.dimitrova,,,Normal,,,,https://github.com/apache/cassandra/commit/0b60c8f37694d44482768ebc327989f7a42c8c08,,,,,,,,,I ran the test within a loop for some time and the problem does not appear anymore (It use to break in less than 15 iterations),,,,,"19/Feb/21 16:46;blerer;The problem is a timestamp issue. If the {{localDeletion}} of the deleted partition is the same as the {{localDeletion}} time of the deleted row they will be merged together and will not appear in the result that will be {{[Row[info=[ts=11] ]: c=1 | [v=1 ts=11]]}}. If the {{localDeletion}} times are not the same (which happen when the queries will not be executed within the same second) the deletions will not be merged and the result will show the row deletion.;;;","19/Feb/21 17:08;blerer;[PR|https://github.com/apache/cassandra/pull/910] and CI results: [j8|https://app.circleci.com/pipelines/github/blerer/cassandra/108/workflows/993f130f-97e2-4597-92ee-c00ac1644471] and [j11|https://app.circleci.com/pipelines/github/blerer/cassandra/108/workflows/5e933725-78e0-4658-b9b8-5afa22a0558a].

I checked 3.11 and the test does not exist there. ;;;","23/Feb/21 01:14;e.dimitrova;Indeed, the test was non-deterministic. I slowed down my machine significantly and I was able to immediately reproduce the described problem. Now the test is deterministic and I also looped the test, thank you!  +1, I suggested only the usage of one of the utility functions. I believe this could be done on commit if [~Bereng] doesn't have anything else that he wants to be addressed.;;;","23/Feb/21 07:16;bereng;I don't have any comments. LGTM. I am just struggling to find where the operations within the same second get/don't get merged together. [~e.dimitrova] pointed me [here|https://github.com/apache/cassandra/blob/5ed5e84613ef0e9664a774493db7d2604e3596e0/src/java/org/apache/cassandra/db/rows/RowAndDeletionMergeIterator.java#L179] but I still can't see where the 'seconds' resolution come into play...;;;","23/Feb/21 10:37;bereng;Ok I _think_ this might be bc {{localDeletionTime}} has a resolution of seconds. Hence {{AtomicBTreePartition.addAllWithSizeDeltaInternal() -> add() -> add() -> superseeds()}} would merge/not merge on a seconds resolution.;;;","23/Feb/21 13:56;e.dimitrova;[~Bereng] when I pointed you there I was responding to a different question but I believe we cleared the topic on Slack. Yes, the merge happens on a per second resolution. Please let me know if there are any additional questions I can try to help with.

Patch committed  [here|https://github.com/apache/cassandra/commit/0b60c8f37694d44482768ebc327989f7a42c8c08]. Thank you!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Snapshot_test.py DTests failing,CASSANDRA-16441,13358243,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,e.dimitrova,e.dimitrova,11/Feb/21 22:01,25/Feb/21 14:51,13/Jul/23 08:40,25/Feb/21 14:28,4.0,4.0-rc1,,,,,,Test/dtest/python,,,,0,,,"[https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/623/workflows/1c89bd58-bcd1-45dc-b923-3aba245a78a6/jobs/3451]

These failures are also observed for other patches in Jenkins dev (weird but they are not seen failing in the latest builds and they are failing with completely unrelated different patches...)

[https://jenkins-cm4.apache.org/job/Cassandra-devbranch/375/#showFailuresLink]

[https://jenkins-cm4.apache.org/job/Cassandra-devbranch/368/]

Jenkins dev history for one of the tests:

https://jenkins-cm4.apache.org/job/Cassandra-devbranch/375/testReport/junit/dtest-novnode.snapshot_test/TestArchiveCommitlog/test_archive_commitlog_with_active_commitlog/history/

 ",,e.dimitrova,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Degradation,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Feb 25 14:41:19 UTC 2021,,,,,,,All,,,,"0|z0nm2g:",9223372036854775807,,,,mck,,,,Normal,,NA,,https://github.com/apache/cassandra-dtest/commit/da9a8ba4bf86a1d833b12f52b6a38f89cc77bcc4,,,,,,,,,test passes reliably,,,,,"12/Feb/21 22:06;e.dimitrova;I wasn't able to reproduce it on my own in any way. 

But from the CircleCI log it seems as a legit issue. A node is not able to be brought up because of the following issue:
{code:java}
INFO [main] 2021-02-11 17:25:08,125 StorageService.java:830 - Populating token metadata from system tables
INFO [main] 2021-02-11 17:25:08,132 StorageService.java:824 - Token metadata: 
ERROR [main] 2021-02-11 17:25:08,153 SchemaKeyspace.java:942 - No partition columns found for table system_auth.network_permissions in system_schema.columns. This may be due to corruption or concurrent dropping and altering of a table. If this table is supposed to be dropped, restart cassandra with -Dcassandra.ignore_corrupted_schema_tables=true and run the following query to cleanup: ""DELETE FROM system_schema.tables WHERE keyspace_name = 'system_auth' AND table_name = 'network_permissions'; DELETE FROM system_schema.columns WHERE keyspace_name = 'system_auth' AND table_name = 'network_permissions';"" If the table is not supposed to be dropped, restore system_schema.columns sstables from backups.
ERROR [main] 2021-02-11 17:25:08,155 CassandraDaemon.java:271 - Error while loading schema: 
org.apache.cassandra.schema.SchemaKeyspace$MissingColumns: Columns not found in schema table for system_auth.network_permissions
 at org.apache.cassandra.schema.SchemaKeyspace.fetchColumns(SchemaKeyspace.java:998)
 at org.apache.cassandra.schema.SchemaKeyspace.fetchTable(SchemaKeyspace.java:962)
 at org.apache.cassandra.schema.SchemaKeyspace.fetchTables(SchemaKeyspace.java:921)
 at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspace(SchemaKeyspace.java:880)
 at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspacesWithout(SchemaKeyspace.java:871)
 at org.apache.cassandra.schema.SchemaKeyspace.fetchNonSystemKeyspaces(SchemaKeyspace.java:859)
 at org.apache.cassandra.schema.Schema.loadFromDisk(Schema.java:100)
 at org.apache.cassandra.schema.Schema.loadFromDisk(Schema.java:89)
 at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:267)
 at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:676)
 at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:800)
ERROR [main] 2021-02-11 17:25:08,155 CassandraDaemon.java:822 - Exception encountered during startup
org.apache.cassandra.schema.SchemaKeyspace$MissingColumns: Columns not found in schema table for system_auth.network_permissions
 at org.apache.cassandra.schema.SchemaKeyspace.fetchColumns(SchemaKeyspace.java:998)
 at org.apache.cassandra.schema.SchemaKeyspace.fetchTable(SchemaKeyspace.java:962)
 at org.apache.cassandra.schema.SchemaKeyspace.fetchTables(SchemaKeyspace.java:921)
 at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspace(SchemaKeyspace.java:880)
 at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspacesWithout(SchemaKeyspace.java:871)
 at org.apache.cassandra.schema.SchemaKeyspace.fetchNonSystemKeyspaces(SchemaKeyspace.java:859)
 at org.apache.cassandra.schema.Schema.loadFromDisk(Schema.java:100)
 at org.apache.cassandra.schema.Schema.loadFromDisk(Schema.java:89)
 at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:267)
 at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:676)
 at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:800){code}
I just started a multiplexer job in a Jenkins environment.

Considering it is flaky, it seems like some race condition maybe? I didn't have a lot of time to dig into the log/code for more details today but felt like leaving here what I have as I will be out almost half of the next week, in case someone is interested and has time to also look at it in the meanwhile. ;;;","23/Feb/21 23:33;brandon.williams;I haven't been able to reproduce these failures exactly, but I did find a race when [copying files|https://github.com/apache/cassandra-dtest/blob/trunk/snapshot_test.py#L216] when autocompaction is still enabled.  Patch to disable it.  So far this seems to be running smoothly for me.;;;","25/Feb/21 14:08;mck;Kicked off ci-cassandra.a.o: [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/406/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/406/pipeline]

Looking at the past trunk history: 
- https://ci-cassandra.apache.org/job/Cassandra-trunk/289/testReport/dtest.snapshot_test/
- https://ci-cassandra.apache.org/job/Cassandra-trunk/289/testReport/dtest-novnode.snapshot_test/
- https://ci-cassandra.apache.org/job/Cassandra-trunk/289/testReport/dtest-offheap.snapshot_test/

the only failure there is in [Cassandra-trunk/289|https://ci-cassandra.apache.org/job/Cassandra-trunk/289/testReport/dtest-novnode.snapshot_test/TestSnapshot/test_snapshot_and_restore_drop_table_remove_dropped_column/] (archived [here|https://nightlies.apache.org/cassandra/ci-cassandra.apache.org/job/Cassandra-trunk/289/index.html#showFailuresLink]). The the inner job to that is [Cassandra-trunk-dtest-novnode/250/label=cassandra,split=8|https://ci-cassandra.apache.org/job/Cassandra-trunk-dtest-novnode/250/label=cassandra,split=8/testReport/junit/dtest-novnode.snapshot_test/TestSnapshot/test_snapshot_and_restore_drop_table_remove_dropped_column/] (archived [here|https://nightlies.apache.org/cassandra/ci-cassandra.apache.org/job/Cassandra-trunk-dtest-novnode/250/index.html#showFailuresLink]). The archived logs to that run are at [nightlies.apache.org/cassandra/Cassandra-trunk-dtest-novnode/label=cassandra,split=8/250/|https://nightlies.apache.org/cassandra/Cassandra-trunk-dtest-novnode/label=cassandra,split=8/250/].

I've extracted the ccm_logs.tar.xz, so [debug.log|https://nightlies.apache.org/cassandra/Cassandra-trunk-dtest-novnode/label=cassandra,split=8/250/tmp/dtest-rieirnpc/test/node1/logs/debug.log] from the dtest-rieirnpc ccm cluster is easily readable. There I cannot see the race condition happening…

Searching archives didn't bring up any (pertinent) failures either
{code}
# mount https://nightlies.apache.org/cassandra/
cd /Volumes/cassandra/ci-cassandra.apache.org/job
grep -l ""snapshot_test.TestSnapshot"" Cassandra-trunk/*/index.html
grep -l ""snapshot_test.TestSnapshot"" Cassandra-trunk-dtest*/*/index.html
{code}

Despite lack of finding the race condition, I'm +1 on the patch. ;;;","25/Feb/21 14:27;brandon.williams;bq. Kicked off ci-cassandra.a.o

That's actually linked to the ticket at the top.

bq. the only failure there is in Cassandra-trunk/289 (archived here). 

Your archive links are broken.  There may very well be other problems with this test, but the race was the most visible one.

bq. Despite lack of finding the race condition, I'm +1 on the patch. 

Thanks.  It won't be visible in the system logs since it causes a python error, but I couldn't find that, either.  That said, it was observable when running the snapshot test suite locally in a loop, where multiple tests failed from the race being in a common function.;;;","25/Feb/21 14:28;brandon.williams;Committed.  Closing for now in hopes this gets it, we can reopen later if not.;;;","25/Feb/21 14:38;mck;bq. That's actually linked to the ticket at the top.

Oops, didn't see that at all :-( 

bq. Your archive links are broken. 

They will work soon. The links under https://nightlies.apache.org/cassandra/ci-cassandra.apache.org/ are still getting sync'd.
Though the archived logs (e.g. nightlies.apache.org/cassandra/Cassandra* links) *are* accessible as soon as the jenkins job has finished.

bq. It won't be visible in the system logs since it causes a python error, … 

I was searching through the ""Compacting …"" log line for compactions happening on {{ks.cf}} table. IIUC that is a requirement for the race condition…?;;;","25/Feb/21 14:41;brandon.williams;bq. IIUC that is a requirement for the race condition

That's my theory at least, unless there's something else that would yank data files out while being copied.  But like I said, there could very well be other problems here, I guess we'll see.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reverse iteration with paging may throw if the page boundary coincides with open tombstone boundary,CASSANDRA-16435,13357795,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,ifesdjeen,ifesdjeen,ifesdjeen,09/Feb/21 16:36,16/Mar/22 15:26,13/Jul/23 08:40,09/Mar/21 13:55,4.0,4.0-rc1,,,,,,Consistency/Coordination,,,,0,,,"If sstable contains a tombstone that has an open bound which coincides with current page bound, we’ll generate an impossible empty slice range. 
 
Minimal repro:
 
{code}
        try (Cluster cluster = init(builder().withNodes(3).start()))
        {
            cluster.schemaChange(""CREATE TABLE "" + KEYSPACE + "".tbl (pk int, ck int, regular int, PRIMARY KEY (pk, ck))"");
            cluster.coordinator(1).execute(""DELETE FROM "" + KEYSPACE + "".tbl WHERE pk = 1 AND ck > 1 AND ck < 10"", ConsistencyLevel.ALL);
            cluster.coordinator(1).execute(""insert into "" + KEYSPACE + "".tbl (pk, ck, regular) values (1,1,1)"", ConsistencyLevel.ALL);
            cluster.coordinator(1).execute(""insert into "" + KEYSPACE + "".tbl (pk, ck, regular) values (1,2,2)"", ConsistencyLevel.ALL);
            cluster.coordinator(1).execute(""insert into "" + KEYSPACE + "".tbl (pk, ck, regular) values (1,3,3)"", ConsistencyLevel.ALL);
            cluster.stream().forEach(n -> {
                n.nodetool(""flush"");
            });
            Iterator<Object[]> iter = cluster.coordinator(1).executeWithPaging(""SELECT pk,ck,regular FROM "" + KEYSPACE + "".tbl "" +
                                                                               ""WHERE pk=? AND ck>=? ORDER BY ck DESC;"",
                                                                               ConsistencyLevel.QUORUM, 1,
                                                                               1,1);
            while (iter.hasNext())
            {
                System.out.println(Arrays.toString(iter.next()));
            }
        }
 {code}
Stack trace: 
 
{code}
Caused by: java.lang.IllegalArgumentException: [1, 1)
at com.google.common.base.Preconditions.checkArgument(Preconditions.java:141)
at org.apache.cassandra.db.Slices.with(Slices.java:66)
at org.apache.cassandra.db.columniterator.SSTableReversedIterator$ReverseReader.setIterator(SSTableReversedIterator.java:140)
at org.apache.cassandra.db.columniterator.SSTableReversedIterator$ReverseReader.setForSlice(SSTableReversedIterator.java:134)
at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.<init>(AbstractSSTableIterator.java:118)
at org.apache.cassandra.db.columniterator.SSTableReversedIterator.<init>(SSTableReversedIterator.java:52)
at org.apache.cassandra.io.sstable.format.big.BigTableReader.iterator(BigTableReader.java:75)
at org.apache.cassandra.io.sstable.format.big.BigTableReader.iterator(BigTableReader.java:67)
at org.apache.cassandra.db.rows.UnfilteredRowIteratorWithLowerBound.initializeIterator(UnfilteredRowIteratorWithLowerBound.java:100)
at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.maybeInit(LazilyInitializedUnfilteredRowIterator.java:48)
at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.partitionLevelDeletion(LazilyInitializedUnfilteredRowIterator.java:81)
at org.apache.cassandra.db.rows.UnfilteredRowIteratorWithLowerBound.partitionLevelDeletion(UnfilteredRowIteratorWithLowerBound.java:161)
at org.apache.cassandra.db.SinglePartitionReadCommand.queryMemtableAndDiskInternal(SinglePartitionReadCommand.java:672)
at org.apache.cassandra.db.SinglePartitionReadCommand.queryMemtableAndDisk(SinglePartitionReadCommand.java:566)
at org.apache.cassandra.db.SinglePartitionReadCommand.queryStorage(SinglePartitionReadCommand.java:400)
at org.apache.cassandra.db.ReadCommand.executeLocally(ReadCommand.java:460)
at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:2011)
at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2725)
... 5 common frames omitted
{code}",,aleksey,ifesdjeen,marcuse,,,,,,,,,,,,,"smiklosovic closed pull request #898:
URL: https://github.com/apache/cassandra/pull/898


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:26;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,ifesdjeen,,,,,,,,,,,,,Availability -> Response Crash,,,,,,,,Normal,Fuzz Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 09 14:02:40 UTC 2021,,,,,,,All,,,,"0|z0njb4:",9223372036854775807,,,,aleksey,marcuse,,,Critical,,4.0-alpha1,,https://github.com/apache/cassandra/commit/6f13c864a02b32daa7696eca27431f5385a306df,,,,,,,,,"Tests included; extensive testing with Harry has been completed",,,,,"15/Feb/21 15:18;ifesdjeen;|[trunk patch|https://github.com/apache/cassandra/pull/898]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=CASSANDRA-16435-trunk]|;;;","18/Feb/21 12:16;marcuse;+1, small inline comment on the PR;;;","02/Mar/21 14:23;aleksey;+1 with the last changes.;;;","09/Mar/21 13:55;ifesdjeen;Thank you for the review. Committed to trunk with [6f13c864a02b32daa7696eca27431f5385a306df|https://github.com/apache/cassandra/commit/6f13c864a02b32daa7696eca27431f5385a306df];;;","09/Mar/21 14:02;ifesdjeen;Thank you for the review! 

Since bug is not present (i.e., there will be no assertion error) in 3.0 or 3.11 due to differences in code: empty bounds check was added in [CASSANDRA-14849], and 3.0 is even more different from 3.11, and won't fail even if assertion is added. 

Committed to trunk with [9bc8d0b452aeb7aaa2005e710fc3de0998172738|https://github.com/apache/cassandra/commit/9bc8d0b452aeb7aaa2005e710fc3de0998172738];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Version family is probably broken for Cassandra 2 and 3.11 in dtests,CASSANDRA-16433,13357686,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,09/Feb/21 06:43,20/Feb/21 10:49,13/Jul/23 08:40,20/Feb/21 10:49,3.0.25,3.11.11,4.0,4.0-rc1,,,,Test/dtest/python,,,,0,,,"It looks like the version families are a bit confused - when we determine version family for the current build, we do:

{code:python}
    if current_version.vstring.startswith('2.0'):
        version_family = '2.0.x'
    elif current_version.vstring.startswith('2.1'):
        version_family = '2.1.x'
    elif current_version.vstring.startswith('2.2'):
        version_family = '2.2.x'
    elif current_version.vstring.startswith('3.0'):
        version_family = '3.0.x'
    elif '3.1' <= current_version < '4.0':
        version_family = '3.x'
    elif '4.0' <= current_version < '4.1':
        version_family = 'trunk'
    else:
        # when this occurs, it's time to update this manifest a bit!
        raise RuntimeError(""4.1+ not yet supported on upgrade tests!"")
{code}

but later, in the upgrade manifest we have:

{code:python}
indev_2_1_x = VersionMeta(name='indev_2_1_x', family='2.1', variant='indev', version='github:apache/cassandra-2.1', min_proto_v=1, max_proto_v=3, java_versions=(7, 8))
current_2_1_x = VersionMeta(name='current_2_1_x', family='2.1', variant='current', version='2.1.20', min_proto_v=1, max_proto_v=3, java_versions=(7, 8))

indev_2_2_x = VersionMeta(name='indev_2_2_x', family='2.2', variant='indev', version='github:apache/cassandra-2.2', min_proto_v=1, max_proto_v=4, java_versions=(7, 8))
current_2_2_x = VersionMeta(name='current_2_2_x', family='2.2', variant='current', version='2.2.13', min_proto_v=1, max_proto_v=4, java_versions=(7, 8))

indev_3_0_x = VersionMeta(name='indev_3_0_x', family='3.0', variant='indev', version='github:apache/cassandra-3.0', min_proto_v=3, max_proto_v=4, java_versions=(8,))
current_3_0_x = VersionMeta(name='current_3_0_x', family='3.0', variant='current', version='3.0.23', min_proto_v=3, max_proto_v=4, java_versions=(8,))

indev_3_11_x = VersionMeta(name='indev_3_11_x', family='3.11', variant='indev', version='github:apache/cassandra-3.11', min_proto_v=3, max_proto_v=4, java_versions=(8,))
current_3_11_x = VersionMeta(name='current_3_11_x', family='3.11', variant='current', version='3.11.9', min_proto_v=3, max_proto_v=4, java_versions=(8,))
{code}

later on in the code we have some manifest filtering:

{code:python}
            if filter_for_current_family and not origin_meta.matches_current_env_version_family and not destination_meta.matches_current_env_version_family:
                logger.debug(""skipping class creation, origin version {} and destination version {} do not match target version {}, and --upgrade-target-version-only was set"".format(origin_meta.name, destination_meta.name, VERSION_FAMILY))
                continue
{code}

This does not cause any problems for {{trunk}}, but when I tried to run some upgrade tests on 3.11 build, I could not do anything. 

Therefore we need to either change families in manifest as follows:
- 2.1 -> 2.1.x
- 2.2 -> 2.2.x
- 3.0 -> 3.0.x
- 3.11 -> 3.x

or change how we assign version family for the current build

",,jlewandowski,mck,tomasz.lasica,,,,,,,,,,,,,"jacek-lewandowski opened a new pull request #122:
URL: https://github.com/apache/cassandra-dtest/pull/122


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Feb/21 06:48;githubbot;600","tlasica commented on a change in pull request #122:
URL: https://github.com/apache/cassandra-dtest/pull/122#discussion_r572656520



##########
File path: upgrade_tests/upgrade_manifest.py
##########
@@ -126,17 +126,17 @@ def clone_with_local_env_version(self):
         return self._replace(version=""clone:{}"".format(cassandra_dir))
 
 
-indev_2_1_x = VersionMeta(name='indev_2_1_x', family='2.1', variant='indev', version='github:apache/cassandra-2.1', min_proto_v=1, max_proto_v=3, java_versions=(7, 8))
-current_2_1_x = VersionMeta(name='current_2_1_x', family='2.1', variant='current', version='2.1.20', min_proto_v=1, max_proto_v=3, java_versions=(7, 8))
+indev_2_1_x = VersionMeta(name='indev_2_1_x', family='2.1.x', variant='indev', version='github:apache/cassandra-2.1', min_proto_v=1, max_proto_v=3, java_versions=(7, 8))
+current_2_1_x = VersionMeta(name='current_2_1_x', family='2.1.x', variant='current', version='2.1.20', min_proto_v=1, max_proto_v=3, java_versions=(7, 8))
 
-indev_2_2_x = VersionMeta(name='indev_2_2_x', family='2.2', variant='indev', version='github:apache/cassandra-2.2', min_proto_v=1, max_proto_v=4, java_versions=(7, 8))
-current_2_2_x = VersionMeta(name='current_2_2_x', family='2.2', variant='current', version='2.2.13', min_proto_v=1, max_proto_v=4, java_versions=(7, 8))
+indev_2_2_x = VersionMeta(name='indev_2_2_x', family='2.2.x', variant='indev', version='github:apache/cassandra-2.2', min_proto_v=1, max_proto_v=4, java_versions=(7, 8))
+current_2_2_x = VersionMeta(name='current_2_2_x', family='2.2.x', variant='current', version='2.2.13', min_proto_v=1, max_proto_v=4, java_versions=(7, 8))
 
-indev_3_0_x = VersionMeta(name='indev_3_0_x', family='3.0', variant='indev', version='github:apache/cassandra-3.0', min_proto_v=3, max_proto_v=4, java_versions=(8,))
-current_3_0_x = VersionMeta(name='current_3_0_x', family='3.0', variant='current', version='3.0.23', min_proto_v=3, max_proto_v=4, java_versions=(8,))
+indev_3_0_x = VersionMeta(name='indev_3_0_x', family='3.0.x', variant='indev', version='github:apache/cassandra-3.0', min_proto_v=3, max_proto_v=4, java_versions=(8,))
+current_3_0_x = VersionMeta(name='current_3_0_x', family='3.0.x', variant='current', version='3.0.23', min_proto_v=3, max_proto_v=4, java_versions=(8,))
 
-indev_3_11_x = VersionMeta(name='indev_3_11_x', family='3.11', variant='indev', version='github:apache/cassandra-3.11', min_proto_v=3, max_proto_v=4, java_versions=(8,))
-current_3_11_x = VersionMeta(name='current_3_11_x', family='3.11', variant='current', version='3.11.9', min_proto_v=3, max_proto_v=4, java_versions=(8,))
+indev_3_11_x = VersionMeta(name='indev_3_11_x', family='3.x', variant='indev', version='github:apache/cassandra-3.11', min_proto_v=3, max_proto_v=4, java_versions=(8,))

Review comment:
       What is the reason to have 3.11.n be a `3.x` family and not a `3.11.x` family?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Feb/21 07:44;githubbot;600","tlasica commented on a change in pull request #122:
URL: https://github.com/apache/cassandra-dtest/pull/122#discussion_r572657544



##########
File path: upgrade_tests/upgrade_manifest.py
##########
@@ -126,17 +126,17 @@ def clone_with_local_env_version(self):
         return self._replace(version=""clone:{}"".format(cassandra_dir))
 
 
-indev_2_1_x = VersionMeta(name='indev_2_1_x', family='2.1', variant='indev', version='github:apache/cassandra-2.1', min_proto_v=1, max_proto_v=3, java_versions=(7, 8))
-current_2_1_x = VersionMeta(name='current_2_1_x', family='2.1', variant='current', version='2.1.20', min_proto_v=1, max_proto_v=3, java_versions=(7, 8))
+indev_2_1_x = VersionMeta(name='indev_2_1_x', family='2.1.x', variant='indev', version='github:apache/cassandra-2.1', min_proto_v=1, max_proto_v=3, java_versions=(7, 8))

Review comment:
       `VersionMeta` should throw assertion if `family` is not withing defined families




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Feb/21 07:47;githubbot;600","jacek-lewandowski opened a new pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Feb/21 21:44;githubbot;600","tlasica commented on a change in pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123#discussion_r573269874



##########
File path: upgrade_tests/upgrade_manifest.py
##########
@@ -19,6 +19,12 @@
 VERSION_FAMILY = None
 CONFIG = None
 
+CASSANDRA_2_0 = '2.0'
+CASSANDRA_2_1 = '2.1'
+CASSANDRA_2_2 = '2.2'
+CASSANDRA_3_0 = '3.0'
+CASSANDRA_3_11 = '3.11'
+CASSANDRA_4_0 = 'trunk'

Review comment:
       Just for my curiosity, not blocking...
   Why not `4.0`?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Feb/21 22:43;githubbot;600","michaelsembwever commented on a change in pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123#discussion_r575488634



##########
File path: upgrade_tests/upgrade_manifest.py
##########
@@ -160,38 +160,15 @@ def clone_with_local_env_version(self):
 #   4) If a new sstable format is present in version B, writes will occur in that format after upgrade. Running sstableupgrade on version B will proactively convert version A sstables to version B.
 # TODO define new upgrade scenarios whenever Cassandra is branched
 MANIFEST = {
-    indev_2_1_x: [indev_2_2_x, current_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-    current_2_1_x: [indev_2_1_x, indev_2_2_x, current_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-
-    indev_2_2_x: [indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-    current_2_2_x: [indev_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-
-    indev_3_0_x: [indev_3_11_x, current_3_11_x, indev_trunk],
-    current_3_0_x: [indev_3_0_x, indev_3_11_x, current_3_11_x, indev_trunk],
-
+    current_2_1_x: [current_2_2_x, indev_3_0_x, indev_3_11_x],
+    current_2_2_x: [indev_3_0_x, indev_3_11_x],
+    current_3_0_x: [indev_3_0_x, indev_3_11_x, indev_trunk],

Review comment:
       do we need `indev_3_0_x` here?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Feb/21 20:00;githubbot;600","jacek-lewandowski commented on a change in pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123#discussion_r575507981



##########
File path: upgrade_tests/upgrade_manifest.py
##########
@@ -160,38 +160,15 @@ def clone_with_local_env_version(self):
 #   4) If a new sstable format is present in version B, writes will occur in that format after upgrade. Running sstableupgrade on version B will proactively convert version A sstables to version B.
 # TODO define new upgrade scenarios whenever Cassandra is branched
 MANIFEST = {
-    indev_2_1_x: [indev_2_2_x, current_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-    current_2_1_x: [indev_2_1_x, indev_2_2_x, current_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-
-    indev_2_2_x: [indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-    current_2_2_x: [indev_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-
-    indev_3_0_x: [indev_3_11_x, current_3_11_x, indev_trunk],
-    current_3_0_x: [indev_3_0_x, indev_3_11_x, current_3_11_x, indev_trunk],
-
+    current_2_1_x: [current_2_2_x, indev_3_0_x, indev_3_11_x],
+    current_2_2_x: [indev_3_0_x, indev_3_11_x],
+    current_3_0_x: [indev_3_0_x, indev_3_11_x, indev_trunk],

Review comment:
       it depends, is 30 still supported? if so - yes, if not, then no :)




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Feb/21 20:41;githubbot;600","michaelsembwever commented on a change in pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123#discussion_r575513481



##########
File path: upgrade_tests/upgrade_manifest.py
##########
@@ -160,38 +160,15 @@ def clone_with_local_env_version(self):
 #   4) If a new sstable format is present in version B, writes will occur in that format after upgrade. Running sstableupgrade on version B will proactively convert version A sstables to version B.
 # TODO define new upgrade scenarios whenever Cassandra is branched
 MANIFEST = {
-    indev_2_1_x: [indev_2_2_x, current_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-    current_2_1_x: [indev_2_1_x, indev_2_2_x, current_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-
-    indev_2_2_x: [indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-    current_2_2_x: [indev_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-
-    indev_3_0_x: [indev_3_11_x, current_3_11_x, indev_trunk],
-    current_3_0_x: [indev_3_0_x, indev_3_11_x, current_3_11_x, indev_trunk],
-
+    current_2_1_x: [current_2_2_x, indev_3_0_x, indev_3_11_x],
+    current_2_2_x: [indev_3_0_x, indev_3_11_x],
+    current_3_0_x: [indev_3_0_x, indev_3_11_x, indev_trunk],

Review comment:
       gotcha. then there should be a `current_2_2_x -> indev_2_2_x` too, since that is currently supported (and will be accepting critical bug fixes for ~one more year)




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;12/Feb/21 20:53;githubbot;600","jacek-lewandowski commented on a change in pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123#discussion_r575632209



##########
File path: upgrade_tests/upgrade_manifest.py
##########
@@ -160,38 +160,15 @@ def clone_with_local_env_version(self):
 #   4) If a new sstable format is present in version B, writes will occur in that format after upgrade. Running sstableupgrade on version B will proactively convert version A sstables to version B.
 # TODO define new upgrade scenarios whenever Cassandra is branched
 MANIFEST = {
-    indev_2_1_x: [indev_2_2_x, current_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-    current_2_1_x: [indev_2_1_x, indev_2_2_x, current_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-
-    indev_2_2_x: [indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-    current_2_2_x: [indev_2_2_x, indev_3_0_x, current_3_0_x, indev_3_11_x, current_3_11_x],
-
-    indev_3_0_x: [indev_3_11_x, current_3_11_x, indev_trunk],
-    current_3_0_x: [indev_3_0_x, indev_3_11_x, current_3_11_x, indev_trunk],
-
+    current_2_1_x: [current_2_2_x, indev_3_0_x, indev_3_11_x],
+    current_2_2_x: [indev_3_0_x, indev_3_11_x],
+    current_3_0_x: [indev_3_0_x, indev_3_11_x, indev_trunk],

Review comment:
       i didn't know that; i'll bring it back then




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Feb/21 07:06;githubbot;600","tlasica commented on a change in pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123#discussion_r577415618



##########
File path: upgrade_tests/upgrade_udtfix_test.py
##########
@@ -154,7 +155,7 @@ def _verify_upgrade_log(self, log_mark, node):
 
     start_family = spec['UPGRADE_PATH'].starting_meta.family
     upgrade_family = spec['UPGRADE_PATH'].upgrade_meta.family
-    start_family_applies = start_family == '3.0' and (upgrade_family == 'trunk' or LooseVersion(upgrade_family) > '3.0')
+    start_family_applies = start_family == CASSANDRA_3_0

Review comment:
       should we not keep the `upgrade_family > CASSANDRA_3_0` condition?
   




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 08:33;githubbot;600","jacek-lewandowski commented on a change in pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123#discussion_r577575725



##########
File path: upgrade_tests/upgrade_udtfix_test.py
##########
@@ -154,7 +155,7 @@ def _verify_upgrade_log(self, log_mark, node):
 
     start_family = spec['UPGRADE_PATH'].starting_meta.family
     upgrade_family = spec['UPGRADE_PATH'].upgrade_meta.family
-    start_family_applies = start_family == '3.0' and (upgrade_family == 'trunk' or LooseVersion(upgrade_family) > '3.0')
+    start_family_applies = start_family == CASSANDRA_3_0

Review comment:
       `start_family_applies`... 
   However the test is tagged with `@since('3.11.6')`




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 12:36;githubbot;600","jacek-lewandowski commented on a change in pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123#discussion_r577581885



##########
File path: upgrade_tests/upgrade_base.py
##########
@@ -262,4 +264,4 @@ def upgrade_version_family(self):
 
     def upgrade_is_version_4_or_greater(self):
         upgrade_version = self.upgrade_version_family()
-        return upgrade_version == 'trunk' or upgrade_version >= '4.0'
+        return upgrade_version == upgrade_version >= CASSANDRA_4_0

Review comment:
       I've made a bug here




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 12:46;githubbot;600","tlasica commented on a change in pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123#discussion_r579095740



##########
File path: upgrade_tests/upgrade_through_versions_test.py
##########
@@ -46,7 +48,10 @@ def data_writer(tester, to_verify_queue, verification_done_queue, rewrite_probab
     def handle_sigterm(signum, frame):
         # need to close queue gracefully if possible, or the data_checker process
         # can't seem to empty the queue and test failures result.
+        logger.info(""Data writer process terminating, closing queues"")
         to_verify_queue.close()

Review comment:
       nit: we may wrap 
   ```
   def cleanup():
       to_verify_queue.close()
       verification_done_queue.close()
       session.shutdown()
   ```
   and call it in both `handle_sigterm()` and on exception




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Feb/21 10:50;githubbot;600","michaelsembwever commented on pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123#issuecomment-782604765


   Merged with https://github.com/apache/cassandra-dtest/commit/e7f7a593427f83ff7a256d91ee48bbb8380bc788


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Feb/21 10:47;githubbot;600","michaelsembwever closed pull request #123:
URL: https://github.com/apache/cassandra-dtest/pull/123


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Feb/21 10:47;githubbot;600","michaelsembwever closed pull request #122:
URL: https://github.com/apache/cassandra-dtest/pull/122


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Feb/21 10:47;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,9600,,,0,9600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jlewandowski,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Sat Feb 20 10:49:05 UTC 2021,,,,,,,All,,,,"0|z0nimw:",9223372036854775807,,,,mck,tomasz.lasica,,,Low,,2.0 beta 1,,https://github.com/apache/cassandra-dtest/commit/e7f7a593427f83ff7a256d91ee48bbb8380bc788,,,,,,,,,run upgrade tests on 3.11,,,,,"09/Feb/21 07:42;tomasz.lasica;I am not a big fun of making things complex, and rather to abstract reality as simple as it is.

So to me family should reflect .... family... means:
 * 2.0.15 and 2.0.2 will be 2.0 family.
 * 3.11.8 and 3.11.9 will be 3.11 family.
 * 3.10.1 and 3.10.20 will be 3.10 family.
 * And 4.0.0  or 4.0.1. will be 4.0 family. 

Explicit is better than implicit. Versions are are added not often, so no need to be smart in the way upgrade tests will automatically switch to latest, because we will have to make sure we still have enough tests for both pre-latest and latest in such case.

 

But I understand that unfortunate 3.0-4.0 -> 3.x was done some time ago.;;;","09/Feb/21 13:21;mck;bq. 3.10.1 and 3.10.20 will be 3.10 family.

this doesn't exist [~tomasz.lasica]. did you mean 3.0.1 and 3.0.20 ?

replacing ""version_family = '3.x'"" to ""version_family = '3.11.x'"" makes sense to me. ;;;","11/Feb/21 15:25;mck;Kicked off in CI
 - trunk: https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/20/
 - cassandra-3.11: https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/21/;;;","12/Feb/21 20:27;mck;With updated patches.
- cassandra-3.11: https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/25/
- cassandra-3.0: https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/26/;;;","13/Feb/21 17:29;mck;With thrift tests fixed:
- cassandra-3.0: https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/28/
 - trunk: https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/29/;;;","15/Feb/21 09:02;mck;With udt and upgrade path (family vs variant) fixes:
- cassandra-3.0: https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/30/
- cassandra-3.11: https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/31/;;;","20/Feb/21 10:09;mck;Latest round of CI (after improvements to closing sessions on process termination, and [other|https://github.com/apache/cassandra-dtest/pull/123/commits] review comments):
- [3.0|https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/48/]
- [3.11|https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/47/]
- [trunk|https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest-upgrade/49];;;","20/Feb/21 10:49;mck;Committed with [e7f7a593427f83ff7a256d91ee48bbb8380bc788|https://github.com/apache/cassandra-dtest/commit/e7f7a593427f83ff7a256d91ee48bbb8380bc788].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix flaky test mixedModeReadColumnSubsetDigestCheck - org.apache.cassandra.distributed.upgrade.MixedModeReadTest,CASSANDRA-16432,13357630,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,dcapwell,dcapwell,08/Feb/21 21:30,25/Feb/21 10:25,13/Jul/23 08:40,08/Feb/21 21:33,4.0,4.0-rc1,,,,,,Test/dtest/java,,,,0,,,"https://app.circleci.com/pipelines/github/dcapwell/cassandra/860/workflows/bde81400-ed6d-4d9c-8447-3dd33b14cddd/jobs/5117

{code}
junit.framework.AssertionFailedError: Found Digest Mismatch
	at org.apache.cassandra.distributed.upgrade.MixedModeReadTest.checkTraceForDigestMismatch(MixedModeReadTest.java:89)
	at org.apache.cassandra.distributed.upgrade.MixedModeReadTest.lambda$mixedModeReadColumnSubsetDigestCheck$0(MixedModeReadTest.java:63)
	at org.apache.cassandra.distributed.upgrade.UpgradeTestBase$TestCase.run(UpgradeTestBase.java:171)
	at org.apache.cassandra.distributed.upgrade.MixedModeReadTest.mixedModeReadColumnSubsetDigestCheck(MixedModeReadTest.java:76)
{code}",,dcapwell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16415,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,2021-02-08 21:30:37.0,,,,,,,All,,,,"0|z0niag:",9223372036854775807,,,,,,,,Normal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix incorrect encoding for strings can be UTF8,CASSANDRA-16429,13357263,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,yifanc,ykimoto,ykimoto,06/Feb/21 13:00,16/Mar/22 15:30,13/Jul/23 08:40,23/Feb/21 03:00,4.0,4.0-rc1,,,,,,CQL/Interpreter,,,,0,,,"Tables created with Japanese character name columns are working well in C* 3.11.10 when doing a SELECT * in cqlsh but will show as garbled (shown as ""?"") in 4.0-beta4. DESCRIBE shows the column names correctly in both cases.

Run the attached jptest.cql script in both envs with cqlsh -f. They will yield different results.

My test env (MacOS 10.15.7):

C* 3.11.10 with
 - OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_252-b09)
 - Python 2.7.16

C* 4.0-beta4
 - OpenJDK Runtime Environment AdoptOpenJDK (build 11.0.9.1+1)
 - Python 3.8.2
",,aholmber,aleksey,blerer,e.dimitrova,jeromatron,yifanc,ykimoto,,,,,,,,,"yifan-c opened a new pull request #907:
URL: https://github.com/apache/cassandra/pull/907


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Feb/21 01:49;githubbot;600","ekaterinadimitrova2 commented on a change in pull request #907:
URL: https://github.com/apache/cassandra/pull/907#discussion_r580287782



##########
File path: test/unit/org/apache/cassandra/transport/SerDeserTest.java
##########
@@ -203,20 +205,32 @@ public void udtSerDeserTest(ProtocolVersion version) throws Exception
         SetType<?> st = SetType.getInstance(UTF8Type.instance, true);
         MapType<?, ?> mt = MapType.getInstance(UTF8Type.instance, LongType.instance, true);
 
+        String typeName = ""myType"" + randomUTF8(3);
+        String fieldName = 'f' + randomUTF8(3);
+
         UserType udt = new UserType(""ks"",
-                                    bb(""myType""),
-                                    Arrays.asList(field(""f1""), field(""f2""), field(""f3""), field(""f4"")),
+                                    bb(typeName),
+                                    Arrays.asList(field(fieldName), field(""f2""), field(""f3""), field(""f4"")),

Review comment:
       I am fine with changing f1 to fieldname but then shouldn't we do something to f2, f3... to keep the naming consistent?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Feb/21 15:33;githubbot;600","smiklosovic closed pull request #907:
URL: https://github.com/apache/cassandra/pull/907


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:30;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,CASSANDRA-15410,,,,,,,,,,,,,,,,,,,,"06/Feb/21 12:56;ykimoto;jptest.cql;https://issues.apache.org/jira/secure/attachment/13020118/jptest.cql",,,,,1.0,yifanc,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Feb 23 03:00:14 UTC 2021,,,,,,,All,,,,"0|z0ng0w:",9223372036854775807,,,,e.dimitrova,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/f32475a839e01e4eea3989871d293d70e8a360d7,,,,,,,,,"unit, circle",,,,,"08/Feb/21 00:38;jeromatron;Could this be related to the new code that exposes table schema directly to the drivers?  CASSANDRA-14825;;;","08/Feb/21 09:46;blerer;[~jeromatron]  CASSANDRA-14825 changed only the way the output of the `DESCRIBE` statement worked. According to your comment this part is functionning so I believe that the problem has been caused by some other change.;;;","10/Feb/21 18:51;aholmber;I'm seeing the same behavior in SELECT results for 3.11. Additionally, 4.0 actually fails to even run the DDL:

{noformat}
'ascii' codec can't encode characters in position 44-45: ordinal not in range(128)
{noformat}
(this is with Python 2.7);;;","10/Feb/21 19:25;aholmber;Scratch that. Not observed in 3.11. They showed when using 3.11 cqlsh against 4.0. I entered this assuming it would be a cqlsh (or driver) issue. It turns out ""??"" is actually coming back in the results metadata from the server. Digging further...;;;","10/Feb/21 19:50;ykimoto;Using 4.10.0 Java driver, If you do:

            rs = session.execute(""select * from jptest.test;"");
            row = rs.one();
            System.out.println(""getFormattedContents() = ""+ row.getFormattedContents());
            System.out.println(""getColumnDefinitions().get(0).getName() = "" + row.getColumnDefinitions().get(0).getName());
            System.out.println(""getColumnDefinitions().get(1).getName() = "" + row.getColumnDefinitions().get(1).getName());

will return the ""??""s in 4 and will be correct in 3.11. And trying

            System.out.println(""getString(キー) = ""+ row.getString(""キー""));
            System.out.println(""getString(値) = ""+ row.getString(""値""));

will result in the following in 4 but works in 3.11:

java.lang.IllegalArgumentException: キー is not a column in this row
    at com.datastax.oss.driver.internal.core.cql.DefaultRow.firstIndexOf (DefaultRow.java:110)
    at com.datastax.oss.driver.api.core.data.GettableByName.getString (GettableByName.java:421)
    at CassandraNonAsciiColumnNameTest.main (CassandraNonAsciiColumnNameTest.java:59)
    at org.codehaus.mojo.exec.ExecJavaMojo$1.run (ExecJavaMojo.java:254)
    at java.lang.Thread.run (Thread.java:834);;;","10/Feb/21 21:01;aholmber;The ResultSet Metadata encoding is failing non-ASCII characters because of an optimization introduced in CASSANDRA-15410, which assumes we're always encoding ASCII identifiers. Cassandra [docs|https://cassandra.apache.org/doc/latest/cql/definitions.html#identifiers] say identifiers are supposed to be ASCII, but that has not been enforced. So we will need to decide if we want to revert this optimization for compatibility, or if we should instead introduce unicode detection.

Paging [~yifanc] and [~aleksey] for their input. I know the microbenchmark showed a great improvement for this encoding in particular, but do we have some idea of how significantly it figures in the overall request execution?;;;","11/Feb/21 01:28;yifanc;[~aholmber], thanks for the investigation! 

I can reproduce the issue with trunk.
{code:java}
cqlsh> CREATE TABLE test.non_ascii_test ( ""测试"" text PRIMARY KEY, value text);
cqlsh> INSERT INTO test.non_ascii_test (""测试"", value) VALUES ('foo', 'bar');
cqlsh> SELECT * FROM test.non_ascii_test;
 ??  | value
-----+-------
 foo |   bar

(1 rows)
{code}
The optimization basically enforce the ASCII encoding for keyspace, table and column name. 
 For the keyspace and table name, the cql parser does have a strict rule of using only
{code:java}
[a-zA-Z_0-9]{1, 48}{code}
However, for the column names, the rule is loose. We can have UTF-8 characters as column names as long as they are quoted, but it is not explicitly mentioned in the docs.

It is important to maintain the backward compatibility. So proposing that we keep the ASCII encoding for keyspace and table name and revert the encoding of the column names back. I can make a small patch that does it real quick.;;;","11/Feb/21 03:14;yifanc;The WIP patch: [https://github.com/yifan-c/cassandra/commit/a5d0c9c4864899ef0f2bf65b82e7dc41288c2d09] to allow UTF-8 string in column name. 

 
{code:java}
➜ bin/cqlsh
Connected to Test Cluster at 127.0.0.1:9042.
[cqlsh 5.0.1 | Cassandra 4.0-beta5-SNAPSHOT | CQL spec 3.4.5 | Native protocol v4]
Use HELP for help.
cqlsh> CREATE KEYSPACE test WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}  AND durable_writes = true;
cqlsh> CREATE TABLE test.non_ascii_test ( ""测试"" text PRIMARY KEY, value text);
cqlsh> INSERT INTO test.non_ascii_test (""测试"", value) VALUES ('foo', 'bar');
cqlsh> SELECT * FROM test.non_ascii_test; 

  测试 | value
------+-------
  foo |   bar

(1 rows)
{code}
 ;;;","11/Feb/21 20:42;aholmber;Yifan asked about taking this over, so I'm reassigning and moving on to something else.;;;","18/Feb/21 02:08;yifanc;PR: https://github.com/apache/cassandra/pull/907
Circle: https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=CASSANDRA-16429%2Ftrunk

The patch reverts back to use the UTF8 compatible string encoding for column names, user defined type names and field names. Those are all the types of names that can use UTF8, according to the cql definition. 
With the patch, the ASCII encoding is only used for table names, keyspace names and places we are sure that only contain ASCII characters. 

The {{SerDeserTest}} test cases are extended to cover the UTF8 cases. If unapply the patch, the test should fail. ;;;","18/Feb/21 19:57;e.dimitrova;As someone who was not familiar with the initial work and looks at it with fresh eyes, I have two directions of thinking:
 * A group of users who were using UTF8 in previous versions (and I can imagine them not being 1 or 2) observe a breaking change of expected behavior which is not documented.
 * We are just before a RC I believe and we promised no breaking changes anymore and now we revert, at least partially, a performance improvement. Then a different part of users gets disappointed as they were already testing and preparing for production migration or even running in production already on top of 4.0? Do we need broader agreement for this change?

In that sense I personally have the same question as [~aholmber]:

_Paging [~yifanc] and [~aleksey] for their input. I know the microbenchmark showed a great improvement for this encoding in particular, but do we have some idea of how significantly it figures in the overall request execution_

PS In both cases I believe we will need to update the documentation accordingly around UTF8.

 ;;;","18/Feb/21 20:14;brandon.williams;bq. we promised no breaking changes anymore and now we revert, at least partially, a performance improvement.

I don't think a performance improvement can be considered a breaking change if removed, provided that improvement does not exist in previously released (ie, 3.x) versions. I also suspect this improvement is difficult to observe outside of a microbenchmark. ;;;","18/Feb/21 23:21;e.dimitrova;I didn't mean breaking in the sense of previous version. Just wanted to be sure that it is acceptable and we are sure about the impact of reverting a performance improvement just before the release. ;;;","19/Feb/21 00:15;yifanc;Thanks everyone for the input!

I would like to revert all the necessary parts in order to maintain the compatibility. The patch attached does it. And we should also update the documentation. 

Regarding the performance optimization,
 * Looking at commit [c3b014a|https://github.com/apache/cassandra/commit/647bdd6a11970f80666d7f20b53af76fbda4ff14#diff-82bdd361868471a5287c3b014ace6b5d3e6307557983d6eb9ef5dff27b97a408R144-R154], I introduced {{writeAsciiString}}, which is the fastest for ASCII strings, and a new implementation of {{writeString}}, which computes the exact size to avoid overallocation. Both changes, according to the [micro bench result|https://issues.apache.org/jira/browse/CASSANDRA-15410?focusedCommentId=16975536&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16975536], provide noticeably speedup comparing with the original implementation that calls {{ByteBufUtil.writeUtf8}}. In the attached patch, I only reverted the improper invocations of {{writeAsciiString}} back to the new {{writeString}}. It should still provide a better performance comparing with the pre-40 code. 
 * The overall speedup for request execution may not be significant. The speedup of the encoding is at nanoseconds level, while, the query execution is at milliseconds level. Even if we are allowed to encode column names using {{writeAsciiString}}, unless there are thousands of columns to be filled, it should not affects the overall execution time a lot. 
 * I would argue to not fully revert back the optimization patch. Because the patch also avoids overallocation that reduces memory usage at runtime.  ;;;","19/Feb/21 15:11;aleksey;As others have said here, I don't believe we have a choice here, unfortunately. Of course there were people relying on lack of enforcement here. Sad to see the partial revert, but I'm on board with keeping compatibility. The lesson here is that we need more validation of user inputs instead of implicit convention.;;;","22/Feb/21 15:33;e.dimitrova;Thank  you all!

The patch looks good to me; we only need to update a bit the doc and I left just single small comment.

bq. The lesson here is that we need more validation of user inputs instead of implicit convention.

Absolutely agree with you.;;;","22/Feb/21 19:19;e.dimitrova;LGTM +1, I believe it is ready to commit after a squash and CHANGES.txt entry being added.

Thanks!;;;","22/Feb/21 21:45;yifanc;Starting commit

CI Results:
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16429-trunk-C3A7A246-F5BF-4A45-9CDF-2D455ADEF39A]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16429-trunk-C3A7A246-F5BF-4A45-9CDF-2D455ADEF39A]|[build|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/393/pipeline]|

The Circle and Jenkins runs have known test failures and they should not be related with the patch. ;;;","23/Feb/21 03:00;yifanc;Committed into trunk as [f32475a839e01e4eea3989871d293d70e8a360d7 |https://github.com/apache/cassandra/commit/f32475a839e01e4eea3989871d293d70e8a360d7];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
In-JVM dtest paging does not handle Group By correctly,CASSANDRA-16427,13357022,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,ifesdjeen,ifesdjeen,ifesdjeen,05/Feb/21 10:28,25/Feb/21 10:10,13/Jul/23 08:40,15/Feb/21 11:23,2.2.20,3.0.25,3.11.11,4.0,4.0-rc1,,,Test/dtest/java,,,,0,,,"In-JVM dtest paging is using a pager that disregards the type of the executed query, resulting into `GROUP BY` queries being executed like normal SELECT queries without GROUP BY clause.",,adelapena,ifesdjeen,jeromatron,maedhroz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16307,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,ifesdjeen,,,,,,,,,,,,,Correctness -> Recoverable Corruption / Loss,,,,,,,,Normal,Fuzz Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Feb 15 11:23:16 UTC 2021,,,,,,,All,,,,"0|z0nejk:",9223372036854775807,,,,adelapena,ifesdjeen,maedhroz,,Normal,,2.2.10,,https://github.com/apache/cassandra/commit/4c3b42612037a74cb7095bdc8485ff42f747b2b4,,,,,,,,,Tested with Harry. Small repro is included into applicable branches. Harry tests pending.,,,,,"05/Feb/21 17:10;ifesdjeen;|[trunk|https://github.com/apache/cassandra/compare/trunk...ifesdjeen:16427-trunk]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=16427-trunk]|
|[3.0|https://github.com/apache/cassandra/compare/cassandra-3.0...ifesdjeen:16427-3.0]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=16427-3.0]|
|[3.11|https://github.com/apache/cassandra/compare/cassandra-3.11...ifesdjeen:16427-3.11]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=16427-3.11]|
|[2.2|https://github.com/apache/cassandra/compare/cassandra-2.2...ifesdjeen:16427-2.2]|[CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=16427-2.2]|

Disclaimer: some of the tests are still queued after several hours. However, CI seems to be ok with achange.;;;","09/Feb/21 18:15;adelapena;The patches look good to me. Just a couple of nits:

* {{ResultSet.ResultMetadata#getPagingState}} is marked in trunk as {{@VisibleForTesting}} in trunk but not in previous branches.
* The new {{GroupByTest}} systematically uses {{DistributedTestBase.withKeyspace}} in some tests, and {{"" + KEYSPACE + ""}} in others. Not a big deal but I think it would be nice if we did the same in all the tests.
* Could you please run the JVM upgrade dtests too?;;;","09/Feb/21 19:43;maedhroz;{quote}Could you please run the JVM upgrade dtests too?
{quote}
Just keep in mind {{UpgradeTest}} might fail until CASSANDRA-16387 is resolved.

-(I'd also run the Python dtests, given I think there are at least a couple things there that touch paging...)-;;;","09/Feb/21 22:02;maedhroz;LGTM, just a couple minor things...
 - -Should the new {{GroupByTest}} exist in the 3.0 patch?-
 - On the trunk patch, {{GroupByTest}}, line 61, there's a dangling closing parenthesis.
 - {{public static Iterator<Object[]> toObjects(ResultSet rs)}} looks like it was moved in the 3.0 branch but not trunk.;;;","09/Feb/21 22:13;adelapena;{quote} - Should the new {{GroupByTest}} exist in the 3.0 patch?{quote}
I think {{GROUP BY}} was introduced in 3.10.;;;","10/Feb/21 15:45;ifesdjeen;Thank you for the review! I've addressed all of your concerns, and am re-running tests right now.
{quote}I'd also run the Python dtests, given I think there are at least a couple things there that touch paging...
{quote}
[~maedhroz] since we're only touching dtest code here and not production code, I think it shuold be ok if we skip python dtests. ;;;","11/Feb/21 18:49;adelapena;Changes look good to me, +1 assuming CI looks good.;;;","15/Feb/21 11:23;ifesdjeen;Committed to 2.2 with [4c3b42612037a74cb7095bdc8485ff42f747b2b4|https://github.com/apache/cassandra/commit/4c3b42612037a74cb7095bdc8485ff42f747b2b4], and merged up to [3.0|https://github.com/apache/cassandra/commit/e538df5e50905e71882e6fbacd835ad333190dba], [3.11|https://github.com/apache/cassandra/commit/b4beebd55a5ebc8d32bb3e6c74c7b8d9797ba14a], and trunk [https://github.com/apache/cassandra/commit/21217671367bf9fcfeec3a4f2e8855183068997b].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve handling of repair sessions during startup/shutdown,CASSANDRA-16425,13357005,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,marcuse,marcuse,marcuse,05/Feb/21 09:24,08/Mar/21 17:13,13/Jul/23 08:40,08/Mar/21 17:03,4.0,4.0-rc1,,,,,,Consistency/Repair,,,,0,,,We should send out a fail message on clean shutdown and if we find an ongoing repair session during startup we should fail it and tell participants.,,aholmber,bereng,clohfink,marcuse,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,marcuse,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Low Hanging Fruit,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Mar 08 17:03:48 UTC 2021,,,,,,,All,,,,"0|z0nefs:",9223372036854775807,,,,aholmber,clohfink,mck,,Low,,4.0-alpha2,,https://github.com/apache/cassandra/commit/5c84ed9ae8227e550630768a47fef7b2d1f1f1d7 https://github.com/apache/cassandra-dtest/commit/ad8ecc8ba492ad2492b57ead65593e0221182198,,,,,,,,,unit test updated,,,,,"05/Feb/21 09:29;marcuse;https://github.com/krummas/cassandra/commits/marcuse/16425
https://app.circleci.com/pipelines/github/krummas/cassandra?branch=marcuse%2F16425;;;","08/Feb/21 16:39;clohfink;failed test looks like flakey unrelated thing if can double check that.

+1;;;","20/Feb/21 23:17;mck;It [looks|https://ci-cassandra.apache.org/job/Cassandra-devbranch/392/#showFailuresLink] like this breaks the following three dtests:
- [repair_tests.incremental_repair_test.TestIncRepair.test_manual_session_fail|https://ci-cassandra.apache.org/job/Cassandra-devbranch/392/testReport/junit/dtest.repair_tests.incremental_repair_test/TestIncRepair/test_manual_session_fail/]
- [repair_tests.incremental_repair_test.TestIncRepair.test_manual_session_cancel_non_coordinator_failure|https://ci-cassandra.apache.org/job/Cassandra-devbranch/392/testReport/junit/dtest.repair_tests.incremental_repair_test/TestIncRepair/test_manual_session_cancel_non_coordinator_failure/]
- [repair_tests.incremental_repair_test.TestIncRepair.test_manual_session_force_cancel|https://ci-cassandra.apache.org/job/Cassandra-devbranch/392/testReport/junit/dtest.repair_tests.incremental_repair_test/TestIncRepair/test_manual_session_force_cancel/]

Confirmed locally as well.;;;","22/Feb/21 08:36;bereng;[~mck] contacted me asking if there was some duplication or overlap between this one and CASSANDRA-16446. I think they touch on the same area but on different points. Whereas [~marcuse] is looking to have a clean startup/shutdown, which is perfectly valid, the other ticket tries to not leak them in the first place. I think they complement each other and are both valid if I am not missing anything.;;;","22/Feb/21 13:26;marcuse;ah thanks for noticing [~mck]

reason for the failures is that the node is bounced after adding the repair sessions to the table, which are then removed on startup by this patch

migrated the tests to in-jvm dtests in the branch above and removed them from the python dtests here: https://github.com/krummas/cassandra-dtest/commits/marcuse/16425;;;","02/Mar/21 12:29;mck;CI: [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/465/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/465/pipeline], 
based on
- [cassandra|https://github.com/krummas/cassandra/commits/marcuse/16425]
- [dtest|https://github.com/krummas/cassandra-dtest/commits/marcuse/16425];;;","05/Mar/21 18:43;aholmber;I ran with rebased patch and tests following all the CI noise from this week, and it looks pretty good. There is a lot of red at first glance, but I think the failures are known and not related:

- python dtests failing two tests, addressed by CASSANDRA-16483
- there are three jvm dtests failing everywhere, including trunk

One I haven't corroborated is {{testRecoverOverflowedExpirationWithSSTableScrub}} in j11_unit_tests.

https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16425
;;;","06/Mar/21 12:34;mck;CI run when through above, as well. {{testRecoverOverflowedExpirationWithSSTableScrub}} looks ok [here|https://ci-cassandra.apache.org/job/Cassandra-devbranch/465/testReport/org.apache.cassandra.cql3.validation.operations/TTLTest/].

Of the 19 failures, most  (like Adam writes) can be attributed to other tickets and work. But it's a bit difficult to see clearly and there's a few that don't make sense. Kicking off a new rebased CI to double check… [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/466/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/466/pipeline];;;","08/Mar/21 16:17;mck;The regressions from the above CI either cannot be reproduced locally or (for test_multi_partition_consistent_reads_after_write and test_resumable_rebuild)  are still the v5 crc known issues. 

+1;;;","08/Mar/21 17:03;mck;Committed as [5c84ed9ae8227e550630768a47fef7b2d1f1f1d7|https://github.com/apache/cassandra/commit/5c84ed9ae8227e550630768a47fef7b2d1f1f1d7] and [ad8ecc8ba492ad2492b57ead65593e0221182198|https://github.com/apache/cassandra-dtest/commit/ad8ecc8ba492ad2492b57ead65593e0221182198].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unsafe to run nodetool cleanup during bootstrap or decommission,CASSANDRA-16418,13356435,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,linzuro,jebaker,jebaker,03/Feb/21 09:15,23/Jan/23 22:45,13/Jul/23 08:40,23/Jan/23 22:45,4.0.8,4.1.1,5.0,,,,,Consistency/Bootstrap and Decommission,,,,0,,,"What we expected: Running a cleanup is a safe operation; the result of running a query after a cleanup should be the same as the result of running a query before a cleanup.

What actually happened: We ran a cleanup during a decommission. All the streamed data was silently deleted, the bootstrap did not fail, the cluster's data after the decommission was very different to the state before.

Why: Cleanups do not take into account pending ranges and so the cleanup thought that all the data that had just been streamed was redundant and so deleted it. We think that this is symmetric with bootstraps, though have not verified.

Not sure if this is technically a bug but it was very surprising (and seemingly undocumented) behaviour.

 ",,jaid,jebaker,leonz,linzuro,paulo,schlosna,shaunakdas,smiklosovic,,,,,,,,"linzuro opened a new pull request, #2061:
URL: https://github.com/apache/cassandra/pull/2061

   Changes:
   
   - Added check during cleanup to ensure the node has no pending ranges before proceeding
   - Bug from JIRA ticket did not exist for bootstrap due to existing safety check but the check was one level below other safeguard checks so moved it to same location
   
   To reproduce, run cleanup on a node receiving data while another node is being decommissioned. I created 20 sstables of data.
   
   patch by Lindsey Zurovchak; reviewed by Paulo Motta for [CASSANDRA-16418](https://issues.apache.org/jira/browse/CASSANDRA-16418)
   


;22/Dec/22 18:40;githubbot;600","pauloricardomg commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1058358818


##########
test/distributed/org/apache/cassandra/distributed/test/CleanupFailureTest.java:
##########
@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.carrotsearch.hppc.LongArrayList;

Review Comment:
   Please remove unused imports.



##########
test/distributed/org/apache/cassandra/distributed/test/CleanupFailureTest.java:
##########
@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.carrotsearch.hppc.LongArrayList;
+import org.apache.cassandra.db.ColumnFamilyStore;
+import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.db.lifecycle.View;
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.IInstanceConfig;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.test.ring.BootstrapTest;
+import org.apache.cassandra.io.sstable.format.SSTableReader;
+import org.apache.cassandra.schema.Schema;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.service.StorageService;
+import org.mortbay.util.IO;
+
+import static java.util.Arrays.asList;
+import static org.apache.cassandra.distributed.action.GossipHelper.bootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.decommission;
+import static org.apache.cassandra.distributed.action.GossipHelper.pullSchemaFrom;
+import static org.apache.cassandra.distributed.action.GossipHelper.statusToBootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.withProperty;
+import static org.apache.cassandra.distributed.api.Feature.GOSSIP;
+import static org.apache.cassandra.distributed.api.Feature.NATIVE_PROTOCOL;
+import static org.apache.cassandra.distributed.api.Feature.NETWORK;
+
+public class CleanupFailureTest extends TestBaseImpl
+{
+    private static Cluster CLUSTER;
+
+    @BeforeClass
+    public static void before() throws IOException
+    {
+        CLUSTER = init(Cluster.build()
+                              .withNodes(3)
+                              .withConfig(config -> config.with(NETWORK, GOSSIP, NATIVE_PROTOCOL))
+                              .start());
+    }
+
+    @AfterClass
+    public static void after()
+    {
+        if (CLUSTER != null)
+            CLUSTER.close();
+    }
+
+    @Test
+    public void testCleanupFailsDuringOngoingDecommission()
+    {
+        // set up keyspace and table
+        CLUSTER.schemaChange(""CREATE KEYSPACE IF NOT EXISTS "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""CREATE TABLE IF NOT EXISTS "" + KEYSPACE + "".tbl (pk int, ck int, v int, PRIMARY KEY (pk, ck))"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE system_distributed WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+
+        // disable autocompaction
+        CLUSTER.get(1).nodetoolResult(""disableautocompaction"", KEYSPACE).asserts().success();
+
+        // populate data and flush
+        for(int i=0; i < 20; i++){

Review Comment:
   add braces after newline according to Cassandra coding conventions



##########
test/distributed/org/apache/cassandra/distributed/test/CleanupFailureTest.java:
##########
@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.carrotsearch.hppc.LongArrayList;
+import org.apache.cassandra.db.ColumnFamilyStore;
+import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.db.lifecycle.View;
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.IInstanceConfig;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.test.ring.BootstrapTest;
+import org.apache.cassandra.io.sstable.format.SSTableReader;
+import org.apache.cassandra.schema.Schema;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.service.StorageService;
+import org.mortbay.util.IO;
+
+import static java.util.Arrays.asList;
+import static org.apache.cassandra.distributed.action.GossipHelper.bootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.decommission;
+import static org.apache.cassandra.distributed.action.GossipHelper.pullSchemaFrom;
+import static org.apache.cassandra.distributed.action.GossipHelper.statusToBootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.withProperty;
+import static org.apache.cassandra.distributed.api.Feature.GOSSIP;
+import static org.apache.cassandra.distributed.api.Feature.NATIVE_PROTOCOL;
+import static org.apache.cassandra.distributed.api.Feature.NETWORK;
+
+public class CleanupFailureTest extends TestBaseImpl
+{
+    private static Cluster CLUSTER;
+
+    @BeforeClass
+    public static void before() throws IOException
+    {
+        CLUSTER = init(Cluster.build()
+                              .withNodes(3)
+                              .withConfig(config -> config.with(NETWORK, GOSSIP, NATIVE_PROTOCOL))
+                              .start());
+    }
+
+    @AfterClass
+    public static void after()
+    {
+        if (CLUSTER != null)
+            CLUSTER.close();
+    }
+
+    @Test
+    public void testCleanupFailsDuringOngoingDecommission()
+    {
+        // set up keyspace and table
+        CLUSTER.schemaChange(""CREATE KEYSPACE IF NOT EXISTS "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""CREATE TABLE IF NOT EXISTS "" + KEYSPACE + "".tbl (pk int, ck int, v int, PRIMARY KEY (pk, ck))"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE system_distributed WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+
+        // disable autocompaction
+        CLUSTER.get(1).nodetoolResult(""disableautocompaction"", KEYSPACE).asserts().success();
+
+        // populate data and flush
+        for(int i=0; i < 20; i++){
+            CLUSTER.get(1).coordinator().execute(""INSERT INTO "" + KEYSPACE + "".tbl (pk, ck, v) VALUES (?, ?, ?)"",
+                    ConsistencyLevel.ALL,
+                    1, i, i);
+            CLUSTER.get(1).flush(KEYSPACE);
+        }
+
+        // assert data has been populated
+        Object[][] beforeDecommResponse = CLUSTER.get(1).executeInternal(""SELECT * FROM "" + KEYSPACE + "".tbl ;"");

Review Comment:
   This is querying data from a single node, I think we can assert the global state instead with:
   ```java
   Object[][] beforeDecommResponse = CLUSTER.coordinator(1).execute(""SELECT * FROM "" + KEYSPACE + "".tbl ;"", ConsistencyLevel.ONE);
   ```



##########
test/distributed/org/apache/cassandra/distributed/test/CleanupFailureTest.java:
##########
@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.carrotsearch.hppc.LongArrayList;
+import org.apache.cassandra.db.ColumnFamilyStore;
+import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.db.lifecycle.View;
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.IInstanceConfig;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.test.ring.BootstrapTest;
+import org.apache.cassandra.io.sstable.format.SSTableReader;
+import org.apache.cassandra.schema.Schema;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.service.StorageService;
+import org.mortbay.util.IO;
+
+import static java.util.Arrays.asList;
+import static org.apache.cassandra.distributed.action.GossipHelper.bootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.decommission;
+import static org.apache.cassandra.distributed.action.GossipHelper.pullSchemaFrom;
+import static org.apache.cassandra.distributed.action.GossipHelper.statusToBootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.withProperty;
+import static org.apache.cassandra.distributed.api.Feature.GOSSIP;
+import static org.apache.cassandra.distributed.api.Feature.NATIVE_PROTOCOL;
+import static org.apache.cassandra.distributed.api.Feature.NETWORK;
+
+public class CleanupFailureTest extends TestBaseImpl
+{
+    private static Cluster CLUSTER;
+
+    @BeforeClass
+    public static void before() throws IOException
+    {
+        CLUSTER = init(Cluster.build()
+                              .withNodes(3)
+                              .withConfig(config -> config.with(NETWORK, GOSSIP, NATIVE_PROTOCOL))
+                              .start());
+    }
+
+    @AfterClass
+    public static void after()
+    {
+        if (CLUSTER != null)
+            CLUSTER.close();
+    }
+
+    @Test
+    public void testCleanupFailsDuringOngoingDecommission()
+    {
+        // set up keyspace and table
+        CLUSTER.schemaChange(""CREATE KEYSPACE IF NOT EXISTS "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""CREATE TABLE IF NOT EXISTS "" + KEYSPACE + "".tbl (pk int, ck int, v int, PRIMARY KEY (pk, ck))"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE system_distributed WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+
+        // disable autocompaction
+        CLUSTER.get(1).nodetoolResult(""disableautocompaction"", KEYSPACE).asserts().success();
+
+        // populate data and flush
+        for(int i=0; i < 20; i++){
+            CLUSTER.get(1).coordinator().execute(""INSERT INTO "" + KEYSPACE + "".tbl (pk, ck, v) VALUES (?, ?, ?)"",
+                    ConsistencyLevel.ALL,
+                    1, i, i);

Review Comment:
   I was not able to make this test fail after commenting out the `Node is receiving data. Not safe to run cleanup` safeguard. Since the PK is fixed at `pk=1`, this means all rows will map to a single node, making this harder to reproduce, since we need the rows to be reassigned to `node2` after decommission. I was able to reproduce this by making `pk=i` what creates 20 partitions and makes this easier to reproduce.



##########
test/distributed/org/apache/cassandra/distributed/test/CleanupFailureTest.java:
##########
@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;

Review Comment:
   Maybe move the test to the `org.apache.cassandra.distributed.test.ring` package where other range movement tests are located (bootstrap/decom/etc).



##########
test/distributed/org/apache/cassandra/distributed/test/CleanupFailureTest.java:
##########
@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.carrotsearch.hppc.LongArrayList;
+import org.apache.cassandra.db.ColumnFamilyStore;
+import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.db.lifecycle.View;
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.IInstanceConfig;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.test.ring.BootstrapTest;
+import org.apache.cassandra.io.sstable.format.SSTableReader;
+import org.apache.cassandra.schema.Schema;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.service.StorageService;
+import org.mortbay.util.IO;
+
+import static java.util.Arrays.asList;
+import static org.apache.cassandra.distributed.action.GossipHelper.bootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.decommission;
+import static org.apache.cassandra.distributed.action.GossipHelper.pullSchemaFrom;
+import static org.apache.cassandra.distributed.action.GossipHelper.statusToBootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.withProperty;
+import static org.apache.cassandra.distributed.api.Feature.GOSSIP;
+import static org.apache.cassandra.distributed.api.Feature.NATIVE_PROTOCOL;
+import static org.apache.cassandra.distributed.api.Feature.NETWORK;
+
+public class CleanupFailureTest extends TestBaseImpl
+{
+    private static Cluster CLUSTER;
+
+    @BeforeClass
+    public static void before() throws IOException
+    {
+        CLUSTER = init(Cluster.build()
+                              .withNodes(3)
+                              .withConfig(config -> config.with(NETWORK, GOSSIP, NATIVE_PROTOCOL))
+                              .start());
+    }
+
+    @AfterClass
+    public static void after()
+    {
+        if (CLUSTER != null)
+            CLUSTER.close();
+    }
+
+    @Test
+    public void testCleanupFailsDuringOngoingDecommission()
+    {
+        // set up keyspace and table
+        CLUSTER.schemaChange(""CREATE KEYSPACE IF NOT EXISTS "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""CREATE TABLE IF NOT EXISTS "" + KEYSPACE + "".tbl (pk int, ck int, v int, PRIMARY KEY (pk, ck))"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE system_distributed WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+
+        // disable autocompaction
+        CLUSTER.get(1).nodetoolResult(""disableautocompaction"", KEYSPACE).asserts().success();
+
+        // populate data and flush
+        for(int i=0; i < 20; i++){
+            CLUSTER.get(1).coordinator().execute(""INSERT INTO "" + KEYSPACE + "".tbl (pk, ck, v) VALUES (?, ?, ?)"",
+                    ConsistencyLevel.ALL,
+                    1, i, i);
+            CLUSTER.get(1).flush(KEYSPACE);
+        }
+
+        // assert data has been populated
+        Object[][] beforeDecommResponse = CLUSTER.get(1).executeInternal(""SELECT * FROM "" + KEYSPACE + "".tbl ;"");
+        Assert.assertEquals(20, beforeDecommResponse.length);
+
+        // assert 20 sstables

Review Comment:
   I don't think we need 20 sstables to reproduce this test, as it seems to be reproducible with a single sstable. To make this simpler I think we don't need to flush after inserting each row nor assert the number of sstables.



;28/Dec/22 15:21;githubbot;600","pauloricardomg commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1058405450


##########
test/distributed/org/apache/cassandra/distributed/test/CleanupFailureTest.java:
##########
@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.carrotsearch.hppc.LongArrayList;
+import org.apache.cassandra.db.ColumnFamilyStore;
+import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.db.lifecycle.View;
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.IInstanceConfig;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.test.ring.BootstrapTest;
+import org.apache.cassandra.io.sstable.format.SSTableReader;
+import org.apache.cassandra.schema.Schema;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.service.StorageService;
+import org.mortbay.util.IO;
+
+import static java.util.Arrays.asList;
+import static org.apache.cassandra.distributed.action.GossipHelper.bootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.decommission;
+import static org.apache.cassandra.distributed.action.GossipHelper.pullSchemaFrom;
+import static org.apache.cassandra.distributed.action.GossipHelper.statusToBootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.withProperty;
+import static org.apache.cassandra.distributed.api.Feature.GOSSIP;
+import static org.apache.cassandra.distributed.api.Feature.NATIVE_PROTOCOL;
+import static org.apache.cassandra.distributed.api.Feature.NETWORK;
+
+public class CleanupFailureTest extends TestBaseImpl
+{
+    private static Cluster CLUSTER;
+
+    @BeforeClass
+    public static void before() throws IOException
+    {
+        CLUSTER = init(Cluster.build()
+                              .withNodes(3)
+                              .withConfig(config -> config.with(NETWORK, GOSSIP, NATIVE_PROTOCOL))
+                              .start());
+    }
+
+    @AfterClass
+    public static void after()
+    {
+        if (CLUSTER != null)
+            CLUSTER.close();
+    }
+
+    @Test
+    public void testCleanupFailsDuringOngoingDecommission()
+    {
+        // set up keyspace and table
+        CLUSTER.schemaChange(""CREATE KEYSPACE IF NOT EXISTS "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""CREATE TABLE IF NOT EXISTS "" + KEYSPACE + "".tbl (pk int, ck int, v int, PRIMARY KEY (pk, ck))"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE system_distributed WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+
+        // disable autocompaction
+        CLUSTER.get(1).nodetoolResult(""disableautocompaction"", KEYSPACE).asserts().success();
+
+        // populate data and flush
+        for(int i=0; i < 20; i++){
+            CLUSTER.get(1).coordinator().execute(""INSERT INTO "" + KEYSPACE + "".tbl (pk, ck, v) VALUES (?, ?, ?)"",
+                    ConsistencyLevel.ALL,
+                    1, i, i);
+            CLUSTER.get(1).flush(KEYSPACE);
+        }
+
+        // assert data has been populated
+        Object[][] beforeDecommResponse = CLUSTER.get(1).executeInternal(""SELECT * FROM "" + KEYSPACE + "".tbl ;"");
+        Assert.assertEquals(20, beforeDecommResponse.length);
+
+        // assert 20 sstables

Review Comment:
   I don't think we need 20 sstables to reproduce this test, as it seems to be reproducible with a single sstable.



;28/Dec/22 20:40;githubbot;600","pauloricardomg commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1058405450


##########
test/distributed/org/apache/cassandra/distributed/test/CleanupFailureTest.java:
##########
@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.carrotsearch.hppc.LongArrayList;
+import org.apache.cassandra.db.ColumnFamilyStore;
+import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.db.lifecycle.View;
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.IInstanceConfig;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.test.ring.BootstrapTest;
+import org.apache.cassandra.io.sstable.format.SSTableReader;
+import org.apache.cassandra.schema.Schema;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.service.StorageService;
+import org.mortbay.util.IO;
+
+import static java.util.Arrays.asList;
+import static org.apache.cassandra.distributed.action.GossipHelper.bootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.decommission;
+import static org.apache.cassandra.distributed.action.GossipHelper.pullSchemaFrom;
+import static org.apache.cassandra.distributed.action.GossipHelper.statusToBootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.withProperty;
+import static org.apache.cassandra.distributed.api.Feature.GOSSIP;
+import static org.apache.cassandra.distributed.api.Feature.NATIVE_PROTOCOL;
+import static org.apache.cassandra.distributed.api.Feature.NETWORK;
+
+public class CleanupFailureTest extends TestBaseImpl
+{
+    private static Cluster CLUSTER;
+
+    @BeforeClass
+    public static void before() throws IOException
+    {
+        CLUSTER = init(Cluster.build()
+                              .withNodes(3)
+                              .withConfig(config -> config.with(NETWORK, GOSSIP, NATIVE_PROTOCOL))
+                              .start());
+    }
+
+    @AfterClass
+    public static void after()
+    {
+        if (CLUSTER != null)
+            CLUSTER.close();
+    }
+
+    @Test
+    public void testCleanupFailsDuringOngoingDecommission()
+    {
+        // set up keyspace and table
+        CLUSTER.schemaChange(""CREATE KEYSPACE IF NOT EXISTS "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""CREATE TABLE IF NOT EXISTS "" + KEYSPACE + "".tbl (pk int, ck int, v int, PRIMARY KEY (pk, ck))"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE system_distributed WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+
+        // disable autocompaction
+        CLUSTER.get(1).nodetoolResult(""disableautocompaction"", KEYSPACE).asserts().success();
+
+        // populate data and flush
+        for(int i=0; i < 20; i++){
+            CLUSTER.get(1).coordinator().execute(""INSERT INTO "" + KEYSPACE + "".tbl (pk, ck, v) VALUES (?, ?, ?)"",
+                    ConsistencyLevel.ALL,
+                    1, i, i);
+            CLUSTER.get(1).flush(KEYSPACE);
+        }
+
+        // assert data has been populated
+        Object[][] beforeDecommResponse = CLUSTER.get(1).executeInternal(""SELECT * FROM "" + KEYSPACE + "".tbl ;"");
+        Assert.assertEquals(20, beforeDecommResponse.length);
+
+        // assert 20 sstables

Review Comment:
   I think we don't need 20 sstables to reproduce this scenario, as it seems to be reproducible with a single sstable.



;28/Dec/22 20:42;githubbot;600","pauloricardomg commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1058405765


##########
test/distributed/org/apache/cassandra/distributed/test/CleanupFailureTest.java:
##########
@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.carrotsearch.hppc.LongArrayList;
+import org.apache.cassandra.db.ColumnFamilyStore;
+import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.db.lifecycle.View;
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.IInstanceConfig;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.test.ring.BootstrapTest;
+import org.apache.cassandra.io.sstable.format.SSTableReader;
+import org.apache.cassandra.schema.Schema;
+import org.apache.cassandra.schema.TableMetadata;
+import org.apache.cassandra.service.StorageService;
+import org.mortbay.util.IO;
+
+import static java.util.Arrays.asList;
+import static org.apache.cassandra.distributed.action.GossipHelper.bootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.decommission;
+import static org.apache.cassandra.distributed.action.GossipHelper.pullSchemaFrom;
+import static org.apache.cassandra.distributed.action.GossipHelper.statusToBootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.withProperty;
+import static org.apache.cassandra.distributed.api.Feature.GOSSIP;
+import static org.apache.cassandra.distributed.api.Feature.NATIVE_PROTOCOL;
+import static org.apache.cassandra.distributed.api.Feature.NETWORK;
+
+public class CleanupFailureTest extends TestBaseImpl
+{
+    private static Cluster CLUSTER;
+
+    @BeforeClass
+    public static void before() throws IOException
+    {
+        CLUSTER = init(Cluster.build()
+                              .withNodes(3)
+                              .withConfig(config -> config.with(NETWORK, GOSSIP, NATIVE_PROTOCOL))
+                              .start());
+    }
+
+    @AfterClass
+    public static void after()
+    {
+        if (CLUSTER != null)
+            CLUSTER.close();
+    }
+
+    @Test
+    public void testCleanupFailsDuringOngoingDecommission()
+    {
+        // set up keyspace and table
+        CLUSTER.schemaChange(""CREATE KEYSPACE IF NOT EXISTS "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""CREATE TABLE IF NOT EXISTS "" + KEYSPACE + "".tbl (pk int, ck int, v int, PRIMARY KEY (pk, ck))"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE "" + KEYSPACE + "" WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+        CLUSTER.schemaChange(""ALTER KEYSPACE system_distributed WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};"");
+
+        // disable autocompaction
+        CLUSTER.get(1).nodetoolResult(""disableautocompaction"", KEYSPACE).asserts().success();
+
+        // populate data and flush
+        for(int i=0; i < 20; i++){

Review Comment:
   please add braces after newline according to Cassandra coding conventions



;28/Dec/22 20:43;githubbot;600","smiklosovic commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1069728342


##########
src/java/org/apache/cassandra/service/StorageService.java:
##########
@@ -3849,6 +3849,12 @@ public int forceKeyspaceCleanup(int jobs, String keyspaceName, String... tables)
         if (SchemaConstants.isLocalSystemKeyspace(keyspaceName))
             throw new RuntimeException(""Cleanup of the system keyspace is neither necessary nor wise"");
 
+        InetAddressAndPort localAddress = FBUtilities.getBroadcastAddressAndPort();
+        if (tokenMetadata.getPendingRanges(keyspaceName, localAddress).size() > 0)
+        {

Review Comment:
   nit: if `if` contains just one statement, we tend to omit the braces to save some space.
   
   nit: `FBUtilities.getBroadcastAddressAndPort()` can be used directly in `if`, I would statically import that method as well.



##########
test/distributed/org/apache/cassandra/distributed/test/ring/CleanupFailureTest.java:
##########
@@ -0,0 +1,111 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test.ring;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.IInstanceConfig;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.api.TokenSupplier;
+import org.apache.cassandra.distributed.shared.NetworkTopology;
+import org.apache.cassandra.distributed.test.TestBaseImpl;
+
+import static org.apache.cassandra.distributed.action.GossipHelper.statusToBootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.statusToDecommission;
+import static org.apache.cassandra.distributed.action.GossipHelper.withProperty;
+import static org.apache.cassandra.distributed.test.ring.BootstrapTest.populate;
+import static org.apache.cassandra.distributed.api.Feature.GOSSIP;
+import static org.apache.cassandra.distributed.api.Feature.NETWORK;
+
+public class CleanupFailureTest extends TestBaseImpl
+{
+    @Test
+    public void cleanupDuringDecommissionTest() throws Throwable
+    {
+        try (Cluster cluster = builder().withNodes(2)
+                                        .withTokenSupplier(TokenSupplier.evenlyDistributedTokens(2))

Review Comment:
   nit: static methods may bev in general imported, especially here in tests where it makes the tests less verbose. Holds for the very next line as well as for `Assert.assertEquals` and similar.



;13/Jan/23 17:22;githubbot;600","linzuro commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1072486690


##########
test/distributed/org/apache/cassandra/distributed/test/ring/CleanupFailureTest.java:
##########
@@ -0,0 +1,111 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test.ring;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.api.IInstanceConfig;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.api.NodeToolResult;
+import org.apache.cassandra.distributed.api.TokenSupplier;
+import org.apache.cassandra.distributed.shared.NetworkTopology;
+import org.apache.cassandra.distributed.test.TestBaseImpl;
+
+import static org.apache.cassandra.distributed.action.GossipHelper.statusToBootstrap;
+import static org.apache.cassandra.distributed.action.GossipHelper.statusToDecommission;
+import static org.apache.cassandra.distributed.action.GossipHelper.withProperty;
+import static org.apache.cassandra.distributed.test.ring.BootstrapTest.populate;
+import static org.apache.cassandra.distributed.api.Feature.GOSSIP;
+import static org.apache.cassandra.distributed.api.Feature.NETWORK;
+
+public class CleanupFailureTest extends TestBaseImpl
+{
+    @Test
+    public void cleanupDuringDecommissionTest() throws Throwable
+    {
+        try (Cluster cluster = builder().withNodes(2)
+                                        .withTokenSupplier(TokenSupplier.evenlyDistributedTokens(2))

Review Comment:
   thanks stefan - updated based on these comments!



;17/Jan/23 17:06;githubbot;600","smiklosovic commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1072607540


##########
test/distributed/org/apache/cassandra/distributed/test/ring/CleanupFailureTest.java:
##########
@@ -0,0 +1,112 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test.ring;
+
+import org.junit.Assert;

Review Comment:
   @linzuro this import is not used, it will error the build when there is an import which is unused.



;17/Jan/23 18:12;githubbot;600","smiklosovic commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1073989486


##########
test/unit/org/apache/cassandra/db/CleanupTest.java:
##########
@@ -117,9 +117,11 @@ public String getDatacenter(InetAddressAndPort endpoint)
     }
 
     @Test
-    public void testCleanup() throws ExecutionException, InterruptedException
+    public void testCleanup() throws ExecutionException, InterruptedException, UnknownHostException

Review Comment:
   isnt just `Throwable` enough? It will not hurt anything, if it fails, it fails.



;18/Jan/23 19:35;githubbot;600","smiklosovic commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1073989486


##########
test/unit/org/apache/cassandra/db/CleanupTest.java:
##########
@@ -117,9 +117,11 @@ public String getDatacenter(InetAddressAndPort endpoint)
     }
 
     @Test
-    public void testCleanup() throws ExecutionException, InterruptedException
+    public void testCleanup() throws ExecutionException, InterruptedException, UnknownHostException

Review Comment:
   isnt just `Throwable` enough? It will not hurt anything, if it fails, it fails. It is also future-proof.



;18/Jan/23 19:36;githubbot;600","linzuro commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1074004266


##########
test/unit/org/apache/cassandra/db/CleanupTest.java:
##########
@@ -117,9 +117,11 @@ public String getDatacenter(InetAddressAndPort endpoint)
     }
 
     @Test
-    public void testCleanup() throws ExecutionException, InterruptedException
+    public void testCleanup() throws ExecutionException, InterruptedException, UnknownHostException

Review Comment:
   wanted to follow the format of the other tests in being explicit. if we use throwable instead of explicit exceptions, should i rework the other tests in this class as well?



;18/Jan/23 19:47;githubbot;600","pauloricardomg commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1074010277


##########
test/unit/org/apache/cassandra/db/CleanupTest.java:
##########
@@ -117,9 +117,11 @@ public String getDatacenter(InetAddressAndPort endpoint)
     }
 
     @Test
-    public void testCleanup() throws ExecutionException, InterruptedException
+    public void testCleanup() throws ExecutionException, InterruptedException, UnknownHostException

Review Comment:
   I think it's fine to keep as is since the other tests follow the same pattern



;18/Jan/23 19:52;githubbot;600","smiklosovic commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1074015052


##########
test/unit/org/apache/cassandra/db/CleanupTest.java:
##########
@@ -117,9 +117,11 @@ public String getDatacenter(InetAddressAndPort endpoint)
     }
 
     @Test
-    public void testCleanup() throws ExecutionException, InterruptedException
+    public void testCleanup() throws ExecutionException, InterruptedException, UnknownHostException

Review Comment:
   Right ... interesting. @pauloricardomg do you think this might be just `Throwable` and we fix that at all other places? I think it is worth it and the change is cosmetic. I consider these explicitly enumerated exceptions for other test methods in this class quite unusual to be there ... I dont know I have ever seen it like that in Cassandra tests.



;18/Jan/23 19:56;githubbot;600","smiklosovic commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1074015052


##########
test/unit/org/apache/cassandra/db/CleanupTest.java:
##########
@@ -117,9 +117,11 @@ public String getDatacenter(InetAddressAndPort endpoint)
     }
 
     @Test
-    public void testCleanup() throws ExecutionException, InterruptedException
+    public void testCleanup() throws ExecutionException, InterruptedException, UnknownHostException

Review Comment:
   Right ... interesting. @pauloricardomg do you think this might be just `Throwable` and we fix that at all other places? I think it is worth it and the change is cosmetic. I consider these explicitly enumerated exceptions for other test methods in this class quite unusual to be there ... I dont know I have ever seen it like that in Cassandra tests.
   
   What do you think it should be like?



;18/Jan/23 19:57;githubbot;600","smiklosovic commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1074015052


##########
test/unit/org/apache/cassandra/db/CleanupTest.java:
##########
@@ -117,9 +117,11 @@ public String getDatacenter(InetAddressAndPort endpoint)
     }
 
     @Test
-    public void testCleanup() throws ExecutionException, InterruptedException
+    public void testCleanup() throws ExecutionException, InterruptedException, UnknownHostException

Review Comment:
   Right ... interesting. @pauloricardomg do you think this might be just `Throwable` and we fix that at all other places? I think it is worth it and the change is cosmetic. I consider these explicitly enumerated exceptions for other test methods in this class quite unusual to be there ... I dont know I have ever seen it like that in Cassandra tests.
   
   What do you think it should be like?
   
   I see the value in explicitly enumerated exceptions in cases when we would leak some resources by not properly managing them when e.g. ""close"" would throw an exception and we would not react on it because it would just propagate. I am not sure there are cases like this in this test class.



;18/Jan/23 20:00;githubbot;600","smiklosovic commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1074015052


##########
test/unit/org/apache/cassandra/db/CleanupTest.java:
##########
@@ -117,9 +117,11 @@ public String getDatacenter(InetAddressAndPort endpoint)
     }
 
     @Test
-    public void testCleanup() throws ExecutionException, InterruptedException
+    public void testCleanup() throws ExecutionException, InterruptedException, UnknownHostException

Review Comment:
   Right ... interesting. @pauloricardomg do you think this might be just `Throwable` and we fix that at all other places? I think it is worth it and the change is cosmetic. I consider these explicitly enumerated exceptions for other test methods in this class quite unusual to be there ... I dont know I have ever seen it like that in Cassandra tests.
   
   What do you think it should be like?
   
   I see the value in explicitly enumerated exceptions in cases when we would leak some resources by not properly managing them when e.g. ""close"" would throw an exception and we would not react on it because it would just propagate. I am not sure there are cases like this in this test class.
   
   edit: ah you already replied ... ok lets leave it as it is.



;18/Jan/23 20:03;githubbot;600","pauloricardomg commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1074024360


##########
test/unit/org/apache/cassandra/db/CleanupTest.java:
##########
@@ -117,9 +117,11 @@ public String getDatacenter(InetAddressAndPort endpoint)
     }
 
     @Test
-    public void testCleanup() throws ExecutionException, InterruptedException
+    public void testCleanup() throws ExecutionException, InterruptedException, UnknownHostException

Review Comment:
   I don't really mind and I think it's fine to keep it as it is since this is an old test, to keep the scope of this change small. But if we were to change I'd normally prefer `throws Exception` since this is usually sufficient to catch checked exceptions.



;18/Jan/23 20:08;githubbot;600","smiklosovic commented on code in PR #2061:
URL: https://github.com/apache/cassandra/pull/2061#discussion_r1074033208


##########
test/unit/org/apache/cassandra/db/CleanupTest.java:
##########
@@ -117,9 +117,11 @@ public String getDatacenter(InetAddressAndPort endpoint)
     }
 
     @Test
-    public void testCleanup() throws ExecutionException, InterruptedException
+    public void testCleanup() throws ExecutionException, InterruptedException, UnknownHostException

Review Comment:
   ok



;18/Jan/23 20:18;githubbot;600","asfgit closed pull request #2061: [CASSANDRA-16418]: Unsafe to run nodetool cleanup during bootstrap or decommission
URL: https://github.com/apache/cassandra/pull/2061


;23/Jan/23 22:44;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,11400,,,0,11400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,linzuro,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Jan 23 20:45:44 UTC 2023,,,paulo,,,,All,,,,"0|z0nax4:",9223372036854775807,,,,paulo,smiklosovic,,,Low,,3.0.0,,https://github.com/apache/cassandra/commit/8bb9c72f582de6bcc39522ba9ade91fd5bc22f67,,,,,,,,,"dtest, CHANGES.txt",,,,,"22/Dec/22 18:42;linzuro;Created [PR|https://github.com/apache/cassandra/pull/2061] for this and made the following changes:
 * Added check during cleanup to ensure the node has no pending ranges before proceeding
 * Bug did not exist for bootstrap due to existing safety check but the check was one level below other safeguard checks so moved it to same location;;;","28/Dec/22 15:21;paulo;Nice work [~linzuro]! The approach and test looks mostly good to me, added a few comments to the PR.

Can you add a similar regression test for bootstrap so we can detect if this is ever broken in the future? The test should fail when the bootstrap safeguard is removed. I think you can find some bootstrap dtest examples on {{{}org.apache.cassandra.distributed.test.ring.BootstrapTest{}}}.

I have submitted a preliminary CI run for your branch on:
 * [https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/2151/];;;","11/Jan/23 22:38;paulo;In order to check the tests were reliably reproducing the issue on Lindsey's [branch|https://github.com/apache/cassandra/pull/2061] I commented out the following excerpt:
{noformat}
        InetAddressAndPort localAddress = FBUtilities.getBroadcastAddressAndPort();
        Integer pendingRangesCount = tokenMetadata.getPendingRanges(keyspaceName, localAddress).size();

        if (pendingRangesCount > 0)
        {
            throw new RuntimeException(""Node is involved in cluster membership changes. Not safe to run cleanup."");
        }
{noformat}
And expected both [testCleanupFailsDuringOngoingDecommission|https://github.com/apache/cassandra/pull/2061/files#diff-68d2cd75caa0e4091c7206717116594bdcb0aab38f72f6d6afa44eac60466e13R41] and [testCleanupFailsDuringOngoingBootstrap|https://github.com/apache/cassandra/pull/2061/files#diff-68d2cd75caa0e4091c7206717116594bdcb0aab38f72f6d6afa44eac60466e13R85] to fail.

Even though the tests failed most of the time, sometimes the tests passed so data was not being wrongly cleaned up as expected.

The reason for this is that these tests require that the cleanup is executed between the sstables are transferred by streaming and the ring membership operation is finished. There is a small chance cleanup is not executed within this window so the issue will not reproduce, especially if we run this test on faster hardware.

I took a slightly different testing approach on [this commit|https://github.com/pauloricardomg/cassandra/blob/702f77d247893a51461823268ad6a20cd6c1a021/test/distributed/org/apache/cassandra/distributed/test/ring/CleanupFailureTest.java#L40] that inserts data while a node is bootstrapping or decommissioning and checks the data is present after a cleanup is run. This was able to reliably reproduce the issue when the excerpt above is commented out.

The updated test is more deterministic because we don't depend on streaming nor timing. Furthermore this makes the test faster since we don't need so many rows to reproduce the issue, which is needed with the streaming approach.

A nice benefit of this approach is that since we only run cleanup a single time while the node is bootstrapping/decommissioning, we're able to [verify that the cleanup fails with the expected error message|https://github.com/pauloricardomg/cassandra/blob/702f77d247893a51461823268ad6a20cd6c1a021/test/distributed/org/apache/cassandra/distributed/test/ring/CleanupFailureTest.java#L105].;;;","11/Jan/23 22:41;paulo;I rebased and squashed Lindsey's commit [on this branch|https://github.com/pauloricardomg/cassandra/tree/CASSANDRA-16418] + updated tests [from this commit|https://github.com/pauloricardomg/cassandra/commit/702f77d247893a51461823268ad6a20cd6c1a021] and submitted CI on https://github.com/pauloricardomg/cassandra/tree/CASSANDRA-16418 (still queued).

I think this is ready for a second round of review. [~JoshuaMcKenzie] [~stefan.miklosovic] would you have cycles to take a look?;;;","12/Jan/23 10:56;smiklosovic;could you please create a PR from your branch so we may potentially comment on it? ;;;","13/Jan/23 17:22;smiklosovic;I ve commented on this https://github.com/apache/cassandra/pull/2061/files

I am +1 on successful build.

Comments in the PR are just nits, I leave this to the author's discretion.;;;","17/Jan/23 18:16;smiklosovic;Thanks [~linzuro] for taking care of that. There is one unused import which fails the build. I am overall +1 when we build this successfully.

[~paulo] would you mind to take the lead here and eventually merge it, please?;;;","17/Jan/23 21:25;paulo;Prepared [~linzuro]'s patch for commit on 4.0/4.1/trunk and submitted CI:


|branch||CI||
|[CASSANDRA-16418-4.0|https://github.com/pauloricardomg/cassandra/tree/CASSANDRA-16418-4.0]|[#2202|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/2202/] (finished)|
|[CASSANDRA-16418-4.1|https://github.com/pauloricardomg/cassandra/tree/CASSANDRA-16418-4.1]|[#2203|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/2203/] (finished)|
|[CASSANDRA-16418-trunk|https://github.com/pauloricardomg/cassandra/tree/CASSANDRA-16418-trunk]|[#2204|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/2204/] (finished)|;;;","18/Jan/23 17:08;paulo;There seems to be a legit failure on [CleanupTest|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/2202/testReport/org.apache.cassandra.db/CleanupTest/testCleanup/];;;","19/Jan/23 00:26;paulo;Resubmitted CI after [test fix|https://github.com/linzuro/cassandra/commit/8de9c73d28291d2df67727ffcb7292f8c21b3442]:
|branch||CI||
|[CASSANDRA-16418-4.0|https://github.com/pauloricardomg/cassandra/tree/CASSANDRA-16418-4.0]|[#2205|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/2205/] (finished)|
|[CASSANDRA-16418-4.1|https://github.com/pauloricardomg/cassandra/tree/CASSANDRA-16418-4.1]|[#2206|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/2206/] (finished)|
|[CASSANDRA-16418-trunk|https://github.com/pauloricardomg/cassandra/tree/CASSANDRA-16418-trunk]|[#2207|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/2207/] (finished)|;;;","20/Jan/23 18:45;paulo;Test failures look unrelated - for instance [test_decommissioned_node_cant_rejoin|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/2205/testReport/junit/dtest.topology_test/TestTopology/test_decommissioned_node_cant_rejoin/] failed on 4.0 and [test_simultaneous_bootstrap|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/2207/testReport/junit/dtest-novnode.bootstrap_test/TestBootstrap/test_simultaneous_bootstrap/] on trunk, but they don't seem to be at all related to this ticket. I ran these tests locally on the respective branches and they're passing.

ok to merge [~smiklosovic]?;;;","23/Jan/23 20:45;smiklosovic;+1. thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Digest mismatches during upgrade,CASSANDRA-16415,13356117,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,yifanc,yifanc,02/Feb/21 05:12,19/Nov/21 06:49,13/Jul/23 08:40,01/Mar/21 12:57,3.0.25,3.11.11,4.0,4.0-rc1,,,,Consistency/Coordination,Test/dtest/java,,,0,,,"The test has been failing and can always be reproduced in the recent CI. 

Stack trace: 
{code:java}
junit.framework.AssertionFailedError: Found Digest Mismatch
 at org.apache.cassandra.distributed.upgrade.MixedModeReadTest.checkTraceForDigestMismatch(MixedModeReadTest.java:89)
 at org.apache.cassandra.distributed.upgrade.MixedModeReadTest.lambda$mixedModeReadColumnSubsetDigestCheck$0(MixedModeReadTest.java:63)
 at org.apache.cassandra.distributed.upgrade.UpgradeTestBase$TestCase.run(UpgradeTestBase.java:171)
 at org.apache.cassandra.distributed.upgrade.MixedModeReadTest.mixedModeReadColumnSubsetDigestCheck(MixedModeReadTest.java:76) {code}
The initial investigation shows that 
 * The test only fails in the setup phase of mixedModeReadColumnSubsetDigestCheck. The cluster version is *Versions.Major.v3X*
 * The test failure is likely a consequence of CASSANDRA-15962. After dropping the commit in branch cassandra-3.11 and rebuild the dtest jar, the upgrade test can pass. Meanwhile, dropping the other commits does not help. ",,adelapena,aholmber,dnk,jlewandowski,maedhroz,mck,yifanc,,,,,,,,,"jacek-lewandowski opened a new pull request #890:
URL: https://github.com/apache/cassandra/pull/890


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;08/Feb/21 10:04;githubbot;600","jacek-lewandowski opened a new pull request #892:
URL: https://github.com/apache/cassandra/pull/892


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Feb/21 09:16;githubbot;600","yifan-c commented on a change in pull request #891:
URL: https://github.com/apache/cassandra/pull/891#discussion_r576389387



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -38,20 +43,24 @@
 
 public class ColumnFilterTest
 {
+    private final static Logger logger = LoggerFactory.getLogger(ColumnFilterTest.class);

Review comment:
       nit: the logger is not used. please remove

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeReadTest.java
##########
@@ -26,26 +27,22 @@
 import org.apache.cassandra.distributed.UpgradeableCluster;
 import org.apache.cassandra.distributed.api.ConsistencyLevel;
 import org.apache.cassandra.distributed.api.Feature;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
+import org.apache.cassandra.distributed.api.IIsolatedExecutor;
+import org.apache.cassandra.distributed.api.IUpgradeableInstance;
 import org.apache.cassandra.distributed.impl.DelegatingInvokableInstance;
 import org.apache.cassandra.distributed.shared.DistributedTestBase;
 import org.apache.cassandra.distributed.shared.Versions;
 import org.apache.cassandra.gms.Gossiper;
 
+import static org.apache.cassandra.distributed.test.ReadDigestConsistencyTest.CREATE_TABLE;

Review comment:
       nit: please remove the unused imports




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Feb/21 22:24;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r576534635



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeReadTest.java
##########
@@ -67,26 +60,24 @@ public void mixedModeReadColumnSubsetDigestCheck() throws Throwable
             if (node != 1)
                 return; // shouldn't happen but guard for future test changes
 
+
+            // we need to let gossip settle or the test will fail
+            int attempts = 1;
+            //noinspection Convert2MethodRef
+            while (!((IInvokableInstance) (cluster.get(1))).callOnInstance(() -> Gossiper.instance.haveMajorVersion3Nodes()))
+            {
+                if (attempts++ > 30)
+                    throw new RuntimeException(""Gossiper.instance.isAnyNodeOn30() continually returns false despite expecting to be true"");
+                Thread.sleep(1000);
+            }
+
             // should not cause a disgest mismatch in mixed mode
+            logger.info(""Testing queries after upgrading - node1: {}, node2: {}"", cluster.get(1).getReleaseVersionString(), cluster.get(2).getReleaseVersionString());

Review comment:
       How about asserting the release version strings of the nodes instead of logging?

##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -158,38 +158,44 @@
 
     private volatile long lastProcessedMessageAt = System.currentTimeMillis();
 
-    //This property and anything that checks it should be removed in 5.0
-    private boolean haveMajorVersion3Nodes = true;
+    // This property and anything that checks it should be removed in 5.0
+    /**
+     * This property is initially set to null version which means that we have no information about the other nodes.
+     * Once we have information about the cluster, it is set to the earliest version encountered in the cluster.
+     * Once all nodes are on at least this node version, it becomes null, which means that we are not upgrading from
+     * the previous version (major, minor).
+     */
+    private CassandraVersion upgradeFromVersion = SystemKeyspace.NULL_VERSION;
 
-    final Supplier<ExpiringMemoizingSupplier.ReturnValue<Boolean>> haveMajorVersion3NodesSupplier = () ->
+    final Supplier<ExpiringMemoizingSupplier.ReturnValue<CassandraVersion>> upgradeFromVersionSupplier = () ->
     {
-        //Once there are no prior version nodes we don't need to keep rechecking
-        if (!haveMajorVersion3Nodes)
-            return new ExpiringMemoizingSupplier.Memoized<>(false);
+        // Once there are no prior version nodes we don't need to keep rechecking
+        if (upgradeFromVersion == null)
+            return new ExpiringMemoizingSupplier.Memoized<>(null);
 
         Iterable<InetAddressAndPort> allHosts = Iterables.concat(Gossiper.instance.getLiveMembers(), Gossiper.instance.getUnreachableMembers());
-        CassandraVersion referenceVersion = null;
 
+        CassandraVersion minVersion = SystemKeyspace.CURRENT_VERSION;
         for (InetAddressAndPort host : allHosts)
         {
             CassandraVersion version = getReleaseVersion(host);
 
             //Raced with changes to gossip state, wait until next iteration
             if (version == null)
-                return new ExpiringMemoizingSupplier.NotMemoized(true);
-
-            if (referenceVersion == null)
-                referenceVersion = version;
+                return new ExpiringMemoizingSupplier.NotMemoized<>(SystemKeyspace.NULL_VERSION);
 
-            if (version.major < 4)
-                return new ExpiringMemoizingSupplier.Memoized<>(true);
+            if (version.isLowerThan(minVersion.major, minVersion.minor)) {

Review comment:
       ```suggestion
               if (version.compareTo(minVersion) < 0) {
   ```

##########
File path: src/java/org/apache/cassandra/utils/CassandraVersion.java
##########
@@ -200,6 +200,11 @@ private static Integer tryParseInt(String str)
         }
     }
 
+    public boolean isLowerThan(int major, int minor)

Review comment:
       nit: the method can be removed. The ""lower than"" relationship can be expressed using compareTo, which is more comprehensive. 
   ```java
   // is version lower than 4.0.0?
   version.compareTo(new CassandraVersion(""4.0.0"")) < 0
   ``` 
   Having multiple methods that compare versions could be confusing. 

##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2130,7 +2136,12 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
 
     public boolean haveMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+        return isUpgradingFromVersionLowerThan(4, 0);
+    }
+
+    public boolean isUpgradingFromVersionLowerThan(int major, int minor) {
+        CassandraVersion v = upgradeFromVersionMemoized.get();
+        return v != null && v.isLowerThan(major, minor);

Review comment:
       `upgradeFromVersionMemoized` can also return `NULL_VERSION`, which is lower than any valid version... This is probably not the desired output. 




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Feb/21 05:10;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r576554260



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -158,38 +158,44 @@
 
     private volatile long lastProcessedMessageAt = System.currentTimeMillis();
 
-    //This property and anything that checks it should be removed in 5.0
-    private boolean haveMajorVersion3Nodes = true;
+    // This property and anything that checks it should be removed in 5.0
+    /**
+     * This property is initially set to null version which means that we have no information about the other nodes.
+     * Once we have information about the cluster, it is set to the earliest version encountered in the cluster.
+     * Once all nodes are on at least this node version, it becomes null, which means that we are not upgrading from
+     * the previous version (major, minor).
+     */
+    private CassandraVersion upgradeFromVersion = SystemKeyspace.NULL_VERSION;
 
-    final Supplier<ExpiringMemoizingSupplier.ReturnValue<Boolean>> haveMajorVersion3NodesSupplier = () ->
+    final Supplier<ExpiringMemoizingSupplier.ReturnValue<CassandraVersion>> upgradeFromVersionSupplier = () ->

Review comment:
       Somehow the comment lost... 
   
   One concern about the new supplier is that it is more expensive, since the prior version has a shortcut to exit early, but the new one has to iterate through all peers to find the `minVersion`. Should it have a higher chance to encounter the case that `getReleaseVersion` returns `null` and delay calculating the `minVersion`? 




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Feb/21 05:16;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r576802515



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeReadTest.java
##########
@@ -67,26 +60,24 @@ public void mixedModeReadColumnSubsetDigestCheck() throws Throwable
             if (node != 1)
                 return; // shouldn't happen but guard for future test changes
 
+
+            // we need to let gossip settle or the test will fail
+            int attempts = 1;
+            //noinspection Convert2MethodRef
+            while (!((IInvokableInstance) (cluster.get(1))).callOnInstance(() -> Gossiper.instance.haveMajorVersion3Nodes()))
+            {
+                if (attempts++ > 30)
+                    throw new RuntimeException(""Gossiper.instance.isAnyNodeOn30() continually returns false despite expecting to be true"");
+                Thread.sleep(1000);
+            }
+
             // should not cause a disgest mismatch in mixed mode
+            logger.info(""Testing queries after upgrading - node1: {}, node2: {}"", cluster.get(1).getReleaseVersionString(), cluster.get(2).getReleaseVersionString());

Review comment:
       The purpose of this message was to make it easy to find the time where the queries started to be executed so I could follow the logs. I can remove that if you insist




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Feb/21 12:57;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r576803466



##########
File path: src/java/org/apache/cassandra/utils/CassandraVersion.java
##########
@@ -200,6 +200,11 @@ private static Integer tryParseInt(String str)
         }
     }
 
+    public boolean isLowerThan(int major, int minor)

Review comment:
       ok




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Feb/21 12:58;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r576914359



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2130,7 +2136,12 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
 
     public boolean haveMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+        return isUpgradingFromVersionLowerThan(4, 0);
+    }
+
+    public boolean isUpgradingFromVersionLowerThan(int major, int minor) {
+        CassandraVersion v = upgradeFromVersionMemoized.get();
+        return v != null && v.isLowerThan(major, minor);

Review comment:
       This is actually what I wanted - my reasoning was like - until we have no information about the cluster, we should assume the most legacy behaviour, which means that this method returns `true` for any reference version




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Feb/21 15:32;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r576917604



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -158,38 +158,44 @@
 
     private volatile long lastProcessedMessageAt = System.currentTimeMillis();
 
-    //This property and anything that checks it should be removed in 5.0
-    private boolean haveMajorVersion3Nodes = true;
+    // This property and anything that checks it should be removed in 5.0
+    /**
+     * This property is initially set to null version which means that we have no information about the other nodes.
+     * Once we have information about the cluster, it is set to the earliest version encountered in the cluster.
+     * Once all nodes are on at least this node version, it becomes null, which means that we are not upgrading from
+     * the previous version (major, minor).
+     */
+    private CassandraVersion upgradeFromVersion = SystemKeyspace.NULL_VERSION;
 
-    final Supplier<ExpiringMemoizingSupplier.ReturnValue<Boolean>> haveMajorVersion3NodesSupplier = () ->
+    final Supplier<ExpiringMemoizingSupplier.ReturnValue<CassandraVersion>> upgradeFromVersionSupplier = () ->

Review comment:
       the comment was moved a bit, but not lost
   
   do you think we can safely assume there are maximum two different versions in the cluster? If so, we can break the loop once we find the first version which is lower than this node version




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Feb/21 15:36;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r576929902



##########
File path: src/java/org/apache/cassandra/utils/CassandraVersion.java
##########
@@ -200,6 +200,11 @@ private static Integer tryParseInt(String str)
         }
     }
 
+    public boolean isLowerThan(int major, int minor)

Review comment:
       Actually, I'd not remove it - the functionality it provides is not covered by simple version comparison because, for example:
   `4.0.0-SNAPSHOT < 4.0.0`
   
   Is there something which can be used as a lower bound for 4.0 family which does not look confusing?
   
   This mechanism is intended to detect minor version upgrades so we do not care what is going on in patch, pre-release or build component of the version because we should not have to change the behaviour of the node in such situation




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Feb/21 15:52;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577016054



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeReadTest.java
##########
@@ -67,26 +60,24 @@ public void mixedModeReadColumnSubsetDigestCheck() throws Throwable
             if (node != 1)
                 return; // shouldn't happen but guard for future test changes
 
+
+            // we need to let gossip settle or the test will fail
+            int attempts = 1;
+            //noinspection Convert2MethodRef
+            while (!((IInvokableInstance) (cluster.get(1))).callOnInstance(() -> Gossiper.instance.haveMajorVersion3Nodes()))
+            {
+                if (attempts++ > 30)
+                    throw new RuntimeException(""Gossiper.instance.isAnyNodeOn30() continually returns false despite expecting to be true"");
+                Thread.sleep(1000);
+            }
+
             // should not cause a disgest mismatch in mixed mode
+            logger.info(""Testing queries after upgrading - node1: {}, node2: {}"", cluster.get(1).getReleaseVersionString(), cluster.get(2).getReleaseVersionString());

Review comment:
       Logging is not very helpful when running on CI, meanwhile assertion is more explicit, hence the asking.
   It is just a nit (sorry for missing the disclaimer). Please pick whichever you are comfortable with. 




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Feb/21 17:46;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577042093



##########
File path: src/java/org/apache/cassandra/utils/CassandraVersion.java
##########
@@ -200,6 +200,11 @@ private static Integer tryParseInt(String str)
         }
     }
 
+    public boolean isLowerThan(int major, int minor)

Review comment:
       A 4.0 lower bound version constant can be defined, just as the one defined in `SystemKeyspace#CURRENT_VERSION`. The earliest canonical 4.0 version is `4.0-alpha1`, which can be used as the lower bound. 
   
   ```java
           v1 = new CassandraVersion(""4.0-alpha1"");
           v2 = new CassandraVersion(""4.0.0-snapshot"");
           v3 = new CassandraVersion(""4.0.0"");
           assertTrue(v1.compareTo(v2) < 0);
           assertTrue(v1.compareTo(v3) < 0);
   ```
   
   I partially agree that `isLowerThan` could be useful. But it can provide conflicting results with the example you are putting, hence confusing.
   
   ```java
           // using the vars defined above.
           assertNotEquals(v1.isLowerThan(4, 0), v1.compareTo(v3) < 0);
   ```




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Feb/21 18:25;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577043418



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2130,7 +2136,12 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
 
     public boolean haveMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+        return isUpgradingFromVersionLowerThan(4, 0);
+    }
+
+    public boolean isUpgradingFromVersionLowerThan(int major, int minor) {
+        CassandraVersion v = upgradeFromVersionMemoized.get();
+        return v != null && v.isLowerThan(major, minor);

Review comment:
       what happens when upgrading cluster from `4.0.0` to `4.0.1`? Do we expect `NULL_VERSION` being returned and doing the more expensive digest query during upgrade? The upgrade process in a large cluster can be time consuming.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Feb/21 18:27;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577060773



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -158,38 +158,44 @@
 
     private volatile long lastProcessedMessageAt = System.currentTimeMillis();
 
-    //This property and anything that checks it should be removed in 5.0
-    private boolean haveMajorVersion3Nodes = true;
+    // This property and anything that checks it should be removed in 5.0
+    /**
+     * This property is initially set to null version which means that we have no information about the other nodes.
+     * Once we have information about the cluster, it is set to the earliest version encountered in the cluster.
+     * Once all nodes are on at least this node version, it becomes null, which means that we are not upgrading from
+     * the previous version (major, minor).
+     */
+    private CassandraVersion upgradeFromVersion = SystemKeyspace.NULL_VERSION;
 
-    final Supplier<ExpiringMemoizingSupplier.ReturnValue<Boolean>> haveMajorVersion3NodesSupplier = () ->
+    final Supplier<ExpiringMemoizingSupplier.ReturnValue<CassandraVersion>> upgradeFromVersionSupplier = () ->

Review comment:
       The cluster wide version check is a special treatment for specific versions, i.e. 3.4 and `v < 4`. What if we keep the checker as-is and always using the `3.4-` behavior during upgrade? 
   It could be more expensive (by how much? probably not a lot) during that time period, but the gain is the simplification. 
   
   In practice, I think there won't be a case that the upgrading cluster have nodes in `3.4-`, `3.11` and `4.0`. The upgrading path is most likely either 3.0 -> 4.0, or 3.x -> 4.0. With such assumption, if we want to lower the data size being queried, we can define a temporarily system property in the 4.0 version to select the behavior. e.g. `cassandra.upgrading_from_3_0_plus`, according to the value use the corresponding behavior. The property, the same as `Gossiper#upgradeFromVersion`, should be removed in 5.0. If we are adding the property, we need to document it in the `NEWS.txt` too in order to inform the instructor when upgrading. 
   (Maybe just using the `3.4-` behavior is the best option, as it add complexity in operations)




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Feb/21 18:54;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577515753



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeReadTest.java
##########
@@ -67,26 +60,24 @@ public void mixedModeReadColumnSubsetDigestCheck() throws Throwable
             if (node != 1)
                 return; // shouldn't happen but guard for future test changes
 
+
+            // we need to let gossip settle or the test will fail
+            int attempts = 1;
+            //noinspection Convert2MethodRef
+            while (!((IInvokableInstance) (cluster.get(1))).callOnInstance(() -> Gossiper.instance.haveMajorVersion3Nodes()))
+            {
+                if (attempts++ > 30)
+                    throw new RuntimeException(""Gossiper.instance.isAnyNodeOn30() continually returns false despite expecting to be true"");
+                Thread.sleep(1000);
+            }
+
             // should not cause a disgest mismatch in mixed mode
+            logger.info(""Testing queries after upgrading - node1: {}, node2: {}"", cluster.get(1).getReleaseVersionString(), cluster.get(2).getReleaseVersionString());

Review comment:
       I'll remove it then




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 10:57;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577522468



##########
File path: src/java/org/apache/cassandra/utils/CassandraVersion.java
##########
@@ -200,6 +200,11 @@ private static Integer tryParseInt(String str)
         }
     }
 
+    public boolean isLowerThan(int major, int minor)

Review comment:
       I think I should name it differently `isMajorMinorLowerThan` or have another method `trim` which would return `CassandraVersion(major + ""."" + minor)` - would that work better for you?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 11:07;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577531522



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2130,7 +2136,12 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
 
     public boolean haveMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+        return isUpgradingFromVersionLowerThan(4, 0);
+    }
+
+    public boolean isUpgradingFromVersionLowerThan(int major, int minor) {
+        CassandraVersion v = upgradeFromVersionMemoized.get();
+        return v != null && v.isLowerThan(major, minor);

Review comment:
       Given we use `isLowerThan(major, minor)`, the supplier will not detect any upgrade because `isLowerThan(4, 0)` returns false in all cases. So we only need the Gossiper to figure out versions of other nodes.
   
   We start from `NULL_VERSION`, so we reduce the significantly digest mismatches during the phase when the Gossiper does not know the versions around the cluster. Another advantage of this approach is the monotonicity of the attribute we use to keep the current minimum version - once it is set to null (the cluster is consistent and stable) we avoid further checks. 
   
   Disadvantage is that when we do not do the minor version upgrade (we do patch version upgrade or we just restart the cluster), we will run in legacy mode until the Gossiper detects versions of all the nodes. 
   




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 11:22;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577535622



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -158,38 +158,44 @@
 
     private volatile long lastProcessedMessageAt = System.currentTimeMillis();
 
-    //This property and anything that checks it should be removed in 5.0
-    private boolean haveMajorVersion3Nodes = true;
+    // This property and anything that checks it should be removed in 5.0
+    /**
+     * This property is initially set to null version which means that we have no information about the other nodes.
+     * Once we have information about the cluster, it is set to the earliest version encountered in the cluster.
+     * Once all nodes are on at least this node version, it becomes null, which means that we are not upgrading from
+     * the previous version (major, minor).
+     */
+    private CassandraVersion upgradeFromVersion = SystemKeyspace.NULL_VERSION;
 
-    final Supplier<ExpiringMemoizingSupplier.ReturnValue<Boolean>> haveMajorVersion3NodesSupplier = () ->
+    final Supplier<ExpiringMemoizingSupplier.ReturnValue<CassandraVersion>> upgradeFromVersionSupplier = () ->

Review comment:
       I was thinking about that but came into conclusion that unfortunately we could not do that. Look, while 4.0 notices the upgrade from 3.11 and it can act in whichever way we decide, 3.11 will work as usual and use 3.11 `ColumnFilter`. That's why we cannot just simply make 4.0 work in 3.0 compatibility mode when upgrading from any 3.0 or 3.11.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 11:29;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577522468



##########
File path: src/java/org/apache/cassandra/utils/CassandraVersion.java
##########
@@ -200,6 +200,11 @@ private static Integer tryParseInt(String str)
         }
     }
 
+    public boolean isLowerThan(int major, int minor)

Review comment:
       I think I should name it differently `isMajorMinorLowerThan` or have another method `family` which would return `CassandraVersion(major + ""."" + minor)` - would that work better for you?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 12:51;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577522468



##########
File path: src/java/org/apache/cassandra/utils/CassandraVersion.java
##########
@@ -200,6 +200,11 @@ private static Integer tryParseInt(String str)
         }
     }
 
+    public boolean isLowerThan(int major, int minor)

Review comment:
       I think I should name it differently `isMajorMinorLowerThan` or have another method `family` / `trimToFamily` which would return `CassandraVersion(major + ""."" + minor)` - would that work better for you?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 12:52;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577854789



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2130,7 +2136,12 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
 
     public boolean haveMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+        return isUpgradingFromVersionLowerThan(4, 0);
+    }
+
+    public boolean isUpgradingFromVersionLowerThan(int major, int minor) {
+        CassandraVersion v = upgradeFromVersionMemoized.get();
+        return v != null && v.isLowerThan(major, minor);

Review comment:
       I do not worry about if the checker has gone to the step to check with `isLowerThan`. 
   
   The concern comes from the line#188-189, where `NULL_VERSION` can be returned if the release version grabbed from peer is null. It can happen during any non-major upgrade. We should avoid such scenario.
   
   ```java
               if (version == null)
                   return new ExpiringMemoizingSupplier.NotMemoized<>(SystemKeyspace.NULL_VERSION);
   ```




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 18:42;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577856470



##########
File path: src/java/org/apache/cassandra/utils/CassandraVersion.java
##########
@@ -200,6 +200,11 @@ private static Integer tryParseInt(String str)
         }
     }
 
+    public boolean isLowerThan(int major, int minor)

Review comment:
       I do not like it due to the redundancy, but can be fine with it if you insist.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 18:45;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r577858163



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -158,38 +158,44 @@
 
     private volatile long lastProcessedMessageAt = System.currentTimeMillis();
 
-    //This property and anything that checks it should be removed in 5.0
-    private boolean haveMajorVersion3Nodes = true;
+    // This property and anything that checks it should be removed in 5.0
+    /**
+     * This property is initially set to null version which means that we have no information about the other nodes.
+     * Once we have information about the cluster, it is set to the earliest version encountered in the cluster.
+     * Once all nodes are on at least this node version, it becomes null, which means that we are not upgrading from
+     * the previous version (major, minor).
+     */
+    private CassandraVersion upgradeFromVersion = SystemKeyspace.NULL_VERSION;
 
-    final Supplier<ExpiringMemoizingSupplier.ReturnValue<Boolean>> haveMajorVersion3NodesSupplier = () ->
+    final Supplier<ExpiringMemoizingSupplier.ReturnValue<CassandraVersion>> upgradeFromVersionSupplier = () ->

Review comment:
       Fair. It is messy and hopefully we can do better in the later releases. 




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Feb/21 18:46;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r578199878



##########
File path: src/java/org/apache/cassandra/utils/CassandraVersion.java
##########
@@ -200,6 +200,11 @@ private static Integer tryParseInt(String str)
         }
     }
 
+    public boolean isLowerThan(int major, int minor)

Review comment:
       Would you be fine if we had a method like:
   
   ```java
   public CassandraVersion familyLowerBound() {
       return new CassandraVersion(major, minor, 0, NO_HOTFIX, new String[0], null);
   }
   ```
   ?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Feb/21 07:54;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r578204362



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2130,7 +2136,12 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
 
     public boolean haveMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+        return isUpgradingFromVersionLowerThan(4, 0);
+    }
+
+    public boolean isUpgradingFromVersionLowerThan(int major, int minor) {
+        CassandraVersion v = upgradeFromVersionMemoized.get();
+        return v != null && v.isLowerThan(major, minor);

Review comment:
       So this is about which type of upgrades we want to optimise for during that ephemeral period - if for 3 -> 4, then we should stay with the current approach, if for 4 -> 4, we should just skip hosts with `null` version. 
   
   I was wondering if there is a way to figure out whether the node has started for the first time with Cassandra 3 data (first started after upgrade). SSTable format has changed to `na` but I don't know if we force rewrite some system tables to the new format after startup. I'm just saying that if we could detect that the node has started for the first time after upgrading it from Cassandra 3, we could assume the current approach, otherwise we could skip null versions.
   




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Feb/21 08:02;githubbot;600","adelapena commented on a change in pull request #890:
URL: https://github.com/apache/cassandra/pull/890#discussion_r578407159



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -33,20 +38,24 @@
 
 public class ColumnFilterTest
 {
+    private final static Logger logger = LoggerFactory.getLogger(ColumnFilterTest.class);
+
     final static ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
 
+    private final Supplier<CFMetaData> metadataSupplier = Suppliers.memoize(() -> CFMetaData.Builder

Review comment:
       Do we need memoization here, instead of just plainly initializing the `CFMetadata`?

##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -33,20 +38,24 @@
 
 public class ColumnFilterTest
 {
+    private final static Logger logger = LoggerFactory.getLogger(ColumnFilterTest.class);

Review comment:
       It seems this logger is not used

##########
File path: test/distributed/org/apache/cassandra/distributed/test/ReadDigestConsistencyTest.java
##########
@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.util.Arrays;
+import java.util.UUID;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.shared.DistributedTestBase;
+
+public class ReadDigestConsistencyTest extends TestBaseImpl
+{
+    public static final String TABLE_NAME = ""tbl"";
+    public static final String CREATE_TABLE = String.format(""CREATE TABLE %s.%s (key int, s1 text static, c1 text, c2 text, c3 text, PRIMARY KEY (key, c1))"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+    public static final String INSERT = String.format(""INSERT INTO %s.%s (key, s1, c1, c2, c3) VALUES (?, ?, ?, ?, ?)"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+
+    public static final String SELECT_C1 = String.format(""SELECT key, c1 FROM %s.%s WHERE key = ?"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+    public static final String SELECT_C1_S1_ROW = String.format(""SELECT key, c1, s1 FROM %s.%s WHERE key = ? and c1 = ? "", DistributedTestBase.KEYSPACE, TABLE_NAME);
+    public static final String SELECT_TRACE = ""SELECT activity FROM system_traces.events where session_id = ? and source = ? ALLOW FILTERING;"";
+
+    @Test
+    public void testDigestConsistency() throws Exception
+    {
+        try (Cluster cluster = init(builder().withNodes(2).start()))
+        {
+            cluster.schemaChange(CREATE_TABLE);
+            cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""foo"", ""bar"", ""baz"");
+            cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""fi"", ""biz"", ""baz"");
+            cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""fo"", ""boz"", ""baz"");
+
+            checkTraceForDigestMismatch(cluster, 1, SELECT_C1, 1);
+            checkTraceForDigestMismatch(cluster, 2, SELECT_C1, 1);
+            checkTraceForDigestMismatch(cluster, 1, SELECT_C1_S1_ROW, 1, ""foo"");
+            checkTraceForDigestMismatch(cluster, 2, SELECT_C1_S1_ROW, 1, ""fi"");
+        }
+    }
+
+    public static void checkTraceForDigestMismatch(Cluster cluster, int coordinatorNode, String query, Object... boundValues)

Review comment:
       Nit: the method could be private.

##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -59,6 +68,17 @@ public void columnFilterSerialisationRoundTrip() throws Exception
         testRoundTrip(ColumnFilter.selection(metadata, metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
     }
 
+    @Test
+    public void testToString()
+    {
+        CFMetaData metadata = metadataSupplier.get();
+        ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+
+        Assert.assertEquals(""*/*"", ColumnFilter.all(metadata).toString());
+        Assert.assertEquals(""[v2, v3]"", ColumnFilter.selection(metadata.partitionColumns().without(v1)).toString());
+        Assert.assertEquals(""*/[v2, v3]"", ColumnFilter.selection(metadata, metadata.partitionColumns().without(v1)).toString());

Review comment:
       I think we could easily extend the test coverage of `ColumnFilter#toString` to subselections if, for example, we declare one of the columns in the table metadata as a not-frozen collection:
   ```java
   .addRegularColumn(""v3"", SetType.getInstance(Int32Type.instance, true))
   ```
   and then we test:
   ```java
   Assert.assertEquals(""[]"", ColumnFilter.selectionBuilder().build().toString());
   Assert.assertEquals(""[v3[1], v3[2]]"", ColumnFilter.selectionBuilder().select(v3, c2).select(v3, c1).build().toString());
   Assert.assertEquals(""[v3[1:2]]"", ColumnFilter.selectionBuilder().slice(v3, c1, c2).build().toString());
   Assert.assertEquals(""*/[v3[1], v3[2]]"", ColumnFilter.allColumnsBuilder(metadata).select(v3, c2).select(v3, c1).build().toString());
   Assert.assertEquals(""*/[v3[1:2]]"", ColumnFilter.allColumnsBuilder(metadata).slice(v3, c1, c2).build().toString());
   ```

##########
File path: test/distributed/org/apache/cassandra/distributed/test/ReadDigestConsistencyTest.java
##########
@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.util.Arrays;
+import java.util.UUID;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.shared.DistributedTestBase;
+
+public class ReadDigestConsistencyTest extends TestBaseImpl
+{
+    public static final String TABLE_NAME = ""tbl"";
+    public static final String CREATE_TABLE = String.format(""CREATE TABLE %s.%s (key int, s1 text static, c1 text, c2 text, c3 text, PRIMARY KEY (key, c1))"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+    public static final String INSERT = String.format(""INSERT INTO %s.%s (key, s1, c1, c2, c3) VALUES (?, ?, ?, ?, ?)"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+
+    public static final String SELECT_C1 = String.format(""SELECT key, c1 FROM %s.%s WHERE key = ?"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+    public static final String SELECT_C1_S1_ROW = String.format(""SELECT key, c1, s1 FROM %s.%s WHERE key = ? and c1 = ? "", DistributedTestBase.KEYSPACE, TABLE_NAME);

Review comment:
       Nit: we don't need the `DistributedTestBase .` prefix, nor the import of `DistributedTestBase` above.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Feb/21 13:40;githubbot;600","adelapena commented on a change in pull request #891:
URL: https://github.com/apache/cassandra/pull/891#discussion_r578665271



##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeReadTest.java
##########
@@ -56,12 +44,13 @@ public void mixedModeReadColumnSubsetDigestCheck() throws Throwable
         .withConfig(config -> config.with(Feature.GOSSIP, Feature.NETWORK))
         .setup(cluster -> {
             cluster.schemaChange(CREATE_TABLE);
-            cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""foo"", ""bar"", ""baz"");
-            cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 2, ""foo"", ""bar"", ""baz"");
+            cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""foo"", ""bar"", ""baz"");
+            cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""fi"", ""biz"", ""baz"");
+            cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""fo"", ""boz"", ""baz"");
 
             // baseline to show no digest mismatches before upgrade
-            checkTraceForDigestMismatch(cluster, 1);
-            checkTraceForDigestMismatch(cluster, 2);
+            checkTraceForDigestMismatch(cluster, 1, SELECT_C1, 1);
+            checkTraceForDigestMismatch(cluster, 2, SELECT_C1, 1);
         })
         .runAfterNodeUpgrade((cluster, node) -> {

Review comment:
       I think we could just use `runAfterClusterUpgrade` instead of `runAfterNodeUpgrade` and get rid of the `if (node != 1)` part.

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -385,44 +404,24 @@ public boolean equals(Object other)
     @Override
     public String toString()
     {
-        if (isFetchAll)
-            return ""*"";
-
-        if (queried.isEmpty())
-            return """";
-
-        Iterator<ColumnDefinition> defs = queried.selectOrderIterator();
-        if (!defs.hasNext())
-            return ""<none>"";
-
-        StringBuilder sb = new StringBuilder();
-        while (defs.hasNext())
-        {
-            appendColumnDef(sb, defs.next());
-            if (defs.hasNext())
-                sb.append("", "");
+        if (isFetchAll && queried == null)
+            return ""*/*"";

Review comment:
       I also like the idea of making it more descriptive, showing which part is the queried one and which is the fetched one, maybe something like `{queried=*, fetched=[v2, v3]}`? I'm not sure whether it would be a too invasive change in the logs, though.

##########
File path: test/distributed/org/apache/cassandra/distributed/upgrade/MixedModeReadTest.java
##########
@@ -18,34 +18,22 @@
 
 package org.apache.cassandra.distributed.upgrade;
 
-import java.util.UUID;
-
-import org.junit.Assert;
 import org.junit.Test;
 
-import org.apache.cassandra.distributed.UpgradeableCluster;
 import org.apache.cassandra.distributed.api.ConsistencyLevel;
 import org.apache.cassandra.distributed.api.Feature;
-import org.apache.cassandra.distributed.impl.DelegatingInvokableInstance;
-import org.apache.cassandra.distributed.shared.DistributedTestBase;
+import org.apache.cassandra.distributed.api.IInvokableInstance;
 import org.apache.cassandra.distributed.shared.Versions;
 import org.apache.cassandra.gms.Gossiper;
 
+import static org.apache.cassandra.distributed.test.ReadDigestConsistencyTest.CREATE_TABLE;
+import static org.apache.cassandra.distributed.test.ReadDigestConsistencyTest.INSERT;
+import static org.apache.cassandra.distributed.test.ReadDigestConsistencyTest.SELECT_C1;
+import static org.apache.cassandra.distributed.test.ReadDigestConsistencyTest.SELECT_C1_S1_ROW;
+import static org.apache.cassandra.distributed.test.ReadDigestConsistencyTest.checkTraceForDigestMismatch;

Review comment:
       Since we are reusing `ReadDigestConsistencyTest` we could add a couple of methods to it for populating the table and do the queries, something like:
   ```java
   public static void initialize(AbstractCluster<?> cluster)
   {
       cluster.schemaChange(CREATE_TABLE);
       cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""foo"", ""bar"", ""baz"");
       cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""fi"", ""biz"", ""baz"");
       cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""fo"", ""boz"", ""baz"");
   }
   
   public static void checkTraceForDigestMismatch(AbstractCluster<?> cluster)
   {
       checkTraceForDigestMismatch(cluster, 1, SELECT_C1, 1);
       checkTraceForDigestMismatch(cluster, 2, SELECT_C1, 1);
       checkTraceForDigestMismatch(cluster, 1, SELECT_C1_S1_ROW, 1, ""foo"");
       checkTraceForDigestMismatch(cluster, 2, SELECT_C1_S1_ROW, 1, ""fi"");
   }
   ```
   We would call these two methods from the upgrade test and from `ReadDigestConsistencyTest#testDigestConsistency`, avoiding the duplication of these two blocks of code and reducing the number of imports, wdyt? We could also put the two methods in a shared helper class, I don't have any preference here.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Feb/21 19:18;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r578756526



##########
File path: src/java/org/apache/cassandra/utils/CassandraVersion.java
##########
@@ -200,6 +200,11 @@ private static Integer tryParseInt(String str)
         }
     }
 
+    public boolean isLowerThan(int major, int minor)

Review comment:
       That sounds good to me. It can be a constant tho. 




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Feb/21 21:27;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r579010420



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2130,7 +2136,12 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
 
     public boolean haveMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+        return isUpgradingFromVersionLowerThan(4, 0);
+    }
+
+    public boolean isUpgradingFromVersionLowerThan(int major, int minor) {
+        CassandraVersion v = upgradeFromVersionMemoized.get();
+        return v != null && v.isLowerThan(major, minor);

Review comment:
       so what do you think @yifan-c ?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Feb/21 08:32;githubbot;600","jacek-lewandowski commented on a change in pull request #891:
URL: https://github.com/apache/cassandra/pull/891#discussion_r579065018



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -385,44 +404,24 @@ public boolean equals(Object other)
     @Override
     public String toString()
     {
-        if (isFetchAll)
-            return ""*"";
-
-        if (queried.isEmpty())
-            return """";
-
-        Iterator<ColumnDefinition> defs = queried.selectOrderIterator();
-        if (!defs.hasNext())
-            return ""<none>"";
-
-        StringBuilder sb = new StringBuilder();
-        while (defs.hasNext())
-        {
-            appendColumnDef(sb, defs.next());
-            if (defs.hasNext())
-                sb.append("", "");
+        if (isFetchAll && queried == null)
+            return ""*/*"";

Review comment:
       Well, I think that information is not useful from the user pov. It is probably useful for developers trying to fix a bug and in such a case, they will easily decode the meaning of pre slash and post slash parts. The idea here was to make that method provide the string representation which is 1:1 mapped to the data in column filter. Previously we were loosing some information




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Feb/21 10:00;githubbot;600","adelapena commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r579295720



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -60,17 +91,13 @@ public void testColumnFilterSerialisationRoundTrip() throws Exception
         ColumnFilter columnFilter;
 
         columnFilter = ColumnFilter.all(metadata);
-        testRoundTrip(columnFilter, ColumnFilter.Serializer.maybeUpdateForBackwardCompatility(columnFilter, MessagingService.VERSION_30), metadata, MessagingService.VERSION_30);

Review comment:
       Now only one of the versions of `testRoundTrip` is called by the tests, we could have a single version of the method.

##########
File path: src/java/org/apache/cassandra/db/SystemKeyspace.java
##########
@@ -90,6 +90,8 @@ private SystemKeyspace()
     // Cassandra was not previously installed and we're in the process of starting a fresh node.
     public static final CassandraVersion NULL_VERSION = new CassandraVersion(""0.0.0-absent"");
 
+    public static final CassandraVersion CURRENT_VERSION = new CassandraVersion(FBUtilities.getReleaseVersionString());

Review comment:
       There is a usage of `new CassandraVersion(FBUtilities.getReleaseVersionString())` below in `SystemKeyspace.getReleaseVersion`, we could use there the new `CURRENT_VERSION` constant.

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -74,25 +78,34 @@
     // null. If false, then _fetched_ == _queried_ and we only store _queried_.
     final boolean fetchAllRegulars;
 
+    // This flag can be only set when fetchAllRegulars is set. When fetchAllRegulars is set and queried==null then
+    // it is implied to be true. The flag when set allows for interpreting the column filter in the same way as it was
+    // interpreted by pre 4.0 Cassandra versions (3.4 ~ 4.0), that is, we fetch all columns (both regulars and static)
+    // but we query only some of them. This allows for proper behaviour during upgrades.
+    final boolean fetchAllStatics;

Review comment:
       We could verify this value in `ColumnFilterTest#testColumnFilterConstruction`, where we verify the value of `fetchAllRegulars`. By the way, I think that all the attributes with default visibility here could use `@VisibleForTesting`.

##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -18,31 +18,62 @@
 
 package org.apache.cassandra.db.filter;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertNull;
-import static org.junit.Assert.assertTrue;
+import java.util.Arrays;
+import java.util.Collection;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
 
+import org.apache.cassandra.Util;
 import org.apache.cassandra.db.RegularAndStaticColumns;
 import org.apache.cassandra.db.marshal.Int32Type;
 import org.apache.cassandra.db.marshal.SetType;
 import org.apache.cassandra.db.rows.CellPath;
 import org.apache.cassandra.dht.Murmur3Partitioner;
+import org.apache.cassandra.gms.Gossiper;
 import org.apache.cassandra.io.util.DataInputBuffer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputBuffer;
 import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.schema.ColumnMetadata;
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.utils.ByteBufferUtil;
-import org.junit.Test;
 
-import org.junit.Assert;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertTrue;
 
+@RunWith(Parameterized.class)
 public class ColumnFilterTest
 {
     private static final ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
 
+    @Parameterized.Parameter(0)
+    public String clusterMinVersion;

Review comment:
       I like the parameterized approach 👍 

##########
File path: test/unit/org/apache/cassandra/Util.java
##########
@@ -797,4 +797,16 @@ public static void disableBloomFilter(ColumnFamilyStore cfs)
         for (SSTableReader reader : cfs.getLiveSSTables())
             assertEquals(FilterFactory.AlwaysPresent, reader.getBloomFilter());
     }
+
+    public static void setUpgradeFromVersion(String version)

Review comment:
       Could we add some JavaDoc here?

##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -208,6 +241,38 @@ private static void testRoundTrip(ColumnFilter columnFilter, ColumnFilter expect
         Assert.assertEquals(deserialized, expected);
     }
 
+    @Test
+    public void testToString()
+    {
+        TableMetadata metadata = TableMetadata.builder(""ks"", ""table"")

Review comment:
       As [suggested in the PR for 3.0](https://github.com/apache/cassandra/pull/890#discussion_r578410628), we could include a multi-cell column to the table metadata to test how subselections are printed.

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -271,15 +329,15 @@ public Tester newTester(ColumnMetadata column)
         if (s.isEmpty())
             return null;
 
-        return new Tester(!column.isStatic() && fetchAllRegulars, s.iterator());
+        return new Tester(!column.isStatic() && fetchAllRegulars || column.isStatic() && fetchAllStatics, s.iterator());
     }
 
     /**
      * Given an iterator on the cell of a complex column, returns an iterator that only include the cells selected by
      * this filter.
      *
      * @param column the (complex) column for which the cells are.
-     * @param cells the cells to filter.
+     * @param cells  the cells to filter.

Review comment:
       ```suggestion
        * @param cells the cells to filter.
   ```

##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2130,7 +2148,12 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
 
     public boolean haveMajorVersion3Nodes()

Review comment:
       I'm not a native English speaker but, shouldn't this be `hasMajorVersion3Nodes`?

##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -483,84 +549,56 @@ public boolean equals(Object other)
     @Override
     public String toString()
     {
-        if (fetchAllRegulars && queried == null)
-            return ""*"";
+        String prefix = """";
 
-        if (queried.isEmpty())
-            return """";
+        if (fetchAllRegulars && queried == null)
+            return ""*/*"";
 
-        Iterator<ColumnMetadata> defs = queried.selectOrderIterator();
-        if (!defs.hasNext())
-            return ""<none>"";
+        if (fetchAllRegulars && fetchAllStatics)
+            prefix = ""*/"";
 
-        StringBuilder sb = new StringBuilder();
-        while (defs.hasNext())
+        if (fetchAllRegulars && !fetchAllStatics)
         {
-            appendColumnDef(sb, defs.next());
-            if (defs.hasNext())
-                sb.append("", "");
+            prefix = queried.statics.isEmpty()
+                     ? ""<all regulars>/""
+                     : String.format(""<all regulars>+%s/"", columnsToString(queried.statics::selectOrderIterator));

Review comment:
       I wonder if it would be easier to understand if we simply print the specific fetched columns, so the only abbreviation used by `toString` is `*`.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Feb/21 16:24;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r579383623



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2130,7 +2136,12 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
 
     public boolean haveMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+        return isUpgradingFromVersionLowerThan(4, 0);
+    }
+
+    public boolean isUpgradingFromVersionLowerThan(int major, int minor) {
+        CassandraVersion v = upgradeFromVersionMemoized.get();
+        return v != null && v.isLowerThan(major, minor);

Review comment:
       Regarding upgrade detection, I can think of 2 approaches. Both have their good and bad.
   - Something similar to `SystemKeyspaceMigrator40`, that check if the new table introduced in 40 exist at local. The good: good UX. The bad: what if the instance has migrated the tables, but failed to start. The operator restarts the instance during cluster upgrade. Now the instance is unable to detect. 
   - Accept a explicit property, say `cassandra.isUpgrade: Boolean`. The good: gives the operator more control. The bad: another property to handle (in some automation/manual process), and need to unset the property later.
   
   Regarding returning `NULL_VERSION`, I just thought of a failure scenario...
   The cluster is upgrading from `3.11` to `4.0`. When `NULL_VERSION` is returned, the 4.0 instance assumes the earliest behavior, which is `3.4-`, and there is a chance for digest mismatch. We can update the property to `cassandra.upgradeFrom: String = CassandraVersion`.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Feb/21 18:19;githubbot;600","jacek-lewandowski commented on a change in pull request #890:
URL: https://github.com/apache/cassandra/pull/890#discussion_r579757448



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -33,20 +38,24 @@
 
 public class ColumnFilterTest
 {
+    private final static Logger logger = LoggerFactory.getLogger(ColumnFilterTest.class);

Review comment:
       indeed, will remove it




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Feb/21 06:13;githubbot;600","jacek-lewandowski commented on a change in pull request #890:
URL: https://github.com/apache/cassandra/pull/890#discussion_r579757773



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -33,20 +38,24 @@
 
 public class ColumnFilterTest
 {
+    private final static Logger logger = LoggerFactory.getLogger(ColumnFilterTest.class);
+
     final static ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
 
+    private final Supplier<CFMetaData> metadataSupplier = Suppliers.memoize(() -> CFMetaData.Builder

Review comment:
       yes, i think we can do that




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Feb/21 06:17;githubbot;600","jacek-lewandowski commented on a change in pull request #890:
URL: https://github.com/apache/cassandra/pull/890#discussion_r579757931



##########
File path: test/distributed/org/apache/cassandra/distributed/test/ReadDigestConsistencyTest.java
##########
@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.util.Arrays;
+import java.util.UUID;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.shared.DistributedTestBase;
+
+public class ReadDigestConsistencyTest extends TestBaseImpl
+{
+    public static final String TABLE_NAME = ""tbl"";
+    public static final String CREATE_TABLE = String.format(""CREATE TABLE %s.%s (key int, s1 text static, c1 text, c2 text, c3 text, PRIMARY KEY (key, c1))"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+    public static final String INSERT = String.format(""INSERT INTO %s.%s (key, s1, c1, c2, c3) VALUES (?, ?, ?, ?, ?)"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+
+    public static final String SELECT_C1 = String.format(""SELECT key, c1 FROM %s.%s WHERE key = ?"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+    public static final String SELECT_C1_S1_ROW = String.format(""SELECT key, c1, s1 FROM %s.%s WHERE key = ? and c1 = ? "", DistributedTestBase.KEYSPACE, TABLE_NAME);

Review comment:
       ok




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Feb/21 06:18;githubbot;600","jacek-lewandowski commented on a change in pull request #890:
URL: https://github.com/apache/cassandra/pull/890#discussion_r579758000



##########
File path: test/distributed/org/apache/cassandra/distributed/test/ReadDigestConsistencyTest.java
##########
@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.cassandra.distributed.test;
+
+import java.util.Arrays;
+import java.util.UUID;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+import org.apache.cassandra.distributed.Cluster;
+import org.apache.cassandra.distributed.api.ConsistencyLevel;
+import org.apache.cassandra.distributed.shared.DistributedTestBase;
+
+public class ReadDigestConsistencyTest extends TestBaseImpl
+{
+    public static final String TABLE_NAME = ""tbl"";
+    public static final String CREATE_TABLE = String.format(""CREATE TABLE %s.%s (key int, s1 text static, c1 text, c2 text, c3 text, PRIMARY KEY (key, c1))"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+    public static final String INSERT = String.format(""INSERT INTO %s.%s (key, s1, c1, c2, c3) VALUES (?, ?, ?, ?, ?)"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+
+    public static final String SELECT_C1 = String.format(""SELECT key, c1 FROM %s.%s WHERE key = ?"", DistributedTestBase.KEYSPACE, TABLE_NAME);
+    public static final String SELECT_C1_S1_ROW = String.format(""SELECT key, c1, s1 FROM %s.%s WHERE key = ? and c1 = ? "", DistributedTestBase.KEYSPACE, TABLE_NAME);
+    public static final String SELECT_TRACE = ""SELECT activity FROM system_traces.events where session_id = ? and source = ? ALLOW FILTERING;"";
+
+    @Test
+    public void testDigestConsistency() throws Exception
+    {
+        try (Cluster cluster = init(builder().withNodes(2).start()))
+        {
+            cluster.schemaChange(CREATE_TABLE);
+            cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""foo"", ""bar"", ""baz"");
+            cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""fi"", ""biz"", ""baz"");
+            cluster.coordinator(1).execute(INSERT, ConsistencyLevel.ALL, 1, ""static"", ""fo"", ""boz"", ""baz"");
+
+            checkTraceForDigestMismatch(cluster, 1, SELECT_C1, 1);
+            checkTraceForDigestMismatch(cluster, 2, SELECT_C1, 1);
+            checkTraceForDigestMismatch(cluster, 1, SELECT_C1_S1_ROW, 1, ""foo"");
+            checkTraceForDigestMismatch(cluster, 2, SELECT_C1_S1_ROW, 1, ""fi"");
+        }
+    }
+
+    public static void checkTraceForDigestMismatch(Cluster cluster, int coordinatorNode, String query, Object... boundValues)

Review comment:
       ok




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Feb/21 06:19;githubbot;600","jacek-lewandowski commented on a change in pull request #890:
URL: https://github.com/apache/cassandra/pull/890#discussion_r579761618



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -59,6 +68,17 @@ public void columnFilterSerialisationRoundTrip() throws Exception
         testRoundTrip(ColumnFilter.selection(metadata, metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
     }
 
+    @Test
+    public void testToString()
+    {
+        CFMetaData metadata = metadataSupplier.get();
+        ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+
+        Assert.assertEquals(""*/*"", ColumnFilter.all(metadata).toString());
+        Assert.assertEquals(""[v2, v3]"", ColumnFilter.selection(metadata.partitionColumns().without(v1)).toString());
+        Assert.assertEquals(""*/[v2, v3]"", ColumnFilter.selection(metadata, metadata.partitionColumns().without(v1)).toString());

Review comment:
       ok, will add that, thank you




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;21/Feb/21 06:58;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r580097127



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2130,7 +2136,12 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
 
     public boolean haveMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+        return isUpgradingFromVersionLowerThan(4, 0);
+    }
+
+    public boolean isUpgradingFromVersionLowerThan(int major, int minor) {
+        CassandraVersion v = upgradeFromVersionMemoized.get();
+        return v != null && v.isLowerThan(major, minor);

Review comment:
       I'm strongly against introducing additional user-facing property. Cassandra is difficult enough without that :)
   
   I'll take it statistically - patch upgrades are much more frequent than major/minor version upgrades. Also I suppose the users are much more careful during major/minor version upgrades and probably less likely to exercise the cluster during that period. Therefore I'll optimise for that by just assuming the cluster is on 4.0, similarly as it has been done for 3.11
   




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Feb/21 09:27;githubbot;600","jacek-lewandowski commented on pull request #892:
URL: https://github.com/apache/cassandra/pull/892#issuecomment-783309414


   Ok guys, I've applied most of the comments. ColumnFilterTest is now refactored and covers more than 90% lines of ColumnFilter. It is also consistent across 3.0, 3.11 and 4.0


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Feb/21 11:32;githubbot;600","adelapena commented on a change in pull request #890:
URL: https://github.com/apache/cassandra/pull/890#discussion_r581119728



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -18,53 +18,348 @@
 
 package org.apache.cassandra.db.filter;
 
+import java.io.IOException;
+import java.util.function.Consumer;
+
+import com.google.common.base.Throwables;
+import org.junit.Assert;
 import org.junit.Test;
 
-import junit.framework.Assert;
 import org.apache.cassandra.config.CFMetaData;
 import org.apache.cassandra.config.ColumnDefinition;
+import org.apache.cassandra.db.PartitionColumns;
 import org.apache.cassandra.db.marshal.Int32Type;
+import org.apache.cassandra.db.marshal.SetType;
+import org.apache.cassandra.db.rows.CellPath;
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.io.util.DataInputBuffer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputBuffer;
 import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.utils.ByteBufferUtil;
 
+import static org.junit.Assert.assertEquals;
+
 public class ColumnFilterTest
 {
-    final static ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
+    private static final ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
+
+    private final CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
+                                                          .withPartitioner(Murmur3Partitioner.instance)
+                                                          .addPartitionKey(""pk"", Int32Type.instance)
+                                                          .addClusteringColumn(""ck"", Int32Type.instance)
+                                                          .addStaticColumn(""s1"", Int32Type.instance)
+                                                          .addStaticColumn(""s2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .addRegularColumn(""v1"", Int32Type.instance)
+                                                          .addRegularColumn(""v2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .build();
+
+    private final ColumnDefinition s1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s1""));
+    private final ColumnDefinition s2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s2""));
+    private final ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+    private final ColumnDefinition v2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v2""));
+    private final CellPath path0 = CellPath.create(ByteBufferUtil.bytes(0));
+    private final CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
+    private final CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
+    private final CellPath path3 = CellPath.create(ByteBufferUtil.bytes(3));
+    private final CellPath path4 = CellPath.create(ByteBufferUtil.bytes(4));
+
+    // Select all
+
+    @Test
+    public void testSelectAll() throws Exception

Review comment:
       Nit: Now that `testRoundTrip` body in inside a try-catch block (I assume that to avoid problems when calling it from the lambdas), none of the methods need the `throws Exception` part.

##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -18,53 +18,348 @@
 
 package org.apache.cassandra.db.filter;
 
+import java.io.IOException;
+import java.util.function.Consumer;
+
+import com.google.common.base.Throwables;
+import org.junit.Assert;
 import org.junit.Test;
 
-import junit.framework.Assert;
 import org.apache.cassandra.config.CFMetaData;
 import org.apache.cassandra.config.ColumnDefinition;
+import org.apache.cassandra.db.PartitionColumns;
 import org.apache.cassandra.db.marshal.Int32Type;
+import org.apache.cassandra.db.marshal.SetType;
+import org.apache.cassandra.db.rows.CellPath;
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.io.util.DataInputBuffer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputBuffer;
 import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.utils.ByteBufferUtil;
 
+import static org.junit.Assert.assertEquals;
+
 public class ColumnFilterTest
 {
-    final static ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
+    private static final ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
+
+    private final CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
+                                                          .withPartitioner(Murmur3Partitioner.instance)
+                                                          .addPartitionKey(""pk"", Int32Type.instance)
+                                                          .addClusteringColumn(""ck"", Int32Type.instance)
+                                                          .addStaticColumn(""s1"", Int32Type.instance)
+                                                          .addStaticColumn(""s2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .addRegularColumn(""v1"", Int32Type.instance)
+                                                          .addRegularColumn(""v2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .build();
+
+    private final ColumnDefinition s1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s1""));
+    private final ColumnDefinition s2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s2""));
+    private final ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+    private final ColumnDefinition v2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v2""));
+    private final CellPath path0 = CellPath.create(ByteBufferUtil.bytes(0));
+    private final CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
+    private final CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
+    private final CellPath path3 = CellPath.create(ByteBufferUtil.bytes(3));
+    private final CellPath path4 = CellPath.create(ByteBufferUtil.bytes(4));
+
+    // Select all
+
+    @Test
+    public void testSelectAll() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""*/*"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.all(metadata));
+        check.accept(ColumnFilter.allColumnsBuilder(metadata).build());
+    }
+
+    // Selections
+
+    @Test
+    public void testSelectNothing() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[]"", filter.toString());
+            assertFetchedQueried(false, false, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.NONE));
+        check.accept(ColumnFilter.selectionBuilder().build());
+    }
+
+    @Test
+    public void testSelectSimpleColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[v1]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1);
+            assertFetchedQueried(false, false, filter, v2, s1, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v1).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v1).build());
+    }
+
+    @Test
+    public void testSelectComplexColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[v2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v2);
+            assertFetchedQueried(false, false, filter, v1, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v2).build());
+    }
 
     @Test
-    public void columnFilterSerialisationRoundTrip() throws Exception
+    public void testSelectStaticColumn() throws Exception
     {
-        CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
-                                                .withPartitioner(Murmur3Partitioner.instance)
-                                                .addPartitionKey(""pk"", Int32Type.instance)
-                                                .addClusteringColumn(""ck"", Int32Type.instance)
-                                                .addRegularColumn(""v1"", Int32Type.instance)
-                                                .addRegularColumn(""v2"", Int32Type.instance)
-                                                .addRegularColumn(""v3"", Int32Type.instance)
-                                                .build();
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s1]"", filter.toString());
+            assertFetchedQueried(true, true, filter, s1);
+            assertFetchedQueried(false, false, filter, v1, v2, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(s1).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(s1).build());
+    }
+
+    @Test
+    public void testSelectStaticComplexColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, s2);
+            assertFetchedQueried(false, false, filter, v1, v2, s1);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(s2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(s2).build());
+    }
 
-        ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+    @Test
+    public void testSelectColumns() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s1, s2, v1, v2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
 
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_3014);
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v1).add(v2).add(s1).add(s2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v1).add(v2).add(s1).add(s2).build());
+    }
 
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
+    @Test
+    public void testSelectIndividualCells() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().select(v2, path1).select(v2, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[v2[1], v2[3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v2);
+        assertFetchedQueried(false, false, filter, v1, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path1, path3);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path2, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+    }
 
-        testRoundTrip(ColumnFilter.selection(metadata, metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.selection(metadata, metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
+    @Test
+    public void testSelectIndividualCellsFromStatic() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().select(s2, path1).select(s2, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[s2[1], s2[3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, s2);
+        assertFetchedQueried(false, false, filter, v1, v2, s1);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1, path3);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path2, path4);
     }
 
-    static void testRoundTrip(ColumnFilter columnFilter, CFMetaData metadata, int version) throws Exception
+    @Test
+    public void testSelectCellSlice() throws Exception
     {
-        DataOutputBuffer output = new DataOutputBuffer();
-        serializer.serialize(columnFilter, output, version);
-        Assert.assertEquals(serializer.serializedSize(columnFilter, version), output.position());
-        DataInputPlus input = new DataInputBuffer(output.buffer(), false);
-        Assert.assertEquals(serializer.deserialize(input, version, metadata), columnFilter);
+        ColumnFilter filter = ColumnFilter.selectionBuilder().slice(v2, path1, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[v2[1:3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v2);
+        assertFetchedQueried(false, false, filter, v1, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path1, path2, path3);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+    }
+
+    @Test
+    public void testSelectCellSliceFromStatic() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().slice(s2, path1, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[s2[1:3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, s2);
+        assertFetchedQueried(false, false, filter, v1, v2, s1);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1, path2, path3);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path4);
+    }
+
+    @Test
+    public void testSelectColumnsWithCellsAndSlices() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().add(v1).add(s1).slice(v2, path0, path2).select(v2, path4).select(s2, path0).slice(s2, path2, path4).build();

Review comment:
       Nit: we could break this long line:
   ```suggestion
           ColumnFilter filter = ColumnFilter.selectionBuilder()
                                             .add(v1)
                                             .add(s1)
                                             .slice(v2, path0, path2)
                                             .select(v2, path4)
                                             .select(s2, path0)
                                             .slice(s2, path2, path4)
                                             .build();
   ```

##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -18,53 +18,348 @@
 
 package org.apache.cassandra.db.filter;
 
+import java.io.IOException;
+import java.util.function.Consumer;
+
+import com.google.common.base.Throwables;
+import org.junit.Assert;
 import org.junit.Test;
 
-import junit.framework.Assert;
 import org.apache.cassandra.config.CFMetaData;
 import org.apache.cassandra.config.ColumnDefinition;
+import org.apache.cassandra.db.PartitionColumns;
 import org.apache.cassandra.db.marshal.Int32Type;
+import org.apache.cassandra.db.marshal.SetType;
+import org.apache.cassandra.db.rows.CellPath;
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.io.util.DataInputBuffer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputBuffer;
 import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.utils.ByteBufferUtil;
 
+import static org.junit.Assert.assertEquals;
+
 public class ColumnFilterTest
 {
-    final static ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
+    private static final ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
+
+    private final CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
+                                                          .withPartitioner(Murmur3Partitioner.instance)
+                                                          .addPartitionKey(""pk"", Int32Type.instance)
+                                                          .addClusteringColumn(""ck"", Int32Type.instance)
+                                                          .addStaticColumn(""s1"", Int32Type.instance)
+                                                          .addStaticColumn(""s2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .addRegularColumn(""v1"", Int32Type.instance)
+                                                          .addRegularColumn(""v2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .build();
+
+    private final ColumnDefinition s1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s1""));
+    private final ColumnDefinition s2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s2""));
+    private final ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+    private final ColumnDefinition v2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v2""));
+    private final CellPath path0 = CellPath.create(ByteBufferUtil.bytes(0));
+    private final CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
+    private final CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
+    private final CellPath path3 = CellPath.create(ByteBufferUtil.bytes(3));
+    private final CellPath path4 = CellPath.create(ByteBufferUtil.bytes(4));
+
+    // Select all
+
+    @Test
+    public void testSelectAll() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""*/*"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.all(metadata));
+        check.accept(ColumnFilter.allColumnsBuilder(metadata).build());
+    }
+
+    // Selections
+
+    @Test
+    public void testSelectNothing() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[]"", filter.toString());
+            assertFetchedQueried(false, false, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.NONE));
+        check.accept(ColumnFilter.selectionBuilder().build());
+    }
+
+    @Test
+    public void testSelectSimpleColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[v1]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1);
+            assertFetchedQueried(false, false, filter, v2, s1, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v1).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v1).build());
+    }
+
+    @Test
+    public void testSelectComplexColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[v2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v2);
+            assertFetchedQueried(false, false, filter, v1, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v2).build());
+    }
 
     @Test
-    public void columnFilterSerialisationRoundTrip() throws Exception
+    public void testSelectStaticColumn() throws Exception
     {
-        CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
-                                                .withPartitioner(Murmur3Partitioner.instance)
-                                                .addPartitionKey(""pk"", Int32Type.instance)
-                                                .addClusteringColumn(""ck"", Int32Type.instance)
-                                                .addRegularColumn(""v1"", Int32Type.instance)
-                                                .addRegularColumn(""v2"", Int32Type.instance)
-                                                .addRegularColumn(""v3"", Int32Type.instance)
-                                                .build();
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s1]"", filter.toString());
+            assertFetchedQueried(true, true, filter, s1);
+            assertFetchedQueried(false, false, filter, v1, v2, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(s1).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(s1).build());
+    }
+
+    @Test
+    public void testSelectStaticComplexColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, s2);
+            assertFetchedQueried(false, false, filter, v1, v2, s1);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(s2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(s2).build());
+    }
 
-        ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+    @Test
+    public void testSelectColumns() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s1, s2, v1, v2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
 
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_3014);
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v1).add(v2).add(s1).add(s2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v1).add(v2).add(s1).add(s2).build());
+    }
 
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
+    @Test
+    public void testSelectIndividualCells() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().select(v2, path1).select(v2, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[v2[1], v2[3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v2);
+        assertFetchedQueried(false, false, filter, v1, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path1, path3);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path2, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+    }
 
-        testRoundTrip(ColumnFilter.selection(metadata, metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.selection(metadata, metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
+    @Test
+    public void testSelectIndividualCellsFromStatic() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().select(s2, path1).select(s2, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[s2[1], s2[3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, s2);
+        assertFetchedQueried(false, false, filter, v1, v2, s1);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1, path3);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path2, path4);
     }
 
-    static void testRoundTrip(ColumnFilter columnFilter, CFMetaData metadata, int version) throws Exception
+    @Test
+    public void testSelectCellSlice() throws Exception
     {
-        DataOutputBuffer output = new DataOutputBuffer();
-        serializer.serialize(columnFilter, output, version);
-        Assert.assertEquals(serializer.serializedSize(columnFilter, version), output.position());
-        DataInputPlus input = new DataInputBuffer(output.buffer(), false);
-        Assert.assertEquals(serializer.deserialize(input, version, metadata), columnFilter);
+        ColumnFilter filter = ColumnFilter.selectionBuilder().slice(v2, path1, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[v2[1:3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v2);
+        assertFetchedQueried(false, false, filter, v1, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path1, path2, path3);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+    }
+
+    @Test
+    public void testSelectCellSliceFromStatic() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().slice(s2, path1, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[s2[1:3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, s2);
+        assertFetchedQueried(false, false, filter, v1, v2, s1);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1, path2, path3);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path4);
+    }
+
+    @Test
+    public void testSelectColumnsWithCellsAndSlices() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().add(v1).add(s1).slice(v2, path0, path2).select(v2, path4).select(s2, path0).slice(s2, path2, path4).build();
+        testRoundTrips(filter);
+        assertEquals(""[s1, s2[0], s2[2:4], v1, v2[0:2], v2[4]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path4);
+        assertCellFetchedQueried(false, false, filter, v2, path3);
+        assertCellFetchedQueried(true, true, filter, s2, path0, path2, path3, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path1);
+    }
+
+    // select with metadata
+
+    @Test
+    public void testSelectSimpleColumnWithMetadata() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertFetchedQueried(true, true, filter, v1);
+
+            assertEquals(""*/*"", filter.toString());
+            assertFetchedQueried(true, true, filter, s1, s2, v2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(metadata, PartitionColumns.builder().add(v1).build()));
+        check.accept(ColumnFilter.allColumnsBuilder(metadata).add(v1).build());
+    }
+
+    @Test
+    public void testSelectStaticColumnWithMetadata() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertFetchedQueried(true, true, filter, s1);
+
+            assertEquals(""*/*"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(metadata, PartitionColumns.builder().add(s1).build()));
+        check.accept(ColumnFilter.allColumnsBuilder(metadata).add(s1).build());
+    }
+
+    @Test
+    public void testSelectCellWithMetadata() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.allColumnsBuilder(metadata).select(v2, path1).build();
+        testRoundTrips(filter);
+        assertFetchedQueried(true, true, filter, v2);
+
+        assertEquals(""*/*"", filter.toString());
+        assertFetchedQueried(true, true, filter, s1, s2, v1);
+        assertCellFetchedQueried(true, true, filter, v2, path1);
+        assertCellFetchedQueried(true, false, filter, v2, path0, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+    }
+
+    @Test
+    public void testSelectStaticColumnCellWithMetadata() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.allColumnsBuilder(metadata).select(s2, path1).build();
+        testRoundTrips(filter);
+        assertFetchedQueried(true, true, filter, s2);
+
+        assertEquals(""*/*"", filter.toString());
+        assertFetchedQueried(true, true, filter, v1, v2, s1);
+        assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1);
+        assertCellFetchedQueried(true, false, filter, s2, path0, path2, path3, path4);
+    }
+
+    private void testRoundTrips(ColumnFilter cf)
+    {
+        testRoundTrip(cf, MessagingService.VERSION_30);
+        testRoundTrip(cf, MessagingService.VERSION_3014);
+    }
+
+    private void testRoundTrip(ColumnFilter columnFilter, int version)
+    {
+        try
+        {
+            DataOutputBuffer output = new DataOutputBuffer();
+            serializer.serialize(columnFilter, output, version);
+            Assert.assertEquals(serializer.serializedSize(columnFilter, version), output.position());
+            DataInputPlus input = new DataInputBuffer(output.buffer(), false);
+            ColumnFilter deserialized = serializer.deserialize(input, version, metadata);
+            Assert.assertEquals(deserialized, columnFilter);
+        }
+        catch (IOException e)
+        {
+            throw Throwables.propagate(e);
+        }
+    }
+
+    private static void assertFetchedQueried(boolean expectedFetched,
+                                             boolean expectedQueried,
+                                             ColumnFilter filter,
+                                             ColumnDefinition... columns)
+    {
+        for (ColumnDefinition column : columns)
+        {
+            assertEquals(String.format(""Expected fetches(%s) to be %s"", column.name, expectedFetched), expectedFetched, filter.includes(column));
+            if (expectedFetched)
+                assertEquals(String.format(""Expected fetchedColumnIsQueried(%s) to be %s"", column.name, expectedQueried), expectedQueried, !filter.canSkipValue(column));
+        }

Review comment:
       It seems that the error messages here are mentioning the methods used in 3.11, not the ones actually used. Also, we could break the lines.

##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -18,53 +18,348 @@
 
 package org.apache.cassandra.db.filter;
 
+import java.io.IOException;
+import java.util.function.Consumer;
+
+import com.google.common.base.Throwables;
+import org.junit.Assert;
 import org.junit.Test;
 
-import junit.framework.Assert;
 import org.apache.cassandra.config.CFMetaData;
 import org.apache.cassandra.config.ColumnDefinition;
+import org.apache.cassandra.db.PartitionColumns;
 import org.apache.cassandra.db.marshal.Int32Type;
+import org.apache.cassandra.db.marshal.SetType;
+import org.apache.cassandra.db.rows.CellPath;
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.io.util.DataInputBuffer;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataOutputBuffer;
 import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.utils.ByteBufferUtil;
 
+import static org.junit.Assert.assertEquals;
+
 public class ColumnFilterTest
 {
-    final static ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
+    private static final ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
+
+    private final CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
+                                                          .withPartitioner(Murmur3Partitioner.instance)
+                                                          .addPartitionKey(""pk"", Int32Type.instance)
+                                                          .addClusteringColumn(""ck"", Int32Type.instance)
+                                                          .addStaticColumn(""s1"", Int32Type.instance)
+                                                          .addStaticColumn(""s2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .addRegularColumn(""v1"", Int32Type.instance)
+                                                          .addRegularColumn(""v2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .build();
+
+    private final ColumnDefinition s1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s1""));
+    private final ColumnDefinition s2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s2""));
+    private final ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+    private final ColumnDefinition v2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v2""));
+    private final CellPath path0 = CellPath.create(ByteBufferUtil.bytes(0));
+    private final CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
+    private final CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
+    private final CellPath path3 = CellPath.create(ByteBufferUtil.bytes(3));
+    private final CellPath path4 = CellPath.create(ByteBufferUtil.bytes(4));
+
+    // Select all
+
+    @Test
+    public void testSelectAll() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""*/*"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.all(metadata));
+        check.accept(ColumnFilter.allColumnsBuilder(metadata).build());
+    }
+
+    // Selections
+
+    @Test
+    public void testSelectNothing() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[]"", filter.toString());
+            assertFetchedQueried(false, false, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.NONE));
+        check.accept(ColumnFilter.selectionBuilder().build());
+    }
+
+    @Test
+    public void testSelectSimpleColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[v1]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1);
+            assertFetchedQueried(false, false, filter, v2, s1, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v1).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v1).build());
+    }
+
+    @Test
+    public void testSelectComplexColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[v2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v2);
+            assertFetchedQueried(false, false, filter, v1, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v2).build());
+    }
 
     @Test
-    public void columnFilterSerialisationRoundTrip() throws Exception
+    public void testSelectStaticColumn() throws Exception
     {
-        CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
-                                                .withPartitioner(Murmur3Partitioner.instance)
-                                                .addPartitionKey(""pk"", Int32Type.instance)
-                                                .addClusteringColumn(""ck"", Int32Type.instance)
-                                                .addRegularColumn(""v1"", Int32Type.instance)
-                                                .addRegularColumn(""v2"", Int32Type.instance)
-                                                .addRegularColumn(""v3"", Int32Type.instance)
-                                                .build();
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s1]"", filter.toString());
+            assertFetchedQueried(true, true, filter, s1);
+            assertFetchedQueried(false, false, filter, v1, v2, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(s1).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(s1).build());
+    }
+
+    @Test
+    public void testSelectStaticComplexColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, s2);
+            assertFetchedQueried(false, false, filter, v1, v2, s1);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(s2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(s2).build());
+    }
 
-        ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+    @Test
+    public void testSelectColumns() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s1, s2, v1, v2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
 
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_3014);
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v1).add(v2).add(s1).add(s2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v1).add(v2).add(s1).add(s2).build());
+    }
 
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
+    @Test
+    public void testSelectIndividualCells() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().select(v2, path1).select(v2, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[v2[1], v2[3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v2);
+        assertFetchedQueried(false, false, filter, v1, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path1, path3);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path2, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+    }
 
-        testRoundTrip(ColumnFilter.selection(metadata, metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.selection(metadata, metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
+    @Test
+    public void testSelectIndividualCellsFromStatic() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().select(s2, path1).select(s2, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[s2[1], s2[3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, s2);
+        assertFetchedQueried(false, false, filter, v1, v2, s1);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1, path3);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path2, path4);
     }
 
-    static void testRoundTrip(ColumnFilter columnFilter, CFMetaData metadata, int version) throws Exception
+    @Test
+    public void testSelectCellSlice() throws Exception
     {
-        DataOutputBuffer output = new DataOutputBuffer();
-        serializer.serialize(columnFilter, output, version);
-        Assert.assertEquals(serializer.serializedSize(columnFilter, version), output.position());
-        DataInputPlus input = new DataInputBuffer(output.buffer(), false);
-        Assert.assertEquals(serializer.deserialize(input, version, metadata), columnFilter);
+        ColumnFilter filter = ColumnFilter.selectionBuilder().slice(v2, path1, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[v2[1:3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v2);
+        assertFetchedQueried(false, false, filter, v1, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path1, path2, path3);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+    }
+
+    @Test
+    public void testSelectCellSliceFromStatic() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().slice(s2, path1, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[s2[1:3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, s2);
+        assertFetchedQueried(false, false, filter, v1, v2, s1);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1, path2, path3);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path4);
+    }
+
+    @Test
+    public void testSelectColumnsWithCellsAndSlices() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().add(v1).add(s1).slice(v2, path0, path2).select(v2, path4).select(s2, path0).slice(s2, path2, path4).build();
+        testRoundTrips(filter);
+        assertEquals(""[s1, s2[0], s2[2:4], v1, v2[0:2], v2[4]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path4);
+        assertCellFetchedQueried(false, false, filter, v2, path3);
+        assertCellFetchedQueried(true, true, filter, s2, path0, path2, path3, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path1);
+    }
+
+    // select with metadata
+
+    @Test
+    public void testSelectSimpleColumnWithMetadata() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertFetchedQueried(true, true, filter, v1);
+
+            assertEquals(""*/*"", filter.toString());
+            assertFetchedQueried(true, true, filter, s1, s2, v2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(metadata, PartitionColumns.builder().add(v1).build()));
+        check.accept(ColumnFilter.allColumnsBuilder(metadata).add(v1).build());
+    }
+
+    @Test
+    public void testSelectStaticColumnWithMetadata() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertFetchedQueried(true, true, filter, s1);
+
+            assertEquals(""*/*"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(metadata, PartitionColumns.builder().add(s1).build()));
+        check.accept(ColumnFilter.allColumnsBuilder(metadata).add(s1).build());
+    }
+
+    @Test
+    public void testSelectCellWithMetadata() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.allColumnsBuilder(metadata).select(v2, path1).build();
+        testRoundTrips(filter);
+        assertFetchedQueried(true, true, filter, v2);
+
+        assertEquals(""*/*"", filter.toString());
+        assertFetchedQueried(true, true, filter, s1, s2, v1);
+        assertCellFetchedQueried(true, true, filter, v2, path1);
+        assertCellFetchedQueried(true, false, filter, v2, path0, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+    }
+
+    @Test
+    public void testSelectStaticColumnCellWithMetadata() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.allColumnsBuilder(metadata).select(s2, path1).build();
+        testRoundTrips(filter);
+        assertFetchedQueried(true, true, filter, s2);
+
+        assertEquals(""*/*"", filter.toString());
+        assertFetchedQueried(true, true, filter, v1, v2, s1);
+        assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1);
+        assertCellFetchedQueried(true, false, filter, s2, path0, path2, path3, path4);
+    }
+
+    private void testRoundTrips(ColumnFilter cf)
+    {
+        testRoundTrip(cf, MessagingService.VERSION_30);
+        testRoundTrip(cf, MessagingService.VERSION_3014);
+    }
+
+    private void testRoundTrip(ColumnFilter columnFilter, int version)
+    {
+        try
+        {
+            DataOutputBuffer output = new DataOutputBuffer();
+            serializer.serialize(columnFilter, output, version);
+            Assert.assertEquals(serializer.serializedSize(columnFilter, version), output.position());
+            DataInputPlus input = new DataInputBuffer(output.buffer(), false);
+            ColumnFilter deserialized = serializer.deserialize(input, version, metadata);
+            Assert.assertEquals(deserialized, columnFilter);
+        }
+        catch (IOException e)
+        {
+            throw Throwables.propagate(e);
+        }
+    }
+
+    private static void assertFetchedQueried(boolean expectedFetched,
+                                             boolean expectedQueried,
+                                             ColumnFilter filter,
+                                             ColumnDefinition... columns)
+    {
+        for (ColumnDefinition column : columns)
+        {
+            assertEquals(String.format(""Expected fetches(%s) to be %s"", column.name, expectedFetched), expectedFetched, filter.includes(column));
+            if (expectedFetched)
+                assertEquals(String.format(""Expected fetchedColumnIsQueried(%s) to be %s"", column.name, expectedQueried), expectedQueried, !filter.canSkipValue(column));
+        }
+    }
+
+    private static void assertCellFetchedQueried(boolean expectedFetched,
+                                                 boolean expectedQueried,
+                                                 ColumnFilter filter,
+                                                 ColumnDefinition column,
+                                                 CellPath... paths)
+    {
+        ColumnFilter.Tester tester = filter.newTester(column);
+
+        for (CellPath path : paths)
+        {
+            int p = ByteBufferUtil.toInt(path.get(0));
+
+            if (tester != null)
+            {
+                assertEquals(String.format(""Expected includesAllColumns || tester.includes(%s:%s) to be %s"", column.name, p, expectedFetched), expectedFetched, tester.includes(path));
+                if (expectedFetched)
+                    assertEquals(String.format(""Expected tester.includes(%s:%s) to be %s"", column.name, p, expectedQueried), expectedQueried, !tester.canSkipValue(path));

Review comment:
       As before, the error messages here are mentioning the methods used in 3.11 and the long lines could be broken.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Feb/21 15:20;githubbot;600","adelapena commented on a change in pull request #891:
URL: https://github.com/apache/cassandra/pull/891#discussion_r581156751



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -36,143 +48,388 @@
 
 import static org.junit.Assert.assertEquals;
 
+@RunWith(Parameterized.class)
 public class ColumnFilterTest
 {
     private static final ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
 
+    private final CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
+                                                          .withPartitioner(Murmur3Partitioner.instance)
+                                                          .addPartitionKey(""pk"", Int32Type.instance)
+                                                          .addClusteringColumn(""ck"", Int32Type.instance)
+                                                          .addStaticColumn(""s1"", Int32Type.instance)
+                                                          .addStaticColumn(""s2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .addRegularColumn(""v1"", Int32Type.instance)
+                                                          .addRegularColumn(""v2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .build();
+
+    private final ColumnDefinition s1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s1""));
+    private final ColumnDefinition s2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s2""));
+    private final ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+    private final ColumnDefinition v2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v2""));
+    private final CellPath path0 = CellPath.create(ByteBufferUtil.bytes(0));
+    private final CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
+    private final CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
+    private final CellPath path3 = CellPath.create(ByteBufferUtil.bytes(3));
+    private final CellPath path4 = CellPath.create(ByteBufferUtil.bytes(4));
+
+    @Parameterized.Parameter(0)
+    public boolean anyNodeOn30;
+
+    @Parameterized.Parameters(name = ""{index}: anyNodeOn30={0}"")
+    public static Collection<Object[]> data()
+    {
+        return Arrays.asList(new Object[]{ true }, new Object[]{ false });
+    }
+
+    @BeforeClass
+    public static void beforeClass()
+    {
+        DatabaseDescriptor.clientInitialization();
+    }
+
+    @Before
+    public void before()
+    {
+        Gossiper.instance.setAnyNodeOn30(anyNodeOn30);
+    }
+
+    // Select all
+
     @Test
-    public void columnFilterSerialisationRoundTrip() throws Exception
-    {
-        CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
-                                                .withPartitioner(Murmur3Partitioner.instance)
-                                                .addPartitionKey(""pk"", Int32Type.instance)
-                                                .addClusteringColumn(""ck"", Int32Type.instance)
-                                                .addRegularColumn(""v1"", Int32Type.instance)
-                                                .addRegularColumn(""v2"", Int32Type.instance)
-                                                .addRegularColumn(""v3"", Int32Type.instance)
-                                                .build();
-
-        ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
-
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_3014);
-
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
-    }
-
-    private static void testRoundTrip(ColumnFilter columnFilter, CFMetaData metadata, int version) throws Exception
-    {
-        DataOutputBuffer output = new DataOutputBuffer();
-        serializer.serialize(columnFilter, output, version);
-        Assert.assertEquals(serializer.serializedSize(columnFilter, version), output.position());
-        DataInputPlus input = new DataInputBuffer(output.buffer(), false);
-        Assert.assertEquals(serializer.deserialize(input, version, metadata), columnFilter);
-    }
-
-    /**
-     * Tests whether a filter fetches and/or queries columns and cells.
-     */
-    @Test
-    public void testFetchedQueried()
-    {
-        CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
-                                              .withPartitioner(Murmur3Partitioner.instance)
-                                              .addPartitionKey(""k"", Int32Type.instance)
-                                              .addRegularColumn(""simple"", Int32Type.instance)
-                                              .addRegularColumn(""complex"", SetType.getInstance(Int32Type.instance, true))
-                                              .build();
-
-        ColumnDefinition simple = metadata.getColumnDefinition(ByteBufferUtil.bytes(""simple""));
-        ColumnDefinition complex = metadata.getColumnDefinition(ByteBufferUtil.bytes(""complex""));
-        CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
-        CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
-        ColumnFilter filter;
-
-        // select only the simple column, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(simple).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(false, false, filter, complex);
-        assertFetchedQueried(false, false, filter, complex, path1);
-        assertFetchedQueried(false, false, filter, complex, path2);
-
-        // select only the complex column, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(complex).build());
-        assertFetchedQueried(false, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select both the simple and complex columns, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(simple).add(complex).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select only the simple column, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(simple).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, false, filter, complex);
-        assertFetchedQueried(true, false, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
-
-        // select only the complex column, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(complex).build());
-        assertFetchedQueried(true, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select both the simple and complex columns, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(simple).add(complex).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select only the simple column, with selection builder
-        filter = ColumnFilter.selectionBuilder().add(simple).build();
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(false, false, filter, complex);
-        assertFetchedQueried(false, false, filter, complex, path1);
-        assertFetchedQueried(false, false, filter, complex, path2);
-
-        // select only a cell of the complex column, with selection builder
-        filter = ColumnFilter.selectionBuilder().select(complex, path1).build();
-        assertFetchedQueried(false, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
-
-        // select both the simple column and a cell of the complex column, with selection builder
-        filter = ColumnFilter.selectionBuilder().add(simple).select(complex, path1).build();
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
+    public void testSelectAll() throws Exception

Review comment:
       As mentioned in the PR for 3.0, we don't need the `throws Exception` anymore

##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -36,143 +48,388 @@
 
 import static org.junit.Assert.assertEquals;
 
+@RunWith(Parameterized.class)
 public class ColumnFilterTest
 {
     private static final ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
 
+    private final CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
+                                                          .withPartitioner(Murmur3Partitioner.instance)
+                                                          .addPartitionKey(""pk"", Int32Type.instance)
+                                                          .addClusteringColumn(""ck"", Int32Type.instance)
+                                                          .addStaticColumn(""s1"", Int32Type.instance)
+                                                          .addStaticColumn(""s2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .addRegularColumn(""v1"", Int32Type.instance)
+                                                          .addRegularColumn(""v2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .build();
+
+    private final ColumnDefinition s1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s1""));
+    private final ColumnDefinition s2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s2""));
+    private final ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+    private final ColumnDefinition v2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v2""));
+    private final CellPath path0 = CellPath.create(ByteBufferUtil.bytes(0));
+    private final CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
+    private final CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
+    private final CellPath path3 = CellPath.create(ByteBufferUtil.bytes(3));
+    private final CellPath path4 = CellPath.create(ByteBufferUtil.bytes(4));
+
+    @Parameterized.Parameter(0)
+    public boolean anyNodeOn30;
+
+    @Parameterized.Parameters(name = ""{index}: anyNodeOn30={0}"")
+    public static Collection<Object[]> data()
+    {
+        return Arrays.asList(new Object[]{ true }, new Object[]{ false });
+    }
+
+    @BeforeClass
+    public static void beforeClass()
+    {
+        DatabaseDescriptor.clientInitialization();
+    }
+
+    @Before
+    public void before()
+    {
+        Gossiper.instance.setAnyNodeOn30(anyNodeOn30);
+    }
+
+    // Select all
+
     @Test
-    public void columnFilterSerialisationRoundTrip() throws Exception
-    {
-        CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
-                                                .withPartitioner(Murmur3Partitioner.instance)
-                                                .addPartitionKey(""pk"", Int32Type.instance)
-                                                .addClusteringColumn(""ck"", Int32Type.instance)
-                                                .addRegularColumn(""v1"", Int32Type.instance)
-                                                .addRegularColumn(""v2"", Int32Type.instance)
-                                                .addRegularColumn(""v3"", Int32Type.instance)
-                                                .build();
-
-        ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
-
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_3014);
-
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
-    }
-
-    private static void testRoundTrip(ColumnFilter columnFilter, CFMetaData metadata, int version) throws Exception
-    {
-        DataOutputBuffer output = new DataOutputBuffer();
-        serializer.serialize(columnFilter, output, version);
-        Assert.assertEquals(serializer.serializedSize(columnFilter, version), output.position());
-        DataInputPlus input = new DataInputBuffer(output.buffer(), false);
-        Assert.assertEquals(serializer.deserialize(input, version, metadata), columnFilter);
-    }
-
-    /**
-     * Tests whether a filter fetches and/or queries columns and cells.
-     */
-    @Test
-    public void testFetchedQueried()
-    {
-        CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
-                                              .withPartitioner(Murmur3Partitioner.instance)
-                                              .addPartitionKey(""k"", Int32Type.instance)
-                                              .addRegularColumn(""simple"", Int32Type.instance)
-                                              .addRegularColumn(""complex"", SetType.getInstance(Int32Type.instance, true))
-                                              .build();
-
-        ColumnDefinition simple = metadata.getColumnDefinition(ByteBufferUtil.bytes(""simple""));
-        ColumnDefinition complex = metadata.getColumnDefinition(ByteBufferUtil.bytes(""complex""));
-        CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
-        CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
-        ColumnFilter filter;
-
-        // select only the simple column, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(simple).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(false, false, filter, complex);
-        assertFetchedQueried(false, false, filter, complex, path1);
-        assertFetchedQueried(false, false, filter, complex, path2);
-
-        // select only the complex column, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(complex).build());
-        assertFetchedQueried(false, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select both the simple and complex columns, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(simple).add(complex).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select only the simple column, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(simple).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, false, filter, complex);
-        assertFetchedQueried(true, false, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
-
-        // select only the complex column, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(complex).build());
-        assertFetchedQueried(true, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select both the simple and complex columns, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(simple).add(complex).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select only the simple column, with selection builder
-        filter = ColumnFilter.selectionBuilder().add(simple).build();
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(false, false, filter, complex);
-        assertFetchedQueried(false, false, filter, complex, path1);
-        assertFetchedQueried(false, false, filter, complex, path2);
-
-        // select only a cell of the complex column, with selection builder
-        filter = ColumnFilter.selectionBuilder().select(complex, path1).build();
-        assertFetchedQueried(false, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
-
-        // select both the simple column and a cell of the complex column, with selection builder
-        filter = ColumnFilter.selectionBuilder().add(simple).select(complex, path1).build();
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
+    public void testSelectAll() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""*/*"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.all(metadata));
+        check.accept(ColumnFilter.allColumnsBuilder(metadata).build());
     }
 
-    private static void assertFetchedQueried(boolean expectedFetched,
-                                             boolean expectedQueried,
-                                             ColumnFilter filter,
-                                             ColumnDefinition column)
+    // Selections
+
+    @Test
+    public void testSelectNothing() throws Exception
     {
-        assert !expectedQueried || expectedFetched;
-        boolean actualFetched = filter.fetches(column);
-        assertEquals(expectedFetched, actualFetched);
-        assertEquals(expectedQueried, actualFetched && filter.fetchedColumnIsQueried(column));
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[]"", filter.toString());
+            assertFetchedQueried(false, false, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.NONE));
+        check.accept(ColumnFilter.selectionBuilder().build());
+    }
+
+    @Test
+    public void testSelectSimpleColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[v1]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1);
+            assertFetchedQueried(false, false, filter, v2, s1, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v1).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v1).build());
+    }
+
+    @Test
+    public void testSelectComplexColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[v2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v2);
+            assertFetchedQueried(false, false, filter, v1, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v2).build());
+    }
+
+    @Test
+    public void testSelectStaticColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s1]"", filter.toString());
+            assertFetchedQueried(true, true, filter, s1);
+            assertFetchedQueried(false, false, filter, v1, v2, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(s1).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(s1).build());
+    }
+
+    @Test
+    public void testSelectStaticComplexColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, s2);
+            assertFetchedQueried(false, false, filter, v1, v2, s1);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(s2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(s2).build());
+    }
+
+    @Test
+    public void testSelectColumns() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s1, s2, v1, v2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v1).add(v2).add(s1).add(s2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v1).add(v2).add(s1).add(s2).build());
+    }
+
+    @Test
+    public void testSelectIndividualCells() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().select(v2, path1).select(v2, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[v2[1], v2[3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v2);
+        assertFetchedQueried(false, false, filter, v1, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path1, path3);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path2, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+    }
+
+    @Test
+    public void testSelectIndividualCellsFromStatic() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().select(s2, path1).select(s2, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[s2[1], s2[3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, s2);
+        assertFetchedQueried(false, false, filter, v1, v2, s1);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1, path3);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path2, path4);
+    }
+
+    @Test
+    public void testSelectCellSlice() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().slice(v2, path1, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[v2[1:3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v2);
+        assertFetchedQueried(false, false, filter, v1, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path1, path2, path3);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+    }
+
+    @Test
+    public void testSelectCellSliceFromStatic() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().slice(s2, path1, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[s2[1:3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, s2);
+        assertFetchedQueried(false, false, filter, v1, v2, s1);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1, path2, path3);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path4);
+    }
+
+    @Test
+    public void testSelectColumnsWithCellsAndSlices() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().add(v1).add(s1).slice(v2, path0, path2).select(v2, path4).select(s2, path0).slice(s2, path2, path4).build();
+        testRoundTrips(filter);
+        assertEquals(""[s1, s2[0], s2[2:4], v1, v2[0:2], v2[4]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path4);
+        assertCellFetchedQueried(false, false, filter, v2, path3);
+        assertCellFetchedQueried(true, true, filter, s2, path0, path2, path3, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path1);
+    }
+
+    // select with metadata
+
+    @Test
+    public void testSelectSimpleColumnWithMetadata() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertFetchedQueried(true, true, filter, v1);
+            if (anyNodeOn30)
+            {
+                assertEquals(""*/*"", filter.toString());
+                assertFetchedQueried(true, true, filter, s1, s2, v2);
+                assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+                assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+            }
+            else
+            {
+                assertEquals(""*/[v1]"", filter.toString());
+                assertFetchedQueried(true, false, filter, s1, s2, v2);
+                assertCellFetchedQueried(true, false, filter, v2, path0, path1, path2, path3, path4);
+                assertCellFetchedQueried(true, false, filter, s2, path0, path1, path2, path3, path4);
+            }

Review comment:
       Nit: maybe it would be a bit easier to spot the differences between mixed and normal modes this way:
   ```suggestion
               assertEquals(anyNodeOn30 ? ""*/*"" : ""*/[v1]"", filter.toString());
               assertFetchedQueried(true, anyNodeOn30, filter, s1, s2, v2);
               assertCellFetchedQueried(true, anyNodeOn30, filter, v2, path0, path1, path2, path3, path4);
               assertCellFetchedQueried(true, anyNodeOn30, filter, s2, path0, path1, path2, path3, path4);
   ```




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Feb/21 15:55;githubbot;600","yifan-c commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r581300735



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2128,9 +2143,25 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
         }
     }
 
-    public boolean haveMajorVersion3Nodes()
+    /**
+     * Returns {@code true} only if the information about the version of each node in the cluster is available and
+     * ALL the nodes are on 4.0 (regardless of the patch version).
+     */
+    public boolean hasMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+

Review comment:
       nit: remove the empty line. 

##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2128,9 +2143,25 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
         }
     }
 
-    public boolean haveMajorVersion3Nodes()
+    /**
+     * Returns {@code true} only if the information about the version of each node in the cluster is available and
+     * ALL the nodes are on 4.0 (regardless of the patch version).
+     */
+    public boolean hasMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+
+        return upgradeInProgressPossible || isUpgradingFromVersionLowerThan(CassandraVersion.CASSANDRA_4_0);

Review comment:
       should the condition be like the below?
   ```java
   upgradeInProgressPossible && isUpgradingFromVersionLowerThan(CassandraVersion.CASSANDRA_4_0);
   ```
   The current behavior (using `||`) is we assume the cluster has v30 nodes when the node does not have version info of all the peers. When `upgradeInProgressPossible == true`, any minVersion memorized in the supplier above is just ignored... 
   If the current behavior is desired, please add comment to the code.  

##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -158,38 +158,53 @@
 
     private volatile long lastProcessedMessageAt = System.currentTimeMillis();
 
-    //This property and anything that checks it should be removed in 5.0
-    private boolean haveMajorVersion3Nodes = true;
+    // This property and anything that checks it should be removed in 5.0
+    /**
+     * This property is initially set to {@code true} which means that we have no information about the other nodes.

Review comment:
       nit: please merge those 2 comments. 
   
   ```suggestion
        /**
        * This property and anything that checks it should be removed in 5.0
        *
        * This property is initially set to {@code true} which means that we have no information about the other nodes.
   ```

##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2128,9 +2143,25 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
         }
     }
 
-    public boolean haveMajorVersion3Nodes()
+    /**
+     * Returns {@code true} only if the information about the version of each node in the cluster is available and
+     * ALL the nodes are on 4.0 (regardless of the patch version).

Review comment:
       The comment does not seem to describe the method correctly. I think you want the below according to the current behavior. 
   
   ```suggestion
        * Returns {@code false} only if the information about the version of each node in the cluster is available and
        * ALL the nodes are on 4.0 (regardless of the patch version).
   ```

##########
File path: src/java/org/apache/cassandra/utils/ExpiringMemoizingSupplier.java
##########
@@ -77,6 +77,11 @@ public T get() {
         return this.value;
     }
 
+    public void expire()

Review comment:
       nit: annotate with `@VisibleForTesting`? It is only used for testing.  

##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -158,38 +158,53 @@
 
     private volatile long lastProcessedMessageAt = System.currentTimeMillis();
 
-    //This property and anything that checks it should be removed in 5.0
-    private boolean haveMajorVersion3Nodes = true;
+    // This property and anything that checks it should be removed in 5.0
+    /**
+     * This property is initially set to {@code true} which means that we have no information about the other nodes.
+     * Once all nodes are on at least this node version, it becomes {@code false}, which means that we are not
+     * upgrading from the previous version (major, minor).
+     */
+    private boolean upgradeInProgressPossible = true;

Review comment:
       We should add `volatile` to the variable, since it is now read by both the supplier and `hasMajorVersion3Nodes()`. It can be accessed from multiple threads. 
   Before the patch, the variable is only accessed by `ExpiringMemoizingSupplier`.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Feb/21 19:15;githubbot;600","jacek-lewandowski commented on a change in pull request #891:
URL: https://github.com/apache/cassandra/pull/891#discussion_r582575148



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -36,143 +48,388 @@
 
 import static org.junit.Assert.assertEquals;
 
+@RunWith(Parameterized.class)
 public class ColumnFilterTest
 {
     private static final ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
 
+    private final CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
+                                                          .withPartitioner(Murmur3Partitioner.instance)
+                                                          .addPartitionKey(""pk"", Int32Type.instance)
+                                                          .addClusteringColumn(""ck"", Int32Type.instance)
+                                                          .addStaticColumn(""s1"", Int32Type.instance)
+                                                          .addStaticColumn(""s2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .addRegularColumn(""v1"", Int32Type.instance)
+                                                          .addRegularColumn(""v2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .build();
+
+    private final ColumnDefinition s1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s1""));
+    private final ColumnDefinition s2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s2""));
+    private final ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+    private final ColumnDefinition v2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v2""));
+    private final CellPath path0 = CellPath.create(ByteBufferUtil.bytes(0));
+    private final CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
+    private final CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
+    private final CellPath path3 = CellPath.create(ByteBufferUtil.bytes(3));
+    private final CellPath path4 = CellPath.create(ByteBufferUtil.bytes(4));
+
+    @Parameterized.Parameter(0)
+    public boolean anyNodeOn30;
+
+    @Parameterized.Parameters(name = ""{index}: anyNodeOn30={0}"")
+    public static Collection<Object[]> data()
+    {
+        return Arrays.asList(new Object[]{ true }, new Object[]{ false });
+    }
+
+    @BeforeClass
+    public static void beforeClass()
+    {
+        DatabaseDescriptor.clientInitialization();
+    }
+
+    @Before
+    public void before()
+    {
+        Gossiper.instance.setAnyNodeOn30(anyNodeOn30);
+    }
+
+    // Select all
+
     @Test
-    public void columnFilterSerialisationRoundTrip() throws Exception
-    {
-        CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
-                                                .withPartitioner(Murmur3Partitioner.instance)
-                                                .addPartitionKey(""pk"", Int32Type.instance)
-                                                .addClusteringColumn(""ck"", Int32Type.instance)
-                                                .addRegularColumn(""v1"", Int32Type.instance)
-                                                .addRegularColumn(""v2"", Int32Type.instance)
-                                                .addRegularColumn(""v3"", Int32Type.instance)
-                                                .build();
-
-        ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
-
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_3014);
-
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
-    }
-
-    private static void testRoundTrip(ColumnFilter columnFilter, CFMetaData metadata, int version) throws Exception
-    {
-        DataOutputBuffer output = new DataOutputBuffer();
-        serializer.serialize(columnFilter, output, version);
-        Assert.assertEquals(serializer.serializedSize(columnFilter, version), output.position());
-        DataInputPlus input = new DataInputBuffer(output.buffer(), false);
-        Assert.assertEquals(serializer.deserialize(input, version, metadata), columnFilter);
-    }
-
-    /**
-     * Tests whether a filter fetches and/or queries columns and cells.
-     */
-    @Test
-    public void testFetchedQueried()
-    {
-        CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
-                                              .withPartitioner(Murmur3Partitioner.instance)
-                                              .addPartitionKey(""k"", Int32Type.instance)
-                                              .addRegularColumn(""simple"", Int32Type.instance)
-                                              .addRegularColumn(""complex"", SetType.getInstance(Int32Type.instance, true))
-                                              .build();
-
-        ColumnDefinition simple = metadata.getColumnDefinition(ByteBufferUtil.bytes(""simple""));
-        ColumnDefinition complex = metadata.getColumnDefinition(ByteBufferUtil.bytes(""complex""));
-        CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
-        CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
-        ColumnFilter filter;
-
-        // select only the simple column, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(simple).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(false, false, filter, complex);
-        assertFetchedQueried(false, false, filter, complex, path1);
-        assertFetchedQueried(false, false, filter, complex, path2);
-
-        // select only the complex column, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(complex).build());
-        assertFetchedQueried(false, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select both the simple and complex columns, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(simple).add(complex).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select only the simple column, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(simple).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, false, filter, complex);
-        assertFetchedQueried(true, false, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
-
-        // select only the complex column, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(complex).build());
-        assertFetchedQueried(true, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select both the simple and complex columns, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(simple).add(complex).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select only the simple column, with selection builder
-        filter = ColumnFilter.selectionBuilder().add(simple).build();
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(false, false, filter, complex);
-        assertFetchedQueried(false, false, filter, complex, path1);
-        assertFetchedQueried(false, false, filter, complex, path2);
-
-        // select only a cell of the complex column, with selection builder
-        filter = ColumnFilter.selectionBuilder().select(complex, path1).build();
-        assertFetchedQueried(false, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
-
-        // select both the simple column and a cell of the complex column, with selection builder
-        filter = ColumnFilter.selectionBuilder().add(simple).select(complex, path1).build();
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
+    public void testSelectAll() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""*/*"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.all(metadata));
+        check.accept(ColumnFilter.allColumnsBuilder(metadata).build());
     }
 
-    private static void assertFetchedQueried(boolean expectedFetched,
-                                             boolean expectedQueried,
-                                             ColumnFilter filter,
-                                             ColumnDefinition column)
+    // Selections
+
+    @Test
+    public void testSelectNothing() throws Exception
     {
-        assert !expectedQueried || expectedFetched;
-        boolean actualFetched = filter.fetches(column);
-        assertEquals(expectedFetched, actualFetched);
-        assertEquals(expectedQueried, actualFetched && filter.fetchedColumnIsQueried(column));
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[]"", filter.toString());
+            assertFetchedQueried(false, false, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.NONE));
+        check.accept(ColumnFilter.selectionBuilder().build());
+    }
+
+    @Test
+    public void testSelectSimpleColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[v1]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1);
+            assertFetchedQueried(false, false, filter, v2, s1, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v1).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v1).build());
+    }
+
+    @Test
+    public void testSelectComplexColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[v2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v2);
+            assertFetchedQueried(false, false, filter, v1, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v2).build());
+    }
+
+    @Test
+    public void testSelectStaticColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s1]"", filter.toString());
+            assertFetchedQueried(true, true, filter, s1);
+            assertFetchedQueried(false, false, filter, v1, v2, s2);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(s1).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(s1).build());
+    }
+
+    @Test
+    public void testSelectStaticComplexColumn() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, s2);
+            assertFetchedQueried(false, false, filter, v1, v2, s1);
+            assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(s2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(s2).build());
+    }
+
+    @Test
+    public void testSelectColumns() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertEquals(""[s1, s2, v1, v2]"", filter.toString());
+            assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+            assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+            assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+        };
+
+        check.accept(ColumnFilter.selection(PartitionColumns.builder().add(v1).add(v2).add(s1).add(s2).build()));
+        check.accept(ColumnFilter.selectionBuilder().add(v1).add(v2).add(s1).add(s2).build());
+    }
+
+    @Test
+    public void testSelectIndividualCells() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().select(v2, path1).select(v2, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[v2[1], v2[3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v2);
+        assertFetchedQueried(false, false, filter, v1, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path1, path3);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path2, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+    }
+
+    @Test
+    public void testSelectIndividualCellsFromStatic() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().select(s2, path1).select(s2, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[s2[1], s2[3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, s2);
+        assertFetchedQueried(false, false, filter, v1, v2, s1);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1, path3);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path2, path4);
+    }
+
+    @Test
+    public void testSelectCellSlice() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().slice(v2, path1, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[v2[1:3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v2);
+        assertFetchedQueried(false, false, filter, v1, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path1, path2, path3);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path1, path2, path3, path4);
+    }
+
+    @Test
+    public void testSelectCellSliceFromStatic() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().slice(s2, path1, path3).build();
+        testRoundTrips(filter);
+        assertEquals(""[s2[1:3]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, s2);
+        assertFetchedQueried(false, false, filter, v1, v2, s1);
+        assertCellFetchedQueried(false, false, filter, v2, path0, path1, path2, path3, path4);
+        assertCellFetchedQueried(true, true, filter, s2, path1, path2, path3);
+        assertCellFetchedQueried(false, false, filter, s2, path0, path4);
+    }
+
+    @Test
+    public void testSelectColumnsWithCellsAndSlices() throws Exception
+    {
+        ColumnFilter filter = ColumnFilter.selectionBuilder().add(v1).add(s1).slice(v2, path0, path2).select(v2, path4).select(s2, path0).slice(s2, path2, path4).build();
+        testRoundTrips(filter);
+        assertEquals(""[s1, s2[0], s2[2:4], v1, v2[0:2], v2[4]]"", filter.toString());
+        assertFetchedQueried(true, true, filter, v1, v2, s1, s2);
+        assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path4);
+        assertCellFetchedQueried(false, false, filter, v2, path3);
+        assertCellFetchedQueried(true, true, filter, s2, path0, path2, path3, path4);
+        assertCellFetchedQueried(false, false, filter, s2, path1);
+    }
+
+    // select with metadata
+
+    @Test
+    public void testSelectSimpleColumnWithMetadata() throws Exception
+    {
+        Consumer<ColumnFilter> check = filter -> {
+            testRoundTrips(filter);
+            assertFetchedQueried(true, true, filter, v1);
+            if (anyNodeOn30)
+            {
+                assertEquals(""*/*"", filter.toString());
+                assertFetchedQueried(true, true, filter, s1, s2, v2);
+                assertCellFetchedQueried(true, true, filter, v2, path0, path1, path2, path3, path4);
+                assertCellFetchedQueried(true, true, filter, s2, path0, path1, path2, path3, path4);
+            }
+            else
+            {
+                assertEquals(""*/[v1]"", filter.toString());
+                assertFetchedQueried(true, false, filter, s1, s2, v2);
+                assertCellFetchedQueried(true, false, filter, v2, path0, path1, path2, path3, path4);
+                assertCellFetchedQueried(true, false, filter, s2, path0, path1, path2, path3, path4);
+            }

Review comment:
       Actually I'd not do that. Especially because to keep easy merge path from 3.0 -> 3.11 -> trunk. Note that in trunk we have 3 scenarios and playing with `? / :` would no longer make it more readable. 
   
   Now we can easily see that the assertions for 3.0 in cassandra-3.0, cassandra-3.11 and trunk are identical. Same for assertions for 3.11 in cassandra-3.11 and trunk. 
   




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 06:28;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r582607713



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2128,9 +2143,25 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
         }
     }
 
-    public boolean haveMajorVersion3Nodes()
+    /**
+     * Returns {@code true} only if the information about the version of each node in the cluster is available and
+     * ALL the nodes are on 4.0 (regardless of the patch version).
+     */
+    public boolean hasMajorVersion3Nodes()
     {
-        return haveMajorVersion3NodesMemoized.get();
+
+        return upgradeInProgressPossible || isUpgradingFromVersionLowerThan(CassandraVersion.CASSANDRA_4_0);

Review comment:
       Yes, it is desired. `ColumnFilter` no longer uses this method but it is used in some other places which I didn't touch or analysed. Thus, I'd like to keep the original behaviour for those cases. I'll actually tweak it a bit for the cases where we upgrading from say 4.0 to 4.1




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 07:44;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r582608011



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -2128,9 +2143,25 @@ public boolean waitForSchemaAgreement(long maxWait, TimeUnit unit, BooleanSuppli
         }
     }
 
-    public boolean haveMajorVersion3Nodes()
+    /**
+     * Returns {@code true} only if the information about the version of each node in the cluster is available and
+     * ALL the nodes are on 4.0 (regardless of the patch version).

Review comment:
       indeed, thanks




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 07:44;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r582608531



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -158,38 +158,53 @@
 
     private volatile long lastProcessedMessageAt = System.currentTimeMillis();
 
-    //This property and anything that checks it should be removed in 5.0
-    private boolean haveMajorVersion3Nodes = true;
+    // This property and anything that checks it should be removed in 5.0
+    /**
+     * This property is initially set to {@code true} which means that we have no information about the other nodes.
+     * Once all nodes are on at least this node version, it becomes {@code false}, which means that we are not
+     * upgrading from the previous version (major, minor).
+     */
+    private boolean upgradeInProgressPossible = true;

Review comment:
       TBH, I haven't change anything in this regards, the supplier is not asynchronous, but I can make it volatile




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 07:45;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r582608866



##########
File path: src/java/org/apache/cassandra/gms/Gossiper.java
##########
@@ -158,38 +158,53 @@
 
     private volatile long lastProcessedMessageAt = System.currentTimeMillis();
 
-    //This property and anything that checks it should be removed in 5.0
-    private boolean haveMajorVersion3Nodes = true;
+    // This property and anything that checks it should be removed in 5.0
+    /**
+     * This property is initially set to {@code true} which means that we have no information about the other nodes.

Review comment:
       ok




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 07:46;githubbot;600","jacek-lewandowski commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r582608939



##########
File path: src/java/org/apache/cassandra/utils/ExpiringMemoizingSupplier.java
##########
@@ -77,6 +77,11 @@ public T get() {
         return this.value;
     }
 
+    public void expire()

Review comment:
       ok




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 07:46;githubbot;600","adelapena commented on a change in pull request #891:
URL: https://github.com/apache/cassandra/pull/891#discussion_r582849027



##########
File path: test/unit/org/apache/cassandra/db/filter/ColumnFilterTest.java
##########
@@ -36,143 +48,388 @@
 
 import static org.junit.Assert.assertEquals;
 
+@RunWith(Parameterized.class)
 public class ColumnFilterTest
 {
     private static final ColumnFilter.Serializer serializer = new ColumnFilter.Serializer();
 
+    private final CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
+                                                          .withPartitioner(Murmur3Partitioner.instance)
+                                                          .addPartitionKey(""pk"", Int32Type.instance)
+                                                          .addClusteringColumn(""ck"", Int32Type.instance)
+                                                          .addStaticColumn(""s1"", Int32Type.instance)
+                                                          .addStaticColumn(""s2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .addRegularColumn(""v1"", Int32Type.instance)
+                                                          .addRegularColumn(""v2"", SetType.getInstance(Int32Type.instance, true))
+                                                          .build();
+
+    private final ColumnDefinition s1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s1""));
+    private final ColumnDefinition s2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""s2""));
+    private final ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
+    private final ColumnDefinition v2 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v2""));
+    private final CellPath path0 = CellPath.create(ByteBufferUtil.bytes(0));
+    private final CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
+    private final CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
+    private final CellPath path3 = CellPath.create(ByteBufferUtil.bytes(3));
+    private final CellPath path4 = CellPath.create(ByteBufferUtil.bytes(4));
+
+    @Parameterized.Parameter(0)
+    public boolean anyNodeOn30;
+
+    @Parameterized.Parameters(name = ""{index}: anyNodeOn30={0}"")
+    public static Collection<Object[]> data()
+    {
+        return Arrays.asList(new Object[]{ true }, new Object[]{ false });
+    }
+
+    @BeforeClass
+    public static void beforeClass()
+    {
+        DatabaseDescriptor.clientInitialization();
+    }
+
+    @Before
+    public void before()
+    {
+        Gossiper.instance.setAnyNodeOn30(anyNodeOn30);
+    }
+
+    // Select all
+
     @Test
-    public void columnFilterSerialisationRoundTrip() throws Exception
-    {
-        CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
-                                                .withPartitioner(Murmur3Partitioner.instance)
-                                                .addPartitionKey(""pk"", Int32Type.instance)
-                                                .addClusteringColumn(""ck"", Int32Type.instance)
-                                                .addRegularColumn(""v1"", Int32Type.instance)
-                                                .addRegularColumn(""v2"", Int32Type.instance)
-                                                .addRegularColumn(""v3"", Int32Type.instance)
-                                                .build();
-
-        ColumnDefinition v1 = metadata.getColumnDefinition(ByteBufferUtil.bytes(""v1""));
-
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.all(metadata), metadata, MessagingService.VERSION_3014);
-
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_30);
-        testRoundTrip(ColumnFilter.selection(metadata.partitionColumns().without(v1)), metadata, MessagingService.VERSION_3014);
-    }
-
-    private static void testRoundTrip(ColumnFilter columnFilter, CFMetaData metadata, int version) throws Exception
-    {
-        DataOutputBuffer output = new DataOutputBuffer();
-        serializer.serialize(columnFilter, output, version);
-        Assert.assertEquals(serializer.serializedSize(columnFilter, version), output.position());
-        DataInputPlus input = new DataInputBuffer(output.buffer(), false);
-        Assert.assertEquals(serializer.deserialize(input, version, metadata), columnFilter);
-    }
-
-    /**
-     * Tests whether a filter fetches and/or queries columns and cells.
-     */
-    @Test
-    public void testFetchedQueried()
-    {
-        CFMetaData metadata = CFMetaData.Builder.create(""ks"", ""table"")
-                                              .withPartitioner(Murmur3Partitioner.instance)
-                                              .addPartitionKey(""k"", Int32Type.instance)
-                                              .addRegularColumn(""simple"", Int32Type.instance)
-                                              .addRegularColumn(""complex"", SetType.getInstance(Int32Type.instance, true))
-                                              .build();
-
-        ColumnDefinition simple = metadata.getColumnDefinition(ByteBufferUtil.bytes(""simple""));
-        ColumnDefinition complex = metadata.getColumnDefinition(ByteBufferUtil.bytes(""complex""));
-        CellPath path1 = CellPath.create(ByteBufferUtil.bytes(1));
-        CellPath path2 = CellPath.create(ByteBufferUtil.bytes(2));
-        ColumnFilter filter;
-
-        // select only the simple column, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(simple).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(false, false, filter, complex);
-        assertFetchedQueried(false, false, filter, complex, path1);
-        assertFetchedQueried(false, false, filter, complex, path2);
-
-        // select only the complex column, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(complex).build());
-        assertFetchedQueried(false, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select both the simple and complex columns, without table metadata
-        filter = ColumnFilter.selection(PartitionColumns.builder().add(simple).add(complex).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select only the simple column, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(simple).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, false, filter, complex);
-        assertFetchedQueried(true, false, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
-
-        // select only the complex column, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(complex).build());
-        assertFetchedQueried(true, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select both the simple and complex columns, with table metadata
-        filter = ColumnFilter.selection(metadata, PartitionColumns.builder().add(simple).add(complex).build());
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, true, filter, complex, path2);
-
-        // select only the simple column, with selection builder
-        filter = ColumnFilter.selectionBuilder().add(simple).build();
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(false, false, filter, complex);
-        assertFetchedQueried(false, false, filter, complex, path1);
-        assertFetchedQueried(false, false, filter, complex, path2);
-
-        // select only a cell of the complex column, with selection builder
-        filter = ColumnFilter.selectionBuilder().select(complex, path1).build();
-        assertFetchedQueried(false, false, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
-
-        // select both the simple column and a cell of the complex column, with selection builder
-        filter = ColumnFilter.selectionBuilder().add(simple).select(complex, path1).build();
-        assertFetchedQueried(true, true, filter, simple);
-        assertFetchedQueried(true, true, filter, complex);
-        assertFetchedQueried(true, true, filter, complex, path1);
-        assertFetchedQueried(true, false, filter, complex, path2);
+    public void testSelectAll() throws Exception

Review comment:
       It seems we still have some unneeded `throws Exception` in 3.11 and trunk.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 13:56;githubbot;600","adelapena commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r583125767



##########
File path: src/java/org/apache/cassandra/db/SystemKeyspace.java
##########
@@ -90,6 +90,8 @@ private SystemKeyspace()
     // Cassandra was not previously installed and we're in the process of starting a fresh node.
     public static final CassandraVersion NULL_VERSION = new CassandraVersion(""0.0.0-absent"");
 
+    public static final CassandraVersion CURRENT_VERSION = new CassandraVersion(FBUtilities.getReleaseVersionString());

Review comment:
       I think this nit has been missed in the last review commit




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 19:59;githubbot;600","adelapena commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r583126857



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -74,25 +78,34 @@
     // null. If false, then _fetched_ == _queried_ and we only store _queried_.
     final boolean fetchAllRegulars;
 
+    // This flag can be only set when fetchAllRegulars is set. When fetchAllRegulars is set and queried==null then
+    // it is implied to be true. The flag when set allows for interpreting the column filter in the same way as it was
+    // interpreted by pre 4.0 Cassandra versions (3.4 ~ 4.0), that is, we fetch all columns (both regulars and static)
+    // but we query only some of them. This allows for proper behaviour during upgrades.
+    final boolean fetchAllStatics;

Review comment:
       I think that with the new changes in `ColumnFilterTest` this one and `queried` below can be `private`




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 20:01;githubbot;600","adelapena commented on a change in pull request #892:
URL: https://github.com/apache/cassandra/pull/892#discussion_r583126857



##########
File path: src/java/org/apache/cassandra/db/filter/ColumnFilter.java
##########
@@ -74,25 +78,34 @@
     // null. If false, then _fetched_ == _queried_ and we only store _queried_.
     final boolean fetchAllRegulars;
 
+    // This flag can be only set when fetchAllRegulars is set. When fetchAllRegulars is set and queried==null then
+    // it is implied to be true. The flag when set allows for interpreting the column filter in the same way as it was
+    // interpreted by pre 4.0 Cassandra versions (3.4 ~ 4.0), that is, we fetch all columns (both regulars and static)
+    // but we query only some of them. This allows for proper behaviour during upgrades.
+    final boolean fetchAllStatics;

Review comment:
       I think that with the new changes in `ColumnFilterTest` this one and `queried` below can be `private`. Also, I wonder if we should include this new attribute in the implementation of `equals`.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Feb/21 20:03;githubbot;600","jacek-lewandowski closed pull request #892:
URL: https://github.com/apache/cassandra/pull/892


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 06:49;githubbot;600","jacek-lewandowski closed pull request #891:
URL: https://github.com/apache/cassandra/pull/891


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 06:49;githubbot;600","jacek-lewandowski closed pull request #890:
URL: https://github.com/apache/cassandra/pull/890


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Nov/21 06:49;githubbot;600",,0,33000,,,0,33000,,,,,,,,,,CASSANDRA-16432,,,,CASSANDRA-16483,,,,,,,,,,,,,,,,,,,,,,,,0.0,jlewandowski,,,,,,,,,,,,,Correctness -> Transient Incorrect Response,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Mar 05 13:42:53 UTC 2021,,,,,,,All,,,,"0|z0n8yg:",9223372036854775807,,,,adelapena,ycai,,,Normal,,3.0.14,,https://github.com/apache/cassandra/commit/865b67b21d326728936f0b80681129c73a2e374a,,,,,,,,,run regression + new tests,,,,,"05/Feb/21 16:42;maedhroz;Another recent failure here: https://app.circleci.com/pipelines/github/maedhroz/cassandra/227/workflows/c8f12d79-8f8c-420c-965c-d8188199822b/jobs/1301;;;","05/Feb/21 19:22;aholmber;I don't think this is actually flaky. It's just broken right now. I'm hoping to take a look at it this afternoon if I get time, and Jacek also indicated he could look into it next week.;;;","05/Feb/21 19:37;yifanc;Thanks for looking into it. Agree that it is broken ATM. 

A bit more info that the ""digest mismatch"" error only occurs in *v3X* and not in *v4*, although the patch is present in both versions. ;;;","08/Feb/21 09:39;jlewandowski;This problem does not affect 4.0 at all. The only reason we can see it in 4.0 tests is that the JVM upgrade distributed tests is different in for {{trunk}} and for {{cassandra-3.11}} branches. I don't remember why is it different, but we should make it look same. 

Also this is interesting problem - tests tied to 4.0 fail during upgrade because C* we upgrade from is broken...;;;","08/Feb/21 14:44;jlewandowski;I encountered a weird problem - see my PR for 3.11: https://github.com/apache/cassandra/pull/891

Basically there are no changes in the production code. I modified a little bit the mixed read test mostly by adding gossip and networking features to the cluster configuration (as gossiper is required for this test run). Apparently I did something wrong because the cluster does not run properly and it complains with the following exception (repeated many, many times):

{noformat}
[junit-timeout] ERROR 14:35:29 Unable to merge schema from /127.0.0.2
[junit-timeout] java.util.concurrent.RejectedExecutionException: ThreadPoolExecutor has shut down
[junit-timeout] 	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:58) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) [na:1.8.0_212]
[junit-timeout] 	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379) [na:1.8.0_212]
[junit-timeout] 	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.execute(DebuggableThreadPoolExecutor.java:162) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.db.ColumnFamilyStore.switchMemtable(ColumnFamilyStore.java:904) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.db.ColumnFamilyStore.switchMemtableIfCurrent(ColumnFamilyStore.java:885) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.db.ColumnFamilyStore.forceFlush(ColumnFamilyStore.java:954) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.schema.SchemaKeyspace.lambda$flush$1(SchemaKeyspace.java:310) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at java.lang.Iterable.forEach(Iterable.java:75) ~[na:1.8.0_212]
[junit-timeout] 	at org.apache.cassandra.schema.SchemaKeyspace.flush(SchemaKeyspace.java:310) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.schema.SchemaKeyspace.mergeSchema(SchemaKeyspace.java:1398) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.schema.SchemaKeyspace.mergeSchemaAndAnnounceVersion(SchemaKeyspace.java:1380) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.service.MigrationCoordinator.mergeSchemaFrom(MigrationCoordinator.java:367) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.service.MigrationCoordinator$Callback.response(MigrationCoordinator.java:404) [dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.service.MigrationCoordinator$Callback.response(MigrationCoordinator.java:393) [dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.net.ResponseVerbHandler.doVerb(ResponseVerbHandler.java:53) [dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:66) [dtest-3.11.11.jar:na]
[junit-timeout] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_212]
[junit-timeout] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_212]
[junit-timeout] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_212]
[junit-timeout] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_212]
[junit-timeout] 	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:84) [dtest-3.11.11.jar:na]
[junit-timeout] 	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_212]
[junit-timeout] ERROR [node1_InternalResponseStage:1] node1 2021-02-08 15:35:29,093 MigrationCoordinator.java:408 - Unable to merge schema from /127.0.0.2
[junit-timeout] java.util.concurrent.RejectedExecutionException: ThreadPoolExecutor has shut down
[junit-timeout] 	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:58) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) [na:1.8.0_212]
[junit-timeout] 	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379) [na:1.8.0_212]
[junit-timeout] 	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.execute(DebuggableThreadPoolExecutor.java:162) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.db.ColumnFamilyStore.switchMemtable(ColumnFamilyStore.java:904) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.db.ColumnFamilyStore.switchMemtableIfCurrent(ColumnFamilyStore.java:885) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.db.ColumnFamilyStore.forceFlush(ColumnFamilyStore.java:954) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.schema.SchemaKeyspace.lambda$flush$1(SchemaKeyspace.java:310) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at java.lang.Iterable.forEach(Iterable.java:75) ~[na:1.8.0_212]
[junit-timeout] 	at org.apache.cassandra.schema.SchemaKeyspace.flush(SchemaKeyspace.java:310) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.schema.SchemaKeyspace.mergeSchema(SchemaKeyspace.java:1398) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.schema.SchemaKeyspace.mergeSchemaAndAnnounceVersion(SchemaKeyspace.java:1380) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.service.MigrationCoordinator.mergeSchemaFrom(MigrationCoordinator.java:367) ~[dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.service.MigrationCoordinator$Callback.response(MigrationCoordinator.java:404) [dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.service.MigrationCoordinator$Callback.response(MigrationCoordinator.java:393) [dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.net.ResponseVerbHandler.doVerb(ResponseVerbHandler.java:53) [dtest-3.11.11.jar:na]
[junit-timeout] 	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:66) [dtest-3.11.11.jar:na]
[junit-timeout] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_212]
[junit-timeout] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_212]
[junit-timeout] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_212]
[junit-timeout] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_212]
[junit-timeout] 	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:84) [dtest-3.11.11.jar:na]
[junit-timeout] 	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_212]
{noformat}

Can someone help me a bit with this? (cc [~jwest], [~blerer])
;;;","08/Feb/21 18:37;yifanc;[~jlewandowski], it seems the only difference in the new 'MixedModeReadTest' is the static column. The old test already had the gossip and networking features enabled. The test runs after reverting the table definition. 

Not sure whether the behavior is unexpected. It is a separate issue and should be tracked in a different ticket, if so. ;;;","09/Feb/21 06:10;jlewandowski;[~yifanc] thank you for checking that. Maybe I'm doing something wrong with how I run that test. All in all, I rewrote that test as Python dtest and it passed without making any changes in production code. However the new test was failing because there was a bug in {{ColumnFilter}}. I fixed the bug and run both tests, both passed.
;;;","09/Feb/21 06:50;jlewandowski;:facepalm

You are absolutely right. I've blindly copied the test from trunk. That test does not use gossip. Let me fix that...;;;","09/Feb/21 18:13;jlewandowski;So, the problem was not visible, but it unfortunately affects 4.0 as well (in terms of upgrading from 3). It is not critical though.

The problem is still the same - {{ColumnFilter}} is buggy. Its structure and interpretation has changed in 3.0.14 (I guess), 3.4 and 4.0 significantly. Although we try to apply some adjustments while sending it to older nodes / receiving it from older nodes, there are some features which are not available for older nodes.

For example, fetch all regular columns and only queried static columns, while there is only a subset of queried regular columns - there is no way to convert the filter for 3.11 or 3.0 so that it gets interpreted in the same way as on 4.0, and thus, the data read on 4.0 will be different to the data read on 3.11 or 3.0, and therefore, the digest will be different as well. The differences are mostly with regard to which cells has skipped values and which cells are removed at all from the results

I'm going to add extra flag to {{ColumnFilter}} in 4.0, which will be set if there are 3.4+ nodes in the cluster, so that the filter can be interpreted on 4.0 in the most efficient way that is also available on 3.4+ nodes. Where there are < 3.4 nodes in the cluster, it is enough to set {{queried}} columns to null (as we try to do now).

 ;;;","10/Feb/21 09:20;jlewandowski;trunk PR: [https://github.com/apache/cassandra/pull/892]

3.11 PR: [https://github.com/apache/cassandra/pull/891]

3.0 PR (just test) [https://github.com/apache/cassandra/pull/890]

 ;;;","15/Feb/21 17:10;adelapena;Running CI:

* [3.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/182/workflows/1eb6d43a-0a8a-40ff-8fb6-fa66806bf595]
* [3.11|https://app.circleci.com/pipelines/github/adelapena/cassandra/184/workflows/70b2942f-45f6-4f5d-8267-511aeef6c9b6]
* [trunk (j8)|https://app.circleci.com/pipelines/github/adelapena/cassandra/183/workflows/d363c206-0cbc-4208-a376-008a7f721d24]
* [trunk (j11)|https://app.circleci.com/pipelines/github/adelapena/cassandra/183/workflows/59f7ed8d-fdce-4054-a007-4aea99dfeb89]

It seems that for trunk there is a failure in {{InsertUpdateIfConditionTest.testConditionalDelete}}.;;;","16/Feb/21 21:51;yifanc;Thanks you [~jlewandowski] for the patches.

The review comments were put in the corresponding PRs. 

The approach/workaround sounds good. It fixes the wrong check and it can largely _reduce_ the occurrence of digest mismatches during upgrade. The gossip based cluster-wide version checking is still possible to produce small time windows that nodes involved in reads hold different knowledge about the Cassandra versions in the cluster, hence the digest mismatches. However, I cannot think of a better way to fully eliminate, since the semantics of the ColumnFilter has been changed multiple times without message version change and we cannot distinguish.

We should also change the title of the ticket. It is a bug fix instead of fixing a broken test. [~jlewandowski], please update with whatever you think is more suitable to describe the bug. ;;;","17/Feb/21 07:42;jlewandowski;thank you [~yifanc] for reviewing

 

All in all, I don't think messaging version change would help there. The problem is that we need to know the version upfront, when executing query locally. We do not know the version yet, because we do not know which replicas are going to be queried. On the other hand, I suppose that when we choose a node as a replica we want to query, we probably already have its endpoint state data populated, thus its version too (though, I'm not sure, I haven't followed the code carefully).

If it was just a messaging version, I could imagine that (since 4.0 is not yet released) we introduced a new version in 3.11 patch release and just incremented the messaging version in 4.0. This way we would fix it properly for 3.0 -> 3.11.new and for 3.11.new -> 4.0.

 

I'm going to fix that unit test mentioned by [~adelapena]. I don't think it will be just a unit test fix, I suppose it will be a change in production code :/;;;","17/Feb/21 10:56;jlewandowski;For the problem discovered by {{InsertUpdateIfConditionTest}} I must say it is probably caused by partial lack of CASSANDRA-13025 in {{trunk}}. I don't know if it was on purpose or it was a merge conflict or what - there were some changes in {{CASRequest}} in 3.0 and 3.11, but in {{trunk}} {{CASRequest}} became an interface and the actual implementation is in {{CQL3CASRequest}}. I assume that it could cause the merge conflict which was not solved properly. 

 

I updated tests a bit in the following ways:
 * so far, all the tests which do not touch {{Gossiper}} could run assuming the cluster is upgrading from null version - I've changed it so if the {{Gossiper}} is not started, we do not assume any upgrade
 * I've created a utility method to setup {{Gossiper}} to mimic upgrade from certain version
 * {{ColumnFilterTest}} and {{InsertUpdateIfConditionTest}} are now parameterized with the minimum version so we test all scenarios

 ;;;","19/Feb/21 18:00;adelapena;Running CI again:

 * [3.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/187/workflows/24f1480f-428f-4816-9af6-2cf751ee9cdc]
 * [3.11|https://app.circleci.com/pipelines/github/adelapena/cassandra/189/workflows/7acb9496-96a5-46b5-ace5-cb651ca2eb6c]
 * [trunk (j8)|https://app.circleci.com/pipelines/github/adelapena/cassandra/188/workflows/1730c947-cd63-4b8b-b4e9-7ba896a945c7]
 * [trunk (j11)|https://app.circleci.com/pipelines/github/adelapena/cassandra/188/workflows/1161f852-1570-420d-b8b3-2a9c6b88ac5d];;;","20/Feb/21 09:57;mck;Matching CI runs on ci-cassandra:
- [3.0|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/389/pipeline]
- [3.11|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/390/pipeline]
- [trunk|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/391/pipeline];;;","23/Feb/21 18:09;adelapena;New CI rounds for the last changes:

* [3.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/192/workflows/7c49eee3-4e2b-4140-bc09-30d80eeb20f7]
* [3.11|https://app.circleci.com/pipelines/github/adelapena/cassandra/190/workflows/4941bf2b-fef2-4cda-aae9-7e2b3e8614a2]
* [trunk (j8)|https://app.circleci.com/pipelines/github/adelapena/cassandra/191/workflows/c5b5107d-70cc-4fcf-8794-fc3b2d903b22]
* [trunk (j11)|https://app.circleci.com/pipelines/github/adelapena/cassandra/191/workflows/0be9401d-a625-4fd8-9cb6-e43d8c181629];;;","24/Feb/21 17:04;adelapena;I'd say the CI results look good. The upgrade test {{mixedModeReadColumnSubsetDigestCheck}} consistently fails on trunk, but I think that's because CI is picking a 3.11 version without the changes proposed here, so we'll have to trust the local runs.;;;","25/Feb/21 19:34;yifanc;+1 on all 3 patches.  ;;;","25/Feb/21 20:10;adelapena;This is looking good to me too, there are only a few remaining nits in the 3.11 and trunk PRs. I have rebased the PRs in separate branches and run CI once again:
 * [CircleCI 3.0|https://app.circleci.com/pipelines/github/adelapena/cassandra/197/workflows/0ced7a12-0872-4b42-b828-e60033b18b47]
 * [CircleCI 3.11|https://app.circleci.com/pipelines/github/adelapena/cassandra/198/workflows/3f84c4e0-1bed-4bef-b832-4c7f39427d10]
 * [CircleCI trunk j8|https://app.circleci.com/pipelines/github/adelapena/cassandra/196/workflows/962b06b5-a7e3-4b1d-8542-a9c0de9db236]
 * [CircleCI trunk j11|https://app.circleci.com/pipelines/github/adelapena/cassandra/196/workflows/d0ffe732-0184-4639-af02-deabdb2627d9]
 * [ci-cassandra 3.0|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/413/pipeline]
 * [ci-cassandra 3.11|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/414/pipeline]
 * [ci-cassandra trunk|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/415/pipeline]

ci-cassandra is taking longer than usual, but I'd say the circle-ci results look good and the failures on it are not related.;;;","25/Feb/21 22:29;jlewandowski;Thank you for reviewing and testing. I've applied the remaining comments from Andres and squashed my commits;;;","26/Feb/21 14:40;adelapena;Thanks for the changes. There are still a few unneeded {{throws Exception}} on the column filter test for 3.11 and trunk that I can easily remove on commit, if that's ok for you. Other than this nit the changes look good to me.

It seems that the runs in ci-cassandra above took longer than usual which I think can produce some test failures, I have re-run those runs:
 * [ci-cassandra 3.0|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/418/pipeline]
 * [ci-cassandra 3.11|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/417/pipeline]
 * [ci-cassandra trunk|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/416/pipeline]

Curiously it seems that for 3.11 the tests {{SASIIndexTest#testIndexRedistribution/testPagination}} fail consistently, when they were occasionally flaky without the patch. Nevertheless the flakiness of these tests is being addressed in CASSANDRA-16444 so I think it's safe to consider the failures as not related.

[~yifanc] if the CI results above look good to you I can proceed to commit.;;;","26/Feb/21 17:13;yifanc;Thanks for running the test!

The test failures from [ci-cassandra 3.0|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/418/pipeline] do not look related.

The test failures from [ci-cassandra 3.11|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/417/pipeline] do not look related. The test {{SASIIndexTest#testIndexRedistribution/testPagination}} does not touch the {{ColumnFilter.Serializer#deserialize}} code path.

The test failures from [ci-cassandra trunk|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/416/pipeline] mostly look unrelated. There is one failure I need to point out, {{mixedModeReadColumnSubsetDigestCheck – org.apache.cassandra.distributed.upgrade.MixedModeReadTest}}. However, it cannot be reproduced by running the test repeatedly on my local. The dtest jars were built from all 3 patched branches. I think Jenkins built the v30/v3x jvm dtest jars from HEAD instead of the patched branches, which explains the failure.

So, +1 on proceed to commit.

Beside, I'd *strongly* suggest to update the title of the ticket, so it provides more clarity on what is the problem the patch to solve. As mentioned in the earlier comment, it is not just fixing the broken test.;;;","01/Mar/21 12:53;adelapena;Committed to 3.0 as [865b67b21d326728936f0b80681129c73a2e374a|https://github.com/apache/cassandra/commit/865b67b21d326728936f0b80681129c73a2e374a] and merged up to [cassandra-3.11|https://github.com/apache/cassandra/commit/0541c5199690757294c40d9adfd1b86419158675] and [trunk|https://github.com/apache/cassandra/commit/d1f3d40afc5d20bab70c6200508baa3cd9409458].;;;","04/Mar/21 23:05;aholmber;It looks to me like some changes here broke a couple of tests.
https://app.circleci.com/pipelines/github/aholmberg/cassandra/206/workflows/d1b3d7d4-5f4e-4485-9767-c2666aad86bd/jobs/2386

The test is failing because the statement is printing wrong in the slow query log:
{{<SELECT */* FROM ks.t_skinny WHERE  LIMIT 5000>}}

I haven't created a new ticket yet. Will do tomorrow if no one gets to it.;;;","04/Mar/21 23:21;adelapena;[~aholmber] CASSANDRA-16483 has already been created for this. I have an almost ready patch adding a new {{ColumnFilter#toCQLString}} method for query logging, so we can keep the changes in {{ColumnFilter#toString}} added in this ticket, although I still need to add some additional dtests. Probably it will be ready for review tomorrow.;;;","05/Mar/21 13:42;aholmber;got it. Sorry, I just noticed on the way out and didn't make the connection.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,
nodetool status doesn't work without system_traces,CASSANDRA-16412,13355219,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,brandon.williams,brandon.williams,28/Jan/21 15:16,25/Apr/21 11:31,13/Jul/23 08:40,19/Feb/21 21:38,4.0,4.0-rc1,,,,,,Tool/nodetool,,,,0,,,"bq. Error: The node does not have system_traces yet, probably still bootstrapping

There's no reason we can't show status because of this, we can simply log that the effective ownership is unknown, like we used to, rather than forcing a user to go to another machine to find out what's going on in the ring.
",,adelapena,bereng,e.dimitrova,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Availability,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Feb 19 21:38:07 UTC 2021,,,,,,,All,,,,"0|z0n3fc:",9223372036854775807,,,,brandon.williams,,,,Normal,,4.0-beta1,,https://github.com/apache/cassandra/commit/5ed5e84613ef0e9664a774493db7d2604e3596e0,,,,,,,,,See PR,,,,,"28/Jan/21 17:22;brandon.williams;Also note that when system_traces does exist, the effective ownership is still unknown and displayed as '?', so this delay is pointless.;;;","11/Feb/21 14:50;e.dimitrova;Good news [~brandon.williams] , I think what you mentioned is already fixed actually as part of CASSANDRA-16283, it was a week or two ago :) ;;;","11/Feb/21 14:54;brandon.williams;Ah, yes.  Well at least that much is fixed here :);;;","11/Feb/21 14:56;e.dimitrova;Yes, Indeed, that looked ugly :) ;;;","15/Feb/21 10:57;bereng;Hi quick q to see if iiuc. Are you guys suggesting?

{noformat}
./nodetool status

Error: The node does not have system_traces yet, probably still bootstrapping
{noformat}

should instead be?

{noformat}
./nodetool status
Datacenter: datacenter1
=======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address    Load       Tokens  Owns  Host ID                               Rack 
UN  127.0.0.1  79.49 KiB  16      ?     39a22b2d-cd2e-41cc-b613-53ba78b6564b  rack1

Note: Unkown ownership as we're still bootstrapping.
{noformat};;;","18/Feb/21 15:59;brandon.williams;Yes, I don't want to throw the baby out with the bathwater just because we don't know the ownership; there's plenty of other useful information.;;;","19/Feb/21 11:39;bereng;Up for review iiuc what was being asked.;;;","19/Feb/21 21:38;brandon.williams;Committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix topology corruption on joining nodes without DC in dtests,CASSANDRA-16411,13355097,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bereng,bereng,bereng,28/Jan/21 06:51,20/Feb/21 10:53,13/Jul/23 08:40,19/Feb/21 16:40,4.0,4.0-rc1,,,,,,Test/dtest/python,,,,0,,,"Dtests with multi-dc setups don't update the topology properties file of a newly joining node without dc post cluster creation.

The new node will join dc1 but it's snitch will report the default snitch config as it doesn't get updated == dc1 == all nodes are in dc1 == there are no other dcs. That leads to bootstrap, token, startup,... problems. Let's see an example:
- populate [1, 1, 1]
- Node1 sees: dc1/ip1, dc2/ip2 and dc3/ip3
- Node2 sees: dc1/ip1, dc2/ip2 and dc3/ip3
- Node3 sees: dc1/ip1, dc2/ip2 and dc3/ip3
- Add a new Node4
- Node4 sees: dc1/ip1+ip2+ip3+ip4

All multi-dc dtests that add a node after cluster creation suffer this problem.

Solution: When a new node is added without specifying a dc in dtests check for existing dcs. If there are any force to specify one to update the topology file.",,adelapena,bereng,e.dimitrova,mck,tomasz.lasica,,,,,,,,,,,"bereng opened a new pull request #125:
URL: https://github.com/apache/cassandra-dtest/pull/125


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Feb/21 07:14;githubbot;600","michaelsembwever closed pull request #125:
URL: https://github.com/apache/cassandra-dtest/pull/125


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Feb/21 10:53;githubbot;600","michaelsembwever commented on pull request #125:
URL: https://github.com/apache/cassandra-dtest/pull/125#issuecomment-782605528


   Merged with https://github.com/apache/cassandra-dtest/commit/8762267b13fffb921ae79b0220630f10695ee9d9


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Feb/21 10:53;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,CASSANDRA-16296,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,bereng,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Feb 19 17:18:49 UTC 2021,,,,,,,All,,,,"0|z0n2o8:",9223372036854775807,,,,adelapena,bereng,e.dimitrova,tomasz.lasica,Normal,,NA,,8762267b13fffb921ae79b0220630f10695ee9d9 https://github.com/riptano/ccm/commit/e5870fd081a927b6d4bad47719b1b1f893d70c3e https://github.com/apache/cassandra-dtest/commit/ad9462ee737ebc92a86cb5b266fccdd93e1111a9,,,,,,,,,See ticket,,,,,"28/Jan/21 08:10;bereng;The change is in the ccm repo. Dtest repro just points to the new cmm and cassandra repro just points to the new dtests repro.

Testing involved raising at least 2 nodes + a 3rd one so it was unnecessarily heavy. Testing for this ticket will be added in CASSANDRA-16296 where we already need such a cluster for the sake QA speed.;;;","28/Jan/21 12:59;bereng;CI:
 - ci-cass: [dtests|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/349/] + the splits where docker failed [here|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-dtest/350/]. cqlsh-dtests [here|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-cqlsh-tests/486/]
- circle: [j11|https://app.circleci.com/pipelines/github/bereng/cassandra/200/workflows/163604d7-5789-4ecd-bc38-655a5dee4f83] & [j8|https://app.circleci.com/pipelines/github/bereng/cassandra/200/workflows/51b54945-5ba5-416b-8e3b-69a77403baa2]. Lots of failures on github clone failures but still dtests and unit tests did run. The only failing dtest on consistency passes locally after looping 50 times. The other failures are known offenders.;;;","07/Feb/21 20:55;e.dimitrova;I believe we already got a consensus on this solution.

Do we need CI run with older Cassandra versions?;;;","08/Feb/21 06:39;bereng;Yep [~e.dimitrova] we did that on the PR :-);;;","08/Feb/21 15:46;e.dimitrova;Thanks [~Bereng], I found the links.

Posting here for visibility:
 * [2.1|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/370/]
 * [2.2|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/371/]
 * [3.0|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/372/]
 * [3.11|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/373/]
 * [trunk|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/374/]

I saw only one new commitlog related test failure on trunk but it is also failing with other unrelated patches in dev, also it seems it has nothing in common with this one.

+1 from me, thank you;;;","09/Feb/21 05:20;bereng;I _think_ this is +1 from [~e.dimitrova] and [~adelapena] so we can move to commit? Please correct me if I am wrong.;;;","09/Feb/21 09:09;tomasz.lasica;+1 from me, but of course not required ;);;;","09/Feb/21 12:11;adelapena;+1 from me too;;;","09/Feb/21 15:01;e.dimitrova;[~tomasz.lasica] your +1 is required as you made a review and provided a valuable input. Thank you for doing it! 

[~adelapena] do you have commit rights for the ccm repo? I don't think I have, I will try to contact service desk but that might take some time;;;","09/Feb/21 16:56;adelapena;[~e.dimitrova] I think I don't have permissions either. Also, the PR seems to be in need of rebase due to some little conflicts.;;;","09/Feb/21 23:40;e.dimitrova;Rebased and squashed:

[CCM |https://github.com/ekaterinadimitrova2/ccm/tree/CASSANDRA-16296-CcmBug] | [DTests |https://github.com/ekaterinadimitrova2/cassandra-dtest/tree/CASSANDRA-16296-CcmBug]

Jenkins run in progress:
 [2.1|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/381/]
 [2.2|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/382/]
 [3.0|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/383/]
 [3.11|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/384/]
 [trunk|https://ci-cassandra.apache.org/view/all/job/Cassandra-devbranch-dtest/380/];;;","10/Feb/21 04:20;e.dimitrova;There are some failures, I can check them tomorrow morning;;;","10/Feb/21 05:30;bereng;Agreed to every reviewer's +1 and thanks all for your work :-)

Failures 'look ok'. I think they are just flaky but I don't know for the <=2.2...;;;","10/Feb/21 15:21;e.dimitrova;Indeed, CI results look fine to me, the regular flakiness plus one timeout in materialized_views test which seems unrelated and random. 

Starting commit soon;;;","10/Feb/21 16:14;e.dimitrova;CCM patch committed [here|https://github.com/riptano/ccm/commit/e5870fd081a927b6d4bad47719b1b1f893d70c3e]. Retag done as per CASSANDRA-16383.
DTests patch committed [here|https://github.com/apache/cassandra-dtest/commit/ad9462ee737ebc92a86cb5b266fccdd93e1111a9];;;","10/Feb/21 16:21;bereng;Yes. Thx [~e.dimitrova], [~tomasz.lasica] and [~adelapena].;;;","11/Feb/21 07:20;bereng;The nightly CI looks good. No weird dtest failures :-);;;","15/Feb/21 06:10;bereng;In the [latest|https://ci-cassandra.apache.org/job/Cassandra-trunk/274/#showFailuresLink] ci-cass I see this message kicking in for a handful dtest-large tests. I'll get a PR ready but I am curious why neither circle or devBranch CI picked it... They don't seem to be ran there so there's little we could have done to catch that iiuc.;;;","15/Feb/21 07:15;bereng;Reopening upon a handful of dtest-large failures that CI doesn't run. Tests can only be tested locally and fail/pass before/after the fix whic is pretty non-controversial imo. See [PR|https://github.com/apache/cassandra-dtest/pull/125];;;","16/Feb/21 18:08;e.dimitrova;Looking at the usages of that function, did you check the upgrade tests? I think they are also run on demand in Jenkins, right? 

I just pushed them in Jenkins [here |https://jenkins-cm4.apache.org/job/Cassandra-devbranch-dtest-upgrade/35/];;;","17/Feb/21 05:17;bereng;They look ok to me but that was a another set of tests circle doesn't run so good you ran them :-);;;","17/Feb/21 15:09;e.dimitrova;+1 from me;;;","19/Feb/21 05:44;bereng;Are we waiting on anything here for the commit? Asking as it would be good to clear these failures from the runs to reduce flakiness noise?;;;","19/Feb/21 16:40;mck;Coordinated with everyone, and committed remaining fix as [8762267b13fffb921ae79b0220630f10695ee9d9|https://github.com/apache/cassandra-dtest/commit/8762267b13fffb921ae79b0220630f10695ee9d9].;;;","19/Feb/21 17:18;bereng;Thx all for the reviews and work here :-);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Table Metrics table in ""doc/source/operating/metrics.rst"" cannot be rendered",CASSANDRA-16410,13355082,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,yifanc,yifanc,yifanc,28/Jan/21 05:21,25/Feb/21 10:10,13/Jul/23 08:40,01/Feb/21 22:02,4.0,4.0-rc1,,,,,,Documentation/Website,,,,0,,,"The page, [https://cassandra.apache.org/doc/latest/operating/metrics.html#table-metrics], is missing the table for table metrics. 

The cause is that the ""="" in the docs source that defines the table is not properly aligned. ",,blerer,yifanc,,,,,,,,,,,,,,"yifan-c opened a new pull request #880:
URL: https://github.com/apache/cassandra/pull/880


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Jan/21 05:42;githubbot;600","yifan-c merged pull request #880:
URL: https://github.com/apache/cassandra/pull/880


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Feb/21 21:59;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jan/21 05:44;yifanc;snapshot.png;https://issues.apache.org/jira/secure/attachment/13019547/snapshot.png",,,,,1.0,yifanc,,,,,,,,,,,,,Documentation,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Feb 01 22:02:08 UTC 2021,,,,,,,All,,,,"0|z0n2kw:",9223372036854775807,,,,blerer,,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/d12cb030690a2673a88d043a265382bdbc7f0009,,,,,,,,,Built source manually and verified the docs html page contains the table. ,,,,,"28/Jan/21 05:45;yifanc;Tiny 1 line fix. [https://github.com/apache/cassandra/pull/880]

Built the source and the table appeared. 

!snapshot.png|width=665,height=580!;;;","29/Jan/21 22:34;yifanc;[~blerer], thanks for reviewing and approving the PR. Would you like to +1 on JIRA? ;;;","30/Jan/21 13:18;blerer;+1;;;","01/Feb/21 22:02;yifanc;Committed to trunk as [d12cb030690a2673a88d043a265382bdbc7f0009|https://github.com/apache/cassandra/commit/d12cb030690a2673a88d043a265382bdbc7f0009]. ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bugs in CQLSH tests,CASSANDRA-16409,13354899,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,27/Jan/21 10:48,28/Jan/21 11:58,13/Jul/23 08:40,28/Jan/21 11:58,4.0,4.0-rc1,,,,,,CI,CQL/Interpreter,Test/dtest/python,,0,,,"There are some bugs in Python CQLSH tests which causes problems when testing in some environments - it hit me when I tried to test that on Mac. In particular the tests seem to be sensitive to terminal settings and Python version (and it seems like the operating system too). 

 ",,jlewandowski,mck,,,,,,,,,,,,,,"jacek-lewandowski opened a new pull request #876:
URL: https://github.com/apache/cassandra/pull/876


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;27/Jan/21 14:17;githubbot;600","michaelsembwever closed pull request #876:
URL: https://github.com/apache/cassandra/pull/876


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Jan/21 11:57;githubbot;600","michaelsembwever commented on pull request #876:
URL: https://github.com/apache/cassandra/pull/876#issuecomment-769005015


   Committed with https://github.com/apache/cassandra/commit/91cb934e25020f83dcb289be9c03292579b5d33b


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Jan/21 11:57;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1200,,,0,1200,,,,,,,,,,,,,CASSANDRA-10190,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jlewandowski,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jan 28 11:58:25 UTC 2021,,,,,,,All,,,,"0|z0n1gg:",9223372036854775807,,,,mck,,,,Low,,4.0-alpha4,,https://github.com/apache/cassandra/commit/91cb934e25020f83dcb289be9c03292579b5d33b,,,,,,,,,CI,,,,,"28/Jan/21 10:20;jlewandowski;The fixes are minimal for Linux based OS. I tried on MacOS with no success, it looks like everything works differently on Mac.

Note for running CQLSH tests - they should be run with a fixed Python environment, 3.9.x I guess because those tests are compatible with Python 3. We should not run them using Python2. Now, if we want to test CQLSH running with different Python versions, we should do that by exporting {{CQLSH_PYTHON=<python_executable>}} instead of running those tests with different environments. We need to clearly separate which Python is used for running the tests (this should be fixed on Python 3.9+) and against which Python version we run the the underlying CQLSH process.

Given the above note, I've tested locally on Ubuntu, with virtual env = 3.9.1 and:
{noformat}
CQLSH_PYTHON=python2.7 nosetests
CQLSH_PYTHON=python3.6 nosetests
CQLSH_PYTHON=python3.7 nosetests
CQLSH_PYTHON=python3.8 nosetests
CQLSH_PYTHON=python3.9 nosetests
{noformat}

Note that without the attached fix, some tests are failing because of either the environment being overwritten by tests or by hostname mismatch (too strict regexp).
;;;","28/Jan/21 11:49;mck;+1

CI: https://ci-cassandra.apache.org/job/Cassandra-devbranch-cqlsh-tests/484/;;;","28/Jan/21 11:53;mck;PR at https://github.com/apache/cassandra/pull/876

;;;","28/Jan/21 11:58;mck;Committed as [91cb934e25020f83dcb289be9c03292579b5d33b|https://github.com/apache/cassandra/commit/91cb934e25020f83dcb289be9c03292579b5d33b];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Debug logging affects repair performance,CASSANDRA-16406,13354443,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,adejanovski,adejanovski,adejanovski,25/Jan/21 13:39,16/Mar/22 15:22,13/Jul/23 08:40,28/Jan/21 09:54,4.0,4.0-rc1,,,,,,Consistency/Repair,,,,0,,,"While working on the repair quality testing in CASSANDRA-16245, it appeared that the node coordinating repairs on a 20GB per node dataset was generating more than 2G of log with a total duration for the incremental repair scenarios of ~2h40m: 
https://app.circleci.com/pipelines/github/riptano/cassandra-rtest/37/workflows/6a7a41c8-0fca-4080-b37e-3b38998b3fab/jobs/49/steps
 ]
 !with_debug_logging.png!  
 The logs showed a lot of messages from the MerkleTree class at high pace:
{noformat}
DEBUG [RepairJobTask:4] 2021-01-21 16:15:29,631 MerkleTree.java:308 - (10) Fully inconsistent range [#<TreeRange (-6738651767434294419,-6738622715859497972] depth=11>, #<TreeRange (-6738622715859497972,-6738593664284701525] depth=11>]
DEBUG [RepairJobTask:4] 2021-01-21 16:15:29,631 MerkleTree.java:292 - (9) Inconsistent digest on right sub-range #<TreeRange (-6738593664284701525,-6738535561135108630] depth=10>: [#<OffHeapInner -6738564612709905078 hash=[b8efd3d684474276f316b1bc9f23b463cda4f8d620a4b5cf4d2c7dbb101bbe85] children=[#<OffHeapLeaf [fff431a30da07558c5106897da9f3fc3bcc598fb59e67c6959f4e70b6d3a7722]> #<OffHeapLeaf [471be27589e7372e3606d92b45bc8ba07161602d7942c9a614d89ab07d21c9a7]>]>, #<OffHeapInner -6738564612709905078 hash=[95334327a0b50b7d3c51d6588a5f3d57701e0b978f6ab28e85cda3cb5a094eb5] children=[#<OffHeapLeaf [0d2c5c21f6b04b098f71f43d0f3f3a5a823b372eb850261774847c456629bedd]> #<OffHeapLeaf [981f1f0656054074b32022658560070df2253cb9373a9499f149df8e3c20f068]>]>]
DEBUG [RepairJobTask:4] 2021-01-21 16:15:29,631 MerkleTree.java:262 - (10) Hashing sub-ranges [#<TreeRange (-6738593664284701525,-6738564612709905078] depth=11>, #<TreeRange (-6738564612709905078,-6738535561135108630] depth=11>] for #<TreeRange (-6738593664284701525,-6738535561135108630] depth=10> divided by midpoint -6738564612709905078
DEBUG [RepairJobTask:4] 2021-01-21 16:15:29,631 MerkleTree.java:272 - (10) Inconsistent digest on left sub-range #<TreeRange (-6738593664284701525,-6738564612709905078] depth=11>: [#<OffHeapLeaf [fff431a30da07558c5106897da9f3fc3bcc598fb59e67c6959f4e70b6d3a7722]>, #<OffHeapLeaf [0d2c5c21f6b04b098f71f43d0f3f3a5a823b372eb850261774847c456629bedd]>]
DEBUG [RepairJobTask:4] 2021-01-21 16:15:29,631 MerkleTree.java:292 - (10) Inconsistent digest on right sub-range #<TreeRange (-6738564612709905078,-6738535561135108630] depth=11>: [#<OffHeapLeaf [471be27589e7372e3606d92b45bc8ba07161602d7942c9a614d89ab07d21c9a7]>, #<OffHeapLeaf [981f1f0656054074b32022658560070df2253cb9373a9499f149df8e3c20f068]>]
DEBUG [RepairJobTask:4] 2021-01-21 16:15:29,631 MerkleTree.java:308 - (10) Fully inconsistent range [#<TreeRange (-6738593664284701525,-6738564612709905078] depth=11>, #<TreeRange (-6738564612709905078,-6738535561135108630] depth=11>]
DEBUG [RepairJobTask:4] 2021-01-21 16:15:29,631 MerkleTree.java:308 - (9) Fully inconsistent range [#<TreeRange (-6738651767434294419,-6738593664284701525] depth=10>, #<TreeRange (-6738593664284701525,-6738535561135108630] depth=10>]
DEBUG [RepairJobTask:4] 2021-01-21 16:15:29,631 MerkleTree.java:292 - (8) Inconsistent digest on right sub-range #<TreeRange (-6738535561135108630,-6738419354835922841] depth=9>: [#<OffHeapInner -6738477457985515736 hash=[806ede1a35783bf5fafe8b8ccefe4d3ff48e8f0e1314f8a9ce4b23f13fed4bf9] children=[#<OffHeapInner -6738506509560312183 hash=[e6d133afbd8041266f8a1cfe456ff07c9e7debe8ff54279b579b252f2af78b6b] children=[#]> #<OffHeapInner -6738448406410719289 hash=[66bfedb588f87ad3957497728b91bd436af364e6ec40df3299d006de151ac092] children=[#]>]>, #<OffHeapInner -6738477457985515736 hash=[bf128431ddf7ad72417ce853f90abd0bc7a2a38088d5fbec864c02c516ed6458] children=[#<OffHeapInner -6738506509560312183 hash=[12a71b62ceb096369c4797f56edd91a16dd9803348b4f4cfe1454027d7dae3d2] children=[#]> #<OffHeapInner -6738448406410719289 hash=[adb59f5313473b44dd3b7fa697d72caaaa7b23b3c0610f23670942e2c137878a] children=[#]>]>]{noformat}
When disabling debug logging, the duration dropped to ~2h05m with decent log sizes:

[https://app.circleci.com/pipelines/github/riptano/cassandra-rtest/38/workflows/c91e6ceb-438b-4f00-b38a-d670f9afb4c3/jobs/51]

!without_debug_logging.png!

There's apparently too much logging for each inconsistency found in the Merkle tree comparisons and we should move this to TRACE level if we still want to allow debug logging to be turned on by default.

I'll prepare a patch for the MerkleTree class and run the repair testing scenarios again to verify their duration.",,adejanovski,marcuse,,,,,,,,,,,,,,"smiklosovic closed pull request #881:
URL: https://github.com/apache/cassandra/pull/881


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:22;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,600,,,0,600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jan/21 08:13;adejanovski;16406-2-trunk.txt;https://issues.apache.org/jira/secure/attachment/13019551/16406-2-trunk.txt","28/Jan/21 07:24;adejanovski;CASSANDRA-16406.png;https://issues.apache.org/jira/secure/attachment/13019549/CASSANDRA-16406.png","25/Jan/21 13:26;adejanovski;with_debug_logging.png;https://issues.apache.org/jira/secure/attachment/13019308/with_debug_logging.png","25/Jan/21 13:29;adejanovski;without_debug_logging.png;https://issues.apache.org/jira/secure/attachment/13019307/without_debug_logging.png",,4.0,adejanovski,,,,,,,,,,,,,Degradation -> Resource Management,,,,,,,,Normal,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jan 28 09:54:18 UTC 2021,,,,,,,All,,,,"0|z0myn4:",9223372036854775807,,,,marcuse,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/f4be27fd079690aab67eaac04bd237b1018140a9,,,,,,,,,"Here's the CircleCI link for the patched run of the repair quality tests: [https://app.circleci.com/pipelines/github/riptano/cassandra-rtest/73/workflows/0828fcad-26d2-43d6-9c8c-7a4102b0e31c]

Full and Incremental test runs lasted 30 minutes less than the current trunk.",,,,,"25/Jan/21 13:50;adejanovski;[~spod], seems like you added most of these debug loggings.

Are you ok with me moving them to TRACE level?;;;","28/Jan/21 07:37;adejanovski;I ran the repair quality test using the [patched branch|https://github.com/apache/cassandra/compare/trunk...adejanovski:CASSANDRA-16406?expand=1] and got the expected 30 minutes reduction on the full and incremental test suites: 

!CASSANDRA-16406.png!

 

[PR|https://github.com/apache/cassandra/pull/881]
 [Branch|https://github.com/adejanovski/cassandra/tree/CASSANDRA-16406]

I've attached the patch.;;;","28/Jan/21 08:01;marcuse;+1 - there is some excessive debug logging in {{RepairJob#createOptimisedSyncingSyncTasks}} as well, could you move them to {{trace}} as well and I'll get this committed?;;;","28/Jan/21 08:14;adejanovski;Done, and I attached the updated patch to the ticket.;;;","28/Jan/21 08:31;marcuse;running tests here: https://app.circleci.com/pipelines/github/krummas/cassandra?branch=CASSANDRA-16406;;;","28/Jan/21 09:54;marcuse;and committed, test failures look unrelated;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cqlsh cannot DESC TYPE with non-ascii character in the identifier,CASSANDRA-16400,13354018,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,aholmber,aholmber,aholmber,22/Jan/21 19:06,17/May/21 19:57,13/Jul/23 08:40,17/May/21 19:57,4.0,4.0-rc2,,,,,,Tool/cqlsh,,,,0,,,"cqlsh fails to describe types with non-ascii characters. This is specific to Python 2 and does not occur in Python 3 (only tested on trunk so far).

{code}
CREATE TYPE ks.""ࠑ "" (
    v int
);
{code}

{noformat}
aholmberg-rmbp16:cassandra adamholmberg$ pyenv shell 2.7.17
aholmberg-rmbp16:cassandra adamholmberg$ bin/cqlsh
Connected to Test Cluster at 127.0.0.1:9042.
[cqlsh 5.0.1 | Cassandra 4.0-beta4-SNAPSHOT | CQL spec 3.4.5 | Native protocol v4]
Use HELP for help.
cqlsh> desc types;
Traceback (most recent call last):
  File ""/Users/adamholmberg/code/cassandra/bin/cqlsh.py"", line 1391, in do_describe
    self.describe_list(result)
  File ""/Users/adamholmberg/code/cassandra/bin/cqlsh.py"", line 1438, in describe_list
    names.append(str(row['name']))
UnicodeEncodeError: 'ascii' codec can't encode character u'\u0811' in position 1: ordinal not in range(128)
{noformat}


3.11 appears to handle everything properly.",,aholmber,djatnieks,e.dimitrova,jeromatron,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16539,,,,,,0.0,aholmber,,,,,,,,,,,,,Availability -> Unavailable,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon May 17 19:57:38 UTC 2021,,,,,,,All,,,,"0|z0mw0o:",9223372036854775807,,,,brandon.williams,e.dimitrova,,,Low,,4.0-alpha1,,https://github.com/apache/cassandra/commit/0301fc6cea733b939066d197effa611a41bb787b,,,,,,,,,unit test expanded,,,,,"08/Apr/21 21:05;aholmber;The patch is based on my branch for CASSANDRA-16539 since it builds on a test introduced there.

[patch|https://github.com/aholmberg/cassandra/pull/52]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16400-trunk];;;","04/May/21 14:20;brandon.williams;Patch seems to have some development testing bits still applied, such as changes to cassandra.yaml;;;","04/May/21 15:08;aholmber;Sorry, that was a mistake. Will push an updated branch shortly.;;;","04/May/21 16:21;aholmber;[updated PR|https://github.com/aholmberg/cassandra/pull/58]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16400];;;","04/May/21 16:55;brandon.williams;Committed, thanks.;;;","06/May/21 21:37;aholmber;This was [reverted|https://github.com/apache/cassandra/commit/a3db11831a0a7dd53c69da8df93bb9c35bc43eca] when it [failed on Jenkins|https://jenkins-cm4.apache.org/job/Cassandra-4.0/4/] running python3.;;;","07/May/21 21:26;aholmber;Giving this another try. I couldn't get the thing to fail the same way anywhere but jenkins. While experimenting with this, I did recall that there were some platform and runtime differences that sometimes cause non-visible control sequences to appear in the echo buffer, blowing up the check for identical echo. I updated the test to work around that since it's not actually the thing being tested.

[updated PR|https://github.com/aholmberg/cassandra/pull/58/commits/054e019025a953b1e35174c6f57141fe2a84df0c]
[ci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16400];;;","08/May/21 17:08;e.dimitrova;Jenkins CI run pushed [here|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/759/];;;","10/May/21 19:36;aholmber;Previous CI run failed, apparently on a transient error in the build script. Ekaterina started another one [here|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/761/].;;;","12/May/21 17:03;aholmber;[updated branch|https://github.com/aholmberg/cassandra/pull/58/files]
[clean ci|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/767/testReport/cqlshlib.python3.jdk8.cython.test.test_unicode/TestCqlshUnicode/];;;","12/May/21 17:55;e.dimitrova;LGTM, [~brandon.williams] is out this week but if [~adelapena] or [~mck] wants to take a look too, would be great.

Thank you;;;","17/May/21 19:57;brandon.williams;Committed, thanks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Selecting resource intensive tests is not consistent,CASSANDRA-16399,13353921,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jlewandowski,jlewandowski,jlewandowski,22/Jan/21 07:52,28/Jan/21 11:03,13/Jul/23 08:40,28/Jan/21 11:03,2.2.20,3.0.24,3.11.10,4.0,4.0-rc1,,,Test/dtest/python,,,,0,,,"It looks like there are two problems:
 - collection of tests to run fails when there are log messages in stderr
 - collection of resource intensive tests (with
{code:java}
--only-resource-intensive-tests{code}
) is broken

 ",,jlewandowski,mck,tomasz.lasica,,,,,,,,,,,,,"jacek-lewandowski opened a new pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Jan/21 07:57;githubbot;600","tlasica commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r562460898



##########
File path: conftest.py
##########
@@ -602,20 +609,17 @@ def pytest_collection_modifyitems(items, config):
             if deselect_test:
                 logger.info(""SKIP: Deselecting non-upgrade test %s because of --execute-upgrade-tests-only"" % item.name)
 
-        if item.get_closest_marker(""resource_intensive"") and not collect_only:
-            force_resource_intensive = config.getoption(""--force-resource-intensive-tests"")
-            skip_resource_intensive = config.getoption(""--skip-resource-intensive-tests"")
-            if not force_resource_intensive:
-                if skip_resource_intensive:
-                    deselect_test = True
-                    logger.info(""SKIP: Deselecting test %s as test marked resource_intensive. To force execution of ""
-                          ""this test re-run with the --force-resource-intensive-tests command line argument"" % item.name)
+        if item.get_closest_marker(""resource_intensive""):

Review comment:
       this code is so complex that IMO it would be reasonable to add tests in `meta_tests` with acceptance criteria validation, so that one does not have to reverse engineer the rules.
   
   decision making for single `item` should be extracted to either a class or a function so that it can be easily tested without whole configuration burden.

##########
File path: conftest.py
##########
@@ -594,6 +594,13 @@ def pytest_collection_modifyitems(items, config):
     sufficient_system_resources_resource_intensive = sufficient_system_resources_for_resource_intensive_tests()
     logger.debug(""has sufficient resources? %s"" % sufficient_system_resources_resource_intensive)
 
+    force_resource_intensive = config.getoption(""--force-resource-intensive-tests"")
+    skip_resource_intensive = config.getoption(""--skip-resource-intensive-tests"")
+    only_resource_intensive = config.getoption(""--only-resource-intensive-tests"")
+    if skip_resource_intensive and only_resource_intensive:

Review comment:
       also `skip` and `force` should not be combined?
   
   

##########
File path: conftest.py
##########
@@ -602,20 +609,17 @@ def pytest_collection_modifyitems(items, config):
             if deselect_test:
                 logger.info(""SKIP: Deselecting non-upgrade test %s because of --execute-upgrade-tests-only"" % item.name)
 
-        if item.get_closest_marker(""resource_intensive"") and not collect_only:
-            force_resource_intensive = config.getoption(""--force-resource-intensive-tests"")
-            skip_resource_intensive = config.getoption(""--skip-resource-intensive-tests"")
-            if not force_resource_intensive:
-                if skip_resource_intensive:
-                    deselect_test = True
-                    logger.info(""SKIP: Deselecting test %s as test marked resource_intensive. To force execution of ""
-                          ""this test re-run with the --force-resource-intensive-tests command line argument"" % item.name)
+        if item.get_closest_marker(""resource_intensive""):
+            if skip_resource_intensive:
+                deselect_test = True
+                logger.info(""SKIP: Deselecting test %s as test marked resource_intensive. To force execution of ""
+                            ""this test re-run with the --force-resource-intensive-tests command line argument"" % item.name)
+            elif not force_resource_intensive:
                 if not sufficient_system_resources_resource_intensive:
                     deselect_test = True
                     logger.info(""SKIP: Deselecting resource_intensive test %s due to insufficient system resources"" % item.name)
 
-        if not item.get_closest_marker(""resource_intensive"") and not collect_only:
-            only_resource_intensive = config.getoption(""--only-resource-intensive-tests"")
+        if not item.get_closest_marker(""resource_intensive""):

Review comment:
       I wonder what was the rationale for running this logic only if `not collect_only`?
   maybe there was a valid reason not to do it always?
   @michaelsembwever ?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Jan/21 08:32;githubbot;600","jacek-lewandowski commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r562473099



##########
File path: conftest.py
##########
@@ -602,20 +609,17 @@ def pytest_collection_modifyitems(items, config):
             if deselect_test:
                 logger.info(""SKIP: Deselecting non-upgrade test %s because of --execute-upgrade-tests-only"" % item.name)
 
-        if item.get_closest_marker(""resource_intensive"") and not collect_only:
-            force_resource_intensive = config.getoption(""--force-resource-intensive-tests"")
-            skip_resource_intensive = config.getoption(""--skip-resource-intensive-tests"")
-            if not force_resource_intensive:
-                if skip_resource_intensive:
-                    deselect_test = True
-                    logger.info(""SKIP: Deselecting test %s as test marked resource_intensive. To force execution of ""
-                          ""this test re-run with the --force-resource-intensive-tests command line argument"" % item.name)
+        if item.get_closest_marker(""resource_intensive""):
+            if skip_resource_intensive:
+                deselect_test = True
+                logger.info(""SKIP: Deselecting test %s as test marked resource_intensive. To force execution of ""
+                            ""this test re-run with the --force-resource-intensive-tests command line argument"" % item.name)
+            elif not force_resource_intensive:
                 if not sufficient_system_resources_resource_intensive:
                     deselect_test = True
                     logger.info(""SKIP: Deselecting resource_intensive test %s due to insufficient system resources"" % item.name)
 
-        if not item.get_closest_marker(""resource_intensive"") and not collect_only:
-            only_resource_intensive = config.getoption(""--only-resource-intensive-tests"")
+        if not item.get_closest_marker(""resource_intensive""):

Review comment:
       @tlasica It was already mentioned as a problem in https://issues.apache.org/jira/browse/CASSANDRA-16221




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Jan/21 08:45;githubbot;600","michaelsembwever commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r562474277



##########
File path: conftest.py
##########
@@ -602,20 +609,17 @@ def pytest_collection_modifyitems(items, config):
             if deselect_test:
                 logger.info(""SKIP: Deselecting non-upgrade test %s because of --execute-upgrade-tests-only"" % item.name)
 
-        if item.get_closest_marker(""resource_intensive"") and not collect_only:
-            force_resource_intensive = config.getoption(""--force-resource-intensive-tests"")
-            skip_resource_intensive = config.getoption(""--skip-resource-intensive-tests"")
-            if not force_resource_intensive:
-                if skip_resource_intensive:
-                    deselect_test = True
-                    logger.info(""SKIP: Deselecting test %s as test marked resource_intensive. To force execution of ""
-                          ""this test re-run with the --force-resource-intensive-tests command line argument"" % item.name)
+        if item.get_closest_marker(""resource_intensive""):
+            if skip_resource_intensive:
+                deselect_test = True
+                logger.info(""SKIP: Deselecting test %s as test marked resource_intensive. To force execution of ""
+                            ""this test re-run with the --force-resource-intensive-tests command line argument"" % item.name)
+            elif not force_resource_intensive:
                 if not sufficient_system_resources_resource_intensive:
                     deselect_test = True
                     logger.info(""SKIP: Deselecting resource_intensive test %s due to insufficient system resources"" % item.name)
 
-        if not item.get_closest_marker(""resource_intensive"") and not collect_only:
-            only_resource_intensive = config.getoption(""--only-resource-intensive-tests"")
+        if not item.get_closest_marker(""resource_intensive""):

Review comment:
       Not that I can remember, unfortunately :( 




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Jan/21 08:47;githubbot;600","tlasica commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r562460898



##########
File path: conftest.py
##########
@@ -602,20 +609,17 @@ def pytest_collection_modifyitems(items, config):
             if deselect_test:
                 logger.info(""SKIP: Deselecting non-upgrade test %s because of --execute-upgrade-tests-only"" % item.name)
 
-        if item.get_closest_marker(""resource_intensive"") and not collect_only:
-            force_resource_intensive = config.getoption(""--force-resource-intensive-tests"")
-            skip_resource_intensive = config.getoption(""--skip-resource-intensive-tests"")
-            if not force_resource_intensive:
-                if skip_resource_intensive:
-                    deselect_test = True
-                    logger.info(""SKIP: Deselecting test %s as test marked resource_intensive. To force execution of ""
-                          ""this test re-run with the --force-resource-intensive-tests command line argument"" % item.name)
+        if item.get_closest_marker(""resource_intensive""):

Review comment:
       this code is so complex that IMO it would be reasonable to add tests in `meta_tests` with acceptance criteria validation, so that one does not have to reverse engineer the rules.
   
   decision making for single `item` should be extracted to either a class or a function so that it can be easily tested without whole configuration burden.
   
   not blocking the fix.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Jan/21 08:48;githubbot;600","michaelsembwever commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r562474277



##########
File path: conftest.py
##########
@@ -602,20 +609,17 @@ def pytest_collection_modifyitems(items, config):
             if deselect_test:
                 logger.info(""SKIP: Deselecting non-upgrade test %s because of --execute-upgrade-tests-only"" % item.name)
 
-        if item.get_closest_marker(""resource_intensive"") and not collect_only:
-            force_resource_intensive = config.getoption(""--force-resource-intensive-tests"")
-            skip_resource_intensive = config.getoption(""--skip-resource-intensive-tests"")
-            if not force_resource_intensive:
-                if skip_resource_intensive:
-                    deselect_test = True
-                    logger.info(""SKIP: Deselecting test %s as test marked resource_intensive. To force execution of ""
-                          ""this test re-run with the --force-resource-intensive-tests command line argument"" % item.name)
+        if item.get_closest_marker(""resource_intensive""):
+            if skip_resource_intensive:
+                deselect_test = True
+                logger.info(""SKIP: Deselecting test %s as test marked resource_intensive. To force execution of ""
+                            ""this test re-run with the --force-resource-intensive-tests command line argument"" % item.name)
+            elif not force_resource_intensive:
                 if not sufficient_system_resources_resource_intensive:
                     deselect_test = True
                     logger.info(""SKIP: Deselecting resource_intensive test %s due to insufficient system resources"" % item.name)
 
-        if not item.get_closest_marker(""resource_intensive"") and not collect_only:
-            only_resource_intensive = config.getoption(""--only-resource-intensive-tests"")
+        if not item.get_closest_marker(""resource_intensive""):

Review comment:
       Not that I can remember, unfortunately :( 
   (though @jacek-lewandowski is correct, the fault has already been illustrated)




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;22/Jan/21 08:48;githubbot;600","michaelsembwever commented on pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#issuecomment-765904473


   Up to https://github.com/apache/cassandra-dtest/pull/115/commits/b4fc4f07c2cc4c2779250f672bc09d9403647bb1 LGTM! 
   
   Given the size of the patch, even if it's simple stuff in practice, it would be nice to see some tests for the different combinations added to `meta_tests/` 


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Jan/21 10:51;githubbot;600","tlasica commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r563147576



##########
File path: conftest.py
##########
@@ -597,58 +588,59 @@ def pytest_collection_modifyitems(items, config):
     for item in items:
         deselect_test = False
 
-        if config.getoption(""--execute-upgrade-tests-only""):
-            deselect_test = not item.get_closest_marker(""upgrade_test"")
-            if deselect_test:
+        is_upgrade_test = _is_upgrade_test(item)
+        is_resource_intensive_test = item.get_closest_marker(""resource_intensive"") is not None
+        is_vnodes_test = item.get_closest_marker(""vnodes"") is not None
+        is_no_vnodes_test = item.get_closest_marker(""no_vnodes"") is not None
+        is_no_offheap_memtable_test = item.get_closest_marker(""no_offheap_memtables"") is not None
+        is_depends_driver_test = item.get_closest_marker(""depends_driver"") is not None
+
+        if is_upgrade_test:
+            if not dtest_config.execute_upgrade_tests and not dtest_config.execute_upgrade_tests_only:
+                deselect_test = True
+                logger.info(""SKIP: Deselecting upgrade test %s because neither --execute-upgrade-tests or ""
+                            ""--execute-upgrade-tests-only was specified"" % item.name)
+        else:
+            if dtest_config.execute_upgrade_tests_only:
+                deselect_test = True
                 logger.info(""SKIP: Deselecting non-upgrade test %s because of --execute-upgrade-tests-only"" % item.name)
 
-        if item.get_closest_marker(""resource_intensive"") and not collect_only:
-            force_resource_intensive = config.getoption(""--force-resource-intensive-tests"")
-            skip_resource_intensive = config.getoption(""--skip-resource-intensive-tests"")
-            if not force_resource_intensive:
-                if skip_resource_intensive:
-                    deselect_test = True
-                    logger.info(""SKIP: Deselecting test %s as test marked resource_intensive. To force execution of ""
-                          ""this test re-run with the --force-resource-intensive-tests command line argument"" % item.name)
-                if not sufficient_system_resources_resource_intensive:
+        if is_resource_intensive_test:
+            if dtest_config.skip_resource_intensive_tests:
+                deselect_test = True
+                logger.info(""SKIP: Deselecting test %s as test marked resource_intensive and ""
+                            ""--skip-resource-intensive-tests was specified."" % item.name)
+            elif not sufficient_system_resources_resource_intensive:
+                if not dtest_config.force_execution_of_resource_intensive_tests:
                     deselect_test = True
-                    logger.info(""SKIP: Deselecting resource_intensive test %s due to insufficient system resources"" % item.name)
-
-        if not item.get_closest_marker(""resource_intensive"") and not collect_only:
-            only_resource_intensive = config.getoption(""--only-resource-intensive-tests"")
-            if only_resource_intensive:
+                    logger.info(""SKIP: Deselecting resource_intensive test %s due to insufficient system resources. ""
+                                ""Specify --force-resource-intensive-tests if you really want to run it"" % item.name)
+        else:

Review comment:
       nit: I am not a big fun of nested ifs and elseses...
   maybe instead it should be a sequence of rules.
   if rules i matched -> skip.
   even if repeating conditions.
   
   ```
   if dtest_config.only_resource_intensive and not is_resource_intentive:
      skip
   if dtest_config.use_vnodes and is_no_vnodes_test:
      skip with log
   if not dtest_config.use_vnodes and is_vnodes_test:
      skip with log
   (...)
   ```

##########
File path: conftest.py
##########
@@ -597,58 +588,59 @@ def pytest_collection_modifyitems(items, config):
     for item in items:
         deselect_test = False
 
-        if config.getoption(""--execute-upgrade-tests-only""):
-            deselect_test = not item.get_closest_marker(""upgrade_test"")
-            if deselect_test:
+        is_upgrade_test = _is_upgrade_test(item)
+        is_resource_intensive_test = item.get_closest_marker(""resource_intensive"") is not None
+        is_vnodes_test = item.get_closest_marker(""vnodes"") is not None
+        is_no_vnodes_test = item.get_closest_marker(""no_vnodes"") is not None
+        is_no_offheap_memtable_test = item.get_closest_marker(""no_offheap_memtables"") is not None
+        is_depends_driver_test = item.get_closest_marker(""depends_driver"") is not None
+
+        if is_upgrade_test:
+            if not dtest_config.execute_upgrade_tests and not dtest_config.execute_upgrade_tests_only:
+                deselect_test = True

Review comment:
       nit: I do not see why we keep `deselect_test` and `deseleted` instead of `skip_test` and `skipped""... of course also in messaging.

##########
File path: conftest.py
##########
@@ -597,58 +588,59 @@ def pytest_collection_modifyitems(items, config):
     for item in items:
         deselect_test = False
 
-        if config.getoption(""--execute-upgrade-tests-only""):
-            deselect_test = not item.get_closest_marker(""upgrade_test"")
-            if deselect_test:
+        is_upgrade_test = _is_upgrade_test(item)

Review comment:
       nit: I think it would not be bad to actually extract:
   ```
   def should_skip_test(test, dtest_config):
   ```
   because one could put `return` statements there which would  not cause reader to reflect if the `deselect` decision can be reverted.. making reasoning easier.
   
   
   and then the loop will become:
   ```
   for item in items:
      skip_test = self.should_skip_test(item, dtest_config)
      if skip_test:
         ...
      else:
         ....
   ```
   

##########
File path: conftest.py
##########
@@ -660,5 +652,17 @@ def pytest_collection_modifyitems(items, config):
     items[:] = selected_items
 
 
-def _upgrade_testing_enabled(config):
-    return config.getoption(""--execute-upgrade-tests"") or config.getoption(""--execute-upgrade-tests-only"")
+def _is_upgrade_test(item):
+    if item.get_closest_marker(""upgrade_test"") is not None:
+        return True
+    else:
+        is_upgrade_test = False
+
+        for test_item_class in inspect.getmembers(item.module, inspect.isclass):
+            if not hasattr(test_item_class[1], ""pytestmark""):
+                continue
+            for module_pytest_mark in test_item_class[1].pytestmark:
+                if module_pytest_mark.name == ""upgrade_test"":
+                    is_upgrade_test = True

Review comment:
       if we want to keep this `for/if` then we can `break` once found.
   
   but we can also go with more like
   ```
   pytest_mark_names = [m.name for m in test_item_class[1].pytestmark
   if ""upgrade_test"" in pytest_mark_names:
       return True
   ```

##########
File path: conftest.py
##########
@@ -597,58 +588,59 @@ def pytest_collection_modifyitems(items, config):
     for item in items:
         deselect_test = False
 
-        if config.getoption(""--execute-upgrade-tests-only""):
-            deselect_test = not item.get_closest_marker(""upgrade_test"")
-            if deselect_test:
+        is_upgrade_test = _is_upgrade_test(item)

Review comment:
       or even better:
   ```
   skipped = [x for x in items if self.should_skip_test(x, dtest_config)
   selected = list((set(items) - set(skipped))
   ```
   no ifs, no loops, voila.

##########
File path: conftest.py
##########
@@ -660,5 +652,17 @@ def pytest_collection_modifyitems(items, config):
     items[:] = selected_items
 
 
-def _upgrade_testing_enabled(config):
-    return config.getoption(""--execute-upgrade-tests"") or config.getoption(""--execute-upgrade-tests-only"")
+def _is_upgrade_test(item):
+    if item.get_closest_marker(""upgrade_test"") is not None:
+        return True
+    else:
+        is_upgrade_test = False
+
+        for test_item_class in inspect.getmembers(item.module, inspect.isclass):

Review comment:
       what will it be? a tuple? then it can be unboxed.
   `test_item_class[1]` is rather cryptic ;-)




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;23/Jan/21 14:13;githubbot;600","tlasica commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r563763263



##########
File path: meta_tests/conftest_test.py
##########
@@ -0,0 +1,87 @@
+import os
+from re import search
+from unittest import TestCase
+
+from dtest_config import DTestConfig
+from mock import Mock
+from pytest import UsageError
+
+from conftest import *
+
+
+def _response(input, responses, default_response):

Review comment:
       why not `responses.get(input, default_response)` ?
   because of logging?




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Jan/21 14:28;githubbot;600","tlasica commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r563763263



##########
File path: meta_tests/conftest_test.py
##########
@@ -0,0 +1,87 @@
+import os
+from re import search
+from unittest import TestCase
+
+from dtest_config import DTestConfig
+from mock import Mock
+from pytest import UsageError
+
+from conftest import *
+
+
+def _response(input, responses, default_response):

Review comment:
       why not `responses.get(input, default_response)` ?
   because of logging?
   
   I think we do not need this function at all.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Jan/21 14:29;githubbot;600","michaelsembwever commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r564031176



##########
File path: .travis.yml
##########
@@ -1,21 +1,23 @@
 language: python
 python:
-  - ""2.7""
+  - ""3.8""
 install:
-  - pip install pycodestyle==2.3.1 flake8
+  - pip install pycodestyle==2.6.0 flake8
   - pip check
+  - CASS_DRIVER_NO_CYTHON=1 pip install -r requirements.txt
 script:
   # we want pyflakes to check all files for unused imports only
   # we use flake8 because it allows us to ignore other warnings
   # exclude the thrift directories - they contain auto-generated code
-  - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
+  # - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
   - git remote add apache git://github.com/apache/cassandra-dtest.git
   - git fetch apache # fetch master for the next diff
   # feed changed lines with no context around them to pycodestyle
   # I know we don't enforce line length but if you introduce
   # 200-char lines you are doing something terribly wrong.
   # lint all files for everything but line length errors
-  - git diff apache/master...HEAD -U0 | pycodestyle --ignore=E501 --diff
+  - git diff apache/trunk...HEAD -U0 | pycodestyle --ignore=E501 --diff
   # lint all files except json_test.py for line length errors
-  - git diff apache/master...HEAD -U0 | pycodestyle --diff --exclude='json_test.py' --exclude='meta_tests/assertion_test.py' --max-line-length=200
+  - git diff apache/trunk...HEAD -U0 | pycodestyle --diff --exclude='json_test.py' --exclude='meta_tests/assertion_test.py' --max-line-length=200
+  - pytest --metatests

Review comment:
       💪 
   




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Jan/21 20:45;githubbot;600","michaelsembwever commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r564031720



##########
File path: .travis.yml
##########
@@ -1,21 +1,23 @@
 language: python
 python:
-  - ""2.7""
+  - ""3.8""
 install:
-  - pip install pycodestyle==2.3.1 flake8
+  - pip install pycodestyle==2.6.0 flake8
   - pip check
+  - CASS_DRIVER_NO_CYTHON=1 pip install -r requirements.txt
 script:
   # we want pyflakes to check all files for unused imports only
   # we use flake8 because it allows us to ignore other warnings
   # exclude the thrift directories - they contain auto-generated code
-  - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
+  # - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .

Review comment:
       instead of commenting it out, could we add more ignores (for those currently failing?) 




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Jan/21 20:46;githubbot;600","michaelsembwever commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r564031720



##########
File path: .travis.yml
##########
@@ -1,21 +1,23 @@
 language: python
 python:
-  - ""2.7""
+  - ""3.8""
 install:
-  - pip install pycodestyle==2.3.1 flake8
+  - pip install pycodestyle==2.6.0 flake8
   - pip check
+  - CASS_DRIVER_NO_CYTHON=1 pip install -r requirements.txt
 script:
   # we want pyflakes to check all files for unused imports only
   # we use flake8 because it allows us to ignore other warnings
   # exclude the thrift directories - they contain auto-generated code
-  - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
+  # - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .

Review comment:
       instead of commenting it out, could we add more ignores (for those currently failing?) 
   
   
   (duplicate and comment out the line so we know what it is supposed to be)
   




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Jan/21 20:52;githubbot;600","jacek-lewandowski commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r564053574



##########
File path: .travis.yml
##########
@@ -1,21 +1,23 @@
 language: python
 python:
-  - ""2.7""
+  - ""3.8""
 install:
-  - pip install pycodestyle==2.3.1 flake8
+  - pip install pycodestyle==2.6.0 flake8
   - pip check
+  - CASS_DRIVER_NO_CYTHON=1 pip install -r requirements.txt
 script:
   # we want pyflakes to check all files for unused imports only
   # we use flake8 because it allows us to ignore other warnings
   # exclude the thrift directories - they contain auto-generated code
-  - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
+  # - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .

Review comment:
       I don't know if you tried, but there are so many of them that is probably make no sense at all - instead, I can spend 1-2 hours on fixing that properly




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Jan/21 21:25;githubbot;600","michaelsembwever commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r564093530



##########
File path: .travis.yml
##########
@@ -1,21 +1,23 @@
 language: python
 python:
-  - ""2.7""
+  - ""3.8""
 install:
-  - pip install pycodestyle==2.3.1 flake8
+  - pip install pycodestyle==2.6.0 flake8
   - pip check
+  - CASS_DRIVER_NO_CYTHON=1 pip install -r requirements.txt
 script:
   # we want pyflakes to check all files for unused imports only
   # we use flake8 because it allows us to ignore other warnings
   # exclude the thrift directories - they contain auto-generated code
-  - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
+  # - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .

Review comment:
       > I can spend 1-2 hours on fixing that properly
   
   i have a PR somewhere for that :-)
   (it would need to be a separate ticket.)
   
   let's just comment out the line then for now 👍 
   




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;25/Jan/21 22:42;githubbot;600","tlasica commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r563763263



##########
File path: meta_tests/conftest_test.py
##########
@@ -0,0 +1,87 @@
+import os
+from re import search
+from unittest import TestCase
+
+from dtest_config import DTestConfig
+from mock import Mock
+from pytest import UsageError
+
+from conftest import *
+
+
+def _response(input, responses, default_response):

Review comment:
       why not `responses.get(input, default_response)` ?
   because of logging?

##########
File path: meta_tests/conftest_test.py
##########
@@ -0,0 +1,87 @@
+import os
+from re import search
+from unittest import TestCase
+
+from dtest_config import DTestConfig
+from mock import Mock
+from pytest import UsageError
+
+from conftest import *
+
+
+def _response(input, responses, default_response):

Review comment:
       why not `responses.get(input, default_response)` ?
   because of logging?
   
   I think we do not need this function at all.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;26/Jan/21 03:59;githubbot;600","jacek-lewandowski commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r564053574



##########
File path: .travis.yml
##########
@@ -1,21 +1,23 @@
 language: python
 python:
-  - ""2.7""
+  - ""3.8""
 install:
-  - pip install pycodestyle==2.3.1 flake8
+  - pip install pycodestyle==2.6.0 flake8
   - pip check
+  - CASS_DRIVER_NO_CYTHON=1 pip install -r requirements.txt
 script:
   # we want pyflakes to check all files for unused imports only
   # we use flake8 because it allows us to ignore other warnings
   # exclude the thrift directories - they contain auto-generated code
-  - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
+  # - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .

Review comment:
       I don't know if you tried, but there are so many of them that is probably make no sense at all - instead, I can spend 1-2 hours on fixing that properly




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;26/Jan/21 04:09;githubbot;600","michaelsembwever commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r564031176



##########
File path: .travis.yml
##########
@@ -1,21 +1,23 @@
 language: python
 python:
-  - ""2.7""
+  - ""3.8""
 install:
-  - pip install pycodestyle==2.3.1 flake8
+  - pip install pycodestyle==2.6.0 flake8
   - pip check
+  - CASS_DRIVER_NO_CYTHON=1 pip install -r requirements.txt
 script:
   # we want pyflakes to check all files for unused imports only
   # we use flake8 because it allows us to ignore other warnings
   # exclude the thrift directories - they contain auto-generated code
-  - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
+  # - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
   - git remote add apache git://github.com/apache/cassandra-dtest.git
   - git fetch apache # fetch master for the next diff
   # feed changed lines with no context around them to pycodestyle
   # I know we don't enforce line length but if you introduce
   # 200-char lines you are doing something terribly wrong.
   # lint all files for everything but line length errors
-  - git diff apache/master...HEAD -U0 | pycodestyle --ignore=E501 --diff
+  - git diff apache/trunk...HEAD -U0 | pycodestyle --ignore=E501 --diff
   # lint all files except json_test.py for line length errors
-  - git diff apache/master...HEAD -U0 | pycodestyle --diff --exclude='json_test.py' --exclude='meta_tests/assertion_test.py' --max-line-length=200
+  - git diff apache/trunk...HEAD -U0 | pycodestyle --diff --exclude='json_test.py' --exclude='meta_tests/assertion_test.py' --max-line-length=200
+  - pytest --metatests

Review comment:
       💪 
   

##########
File path: .travis.yml
##########
@@ -1,21 +1,23 @@
 language: python
 python:
-  - ""2.7""
+  - ""3.8""
 install:
-  - pip install pycodestyle==2.3.1 flake8
+  - pip install pycodestyle==2.6.0 flake8
   - pip check
+  - CASS_DRIVER_NO_CYTHON=1 pip install -r requirements.txt
 script:
   # we want pyflakes to check all files for unused imports only
   # we use flake8 because it allows us to ignore other warnings
   # exclude the thrift directories - they contain auto-generated code
-  - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
+  # - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .

Review comment:
       instead of commenting it out, could we add more ignores (for those currently failing?) 

##########
File path: .travis.yml
##########
@@ -1,21 +1,23 @@
 language: python
 python:
-  - ""2.7""
+  - ""3.8""
 install:
-  - pip install pycodestyle==2.3.1 flake8
+  - pip install pycodestyle==2.6.0 flake8
   - pip check
+  - CASS_DRIVER_NO_CYTHON=1 pip install -r requirements.txt
 script:
   # we want pyflakes to check all files for unused imports only
   # we use flake8 because it allows us to ignore other warnings
   # exclude the thrift directories - they contain auto-generated code
-  - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
+  # - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .

Review comment:
       instead of commenting it out, could we add more ignores (for those currently failing?) 
   
   
   (duplicate and comment out the line so we know what it is supposed to be)
   

##########
File path: .travis.yml
##########
@@ -1,21 +1,23 @@
 language: python
 python:
-  - ""2.7""
+  - ""3.8""
 install:
-  - pip install pycodestyle==2.3.1 flake8
+  - pip install pycodestyle==2.6.0 flake8
   - pip check
+  - CASS_DRIVER_NO_CYTHON=1 pip install -r requirements.txt
 script:
   # we want pyflakes to check all files for unused imports only
   # we use flake8 because it allows us to ignore other warnings
   # exclude the thrift directories - they contain auto-generated code
-  - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .
+  # - flake8 --ignore=E501,F811,F812,F822,F823,F831,F841,N8,C9 --exclude=thrift_bindings,cassandra-thrift .

Review comment:
       > I can spend 1-2 hours on fixing that properly
   
   i have a PR somewhere for that :-)
   (it would need to be a separate ticket.)
   
   let's just comment out the line then for now 👍 
   




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;26/Jan/21 04:32;githubbot;600","tlasica commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r564301868



##########
File path: meta_tests/dtest_config_test.py
##########
@@ -0,0 +1,121 @@
+import os
+from re import search
+from unittest import TestCase
+
+from dtest_config import DTestConfig
+from mock import Mock, patch
+from pytest import UsageError
+import ccmlib.repository
+import ccmlib.common
+
+
+def _mock_responses(responses, default_response=None):
+    return lambda input: responses[input] if input in responses else \
+        ""%s/meta_tests/cassandra-dir-4.0-beta"" % os.getcwd() if input == ""--cassandra-dir"" else default_response
+
+
+def _check_with_params(params):
+    config = Mock()
+    config.getoption.side_effect = _mock_responses(params)
+    config.getini.side_effect = _mock_responses({})
+
+    dTestConfig = DTestConfig()
+    dTestConfig.setup(config)
+    return dTestConfig
+
+
+def _check_with_params_expect(params, pattern):

Review comment:
       this will pass if exception is not thrown, why actually it should be thrown, correct
   we should instead use:
   ```with pytest.raises(ValueError, match=r"".* 123 .*""):```




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;26/Jan/21 07:40;githubbot;600","tlasica commented on a change in pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#discussion_r564301868



##########
File path: meta_tests/dtest_config_test.py
##########
@@ -0,0 +1,121 @@
+import os
+from re import search
+from unittest import TestCase
+
+from dtest_config import DTestConfig
+from mock import Mock, patch
+from pytest import UsageError
+import ccmlib.repository
+import ccmlib.common
+
+
+def _mock_responses(responses, default_response=None):
+    return lambda input: responses[input] if input in responses else \
+        ""%s/meta_tests/cassandra-dir-4.0-beta"" % os.getcwd() if input == ""--cassandra-dir"" else default_response
+
+
+def _check_with_params(params):
+    config = Mock()
+    config.getoption.side_effect = _mock_responses(params)
+    config.getini.side_effect = _mock_responses({})
+
+    dTestConfig = DTestConfig()
+    dTestConfig.setup(config)
+    return dTestConfig
+
+
+def _check_with_params_expect(params, pattern):

Review comment:
       reading the name I would say we always expect exception.
   but the code as it is does not check if exception is actually thrown,
   it only checks if ""when exception is thrown it has proper message"".
   
   maybe we should instead use:
   ```with pytest.raises(ValueError, match=r"".* 123 .*""):```




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;26/Jan/21 07:44;githubbot;600","michaelsembwever closed pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Jan/21 11:02;githubbot;600","michaelsembwever commented on pull request #115:
URL: https://github.com/apache/cassandra-dtest/pull/115#issuecomment-768975190


   Merged with https://github.com/apache/cassandra-dtest/commit/ec84618b7450ef9357a3a88fc93e39d74a34b02e


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Jan/21 11:02;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,13200,,,0,13200,,CASSANDRA-16221,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jlewandowski,,,,,,,,,,,,,Code -> Bug - Unclear Impact,,,,,,,,Low Hanging Fruit,Adhoc Test,,false,CASSANDRA-15536,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jan 28 11:03:15 UTC 2021,,,,,,,All,,,,"0|z0mvf4:",9223372036854775807,,,,mck,tomasz.lasica,,,Low,,NA,,https://github.com/apache/cassandra-dtest/commit/ec84618b7450ef9357a3a88fc93e39d74a34b02e,,,,,,,,,"Manual testing, plus ci-cassandra.a.o",,,,,"22/Jan/21 08:12;mck;CI
 - pipeline :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/317/
 - dtest-upgrade :: https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-dtest-upgrade/15/;;;","22/Jan/21 13:13;mck;CI looks good. 

Here you can see the disitribution of tests among the splits more balanced than previous runs:
 https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-dtest-large/84/testReport/;;;","23/Jan/21 08:45;jlewandowski;Summary:

 

This patch fixes behaviour for both {{run_dtests.py}} and {{pytest}}.

In particular:
- Error handling for invalid parameter values / combinations is in a single place ({{dtest_config.py}}) and is executed before we actually traverse through the tests
- We exit with just a clean error message instead of tons of spam
- {{run_dtests.sh}} will not loose the exit code of {{pytest}} any more so we can clearly detect when test cases collection fails
- removed a bit of boilerplate code from {{run_dtests.py}} - in particular what it did with xml processing is simply provided with {{-q}} argument of {{pytest}}
- tests filtering has been refactored to be cleaner
- fixed filtering of resource intensive tests

Note that now {{run_dtests.py}} seems to be redundant. If we need it only for listing dtests, we can simply achieve exactly the same effect using {{\-\-collect-only -q \-\-ignore=meta_tests}} arguments for {{pytest}} instead of {{\-\-dtest-print-tests-only}}, plus we need to filter output with {{grep '.py::'}} (in order to not include the summary line) and pipe stdout to the target file. Anyway I simplified {{run_dtests.sh}} so that it just use {{pytest}} with those arguments.

Regarding Cassandra CI, I suppose most of the configurations will benefit with this fix:
 - {{no-vnodes}}, {{vnodes}}, {{off-heap-memtables}} - previously included resource intensive tests although it was specified to skip them in the build script
 - {{large}} - instead of listing just resource intensive tests it listed all tests

Some examples of error handling now vs before:
 * before:

{noformat}
$ ./run_dtests.py --dtest-print-tests-only
<?xml version=""1.0"" encoding=""UTF-8""?>
<Modules>
      </Instance>
    </Class>
  </Module>
</Modules>

$ pytest --collect-only
==================================================== test session starts =====================================================
platform darwin -- Python 3.9.1, pytest-3.6.4, py-1.10.0, pluggy-0.7.1
rootdir: /Users/jlewandowski/dev/datastax/cassandra-dtest/trunk, inifile: pytest.ini
plugins: timeout-1.4.2, flaky-3.7.0
timeout: 900.0s
timeout method: signal
timeout func_only: False
collecting 0 items / 1 errors                                                                                                INTERNALERROR> Traceback (most recent call last):
INTERNALERROR>   File ""/Users/jlewandowski/dev/datastax/cassandra-dtest/trunk/venv/lib/python3.9/site-packages/_pytest/main.py"", line 178, in wrap_session
INTERNALERROR>     session.exitstatus = doit(config, session) or 0
...
INTERNALERROR> FileNotFoundError: [Errno 2] No such file or directory: 'build.xml'================================================== 1 error in 0.18 seconds ===================================================

$ ./run_dtests.py --cassandra-dir=../../cassandra/ds-trunk --dtest-print-tests-only --only-resource-intensive-tests --skip-resource-intensive-tests
<?xml version=""1.0"" encoding=""UTF-8""?>
<Modules>
  <Module name=""auditlog_test.py"">
...
auth_test.py::TestAuthUnavailable::test_permission_cache_background_reload_handle_unavailable
auth_test.py::TestNetworkAuth::test_full_dc_access
auth_test.py::TestNetworkAuth::test_single_dc_access
...
(no error)
{noformat}

 * now:

{noformat}
 $ ./run_dtests.py --dtest-print-tests-only
ERROR: Required dtest arguments were missing! You must provide either --cassandra-dir or --cassandra-version. You can also set 'cassandra_dir' in pytest.ini. Refer to the documentation or invoke the help with --help.

$ pytest --collect-only
ERROR: Required dtest arguments were missing! You must provide either --cassandra-dir or --cassandra-version. You can also set 'cassandra_dir' in pytest.ini. Refer to the documentation or invoke the help with --help.

$ ./run_dtests.py --cassandra-dir=../../cassandra/ds-trunk --dtest-print-tests-only --only-resource-intensive-tests --skip-resource-intensive-tests
ERROR: --skip-resource-intensive-tests does not make any sense with either --only-resource-intensive-tests or --force-resource-intensive-tests.

$ pytest --cassandra-dir=../../cassandra/ds-trunk --collect-only --only-resource-intensive-tests --skip-resource-intensive-tests
ERROR: --skip-resource-intensive-tests does not make any sense with either --only-resource-intensive-tests or --force-resource-intensive-tests.
{noformat};;;","23/Jan/21 11:17;mck;CI runs off [jacek-lewandowski/cassandra-dtest:b4fc4f07c2cc4c2779250f672bc09d9403647bb1|https://github.com/jacek-lewandowski/cassandra-dtest/commit/b4fc4f07c2cc4c2779250f672bc09d9403647bb1]
- cassandra-2.2 :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/319/pipeline
- cassandra-3.0 :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/320/pipeline
- cassandra-3.11 :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/321/pipeline
- trunk :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/322/pipeline;;;","26/Jan/21 18:42;tomasz.lasica;Code LGTM.;;;","28/Jan/21 10:56;mck;+1 (most of the review communication has happened in the PR);;;","28/Jan/21 11:03;mck;PR was https://github.com/apache/cassandra-dtest/pull/115

;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add access and datacenters to unreserved keywords,CASSANDRA-16398,13353880,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,yifanc,yifanc,yifanc,22/Jan/21 01:27,16/Mar/22 15:21,13/Jul/23 08:40,03/Feb/21 19:31,4.0,4.0-rc1,,,,,,CQL/Interpreter,CQL/Syntax,,,0,,,"The terms, ""ACCESS TO ALL DATACENTERS"" (for role control,) are introduced in CASSANDRA-13985. 
They are not marked as unreserved keywords. So in the non-role related DDL statements, for example, create table statement, the parser fails.
 
cqlsh> CREATE TABLE test.test_access ( foo text PRIMARY KEY, access text, bar text);
SyntaxException: line 1:54 mismatched input 'access' expecting ')' (... foo text PRIMARY KEY, [access]...)
 
cqlsh> CREATE TABLE test.test_datacenters ( foo text PRIMARY KEY, datacenters text, bar text);
SyntaxException: line 1:59 mismatched input 'datacenters' expecting ')' (... foo text PRIMARY KEY, [datacenters]...)
 
Since ACCESS and DATACENTERS are only applicable to the role defining statements. We should mark them as unreserved keywords in order to allow to use them in the DDL statement. ",,blerer,e.dimitrova,yifanc,,,,,,,,,,,,,"yifan-c opened a new pull request #883:
URL: https://github.com/apache/cassandra/pull/883


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;28/Jan/21 20:40;githubbot;600","blerer commented on a change in pull request #883:
URL: https://github.com/apache/cassandra/pull/883#discussion_r566907931



##########
File path: test/unit/org/apache/cassandra/tools/cqlsh/CqlshTest.java
##########
@@ -44,4 +48,29 @@ public void testKeyspaceRequired()
         assertThat(tool.getCleanedStderr(), CoreMatchers.containsStringIgnoringCase(""No keyspace has been specified""));
         assertEquals(2, tool.getExitCode());
     }
+
+    @Test
+    public void testUseUnreservedKeywordAsColumnName()
+    {
+        List<String> names = Arrays.asList(""access"", ""datacenters"");
+        for (String name : names)
+        {
+            testUseUnreservedKeywordAsColumnName(name);
+            testUseUnreservedKeywordAsColumnName(name.toUpperCase());
+        }
+    }

Review comment:
       nit: I would have put that test into  `CreateTest`. I would not think of looking into CqlshTest for a test on unreserved Keywords. 




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jan/21 15:39;githubbot;600","yifan-c commented on pull request #883:
URL: https://github.com/apache/cassandra/pull/883#issuecomment-770021253


   @blerer thanks for the feedback. 
   I move the test to `CreateTest` and rewrite using `createTable()` instead of invoking cqlsh. 
   
   I also made an optional commit c81be6f that determines all the unreserved keywords and enumerate through to give the best coverage. It helps to prevent the scenario that add a keyword but forgot to add it to either unreserved or reserved. 
   However, the commit opens up the access level to `ReservedKeywords` class. Would it be a concern? Intuitively, I think ""no"". Or if we want to keep the access level, we can move the test into `ReservedKeywordsTest` (and potentially change the test class name)?


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jan/21 20:05;githubbot;600","yifan-c edited a comment on pull request #883:
URL: https://github.com/apache/cassandra/pull/883#issuecomment-770021253


   @blerer thanks for the feedback. 
   I move the test to `CreateTest` and rewrite using `createTable()` instead of invoking cqlsh. 
   
   I also made an optional commit c81be6f that determines all the unreserved keywords and enumerate through to give the best coverage. It helps to prevent the scenario that adds a keyword but forgot to add it to either unreserved or reserved list. 
   However, the commit opens up the access level to `ReservedKeywords` class. Would it be a concern? Intuitively, I think ""no"". Or if we want to keep the access level, we can move the test into `ReservedKeywordsTest` (and potentially change the test class name)?


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;29/Jan/21 20:06;githubbot;600","blerer commented on pull request #883:
URL: https://github.com/apache/cassandra/pull/883#issuecomment-770857698


   Your new test is a great idea. :-) We often messed up with reserved and unreserved keywords.
   I do not believe that changing the access level is an issue.
   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Feb/21 13:30;githubbot;600","blerer commented on a change in pull request #883:
URL: https://github.com/apache/cassandra/pull/883#discussion_r567829322



##########
File path: test/unit/org/apache/cassandra/cql3/validation/operations/CreateTest.java
##########
@@ -688,12 +692,16 @@ public void testCreateTableWithCompression() throws Throwable
     @Test
     public void testUseUnreservedKeywordAsColumnName()
     {
-        List<String> names = Arrays.asList(""access"", ""datacenters"");
-        for (String colName : names)
+        Set<String> allKeywords = Arrays.stream(CqlLexer.class.getDeclaredFields())
+                                        .filter(f -> f.getName().startsWith(""K_""))
+                                        .map(f -> f.getName().substring(2)) // remove the heading ""K_""
+                                        .collect(Collectors.toSet());
+        Set<String> unreservedKeywords = Sets.difference(allKeywords, ReservedKeywords.reservedSet);

Review comment:
       Another approach would be to make `isReserved(String text)` `public` and to use it to filter the stream.
   ```
   
   Set<String> unreservedKeywords = Arrays.stream(CqlLexer.class.getDeclaredFields())
                                                                     .filter(f -> f.getName().startsWith(""K_""))
                                                                     .map(f -> f.getName().substring(2)) // remove the heading ""K_""
                                                                     .filter(f -> !ReservedKeywords.isReserved(f))
                                                                    .collect(Collectors.toSet());
   ```
   Making `isReserved(String text)` `public` allow us to expose less of the class internals but I do not really have a strong opinion on which solution we should use.

##########
File path: src/java/org/apache/cassandra/cql3/ReservedKeywords.java
##########
@@ -23,7 +23,7 @@
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.collect.ImmutableSet;
 
-class ReservedKeywords
+public class ReservedKeywords

Review comment:
       We should probably make the class `final`.




----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;01/Feb/21 13:36;githubbot;600","smiklosovic closed pull request #883:
URL: https://github.com/apache/cassandra/pull/883


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:21;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,4200,,,0,4200,,,,,,,,,,,,,,,CASSANDRA-15537,,,,,,,,,,,,,,,,,,,,,,,0.0,yifanc,,,,,,,,,,,,,Correctness -> API / Semantic Implementation,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Feb 03 19:31:20 UTC 2021,,,,,,,All,,,,"0|z0mv60:",9223372036854775807,,,,blerer,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/0373037a0db7e13548b0f302cad9414f00e58991,,,,,,,,,unit test. ci,,,,,"28/Jan/21 21:11;yifanc;PR: [https://github.com/apache/cassandra/pull/883]
CI: [j11|https://app.circleci.com/pipelines/github/yifan-c/cassandra/183/workflows/eef6f9b0-1d10-4884-96b8-bf4946082654], [j8|https://app.circleci.com/pipelines/github/yifan-c/cassandra/183/workflows/8c6677cc-7967-4b55-9b37-3b81e1de7465]

The patch adds a test to demonstrate the parsing failure and adds 'access' and 'datacenters' to the unreserved keywords in the parser definition. ;;;","01/Feb/21 17:30;blerer;The patch looks good to me. Thanks a lot [~yifanc];;;","01/Feb/21 22:36;yifanc;Starting commit

CI Results:
||Branch||Source||Circle CI||Jenkins||
|trunk|[branch|https://github.com/yifan-c/cassandra/tree/commit_remote_branch/CASSANDRA-16398-trunk-639D5402-A26D-464E-BA14-C61A7EA11DCE]|[build|https://app.circleci.com/pipelines/github/yifan-c/cassandra?branch=commit_remote_branch%2FCASSANDRA-16398-trunk-639D5402-A26D-464E-BA14-C61A7EA11DCE]|[build|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/349/pipeline]|

The test, ""mixedModeReadColumnSubsetDigestCheck - MixedModeReadTest"" failed. Quite certain that the failure is not related with the cqlsh parser definition change. 

Filed the ticket for the flaky test, CASSANDRA-16415;;;","03/Feb/21 19:31;yifanc;Committed to trunk as [0373037a0db7e13548b0f302cad9414f00e58991|https://github.com/apache/cassandra/commit/0373037a0db7e13548b0f302cad9414f00e58991];;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Running python dtest with --keep-failed-test-dir causes ERROR for SKIP tests,CASSANDRA-16397,13353569,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mck,tomasz.lasica,tomasz.lasica,20/Jan/21 16:20,21/Jan/21 15:04,13/Jul/23 08:40,21/Jan/21 15:04,4.0,4.0-rc1,,,,,,Test/dtest/python,,,,0,,,"There is a new flag, added in CASSANDRA-16070: ""--keep-failed-test-dir"".

In some cases (I am not sure if always),

when this flag is set and when test is SKIP-ed it will cause test ERROR.

 

Good run (without --keep-failed-test-dir)
{code:java}
 pytest  --cassandra-dir=/home/tomek/repos/apache/cassandra client_network_stop_start_test.py 
===================================================================================== test session starts =====================================================================================
platform linux -- Python 3.6.12, pytest-3.6.4, py-1.10.0, pluggy-0.7.1
rootdir: /home/tomek/repos/tlasica/cassandra-dtest, inifile: pytest.ini
plugins: timeout-1.4.2, flaky-3.7.0
timeout: 900.0s
timeout method: signal
timeout func_only: False
collected 3 items                                                                                                                                                                             client_network_stop_start_test.py .ss                                                                                                                                                   [100%]
===Flaky Test Report===test_defaults passed 1 out of the required 1 times. Success!===End Flaky Test Report=============================================================================== 1 passed, 2 skipped in 11.25 seconds ============================================================================={code}
and bad one (with flag):
{code:java}

pytest --keep-failed-test-dir --cassandra-dir=/home/tomek/repos/apache/cassandra client_network_stop_start_test.py 
===================================================================================== test session starts =====================================================================================
platform linux -- Python 3.6.12, pytest-3.6.4, py-1.10.0, pluggy-0.7.1
rootdir: /home/tomek/repos/tlasica/cassandra-dtest, inifile: pytest.ini
plugins: timeout-1.4.2, flaky-3.7.0
timeout: 900.0s
timeout method: signal
timeout func_only: False
collected 3 items                                                                                                                                                                             client_network_stop_start_test.py .sEsE                                                                                                                                                 [100%]=========================================================================================== ERRORS ============================================================================================
_____________________________________________________________ ERROR at teardown of TestClientNetworkStopStart.test_hsha_defaults ______________________________________________________________request = <SubRequest 'fixture_dtest_setup' for <Function 'test_hsha_defaults'>>, dtest_config = <dtest_config.DTestConfig object at 0x7fd313af9908>
fixture_dtest_setup_overrides = <dtest_setup_overrides.DTestSetupOverrides object at 0x7fd313263048>, fixture_logging_setup = None, fixture_dtest_cluster_name = 'test'
fixture_dtest_create_cluster_func = <function DTestSetup.create_ccm_cluster at 0x7fd313b15488>    @pytest.fixture(scope='function', autouse=False)
    def fixture_dtest_setup(request,
                            dtest_config,
                            fixture_dtest_setup_overrides,
                            fixture_logging_setup,
                            fixture_dtest_cluster_name,
                            fixture_dtest_create_cluster_func):
        if running_in_docker():
            cleanup_docker_environment_before_test_execution()
    
        # do all of our setup operations to get the enviornment ready for the actual test
        # to run (e.g. bring up a cluster with the necessary config, populate variables, etc)
        initial_environment = copy.deepcopy(os.environ)
        dtest_setup = DTestSetup(dtest_config=dtest_config,
                                 setup_overrides=fixture_dtest_setup_overrides,
                                 cluster_name=fixture_dtest_cluster_name)
        dtest_setup.initialize_cluster(fixture_dtest_create_cluster_func)
    
        if not dtest_config.disable_active_log_watching:
            dtest_setup.begin_active_log_watch()
    
        # at this point we're done with our setup operations in this fixture
        # yield to allow the actual test to run
        yield dtest_setup
    
        # phew! we're back after executing the test, now we need to do
        # all of our teardown and cleanup operations
    
        reset_environment_vars(initial_environment)
        dtest_setup.jvm_args = []
    
        for con in dtest_setup.connections:
            con.cluster.shutdown()
        dtest_setup.connections = []
    
        failed = False
        try:
            if not dtest_setup.allow_log_errors:
                errors = check_logs_for_errors(dtest_setup)
                if len(errors) > 0:
                    failed = True
                    pytest.fail(msg='Unexpected error found in node logs (see stdout for full details). Errors: [{errors}]'
                                         .format(errors=str.join("", "", errors)), pytrace=False)
        finally:
            try:
                # save the logs for inspection
                if failed or not dtest_config.delete_logs:
                    copy_logs(request, dtest_setup.cluster)
            except Exception as e:
                logger.error(""Error saving log:"", str(e))
            finally:
>               dtest_setup.cleanup_cluster(request)conftest.py:352: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _self = <dtest_setup.DTestSetup object at 0x7fd313adc898>, request = <SubRequest 'fixture_dtest_setup' for <Function 'test_hsha_defaults'>>    def cleanup_cluster(self, request=None):
        with log_filter('cassandra'):  # quiet noise from driver when nodes start going down
>           if self.dtest_config.keep_test_dir or (self.dtest_config.keep_failed_test_dir and request and request.node.rep_call.failed):
E           AttributeError: 'Function' object has no attribute 'rep_call'dtest_setup.py:351: AttributeError
------------------------------------------------------------------------------------ Captured stdout setup ------------------------------------------------------------------------------------
17:18:59,827 ccm DEBUG Log-watching thread starting.
------------------------------------------------------------------------------------- Captured log setup --------------------------------------------------------------------------------------
17:18:59,735 conftest INFO Starting execution of test_hsha_defaults at 2021-01-20 17:18:59.735191
17:18:59,736 dtest_setup INFO cluster ccm directory: /tmp/dtest-10reduiu
---------------------------------------------------------------------------------- Captured stdout teardown -----------------------------------------------------------------------------------_____________________________________________________________ ERROR at teardown of TestClientNetworkStopStart.test_hsha_with_ssl ______________________________________________________________request = <SubRequest 'fixture_dtest_setup' for <Function 'test_hsha_with_ssl'>>, dtest_config = <dtest_config.DTestConfig object at 0x7fd313af9908>
fixture_dtest_setup_overrides = <dtest_setup_overrides.DTestSetupOverrides object at 0x7fd31301f5c0>, fixture_logging_setup = None, fixture_dtest_cluster_name = 'test'
fixture_dtest_create_cluster_func = <function DTestSetup.create_ccm_cluster at 0x7fd313b15488>    @pytest.fixture(scope='function', autouse=False)
    def fixture_dtest_setup(request,
                            dtest_config,
                            fixture_dtest_setup_overrides,
                            fixture_logging_setup,
                            fixture_dtest_cluster_name,
                            fixture_dtest_create_cluster_func):
        if running_in_docker():
            cleanup_docker_environment_before_test_execution()
    
        # do all of our setup operations to get the enviornment ready for the actual test
        # to run (e.g. bring up a cluster with the necessary config, populate variables, etc)
        initial_environment = copy.deepcopy(os.environ)
        dtest_setup = DTestSetup(dtest_config=dtest_config,
                                 setup_overrides=fixture_dtest_setup_overrides,
                                 cluster_name=fixture_dtest_cluster_name)
        dtest_setup.initialize_cluster(fixture_dtest_create_cluster_func)
    
        if not dtest_config.disable_active_log_watching:
            dtest_setup.begin_active_log_watch()
    
        # at this point we're done with our setup operations in this fixture
        # yield to allow the actual test to run
        yield dtest_setup
    
        # phew! we're back after executing the test, now we need to do
        # all of our teardown and cleanup operations
    
        reset_environment_vars(initial_environment)
        dtest_setup.jvm_args = []
    
        for con in dtest_setup.connections:
            con.cluster.shutdown()
        dtest_setup.connections = []
    
        failed = False
        try:
            if not dtest_setup.allow_log_errors:
                errors = check_logs_for_errors(dtest_setup)
                if len(errors) > 0:
                    failed = True
                    pytest.fail(msg='Unexpected error found in node logs (see stdout for full details). Errors: [{errors}]'
                                         .format(errors=str.join("", "", errors)), pytrace=False)
        finally:
            try:
                # save the logs for inspection
                if failed or not dtest_config.delete_logs:
                    copy_logs(request, dtest_setup.cluster)
            except Exception as e:
                logger.error(""Error saving log:"", str(e))
            finally:
>               dtest_setup.cleanup_cluster(request)conftest.py:352: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _self = <dtest_setup.DTestSetup object at 0x7fd31301f2b0>, request = <SubRequest 'fixture_dtest_setup' for <Function 'test_hsha_with_ssl'>>    def cleanup_cluster(self, request=None):
        with log_filter('cassandra'):  # quiet noise from driver when nodes start going down
>           if self.dtest_config.keep_test_dir or (self.dtest_config.keep_failed_test_dir and request and request.node.rep_call.failed):
E           AttributeError: 'Function' object has no attribute 'rep_call'dtest_setup.py:351: AttributeError
------------------------------------------------------------------------------------ Captured stdout setup ------------------------------------------------------------------------------------
17:19:00,1 ccm DEBUG Log-watching thread starting.
------------------------------------------------------------------------------------- Captured log setup --------------------------------------------------------------------------------------
17:18:59,922 conftest INFO Starting execution of test_hsha_with_ssl at 2021-01-20 17:18:59.922782
17:18:59,923 dtest_setup INFO cluster ccm directory: /tmp/dtest-zlpb7lfk
===Flaky Test Report===test_defaults passed 1 out of the required 1 times. Success!===End Flaky Test Report===
======================================================================== 1 passed, 2 skipped, 2 error in 12.22 seconds ======================================================================== {code}
 ",,brandon.williams,mck,tomasz.lasica,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,mck,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jan 21 15:04:46 UTC 2021,,,,,,,All,,,,"0|z0mt8w:",9223372036854775807,,,,tomasz.lasica,,,,Normal,,4.0-beta2,,https://github.com/apache/cassandra-dtest/commit/7ed2daf38699fa9555feb9049c1c27a410f1520e,,,,,,,,,manual,,,,,"20/Jan/21 16:21;tomasz.lasica;[~mck] do You remember such behavior maybe?;;;","21/Jan/21 13:48;mck;It looks to be a new failure… (though I can't see how the setup of skipped tests was happening before but isn't now 🤷🏻‍♀️)

{code}
E           AttributeError: 'Function' object has no attribute 'rep_call'dtest_setup.py:351: AttributeError
{code};;;","21/Jan/21 14:01;mck;Patch at https://github.com/apache/cassandra-dtest/compare/trunk...thelastpickle:mck/16397 

Just add additional check that 'rep_call' exists, i.e. the test was setup. If it wasn't setup then we know it hasn't failed.;;;","21/Jan/21 14:57;tomasz.lasica;LGTM.

I confirmed manually that indeed it fixes the problem and code looks good.;;;","21/Jan/21 15:04;mck;Committed as [7ed2daf38699fa9555feb9049c1c27a410f1520e|https://github.com/apache/cassandra-dtest/commit/7ed2daf38699fa9555feb9049c1c27a410f1520e].

Thanks [~tomasz.lasica] for the report!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update debian packaging for python3,CASSANDRA-16396,13353333,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,19/Jan/21 17:33,09/Mar/21 23:25,13/Jul/23 08:40,09/Mar/21 23:24,4.0,4.0-rc1,,,,,,Packaging,,,,0,,,Currently we require 'python >= 2.7' but we need to allow the 'python3' package in order to avoid python 2.,,aholmber,mck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,brandon.williams,,,,,,,,,,,,,Packaging,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Mar 09 23:24:48 UTC 2021,,,,,,,All,,,,"0|z0mrs8:",9223372036854775807,,,,mck,,,,Normal,,3.0.6,,https://github.com/apache/cassandra/commit/8c43f510a3a97977bc499b1b12c350169eb8076f,,,,,,,,,install packages.,,,,,"02/Feb/21 21:21;brandon.williams;Patch to use python3.;;;","07/Feb/21 19:24;mck;CI
 - https://ci-cassandra.apache.org/job/Cassandra-devbranch-artifacts/332/ 

Everything around {{python3-dev}} looks fine, but the build (console) is complaining around {{dh_python3}}
{noformat}
18:49:43 dh_python3
18:49:43 E: dh_python3 dh_python3:176: no package to act on (python3-foo or one with ${python3:Depends} in Depends)
18:49:43 # Copy in the jar and symlink to something stable
{noformat};;;","09/Feb/21 18:54;brandon.williams;Ah, well, apparently this was always an issue:
{quote}E: dh_python2 dh_python2:408: no package to act on (python-foo or one with ${python:Depends} in Depends)
{quote}
Updated the patch to try adding ${python3:Depends} and changed invocation of setup.py from `python` to `python3` since the former on a debian system will build with python 2.7.  I'm not sure if CI will like that, but I'm not sure how to handle that in a portable fashion.

We could also just remove dh_python3 since we weren't using it previously, but the point about setup.py remains.;;;","09/Feb/21 20:10;mck;This CI [run|https://ci-cassandra.apache.org/job/Cassandra-devbranch-artifacts/337/jdk=jdk_1.8_latest,label=cassandra/console] looks much better.

{noformat}
20:59:41 dh_python3
20:59:41 I: dh_python3 fs:343: renaming libsigar-amd64-freebsd-6.so to libsigar-amd64-freebsd-6.cpython-37m-x86_64-linux-gnu.so
20:59:41 I: dh_python3 fs:343: renaming libsigar-amd64-linux.so to libsigar-amd64-linux.cpython-37m-x86_64-linux-gnu.so
20:59:41 I: dh_python3 fs:343: renaming libsigar-amd64-solaris.so to libsigar-amd64-solaris.cpython-37m-x86_64-linux-gnu.so
20:59:41 I: dh_python3 fs:343: renaming libsigar-ia64-linux.so to libsigar-ia64-linux.cpython-37m-x86_64-linux-gnu.so
20:59:41 I: dh_python3 fs:343: renaming libsigar-ppc-aix-5.so to libsigar-ppc-aix-5.cpython-37m-x86_64-linux-gnu.so
20:59:41 I: dh_python3 fs:343: renaming libsigar-ppc-linux.so to libsigar-ppc-linux.cpython-37m-x86_64-linux-gnu.so
20:59:41 I: dh_python3 fs:343: renaming libsigar-ppc64-aix-5.so to libsigar-ppc64-aix-5.cpython-37m-x86_64-linux-gnu.so
20:59:41 I: dh_python3 fs:343: renaming libsigar-ppc64-linux.so to libsigar-ppc64-linux.cpython-37m-x86_64-linux-gnu.so
20:59:41 I: dh_python3 fs:343: renaming libsigar-ppc64le-linux.so to libsigar-ppc64le-linux.cpython-37m-x86_64-linux-gnu.so
20:59:41 I: dh_python3 fs:343: renaming libsigar-s390x-linux.so to libsigar-s390x-linux.cpython-37m-x86_64-linux-gnu.so
20:59:42 I: dh_python3 fs:343: renaming libsigar-sparc-solaris.so to libsigar-sparc-solaris.cpython-37m-x86_64-linux-gnu.so
20:59:42 I: dh_python3 fs:343: renaming libsigar-sparc64-solaris.so to libsigar-sparc64-solaris.cpython-37m-x86_64-linux-gnu.so
20:59:42 I: dh_python3 fs:343: renaming libsigar-x86-freebsd-5.so to libsigar-x86-freebsd-5.cpython-37m-x86_64-linux-gnu.so
20:59:42 I: dh_python3 fs:343: renaming libsigar-x86-freebsd-6.so to libsigar-x86-freebsd-6.cpython-37m-x86_64-linux-gnu.so
20:59:42 I: dh_python3 fs:343: renaming libsigar-x86-linux.so to libsigar-x86-linux.cpython-37m-x86_64-linux-gnu.so
20:59:42 I: dh_python3 fs:343: renaming libsigar-x86-solaris.so to libsigar-x86-solaris.cpython-37m-x86_64-linux-gnu.so
20:59:42 # Copy in the jar and symlink to something stable
{noformat};;;","09/Feb/21 20:13;mck;+1;;;","12/Feb/21 14:12;brandon.williams;Updated python to 3.6 as the minimum since that is the lowest version cqlsh will support, also bumped compatibility to 11 which is more correct for python3. [CI here|https://ci-cassandra.apache.org/job/Cassandra-devbranch/378/].  3.x and 3.11 are a bit different, I'll work on patches for those as well.;;;","26/Feb/21 21:27;brandon.williams;||Patch||CI||
|[trunk|https://github.com/driftx/cassandra/tree/CASSANDRA-16396]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/420/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/420/pipeline]|
|[3.11|https://github.com/driftx/cassandra/tree/CASSANDRA-16396-3.11]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/428/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/428/pipeline]|
|[3.0|https://github.com/driftx/cassandra/tree/CASSANDRA-16396-3.0]|[!https://ci-cassandra.apache.org/job/Cassandra-devbranch/429/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/429/pipeline]|;;;","26/Feb/21 22:28;mck;+1;;;","27/Feb/21 16:17;mck;Committed as [8c43f510a3a97977bc499b1b12c350169eb8076f|https://github.com/apache/cassandra/commit/8c43f510a3a97977bc499b1b12c350169eb8076f].;;;","09/Mar/21 23:13;brandon.williams;I must have gotten confused when I mentioned 3.0 and 3.11 here as neither supports python3.  Reopening to revert there; there were a couple of fixes afterward as well.;;;","09/Mar/21 23:24;brandon.williams;Reverted in 3.0 and 3.11.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix schema aggreement race conditions in in-JVM dtests ,CASSANDRA-16394,13353105,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,ifesdjeen,ifesdjeen,ifesdjeen,18/Jan/21 15:48,25/Feb/21 10:10,13/Jul/23 08:40,28/Jan/21 14:55,2.2.20,3.0.24,3.11.10,4.0,4.0-rc1,,,Test/dtest/java,,,,0,,,"There there are two race conditions in in-JVM dtest schema agreement, which are causing test failures:

1. First is caused by the fact we’re starting waiting for schema propagation already after the schema agreement was reached (which was resulting into us endlessly waiting for an agreement that has already been established);
 2. The other one was because the callback to notify about successful agreement can be triggered already after the other node has notified about it, and control flow might have moved cluster to a different configuration.

Example of exception:
{code:java}
Caused by: java.lang.IllegalStateException: Schema agreement not reached
	at org.apache.cassandra.distributed.impl.AbstractCluster$ChangeMonitor.waitForCompletion(AbstractCluster.java:?)
	at org.apache.cassandra.distributed.impl.AbstractCluster.lambda$schemaChange$5(AbstractCluster.java:?)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:?)
	at java.util.concurrent.FutureTask.run(FutureTask.java:?)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:?)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:?)
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:?)
	at java.lang.Thread.run(Thread.java:?)
{code}",,dcapwell,ifesdjeen,maedhroz,sumanth.pasupuleti,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,ifesdjeen,,,,,,,,,,,,,Availability -> Response Crash,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Thu Jan 28 14:54:57 UTC 2021,,,,,,,All,,,,"0|z0mqdk:",9223372036854775807,,,,dcapwell,maedhroz,marcuse,,Normal,,2.2.19,,https://github.com/apache/cassandra/commit/276249910ec1c0aee881947fc81cd323cc604476,,,,,,,,,Test included in the patch,,,,,"26/Jan/21 17:06;ifesdjeen;|[2.2 branch|https://github.com/apache/cassandra/compare/cassandra-2.2...ifesdjeen:CASSANDRA-16394-2.2]|[2.2 CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=CASSANDRA-16394-2.2]|
|[3.0 branch|https://github.com/apache/cassandra/compare/cassandra-3.0...ifesdjeen:CASSANDRA-16394-3.0]|[3.0 CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=CASSANDRA-16394-3.0]|
|[3.11 branch|https://github.com/apache/cassandra/compare/cassandra-3.11...ifesdjeen:CASSANDRA-16394-3.11]|[3.11 CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=CASSANDRA-16394-3.11]|
|[trunk branch|https://github.com/apache/cassandra/compare/trunk...ifesdjeen:CASSANDRA-16394-4.0]|[trunk CI|https://app.circleci.com/pipelines/github/ifesdjeen/cassandra?branch=CASSANDRA-16394-4.0]|
;;;","26/Jan/21 23:51;maedhroz;[~ifesdjeen] LGTM, aside from the minor issue of whether or not we still need to protect {{Instance#liveMemberCount()}} with a check to make sure the instances is initialized and not shut down. We should probably also run the in-JVM upgrade tests before we commit. (Clean runs of {{UpgradeTest}} would be nice to see, etc.);;;","27/Jan/21 20:37;dcapwell;+1 from me.  If you need any help with running upgrade against your branches let me know, have a script for that.;;;","28/Jan/21 14:54;ifesdjeen;Tests passed, including upgrade ones, with an exception of 3.11 branch where there are unrelated static initializer issues. 

Committed to 2.2 with [276249910ec1c0aee881947fc81cd323cc604476|https://github.com/apache/cassandra/commit/276249910ec1c0aee881947fc81cd323cc604476] and merged up to [3.0|https://github.com/apache/cassandra/commit/88e7430bad3e9df810eb3e58c5e8542952b95dd9], [3.11|https://github.com/apache/cassandra/commit/24d133ecbd99a7e41cc985c6721670c705005184] and [trunk|https://github.com/apache/cassandra/commit/b55d830b093016cf364a6e8999175e1e3665348d].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update lib/jflex-1.6.0.jar to match upstream jflex-1.6.0.jar,CASSANDRA-16393,13352930,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mck,mck,mck,17/Jan/21 19:59,25/Feb/21 10:10,13/Jul/23 08:40,20/Jan/21 15:45,3.11.10,4.0,4.0-rc1,,,,,Dependencies,,,,0,,,"jflex-1.6.0.jar was added to lib/ when SASI was added, as part of CASSANDRA-10661

The file in lib/ does not match the upstream file.",,mck,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-10661,,,,,,,,,,,,,,,,,,,,,,,,,0.0,mck,,,,,,,,,,,,,Security,,,,,,,,Low Hanging Fruit,Adhoc Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jan 20 15:45:29 UTC 2021,,,,,,,All,,,,"0|z0mpaw:",9223372036854775807,,,,samt,,,,Low,,3.4,,https://github.com/apache/cassandra/commit/ae58620aaee430a1edc161a05372111abd567c3b,,,,,,,,,CI,,,,,"17/Jan/21 20:05;mck;Patches
- 3.11 :: https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/cassandra-3.11_16393
- trunk :: https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/trunk_16393;;;","17/Jan/21 20:07;mck;[~xedin], [~samt], are you aware why flex-1.6.0.jar doesn't match upstream?  Was this intentional? ;;;","18/Jan/21 08:28;mck;CI run looks [good|https://ci-cassandra.apache.org/job/Cassandra-devbranch/303/parameters/].;;;","19/Jan/21 19:12;samt;Sorry [~mck] I have no recollection of the reason for the discrepancy. Change looks good though so +1;;;","20/Jan/21 15:45;mck;Committed as [ae58620aaee430a1edc161a05372111abd567c3b|https://github.com/apache/cassandra/commit/ae58620aaee430a1edc161a05372111abd567c3b].;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
 Unable to load the library netty_tcnative_linux_aarch_64  when running ant test on aarch64 platform,CASSANDRA-16392,13352758,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,RenhaiZhao,RenhaiZhao,RenhaiZhao,17/Jan/21 09:53,22/Jan/21 09:09,13/Jul/23 08:40,22/Jan/21 09:09,4.0,4.0-rc1,,,,,,Dependencies,,,,0,,,"log:
{code:java}
DEBUG [main] 2021-01-14 17:33:05,365 Unable to load the library 'netty_tcnative_linux_aarch_64', trying other loading mechanism.
java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_aarch_64 in java.library.path
        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
        at java.lang.Runtime.loadLibrary0(Runtime.java:871)
        at java.lang.System.loadLibrary(System.java:1124)
        at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at io.netty.util.internal.NativeLibraryLoader$1.run(NativeLibraryLoader.java:385)
        at java.security.AccessController.doPrivileged(Native Method)
        at io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(NativeLibraryLoader.java:377)
        at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:341)
        at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:136)
        at io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(NativeLibraryLoader.java:96)
        at io.netty.handler.ssl.OpenSsl.loadTcNative(OpenSsl.java:590)
        at io.netty.handler.ssl.OpenSsl.<clinit>(OpenSsl.java:136)
        at org.apache.cassandra.security.SSLFactory.<clinit>(SSLFactory.java:99)
        at org.apache.cassandra.config.EncryptionOptions.<clinit>(EncryptionOptions.java:242)
        at org.apache.cassandra.config.Config.<init>(Config.java:274)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:330)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:308)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:301)
        at org.yaml.snakeyaml.constructor.Constructor$ConstructMapping.construct(Constructor.java:167)
        at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:331)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:219)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:173)
        at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:157)
        at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:472)
        at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:466)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:199)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:129)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:105)
        at org.apache.cassandra.OffsetAwareConfigurationLoader.loadConfig(OffsetAwareConfigurationLoader.java:55)
        at org.apache.cassandra.config.DatabaseDescriptor.loadConfig(DatabaseDescriptor.java:300)
        at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:176)
        at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:161)
        at org.apache.cassandra.ServerTestUtils.daemonInitialization(ServerTestUtils.java:61)
        at org.apache.cassandra.cql3.CQLTester.<clinit>(CQLTester.java:153)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
        at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:38)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:534)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1196)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:1041)
DEBUG [main] 2021-01-14 17:33:05,366 netty_tcnative_linux_aarch_64 cannot be loaded from java.library.path, now trying export to -Dio.netty.native.workdir: /tmp
java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_aarch_64 in java.library.path
        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
        at java.lang.Runtime.loadLibrary0(Runtime.java:871)
        at java.lang.System.loadLibrary(System.java:1124)
        at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
        at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:351)
        at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:136)
        at io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(NativeLibraryLoader.java:96)
        at io.netty.handler.ssl.OpenSsl.loadTcNative(OpenSsl.java:590)
        at io.netty.handler.ssl.OpenSsl.<clinit>(OpenSsl.java:136)
        at org.apache.cassandra.security.SSLFactory.<clinit>(SSLFactory.java:99)
        at org.apache.cassandra.config.EncryptionOptions.<clinit>(EncryptionOptions.java:242)
        at org.apache.cassandra.config.Config.<init>(Config.java:274)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:330)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:308)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:301)
        at org.yaml.snakeyaml.constructor.Constructor$ConstructMapping.construct(Constructor.java:167)
        at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:331)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:219)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:173)
        at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:157)
        at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:472)
        at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:466)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:199)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:129)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:105)
        at org.apache.cassandra.OffsetAwareConfigurationLoader.loadConfig(OffsetAwareConfigurationLoader.java:55)
        at org.apache.cassandra.config.DatabaseDescriptor.loadConfig(DatabaseDescriptor.java:300)
        at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:176)
        at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:161)
        at org.apache.cassandra.ServerTestUtils.daemonInitialization(ServerTestUtils.java:61)
        at org.apache.cassandra.cql3.CQLTester.<clinit>(CQLTester.java:153)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
        at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:38)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:534)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1196)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:1041)
        Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_aarch_64 in java.library.path
                at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
                at java.lang.Runtime.loadLibrary0(Runtime.java:871)
                at java.lang.System.loadLibrary(System.java:1124)
                at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
                at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                at java.lang.reflect.Method.invoke(Method.java:498)
                at io.netty.util.internal.NativeLibraryLoader$1.run(NativeLibraryLoader.java:385)
                at java.security.AccessController.doPrivileged(Native Method)
                at io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(NativeLibraryLoader.java:377)
                at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:341)
                ... 45 common frames omitted
DEBUG [main] 2021-01-14 17:33:05,367 Unable to load the library 'netty_tcnative_linux_aarch_64', trying next name...
java.lang.UnsatisfiedLinkError: could not load a native library: netty_tcnative_linux_aarch_64
        at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:226)
        at io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(NativeLibraryLoader.java:96)
        at io.netty.handler.ssl.OpenSsl.loadTcNative(OpenSsl.java:590)
        at io.netty.handler.ssl.OpenSsl.<clinit>(OpenSsl.java:136)
        at org.apache.cassandra.security.SSLFactory.<clinit>(SSLFactory.java:99)
        at org.apache.cassandra.config.EncryptionOptions.<clinit>(EncryptionOptions.java:242)
        at org.apache.cassandra.config.Config.<init>(Config.java:274)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:330)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:308)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:301)
        at org.yaml.snakeyaml.constructor.Constructor$ConstructMapping.construct(Constructor.java:167)
        at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:331)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:219)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:173)
        at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:157)
        at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:472)
        at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:466)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:199)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:129)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:105)
        at org.apache.cassandra.OffsetAwareConfigurationLoader.loadConfig(OffsetAwareConfigurationLoader.java:55)
        at org.apache.cassandra.config.DatabaseDescriptor.loadConfig(DatabaseDescriptor.java:300)
        at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:176)
        at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:161)
        at org.apache.cassandra.ServerTestUtils.daemonInitialization(ServerTestUtils.java:61)
        at org.apache.cassandra.cql3.CQLTester.<clinit>(CQLTester.java:153)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
        at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:38)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:534)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1196)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:1041)
Caused by: java.io.FileNotFoundException: META-INF/native/libnetty_tcnative_linux_aarch_64.so
        at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:175)
        ... 44 common frames omitted
        Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_aarch_64 in java.library.path
                at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
                at java.lang.Runtime.loadLibrary0(Runtime.java:871)
                at java.lang.System.loadLibrary(System.java:1124)
                at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
                at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:351)
                at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:136)
                ... 44 common frames omitted
                Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_aarch_64 in java.library.path
                        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
                        at java.lang.Runtime.loadLibrary0(Runtime.java:871)
                        at java.lang.System.loadLibrary(System.java:1124)
                        at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
                        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
                        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                        at java.lang.reflect.Method.invoke(Method.java:498)
                        at io.netty.util.internal.NativeLibraryLoader$1.run(NativeLibraryLoader.java:385)
                        at java.security.AccessController.doPrivileged(Native Method)
                        at io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(NativeLibraryLoader.java:377)
                        at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:341)
                        ... 45 common frames omitted
.....
.....
.....
DEBUG [main] 2021-01-14 17:33:05,376 Failed to load netty-tcnative; OpenSslEngine will be unavailable, unless the application has already loaded the symbols by some other means. See https://netty.io/wiki/forked-tomcat-native.html for more information.
java.lang.IllegalArgumentException: Failed to load any of the given libraries: [netty_tcnative_linux_aarch_64, netty_tcnative_linux_aarch_64_fedora, netty_tcnative_aarch_64, netty_tcnative]
        at io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(NativeLibraryLoader.java:104)
        at io.netty.handler.ssl.OpenSsl.loadTcNative(OpenSsl.java:590)
        at io.netty.handler.ssl.OpenSsl.<clinit>(OpenSsl.java:136)
        at org.apache.cassandra.security.SSLFactory.<clinit>(SSLFactory.java:99)
        at org.apache.cassandra.config.EncryptionOptions.<clinit>(EncryptionOptions.java:242)
        at org.apache.cassandra.config.Config.<init>(Config.java:274)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:330)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:308)
        at org.yaml.snakeyaml.constructor.BaseConstructor.newInstance(BaseConstructor.java:301)
        at org.yaml.snakeyaml.constructor.Constructor$ConstructMapping.construct(Constructor.java:167)
        at org.yaml.snakeyaml.constructor.Constructor$ConstructYamlObject.construct(Constructor.java:331)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:219)
        at org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:173)
        at org.yaml.snakeyaml.constructor.BaseConstructor.getSingleData(BaseConstructor.java:157)
        at org.yaml.snakeyaml.Yaml.loadFromReader(Yaml.java:472)
        at org.yaml.snakeyaml.Yaml.loadAs(Yaml.java:466)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:199)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:129)
        at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:105)
        at org.apache.cassandra.OffsetAwareConfigurationLoader.loadConfig(OffsetAwareConfigurationLoader.java:55)
        at org.apache.cassandra.config.DatabaseDescriptor.loadConfig(DatabaseDescriptor.java:300)
        at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:176)
        at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:161)
        at org.apache.cassandra.ServerTestUtils.daemonInitialization(ServerTestUtils.java:61)
        at org.apache.cassandra.cql3.CQLTester.<clinit>(CQLTester.java:153)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
        at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:38)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:534)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:1196)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:1041)
        Suppressed: java.lang.UnsatisfiedLinkError: could not load a native library: netty_tcnative_linux_aarch_64
                at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:226)
                at io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(NativeLibraryLoader.java:96)
                ... 43 common frames omitted
        Caused by: java.io.FileNotFoundException: META-INF/native/libnetty_tcnative_linux_aarch_64.so
                at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:175)
                ... 44 common frames omitted
                Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_aarch_64 in java.library.path
                        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
                        at java.lang.Runtime.loadLibrary0(Runtime.java:871)
                        at java.lang.System.loadLibrary(System.java:1124)
                        at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
                        at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:351)
                        at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:136)
                        ... 44 common frames omitted
                        Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_aarch_64 in java.library.path
                                at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
                                at java.lang.Runtime.loadLibrary0(Runtime.java:871)
                                at java.lang.System.loadLibrary(System.java:1124)
                                at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
                                at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                                at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
                                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                                at java.lang.reflect.Method.invoke(Method.java:498)
                                at io.netty.util.internal.NativeLibraryLoader$1.run(NativeLibraryLoader.java:385)
                                at java.security.AccessController.doPrivileged(Native Method)
                                at io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(NativeLibraryLoader.java:377)
                                at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:341)
                                ... 45 common frames omitted
        Suppressed: java.lang.UnsatisfiedLinkError: could not load a native library: netty_tcnative_linux_aarch_64_fedora
                at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:226)
                at io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(NativeLibraryLoader.java:96)
                ... 43 common frames omitted
        Caused by: java.io.FileNotFoundException: META-INF/native/libnetty_tcnative_linux_aarch_64_fedora.so
                at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:175)
                ... 44 common frames omitted
                Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_aarch_64_fedora in java.library.path
                        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
                        at java.lang.Runtime.loadLibrary0(Runtime.java:871)
                        at java.lang.System.loadLibrary(System.java:1124)
                        at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
                        at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:351)
                        at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:136)
                        ... 44 common frames omitted
                        Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative_linux_aarch_64_fedora in java.library.path
                                at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
                                at java.lang.Runtime.loadLibrary0(Runtime.java:871)
                                at java.lang.System.loadLibrary(System.java:1124)
                                at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
                                at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                                at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
                                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                                at java.lang.reflect.Method.invoke(Method.java:498)
                                at io.netty.util.internal.NativeLibraryLoader$1.run(NativeLibraryLoader.java:385)
                                at java.security.AccessController.doPrivileged(Native Method)
                                at io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(NativeLibraryLoader.java:377)
                                at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:341)
                                ... 45 common frames omitted
        Suppressed: java.lang.UnsatisfiedLinkError: could not load a native library: netty_tcnative_aarch_64
                at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:226)
                at io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(NativeLibraryLoader.java:96)
                ... 43 common frames omitted
        Caused by: java.io.FileNotFoundException: META-INF/native/libnetty_tcnative_aarch_64.so
                at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:175)
                ... 44 common frames omitted
                Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative_aarch_64 in java.library.path
                        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
                        at java.lang.Runtime.loadLibrary0(Runtime.java:871)
                        at java.lang.System.loadLibrary(System.java:1124)
                        at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
                        at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:351)
                        at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:136)
                        ... 44 common frames omitted
                        Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative_aarch_64 in java.library.path
                                at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
                                at java.lang.Runtime.loadLibrary0(Runtime.java:871)
                                at java.lang.System.loadLibrary(System.java:1124)
                                at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
                                at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                                at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
                                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                                at java.lang.reflect.Method.invoke(Method.java:498)
                                at io.netty.util.internal.NativeLibraryLoader$1.run(NativeLibraryLoader.java:385)
                                at java.security.AccessController.doPrivileged(Native Method)
                                at io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(NativeLibraryLoader.java:377)
                                at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:341)
                                ... 45 common frames omitted
        Suppressed: java.lang.UnsatisfiedLinkError: could not load a native library: netty_tcnative
                at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:226)
                at io.netty.util.internal.NativeLibraryLoader.loadFirstAvailable(NativeLibraryLoader.java:96)
                ... 43 common frames omitted
        Caused by: java.io.FileNotFoundException: META-INF/native/libnetty_tcnative.so
                at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:175)
                ... 44 common frames omitted
                Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative in java.library.path
                        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
                        at java.lang.Runtime.loadLibrary0(Runtime.java:871)
                        at java.lang.System.loadLibrary(System.java:1124)
                        at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
                        at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:351)
                        at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:136)
                        ... 44 common frames omitted
                        Suppressed: java.lang.UnsatisfiedLinkError: no netty_tcnative in java.library.path
                                at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1860)
                                at java.lang.Runtime.loadLibrary0(Runtime.java:871)
                                at java.lang.System.loadLibrary(System.java:1124)
                                at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38)
                                at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                                at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
                                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                                at java.lang.reflect.Method.invoke(Method.java:498)
                                at io.netty.util.internal.NativeLibraryLoader$1.run(NativeLibraryLoader.java:385)
                                at java.security.AccessController.doPrivileged(Native Method)
                                at io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(NativeLibraryLoader.java:377)
                                at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:341)
                                ... 45 common frames omitted
DEBUG [main] 2021-01-14 17:33:05,376 Initialize netty-tcnative using engine: 'default'
DEBUG [main] 2021-01-14 17:33:05,377 Failed to initialize netty-tcnative; OpenSslEngine will be unavailable. See https://netty.io/wiki/forked-tomcat-native.html for more information.

{code}",,e.dimitrova,ganeshraju,mck,RenhaiZhao,v_ganeshraju,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16384,,,,,,,,,,,,,,,,,,,,,,,0.0,RenhaiZhao,,,,,,,,,,,,,Correctness,,,,,,,,Low Hanging Fruit,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jan 22 09:09:07 UTC 2021,,,,,,,ARM,,,,"0|z0mo8o:",9223372036854775807,,,,mck,,,,Normal,,0.3,,https://github.com/apache/cassandra/commit/7f1659cd1d46ab8904eee99daefcaaa7a521e00b,,,,,,,,,"User manual testing, and ci-cassandra if agents are ready.",,,,,"17/Jan/21 10:04;RenhaiZhao;This will cause OpenSslEngine not available.

The root cause is :

[https://github.com/netty/netty-tcnative/issues/571]

[https://github.com/netty/netty-tcnative/pull/572]

[https://github.com/netty/netty-tcnative/issues/576]

[https://github.com/netty/netty-tcnative/pull/591]

 

will submit patch soon.;;;","17/Jan/21 13:49;RenhaiZhao;patch link: 

[https://github.com/apache/cassandra/pull/869]

Because the file 'project.xml' will conflict , so I merge cassandra-16384 and cassandra-16392's patch together.;;;","20/Jan/21 20:57;mck;Waiting on https://lists.apache.org/thread.html/rc677261c9258a684720fbdbd301f6e854545168229534332d88d4b24%40%3Cdev.cassandra.apache.org%3E , otherwise ready to commit.;;;","22/Jan/21 09:09;mck;Committed as [7f1659cd1d46ab8904eee99daefcaaa7a521e00b|https://github.com/apache/cassandra/commit/7f1659cd1d46ab8904eee99daefcaaa7a521e00b].

Thanks [~RenhaiZhao]!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
UpgradeTest sporadically failing on schema updates,CASSANDRA-16387,13352575,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,maedhroz,maedhroz,maedhroz,15/Jan/21 22:57,16/Mar/22 15:24,13/Jul/23 08:40,15/Feb/21 13:48,3.0.25,3.11.11,4.0,4.0-rc1,,,,Test/dtest/java,,,,0,,,"We’ve observed {{UpdateTest}} failing during what appears to be a schema change:

https://app.circleci.com/pipelines/github/maedhroz/cassandra/192/workflows/ed5305e6-e4f9-420e-9f0a-6153333746dc/jobs/1068

It almost looks like the Gossiper can’t find its own endpoint state in the endpoint state map, and the failure is not consistent, which might suggest a race.",,aholmber,aleksey,blerer,e.dimitrova,maedhroz,,,,,,,,,,,"maedhroz opened a new pull request #885:
URL: https://github.com/apache/cassandra/pull/885


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Feb/21 19:10;githubbot;600","maedhroz commented on pull request #885:
URL: https://github.com/apache/cassandra/pull/885#issuecomment-772788999


   https://app.circleci.com/pipelines/github/maedhroz/cassandra/220/workflows/77a03059-1e80-4250-adb2-949fbada2e07


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;03/Feb/21 20:10;githubbot;600","maedhroz removed a comment on pull request #885:
URL: https://github.com/apache/cassandra/pull/885#issuecomment-772788999


   https://app.circleci.com/pipelines/github/maedhroz/cassandra/220/workflows/77a03059-1e80-4250-adb2-949fbada2e07


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Feb/21 00:41;githubbot;600","maedhroz commented on pull request #885:
URL: https://github.com/apache/cassandra/pull/885#issuecomment-772936178


   https://app.circleci.com/pipelines/github/maedhroz/cassandra/222/workflows/2866e273-279a-46c5-8d13-d6c18c5a383a


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Feb/21 00:41;githubbot;600","maedhroz edited a comment on pull request #885:
URL: https://github.com/apache/cassandra/pull/885#issuecomment-772936178


   https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16387-3.0


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Feb/21 03:58;githubbot;600","maedhroz opened a new pull request #886:
URL: https://github.com/apache/cassandra/pull/886


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Feb/21 18:13;githubbot;600","maedhroz opened a new pull request #887:
URL: https://github.com/apache/cassandra/pull/887


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;04/Feb/21 19:10;githubbot;600","maedhroz opened a new pull request #887:
URL: https://github.com/apache/cassandra/pull/887


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;05/Feb/21 10:15;githubbot;600","maedhroz opened a new pull request #886:
URL: https://github.com/apache/cassandra/pull/886


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;05/Feb/21 10:16;githubbot;600","maedhroz closed pull request #887:
URL: https://github.com/apache/cassandra/pull/887


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Feb/21 17:33;githubbot;600","maedhroz commented on pull request #887:
URL: https://github.com/apache/cassandra/pull/887#issuecomment-779364951


   Committed in https://github.com/apache/cassandra/commit/1f686fd634dbe9b46c03629d2b3bfae345a151e3


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Feb/21 17:33;githubbot;600","maedhroz commented on pull request #887:
URL: https://github.com/apache/cassandra/pull/887#issuecomment-779369036


   Committed in https://github.com/apache/cassandra/commit/1f686fd634dbe9b46c03629d2b3bfae345a151e3 and merged forward.


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;15/Feb/21 17:41;githubbot;600","smiklosovic closed pull request #885:
URL: https://github.com/apache/cassandra/pull/885


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:23;githubbot;600","smiklosovic closed pull request #886:
URL: https://github.com/apache/cassandra/pull/886


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:24;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,8400,,,0,8400,,,,,,,,,,,,,,,CASSANDRA-16181,,,,,,,,,,,,,,,,,,,,,,,0.0,maedhroz,,,,,,,,,,,,,Correctness -> Test Failure,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Mon Feb 15 13:48:45 UTC 2021,,,,,,,All,,,,"0|z0mn48:",9223372036854775807,,,,aleksey,blerer,brandon.williams,,Normal,,3.0.0,,https://github.com/apache/cassandra/commit/1f686fd634dbe9b46c03629d2b3bfae345a151e3,,,,,,,,,The ultimate goal here is for the upgrade tests that indicated the problem in the first place to pass consistently. It should be easy enough to modify the CircleCI config to pull the right branches from the previous versions...,,,,,"19/Jan/21 16:23;maedhroz;This may be a duplicate of CASSANDRA-16394, but I'll mark it as such when/if that is confirmed.;;;","01/Feb/21 15:46;aholmber;[~maedhroz] with CASSANDRA-16394 closing last week, was there a disposition on this one?;;;","01/Feb/21 18:32;maedhroz;[~aholmber] I'm waiting for the results of some upgrade tests on the CASSANDRA-16181 patch (after rebasing that on trunk w/ the changes from CASSANDRA-16394).;;;","02/Feb/21 16:48;maedhroz;Unfortunately, this still [seems to be happening|https://app.circleci.com/pipelines/github/maedhroz/cassandra/216/workflows/f821efda-dbcd-4281-b2df-e4a3611b1b23/jobs/1195] even after a rebase on trunk w/ CASSANDRA-16394. Going to need to have to dig in a bit more...;;;","02/Feb/21 21:22;maedhroz;Nominally, this looks like it's happening is when:

1.) A cluster is created at 3.0.
 2.) The schema is updated, in this case a keyspace is created in {{init()}} and another keyspace and table immediately after, as laid out in {{setup()}}.
 3.) The schema migration coordinator node pushes schema mutations out.
 4.) Some other node (again still on 3.0) receives the update message/partitions.
 5.) When it tries to gossip its new schema version, it can't even find its *own endpoint state* in {{endpointStateMap}} in {{Gossiper#addLocalApplicationStateInternal()}}.
{noformat}
org.apache.cassandra.distributed.shared.ShutdownException: Uncaught exceptions were thrown during test

	at org.apache.cassandra.distributed.impl.AbstractCluster.checkAndResetUncaughtExceptions(AbstractCluster.java:866)
	at org.apache.cassandra.distributed.impl.AbstractCluster.close(AbstractCluster.java:852)
	at org.apache.cassandra.distributed.upgrade.UpgradeTestBase$TestCase.run(UpgradeTestBase.java:188)
	at org.apache.cassandra.distributed.upgrade.MixedModeBatchTestBase.testSimpleStrategy(MixedModeBatchTestBase.java:70)
	at org.apache.cassandra.distributed.upgrade.MixedModeFrom3UnloggedBatchTest.testSimpleStrategy30to4(MixedModeFrom3UnloggedBatchTest.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53)
	Suppressed: java.lang.AssertionError
		at org.apache.cassandra.gms.Gossiper.addLocalApplicationStateInternal(Gossiper.java:1551)
		at org.apache.cassandra.gms.Gossiper.addLocalApplicationStates(Gossiper.java:1575)
		at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1565)
		at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:478)
		at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:600)
		at org.apache.cassandra.schema.SchemaKeyspace.mergeSchemaAndAnnounceVersion(SchemaKeyspace.java:1336)
		at org.apache.cassandra.db.DefinitionsUpdateVerbHandler$1.runMayThrow(DefinitionsUpdateVerbHandler.java:51)
		at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
		at java.util.concurrent.FutureTask.run(FutureTask.java:266)
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
		at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:83)
		at java.lang.Thread.run(Thread.java:748)
{noformat}
This only happens sporadically, so it feels like we're randomly losing the race to update {{endpointStateMap}}...;;;","03/Feb/21 06:17;maedhroz;Alright, after digging around even more, I'm starting to wonder how tests that start 3 or more nodes (and don't use the GOSSIP feature) could be expected to avoid this problem. In {{AbstractCluster#startup()}}, we start the first node and any nodes using {{auto_bootstrap}} sequentially, one-at-a-time. After that, the other nodes are started in parallel. This seems to open a whole pandoras box of races in the initialization of the messaging service, gossiper, and migration manager.

In this case nodes 2 and 3 start up in parallel. By default, {{UpgradeTestBase}} doesn't use {{auto_bootstrap}}, and it doesn't use the GOSSIP or NETWORK features. For the 3.0 {{Instance}} this means we rely on {{Gossiper#initializeNodeUnsafe()}} to initialize the endpoint state map entry for the local node and then immediately treat all other nodes as being live via a call to {{Gossiper#realMarkAlive()}}. Importantly, this happens after mock messaging is set up. Lastly, a call to {{StorageService#ensureTraceKeyspace()}} makes sure the traces keyspace is created and _pushes the schema change to other live nodes_. The problem is that means all nodes in the cluster, even the ones that haven't finished calling {{Gossiper#initializeNodeUnsafe()}} will get a {{DEFINITIONS_UPDATE}} message and try to access the local node gossip state from the endpoint state map that doesn't exist yet.

With some extra debugging and stack traces, this is what the progression looks like in the logs:

1.) Node 2 create the traces keyspace, announces it, and pushes the schema change mutations.

{noformat}
INFO  [node2_isolatedExecutor:3] node2 2021-02-02 19:33:54,101 StorageService.java:1293 - NORMAL
java.lang.RuntimeException
	at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:433)
	at org.apache.cassandra.service.MigrationManager.announceGlobally(MigrationManager.java:419)
	at java.util.Optional.ifPresent(Optional.java:159)
	at org.apache.cassandra.service.StorageService.ensureTraceKeyspace(StorageService.java:1080)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$7(Instance.java:609)
{noformat}

2.) Node 3 get the message.

{noformat}
INFO  [node3_MigrationStage:1] node3 2021-02-02 19:33:54,119 DefinitionsUpdateVerbHandler.java:48 - Received schema mutation push from /127.0.0.2 for keyspaces [system_schema]
{noformat}

3.) Node 3 tries to update its own schema version, but can't since its own endpoint state is very much missing.

{noformat}
DEBUG [node3_MigrationStage:1] node3 2021-02-02 19:33:54,186 Schema.java:485 - Adding org.apache.cassandra.config.CFMetaData@3262feed[cfId=c5e99f16-8677-3914-b17e-960613512345,ksName=system_traces
Exception null occurred on thread node3_MigrationStage:1
java.lang.AssertionError
	at org.apache.cassandra.gms.Gossiper.addLocalApplicationStateInternal(Gossiper.java:1555)
	at org.apache.cassandra.gms.Gossiper.addLocalApplicationStates(Gossiper.java:1579)
	at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1569)
	at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:479)
	at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:600)
	at org.apache.cassandra.schema.SchemaKeyspace.mergeSchemaAndAnnounceVersion(SchemaKeyspace.java:1336)
	at org.apache.cassandra.db.DefinitionsUpdateVerbHandler$1.runMayThrow(DefinitionsUpdateVerbHandler.java:54)
{noformat}

4.) Node 3 finally gets initialized, but it's too late.

{noformat}
INFO  [node3_GossipStage:1] node3 2021-02-02 19:33:54,304 Gossiper.java:1633 - Initializing state for /127.0.0.3 on /127.0.0.3
java.lang.RuntimeException
	at org.apache.cassandra.gms.Gossiper.initializeNodeUnsafe(Gossiper.java:1634)
	at org.apache.cassandra.distributed.impl.Instance.lambda$addToRing$8(Instance.java:666)
{noformat}
;;;","03/Feb/21 06:40;maedhroz;As an experiment, I changed {{UpgradeTestBase}} to use {{auto_bootstrap}} by default, and so far I've been unable to trigger the failure locally (dozens of runs) or on [Circle|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16181], where the failure was almost constant beforehand. I'm not sure if that's a solution though, if we want to preserve the performance improvement I'm guessing we get with concurrent {{Instance}} startup.

Perhaps all we need to do is avoid {{pushSchemaMutation()}} when we're creating the traces keyspace at every instance. It seems redundant anyway, and I'm actually not even sure why we push the mutations to other nodes via {{setUpDistributedSystemKeyspaces()}} in a production scenario, given each node has the mutations applied locally already on join. (Like forcing serial startup, avoiding the push also stabilizes the failing upgrade tests locally.)

CC [~aleksey];;;","04/Feb/21 04:04;maedhroz;I did some 3.0 and trunk experiments where we avoid {{pushSchemaMutation()}} for the locally added distributed system schema changes, as mentioned above:

3.0: https://github.com/apache/cassandra/pull/885
test: https://app.circleci.com/pipelines/github/maedhroz/cassandra/222/workflows/2866e273-279a-46c5-8d13-d6c18c5a383a

trunk: https://github.com/apache/cassandra/pull/821 (recent commits)
test: https://app.circleci.com/pipelines/github/maedhroz/cassandra/221/workflows/4adb761f-2521-495a-9715-dcf5a9c7eadf

This doesn't appear to cause a single new test failure (except for maybe {{InternodeEncryptionEnforcementTest}} which seems to implicitly rely on a connection being made when the definitions update is sent). That doesn't necessarily mean things are safe, but it pushes this idea toward viability...

(Note that a couple of the in-JVM upgrade tests for the trunk patch still fail, because the version of 3.0 used there doesn't include the fix from the 3.0 patch above.);;;","04/Feb/21 18:47;maedhroz;Given the clean test runs, I'm posting the 3.0 and 3.11 versions of the solution that avoids globally pushing mutations from the distributed system keyspace schema changes at startup. (Nodes still passively announce their schema version.)

While this change appears to consistently fix the problem in local test runs (3.0 -> trunk in-JVM upgrade tests), the next step would be modifying the CircleCI config to use my 3.0 and 3.11 branches rather than the base branches to build dtest JARs.

|[CASSANDRA-16387-3.0|https://github.com/apache/cassandra/pull/885]|[CircleCI|https://app.circleci.com/pipelines/github/maedhroz/cassandra/223/workflows/e60f131d-326e-4241-92d4-f51b9043eb62]|
|[CASSANDRA-16387-3.11|https://github.com/apache/cassandra/pull/886]|[CircleCI|https://app.circleci.com/pipelines/github/maedhroz/cassandra/225/workflows/0bea0ed5-9dd6-4a7e-8cae-3a6c5ea7942d]|

UPDATE: The trunk version also looks not to have created any new test failures.

|[CASSANDRA-16387-trunk|https://github.com/apache/cassandra/pull/887]|[CircleCI|https://app.circleci.com/pipelines/github/maedhroz/cassandra/227/workflows/93a9d7d5-df87-41bd-a4be-5ea689416f30]|

In any case, judging from these results, either it *is* safe to avoid the global push, or we just lack the tests/in-code documentation to make it obvious that it isn't.;;;","05/Feb/21 08:48;blerer;[~maedhroz] Your reasoning and the patches make sense to me.
The {{j8_upgradetests-no-vnodes}} seems to be failing in 3.0 and 3.11 and I am not sure of what should be the state of those tests.;;;","05/Feb/21 16:11;maedhroz;[~dcapwell] Do we actually expect the {{j8_upgradetests-no-vnodes}} to work on 3.0 and 3.11 right now?

[~blerer] [~aleksey] Any chance you'd like to be an official reviewers?;;;","05/Feb/21 16:41;maedhroz;Also a quick note for reviewers, we're obviously seeing CASSANDRA-16415 in our test results.;;;","11/Feb/21 18:12;aleksey;All three patches look good to me, except for one omission. {{StorageService#doAuthSetup()}} is also a user of {{evolveSystemKeyspace()}}, and probably should be updated to not actively push.;;;","11/Feb/21 22:35;maedhroz;Addressed [~aleksey]'s feedback and started new CI runs for [3.0|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16387-3.0], [3.11|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16387-3.11], and [trunk|https://app.circleci.com/pipelines/github/maedhroz/cassandra?branch=CASSANDRA-16387-trunk].;;;","12/Feb/21 01:18;brandon.williams;Patches look good to me, +1 if CI is happy.;;;","12/Feb/21 04:16;maedhroz;I'm not seeing anything problematic in the CircleCI runs, and we've got 3 +1's. Unless we want to throw up ci-cassandra runs, anyone willing to commit this?

Thanks for all the review!;;;","15/Feb/21 13:48;blerer;Committed into 3.0 at 1f686fd634dbe9b46c03629d2b3bfae345a151e3 and merged into cassandra-3.11 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test case AuditLoggerTest  fail on aarch64 platform,CASSANDRA-16384,13352137,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,RenhaiZhao,RenhaiZhao,RenhaiZhao,14/Jan/21 03:19,16/Mar/22 15:16,13/Jul/23 08:40,22/Jan/21 09:09,4.0,4.0-rc1,,,,,,Dependencies,,,,0,,,"When run ant; ant test on aarch64 platform, AuditLoggerTest failed，the output as follows:

 
{code:java}
[junit-timeout] Testsuite: org.apache.cassandra.audit.AuditLoggerTest
[junit-timeout] #
[junit-timeout] # A fatal error has been detected by the Java Runtime Environment:
[junit-timeout] #
[junit-timeout] #  SIGBUS (0x7) at pc=0x0000ffff81add020, pid=27652, tid=0x0000ffff80e1f1f0
[junit-timeout] #
[junit-timeout] # JRE version: OpenJDK Runtime Environment (8.0_222-b10) (build 1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10)
[junit-timeout] # Java VM: OpenJDK 64-Bit Server VM (25.222-b10 mixed mode linux-aarch64 compressed oops)
[junit-timeout] # Problematic frame:
[junit-timeout] # V  [libjvm.so+0xa4d020]
[junit-timeout] #
[junit-timeout] # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again
[junit-timeout] #
[junit-timeout] # An error report file with more information is saved as:
[junit-timeout] # /home/cassandra/cassandra/hs_err_pid27652.log
[junit-timeout] #
[junit-timeout] # If you would like to submit a bug report, please visit:
[junit-timeout] #   http://bugreport.java.com/bugreport/crash.jsp
[junit-timeout] #
[junit-timeout] Testsuite: org.apache.cassandra.audit.AuditLoggerTest
[junit-timeout] Testsuite: org.apache.cassandra.audit.AuditLoggerTest Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0 sec
[junit-timeout]
[junit-timeout] Testcase: org.apache.cassandra.audit.AuditLoggerTest:testConflictingPaths:      Caused an ERROR
[junit-timeout] Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.
[junit-timeout] junit.framework.AssertionFailedError: Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.
[junit-timeout]         at java.util.Vector.forEach(Vector.java:1275)
[junit-timeout]         at java.util.Vector.forEach(Vector.java:1275)
[junit-timeout]         at java.lang.Thread.run(Thread.java:748)
[junit-timeout]
[junit-timeout]
[junit-timeout] Test org.apache.cassandra.audit.AuditLoggerTest FAILED (crashed)
   [delete] Deleting directory /home/cassandra/cassandra/build/test/cassandra/commitlog:2
   [delete] Deleting directory /home/cassandra/cassandra/build/test/cassandra/data:2
   [delete] Deleting directory /home/cassandra/cassandra/build/test/cassandra/saved_caches:2
   [delete] Deleting directory /home/cassandra/cassandra/build/test/cassandra/hints:2

{code}
attached file hs_err_pid27652.log",,e.dimitrova,ganeshraju,mck,RenhaiZhao,slachiewicz,v_ganeshraju,,,,,,,,,,"zhaorenhai opened a new pull request #869:
URL: https://github.com/apache/cassandra/pull/869


   CASSANDRA-16392 Unable to load the library netty_tcnative_linux_aarch_64
   
   Upgrade chronicle*jar and netty-tcnative*jar to fix above 2 issues on aarch64


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Jan/21 13:45;githubbot;600","michaelsembwever commented on pull request #869:
URL: https://github.com/apache/cassandra/pull/869#issuecomment-761860506


   The license files under `lib/licenses/` also need to be renamed (and checked for updates)


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;17/Jan/21 18:48;githubbot;600","michaelsembwever commented on pull request #869:
URL: https://github.com/apache/cassandra/pull/869#issuecomment-762294059


   it's looking much better now.
   
   can we please (even though these faults existed before, it would be nice to fix them up to standard)…
   - rename `lib/licenses/chronicle-core-2.20.126-SNAPSHOT.txt` to `lib/licenses/chronicle-core-2.20.126.txt`
   - rename `lib/licenses/netty-4.1.58.txt` to `lib/licenses/netty-all-4.1.58.txt`
   - rename `lib/licenses/netty-tcnative-2.0.36.txt` to `lib/licenses/netty-tcnative-boringssl-static-2.0.36.txt`


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Jan/21 14:44;githubbot;600","michaelsembwever edited a comment on pull request #869:
URL: https://github.com/apache/cassandra/pull/869#issuecomment-762294059


   it's looking much better now.
   
   can we please (even though these faults existed before, it would be nice to fix them up to standard)…
   - rename `lib/licenses/chronicle-core-2.20.126-SNAPSHOT.txt` to `lib/licenses/chronicle-core-2.20.126.txt`
   - rename `lib/licenses/netty-4.1.58.txt` to `lib/licenses/netty-all-4.1.58.txt`
   - rename `lib/licenses/netty-tcnative-2.0.36.txt` to `lib/licenses/netty-tcnative-boringssl-static-2.0.36.txt`
   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Jan/21 14:48;githubbot;600","michaelsembwever edited a comment on pull request #869:
URL: https://github.com/apache/cassandra/pull/869#issuecomment-762294059


   it's looking much better now.
   
   can we please…
   - rename `lib/licenses/chronicle-core-2.20.126-SNAPSHOT.txt` to `lib/licenses/chronicle-core-2.20.126.txt`
   - rename `lib/licenses/netty-4.1.58.txt` to `lib/licenses/netty-all-4.1.58.txt`
   - rename `lib/licenses/netty-tcnative-2.0.36.txt` to `lib/licenses/netty-tcnative-boringssl-static-2.0.36.txt`
   
    (even though these faults existed before this PR, if we're going to touch them let's correct them to the standard)


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;18/Jan/21 20:26;githubbot;600","zhaorenhai commented on pull request #869:
URL: https://github.com/apache/cassandra/pull/869#issuecomment-762543585


   Hello, mck, now files have been renamed as your request.


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;19/Jan/21 01:25;githubbot;600","zhaorenhai commented on pull request #869:
URL: https://github.com/apache/cassandra/pull/869#issuecomment-763279350


   Hello, mck, if no issue, could you help to merge this?


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;20/Jan/21 02:13;githubbot;600","smiklosovic closed pull request #869:
URL: https://github.com/apache/cassandra/pull/869


   


-- 
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

To unsubscribe, e-mail: pr-unsubscribe@cassandra.apache.org

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;16/Mar/22 15:16;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,4800,,,0,4800,,,,,,,,,,,,,,,,,,,CASSANDRA-15889,CASSANDRA-16392,,,,,,,,,,,,,"19/Jan/21 01:26;RenhaiZhao;16384-trunk.txt;https://issues.apache.org/jira/secure/attachment/13018977/16384-trunk.txt","16/Jan/21 08:06;RenhaiZhao;hs_err_pid27652.log;https://issues.apache.org/jira/secure/attachment/13018862/hs_err_pid27652.log",,,,2.0,RenhaiZhao,,,,,,,,,,,,,Availability,,,,,,,,Normal,Unit Test,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Fri Jan 22 09:09:59 UTC 2021,,,,,,,ARM,,,,"0|z0mkew:",9223372036854775807,,,,mck,,,,Normal,,4.0-alpha1,,https://github.com/apache/cassandra/commit/7f1659cd1d46ab8904eee99daefcaaa7a521e00b,,,,,,,,,Tested successfully on aarch64 platform,,,,,"16/Jan/21 08:14;RenhaiZhao;I think the root cause is : [https://github.com/OpenHFT/Chronicle-Queue/issues/528]

I will try to upgrade all chronicle jar version to latest stable version, any suggestions?

If no, I will upload patch asap.;;;","16/Jan/21 11:13;mck;No objections [~RenhaiZhao], an upgrade to the latest chronicle-queue-5.x.x makes sense here. That would be a major upgrade of the dependency so maybe some APIs have changed. Please make sure to upgrade the chronicle-* dependencies (as found in the corresponding chronicle-bom).;;;","17/Jan/21 13:43;RenhaiZhao;attached patch file: 16384-trunk.txt;;;","17/Jan/21 13:47;RenhaiZhao;patch link: 

[https://github.com/apache/cassandra/pull/869]

Because the file 'project.xml' will conflict , so I merge cassandra-16384 and cassandra-16392's patch together.;;;","17/Jan/21 19:50;mck;I have confirmed the updated jar files in commit [72f8265a55f908213dd45907a8fdf7a1135b8180|https://github.com/apache/cassandra/pull/869/commits/72f8265a55f908213dd45907a8fdf7a1135b8180] match those upstream.

This was done with the following
{code}
ant write-poms
rm lib/*.jar
mvn dependency:copy-dependencies -DoutputDirectory=`pwd`/lib/ -f ./build/apache-cassandra-4.0-beta5-SNAPSHOT.pom
git status
{code};;;","17/Jan/21 20:12;mck;CI looks [good|https://ci-cassandra.apache.org/job/Cassandra-devbranch/302/].

Just the license files need to be updated too… ;;;","18/Jan/21 02:15;RenhaiZhao;[~mck]

License files updated.

But there are 4 license fiels under the latest netty-tcnative project.

[https://github.com/netty/netty-tcnative/tree/main/license]

Should we include them all? If yes, how?  paste all contents of 4 files to 1 file? or just include 4  files?

Thanks;;;","18/Jan/21 11:12;mck;{quote}
But there are 4 license fiels under the latest netty-tcnative project.
https://github.com/netty/netty-tcnative/tree/main/license
Should we include them all? If yes, how?  paste all contents of 4 files to 1 file? or just include 4  files?
{quote}

They are the licenses to the dependencies of netty-tcnative. They don't need to be included.

netty-tcnative itself remains under the same [license|https://github.com/netty/netty-tcnative/blob/main/LICENSE.txt] (APLv2). So all that needs to be done is to rename the license file, for example for netty-tcnative, rename {{lib/licenses/netty-tcnative-2.0.34.txt}} to {{lib/licenses/netty-tcnative-2.0.36.txt}};;;","18/Jan/21 12:15;RenhaiZhao;[~mck]

Yes, I just copied latest netty-tcnative license,  could you please help to review?;;;","20/Jan/21 16:14;mck;FYI, the areas of impact of the major upgrade of chronicle-queue is Auditing, FQL (Full Query Logger), and Diagnostics. It makes sense to upgrade before 4.0 GA. 

Major changes from 4 to 5 are described here: https://github.com/OpenHFT/Chronicle-Queue#the-changes-from-chronicle-queue-version-4-to-version-5 

There's significant changes in the way chronicle-queue version 5 deals with its tailers (they are now read-only and the indexing are not lazy) and locking model (a separate metadata.cq4t file is now used). More importantly, a version 4 Tailer shouldn't be reading from a version 5 Appender. The last reason breaks our [Beta Release Lifecycle rules|https://cwiki.apache.org/confluence/display/CASSANDRA/Release+Lifecycle], if we are to define the chronicle-queue files as a project interface (which it is). For this reason I shall raise the upgrade via the dev ML.

;;;","20/Jan/21 20:51;mck;Notice has been provided to the dev ML [here|https://lists.apache.org/thread.html/rc677261c9258a684720fbdbd301f6e854545168229534332d88d4b24%40%3Cdev.cassandra.apache.org%3E]. I will need to wait a few days before moving forward.;;;","22/Jan/21 09:09;mck;Committed as [7f1659cd1d46ab8904eee99daefcaaa7a521e00b|https://github.com/apache/cassandra/commit/7f1659cd1d46ab8904eee99daefcaaa7a521e00b].

Thanks [~RenhaiZhao]!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nodetool removenode error “Conflicting replica added”,CASSANDRA-16381,13351820,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,mck,vroyer59,vroyer59,12/Jan/21 16:50,02/Jun/21 18:11,13/Jul/23 08:40,03/Mar/21 07:16,4.0,4.0-rc1,,,,,,Consistency/Bootstrap and Decommission,,,,0,,,"When testing elassandra on C* 4.0, integration tests with ccm systematically failed on removing a node with the following error “Conflicting replica added” . [This integration test |https://github.com/strapdata/elassandra/blob/v6.8.4-strapdata/integ-test/test-cleanup-repair.sh#L289] was ok with Elassandra based on Cassandra 3.11, and there is no changes in that test. Moreover, it seems there is no cassandra-test (dtest) for removing a node (there is only one removenode test for transient replication). The topology_test.py remove a node from the CCM cluster, but it does not call nodetool removenode.

I wonder if we have a non-tested regression here in C 4.0 ?
{noformat}
++ ccm node1 nodetool status
++ awk ‘/127.0.0.3/ \{ print $7 }’
+ HOST_ID3=6d2e858f-dacc-4c7c-a626-14b45f6b3b94
+ ccm node3 stop
+ ccm node1 nodetool removenode 6d2e858f-dacc-4c7c-a626-14b45f6b3b94
Traceback (most recent call last):
  File “/usr/local/bin/ccm”, line 4, in <module>
    __import__(‘pkg_resources’).run_script(‘ccm==3.1.6’, ‘ccm’)
  File “/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py”, line 742, in run_script
    self.require(requires)[0].run_script(script_name, ns)
  File “/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py”, line 1674, in run_script
    exec(script_code, namespace, namespace)
  File “/Library/Python/2.7/site-packages/ccm-3.1.6-py2.7.egg/EGG-INFO/scripts/ccm”, line 112, in <module>  File “build/bdist.macosx-10.14-intel/egg/ccmlib/cmds/node_cmds.py”, line 233, in run
  File “build/bdist.macosx-10.14-intel/egg/ccmlib/node.py”, line 848, in nodetool
  File “build/bdist.macosx-10.14-intel/egg/ccmlib/node.py”, line 2131, in handle_external_tool_process
ccmlib.node.ToolError: Subprocess [‘nodetool’, ‘-h’, ‘localhost’, ‘-p’, ‘7100’, ‘removenode’, ‘6d2e858f-dacc-4c7c-a626-14b45f6b3b94’] exited with non-zero status; exit status: 1;
stdout: nodetool: Conflicting replica added (expected unique ranges): Full(/127.0.0.1:7000,(4949329179655327935,6135417578204142297]); existing: Full(/127.0.0.1:7000,(4949329179655327935,6135417578204142297])
See ‘nodetool help’ or ‘nodetool help <command>’.++ finish
++ echo ‘ERROR occurs, test failed’
ERROR occurs, test failed
++ ‘[’ ‘!’ -z ‘’ ‘]’
++ exit 1
{noformat}",,aholmber,bereng,blerer,brandon.williams,jhickey,maedhroz,mck,samt,vroyer59,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16525,,,,,,,,,,,,,,,,,,,"03/Feb/21 15:13;brandon.williams;dtest.tar.bz2;https://issues.apache.org/jira/secure/attachment/13019930/dtest.tar.bz2","03/Feb/21 15:13;brandon.williams;node1.tar.bz2;https://issues.apache.org/jira/secure/attachment/13019931/node1.tar.bz2","03/Feb/21 15:13;brandon.williams;node2.tar.bz2;https://issues.apache.org/jira/secure/attachment/13019932/node2.tar.bz2","03/Feb/21 15:13;brandon.williams;node3.tar.bz2;https://issues.apache.org/jira/secure/attachment/13019933/node3.tar.bz2",,4.0,mck,,,,,,,,,,,,,Correctness -> API / Semantic Definition,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Wed Jun 02 18:09:07 UTC 2021,,,,,,,All,,,,"0|z0migg:",9223372036854775807,,,,aholmber,bereng,brandon.williams,,Critical,,4.0-alpha1,,https://github.com/apache/cassandra/commit/64f54f9fb0ac1fe2920f44379326cf076ab8aab8,,,,,,,,,dtest offered by Brandon.,,,,,"01/Feb/21 23:58;brandon.williams;I added a simple removenode test [here|https://github.com/driftx/cassandra-dtest/tree/CASSANDRA-16381] and a patch that gets around the duplicate sources [here|https://github.com/driftx/cassandra/tree/CASSANDRA-16381] which were coming from system_traces (for some reason.)  This works great... until you add any user defined data, as stress does.   This will cause streaming errors and then the hosts involved in streaming will also lose network connectivity to each other and begin dropping gossip syn messages.

The area of code to modify to make the replicas distinct comes from transient replication, but the duplicates don't occur until CASSANDRA-15666.  I'm not really sure what's going on here, could you take a look, [~blerer]?;;;","02/Feb/21 12:08;blerer;[~brandon.williams] Sure :-)
;;;","03/Feb/21 12:06;blerer;Looking into it more deeply. I had initially misunderstood the problem.;;;","03/Feb/21 15:14;brandon.williams;Attaching the dtest dir from a failed run. You can see that a node not being removed is marked down but then quickly marked back up.  Also attaching logs from a manual test I did; there seems to be a timing component here, as in the manual test the node is marked down and never comes back up.;;;","03/Feb/21 15:28;samt;{quote}a node not being removed is marked down but then quickly marked back up{quote}

Sounds similar to CASSANDRA-16094;;;","03/Feb/21 15:29;brandon.williams;But this is a node that is NOT being removed - it was never down.;;;","03/Feb/21 15:31;samt;ah sorry, I misread and thought that the node going DOWN/UP was not removed when it should have been 
/me slides back into the shadows;;;","17/Feb/21 20:11;aholmber;I've been looking at this, but don't let that deter anyone else who wants to have a go. I'm not previously knowledgable in these areas of the code.

bq. This will cause streaming errors and then the hosts involved in streaming will also lose network connectivity to each other and begin dropping gossip syn messages.

That doesn't match exactly what I've seen here on trunk. We should see if we can corroborate. I'll describe my observations here:

When running Brandon's simple test, intermittently (but consistently) we see removenode hang. When in this state, the remaining servers are still responsive to client traffic, but the nodetool command will hang forever (until the test times out). The remaining nodes continue attempting to reconnect to the node intended for removal. Meanwhile a previously queued SYN message to that node expires. I think the reconnect and message expiry are non-issues, assuming that would stop if the node removal completes. Will have to get back to that after figuring out the primary issue. On to that...

{{removenode}} is hanging forever in [this loop|https://github.com/apache/cassandra/blob/e8a9d4203c81e622fc2418d2faf2593e2123161e/src/java/org/apache/cassandra/service/StorageService.java#L4732-L4735] on the coordinating node1 because it is never receiving the final {{REPLICATION_DONE_REQ}} message sent by node2. Both nodes appear to complete their streaming sessions without error and send that message. We never see the one from node2 arrive at node1. At the same time, I'm seeing gossip diverge between node1. node2. They eventually convict each other. The node2 streaming session complete message [times out|https://github.com/apache/cassandra/blob/e8a9d4203c81e622fc2418d2faf2593e2123161e/src/java/org/apache/cassandra/service/StorageService.java#L3027-L3028] having never seen a response. The loop is exited because node1 is not ""alive"" immediately after the conviction.

Current avenues of investigation:
1.) Look into why the replication done request is not being sent/received. Presently I think I see it being enqueued, but never serialized and sent.
2.) Understand gossip diverging at the end of the streaming session.;;;","22/Feb/21 22:56;aholmber;The apparent network/messaging interruption was being caused by a deadlock of the OutboundConnection event loop thread and the streaming threads. I'll explain a bit more below, but for now I'm going to offer the patch removing the duplicated replication tasks, which also removes the deadlock. We can decide in review if the other stuff warrants another ticket.

The duplication was being caused because SS processes each change for [each key|https://github.com/apache/cassandra/blob/5ed5e84613ef0e9664a774493db7d2604e3596e0/src/java/org/apache/cassandra/service/StorageService.java#L3234-L3237} in the event {{EndpointState}}, but that presently has keys for both {{STATUS_WITH_PORT}} and the deprecated {{STATUS}} ([ref|https://github.com/apache/cassandra/blob/5ed5e84613ef0e9664a774493db7d2604e3596e0/src/java/org/apache/cassandra/service/StorageService.java#L3234-L3237]), so two replication tasks get kicked off for the same event.

[patch|https://github.com/aholmberg/cassandra/pull/40]
[circleci|https://app.circleci.com/pipelines/github/aholmberg/cassandra?branch=CASSANDRA-16381] running;;;","23/Feb/21 07:28;bereng;You will have to rerun circle with MID config as it's just a wall of red now :-);;;","23/Feb/21 14:08;aholmber;argh. I was in a rush and forgot the circle config. Thanks Berenguer. Will get back with that.
(another run is started at the same link);;;","23/Feb/21 14:14;brandon.williams;Jenkins running [here|https://ci-cassandra.apache.org/job/Cassandra-devbranch/395/];;;","23/Feb/21 21:52;brandon.williams;[This|https://ci-cassandra.apache.org/job/Cassandra-devbranch/395/testReport/junit/dtest-large-novnode.replication_test/TestReplication/test_network_topology/] looks a bit suspect to me, though the code looks good and my dtest passed.;;;","23/Feb/21 22:51;aholmber;This test is broken for 4.0, independent of the changes I'm proposing here (it's regexing for trace messages that changed format). I'll open a ticket, but I would prefer not to block since it's known to be a test issue, and I've manually verified the functionality that test is trying to characterize.;;;","23/Feb/21 22:52;brandon.williams;bq. my dtest passed.

Scratch that, it never ran because I ran against the current dtests.;;;","24/Feb/21 05:47;bereng;The networking topology failure is a known failure, correct.

[~aholmber] plenty of random commits got pushed to the PR, probably some git acrobatics gone wrong :-) Also seems the original commit is missing a test _if_ it's doable and you'll have to re-run ci bc the ci runs we have have those extra commits.;;;","24/Feb/21 15:50;aholmber;[~Bereng] thanks for pointing that out. I rebased against the stuff coming in on apache/cassandra and forgot to update trunk on my fork. It's clean now.;;;","25/Feb/21 06:02;bereng;Wall of red again. The cqlsh failures I can't tell. But the dtests failures upon the missing  'parentRepairSessionsCount' is bc you have to rebase both dtests and C* code. But that would bring you up to date with ci-cass imo which atm is also a wall of red.

So I think our best bet here is to wait for ci-cass to be back to green-ish and then rebase bc there are too many things breaking the code going on at once.;;;","25/Feb/21 14:48;brandon.williams;bq. The cqlsh failures I can't tell. 

These are currently known to fail after the driver change and are being worked on.;;;","25/Feb/21 22:52;aholmber;I see Sam pushed some dtest changes today. I've rebased both server PR and my dtest branch containing Brandon's test. CI running now.;;;","26/Feb/21 05:15;bereng;Nah wall of red still on driver issues. Btw do you think adding a unit test is feasible?;;;","26/Feb/21 17:23;aholmber;[~mck] had a good suggestion during review.  I'm not in a position to be as responsive as I'd like at this time, and he's offered to take the reins on this. Thanks Mick!;;;","26/Feb/21 18:20;mck;Thanks [~aholmber]. New patch is Adam's work, just with the filtering moved from {{StorageService}} up to {{Gossiper}}. I think this helps it be a bit more inclusive it catching the redundant application states on incoming endpoint changes.

- patches: [cassandra|https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/trunk_16381], [cassandra-dtest|https://github.com/driftx/cassandra-dtest/commits/CASSANDRA-16381]
- ci-cassandra.a.o: [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/424/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/424/pipeline], and with [~brandon.williams]'s dtest:  [!https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest/438/badge/icon!|https://ci-cassandra.apache.org/job/Cassandra-devbranch-dtest/438/]

;;;","26/Feb/21 22:52;mck;CI is a bit of a mess atm, e.g. topology_test.py::TestTopology::test_simple_removenode is working locally for me. But I think there's a fair few breakages here that I do need to look into tomorrow.;;;","27/Feb/21 10:10;mck;A consequence of this patch is that {{`nodetool gossipinfo`}} will no longer list the deprecated application states on remote (4.0) endpoints. Gossipinfo will still list both versions of application states of the local endpoint (as that needs to be broadcasted so for <4.0 endpoints in a mix-version cluster). This required a [fix|https://github.com/thelastpickle/cassandra-dtest/commit/6b63a1831000a462209978af1263a3ea32d38344] in the snitch_test.py dtest.

For example, this output from {{snitch_test.py::TestGossipingPropertyFileSnitch::test_prefer_local_reconnect_on_listen_address}} called on node1 (127.0.0.3).
{noformat}
/127.0.0.4
  generation:1614418673
  heartbeat:88
  STATUS:75:NORMAL,0
  LOAD:18:75875.0
  SCHEMA:21:5a4d7919-7143-3e86-a586-ce62ee960249
  DC:11:dc1
  RACK:13:rack1
  RELEASE_VERSION:5:4.0-beta5-SNAPSHOT
  INTERNAL_IP:9:127.0.0.2
  RPC_ADDRESS:4:127.0.0.2
  NET_VERSION:1:12
  HOST_ID:2:92406fb2-63ba-4e4d-9228-bf14ed22d7c4
  RPC_READY:85:true
  INTERNAL_ADDRESS_AND_PORT:7:127.0.0.2:7000
  NATIVE_ADDRESS_AND_PORT:3:127.0.0.2:9042
  STATUS_WITH_PORT:74:NORMAL,0
  TOKENS:73:<hidden>
/127.0.0.3
  generation:1614418645
  heartbeat:117
  LOAD:96:105177.0
  SCHEMA:43:5a4d7919-7143-3e86-a586-ce62ee960249
  DC:11:dc1
  RACK:13:rack1
  RELEASE_VERSION:5:4.0-beta5-SNAPSHOT
  NET_VERSION:1:12
  HOST_ID:2:53cacd4a-7ed9-4efe-bbe3-de04701a9c74
  RPC_READY:35:true
  INTERNAL_ADDRESS_AND_PORT:7:127.0.0.1:7000
  NATIVE_ADDRESS_AND_PORT:3:127.0.0.1:9042
  STATUS_WITH_PORT:22:NORMAL,-9223372036854775808
  TOKENS:21:<hidden>
{noformat};;;","01/Mar/21 13:08;mck;There's another bug here, introduced with the transient replicas work, only visible when testing with vnodes.

{{StorageServer.restoreReplicaCount(..)}} can come up with a list of new replica token ranges where one of them is identical to an existing. This causes the error like…
{noformat}
java.lang.IllegalArgumentException: Conflicting replica added (expected unique ranges): Full(/127.0.0.2:7000,(-7412624036846214601,-4901911818908895437]); existing: Full(/127.0.0.2:7000,(-7412624036846214601,-4901911818908895437])
	at org.apache.cassandra.locator.RangesAtEndpoint$Builder.add(RangesAtEndpoint.java:212)
	at org.apache.cassandra.locator.RangesAtEndpoint$Builder.add(RangesAtEndpoint.java:189)
	at org.apache.cassandra.locator.ReplicaCollection$Builder.add(ReplicaCollection.java:154)
	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)
	at java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1556)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)
	at org.apache.cassandra.service.StorageService.lambda$null$18(StorageService.java:3127)
	at java.util.Map.forEach(Map.java:630)
	at org.apache.cassandra.service.StorageService.lambda$restoreReplicaCount$19(StorageService.java:3119)
	at java.util.HashMap.forEach(HashMap.java:1289)
	at org.apache.cassandra.service.StorageService.restoreReplicaCount(StorageService.java:3117)
	at org.apache.cassandra.service.StorageService.handleStateRemoving(StorageService.java:2893)
	at org.apache.cassandra.service.StorageService.onChange(StorageService.java:2285)
	at org.apache.cassandra.service.StorageService.onJoin(StorageService.java:3236)
	at org.apache.cassandra.gms.Gossiper.handleMajorStateChange(Gossiper.java:1276)
	at org.apache.cassandra.gms.Gossiper.applyStateLocally(Gossiper.java:1394)
	at org.apache.cassandra.gms.GossipDigestAckVerbHandler.doVerb(GossipDigestAckVerbHandler.java:84)
        …
{noformat}
A simple fix is to change the behaviour of {{RangesAtEndpoint.add(..)}} from {{Conflict.NONE}} to {{Conflict.DUPLICATE}}, but I'm not too sure if that is safe…;;;","01/Mar/21 13:22;brandon.williams;Is this different from the one my [first patch|https://github.com/driftx/cassandra/commit/40a3ec5f5d6d3eb2677fa5b8a765719493312706] tried to solve?;;;","01/Mar/21 13:36;mck;bq. … a patch that gets around the duplicate sources here …

I totally missed that you had already spotted this [~brandon.williams]! Yes, it is the same thing. 
;;;","01/Mar/21 15:47;mck;New patch, includes fix for deprecated ApplicationStates and for handling duplicated replicas collected in {{RangesAtEndpoint}}.

- patches: [cassandra|https://github.com/apache/cassandra/compare/trunk...thelastpickle:mck/trunk_16381], [cassandra-dtest|https://github.com/apache/cassandra-dtest/compare/trunk...thelastpickle:mck/trunk_16381]
- ci-cassandra.a.o: [!https://ci-cassandra.apache.org/job/Cassandra-devbranch/437/badge/icon!|https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/437/pipeline], 

UPDATE: CI results look good (unrelated).
;;;","01/Mar/21 22:53;jhickey;Hi, I stumbled upon this issue because I just ran into this live when trying to nodetool remove a DN node (EC2 instance failed healthcheck/terminated).


{noformat}
nodetool: Conflicting replica added (expected unique ranges): Full(/10.65.13.40:7000,(4964172795476831591,5638026500598693924]); existing: Full(/10.65.13.40:7000,(4964172795476831591,5638026500598693924]){noformat}

Commenting in case this info helps with patch priority. Version is 4.0-beta4, using vnodes.;;;","02/Mar/21 07:41;mck;Thanks for the report [~jhickey]. This ticket is urgent (and the ticket now marked as such) and is blocking the next release.;;;","02/Mar/21 13:17;mck;I've bisected using the new dtest, and the duplicates bug goes back to CASSANDRA-14404 and [f7431b432875e334170ccdb19934d05545d2cebd|https://github.com/thelastpickle/cassandra/commit/f7431b432875e334170ccdb19934d05545d2cebd#diff-a8ef260117550e1d260388e780f7197a624d7aba98af043100d31f40771117c1]. 
;;;","02/Mar/21 15:43;brandon.williams;+1;;;","02/Mar/21 21:39;aholmber;+1;;;","03/Mar/21 04:16;bereng;+1;;;","03/Mar/21 07:16;mck;Committed as [64f54f9fb0ac1fe2920f44379326cf076ab8aab8|https://github.com/apache/cassandra/commit/64f54f9fb0ac1fe2920f44379326cf076ab8aab8];;;","04/Mar/21 19:49;aholmber;Are the dtest changes still forthcoming? I saw the patch, but it appears to me that it was not merged on {{apache/cassandra-dtest}};;;","04/Mar/21 20:00;brandon.williams;I've committed those.;;;","04/Mar/21 20:01;aholmber;I see it. Thanks!;;;","05/Mar/21 08:51;mck;Thanks for catching that [~aholmber] [~brandon.williams]!;;;","02/Jun/21 18:09;maedhroz;bq. A simple fix is to change the behaviour of RangesAtEndpoint.add(..) from Conflict.NONE to Conflict.DUPLICATE, but I'm not too sure if that is safe…

Did we ever figure out what about CASSANDRA-14404 started generating duplicates?

(Aside: I'm guessing this is one of the things we would have discovered in CASSANDRA-14669...);;;",,,,,,,,,,,,
Response headers to OPTION messages always have Stream ID of zero ,CASSANDRA-16376,13351421,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,pauliusb,pauliusb,11/Jan/21 10:14,05/Feb/21 10:38,13/Jul/23 08:40,15/Jan/21 12:08,4.0,4.0-rc1,,,,,,Messaging/Client,,,,0,protocolv5,,"It seems that streaming behavior has changed since version 4.0-beta2. When a new connection is made, all responses to the OPTIONS messages always return with stream id 0 even if requests are made with stream id 1. This causes connection failures on some clients. 

Attached wireshark dump with an example.

 

Node version: 4.0-beta4

Native protocol version: tested with v3 and v4",,brandon.williams,jmckenzie,mck,pauliusb,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-16424,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/21 10:13;pauliusb;cass-dump.pcap;https://issues.apache.org/jira/secure/attachment/13018502/cass-dump.pcap",,,,,1.0,samt,,,,,,,,,,,,,Availability -> Response Crash,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,Clients,,Fri Jan 15 12:08:20 UTC 2021,,,,,,,All,,,,"0|z0mg00:",9223372036854775807,,,,mck,,,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/7e936e7f2c6ccc73d8e3acd31d7050889ec1efbe,,,,,,,,,Added unit test covering all supported protocol versions.,,,,,"11/Jan/21 21:03;jmckenzie;Thanks for the report [~pauliusb]. Someone will take a look and get back with you; this definitely looks like a blocker to hit RC.;;;","13/Jan/21 11:46;samt;The fix is really trivial, just an oversight in the handler which takes care of initial protocol negotiation. I've added a unit test which checks the stream ids across the negotiation process for all supported versions. 

[~pauliusb] if you're able to test with a dev build, please give it a try & thanks for the report.

||branch||Circle CI|Apache CI|
|[16376-trunk|https://github.com/beobal/cassandra/tree/16376-trunk]|[circle|https://circleci.com/gh/beobal/cassandra?branch=16376-trunk]|[apache|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/283]|;;;","13/Jan/21 13:14;pauliusb;[~samt] I've tried the patch with a local build and this problem no longer occurs. Thanks!;;;","14/Jan/21 20:09;mck;some small nit comment on [commit|https://github.com/beobal/cassandra/commit/2764a5f33ebe61e272c39ed9de3f38428c37089b], otherwise +1;;;","15/Jan/21 12:08;samt;Thanks [~pauliusb] & [~mck], committed to trunk with the nit addressed & the eclipse warning in `BurnTestUtil` removed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Restore check for consistent native protocol versions for connection,CASSANDRA-16374,13349214,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,samt,samt,samt,05/Jan/21 14:30,22/Jan/21 14:03,13/Jul/23 08:40,22/Jan/21 14:03,4.0,4.0-rc1,,,,,,Messaging/Client,,,,0,protocolv5,,"In protocol v4 and earlier, the frame header is checked during deserialization to ensure that the version matches the one negotiated for the connection.
The original intention was to remove this version id from the frame (renamed to envelope in v5) header. However, there is value in keeping this check as well as the the one for the beta flag, so it remains in the frame/envelope format. The validation itself however, was removed by some refactoring as part of CASSANDRA-15299 and should be added back for all protocol versions before finalizing v5 and cutting a release candidate. The text detailing its removal also remains in the proposed spec update attached to CASSANDRA-14688, which also needs to be updated.",,mck,samt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,samt,,,,,,,,,,,,,Correctness -> API / Semantic Implementation,,,,,,,,Normal,Code Inspection,,false,,,,,,,,,,,,,,,,,9223372036854775807,,Clients,,Fri Jan 22 14:03:14 UTC 2021,,,,,,,All,,,,"0|z0m274:",9223372036854775807,,,,mck,,,,Normal,,4.0-beta4,,https://github.com/apache/cassandra/commit/a0441eb66b1976865c105069e9964104720db7fb,,,,,,,,,New unit test covering all supported protocol versions. Protocol spec to be finalized in CASSANDRA-14688.,,,,,"15/Jan/21 16:38;samt;Pushed a branch with the fix and new test, CI is running now.
||branch||Circle CI|Apache CI|
|[16374-trunk|https://github.com/beobal/cassandra/tree/16374-trunk]|[circle|https://circleci.com/gh/beobal/cassandra?branch=16374-trunk]|[apache|https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch/289]|;;;","21/Jan/21 14:50;mck;+1;;;","22/Jan/21 14:03;samt;Committed, thanks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Import from csv of empty strings in list fails with a ParseError: Empty values are not allowed,  given up without retries",CASSANDRA-16372,13348959,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,Gerrrr,Ostico,Ostico,04/Jan/21 15:23,13/Jan/21 09:47,13/Jul/23 08:40,12/Jan/21 19:32,3.0.24,3.11.10,4.0,4.0-rc1,,,,Tool/cqlsh,,,,1,,," 

Cqlsh fail to import an empty string which is present in a list data type.

{color:#ff0000}_In those conditions, simple csv backups can discard rows and data can be corrupted._{color}

 

*Conditions*

 
{code:java}
# cqlsh
Connected to Test Cluster at 127.0.0.1:9042.
[cqlsh 5.0.1 | Cassandra 3.11.6 | CQL spec 3.4.4 | Native protocol v4]
Use HELP for help.

CREATE TABLE test.test_1 (
    uid uuid PRIMARY KEY,
    texts list<text>
);

insert into test.test_1 ( uid, texts ) VALUES( 833fee3f-d4f9-418b-9387-84ac2cda5cb7, ['But if you now try to wash your hands,', ''] );

{code}
 

Now exporting and and re-importing data fails:

 
{code:java}
cqlsh> select * from test.test_1;

 uid                                  | texts
--------------------------------------+------------------------------------------------
 833fee3f-d4f9-418b-9387-84ac2cda5cb7 | ['But if you now try to wash your hands,', '']


cqlsh> COPY test.test_1 (uid, texts) TO 'ctm.csv'; 
Using 7 child processesStarting copy of test.test_1 with columns [uid, texts].
Processed: 1 rows; Rate: 9 rows/s; Avg. rate: 9 rows/s 1 rows exported to 1 files in 0.148 seconds. 

cqlsh> truncate table test.test_1;


cqlsh> COPY test.test_1 (uid, texts) FROM 'ctm.csv';
Using 7 child processes
Starting copy of test.test_1 with columns [uid, texts].
Failed to import 1 rows: ParseError - Failed to parse ['But if you now try to wash your hands,', ''] : Empty values are not allowed,  given up without retries
Failed to process 1 rows; failed rows written to import_test_test_1.err
Processed: 1 rows; Rate:       2 rows/s; Avg. rate:       2 rows/s
1 rows imported from 1 files in 0.415 seconds (0 skipped).


cqlsh> select * from test.test_1; 
uid  | pid
-----+-----

{code}
 

 

 ",,brandon.williams,Gerrrr,Ostico,,,,,,,,,,,,,"Gerrrr opened a new pull request #111:
URL: https://github.com/apache/cassandra-dtest/pull/111


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Jan/21 16:29;githubbot;600","Gerrrr opened a new pull request #111:
URL: https://github.com/apache/cassandra-dtest/pull/111


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jan/21 04:29;githubbot;600","Gerrrr closed pull request #111:
URL: https://github.com/apache/cassandra-dtest/pull/111


   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;13/Jan/21 09:47;githubbot;600",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0,1800,,,0,1800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,Gerrrr,,,,,,,,,,,,,Correctness,,,,,,,,Normal,User Report,,false,,,,,,,,,,,,,,,,,9223372036854775807,,None,,Tue Jan 12 19:32:18 UTC 2021,,,,,,,All,,,,"0|z0m0mw:",9223372036854775807,,,,brandon.williams,,,,Normal,,3.0.0,,https://github.com/apache/cassandra/commit/a542b865047ad8cc3d9f64ab3c3a018ac069331e,,,,,,,,,"[dtests patch|https://github.com/apache/cassandra-dtest/pull/111] adds test cases with empty strings inside collections. Already existing [test_reading_collections_with_empty_values|https://github.com/apache/cassandra-dtest/blob/trunk/cqlsh_tests/test_cqlsh_copy.py#L559-L586] covers the case where empty values for other data types still throw during parsing rather than on the server-side.",,,,,"04/Jan/21 20:56;brandon.williams;Repros against 3.11 head.;;;","04/Jan/21 20:59;brandon.williams;Also note that the summary at the end is completely wrong and does not count the skip.;;;","09/Jan/21 16:59;Gerrrr;{{ParseError}} happens because the check for {{null}} fields inside a collection mistakes empty strings for null fields, which are not allowed inside collections. In addition to allowing empty strings, the patch subtracts failed rows from the total number of processed rows.


|Branch||Source||
|trunk|[branch|https://github.com/apache/cassandra/pull/863]|
|3.11|[branch|https://github.com/apache/cassandra/pull/862]|
|3.0|[branch|https://github.com/apache/cassandra/pull/864]|
|dtests|[branch|https://github.com/apache/cassandra-dtest/pull/111]|
 

 ;;;","12/Jan/21 19:32;brandon.williams;Committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
