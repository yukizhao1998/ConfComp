Summary,Issue key,Issue id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Fix Version/s,Fix Version/s,Component/s,Due Date,Votes,Labels,Labels,Labels,Labels,Labels,Description,Environment,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Original Estimate,Remaining Estimate,Time Spent,Work Ratio,Σ Original Estimate,Σ Remaining Estimate,Σ Time Spent,Security Level,Inward issue link (Blocker),Outward issue link (Blocker),Outward issue link (Blocker),Inward issue link (Duplicate),Outward issue link (Duplicate),Outward issue link (Incorporates),Inward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Inward issue link (Required),Inward issue link (dependent),Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Custom field (Affects version (Component)),Custom field (Attachment count),Custom field (Authors),Custom field (Blog - New Blog Administrators),Custom field (Blog - New Blog PMC),Custom field (Blog - Write access),Custom field (Blog Administrator?),Custom field (Blogs - Admin for blog),Custom field (Blogs - Email Address),Custom field (Blogs - Existing Blog Access Level),Custom field (Blogs - Existing Blog Name),Custom field (Blogs - New Blog Write Access),Custom field (Blogs - Username),Custom field (Bug Category),Custom field (Bugzilla - Email Notification Address),Custom field (Bugzilla - List of usernames),Custom field (Bugzilla - PMC Name),Custom field (Bugzilla - Project Name),Custom field (Bugzilla Id),Custom field (Bugzilla Id),Custom field (Change Category),Custom field (Complexity),Custom field (Discovered By),Custom field (Docs Text),Custom field (Enable Automatic Patch Review),Custom field (Epic Link),Custom field (Estimated Complexity),Custom field (Evidence Of Open Source Adoption),Custom field (Evidence Of Registration),Custom field (Evidence Of Use On World Wide Web),Custom field (Existing GitBox Approval),Custom field (External issue ID),Custom field (External issue URL),Custom field (Fix version (Component)),Custom field (Git Notification Mailing List),Custom field (Git Repository Import Path),Custom field (Git Repository Name),Custom field (Git Repository Type),Custom field (GitHub Options),Custom field (Github Integration),Custom field (Github Integrations - Other),Custom field (Global Rank),Custom field (INFRA - Subversion Repository Path),Custom field (Initial Confluence Contributors),Custom field (Last public comment date),Custom field (Level of effort),Custom field (Machine Readable Info),Custom field (Mentor),Custom field (New-TLP-TLPName),Custom field (Original story points),Custom field (Parent Link),Custom field (Priority),Custom field (Project),Custom field (Protected Branch),Custom field (Rank),Custom field (Rank (Obsolete)),Custom field (Review Date),Custom field (Reviewer),Custom field (Reviewer),Custom field (Reviewers),Custom field (Severity),Custom field (Severity),Custom field (Skill Level),Custom field (Source Control Link),Custom field (Space Description),Custom field (Space Key),Custom field (Space Name),Custom field (Start Date),Custom field (Tags),Custom field (Target end),Custom field (Target start),Custom field (Team),Custom field (Test and Documentation Plan),Custom field (Testcase included),Custom field (Tester),Custom field (Tester),Custom field (Workaround),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment
Broken keyspace strategy_option with zero replicas,CASSANDRA-1924,12494336,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,thorcarpenter,thorcarpenter,30/Dec/10 22:59,16/Apr/19 09:33,14/Jul/23 05:51,11/Mar/11 18:18,0.7.4,,,,0,,,,,,"When a keyspace is defined that has strategy options specifying zero replicas should be place in a datacenter (e.g. DCX:0), an assert is violated for any insert and LOCAL_QUORUM reads fail.  I'm not sure if the issue is that there are no nodes in DCX or that I'm saying DCX shouldn't get any replicas, or a combination of the two.

The broken keyspace:

create keyspace KeyspaceDC1 with
  replication_factor = 1 and
  placement_strategy = 'org.apache.cassandra.locator.NetworkTopologyStrategy' and
  strategy_options = [{DC1:1, DC2:0}];

The fixed keyspace:

create keyspace KeyspaceDC1 with
  replication_factor = 1 and
  placement_strategy = 'org.apache.cassandra.locator.NetworkTopologyStrategy' and
  strategy_options = [{DC1:1}];


To reproduce:

* Install the 0.7rc3 rpm on a single node in ""DC1"".
* In cassandra.yaml set initial_token = 1 and specify PropertyFileSnitch.
* cassandra-topology.properties:

10.5.64.26=DC1:R1
default=DC2:R1

* Schema loaded via cassandra-cli:

create keyspace KeyspaceDC1 with
  replication_factor = 1 and
  placement_strategy = 'org.apache.cassandra.locator.NetworkTopologyStrategy' and
  strategy_options = [{DC1:1, DC2:0}];

use KeyspaceDC1;

create column family TestCF with
  column_type = 'Standard' and
  comparator = 'BytesType' and
  keys_cached = 200000 and
  rows_cached = 2000 and
  gc_grace = 0 and
  read_repair_chance = 0.0;

* In cassandra-cli execute the following:

[default@unknown] use KeyspaceDC1;
Authenticated to keyspace: KeyspaceDC1
[default@KeyspaceDC1] set TestCF['some key']['some col'] = 'some value';
Internal error processing insert

* If you have asserts enabled, check system.log where you should find the assertion error: 

DEBUG [pool-1-thread-3] 2010-12-29 12:10:38,897 CassandraServer.java (line 362) insert
ERROR [pool-1-thread-3] 2010-12-29 12:10:38,906 Cassandra.java (line 2960) Internal error processing insert
java.lang.AssertionError
        at org.apache.cassandra.locator.TokenMetadata.firstTokenIndex(TokenMetadata.java:392) 
        at org.apache.cassandra.locator.TokenMetadata.ringIterator(TokenMetadata.java:417)
        at org.apache.cassandra.locator.NetworkTopologyStrategy.calculateNaturalEndpoints(NetworkTopologyStrategy.java:95)
        at org.apache.cassandra.locator.AbstractReplicationStrategy.getNaturalEndpoints(AbstractReplicationStrategy.java:99)
        at org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:1411)
        at org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:1394)
        at org.apache.cassandra.service.StorageProxy.mutate(StorageProxy.java:109)
        at org.apache.cassandra.thrift.CassandraServer.doInsert(CassandraServer.java:442)
        at org.apache.cassandra.thrift.CassandraServer.insert(CassandraServer.java:379)
        at org.apache.cassandra.thrift.Cassandra$Processor$insert.process(Cassandra.java:2952)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:2555)
        at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) 
        at java.lang.Thread.run(Thread.java:619)

* If you don't have asserts enabled, you should find that no errors are logged but LOCAL_QUORUM reads cause TimedOutExceptions on the client.
",,thorcarpenter,tommysdk,,,,,,,,7200,7200,,0%,7200,7200,,,,,,,,,,,,,,"11/Mar/11 14:54;slebresne;0001-Ring-iterator-empty-list-test.patch;https://issues.apache.org/jira/secure/attachment/12473396/0001-Ring-iterator-empty-list-test.patch","11/Mar/11 13:43;slebresne;0002-NetworkTopologyStrategy-test-and-small-optim.patch;https://issues.apache.org/jira/secure/attachment/12473392/0002-NetworkTopologyStrategy-test-and-small-optim.patch",,,,,,,,,,,,,2.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20372,,,Fri Mar 11 23:07:03 UTC 2011,,,,,,,,,,"0|i0g88v:",92766,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"10/Mar/11 09:11;tommysdk;So the AssertionError occurs in TokenMetadata.firstTokenIndex where the token ring is expected to have a size greater than 0. A discovery I made is that the TokenMetadata.ringIterator method which makes the call to firstTokenIndex, also expects the ring to be non-empty if the includeMin parameter is true:
final boolean insertMin = (includeMin && !ring.get(0).equals(StorageService.getPartitioner().getMinimumToken())) ? true : false;

If the includeMin parameter is true and the ring is empty, it would raise a java.lang.IndexOutOfBoundsException: Index: 0, Size: 0. However, the method only seems to be called with includeMin == true from StorageProxy.getRestrictedRanges. As in the case of this issue, it is called from NetworkTopologyStrategy with a includeMin == false, thus failing at the assertion in TokenMetadata.firstTokenIndex since there are no TokenMetadata tokens present.

;;;","11/Mar/11 13:43;slebresne;Indeed ringIterator() shouldn't fail when the argument token list is empty.

Attaching patch to fix this with a unit test.

The second patch attached adds a more high level unit test that tests the problem at the level of NetworkTopologyStrategy (while the first patch has a ringIterator test). It also include a tiny optimisation for NetworkTopologyStrategy that skip unnecessary steps when the number of replicas in the DC is 0. This optimisation would hide the actual problem so that's why it's attached separately.;;;","11/Mar/11 14:18;jbellis;would it be simpler to say something like ""if ring.isEmpty() return Iterators.emptyIterator()""?;;;","11/Mar/11 14:54;slebresne;You are right, it's a bit cleaner. Attaching new version of first patch using Iterators functions.;;;","11/Mar/11 18:18;jbellis;committed w/o the NTS optimization.

(open to being convinced otherwise but my reasoning is that performance is not critical--since the result of calculateNE is cached by ARS.getNE--so we should not add special cases there that can hide bugs.);;;","11/Mar/11 23:07;hudson;Integrated in Cassandra-0.7 #375 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/375/])
    allow zero replicas in a NTSdatacenter
patch by slebresne; reviewed by jbellis for CASSANDRA-1924
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
exceptions after cleanup,CASSANDRA-1922,12494314,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,brandon.williams,brandon.williams,30/Dec/10 17:29,16/Apr/19 09:33,14/Jul/23 05:51,30/Dec/10 18:20,0.7.0,,,,0,,,,,,"It looks like CASSANDRA-1916 may have introduced a regression.  After running a cleanup, I get the following exception when trying to read:

{noformat}

ERROR 17:25:23,574 Fatal exception in thread Thread[ReadStage:99,5,main]
java.lang.AssertionError: skipping negative bytes is illegal: -1393754107
        at org.apache.cassandra.io.util.MappedFileDataInput.skipBytes(MappedFileDataInput.java:96)
        at org.apache.cassandra.io.sstable.IndexHelper.skipBloomFilter(IndexHelper.java:50)
        at org.apache.cassandra.db.columniterator.SimpleSliceReader.<init>(SimpleSliceReader.java:56)
        at org.apache.cassandra.db.columniterator.SSTableSliceIterator.createReader(SSTableSliceIterator.java:91)
        at org.apache.cassandra.db.columniterator.SSTableSliceIterator.<init>(SSTableSliceIterator.java:67)
        at org.apache.cassandra.db.filter.SliceQueryFilter.getSSTableColumnIterator(SliceQueryFilter.java:68)
        at org.apache.cassandra.db.filter.QueryFilter.getSSTableColumnIterator(QueryFilter.java:80)
        at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1215)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1107)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1077)
        at org.apache.cassandra.db.Table.getRow(Table.java:384)
        at org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:63)
        at org.apache.cassandra.db.ReadVerbHandler.doVerb(ReadVerbHandler.java:68)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:63)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Dec/10 18:00;jbellis;1922.txt;https://issues.apache.org/jira/secure/attachment/12467174/1922.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20371,,,Thu Dec 30 19:37:30 UTC 2010,,,,,,,,,,"0|i0g88f:",92764,,,,,Normal,,,,,,,,,,,,,,,,,"30/Dec/10 18:00;jbellis;Patch includes test to reproduce the problem and a (one-line) fix in CompactionManager.  Also includes comments on AbstractCompactionIterator as to what each method is supposed to include, to make it easier to avoid this mistake in the future.;;;","30/Dec/10 18:20;brandon.williams;Committed with unused import removed.;;;","30/Dec/10 19:37;hudson;Integrated in Cassandra-0.7 #137 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/137/])
    Fix CompactionManager regression from CASSANDRA-1916 and add a better
test and more docs to prevent in the future.
Patch by jbellis, reviewed by brandonwilliams for CASSANDRA-1922
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Insert performance regression,CASSANDRA-1917,12494259,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,jbellis,brandon.williams,brandon.williams,29/Dec/10 17:52,16/Apr/19 09:33,14/Jul/23 05:51,29/Dec/10 19:24,0.7.0,,,,0,,,,,,"We caused a performance regression in CASSANDRA-1780, costing us about 33% on inserts.",,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Dec/10 17:58;jbellis;1917.txt;https://issues.apache.org/jira/secure/attachment/12467126/1917.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20369,,,Wed Dec 29 19:24:11 UTC 2010,,,,,,,,,,"0|i0g87j:",92760,,brandon.williams,,brandon.williams,Critical,,,,,,,,,,,,,,,,,"29/Dec/10 17:58;jbellis;revert the default to without-flush mode;;;","29/Dec/10 19:24;jbellis;reverted CASSANDRA-1780 entirely instead.  Created CASSANDRA-1919 to provide a ""principle of least surprise"" solution for people restarting the server w/ periodic flushing configured.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cleanup needs to remove secondary index entries,CASSANDRA-1916,12494258,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,29/Dec/10 17:39,16/Apr/19 09:33,14/Jul/23 05:51,30/Dec/10 16:35,0.7.1,,Feature/2i Index,,0,,,,,,,,urandom,,,,,,,,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,,"30/Dec/10 14:00;tjake;0003-add-unit-test.txt;https://issues.apache.org/jira/secure/attachment/12467167/0003-add-unit-test.txt","29/Dec/10 17:39;jbellis;ASF.LICENSE.NOT.GRANTED--0001-merge-doCleanup-doAntiCompaction.txt;https://issues.apache.org/jira/secure/attachment/12467123/ASF.LICENSE.NOT.GRANTED--0001-merge-doCleanup-doAntiCompaction.txt","29/Dec/10 17:39;jbellis;ASF.LICENSE.NOT.GRANTED--0002-replace-AntiCompactionIterator-w-per-sstable-iteration.txt;https://issues.apache.org/jira/secure/attachment/12467124/ASF.LICENSE.NOT.GRANTED--0002-replace-AntiCompactionIterator-w-per-sstable-iteration.txt",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19355,,,Thu Dec 30 19:37:30 UTC 2010,,,,,,,,,,"0|i0g87b:",92759,,tjake,,tjake,Normal,,,,,,,,,,,,,,,,,"29/Dec/10 17:40;jbellis;patches are against trunk;;;","29/Dec/10 18:33;tjake;Looks like the secondary index entried aren't actually removed, only tombstoned.  Are you planning them to be removed on next minor compaction?

;;;","29/Dec/10 19:08;jbellis;bq. Looks like the secondary index entried aren't actually removed, only tombstoned

right.  sstables being immutable, and all that.

bq. Are you planning them to be removed on next minor compaction

yes.;;;","30/Dec/10 14:00;tjake;Added test case for this change. It verifies the tombstones are added on cleanup;;;","30/Dec/10 14:11;jbellis;simplified getRing in test to ""return StorageService.instance.getTokenMetadata();"" :)

committed w/ addition of post-cleanup flush of 2ary indexes;;;","30/Dec/10 19:37;hudson;Integrated in Cassandra-0.7 #137 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/137/])
    Fix CompactionManager regression from CASSANDRA-1916 and add a better
test and more docs to prevent in the future.
Patch by jbellis, reviewed by brandonwilliams for CASSANDRA-1922
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stress.java doesn't actually read its data,CASSANDRA-1915,12494256,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,xedin,brandon.williams,brandon.williams,29/Dec/10 16:58,16/Apr/19 09:33,14/Jul/23 05:51,29/Dec/10 19:38,0.7.1,,,,0,,,,,,"stress.java doesn't actually read back the keys it inserts, but also reports no errors.  This is evident on larger (1M) runs where the read request rate is equal to what the bloom filter can do.  Stress.py also cannot find the rows that stress.java inserts.",,,,,,,,,,,14400,14400,,0%,14400,14400,,,,,,,,,,,,,,"29/Dec/10 19:27;xedin;CASSANDRA-1915.patch;https://issues.apache.org/jira/secure/attachment/12467131/CASSANDRA-1915.patch",,,,,,,,,,,,,,1.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20368,,,Wed Dec 29 20:21:56 UTC 2010,,,,,,,,,,"0|i0g873:",92758,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"29/Dec/10 19:38;brandon.williams;Committed, thanks!;;;","29/Dec/10 20:21;hudson;Integrated in Cassandra-0.7 #133 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/133/])
    Fix for stress.java using wrong key names and not detecting empty keys.
Patch by Pavel Yaskevich, reviewed by brandonwilliams for CASSANDRA-1915
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
validation of time uuid is incorrect,CASSANDRA-1910,12494185,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,dave111,dave111,28/Dec/10 18:18,16/Apr/19 09:33,14/Jul/23 05:51,29/Dec/10 19:45,0.6.9,0.7.0,,,0,,,,,,"It appears _TimeUUIDType_ (as of 12/9) is checking the wrong bits when validating a time UUID as version 1.

Per the comment and rfc4122, ""_version is bits 4-7 of byte 6_"", however validate() is actually checking the least significant bits:

> _if ((slice.get() & 0x0f) != 1)_

Sample java/hector code:

{code}
// displays ""version 1"" but validation fails
java.util.UUID uuid1 = java.util.UUID.fromString(""00000000-0000-1000-0000-000000000000"");
System.out.println(uuid1 + "" "" + uuid1.version());
TimeUUIDType.instance.validate(UUIDSerializer.get().toByteBuffer(uuid1));

// displays ""version 2"" but validation succeeds
java.util.UUID uuid2 = java.util.UUID.fromString(""00000000-0000-2100-0000-000000000000"");
System.out.println(uuid2 + "" "" + uuid2.version());
TimeUUIDType.instance.validate(UUIDSerializer.get().toByteBuffer(uuid2));
{code}

The issue can be seen with any UUID where the timestamp doesn't start with 1:

b54adc00-67f9-10d9-9669-0800200c9a66, (timestamp year 1776) version 1 fails
b54adc00-67f9-12d9-9669-0800200c9a66, (timestamp year 2233) version 1 fails
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Dec/10 18:58;gdusbabek;1910-0.6.txt;https://issues.apache.org/jira/secure/attachment/12467129/1910-0.6.txt","29/Dec/10 18:40;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-examine-the-right-nibble-when-validating-TimeUUIDs.txt;https://issues.apache.org/jira/secure/attachment/12467127/ASF.LICENSE.NOT.GRANTED--v1-0001-examine-the-right-nibble-when-validating-TimeUUIDs.txt",,,,,,,,,,,,,2.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20367,,,Wed Dec 29 19:45:09 UTC 2010,,,,,,,,,,"0|i0g85z:",92753,,,,,Low,,,,,,,,,,,,,,,,,"29/Dec/10 17:30;jbellis;probably related: I have seen this error in the test suite --

{noformat}
    [junit] Testcase: testInvalidTimeUUID(org.apache.cassandra.db.marshal.TypeValidationTest):	FAILED
    [junit] Expected exception: org.apache.cassandra.db.marshal.MarshalException
    [junit] junit.framework.AssertionFailedError: Expected exception: org.apache.cassandra.db.marshal.MarshalException
{noformat};;;","29/Dec/10 18:44;gdusbabek;patch is for 0.7+trunk.  0.6 will be different.;;;","29/Dec/10 18:58;gdusbabek;Implements proper TimeUUID validation in 0.6.;;;","29/Dec/10 19:04;jbellis;+1

let's commit to 0.6, 0.7.0, 0.7, and trunk;;;","29/Dec/10 19:32;hudson;Integrated in Cassandra-0.6 #41 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/41/])
    examine the right nibble when validating TimeUUIDs. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1910
;;;","29/Dec/10 19:45;gdusbabek;committed everywhere.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AbstractCassandraDaemon blows up when log4j config is specified using a physical file.,CASSANDRA-1907,12494138,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,gdusbabek,gdusbabek,27/Dec/10 20:56,16/Apr/19 09:33,14/Jul/23 05:51,27/Dec/10 22:19,0.7.1,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Dec/10 21:06;gdusbabek;0001-1907.patch;https://issues.apache.org/jira/secure/attachment/12467015/0001-1907.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19357,,,Mon Dec 27 22:34:38 UTC 2010,,,,,,,,,,"0|i0g85b:",92750,,tjake,,tjake,Low,,,,,,,,,,,,,,,,,"27/Dec/10 21:31;tjake;+1;;;","27/Dec/10 22:19;gdusbabek;committed.;;;","27/Dec/10 22:34;hudson;Integrated in Cassandra-0.7 #120 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/120/])
    log4j configuration wasn't handling configurations specified by URL. patch by Gary Dusbabek, reviewed by Jake Luciani. CASSANDRA-1907
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
count timeouts towards dynamicsnitch latencies,CASSANDRA-1905,12494126,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,27/Dec/10 15:54,16/Apr/19 09:33,14/Jul/23 05:51,28/Dec/10 03:36,0.6.9,0.7.0,,,0,,,,,,"receiveTiming is only called by ResponseVerbHandler; we need to add timing information for timed-out requests as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Dec/10 21:26;jbellis;1905.txt;https://issues.apache.org/jira/secure/attachment/12467016/1905.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20365,,,Tue Dec 28 15:00:40 UTC 2010,,,,,,,,,,"0|i0g84v:",92748,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"27/Dec/10 17:02;hudson;Integrated in Cassandra-0.6 #34 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/34/])
    convert ConsistencyChecker to use an executor as in 0.7 to ease merging of CASSANDRA-1905
patch by jbellis
;;;","27/Dec/10 21:26;jbellis;The idea is simply, ""when a message expires from our Map without a response, count it at the maximum latency.""  ExpiringMap is thus extended with an optional postExpireHook Function.

In MessagingService we add a ""targets"" multimap (since a message can be sent to multiple recipients), and update that with the destinations for any message with a callback.  ResponseVerbHandler removes each destination from ""targets"" when it gets a reply.  We also combine the former ""callbackMap_"" and ""taskCompletionMap_"" into a single ""callbacks"" object to avoid redundancy.  IMessageCallback is introduced to mean ""IASyncCallback or IAsyncResult.""

Also, for consistency, removing objects from ""callbacks"" is defined to be the responsibility of the IMessageCallback, so I've moved that from the AsyncResult section into AR, rather than RVH.  It would be nice to do it in RVH but there is not enough information there, in the case of quorum reads, to know when it's safe to do the remove (RVH is per-message based, and quorum reads by definition span multiple messages).;;;","27/Dec/10 23:34;brandon.williams;+1;;;","28/Dec/10 15:00;hudson;Integrated in Cassandra-0.6 #38 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/38/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Crash during startup: SSTable doesn't handle corrupt (empty) tmp files,CASSANDRA-1904,12494118,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,tcn,tcn,27/Dec/10 11:01,16/Apr/19 09:33,14/Jul/23 05:51,30/Dec/10 13:57,0.7.0,,,,0,,,,,,"Applies to 0.7rc3 as well, but not yet selectable in Jira.

cassandra stumbles upons empty Data files and crashes during startup rather than ignoring these files:

java.lang.ArithmeticException: / by zero
	at org.apache.cassandra.io.sstable.SSTable.estimateRowsFromIndex(SSTable.java:233)
	at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:284)
	at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:200)
	at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:225)
	at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:448)
	at org.apache.cassandra.db.ColumnFamilyStore.addIndex(ColumnFamilyStore.java:305)
	at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:246)
	at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:448)
	at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:436)
	at org.apache.cassandra.db.Table.initCf(Table.java:360)
	at org.apache.cassandra.db.Table.<init>(Table.java:290)
	at org.apache.cassandra.db.Table.open(Table.java:107)
	at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:138)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:55)
	at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:216)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:134)
Exception encountered during startup.
java.lang.ArithmeticException: / by zero
	at org.apache.cassandra.io.sstable.SSTable.estimateRowsFromIndex(SSTable.java:233)
	at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:284)
	at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:200)
	at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:225)
	at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:448)
	at org.apache.cassandra.db.ColumnFamilyStore.addIndex(ColumnFamilyStore.java:305)
	at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:246)
	at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:448)
	at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:436)
	at org.apache.cassandra.db.Table.initCf(Table.java:360)
	at org.apache.cassandra.db.Table.<init>(Table.java:290)
	at org.apache.cassandra.db.Table.open(Table.java:107)
	at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:138)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:55)
	at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:216)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:134)

The empty Data/Index tmp files were in my case created and left over when I attempted to create a secondary index at runtime which crashed the JVM due to OOM.

SSTable handles IOExceptions so it should be an easy fix: in SSTable.estimateRowsFromIndex() just check for ifile.length() ==ifile.getFilePointer()==keys==0 and throw an IOException.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Dec/10 23:26;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-CFS.scrubDataDirectories-to-include-index-files.txt;https://issues.apache.org/jira/secure/attachment/12467142/ASF.LICENSE.NOT.GRANTED--v1-0001-CFS.scrubDataDirectories-to-include-index-files.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20364,,,Thu Dec 30 13:57:42 UTC 2010,,,,,,,,,,"0|i0g84n:",92747,,,,,Normal,,,,,,,,,,,,,,,,,"29/Dec/10 21:25;gdusbabek;I get a different error, which happens before the error in Timo's stack trace.  I suspect his files weren't really zero-length, but the BRAF just reported them that way.  Either way: CFS.scrubDataDirectories() should take secondary indexes into account.

My forced error:

 INFO [main] SSTableReader.java@154 14:43:44,146 Opening /Users/gary.dusbabek/cass-configs/trunk/data_1/data/Keyspace1/Indexed1.birthdate_idx-f-1
DEBUG [main] SSTableReader.java@164 14:43:44,146 Load statistics for /Users/gary.dusbabek/cass-configs/trunk/data_1/data/Keyspace1/Indexed1.birthdate_idx-f-1
ERROR [main] ColumnFamilyStore.java@234 14:43:44,147 Corrupt sstable /Users/gary.dusbabek/cass-configs/trunk/data_1/data/Keyspace1/Indexed1.birthdate_idx-f-1=[Filter.db, Index.db, Data.db, Statistics.db]; skipped
java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:375)
	at org.apache.cassandra.utils.EstimatedHistogram$EstimatedHistogramSerializer.deserialize(EstimatedHistogram.java:179)
	at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:166)
	at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:225)
	at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:488)
	at org.apache.cassandra.db.ColumnFamilyStore.addIndex(ColumnFamilyStore.java:345)
	at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:246)
	at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:488)
	at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:476)
	at org.apache.cassandra.db.Table.initCf(Table.java:360)
	at org.apache.cassandra.db.Table.<init>(Table.java:290)
	at org.apache.cassandra.db.Table.open(Table.java:107)
	at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:162)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:54)
	at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:240)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:133)
DEBUG [main] SSTableTracker.java@179 14:43:44,148 key cache capacity for Indexed1.birthdate_idx is 200000
DEBUG [main] SSTableTracker.java@190 14:43:44,149 row cache capacity for Indexed1.birthdate_idx is 0;;;","29/Dec/10 22:11;tcn;What is BRAF? Yes, they were zero-length, at least according to ls and eclipse' debugger and I even deleted the files and recreated equally named, empty files manually :) 

IMHO code like

  int foo = 0;

  while(whatever) { whatever }

  bar / foo;

is always broken. A simple additional if-throw-IOException won't hurt and will help to grasp things faster.;;;","29/Dec/10 22:55;gdusbabek;I reproduced the original error by removing the statistics db in my database.  I still think the right approach is to make sure that CFS.scrubDataDirectories() includes index CFs.  

FWIW empty files will cause problems all over the place, not just at that particular spot.  The approach that has worked so far is to 'scrub' the directories of undesired files at startup rather than address all the places in the code where we've assumed the files in the directories are healthy and supposed to be there.;;;","29/Dec/10 23:36;jbellis;bq. I still think the right approach is to make sure that CFS.scrubDataDirectories() includes index CFs. 

+1, recovering from random files being missing isn't something we want to try to handle now.;;;","29/Dec/10 23:40;jbellis;also +1 to the patch;;;","30/Dec/10 13:57;gdusbabek;committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NullPointerException from o.a.c.db.ReplicateOnWriteTask,CASSANDRA-1903,12494050,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,kelvin,urandom,urandom,25/Dec/10 00:27,16/Apr/19 09:33,14/Jul/23 05:51,27/Dec/10 23:25,0.8 beta 1,,,,0,,,,,,"I'm seeing a whole lot of these when writing to a node.
 
{noformat}
java.lang.NullPointerException
	at org.apache.cassandra.db.ReplicateOnWriteTask.run(ReplicateOnWriteTask.java:97)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)
{noformat}

I don't think it will be difficult to reproduce, but the script I'm using is attached.

I bisected the source tree and and http://svn.apache.org/viewvc?view=rev&revision=1052356 seems to the culprit (a merge from 0.7).  Maybe CASSANDRA-1530?",,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Dec/10 23:23;gdusbabek;1903.diff;https://issues.apache.org/jira/secure/attachment/12467020/1903.diff","25/Dec/10 00:27;urandom;thrift-test.py;https://issues.apache.org/jira/secure/attachment/12466952/thrift-test.py",,,,,,,,,,,,,2.0,kelvin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20363,,,Tue Dec 28 01:10:01 UTC 2010,,,,,,,,,,"0|i0g84f:",92746,,,,,Normal,,,,,,,,,,,,,,,,,"27/Dec/10 22:24;urandom;Upon further examination...

The null value here is row.cf, it's null because the read came up empty, so this looks like a race to me (the read is beating the write).  But... the bigger question is, why have we added a read to the write path? This seems very wrong to me.

Also, what does ReplicateOnWriteTask do that the existing replication doesn't? How come we're doing both?  This all seems to have changed as part of the counters implementation, so it would be great if someone involved with that could sound off on this.;;;","27/Dec/10 23:12;kelvin;R-O-W is optional.

The goal is to provide faster convergence for CL.ONE writes.;;;","27/Dec/10 23:25;gdusbabek;committed.;;;","27/Dec/10 23:48;urandom;So the NullPointerExceptions are normal?;;;","28/Dec/10 01:10;hudson;Integrated in Cassandra #642 (See [https://hudson.apache.org/hudson/job/Cassandra/642/])
    set DEFAULT_REPLICATE_ON_WRITE to false. patch by gdusbabek, reviewed by eevans. CASSANDRA-1903
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
getRestrictedRanges bug where node owns minimum token,CASSANDRA-1901,12494015,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,jbellis,jbellis,23/Dec/10 23:44,16/Apr/19 09:33,14/Jul/23 05:51,30/Dec/10 03:38,0.6.9,0.7.0,,,0,,,,,,"From the ML, there are two RF=1 nodes, 0 for the local node (17.224.36.17) and 85070591730234615865843651857942052864 for the remote node (17.224.109.80).  Debug log shows

{code}
DEBUG [pool-1-thread-4] 2010-12-23 12:54:26,958 CassandraServer.java (line 479) range_slice
DEBUG [pool-1-thread-4] 2010-12-23 12:54:26,958 StorageProxy.java (line 412) RangeSliceCommand{keyspace='Harvest', column_family='TestCentroids', super_column=null, predicate=SlicePredicate(slice_range:SliceRange(start:80 01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 65 5F 73 6C 69 63 65 73 00 00 00 0C 0C 00 01 0B 00 03 00 00 00 0D 54 65 73 74 43 65 6E 74 72 6F 69 64 73 00 0C 00 02 0C 00 02 0B 00 01 00 00 00 00, finish:80 01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 65 5F 73 6C 69 63 65 73 00 00 00 0C 0C 00 01 0B 00 03 00 00 00 0D 54 65 73 74 43 65 6E 74 72 6F 69 64 73 00 0C 00 02 0C 00 02 0B 00 01 00 00 00 00 0B 00 02 00 00 00 00, reversed:false, count:1)), range=[0,0], max_keys=11}
DEBUG [pool-1-thread-4] 2010-12-23 12:54:26,958 StorageProxy.java (line 597) restricted ranges for query [0,0] are [[0,0]]
DEBUG [pool-1-thread-4] 2010-12-23 12:54:26,959 StorageProxy.java (line 423) === endpoint: belize1.apple.com/17.224.36.17 for range.right 0
{code}

Thus, node 85070591730234615865843651857942052864 is left out.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Dec/10 18:19;stuhood;0.6-0001-Switch-minimum-token-for-RP-to-1-for-midpoint-purposes.txt;https://issues.apache.org/jira/secure/attachment/12467053/0.6-0001-Switch-minimum-token-for-RP-to-1-for-midpoint-purposes.txt","28/Dec/10 07:48;stuhood;0001-Switch-minimum-token-for-RP-to-1-for-midpoint-purposes.txt;https://issues.apache.org/jira/secure/attachment/12467031/0001-Switch-minimum-token-for-RP-to-1-for-midpoint-purposes.txt",,,,,,,,,,,,,2.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20362,,,Thu Dec 30 03:38:32 UTC 2010,,,,,,,,,,"0|i0g83z:",92744,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"23/Dec/10 23:48;jbellis;I'm guessing this is related to the special cases on minimum tokens -- should we just disallow using that in a live node token?;;;","24/Dec/10 23:53;jbellis;Mike reports,

bq. it looks like the workaround of using an initial token of 1 works;;;","25/Dec/10 06:15;stuhood;The problem is that the minimum token plays double duty by being ""less than all possible tokens"", while also being a valid token for RP (not for OPP). Changing the minimum token for RP to -1 (which is impossible to generate any other way) might help minimize these bugs. I started playing around with this tonight, but need to adjust the midpoint calculation code a little bit. I'd like to avoid disallowing 0, so I'll try to attach a better solution before the end of the weekend.;;;","28/Dec/10 07:48;stuhood;Switches the minimum token for RP to -1. Fixes the case mentioned on the mailing list, but hasn't been subjected to the same scrutiny as the OPPs get in StorageProxyTest: the singletons make this excessively difficult.;;;","28/Dec/10 07:59;stuhood;Patch tested against trunk, but should apply cleanly to 0.6/0.7;;;","28/Dec/10 16:34;jbellis;I get

{noformat}
patching file src/java/org/apache/cassandra/dht/RandomPartitioner.java
...
Hunk #2 FAILED at 67.
{noformat}

against 0.6;;;","28/Dec/10 18:19;stuhood;Rebased for 0.6;;;","29/Dec/10 23:24;hudson;Integrated in Cassandra-0.6 #43 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/43/])
    change RandomPartitioner mintoken to -1 to avoid collision w/
tokens in the ring
patch by Stu Hood; reviewed by jbellis for CASSANDRA-1901
;;;","30/Dec/10 03:38;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failed to get columns from super column in cassandra-cli (0.7-rc2),CASSANDRA-1899,12494000,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,xedin,xedin,xedin,23/Dec/10 18:48,16/Apr/19 09:33,14/Jul/23 05:51,23/Dec/10 18:57,0.7.0,,Legacy/Tools,,0,,,,,,"I'm using cassandra 0.7.0-rc2. 

When I tried to get column contents in a super column of Super CF like below;
{code}
get myCF['key']['scName'];
{code}

the client reply: supercolumn parameter is not optional for super CF user
","The cluster was made in cassandra-0.7.0-beta1 and the script was

create column family myCF with column_type='Super' and comparator='UTF8Type' AND subcomparator='UTF8Type';",tcn,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Dec/10 18:49;xedin;super_columns_get.patch;https://issues.apache.org/jira/secure/attachment/12466908/super_columns_get.patch",,,,,,,,,,,,,,1.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20361,,,Wed Dec 29 16:38:24 UTC 2010,,,,,,,,,,"0|i0g83j:",92742,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"23/Dec/10 18:49;xedin;Tests added. work branch: trunk (latest commit 44f0214b1d0e0ab11ffa8d8df1055458e17e1e45);;;","23/Dec/10 18:57;jbellis;committed;;;","23/Dec/10 19:46;hudson;Integrated in Cassandra-0.7 #114 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/114/])
    fix CLI get recognition of supercolumns
patch by Pavel Yaskevich; reviewed by jbellis for CASSANDRA-1899
;;;","29/Dec/10 16:23;tcn;Just hit this one. Why 0.7.1 and not 0.7.0rc3 (rc4)?;;;","29/Dec/10 16:38;jbellis;We can't fix it in rc3 since rc3 is already released.

This isn't severe enough to justify an rc4.  If we do roll an rc4 for other reasons, it will be incorporated;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Loadbalance during gossip issues leaves cluster in bad state,CASSANDRA-1895,12493949,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,brandon.williams,stuhood,stuhood,23/Dec/10 07:31,16/Apr/19 09:33,14/Jul/23 05:51,16/Jan/11 23:54,0.7.1,,,,0,,,,,,Running loadbalance against a node in a 4 node cluster leaves gossip in a wonky state.,,,,,,,,,,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,,"03/Jan/11 22:39;brandon.williams;1895.txt;https://issues.apache.org/jira/secure/attachment/12467374/1895.txt","23/Dec/10 07:33;stuhood;logs.tgz;https://issues.apache.org/jira/secure/attachment/12466861/logs.tgz","23/Dec/10 07:33;stuhood;ring-views.txt;https://issues.apache.org/jira/secure/attachment/12466862/ring-views.txt",,,,,,,,,,,,3.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20360,,,Mon Jan 17 00:37:15 UTC 2011,,,,,,,,,,"0|i0g82n:",92738,,,,,Low,,,,,,,,,,,,,,,,,"23/Dec/10 07:33;stuhood;Attaching logs and {{nodetool ring}} output from after running loadbalance against 10.97.29.122.;;;","23/Dec/10 15:31;jbellis;trunk, or 0.7 branch?;;;","23/Dec/10 17:56;nickmbailey;this looks very similar to CASSANDRA-1895;;;","23/Dec/10 18:04;nickmbailey;It also looks like CASSANDRA-1829 :);;;","23/Dec/10 18:24;stuhood;This run is from trunk. I'm traveling today, but I should be able to try it against 0.7 when I get settled this evening.;;;","23/Dec/10 19:59;brandon.williams;I'm unable to repro against 0.7.;;;","23/Dec/10 20:00;tjake;Based on the ring and .122 log it looks like you were missing fix for CASSANDRA-1829

If see this in the log: "" INFO [RMI TCP Connection(2)-10.97.29.122] 2010-12-22 01:33:47,328 StorageService.java (line 249) Bootstrap/move completed! Now serving reads.""

Then the local ring state would say Normal since finishBootstrap() calls setToken() which sets the ring state to normal. hmm.
;;;","23/Dec/10 20:03;tjake;In fact, based on the log message above I can see you didn't have the fix in palace since the line is now 250 after the fix for the above message:

http://svn.apache.org/viewvc/cassandra/trunk/src/java/org/apache/cassandra/service/StorageService.java?r1=1043262&r2=1044034;;;","25/Dec/10 06:34;stuhood;It looks like the patch you mentioned was only partially applied to trunk. The last chunk in the patch should have added {code}+        if(!bootstrapped)
+            setToken(token);{code}
...but didn't.;;;","25/Dec/10 06:39;nickmbailey;Stu,

That  if check was removed in a later commit. The current code will call setToken() no matter what. The only difference is if the node bootstrapped, setToken will be called twice but that shouldn't be a problem and I don't think that is causing the bug here.;;;","28/Dec/10 07:58;stuhood;I think the burden of proof is back on me now, so I'll try and reproduce this once I'm back in the office tomorrow.;;;","29/Dec/10 02:24;stuhood;After a rebase and changes to the EC2 images I was using, I'm no longer able to reproduce this against either 0.7 or trunk.

Nick noticed some gossip related problems in the attached logs, so I'm going to chalk this up to _either_ a bad rebase, or problems related to bootstrapping during gossip problems. Nick: could you chime in with details, and whether you think those gossip issues might be worth pursuing?;;;","29/Dec/10 19:34;nickmbailey;I just noticed that the logs on one of the machines contains a ""Removing token"" line followed by a new node line 3 times. Since Stu only called loadbalance once, I believe this is likely due to gossip issues, where a node completes the decom then gets gossip about the same node leaving and readds it.

I've also talked to one other person in irc who had a similar problem.  Every time a decommission happened, the node would get removed but added 30 seconds later (gossip timeout after removal) due to some other node in the cluster.  ;;;","29/Dec/10 21:33;gdusbabek;We've had this problem before.  I think it was CASSANDRA-1467, but not sure.;;;","30/Dec/10 20:40;stuhood;Is this the sort of problem where having a gossip generation might help? The node that readded an older node should have ignored the outdated gossip.;;;","30/Dec/10 21:55;nickmbailey;We have generations for node states. The problem is after 30 seconds we assume gossip has propagated and forget about nodes that have been removed.  Then when we see the gossip again it looks like a brand new node.;;;","30/Dec/10 22:10;jbellis;sounds like the inverse of CASSANDRA-1730;;;","03/Jan/11 22:39;brandon.williams;Revival of my first try at CASSANDRA-1730: change the quarantine interval for justRemovedEndpoints to RING_DELAY * 2.;;;","03/Jan/11 23:03;nickmbailey;Would it be a good idea to make this configurable? I've seen nodes that have failed to process a REMOVED state for up to 45 minutes, although that was one extreme case. It might be useful in a case like that to temporarily configure this very high in order to process ring operations when the cluster is having issues otherwise.;;;","03/Jan/11 23:08;brandon.williams;I'm guessing in the 45 minute case, what was happening was the state was being re-gossiped just outside of RING_DELAY many times, but finally it propagated fast enough.  I think the next step, if this isn't sufficient, is to expose RING_DELAY as a tunable.;;;","15/Jan/11 05:11;jbellis;would it make more sense to change FatClientTimeout to QUARANTINE_DELAY / 2?;;;","16/Jan/11 18:47;brandon.williams;It wouldn't hurt, though we established in CASSANDRA-1730 the timeout was rather arbitrary.  It could help in the case of a 'flapping' bootstrap, though I tend to think there will be problems there in any case.;;;","16/Jan/11 23:10;jbellis;let's commit w/ that change then;;;","16/Jan/11 23:54;brandon.williams;Committed w/fatclient timeout change.;;;","17/Jan/11 00:37;hudson;Integrated in Cassandra-0.7 #165 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/165/])
    Set quarantine delay to RING_DELAY * 2
Patch by brandonwilliams, reviewed by jbellis for CASSANDRA-1895
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Timed out reads not counted in metrics,CASSANDRA-1893,12493818,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,stuhood,stuhood,stuhood,21/Dec/10 23:07,16/Apr/19 09:33,14/Jul/23 05:51,22/Dec/10 18:47,0.7.0,,,,0,,,,,,Reads that experience timeouts (or other exceptions) are not tracked in StorageProxy latencies.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Dec/10 23:09;stuhood;0001-Move-metrics-into-finally-blocks.txt;https://issues.apache.org/jira/secure/attachment/12466775/0001-Move-metrics-into-finally-blocks.txt","21/Dec/10 23:09;stuhood;0002-Fully-expose-read-write-range-histograms-in-StoragePro.txt;https://issues.apache.org/jira/secure/attachment/12466776/0002-Fully-expose-read-write-range-histograms-in-StoragePro.txt",,,,,,,,,,,,,2.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20358,,,Wed Dec 22 19:05:02 UTC 2010,,,,,,,,,,"0|i0g827:",92736,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"21/Dec/10 23:09;stuhood;Patches to record all SP calls, and expos the histograms that we were recording anyway.;;;","22/Dec/10 18:47;jbellis;committed, thanks!;;;","22/Dec/10 19:05;hudson;Integrated in Cassandra-0.7 #109 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/109/])
    count timeouts in storageproxy latencies, and include latency
histograms in StorageProxyMBean
patch by Stu Hood; reviewed by jbellis for CASSANDRA-1893
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
heisenbug in SSTableExportTest,CASSANDRA-1892,12493807,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,tjake,jbellis,jbellis,21/Dec/10 21:21,16/Apr/19 09:33,14/Jul/23 05:51,24/Dec/10 18:23,0.7.0,,,,0,test,,,,,"{code}
    [junit] java.lang.IndexOutOfBoundsException: Index: 4, Size: 4
    [junit] 	at java.util.ArrayList.RangeCheck(ArrayList.java:547)
    [junit] 	at java.util.ArrayList.get(ArrayList.java:322)
    [junit] 	at org.apache.cassandra.tools.SSTableExportTest.testExportSimpleCf(SSTableExportTest.java:130)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Dec/10 18:08;tjake;1892.txt;https://issues.apache.org/jira/secure/attachment/12466946/1892.txt",,,,,,,,,,,,,,1.0,tjake,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20357,,,Mon Dec 27 17:45:26 UTC 2010,,,,,,,,,,"0|i0g81z:",92735,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"21/Dec/10 21:22;jbellis;most of the time this passes.;;;","24/Dec/10 18:08;tjake;The test checks for an expiring column but the localDeleteTime is specified as now.  so if the test takes longer than a second to run it fails.  I verified this with a Thread.sleep call. The patch adds an extra 42 seconds to the expiring column.;;;","24/Dec/10 18:23;jbellis;committed, thanks!;;;","27/Dec/10 17:45;hudson;Integrated in Cassandra-0.7 #118 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/118/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in get_slice quorum read,CASSANDRA-1883,12493608,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,kmueller,kmueller,18/Dec/10 21:16,16/Apr/19 09:33,14/Jul/23 05:51,21/Dec/10 21:37,0.6.9,0.7.0 rc 3,,,0,,,,,,"Getting this NPE as of the 2010-12-17 0.7 trunk.  Some data may be corrupt somewhere on a node.  It could be a null key somewhere.

ERROR [pool-1-thread-28] 2010-12-18 12:53:20,411 Cassandra.java (line 2707) Internal error processing get_slice
java.lang.NullPointerException
        at org.apache.cassandra.service.DigestMismatchException.<init>(DigestMismatchException.java:30)
        at org.apache.cassandra.service.ReadResponseResolver.resolve(ReadResponseResolver.java:92)
        at org.apache.cassandra.service.ReadResponseResolver.resolve(ReadResponseResolver.java:43)
        at org.apache.cassandra.service.QuorumResponseHandler.get(QuorumResponseHandler.java:91)
        at org.apache.cassandra.service.StorageProxy.strongRead(StorageProxy.java:362)
        at org.apache.cassandra.service.StorageProxy.readProtocol(StorageProxy.java:229)
        at org.apache.cassandra.thrift.CassandraServer.readColumnFamily(CassandraServer.java:128)
        at org.apache.cassandra.thrift.CassandraServer.getSlice(CassandraServer.java:225)
        at org.apache.cassandra.thrift.CassandraServer.multigetSliceInternal(CassandraServer.java:301)
        at org.apache.cassandra.thrift.CassandraServer.get_slice(CassandraServer.java:263)
        at org.apache.cassandra.thrift.Cassandra$Processor$get_slice.process(Cassandra.java:2699)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:2555)
        at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)",Linux Fedora 12 x86_64,mdennis,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Dec/10 05:23;jbellis;1883.txt;https://issues.apache.org/jira/secure/attachment/12466603/1883.txt","19/Dec/10 02:09;kmueller;digestmismatch-debug.txt;https://issues.apache.org/jira/secure/attachment/12466556/digestmismatch-debug.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19360,,,Tue Dec 21 21:37:43 UTC 2010,,,,,,,,,,"0|i0g7zr:",92725,,tjake,,tjake,Low,,,,,,,,,,,,,,,,,"18/Dec/10 21:26;kmueller;Additional information: one of the SSD raid0s went bad recently.  This may have produced weird data for one cassandra node.   ;;;","19/Dec/10 02:09;kmueller;this is a debug output from a node with this NPE happening around the same time.  If you need more from the log, I have the rest of it available;;;","19/Dec/10 03:50;jbellis;Does this reproduce whenever you query a certain key?;;;","20/Dec/10 03:54;brandon.williams;Note that there was data here inserted from RC2, and then CASSANDRA-1847 was encountered causing the upgrade to trunk, so this may just be fallout from previous corruption.;;;","20/Dec/10 05:23;jbellis;patch to fix NPE when two different digests arrive before the data read does;;;","20/Dec/10 05:59;mdennis;+1;;;","20/Dec/10 17:33;tjake;+1 this was a regression from CASSANDRA-1830;;;","21/Dec/10 21:37;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
backgrounding cli makes it crash,CASSANDRA-1875,12493522,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,xedin,jbellis,jbellis,17/Dec/10 15:32,16/Apr/19 09:33,14/Jul/23 05:51,22/Dec/10 18:31,0.7.0,,Legacy/Tools,,0,,,,,,"{code}
$ bin/cassandra-cli 
Welcome to cassandra CLI.

Type 'help;' or '?' for help. Type 'quit;' or 'exit;' to quit.
[default@unknown] 
[1]+  Stopped                 bin/cassandra-cli
$ fg
bin/cassandra-cli
Exception in thread ""main"" java.io.IOException: Interrupted system call
	at java.io.FileInputStream.read(Native Method)
	at jline.Terminal.readCharacter(Terminal.java:99)
	at jline.UnixTerminal.readVirtualKey(UnixTerminal.java:128)
	at jline.ConsoleReader.readVirtualKey(ConsoleReader.java:1453)
	at jline.ConsoleReader.readBinding(ConsoleReader.java:654)
	at jline.ConsoleReader.readLine(ConsoleReader.java:494)
	at jline.ConsoleReader.readLine(ConsoleReader.java:448)
	at org.apache.cassandra.cli.CliMain.main(CliMain.java:328)
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Dec/10 17:30;xedin;CASSANDRA-1875.patch;https://issues.apache.org/jira/secure/attachment/12466818/CASSANDRA-1875.patch",,,,,,,,,,,,,,1.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20354,,,Wed Dec 22 19:05:02 UTC 2010,,,,,,,,,,"0|i0g7xz:",92717,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"22/Dec/10 17:37;jbellis;Isn't this going to catch, say, EOF as well?;;;","22/Dec/10 17:43;xedin;EOFException is a subclass of the IOException like others (http://download.oracle.com/javase/6/docs/api/java/io/IOException.html).;;;","22/Dec/10 17:52;jbellis;Right, so I'm saying, isn't this potentially broken if you're piping input to the cli from a text file?;;;","22/Dec/10 18:06;xedin;No, this won't broke when piping (I'm doing that all the time) or reading from file. I have tried to use --file option and piping file before submitting this patch :);;;","22/Dec/10 18:31;jbellis;committed;;;","22/Dec/10 19:05;hudson;Integrated in Cassandra-0.7 #109 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/109/])
    fix cli crash after backgrounding
patch by Pavel Yaskevich; reviewed by jbellis for CASSANDRA-1875
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Read Repair behavior thwarts DynamicEndpointSnitch at CL.ONE,CASSANDRA-1873,12493477,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,17/Dec/10 00:23,16/Apr/19 09:33,14/Jul/23 05:51,21/Dec/10 21:23,0.6.9,0.7.0 rc 3,,,0,,,,,,"When doing a CL.ONE read, the coordinator node selects the data node from the list of replicas via snitch sortByProximity.  The data node (_not_ the coordinator) then sends digest requests to the remaining replicas, and compares their answers to its own (in ConsistencyChecker).

This means that, in a multi-datacenter situation, for any given range R with replicas X in dc1 and Y in dc2, the only node with latency information for Y will be X.  Since DES falls back to subsnitch (static) order when latency information is missing for any replica it is asked to sort, DES will be unable to direct requests to Y no matter how overwhelmed X becomes.

To fix this, we should move the digest-checking code into the coordinator node (probably starting with the 0.7 ConsistencyChecker, which represents a cleanup of the 0.6 one).",,brandon.williams,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Dec/10 17:58;jbellis;1873.txt;https://issues.apache.org/jira/secure/attachment/12466542/1873.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20353,,,Tue Dec 21 21:23:24 UTC 2010,,,,,,,,,,"0|i0g7xj:",92715,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"17/Dec/10 00:24;jbellis;Note: IMO it is okay to break RR temporarily when upgrading a cluster piecemeal -- that is, it's okay for RR to not happen; it's not okay to generate internal errors.;;;","18/Dec/10 17:58;jbellis;the only tricky part was getting handles to both a command object and the address of the data read efficiently.  ended up handling the former w/ a Map in StorageProxy.weakRead, and the latter by adding a field to AsyncResult.

RR vs local reads continues to be handled by weakReadCallable.  that part required relatively little change.;;;","18/Dec/10 17:58;jbellis;(patch is against 0.6);;;","21/Dec/10 18:37;brandon.williams;+1, no internal errors generated during a rolling restart.;;;","21/Dec/10 20:58;hudson;Integrated in Cassandra-0.6 #31 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/31/])
    manage read repair in coordinator instead of data source, to provide latency information to dynamic snitch
patch by jbellis; reviewed by brandonwilliams for CASSANDRA-1873
;;;","21/Dec/10 21:23;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Internal error from malformed remove with supercolumns,CASSANDRA-1866,12493352,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,thobbs,jbellis,jbellis,15/Dec/10 17:56,16/Apr/19 09:33,14/Jul/23 05:51,19/Dec/10 03:40,0.6.9,0.7.0 rc 3,Legacy/CQL,,0,,,,,,"From the ML: 

""I just call ""remove"" method where ColumnPath structure has ""column_family"" and ""column"" members set (""super_column"" not set).""
{code}
ERROR 17:57:46,924 Error in ThreadPoolExecutor
java.lang.RuntimeException: java.lang.ClassCastException: org.apache.cassandra.db.DeletedColumn cannot be cast to org.apache.cassandra.db.SuperColumn
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.ClassCastException: org.apache.cassandra.db.DeletedColumn cannot be cast to org.apache.cassandra.db.SuperColumn
        at org.apache.cassandra.db.SuperColumnSerializer.serialize(SuperColumn.java:318)
        at org.apache.cassandra.db.SuperColumnSerializer.serialize(SuperColumn.java:298)
        at org.apache.cassandra.db.ColumnFamilySerializer.serializeForSSTable(ColumnFamilySerializer.java:82)
        at org.apache.cassandra.db.ColumnFamilySerializer.serialize(ColumnFamilySerializer.java:68)
        at org.apache.cassandra.db.RowMutationSerializer.freezeTheMaps(RowMutation.java:344)
        at org.apache.cassandra.db.RowMutationSerializer.serialize(RowMutation.java:355)
        at org.apache.cassandra.db.RowMutationSerializer.serialize(RowMutation.java:333)
        at org.apache.cassandra.db.RowMutation.getSerializedBuffer(RowMutation.java:269)
        at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:194)
        at org.apache.cassandra.service.StorageProxy$1.runMayThrow(StorageProxy.java:197)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 3 more
ERROR 17:57:46,928 Fatal exception in thread Thread[MUTATION_STAGE:2,5,main]
java.lang.RuntimeException: java.lang.ClassCastException: org.apache.cassandra.db.DeletedColumn cannot be cast to org.apache.cassandra.db.SuperColumn
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.ClassCastException: org.apache.cassandra.db.DeletedColumn cannot be cast to org.apache.cassandra.db.SuperColumn
        at org.apache.cassandra.db.SuperColumnSerializer.serialize(SuperColumn.java:318)
        at org.apache.cassandra.db.SuperColumnSerializer.serialize(SuperColumn.java:298)
        at org.apache.cassandra.db.ColumnFamilySerializer.serializeForSSTable(ColumnFamilySerializer.java:82)
        at org.apache.cassandra.db.ColumnFamilySerializer.serialize(ColumnFamilySerializer.java:68)
        at org.apache.cassandra.db.RowMutationSerializer.freezeTheMaps(RowMutation.java:344)
        at org.apache.cassandra.db.RowMutationSerializer.serialize(RowMutation.java:355)
        at org.apache.cassandra.db.RowMutationSerializer.serialize(RowMutation.java:333)
        at org.apache.cassandra.db.RowMutation.getSerializedBuffer(RowMutation.java:269)
        at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:194)
        at org.apache.cassandra.service.StorageProxy$1.runMayThrow(StorageProxy.java:197)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 3 more
{code}

Fix: add system test to catch this & raise invalidrequestexception from ThriftValidation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Dec/10 18:40;thobbs;1866-0.6-test.txt;https://issues.apache.org/jira/secure/attachment/12466481/1866-0.6-test.txt","17/Dec/10 18:40;thobbs;1866-0.6.txt;https://issues.apache.org/jira/secure/attachment/12466480/1866-0.6.txt","16/Dec/10 22:22;thobbs;1866-0.7-test.txt;https://issues.apache.org/jira/secure/attachment/12466413/1866-0.7-test.txt","16/Dec/10 22:22;thobbs;1866-0.7.txt;https://issues.apache.org/jira/secure/attachment/12466412/1866-0.7.txt",,,,,,,,,,,4.0,thobbs,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20350,,,Sun Dec 19 04:03:35 UTC 2010,,,,,,,,,,"0|i0g7vz:",92708,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"16/Dec/10 22:24;thobbs;Patches also apply to trunk.;;;","17/Dec/10 15:34;jbellis;committed, thanks!;;;","17/Dec/10 15:35;jbellis;can you backport to 0.6 too?;;;","17/Dec/10 17:17;hudson;Integrated in Cassandra-0.7 #94 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/94/])
    ;;;","17/Dec/10 18:40;thobbs;0.6 versions attached.;;;","19/Dec/10 03:40;jbellis;committed, thanks;;;","19/Dec/10 04:03;hudson;Integrated in Cassandra-0.6 #28 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/28/])
    backport CASSANDRA-1866 from 0.7
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
StorageProxy throws an InvalidRequestException in readProtocol during bootstrap,CASSANDRA-1862,12493250,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,zznate,zznate,zznate,14/Dec/10 22:40,16/Apr/19 09:33,14/Jul/23 05:51,16/Dec/10 19:51,0.7.0 rc 3,,,,0,,,,,,"Though the error message provides details, IRE is supposed to signify poorly formed API requests. In the context of a client request, an UnavailableException is more appropriate. This would allow the client to take action like removing the node from its host list. ",,doubleday,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Dec/10 22:42;zznate;1862.txt;https://issues.apache.org/jira/secure/attachment/12466266/1862.txt","15/Dec/10 16:32;zznate;1862_0.6.txt;https://issues.apache.org/jira/secure/attachment/12466327/1862_0.6.txt",,,,,,,,,,,,,2.0,zznate,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20348,,,Wed Apr 20 15:40:47 UTC 2011,,,,,,,,,,"0|i0g7v3:",92704,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"14/Dec/10 22:42;zznate;Changes exception type to UnavailalbeException;;;","15/Dec/10 15:10;jbellis;committed, thanks!;;;","15/Dec/10 15:24;hudson;Integrated in Cassandra-0.7 #83 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/83/])
    change exceptionfor readrequests duringbootstrap from InvalidRequest to Unavailable
patch by Nate McCall; reviewed by jbellis for CASSANDRA-1862
;;;","15/Dec/10 16:32;zznate;Backport to 0.6;;;","15/Dec/10 16:50;jbellis;I'm a little leery of breaking 0.6 compatibility for something fairly minor.  Thoughts?;;;","15/Dec/10 17:38;zznate;I think this is extremely minor (the exception declaration of the method did not change) and brings us in line with the API as specified in cassandra.thrift: 

IRE:
""Invalid request could mean keyspace or column family does not exist, required parameters are missing, or a parameter is malformed...""

vs. UE:
""Not all the replicas required could be created and/or read."";;;","15/Dec/10 17:43;jbellis;bq. the exception declaration of the method did not change

i'll buy that.  committed;;;","15/Dec/10 18:14;hudson;Integrated in Cassandra-0.6 #24 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/24/])
    backport CASSANDRA-1862 from 0.7
;;;","20/Apr/11 15:40;doubleday;Don't know wether commenting a closed jira makes sense but I think that this made matters worse because now bootstrapping is not distinguishable anymore.
I thought that UnavailableException would signal that a read cannot be served due to CL. And a bootstrapping coordinator does not imply this right? ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"changing row cache save interval is reflected in 'describe keyspace' on node it was submitted to, but not nodes it was propagated to",CASSANDRA-1853,12493092,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,scode,scode,13/Dec/10 17:19,16/Apr/19 09:33,14/Jul/23 05:51,21/Dec/10 22:31,0.7.0 rc 3,,,,0,,,,,,"This is minor unless it indicates a bigger issue. On our test cluster (running cassandra 0.7 branch from today) we noticed that on submission of a new row cache save period, such as:

   update column family KeyValue with row_cache_save_period=3600;

The change would be reflected in describe_keyspace() (describe keyspace ... in cassandra-cli) on the node to which the schema migration was submitted, but not on other nodes in the cluster.

This in spite of the schema migration having propagated, judging by Schema['Last Migration'] being identical on all nodes. It is not n and of itself is not a big problem, but it does give the impression that the migrations have trouble propagating throughout the cluster even though they do.

(I had a quick (only) look in the code paths of migration application and did not find any obvious special casing of the node that happens to be local. Filing bug instead, hoping someone knows off hand what the reason is.)


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Dec/10 17:47;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-apply-CF-metadata-updates-on-replicas.txt;https://issues.apache.org/jira/secure/attachment/12466475/ASF.LICENSE.NOT.GRANTED--v1-0001-apply-CF-metadata-updates-on-replicas.txt","20/Dec/10 14:26;gdusbabek;ASF.LICENSE.NOT.GRANTED--v2-0001-apply-CF-metadata-updates-only-at-apply-time.txt;https://issues.apache.org/jira/secure/attachment/12466635/ASF.LICENSE.NOT.GRANTED--v2-0001-apply-CF-metadata-updates-only-at-apply-time.txt","21/Dec/10 12:15;gdusbabek;ASF.LICENSE.NOT.GRANTED--v3-0001-apply-CF-metadata-updates-only-at-apply-time.txt;https://issues.apache.org/jira/secure/attachment/12466704/ASF.LICENSE.NOT.GRANTED--v3-0001-apply-CF-metadata-updates-only-at-apply-time.txt","21/Dec/10 17:37;gdusbabek;ASF.LICENSE.NOT.GRANTED--v4-0001-apply-CF-metadata-updates-only-at-apply-time.txt;https://issues.apache.org/jira/secure/attachment/12466742/ASF.LICENSE.NOT.GRANTED--v4-0001-apply-CF-metadata-updates-only-at-apply-time.txt",,,,,,,,,,,4.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,682,,,Tue Dec 21 23:14:44 UTC 2010,,,,,,,,,,"0|i0g7tb:",92696,,,,,Low,,,,,,,,,,,,,,,,,"13/Dec/10 17:30;scode;Forgot to say that restarting the nodes in question (that do not show the updated value) causes it to catch up in describe keyspace output.;;;","17/Dec/10 19:49;jbellis;shouldn't applyModels be the One True Place to call CFMetaData.apply?  I'd like to r/m the apply calls in the constructor and in CassandraServer to avoid confusion.;;;","20/Dec/10 20:58;jbellis;- still have the apply in CassandraServer, is that redundant?
- iirc (and maybe i do not) the original explanation for this patch was that the other nodes don't go through the constructor that calls apply.  how else are they getting a UCF object?  intellij says the no-op constructor is unused.  i feel like i'm missing something important here.
- brace placement
;;;","21/Dec/10 12:15;gdusbabek;bq. still have the apply in CassandraServer
That apply() is on the Mutation, not a CFMetaData.

bq. how else are they getting a UCF object?
They deserialize the one they are sent by inflate()ing it.  It uses the no-arg constructor.

fixed the braces in v3.;;;","21/Dec/10 14:34;jbellis;bq. That apply() is on the Mutation, not a CFMetaData.

I'm talking about this one:
{code}
        CFMetaData oldCfm = DatabaseDescriptor.getCFMetaData(...);
...
            oldCfm.apply(cf_def);
{code}

bq. They deserialize the one they are sent by inflate()ing it. It uses the no-arg constructor.

inflate calls the many-arg constructor.  I removed the no-arg constructor to experiment and ""ant clean test"" passes.;;;","21/Dec/10 14:36;jbellis;bq. I'm talking about this one

... that's in the _avro_ CassandraServer, btw.;;;","21/Dec/10 17:37;gdusbabek;fixed the avro.CassandraServer problem.

bq. inflate calls the many-arg constructor. 
I think we're talking about different things. I referred to UCF.inflate().  Either way, CFM.apply() is only called on the active metadata in one place.

v4 attached.;;;","21/Dec/10 18:32;jbellis;I still don't see anything calling a no-arg UCF constructor, including UCF.subinflate (there is no UCF.inflate).

The reason I am stuck on this is, if everyone was calling the arg-full UCF constructor, then apply must have been getting called, which means our bug diagnosis is wrong.;;;","21/Dec/10 22:12;jbellis;{code}
 * Each class that extends Migration is required to implement a no arg constructor, which will be used to inflate the
 * object from it's serialized form.
{code}

reflection ftw.

+1 after fixing formatting of
{code}
        } catch (ConfigurationException ex) 
{code}

:);;;","21/Dec/10 22:31;gdusbabek;committed.;;;","21/Dec/10 22:43;hudson;Integrated in Cassandra-0.7 #106 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/106/])
    apply CF metadata updates only at apply time. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1853
;;;","21/Dec/10 23:14;hudson;Integrated in Cassandra #637 (See [https://hudson.apache.org/hudson/job/Cassandra/637/])
    apply CF metadata updates only at apply time. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1853
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
When restarting Cassandra I get this error: java.io.IOError: java.io.IOException: Failed to delete  ..data\system\LocationInfo-e-1-Data.db,CASSANDRA-1852,12493087,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,aadel,aadel,13/Dec/10 16:06,16/Apr/19 09:33,14/Jul/23 05:51,13/Dec/10 16:23,0.7.0 rc 2,,,,0,,,,,,"java.io.IOError: java.io.IOException: Failed to delete C:\Documents and Settings\Bureaublad\cassandra\data\system\LocationInfo-e-1-Data.db
	at org.apache.cassandra.db.ColumnFamilyStore.scrubDataDirectories(ColumnFamilyStore.java:483)
	at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:102)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:55)
	at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:216)
	at com.remainsoftware.gravity.cassandra.internal.GCassandra$1.run(GCassandra.java:21)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
	at java.lang.Thread.run(Thread.java:619)
Caused by: java.io.IOException: Failed to delete C:\Documents and Settings\Bureaublad\cassandra\data\system\LocationInfo-e-1-Data.db
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:54)
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:44)
	at org.apache.cassandra.db.ColumnFamilyStore.scrubDataDirectories(ColumnFamilyStore.java:479)
	... 7 more
ERROR 16:54:52,984 Exception encountered during startup.
java.io.IOError: java.io.IOException: Failed to delete C:\Documents and Settings\Bureaublad\cassandra\data\system\LocationInfo-e-1-Data.db
	at org.apache.cassandra.db.ColumnFamilyStore.scrubDataDirectories(ColumnFamilyStore.java:483)
	at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:102)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:55)
	at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:216)
	at com.remainsoftware.gravity.cassandra.internal.GCassandra$1.run(GCassandra.java:21)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
	at java.lang.Thread.run(Thread.java:619)
Caused by: java.io.IOException: Failed to delete C:\Documents and Settings\Bureaublad\cassandra\data\system\LocationInfo-e-1-Data.db
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:54)
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:44)
	at org.apache.cassandra.db.ColumnFamilyStore.scrubDataDirectories(ColumnFamilyStore.java:479)
	... 7 more",Windows,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20344,,,Mon Dec 13 16:23:10 UTC 2010,,,,,,,,,,"0|i0g7t3:",92695,,,,,Normal,,,,,,,,,,,,,,,,,"13/Dec/10 16:23;aadel;I just downloaded  the latest beta version: 0.7.0 rc 2.  It seems to be fixed. Thanks folks.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
When the ANTLR code generation fails the build continues and ignores the failure,CASSANDRA-1850,12493071,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,stephenc,stephenc,stephenc,13/Dec/10 13:49,16/Apr/19 09:33,14/Jul/23 05:51,13/Dec/10 19:48,0.7.0 rc 3,,,,0,,,,,,"When trying to tweak the build, I broke the ANTLR code generation tasks, but as I was not doing a full clean build the generated code was still present, so I missed the fact that the code generation was broken. It would be nice if the antlr tasks had failonerror=""true""",,,,,,,,,,,0,0,,0%,0,0,,,,,,,,,,,,,,"13/Dec/10 13:50;stephenc;fail-build-if-codegen-fails.patch;https://issues.apache.org/jira/secure/attachment/12466133/fail-build-if-codegen-fails.patch",,,,,,,,,,,,,,1.0,stephenc,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20343,,,Mon Dec 13 20:16:14 UTC 2010,,,,,,,,,,"0|i0g7sn:",92693,,urandom,,urandom,Low,,,,,,,,,,,,,,,,,"13/Dec/10 13:50;stephenc;patch to fix this issue;;;","13/Dec/10 19:48;urandom;committed; thanks.;;;","13/Dec/10 20:08;hudson;Integrated in Cassandra-0.7 #74 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/74/])
    failonerror for Cli antlr generation target

Patch by Stephen Connolly; reviewed by eevans for CASSANDRA-1850
;;;","13/Dec/10 20:16;hudson;Integrated in Cassandra #625 (See [https://hudson.apache.org/hudson/job/Cassandra/625/])
    failonerror for Cql and Cli antlr generation targets

Patch by Stephen Connolly; reviewed by eevans for CASSANDRA-1850
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ByteBufferUtil.clone shouldn't mutate the passed bytebuffer,CASSANDRA-1847,12493038,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,tjake,tjake,tjake,13/Dec/10 01:57,16/Apr/19 09:33,14/Jul/23 05:51,13/Dec/10 16:56,0.7.0 rc 3,,,,0,,,,,,"Currently ByteBufferUtil.clone uses .mark and .reset on the passed ByteBuffer.

This is fine when using thrift because no two ByteBuffer are being accessed at the same time, but this could be thread-unsafe if the same BB was passed concurrently.

Solandra is having problems with this (Solandra shares JVM with Cassandra).",,tcn,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Dec/10 02:13;jbellis;1847-v2.txt;https://issues.apache.org/jira/secure/attachment/12466113/1847-v2.txt","13/Dec/10 15:04;tjake;1847-v3.txt;https://issues.apache.org/jira/secure/attachment/12466137/1847-v3.txt","13/Dec/10 16:44;jbellis;1847-v4.txt;https://issues.apache.org/jira/secure/attachment/12466146/1847-v4.txt","13/Dec/10 02:00;tjake;1847_v1.txt;https://issues.apache.org/jira/secure/attachment/12466111/1847_v1.txt",,,,,,,,,,,4.0,tjake,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20342,,,Mon Dec 13 17:14:37 UTC 2010,,,,,,,,,,"0|i0g7rz:",92690,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"13/Dec/10 02:13;jbellis;v2 uses arraycopy instead of manual loop and enforces non-null;;;","13/Dec/10 08:59;slebresne;+1 on v2;;;","13/Dec/10 14:00;tjake;Right, thats faster but I was thinking ahead for CASSANDRA-1714 we'd need to use this for putting a row into the cache and .array() only works with HeapByteBuffers.  ;;;","13/Dec/10 14:49;jbellis;should we add an instanceof check for HeapByteBuffer then? seems like it's probably worth it. ;;;","13/Dec/10 15:04;tjake;v3 checks if buffer isDirect();;;","13/Dec/10 16:44;jbellis;BB.get(i) adds arrayoffset to the given index, so I think the loop in v3 is buggy.  v4 attached;;;","13/Dec/10 16:52;tjake;ok took ""absolute"" too literally then :)
+1 v4;;;","13/Dec/10 16:56;jbellis;committed;;;","13/Dec/10 17:14;hudson;Integrated in Cassandra-0.7 #72 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/72/])
    make ByteBufferUtil.clone thread-safe
patch by tjake and jbellis for CASSANDRA-1847
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indexes: CF MBeans for automatic indexes are never unregistered when they are deleted.,CASSANDRA-1843,12492991,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jhermes,jhermes,jhermes,10/Dec/10 23:33,16/Apr/19 09:33,14/Jul/23 05:51,11/Dec/10 00:06,0.7.0 rc 3,,,,0,,,,,,"Add, delete, and add the same index and you should get a stacktrace to this effect:
{noformat}
java.lang.RuntimeException: javax.management.InstanceAlreadyExistsException: org.apache.cassandra.db:type=IndexColumnFamilies,keyspace=Keyspace1,columnfamily=Standard1.616765
  at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:259)
  at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:447)
  at org.apache.cassandra.db.ColumnFamilyStore.addIndex(ColumnFamilyStore.java:304)
  at org.apache.cassandra.db.ColumnFamilyStore.reload(ColumnFamilyStore.java:193)
  at org.apache.cassandra.db.migration.UpdateColumnFamily.applyModels(UpdateColumnFamily.java:80)
  at org.apache.cassandra.db.migration.Migration.apply(Migration.java:171)
  at org.apache.cassandra.thrift.CassandraServer$2.call(CassandraServer.java:663)
  at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
  at java.util.concurrent.FutureTask.run(FutureTask.java:138)
  at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
  at java.lang.Thread.run(Thread.java:662)
Caused by: javax.management.InstanceAlreadyExistsException: org.apache.cassandra.db:type=IndexColumnFamilies,keyspace=Keyspace1,columnfamily=Standard1.616765
  at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:453)
  at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.internal_addObject(DefaultMBeanServerInterceptor.java:1484)
  at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:963)
  at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:917)
  at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:312)
  at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:482)
  at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:255)
  ... 11 more{noformat}
CFS.reload() manages index deletion, but never unregisters the MBeans it creates during initialization.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Dec/10 00:03;jhermes;1843.txt;https://issues.apache.org/jira/secure/attachment/12466029/1843.txt",,,,,,,,,,,,,,1.0,jhermes,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20341,,,Mon Dec 13 20:16:15 UTC 2010,,,,,,,,,,"0|i0g7r3:",92686,,,,,Low,,,,,,,,,,,,,,,,,"11/Dec/10 00:03;jhermes;Someone already wrote this method and just forgot to call it.
Whoops.;;;","11/Dec/10 00:06;brandon.williams;Committed.;;;","11/Dec/10 05:13;jbellis;updated CHANGES;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;","13/Dec/10 20:16;hudson;Integrated in Cassandra #625 (See [https://hudson.apache.org/hudson/job/Cassandra/625/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ColumnFamilyOutputFormat only writes the first column,CASSANDRA-1842,12492961,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jeromatron,brandon.williams,brandon.williams,10/Dec/10 17:24,16/Apr/19 09:33,14/Jul/23 05:51,12/Dec/10 04:03,0.7.0 rc 3,,,,0,,,,,,"In CASSANDRA-1774 we fixed a problem where only the last column was being written.  However, it appears that we only write the first one now.  This is easy to observe in the word count example:

{noformat}
RowKey: text2
=> (column=word1, value=1, timestamp=1291666461685000)
{noformat}

is what the output for text2 looks like, but there should be another column, word2.  If the word count is run without CFOF it works correctly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Dec/10 03:12;jeromatron;1842-2.txt;https://issues.apache.org/jira/secure/attachment/12466092/1842-2.txt","12/Dec/10 02:35;jbellis;1842.txt;https://issues.apache.org/jira/secure/attachment/12466091/1842.txt",,,,,,,,,,,,,2.0,jeromatron,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20340,,,Sun Dec 12 03:49:56 UTC 2010,,,,,,,,,,"0|i0g7qv:",92685,,,,,Normal,,,,,,,,,,,,,,,,,"12/Dec/10 02:35;jbellis;This is a bug where the WordCount example incorrectly wraps a byte array that is subsequently re-used w/o copying.  Fix attached.;;;","12/Dec/10 03:12;jeromatron;Added some housekeeping to the patch like a semi-colon to the README and some naming in WordCount.java - also tested.;;;","12/Dec/10 03:49;hudson;Integrated in Cassandra-0.7 #71 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/71/])
    copy Text bytes because it gets re-used
patch by jbellis; tested by Jeremy Hanna for CASSANDRA-1842
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cli formatted help width,CASSANDRA-1841,12492953,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,urandom,urandom,10/Dec/10 16:04,16/Apr/19 09:33,14/Jul/23 05:51,14/Dec/10 23:36,0.7.0 rc 3,,Legacy/Tools,,0,,,,,,"Most of cassandra-cli's help output justifies to 81 chars, just enough to cause line wrap on most default sized terminals.  It would improve appearance here if one character of the separating white space was removed so that it justified at 80 chars.",,,,,,,,,,,0,0,,0%,0,0,,,,,,,,,,,,,,"13/Dec/10 22:06;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1841-justify-at-80-chars-instead-of-81.txt;https://issues.apache.org/jira/secure/attachment/12466170/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1841-justify-at-80-chars-instead-of-81.txt",,,,,,,,,,,,,,1.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20339,,,Tue Dec 14 23:54:56 UTC 2010,,,,,,,,,,"0|i0g7qn:",92684,,,,,Low,,,,,,,,,,,,,,,,,"14/Dec/10 18:16;jbellis;+1;;;","14/Dec/10 23:36;urandom;committed;;;","14/Dec/10 23:54;hudson;Integrated in Cassandra-0.7 #82 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/82/])
    CASSANDRA-1841: justify at 80 chars (instead of 81)

Patch by eevans
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Deleted columns are resurrected after a flush,CASSANDRA-1837,12492744,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,gdusbabek,brandon.williams,brandon.williams,08/Dec/10 15:25,16/Apr/19 09:33,14/Jul/23 05:51,15/Dec/10 15:24,0.7.0 rc 3,,,,1,,,,,,"Easily reproduced with the cli:

{noformat}
[default@unknown] create keyspace testks;
2785d67c-02df-11e0-ac09-e700f669bcfc
[default@unknown] use testks;
Authenticated to keyspace: testks
[default@testks] create column family testcf;
2fbad20d-02df-11e0-ac09-e700f669bcfc
[default@testks] set testcf['test']['foo'] = 'foo';
Value inserted.
[default@testks] set testcf['test']['bar'] = 'bar';
Value inserted.
[default@testks] list testcf;
Using default limit of 100
-------------------
RowKey: test
=> (column=626172, value=626172, timestamp=1291821869120000)
=> (column=666f6f, value=666f6f, timestamp=1291821857320000)

1 Row Returned.
[default@testks] del testcf['test'];
row removed.
[default@testks] list testcf;
Using default limit of 100
-------------------
RowKey: test

1 Row Returned.
{noformat}

Now flush testks and look again:

{noformat}

[default@testks] list testcf;
Using default limit of 100
-------------------
RowKey: test
=> (column=626172, value=626172, timestamp=1291821869120000)
=> (column=666f6f, value=666f6f, timestamp=1291821857320000)

1 Row Returned.
{noformat}",,dave111,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Dec/10 17:52;gdusbabek;1837-0.6-unit-test.diff;https://issues.apache.org/jira/secure/attachment/12466228/1837-0.6-unit-test.diff","14/Dec/10 17:29;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-unit-tests-that-show-bug.txt;https://issues.apache.org/jira/secure/attachment/12466225/ASF.LICENSE.NOT.GRANTED--v1-0001-unit-tests-that-show-bug.txt","14/Dec/10 17:29;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0002-copy-deletion-time-to-reduced-column-families.txt;https://issues.apache.org/jira/secure/attachment/12466226/ASF.LICENSE.NOT.GRANTED--v1-0002-copy-deletion-time-to-reduced-column-families.txt","14/Dec/10 22:26;jbellis;v2-0002.txt;https://issues.apache.org/jira/secure/attachment/12466259/v2-0002.txt",,,,,,,,,,,4.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20337,,,Wed Jan 19 01:21:24 UTC 2011,,,,,,,,,,"0|i0g7pr:",92680,,jbellis,,jbellis,Critical,,,,,,,,,,,,,,,,,"08/Dec/10 15:36;brandon.williams;I had a suspicion it was related to CASSANDRA-1780, but I backed it out and the problem persists.;;;","08/Dec/10 20:40;jbellis;can you port to TableTest?  it has reTest to check for same behavior before-and-after-flush.;;;","10/Dec/10 20:10;gdusbabek;This is happening because of bug in the way deleted rows are [not] interpreted once they leave the memtable in the CFS.getRangeSlice code.  CFS.getColumnFamily doesn't exhibit the bug, but the codepath is pretty different.

I've got a fix that addresses standard columns, but it breaks a few of the nosetests for super columns.  Looking into that now.;;;","14/Dec/10 17:31;gdusbabek;This might be a problem in 0.6 too.  Porting the unit test over isn't trivial though...;;;","14/Dec/10 17:52;gdusbabek;Ported unit test to 0.6. Verifies non-breakage there.;;;","14/Dec/10 22:26;jbellis;Thanks for tracking that down, Gary!

I think it makes sense to centralize the lastReducedAt logic in getReduced to avoid having a field that is initialized in one method and cleared in another (which looks like a bug in v1, that it doesn't get cleared between rows).  v2 attached w/ this approach.;;;","14/Dec/10 22:47;gdusbabek;bq. I think it makes sense to centralize the lastReducedAt logic in getReduced...
Right. My mistake.;;;","15/Dec/10 15:12;jbellis;+1;;;","15/Dec/10 15:24;gdusbabek;committed.;;;","15/Dec/10 15:44;hudson;Integrated in Cassandra-0.7 #84 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/84/])
    track row deletions when merging cols to form a row. patch by gdusbabek and jbellis. CASSANDRA-1837
;;;","15/Dec/10 16:15;hudson;Integrated in Cassandra #631 (See [https://hudson.apache.org/hudson/job/Cassandra/631/])
    changes for CASSANDRA-1837
track row deletions when merging cols to form a row. patch by gdusbabek and jbellis. CASSANDRA-1837
unit tests that show bug. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1837
;;;","19/Jan/11 01:19;dave111;just wanted to take credit for originally discovering and reporting this to driftx in the chat. my original example- http://pastie.org/1358812.  thanks for the fix and quick turnaround.;;;","19/Jan/11 01:21;brandon.williams;Thanks for finding this, Dave.  (I am driftx on irc);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""null"" error creating CF from cli",CASSANDRA-1835,12492695,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,xedin,jbellis,jbellis,08/Dec/10 01:37,16/Apr/19 09:33,14/Jul/23 05:51,10/Dec/10 16:37,0.7.0 rc 3,,Legacy/Tools,,0,,,,,,"This fails with only ""null"" as the failure message:

{code}
create column family test1 with column_type = 'Super' and comparator = 'LongType' and column_metadata=[{column_name:a,validation_class:LongType}];
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Dec/10 10:35;xedin;CASSANDRA-1835.patch;https://issues.apache.org/jira/secure/attachment/12465789/CASSANDRA-1835.patch",,,,,,,,,,,,,,1.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20335,,,Sat Dec 11 07:35:17 UTC 2010,,,,,,,,,,"0|i0g7pb:",92678,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"09/Dec/10 20:08;jbellis;should we require subcomparator instead of guessing?  that may be better.;;;","09/Dec/10 20:40;xedin;I think warning here will be a pretty good option but as you think the best...;;;","09/Dec/10 22:47;xedin;In other words I think we should keep it with warning, what do you say?;;;","10/Dec/10 16:37;jbellis;committed;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"hudson test failure: ""Forked Java VM exited abnormally.""",CASSANDRA-1834,12492681,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,urandom,urandom,07/Dec/10 23:04,16/Apr/19 09:33,14/Jul/23 05:51,11/Dec/10 16:12,0.7.0 rc 3,,,,0,,,,,,"https://hudson.apache.org/hudson/view/A-F/view/Cassandra/job/Cassandra-0.7/56/

{noformat}
    [junit] Testsuite: org.apache.cassandra.service.EmbeddedCassandraServiceTest
    [junit] Testsuite: org.apache.cassandra.service.EmbeddedCassandraServiceTest
    [junit] Tests run: 1, Failures: 0, Errors: 1, Time elapsed: 0 sec
    [junit] 
    [junit] Testcase: org.apache.cassandra.service.EmbeddedCassandraServiceTest:BeforeFirstTest:	Caused an ERROR
    [junit] Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.
    [junit] junit.framework.AssertionFailedError: Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.
    [junit] 
    [junit] 
    [junit] Test org.apache.cassandra.service.EmbeddedCassandraServiceTest FAILED (crashed)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20334,,,Sat Dec 11 16:12:28 UTC 2010,,,,,,,,,,"0|i0g7p3:",92677,,,,,Normal,,,,,,,,,,,,,,,,,"07/Dec/10 23:40;urandom;a bisect suggests it was introduced here: https://svn.apache.org/viewvc?view=revision&revision=1041951

""reads at ConsistencyLevel > 1 throwUnavailableException immediately if insufficient live nodes exist
patch by jbellis and tjake for CASSANDRA-1803"";;;","08/Dec/10 00:59;jbellis;usually when i've seen ""vm exited abnormally"" there is something in the log or on stdout, can we get the subprocess stdout from hudson?;;;","08/Dec/10 01:36;urandom;Is this not it? https://hudson.apache.org/hudson/view/A-F/view/Cassandra/job/Cassandra-0.7/56/console

That's everything that I see when it fails on me locally.;;;","08/Dec/10 01:43;jbellis;that's the console of the junit jvm, not the console of the jvm it forked to run the test;;;","08/Dec/10 04:27;urandom;{noformat}
org.apache.cassandra.config.ConfigurationException: Found system table files, but they couldn't be loaded. Did you change the partitioner?
        at org.apache.cassandra.db.SystemTable.checkHealth(SystemTable.java:236)
        at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:105)
        at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:55)
        at org.apache.cassandra.service.AbstractCassandraDaemon.init(AbstractCassandraDaemon.java:183)
        at org.apache.cassandra.service.EmbeddedCassandraService.init(EmbeddedCassandraService.java:72)
        at org.apache.cassandra.service.EmbeddedCassandraServiceTest.setup(EmbeddedCassandraServiceTest.java:78)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:616)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
        at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:422)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:931)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:785
{noformat};;;","08/Dec/10 05:54;jbellis;I bet having ECST extend CleanupHelper will clear that up;;;","08/Dec/10 06:56;tjake;When this happens to me I normally do remove the build/test dir to resolve (some kind of corruption)
;;;","11/Dec/10 16:12;jbellis;bq. I bet having ECST extend CleanupHelper will clear that up 

done.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"clustertool get_endpoints needs key as String, not ByteBuffer",CASSANDRA-1833,12492646,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,kelvin,kelvin,kelvin,07/Dec/10 18:12,16/Apr/19 09:33,14/Jul/23 05:51,19/Jan/11 01:02,0.7.0 rc 3,,Legacy/Tools,,0,,,,,,"java RMI does not serialize ByteBuffer; revert clustertool to use String for key",all environments,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Dec/10 23:20;kelvin;CASSANDRA-1833.120710.patch;https://issues.apache.org/jira/secure/attachment/12465757/CASSANDRA-1833.120710.patch",,,,,,,,,,,,,,1.0,kelvin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20333,,,Wed Jan 19 01:02:32 UTC 2011,,,,,,,,,,"0|i0g7ov:",92676,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"07/Dec/10 18:14;kelvin;replace ByteBuffer w/ String;;;","07/Dec/10 20:45;jbellis;trying to decode to UTF8 is going to break on a lot of keys.  you'll want to use hex and FBUtilities.hexToBytes.;;;","07/Dec/10 20:46;jbellis;... actually probably the best solution would be to put it back to being a byte[] the way it was pre-beta3.;;;","07/Dec/10 23:20;kelvin;modified to use byte[] (like beta-2);;;","08/Dec/10 00:57;jbellis;committed, w/ addition of hexToBytes for nodeprobe;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;","18/Jan/11 23:25;kelvin;just discovered that bytesToHex doesn't work via cluster tool get_endpoints.  The CharSets.UTF_8 version does, though.;;;","19/Jan/11 01:02;kelvin;It's actually fine.

When using the cluster tool, keys must be hex-encoded.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
mx4j does not load,CASSANDRA-1832,12492636,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,rantav,rstml,rstml,07/Dec/10 16:28,16/Apr/19 09:33,14/Jul/23 05:51,08/Dec/10 01:01,0.7.0 rc 3,,Legacy/Tools,,0,,,,,,"Adding mx4j-tools.jar (latest) to the library causes following exception:

{code}
 WARN 20:22:25,123 Could not start register mbean in JMX
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.cassandra.utils.Mx4jTool.maybeLoad(Mx4jTool.java:67)
	at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:169)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:55)
	at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:216)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:134)
Caused by: java.net.BindException: Address already in use
	at java.net.PlainSocketImpl.socketBind(Native Method)
	at java.net.PlainSocketImpl.bind(PlainSocketImpl.java:365)
	at java.net.ServerSocket.bind(ServerSocket.java:319)
	at java.net.ServerSocket.<init>(ServerSocket.java:185)
	at mx4j.tools.adaptor.PlainAdaptorServerSocketFactory.createServerSocket(PlainAdaptorServerSocketFactory.java:24)
	at mx4j.tools.adaptor.http.HttpAdaptor.createServerSocket(HttpAdaptor.java:672)
	at mx4j.tools.adaptor.http.HttpAdaptor.start(HttpAdaptor.java:478)
	... 9 more
{code}",CentOS 5.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Dec/10 21:48;rantav;CASSANDRA-1832.patch;https://issues.apache.org/jira/secure/attachment/12465736/CASSANDRA-1832.patch",,,,,,,,,,,,,,1.0,rantav,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20332,,,Sat Dec 11 07:35:18 UTC 2010,,,,,,,,,,"0|i0g7on:",92675,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"07/Dec/10 17:24;rstml;I did a bit more tests and here are some results which might help:

1. JMX port set to 9090 in cassandra-env.sh
2. On the machine where another service running on 8080 we get exception above
3. On the machine where no service running on 8080 we don't get any exception and MX4J runs on port 9090

Seems like something checks for port 8080 even though it is configured to run on 9090.;;;","07/Dec/10 21:40;rantav;I think there's a confusion. 
There are two ports in business, one is the JMX port (default is 8080) and one is the MX4J port (default 8081)
If the JMX port is used when cassandra starts you see the following exception, which is different from what's pasted in this bug report:

apache-cassandra-0.7.0-rc1 $ bin/cassandra -f 
Error: Exception thrown by the agent : java.rmi.server.ExportException: Port already in use: 8080; nested exception is: 
	java.net.BindException: Address already in use

If mx4j's port, by default 8081, is used, then you see the report from above, which btw isn't fatal, the server operates correctly but without mx4j.

WARN 20:22:25,123 Could not start register mbean in JMX
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.cassandra.utils.Mx4jTool.maybeLoad(Mx4jTool.java:67)
	at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:169)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:55)
	at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:216)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:134)
Caused by: java.net.BindException: Address already in use
	at java.net.PlainSocketImpl.socketBind(Native Method)
	at java.net.PlainSocketImpl.bind(PlainSocketImpl.java:365)
	at java.net.ServerSocket.bind(ServerSocket.java:319)
	at java.net.ServerSocket.<init>(ServerSocket.java:185)
	at mx4j.tools.adaptor.PlainAdaptorServerSocketFactory.createServerSocket(PlainAdaptorServerSocketFactory.java:24)
	at mx4j.tools.adaptor.http.HttpAdaptor.createServerSocket(HttpAdaptor.java:672)
	at mx4j.tools.adaptor.http.HttpAdaptor.start(HttpAdaptor.java:478)
	... 9 more


So the problem in this case. I believe was that mx4j's port was bound to a different process.
To control the port used by mx4j use  -Dmx4jport=8082. See https://issues.apache.org/jira/browse/CASSANDRA-1068 for more details.

I think this is not a bug and recommend to close it as such.
I will, however, attach a patch for trunk to make this more obvious and add -Dmx4jport=8081 to conf/cassandra-env.sh;;;","07/Dec/10 21:48;rantav;Patch that adds the variables MX4J_ADDRESS and MX4J_PORT to conf/cassandra-env.sh make configuration for mx4j obvious.;;;","07/Dec/10 22:03;rstml;You right Ran, I checked this machine again and I have another service listening on 8081.
For some reason I thought that MX4J uses same port.

With config options we can close it now.;;;","08/Dec/10 01:01;jbellis;committed, thanks!;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ReadResponseResolver might miss an inconsistency,CASSANDRA-1830,12492543,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,tilgovi,jbellis,jbellis,06/Dec/10 21:52,16/Apr/19 09:33,14/Jul/23 05:51,15/Dec/10 16:10,0.6.9,0.7.0 rc 3,,,0,,,,,,"Rather than comparing the digests of all the digest requests to one another, the last one seen ""wins"" and is compared to the digest of each version seen from a data request.",,tilgovi,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Dec/10 21:53;jbellis;1830.txt;https://issues.apache.org/jira/secure/attachment/12465620/1830.txt","15/Dec/10 15:47;slebresne;1830_0.7.txt;https://issues.apache.org/jira/secure/attachment/12466326/1830_0.7.txt",,,,,,,,,,,,,2.0,tilgovi,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20330,,,Tue Dec 21 21:48:55 UTC 2010,,,,,,,,,,"0|i0g7o7:",92673,,slebresne,,slebresne,Low,,,,,,,,,,,,,,,,,"06/Dec/10 21:53;jbellis;Patch based on Randall Leeds's from CASSANDRA-982.;;;","15/Dec/10 15:47;slebresne;+1 on v6 version (very minor comment: the import of ColumnFamily in DigestMismatchException.java is unnecessary)

Also attaching a port to 0.7.;;;","15/Dec/10 16:10;jbellis;committed, thanks!;;;","15/Dec/10 16:43;hudson;Integrated in Cassandra-0.6 #23 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/23/])
    ReadResponseResolver check digests against each other
patch by Randall Leeds and jbellis; reviewed by slebrense for CASSANDRA-1830
;;;","21/Dec/10 21:48;hudson;Integrated in Cassandra-0.6 #32 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/32/])
    fix NPE regression caused by CASSANDRA-1830
patch by jbellis; reviewed by mdennis and tjake
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Nodetool move is broken,CASSANDRA-1829,12492542,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,nickmbailey,nickmbailey,nickmbailey,06/Dec/10 21:49,16/Apr/19 09:33,14/Jul/23 05:51,09/Dec/10 16:59,0.7.0 rc 3,,,,0,,,,,,The code from finishBootstrapping that finishes a move was removed. This means a move will leave a node stuck in a bootstrapping state forever.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Dec/10 08:02;nickmbailey;0001-Update-token-after-bootstrapping.patch;https://issues.apache.org/jira/secure/attachment/12465783/0001-Update-token-after-bootstrapping.patch",,,,,,,,,,,,,,1.0,nickmbailey,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20329,,,Mon Dec 13 20:16:13 UTC 2010,,,,,,,,,,"0|i0g7nz:",92672,,,,,Critical,,,,,,,,,,,,,,,,,"08/Dec/10 08:02;nickmbailey;Still need to test this on a couple vms but this should be right.;;;","08/Dec/10 17:23;nickmbailey;tested on a 3 node cluster;;;","09/Dec/10 16:59;brandon.williams;Committed.;;;","09/Dec/10 23:17;jbellis;committed r1044161 to fix regression of setBootstrapped treatment;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;","13/Dec/10 20:16;hudson;Integrated in Cassandra #625 (See [https://hudson.apache.org/hudson/job/Cassandra/625/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
system_create_cf() makes a SuperCF when column_type is Standard and subcolumn_comparator_type is present,CASSANDRA-1826,12492539,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,thobbs,thobbs,06/Dec/10 20:39,16/Apr/19 09:33,14/Jul/23 05:51,06/Dec/10 21:57,0.7.0 rc 2,,,,0,,,,,,"If you create a CF with system_create_column_family() and the CfDef has column_type = 'Standard' and subcomparator_type is present, it creates a SuperCF.  I would expect an InvalidRequestException, instead.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20328,,,Mon Dec 06 21:57:42 UTC 2010,,,,,,,,,,"0|i0g7nb:",92669,,,,,Normal,,,,,,,,,,,,,,,,,"06/Dec/10 21:57;jbellis;fixed in rc2 by patches for CASSANDRA-1773 and CASSANDRA-1813;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Schema only fully propagates from seeds,CASSANDRA-1824,12492268,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,brandon.williams,brandon.williams,06/Dec/10 18:10,16/Apr/19 09:33,14/Jul/23 05:51,14/Dec/10 22:44,0.7.0 rc 3,,,,0,,,,,,"If you have nodes X, Y, and Z, and Y already has some schema, but X and Z do not, and X is the seed node for the cluster, X will pick up the schema from Y, but it will never propagate to Z.  If X has the schema, it will propagate to both Y and Z.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Dec/10 22:25;gdusbabek;ASF.LICENSE.NOT.GRANTED--v2-0001-always-put-schema-state-in-local-gossip.txt;https://issues.apache.org/jira/secure/attachment/12466258/ASF.LICENSE.NOT.GRANTED--v2-0001-always-put-schema-state-in-local-gossip.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20327,,,Wed Dec 15 16:15:06 UTC 2010,,,,,,,,,,"0|i0g7mv:",92667,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"09/Dec/10 17:17;gdusbabek;can't reproduce.  Tested on 3-node clusters in trunk, 0.7 and 0.7-rc1.;;;","09/Dec/10 20:12;brandon.williams;It takes me a few tries, but the procedure is:

1) start a non-seed, load schema
2) start other non-seed
3) start seed

Usually I can reproduce in 10 tries or less.;;;","14/Dec/10 22:39;gdusbabek;Here is how things broke:
1. Node 2 starts up and is fed a schema. it then includes SCHEMA in its gossip state as part of *applying the migration.*
2. Node 2 is restarted. It no longer includes SCHEMA in its gossip state.
3. Start any number of nodes. None of them will get schema.

The fix puts SCHEMA in the gossip state every time schema is announced.;;;","14/Dec/10 22:44;brandon.williams;+1, committed.;;;","14/Dec/10 23:33;hudson;Integrated in Cassandra-0.7 #81 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/81/])
    fix breaking tests from CASSANDRA-1824
;;;","15/Dec/10 16:15;hudson;Integrated in Cassandra #631 (See [https://hudson.apache.org/hudson/job/Cassandra/631/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra deb should depend on adduser,CASSANDRA-1816,12492012,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,thepaul,thepaul,thepaul,03/Dec/10 18:04,16/Apr/19 09:33,14/Jul/23 05:51,04/Dec/10 01:51,0.7.0 rc 2,,Packaging,,0,,,,,,"The cassandra debian package uses the addgroup and adduser commands in its postinst script, which are found in the 'adduser' package, but the cassandra debian package does not depend on adduser.   When a user does not already have adduser installed, this will lead to an error like:

{noformat}
Setting up cassandra (0.7.0~rc1) ...
/var/lib/dpkg/info/cassandra.postinst: 50: addgroup: not found
dpkg: error processing cassandra (--configure):
 subprocess installed post-installation script returned error exit status 127
{noformat}

Yes, this won't happen much, because systems without adduser installed are rare.  But adduser is not ""Essential: yes"", so it will happen sometimes in bare-bones VMs or development environments.",Debian squeeze,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Dec/10 18:05;thepaul;cass-1816.txt;https://issues.apache.org/jira/secure/attachment/12465251/cass-1816.txt",,,,,,,,,,,,,,1.0,thepaul,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20326,,,Tue Dec 07 20:30:52 UTC 2010,,,,,,,,,,"0|i0g7l3:",92659,,urandom,,urandom,Low,,,,,,,,,,,,,,,,,"04/Dec/10 01:51;urandom;committed; thanks!;;;","07/Dec/10 20:30;hudson;Integrated in Cassandra #615 (See [https://hudson.apache.org/hudson/job/Cassandra/615/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
return invalidrequest when client attempts to create secondary index on supercolumns,CASSANDRA-1813,12491990,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,03/Dec/10 14:52,16/Apr/19 09:33,14/Jul/23 05:51,03/Dec/10 18:56,0.7.0 rc 2,,Feature/2i Index,,0,,,,,,,,bshi,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Dec/10 16:13;jbellis;1813.txt;https://issues.apache.org/jira/secure/attachment/12465237/1813.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20325,,,Sat Dec 11 07:35:18 UTC 2010,,,,,,,,,,"0|i0g7kf:",92656,,gdusbabek,,gdusbabek,Low,,,,,,,,,,,,,,,,,"03/Dec/10 16:13;jbellis;also fixes assumption in validateCfDef that presence of subcomparator_type implies supercolumn-ness;;;","03/Dec/10 17:03;gdusbabek;+1;;;","03/Dec/10 18:56;jbellis;committed;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cli support index_type enum names in column_metadata,CASSANDRA-1810,12491944,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,xedin,jbellis,jbellis,02/Dec/10 23:58,16/Apr/19 09:33,14/Jul/23 05:51,03/Dec/10 14:26,0.7.0 rc 2,,Legacy/Tools,,0,,,,,,currently you have to write index_type: 0 when index_type: KEYS would be better,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Dec/10 10:38;xedin;CASSANDRA-1810.patch;https://issues.apache.org/jira/secure/attachment/12465222/CASSANDRA-1810.patch",,,,,,,,,,,,,,1.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20324,,,Sat Dec 11 07:35:17 UTC 2010,,,,,,,,,,"0|i0g7jr:",92653,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"03/Dec/10 10:40;xedin;Please review this after CASSANDRA-1809. Current version will support both - numeric and string values for index_type.;;;","03/Dec/10 10:41;xedin;Work branch: cassandra-0.7 (latest commit was d6b1d581e9ad28ea2106462d306304e821a335f9);;;","03/Dec/10 14:26;jbellis;committed;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cli executeGetWithConditions is not case-insensitive for CF names,CASSANDRA-1809,12491943,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,xedin,jbellis,jbellis,02/Dec/10 23:57,16/Apr/19 09:33,14/Jul/23 05:51,03/Dec/10 14:25,0.7.0 rc 2,,Legacy/Tools,,0,,,,,,"{code}
        String columnFamily = statement.getChild(0).getText();
{code}

is not being normalized for case...

I tried
{code}
-        String columnFamily = statement.getChild(0).getText();
+        String columnFamily = CliCompiler.getColumnFamily(statement.getChild(0), keyspacesMap.get(keySpace).cf_defs);
{code}

but that broke it, all gets returned null (missing exception message?)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Dec/10 10:12;xedin;CASSANDRA-1809.patch;https://issues.apache.org/jira/secure/attachment/12465220/CASSANDRA-1809.patch",,,,,,,,,,,,,,1.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20323,,,Sat Dec 11 07:35:15 UTC 2010,,,,,,,,,,"0|i0g7jj:",92652,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"03/Dec/10 10:12;xedin;Tests are updated too.;;;","03/Dec/10 10:41;xedin;Work branch: cassandra-0.7 (latest commit was d6b1d581e9ad28ea2106462d306304e821a335f9);;;","03/Dec/10 14:25;jbellis;committed;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Quorum calculation code needs to use polymorphic Strategy method for determining replica counts,CASSANDRA-1804,12491833,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,01/Dec/10 23:01,16/Apr/19 09:33,14/Jul/23 05:51,02/Dec/10 01:49,0.7.0 rc 2,,,,0,,,,,,"Keyspace.replication_factor is only valid for SimpleStrategy and ONTS, we shouldn't use it directly anywhere.

Related: CASSANDRA-1263 would remove the temptation to do the Wrong Thing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Dec/10 23:23;jbellis;1804.txt;https://issues.apache.org/jira/secure/attachment/12465089/1804.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20320,,,Sat Dec 11 07:35:16 UTC 2010,,,,,,,,,,"0|i0g7if:",92647,,jhermes,,jhermes,Normal,,,,,,,,,,,,,,,,,"02/Dec/10 00:10;jhermes;+1.
(An optional improvement would be to leave getRF in ARS abstract, and to provide dummy implementations in the child strategies to be rewritten at a later date (namely for #1263)).;;;","02/Dec/10 01:49;jbellis;committed;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bytebuffers of column data written locally prevent GC of original thrift mutation byte[],CASSANDRA-1801,12491821,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,tjake,mdennis,mdennis,01/Dec/10 22:03,16/Apr/19 09:33,14/Jul/23 05:51,03/Dec/10 19:25,0.7.0 rc 2,,,,0,,,,,,It appears C* isn't releasing buffers that were used during the writes of batch mutates.  See attached screenshot of heap dump.,,gdusbabek,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Dec/10 16:27;tjake;1801_v1.txt;https://issues.apache.org/jira/secure/attachment/12465143/1801_v1.txt","03/Dec/10 19:09;tjake;1801_v2.txt;https://issues.apache.org/jira/secure/attachment/12465262/1801_v2.txt","01/Dec/10 22:03;mdennis;screenie.png;https://issues.apache.org/jira/secure/attachment/12465079/screenie.png",,,,,,,,,,,,3.0,tjake,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20318,,,Sat Dec 11 07:35:09 UTC 2010,,,,,,,,,,"0|i0g7hr:",92644,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"02/Dec/10 16:27;tjake;The thrift transport is now zero-copy for local writes. This means a larger underlying byte[] is held onto for many writes. 

This patch does a deep copy of the row mutation BB before storing in local memtable to avoid this.

;;;","02/Dec/10 21:46;gdusbabek;Would it be more prudent to ensure that copies of the BBs that are needed are made in Table.apply, rather than copying everything wholesale up front?;;;","02/Dec/10 22:15;jbellis;We'd like to avoid doing a second copy for BB that we just read (copied) off IncomingTcpConnection.;;;","03/Dec/10 19:09;tjake;v2 rebased for 0.7;;;","03/Dec/10 19:25;jbellis;committed;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Booting fails on Windows 7/Windows 2003 because of a file rename failure,CASSANDRA-1790,12491618,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,jbellis,rockxwre,rockxwre,30/Nov/10 08:16,16/Apr/19 09:33,14/Jul/23 05:51,30/Nov/10 21:32,0.7.0 rc 2,,,,1,,,,,,"Cassandra 0.7.0 rc will not boot on Windows 7 and Windows 2003 because of a file rename failure. The logging:

{noformat}
 INFO [FlushWriter:1] 2010-11-25 17:12:43,796 Memtable.java (line 155) Writing Memtable-LocationInfo@691789110(435 bytes, 8 operations)
ERROR [FlushWriter:1] 2010-11-25 17:12:43,993 AbstractCassandraDaemon.java (line 90) Fatal exception in thread Thread[FlushWriter:1,5,main]
java.io.IOError: java.io.IOException: rename failed of d:\cassandra\data\system\LocationInfo-e-1-Data.db
	at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.java:214)
	at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SSTableWriter.java:184)
	at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SSTableWriter.java:167)
	at org.apache.cassandra.db.Memtable.writeSortedContents(Memtable.java:161)
	at org.apache.cassandra.db.Memtable.access$000(Memtable.java:49)
	at org.apache.cassandra.db.Memtable$1.runMayThrow(Memtable.java:174)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
Caused by: java.io.IOException: rename failed of d:\cassandra\data\system\LocationInfo-e-1-Data.db
	at org.apache.cassandra.utils.FBUtilities.renameWithConfirm(FBUtilities.java:359)
	at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.java:210)
	... 12 more
 INFO [main] 2010-11-29 09:16:36,219 AbstractCassandraDaemon.java (line 73) Heap size: 1067253760/1067253760
{noformat}
","Windows 7 (64-bit), Windows 2003 (32-bit)",mdennis,rockxwre,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Nov/10 16:26;jbellis;1790.txt;https://issues.apache.org/jira/secure/attachment/12464967/1790.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20316,,,Sat Dec 11 07:35:11 UTC 2010,,,,,,,,,,"0|i0g7fb:",92633,,mdennis,,mdennis,Critical,,,,,,,,,,,,,,,,,"30/Nov/10 16:26;jbellis;patch to close file handle used for post-flush truncate, which will allow the rename to complete on Windows;;;","30/Nov/10 20:04;mdennis;+1;;;","30/Nov/10 21:32;jbellis;committed;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[patch] use cross platform new lines in printf calls,CASSANDRA-1786,12491508,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,dbrosius,dbrosius@apache.org,dbrosius@apache.org,28/Nov/10 20:51,16/Apr/19 09:33,14/Jul/23 05:51,29/Nov/10 16:51,0.7.0 rc 2,,,,0,,,,,,"code uses printf(""\n"") for new lines, should use ""%n"" instead.",ubuntu10.10 java 1.6.17 ant 1.8,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,"28/Nov/10 20:51;dbrosius@apache.org;use_crossplatform_newlines.diff;https://issues.apache.org/jira/secure/attachment/12464819/use_crossplatform_newlines.diff",,,,,,,,,,,,,,1.0,dbrosius,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20314,,,Sat Dec 11 07:35:22 UTC 2010,,,,,,,,,,"0|i0g7dz:",92627,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"29/Nov/10 16:51;jbellis;committed, thanks!;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"[patch] use long math, if long values are expected.",CASSANDRA-1785,12491506,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,dbrosius,dbrosius@apache.org,dbrosius@apache.org,28/Nov/10 20:34,16/Apr/19 09:33,14/Jul/23 05:51,29/Nov/10 16:48,0.7.0 rc 2,,,,0,,,,,,"code does math assuming the result is a long, but uses integer math. Might as well use long math to avoid possible truncation.",ubuntu10.10 java1.6.17 ant1.8,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,"28/Nov/10 20:34;dbrosius@apache.org;use_long_math.diff;https://issues.apache.org/jira/secure/attachment/12464818/use_long_math.diff",,,,,,,,,,,,,,1.0,dbrosius,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20313,,,Sat Dec 11 07:35:21 UTC 2010,,,,,,,,,,"0|i0g7dr:",92626,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"29/Nov/10 16:48;jbellis;commited, thanks!;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
spurious failures of o.a.c.db.NameSortTest:testNameSort100,CASSANDRA-1783,12491450,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,urandom,urandom,27/Nov/10 16:09,16/Apr/19 09:33,14/Jul/23 05:51,11/Dec/10 06:52,0.7.0 rc 3,,,,0,,,,,,"{noformat}
    [junit] Cobertura: Loaded information on 961 classes.
    [junit] Cobertura: Saved information on 961 classes.
    [junit] Testsuite: org.apache.cassandra.db.NameSortTest
    [junit] Testsuite: org.apache.cassandra.db.NameSortTest
    [junit] Tests run: 1, Failures: 0, Errors: 1, Time elapsed: 0 sec
    [junit] 
    [junit] Testcase: org.apache.cassandra.db.NameSortTest:testNameSort100:	Caused an ERROR
    [junit] Timeout occurred. Please note the time in the report does not reflect the time until the timeout.
    [junit] junit.framework.AssertionFailedError: Timeout occurred. Please note the time in the report does not reflect the time until the timeout.
    [junit]
{noformat}

See also: https://hudson.apache.org/hudson/job/Cassandra-0.7/33/console","Hudson, ubuntu2 (vesta.apache.org)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20312,,,Sat Dec 11 06:52:24 UTC 2010,,,,,,,,,,"0|i0g7db:",92624,,,,,Low,,,,,,,,,,,,,,,,,"11/Dec/10 06:52;jbellis;fixed in r1044570;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Example session in README is missing semicolons,CASSANDRA-1782,12481001,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,justinazoff,justinazoff,justinazoff,26/Nov/10 23:01,16/Apr/19 09:33,14/Jul/23 05:51,27/Nov/10 02:18,0.7.0 rc 2,,Legacy/Documentation and Website,,0,,,,,,The example session in the README is missing the semicolons at the end of each command.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Nov/10 23:03;justinazoff;cassandra-1782.patch;https://issues.apache.org/jira/secure/attachment/12460521/cassandra-1782.patch",,,,,,,,,,,,,,1.0,justinazoff,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20311,,,Sat Nov 27 02:18:41 UTC 2010,,,,,,,,,,"0|i0g7d3:",92623,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"26/Nov/10 23:03;justinazoff;Patch that adds the missing semicolons.;;;","27/Nov/10 02:18;jbellis;committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Internal error processing get_range_slices,CASSANDRA-1781,12480961,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,patrik.modesto,patrik.modesto,26/Nov/10 09:51,16/Apr/19 09:33,14/Jul/23 05:51,02/Dec/10 01:20,0.6.9,0.7.0 rc 2,,,0,,,,,,"Runnig mapreduce task on two or more Cassandra nodes gives following error:

DEBUG 16:51:48,653 range_slice
DEBUG 16:51:48,653 RangeSliceCommand{keyspace='TEST', column_family='Url', super_column=null, predicate=SlicePredicate(column_names:[java.nio.HeapByteBuffer[pos=57 lim=67 cap=177]]), range=(162950022446285318630909295651345252065,9481098247439719900692337295923514899], max_keys=4096}
DEBUG 16:51:48,653 restricted ranges for query (162950022446285318630909295651345252065,9481098247439719900692337295923514899] are [(162950022446285318630909295651345252065,9481098247439719900692337295923514899]]
DEBUG 16:51:48,653 local range slice
ERROR 16:51:48,653 Internal error processing get_range_slices
java.lang.AssertionError: (162950022446285318630909295651345252065,9481098247439719900692337295923514899]
at org.apache.cassandra.db.ColumnFamilyStore.getRangeSlice(ColumnFamilyStore.java:1264)
at org.apache.cassandra.service.StorageProxy.getRangeSlice(StorageProxy.java:429)
at org.apache.cassandra.thrift.CassandraServer.get_range_slices(CassandraServer.java:514)
at org.apache.cassandra.thrift.Cassandra$Processor$get_range_slices.process(Cassandra.java:2868)
at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:2555)
at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:619)
DEBUG 16:51:48,838 logged out: #<User allow_all groups=[]>

You can reproduce this by just running contrib/word_count example. Mapreduce last worked with Cassandra 0.7-beta2. Important is to run more than one node.","Debian Linux 2.6.32-openvz-amd64 x86_64 GNU/Linux, Cloudera hadoop CDH3",chrusty,jeromatron,patrik.modesto,shroman,stuhood,,,,,,,,,,,,,,,,CASSANDRA-1787,,,,,,,,"02/Dec/10 01:06;stuhood;1781.txt;https://issues.apache.org/jira/secure/attachment/12465094/1781.txt",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20310,,,Thu Dec 02 02:46:42 UTC 2010,,,,,,,,,,"0|i0g7cv:",92622,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"27/Nov/10 19:22;chrusty;I'm seeing exactly the same behaviour on 0.7-rc1. contrib/word_count (as well as my own map-reduce code based on contrib/word_count) works fine on a single-node, but as soon as i add more nodes to the cluster i get the same errors.

This seems identical to issue #1724 (https://issues.apache.org/jira/browse/CASSANDRA-1724), but that ticket has been ""resolved"".

I can provide logs if they're of use to anybody.


Chris;;;","02/Dec/10 01:06;stuhood;Ack! Posted this to CASSANDRA-1787 yesterday: we had another missing test case. Should be applied to 0.6, 0.7, trunk, etc.;;;","02/Dec/10 01:20;jbellis;committed, thanks!;;;","02/Dec/10 02:46;hudson;Integrated in Cassandra-0.6 #15 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/15/])
    fix range queries against wrapped range
patch by Stu Hood; reviewed by jbellis for CASSANDRA-1781
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The describe_host API method is misleading in that it returns the interface associated with gossip traffic,CASSANDRA-1777,12480888,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,zznate,zznate,25/Nov/10 05:06,16/Apr/19 09:33,14/Jul/23 05:51,03/Aug/11 21:46,0.8.4,,,,3,,,,,,"If the hardware is configured to use separate interfaces for thrift and gossip, the gossip interface will be returned, given the results come out of the ReplicationStrategy eventually.

I understand the approach, but given this is on the API, it effective worthless in situations of host auto discovery via describe_ring from a client. I actually see this as the primary use case of this method - why else would I care about the gossip iface from the client perspective? It's current form should be relegated to JMX only. 

At the same time, we should add port information as well. 

describe_splits probably has similar issues.

I see the potential cart-before-horse issues here and that this will probably be non-trivial to fix, but I think ""give me a set of all the hosts to which I can talk"" is pretty important from a client perspective.",,clavoie,sebastienc,,,,,,,,57600,57600,,0%,57600,57600,,,,,,,,,,CASSANDRA-2882,CASSANDRA-3173,,,"03/Aug/11 20:12;brandon.williams;1777-v2.txt;https://issues.apache.org/jira/secure/attachment/12489239/1777-v2.txt","19/Jan/11 23:06;brandon.williams;1777.txt;https://issues.apache.org/jira/secure/attachment/12468792/1777.txt",,,,,,,,,,,,,2.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,659,,,Wed Aug 03 22:19:59 UTC 2011,,,,,,,,,,"0|i0g7bz:",92618,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"19/Jan/11 23:06;brandon.williams;This is actually simple enough to apply to 0.7 if we leave out the rpc port (since that would require a thrift api change.)  describe_splits doesn't appear to be affected, just describe_ring.;;;","20/Jan/11 18:57;jbellis;gossip is for internal cluster state, we definitely shouldn't be using it for rpc_address and rpc_port.

90% convinced the answer is ""don't use describe_ring for node discovery, that's what RRDNS is for."";;;","20/Jan/11 19:20;brandon.williams;You can't build a routing-aware client from RRDNS though because you'll have no way to map the IP to the token.  describe_ring really is useless if the gossip iface isn't the same as the rpc address right now (describe_ring is already using gossip for the info it returns, it's just the wrong info.);;;","20/Jan/11 23:31;kingryan;Unless you have a dns server that can understand cassandra membership, RRDNS is actually a rough way to do this. I'd prefer to supply something for clients that works correctly.;;;","21/Jan/11 04:26;urandom;I don't see how you could build a non-Java routing-aware client without replicating the partitioner and replica placement client-side. Ick.;;;","21/Jan/11 17:59;kingryan;I don't care about making it routing-aware. I just want to do discovery.;;;","09/May/11 21:24;nickmbailey;Besides just auto_discovery this breaks the pig storage func in contrib if you use different interfaces. That class uses describe ring to generate the input splits for map tasks to work on, which obviously doesn't work if it returns the gossip interface instead of the thrift interface.

+1 on fixing this and backporting to 0.7;;;","09/May/11 21:29;brandon.williams;Since the problem is rooted in CFIF, this actually runs deeper than just Pig.;;;","03/Aug/11 18:22;jbellis;Brandon, what is the status here?;;;","03/Aug/11 18:27;brandon.williams;describe_ring, as is, is completely useless if you don't have thrift bound to the same interface as the storage proto, so I stand by the change to advertise the thrift address instead.;;;","03/Aug/11 19:07;jbellis;is that what the attached patch does?;;;","03/Aug/11 19:12;brandon.williams;That's what it did 8 months ago :)  It gets the rpc address/port information for each machine via gossip and returns that in describe_ring.;;;","03/Aug/11 19:22;jbellis;oh yeah.  the whole ""gossip is for internal cluster state, we definitely shouldn't be using it for rpc_address and rpc_port"" thing I objected to originally.

however, I don't have a better solution (asking nodes directly would mean we couldn't include nodes that are currently unreachable), so +1 I guess on the general approach.

if we're not going to expose individual rpc_port can we just require that it be the same cluster-wide and not bother gossiping it?  it's kind of a misfeature anyway to allow different ones.

the old getRangeToEndpointMap is unused and can be removed now right?

Committing to 0.8 is probably fine but let's leave 0.7 alone.;;;","03/Aug/11 19:27;brandon.williams;bq. if we're not going to expose individual rpc_port can we just require that it be the same cluster-wide and not bother gossiping it? it's kind of a misfeature anyway to allow different ones.

I agree, I'll remove the port.

bq. the old getRangeToEndpointMap is unused and can be removed now right?

I think I originally left it in because it's exposed over JMX and I didn't want to break it if anyone was using it for something.;;;","03/Aug/11 20:12;brandon.williams;v2 only communicate the rpc address over gossip, and fixes a problem in v1 when the rpc address is left blank.;;;","03/Aug/11 21:08;jbellis;+1, but let's remove getRangeToEndpointMap when you merge to trunk.;;;","03/Aug/11 21:46;brandon.williams;Committed.;;;","03/Aug/11 22:19;hudson;Integrated in Cassandra-0.8 #254 (See [https://builds.apache.org/job/Cassandra-0.8/254/])
    describe_ring returns the interface thrift is bound to instead of the
one the storage proto is bound to.
Patch by brandonwilliams, reviewed by jbellis for CASSANDRA-1777

brandonwilliams : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1153683
Files : 
* /cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/gms/VersionedValue.java
* /cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/thrift/CassandraServer.java
* /cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/service/StorageService.java
* /cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/gms/ApplicationState.java
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ColumnFamilyOutputFormat only writes one column (per key),CASSANDRA-1774,12480793,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mck,mck,mck,24/Nov/10 12:17,16/Apr/19 09:33,14/Jul/23 05:51,25/Nov/10 17:24,0.7.0 rc 2,,,,0,,,,,,"From mailing list http://thread.gmane.org/gmane.comp.db.cassandra.user/10385

ColumnFamilyOutputFormat will only write out one column
per key.

Alex Burkoff also reported this nearly two months ago, but nobody ever
replied...
 http://article.gmane.org/gmane.comp.db.cassandra.user/9325

has anyone any ideas? 
should it be possible to write multiple columns out?

This is very easy to reproduce. Use the contrib/wordcount example, with
OUTPUT_REDUCER=cassandra and in WordCount.java add at line 132

>              results.add(getMutation(key, sum));
> +            results.add(getMutation(new Text(""doubled""), sum*2));

Only the last mutation for any key seems to be written.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Nov/10 07:34;mck;CASSANDRA-1774.patch;https://issues.apache.org/jira/secure/attachment/12460435/CASSANDRA-1774.patch",,,,,,,,,,,,,,1.0,mck,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20306,,,Sat Dec 11 07:35:15 UTC 2010,,,,,,,,,,"0|i0g7bb:",92615,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"25/Nov/10 07:34;mck;The problem was the list of mutations inside the Map<ByteBuffer, Map<String, List<Mutation>>> that is sent to batch_mutate(..) isn't appended to, instead it was overridden.

This patch allows subsequent mutations (under the same columnFamily and key) to be appended to the existing list.;;;","25/Nov/10 17:24;jbellis;Thanks for the fix!  Committed w/ minor change to emphasize that subBatch is only created once.;;;","25/Nov/10 23:19;karthick;+1 on the patch.;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"debian initscript sometimes mistakenly thinks it failed, gives extraneous output",CASSANDRA-1772,12480761,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,thepaul,thepaul,thepaul,24/Nov/10 01:15,16/Apr/19 09:33,14/Jul/23 05:51,24/Nov/10 23:11,0.7.0 rc 2,,Packaging,,0,,,,,,"On my test systems, which are all relatively slow VMs, the Cassandra debian initscript usually thinks it fails to start, even though the startup was successful.  It appears that jsvc forks the daemon process and exits, and the initscript check for the running Cassandra service occurs before the new daemon is able to initialize itself and create its pidfile.

On top of that, most invocations end up spitting out a small amount of garbage from /bin/ps, in addition to the typical ""Stopping Cassandra: cassandra."" log messages one sees if verbose=yes in /etc/default/rcS.  This is not very flattering.

Finally, the initscript should provide the ""status"" command to meet current LSB spec. The functionality is mostly complete already anyway, and it can be quite useful.",Debian Squeeze with cassandra 0.7.0~rc1 on a slicehost VM,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Nov/10 01:31;thepaul;cass-add-status.patch.txt;https://issues.apache.org/jira/secure/attachment/12460327/cass-add-status.patch.txt","24/Nov/10 01:34;thepaul;cass-wait-for-start.patch.txt;https://issues.apache.org/jira/secure/attachment/12460328/cass-wait-for-start.patch.txt",,,,,,,,,,,,,2.0,thepaul,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20305,,,Sat Dec 11 07:35:11 UTC 2010,,,,,,,,,,"0|i0g7av:",92613,,urandom,,urandom,Low,,,,,,,,,,,,,,,,,"24/Nov/10 01:31;thepaul;cass-add-status.patch adds a slightly more robust is_running check (ensures the command line of the process $(cat $PIDFILE) matches what we expect, instead of just checking that there is a process with that number).

It also gets rid of the extraneous ""ps"" output to the terminal, and adds the ""status"" command to the initscript.;;;","24/Nov/10 01:34;thepaul;cass-wait-for-startup.patch.txt allows the ""start"" and ""restart"" actions to wait for up to 10 seconds (configurable) for the Cassandra service to start up fully.

This should eliminate the false failure messages.;;;","24/Nov/10 23:11;urandom;committed, w/ discussed (minor )changes.;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Script in debian/cassandra.in.sh is significantly out of date,CASSANDRA-1771,12480756,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,zznate,zznate,24/Nov/10 00:06,16/Apr/19 09:33,14/Jul/23 05:51,24/Nov/10 15:19,0.7.0 rc 2,,,,0,,,,,,Looks like the correct version is in TRUNK given the 0.7 environment property changes.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20304,,,Wed Nov 24 15:19:30 UTC 2010,,,,,,,,,,"0|i0g7an:",92612,,,,,Low,,,,,,,,,,,,,,,,,"24/Nov/10 15:19;urandom;I should have made the change in 0.7 and merged it forward to trunk/.  Thanks for the catch, this is fixed in r1038639.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cli help output should mention the need for semicolons,CASSANDRA-1770,12480726,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,xedin,thepaul,thepaul,23/Nov/10 20:15,16/Apr/19 09:33,14/Jul/23 05:51,24/Nov/10 16:25,0.7.0 rc 2,,Legacy/Tools,,0,,,,,,"When running cassandra-cli for the first time after upgrading beta3 -> rc1, I thought it was broken, because any command I typed (""?"", ""quit"", ""exit"", ""use system"", etc) just printed some empty space and sat there until I killed it. I didn't know it was a continuation prompt, or that semicolons were needed.

The startup banner message currently says:

{noformat}
Connected to: ""Test Cluster"" on localhost/9160
Welcome to cassandra CLI.

Type 'help' or '?' for help. Type 'quit' or 'exit' to quit.
{noformat}

I believe that the example commands should have semicolons after them, to let the user know about the change.

Also, a ""?"" by itself should probably not require a semicolon.",Debian squeeze with 0.7.0~rc1 package installed,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Nov/10 15:36;xedin;CASSANDRA-1770.patch;https://issues.apache.org/jira/secure/attachment/12460374/CASSANDRA-1770.patch",,,,,,,,,,,,,,1.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20303,,,Sat Dec 11 07:35:10 UTC 2010,,,,,,,,,,"0|i0g7a7:",92610,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"23/Nov/10 20:18;thepaul;Oh yeah, and when a semicolon isn't given, the continuation line should have a secondary prompt, like "">  "" or ""...  "" or something.;;;","24/Nov/10 16:25;jbellis;committed;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
UnsupportedOperationException in system_update_column_family,CASSANDRA-1768,12480629,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,tjake,tjake,23/Nov/10 02:14,16/Apr/19 09:33,14/Jul/23 05:51,23/Nov/10 17:09,0.7.0 rc 2,,,,0,,,,,,"During testing I hit this section of code:

CFMetaData.java:662
{code}
 // remove the ones leaving.
       for (ByteBuffer indexName : toRemove)
           column_metadata.remove(indexName);
{code}

but column_metadata is defined as:

{code}
       this.column_metadata = Collections.unmodifiableMap(column_metadata);
{code}

So remove() will throw an exception.

{code}
java.lang.UnsupportedOperationException
        at java.util.Collections$UnmodifiableMap.remove(Collections.java:1288)
        at org.apache.cassandra.config.CFMetaData.apply(CFMetaData.java:662)
        at org.apache.cassandra.db.migration.UpdateColumnFamily.<init>(UpdateColumnFamily.java:56)
        at org.apache.cassandra.thrift.CassandraServer.system_update_column_family(CassandraServer.java:863)
        at org.apache.cassandra.thrift.Cassandra$Processor$system_update_column_family.process(Cassandra.java:3592)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:2555)
        at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:680)
{code}

This was introduced by CASSANDRA-1715",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Nov/10 15:44;gdusbabek;ASF.LICENSE.NOT.GRANTED--v0-0001-fix-add-remove-index-bugs-in-CFMetadata.txt;https://issues.apache.org/jira/secure/attachment/12460274/ASF.LICENSE.NOT.GRANTED--v0-0001-fix-add-remove-index-bugs-in-CFMetadata.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20302,,,Sat Dec 11 07:35:20 UTC 2010,,,,,,,,,,"0|i0g79r:",92608,,,,,Normal,,,,,,,,,,,,,,,,,"23/Nov/10 16:23;tjake;+1, there is no chance it could be called concurrently correct?;;;","23/Nov/10 16:25;gdusbabek;correct. the mutation state is single-threaded.;;;","24/Nov/10 18:19;hudson;Integrated in Cassandra #606 (See [https://hudson.apache.org/hudson/job/Cassandra/606/])
    fix add/remove index bugs in CFMetadata. patch by gdusbabek, reviewed by tjake. CASSANDRA-1768
;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Streaming never makes progress,CASSANDRA-1766,12480607,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,brandon.williams,brandon.williams,22/Nov/10 20:25,16/Apr/19 09:33,14/Jul/23 05:51,27/Dec/10 22:47,0.6.9,0.7.0,,,0,,,,,,"I have a client that can never complete a bootstrap.  AC finishes, streaming begins.  Stream initiate completes, and the sources wait on the transfer to finish, but progress is never made on any stream.  Nodetool reports streaming is happening, the socket is held open, but nothing happens.",,eonnen,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Dec/10 20:02;jbellis;1766-keepalive.txt;https://issues.apache.org/jira/secure/attachment/12466831/1766-keepalive.txt","24/Nov/10 00:25;eonnen;CASSANDRA-1766.patch;https://issues.apache.org/jira/secure/attachment/12460325/CASSANDRA-1766.patch",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20301,,,Mon Dec 27 23:00:45 UTC 2010,,,,,,,,,,"0|i0g79b:",92606,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"24/Nov/10 00:25;eonnen;Not sure it's exactly related but I encountered an issue where a stream failed post AE and was just wedged with the following stack trace:

""STREAM-STAGE:1"" prio=10 tid=0x00007ff2440a5800 nid=0x3c3c in Object.wait() [0x00007ff24a21f000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        - waiting on <0x00007ff28884fad8> (a org.apache.cassandra.utils.SimpleCondition)
        at java.lang.Object.wait(Object.java:485)
        at org.apache.cassandra.utils.SimpleCondition.await(SimpleCondition.java:38)
        - locked <0x00007ff28884fad8> (a org.apache.cassandra.utils.SimpleCondition)
        at org.apache.cassandra.streaming.StreamOutManager.waitForStreamCompletion(StreamOutManager.java:164)
        at org.apache.cassandra.streaming.StreamOut.transferSSTables(StreamOut.java:138)
        at org.apache.cassandra.service.AntiEntropyService$Differencer$1.runMayThrow(AntiEntropyService.java:511)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)

We suspect that this occurred because the destination node was in drain state, although from reading the code it appears that any failed stream where the destination goes away would be susceptible to this issue. In this case, the StreamManager will never unblock making subsequent repairs to any node that was pending transfer impossible.

I've attached a patch that smooths out some possible streaming issues:

* Catches streaming errors. Near as I can tell, if an error occurred during streaming because the remote node went away, it would bubble all the way out of the executor and not even be logged. Worse, it would keep the current pending file wedged and never allow it to be cleared. This patch will remove the failed transfer when an IOException occurs. Could be it should be more general
* Allows for manual purging of pending files to a host via JMX which means un-sticking a wedged transfer no-longer requires a restart of that node. It also unfortunately results in removal of the file which could require anti-compaction again but this was the least painful path through the code.
* Corrects an unlikely but potentially fatal scenario where concurrent mutation/read from the file and fileMap references could result in dirty reads by making them concurrency-safe collections. Only way I could see this happening is if someone were to run repair multiple times in succession while streaming was happening. Unlikely but possible and the effects on unsafe map reads can result in a completely unresponsive JVM.


I'm not entirely sure this is the right thing to do but I though I'd float it out there for review. Whatever the correct fix, I think there needs to be a way to cancel pending streams so that they aren't stuck.;;;","24/Nov/10 17:18;jbellis;Thanks for the patch, Erik.  Moving followup on that to CASSANDRA-1438 to leave this for the ""streaming doesn't start at all"" problem.;;;","22/Dec/10 18:57;brandon.williams;What's happening here in my case, is there is a firewall/vpn between the bootstrapping node and the source.  The source takes a long time to anticompact, and in this time the tcp connection is killed due to being idle by the firewall.  This causes the stream initiate done message to never be received, because OutboundTcpConnection doesn't actually retry, it only buffers.;;;","22/Dec/10 19:01;jbellis;Should we just turn on socket keepalive?;;;","22/Dec/10 19:15;brandon.williams;That would hack around the problem, but the real issue is SID can get lost on the wire and hang the streaming process forever.  For 0.6, maybe keepalive is the least invasive thing to do.;;;","22/Dec/10 20:02;jbellis;keepalive patch against 0.6;;;","23/Dec/10 22:28;brandon.williams;+1 on keepalive;;;","27/Dec/10 22:47;jbellis;committed.

if you want you can open a new ticket for retrying Initiate if the message gets swallowed, as well as recovering if a source is correctly/incorrectly marked dead, but IMO those have very small benefit:effort ratios.;;;","27/Dec/10 23:00;hudson;Integrated in Cassandra-0.6 #36 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/36/])
    enable keepalive on intra-cluster sockets
patch by jbellis; reviewed by brandonwilliams for CASSANDRA-1766
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE on system_update_cf when adding an index to a column without existing metadata,CASSANDRA-1764,12480549,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,thobbs,thobbs,22/Nov/10 01:34,16/Apr/19 09:33,14/Jul/23 05:51,23/Nov/10 19:14,0.7.0 rc 2,,,,0,,,,,,"When trying to create a secondary index using system_update_column_family(), if you try to add an index on a column that does not already have an existing entry in the CfDef's column_metadata, a NullPointerException is thrown.

Looks like the logic in o.a.c.config.CFMetaData.apply() is faulty.  Specifically, creating a toUpdate Set (similar to the toAdd and toDelete) sets and using that for the loop ~ line 663 would fix this.",Cassandra 0.7 branch,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Nov/10 18:49;thobbs;1764-test-v2.txt;https://issues.apache.org/jira/secure/attachment/12460292/1764-test-v2.txt","22/Nov/10 01:38;thobbs;1764-test.txt;https://issues.apache.org/jira/secure/attachment/12460152/1764-test.txt",,,,,,,,,,,,,2.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20300,,,Sat Dec 11 07:35:19 UTC 2010,,,,,,,,,,"0|i0g78v:",92604,,,,,Normal,,,,,,,,,,,,,,,,,"23/Nov/10 17:04;gdusbabek;+1.  test passes after applying the fix for CASSANDRA-1768.;;;","23/Nov/10 17:13;gdusbabek;reopening to track committing the test.;;;","23/Nov/10 19:14;gdusbabek;committed.;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
UpdateKeyspace does not modify strategy or strategy_options (until restart),CASSANDRA-1762,12480464,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,19/Nov/10 22:54,16/Apr/19 09:33,14/Jul/23 05:51,23/Nov/10 19:29,0.7.0 rc 2,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Nov/10 17:25;jbellis;1762.txt;https://issues.apache.org/jira/secure/attachment/12460282/1762.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20299,,,Sat Dec 11 07:35:21 UTC 2010,,,,,,,,,,"0|i0g78f:",92602,,gdusbabek,,gdusbabek,Normal,,,,,,,,,,,,,,,,,"23/Nov/10 17:25;jbellis;Most of this patch is the encapsulation of ARS.replicationStrategy; the actual fix is in UpdateKeyspace and in ARS.createReplicationStrategy;;;","23/Nov/10 19:23;gdusbabek;+1.;;;","23/Nov/10 19:29;jbellis;committed;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indexes: Auto-generating the CFname may collide with user-generated names,CASSANDRA-1761,12480462,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jhermes,jhermes,jhermes,19/Nov/10 22:51,16/Apr/19 09:33,14/Jul/23 05:51,15/Mar/11 16:27,0.7.5,,,,0,,,,,,"{noformat}column_families:
  - name: CF
    comparator: BytesType
    column_metadata: 
      - name: foo
        index_name: 626172
        index_type: KEYS
      - name: bar
        index_type: KEYS{noformat}

Auto-generated versus user-supplied names collide in the YAML above. The code:
{code}cfname = parentCf + ""."" + (info.getIndexName() == null ? FBUtilities.bytesToHex(info.name) : info.getIndexName()){code}

From the first ColumnDefinition, we create cfname = ""CF.626172"" (from the fail clause of the ternany, user-supplied name)
From the second ColumnDefinition, we create cfname = ""CF.626172"" (from the pass clause of the ternary, we generate the name)

They're in hex form. This is possible, but fairly unlikely that someone will do this.",,,,,,,,,,,57600,57600,,0%,57600,57600,,,,,,,,,,,,,,"15/Mar/11 00:11;jhermes;1761-0.7.txt;https://issues.apache.org/jira/secure/attachment/12473640/1761-0.7.txt","15/Mar/11 00:00;jhermes;1761.txt;https://issues.apache.org/jira/secure/attachment/12473638/1761.txt","15/Mar/11 00:03;jhermes;repro.cli;https://issues.apache.org/jira/secure/attachment/12473639/repro.cli",,,,,,,,,,,,3.0,jhermes,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20298,,,Tue Mar 15 16:46:45 UTC 2011,,,,,,,,,,"0|i0g787:",92601,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"20/Nov/10 00:05;jhermes;CF.bar -> CF.626172.;;;","16/Dec/10 22:33;jbellis;This will require some re-organization to solve.  Currently, ColumnDefinition index_name is just copied from CfDef and may be null; final index name is determined by CFMetaData.newIndexMetadata, which has no context as to what other indexes exist in the CF.

What we should do is create the final index name at the CassandraServer level, and validate at that point that it does not cause conflicts with existing ones.  (Also: index_name and index_type fields of CD become final.)

(This lets us return appropriate InvalidRequest exceptions to the client instead of failing with an internal error, too.)

Then by the time we get to addIndex/newIndexMetadata, all we need to do is a final sanity check as a defense against users violating the one-schema-change-at-a-time rule.;;;","14/Mar/11 23:59;jhermes;Because the column_metadata has to be passed in full, it can be fully validated in ThriftValidation of the cf_def in the system_{update,add}_column_family and system_add_keyspace calls.

In related news, I also found out that we never validated CfDefs in system_update_column_family, so I'm surprised to say the least and glad it was found in an innocuous bug instead of something more serious.

As for the one-schema-change-at-a-time rule, this is now enforced by default with validateSchemaAgreement() calls in CassandraServer.;;;","15/Mar/11 00:03;jhermes;Also attaching repro script.

Without patch you should see an error trying to register an MBean twice, and the first index will no longer work.
After patch you should see an IRE.;;;","15/Mar/11 00:11;jhermes;1761.txt is for trunk.
1761-0.7.txt is for 0.7*.

(Slight difference in imports makes it not apply cleanly.);;;","15/Mar/11 16:27;jbellis;committed w/ some improvements:

- added a system test
- fix migration failure to throw InternalError back to client instead of InvalidRequestException (a bug found by the new test)
- use Set instead of List for .contains checks;;;","15/Mar/11 16:46;hudson;Integrated in Cassandra-0.7 #382 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/382/])
    validate index names
patch by jhermes and jbellis for CASSANDRA-1761
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JNA Native check can throw a NoSuchMethodError,CASSANDRA-1760,12480451,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,tjake,tjake,tjake,19/Nov/10 21:33,16/Apr/19 09:33,14/Jul/23 05:51,19/Nov/10 21:49,0.6.9,0.7.0 rc 1,,,0,,,,,,"Looks like older versions of JNA have a different Native.register() method

From IRC:
hi, i'm having trouble starting cassandra up...the error is very bizarre: java.lang.NoSuchMethodError: com.sun.jna.Native.register(Ljava/lang/String;)V",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/10 21:34;tjake;1760_v1.txt;https://issues.apache.org/jira/secure/attachment/12460055/1760_v1.txt",,,,,,,,,,,,,,1.0,tjake,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20297,,,Fri Nov 19 21:49:34 UTC 2010,,,,,,,,,,"0|i0g77z:",92600,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"19/Nov/10 21:43;tjake;it was jruby :(;;;","19/Nov/10 21:49;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Column MetaData: Index_name should not be allowed if index_type is not set.,CASSANDRA-1759,12480444,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jhermes,jhermes,jhermes,19/Nov/10 20:24,16/Apr/19 09:33,14/Jul/23 05:51,23/Nov/10 16:57,0.7.0 rc 2,,,,0,,,,,,"Giving an indexName starts the automatic index creation process.
If indexType is not also set, then that process barfs.
If a name is present, a type must be also (but the reverse is not necessarily true).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/10 22:39;jhermes;1759-2.txt;https://issues.apache.org/jira/secure/attachment/12460067/1759-2.txt","19/Nov/10 21:37;jhermes;1759.txt;https://issues.apache.org/jira/secure/attachment/12460056/1759.txt",,,,,,,,,,,,,2.0,jhermes,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20296,,,Sat Dec 11 07:35:14 UTC 2010,,,,,,,,,,"0|i0g77r:",92599,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"19/Nov/10 21:37;jhermes;Similar to the patch for CASSANDRA-1527, this validates the creation of ColumnDefs from YAML and then from thrift/avro.

For simplicity, both name and index need to be set or unset at the same time. I don't think anyone is complaining that it's too hard to introduce non-obvious bugs, so I'm being explicit here.;;;","19/Nov/10 21:57;jbellis;Looks like you got a little too clever with the xors -- index_type set but index_name not, is valid.;;;","19/Nov/10 22:39;jhermes;Whoops, I read CFMD:279 wrong. I thought it was a bug that we were auto-generating the name incorrectly. Back to previous logic.;;;","22/Nov/10 16:08;jhermes;CASSANDRA-1761 is the bug that I originally caught and is separate from this one.;;;","23/Nov/10 16:57;jbellis;committed;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DatabaseDescriptor static initialization circular reference when initialized through call to StorageService.instance.initClient ,CASSANDRA-1756,12480378,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,eonnen,eonnen,18/Nov/10 21:58,16/Apr/19 09:33,14/Jul/23 05:51,19/Nov/10 16:31,0.7.0 rc 1,,,,0,,,,,,"In trunk, attempting to invoke StorageService.instance.initClient results in an NPE due to static definition field ordering in StorageService and a circular reference from DatabaseDescriptor back into an uninitialized field (scheduledTasks). Changing the ordering of the static fields such that scheduledTasks is defined before the static partitioner fixes the issue.

I've also marked the scheduledTasks executor as final as it doesn't seem to make sense changing it.

All tests pass with this change locally.

I suspect this hasn't surfaced in tests as calling initServer first in the same JVM will allow later calls to initClient to see the correctly defined scheduledTasks fields.

I'm following the recommended way to do this from ClientOnlyExample, if this isn't the right way to initialize things let me know.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/10 14:34;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-fix-cicular-initialization-problem-between-StorageServ.txt;https://issues.apache.org/jira/secure/attachment/12460006/ASF.LICENSE.NOT.GRANTED--v1-0001-fix-cicular-initialization-problem-between-StorageServ.txt","19/Nov/10 14:34;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0002-StorageService.initClient-unit-test-that-never-finishe.txt;https://issues.apache.org/jira/secure/attachment/12460007/ASF.LICENSE.NOT.GRANTED--v1-0002-StorageService.initClient-unit-test-that-never-finishe.txt","19/Nov/10 14:34;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0003-DynamicEndpointSnitch-shouldn-t-update-if-SS-isn-t-ini.txt;https://issues.apache.org/jira/secure/attachment/12460008/ASF.LICENSE.NOT.GRANTED--v1-0003-DynamicEndpointSnitch-shouldn-t-update-if-SS-isn-t-ini.txt","18/Nov/10 21:59;eonnen;CS-1756;https://issues.apache.org/jira/secure/attachment/12459948/CS-1756",,,,,,,,,,,4.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20295,,,Fri Nov 19 20:05:42 UTC 2010,,,,,,,,,,"0|i0g773:",92596,,,,,Low,,,,,,,,,,,,,,,,,"18/Nov/10 22:01;eonnen;Attached;;;","18/Nov/10 22:57;eonnen;I forgot to add the stack trace resulting in the NPE in the original bug, sorry about that.

Exception in thread ""main"" java.lang.ExceptionInInitializerError
	at org.apache.cassandra.service.StorageService.<clinit>(StorageService.java:199)
	at io.eao.cassandra.http.Main.main(Main.java:24)
Caused by: java.lang.RuntimeException: java.lang.NullPointerException
	at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:396)
	... 2 more
Caused by: java.lang.NullPointerException
	at org.apache.cassandra.locator.DynamicEndpointSnitch.<init>(DynamicEndpointSnitch.java:74)
	at org.apache.cassandra.config.DatabaseDescriptor.createEndpointSnitch(DatabaseDescriptor.java:403)
	at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:275);;;","19/Nov/10 13:42;gdusbabek;That patch does fix the circular reference but exposes other problems in the fat client.  I've attached a test case that never finishes.  I suspect over time we've introduced changes that couple a few of the singleton services together in undesirable ways.  

I'll spend some time looking at it this morning and see if I can make sense of it.;;;","19/Nov/10 14:39;gdusbabek;0001 is Erik's patch
0002 is a test case that exposes an bug in the assumption DynamicEndpointSnitch makes about service initialization.
0003 fixes the bug.

Here is the chain of events.
StorageService.initClient() triggers static initializer in DD which instantiates a DynamicEndpointSnitch.  DES, as part of it's constructors schedule some tasks with SS.scheduledTasks which promptly starts executing them.  This causes MessagingService to initialize out of order which tries to access the not-fully-initialized SS, causing deadlock.  

SS cannot finish initializing until MS is done initializing, but MS is waiting on SS to do the same thing, near as I can tell.;;;","19/Nov/10 14:43;jbellis;+1;;;","19/Nov/10 16:31;gdusbabek;committed with a few changes.  It turns out System.exit() in a unit test is not good and I had to change the DES unit test to (rightfully) initialize StorageService.;;;","19/Nov/10 20:05;hudson;Integrated in Cassandra-0.7 #19 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/19/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
handle replica unavailability in index scan,CASSANDRA-1755,12480376,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,tjake,jbellis,jbellis,18/Nov/10 21:46,16/Apr/19 09:33,14/Jul/23 05:51,19/Nov/10 15:17,0.7.0 rc 1,,,,0,,,,,,StorageProxy.scan should return UnavailableException to clients under this condition,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/10 14:58;tjake;1755_v1.txt;https://issues.apache.org/jira/secure/attachment/12460013/1755_v1.txt",,,,,,,,,,,,,,1.0,tjake,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20294,,,Fri Nov 19 15:37:33 UTC 2010,,,,,,,,,,"0|i0g76v:",92595,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"19/Nov/10 15:17;jbellis;committed, thanks!;;;","19/Nov/10 15:37;hudson;Integrated in Cassandra-0.7 #17 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/17/])
    handle replica unavailability in index scan
patch by tjake; reviewed by jbellis for CASSANDRA-1755
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SSTable Import/Export doesn't support ExpiringColumns,CASSANDRA-1754,12480308,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,slebresne,slebresne,18/Nov/10 08:34,16/Apr/19 09:33,14/Jul/23 05:51,29/Nov/10 19:37,0.7.0 rc 2,,Legacy/Tools,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Nov/10 16:07;slebresne;0001-Support-Expiring-Columns-in-SSTableImport-Export.patch;https://issues.apache.org/jira/secure/attachment/12464872/0001-Support-Expiring-Columns-in-SSTableImport-Export.patch",,,,,,,,,,,,,,1.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20293,,,Sat Dec 11 07:35:11 UTC 2010,,,,,,,,,,"0|i0g76n:",92594,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"29/Nov/10 19:37;jbellis;committed;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SSTableImport adds columns marked for delete incorrectly in methods addToStandardCF & addToSuperCF,CASSANDRA-1753,12480245,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,bryantower,pushpinder.heer,pushpinder.heer,17/Nov/10 19:50,16/Apr/19 09:33,14/Jul/23 05:51,18/Nov/10 10:14,0.7.0 rc 1,,Legacy/Tools,,0,,,,,,"The logic for adding column families in the methods addToStandardCF & addToSuperCF appears to be backwards

            if (col.isDeleted) {
                cfamily.addColumn(path, hexToBytes(col.value), new TimestampClock(col.timestamp));
            } else {
                cfamily.addTombstone(path, hexToBytes(col.value), new TimestampClock(col.timestamp));
            }

",,bryantower,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,"17/Nov/10 22:26;bryantower;cassandra-0.7-1753.txt;https://issues.apache.org/jira/secure/attachment/12459838/cassandra-0.7-1753.txt",,,,,,,,,,,,,,1.0,bryantower,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20292,,,Fri Nov 19 15:12:34 UTC 2010,,,,,,,,,,"0|i0g76f:",92593,,slebresne,,slebresne,Normal,,,,,,,,,,,,,,,,,"17/Nov/10 22:26;bryantower;This patch adds a check to the SSTableImportTest to make sure that the retrieved Column is not deleted and fixes the bug in the SSTableImport.java by switching the logic on the isDeletedCheck.
The patch is for the cassandra-0.7 branch.;;;","18/Nov/10 00:21;bryantower;This bug prevents anyone importing to SSTables from JSON format.  All of the data that was exported shows up as tombstoned when trying to do an import on the 0.7 branch.  This patch is simple and is isolated to the SSTableImport;;;","18/Nov/10 08:23;slebresne;+1;;;","18/Nov/10 10:14;jbellis;committed, thanks!;;;","19/Nov/10 15:12;hudson;Integrated in Cassandra-0.7 #16 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/16/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
repair leaving FDs unclosed,CASSANDRA-1752,12480189,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,thobbs,jbellis,jbellis,17/Nov/10 09:15,16/Apr/19 09:33,14/Jul/23 05:51,01/Dec/10 22:42,0.6.9,,,,0,,,,,,"""We noticed that after a `nodetool repair` was ran, several of our nodes reported high disk usage; -- even one node hit 100% disk usage. After a restart of that node, disk usage drop instantly by 80 gigabytes -- well that was confusing, but we quickly formed the theory that Cassandra must of been holding open references to deleted file descriptors.

""Later, i found this node as an example, it is using about 8-10 gigabytes more than it should be -- 118 gigabytes reported by df, yet du reports only 106 gigabytes in the cassandra directory (nothing else on the mahcine). As you can see from the lsof listing, it is holding open FDs to files that no longer exist on the filesystem, and there are no open streams or as far as I can tell other reasons for the deleted sstable to be open.

""This seems to be related to running a repair, as we haven't seen it in any other situations before.""

A quick check of FileStreamTask shows that the obvious base is covered:
{code}
        finally
        {
            try
            {
                raf.close();
            }
            catch (IOException e)
            {
                throw new AssertionError(e);
            }
        }
{code}

So it seems that either the transfer loop is never finishing to get to that finally block (in which case why isn't it showing up in outbound streams?) or something else is the problem.",,johanoskarsson,mdennis,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Dec/10 04:23;thobbs;1752-0.6-v2.txt;https://issues.apache.org/jira/secure/attachment/12465023/1752-0.6-v2.txt","01/Dec/10 19:34;thobbs;1752-0.6-v3.txt;https://issues.apache.org/jira/secure/attachment/12465061/1752-0.6-v3.txt","29/Nov/10 23:58;thobbs;1752-0.6.txt;https://issues.apache.org/jira/secure/attachment/12464921/1752-0.6.txt",,,,,,,,,,,,3.0,thobbs,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20291,,,Wed Dec 01 23:59:27 UTC 2010,,,,,,,,,,"0|i0g767:",92592,,mdennis,,mdennis,Normal,,,,,,,,,,,,,,,,,"29/Nov/10 19:15;thobbs;This appears to be a large part of the problem: http://bugs.sun.com/view_bug.do?bug_id=4724038;;;","29/Nov/10 19:44;jbellis;But the unmapping is supposed to take place at finalization time, which is also when we actually issue the unlink.;;;","29/Nov/10 20:04;thobbs;Ah, when StreamOut.transferSSTables() blocks on waitForStreamCompletion(), the list of SSTableReaders is still in scope, so they aren't garbage collected.;;;","30/Nov/10 00:47;thobbs;The temporary files that are streamed get deleted whenever the node receives a message saying that the file was streamed successfully.  There isn't a need for SSTableReaders at all in this case; only the names of the files produced by the anticompaction are needed for streaming.  The fix here is to to simply close the SSTableWriter without opening an SSTableReader after anticompaction and return a the list of filenames for use with streaming instead.  This way, if waitForStreamCompletion() hangs indefinitely, there are no SSTRs around to keep the FDs open.;;;","30/Nov/10 04:37;mdennis;+1 

(but CompactionManager.java:355-358 are superfluous given the loop check after that statement and the added return at the end of the method);;;","30/Nov/10 18:51;jbellis;can't we leave the timing and logging code inside the Helper compaction method to reduce duplication in its callers?;;;","30/Nov/10 18:52;jbellis;where do the temporary files get deleted post-stream with this patch?;;;","01/Dec/10 01:53;thobbs;Files are deleted post-stream in StreamOutManager.finishAndStartNext().  I'll clean up the code a bit and post a new patch shortly.;;;","01/Dec/10 04:23;thobbs;Cleaned up version of patch attached.;;;","01/Dec/10 17:51;jbellis;committed;;;","01/Dec/10 18:01;jbellis;reverted -- tests fail to build;;;","01/Dec/10 18:29;hudson;Integrated in Cassandra-0.6 #13 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/13/])
    avoid opening readers on anticompacted to-be-streamed temporary files
patch by thobbs; reviewed by mdennis and jbellis for CASSANDRA-1752
;;;","01/Dec/10 19:34;thobbs;Unit tests are fixed in the v3 patch.;;;","01/Dec/10 22:42;jbellis;re-committed, thanks;;;","01/Dec/10 23:59;hudson;Integrated in Cassandra-0.6 #14 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/14/])
    avoid opening readers on anticompacted to-be-streamed temporary files
patch by thobbs; reviewed by mdennis and jbellis for CASSANDRA-1752
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Streaming should hold a reference to the source SSTR to prevent GC races,CASSANDRA-1749,12479993,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,stuhood,stuhood,stuhood,15/Nov/10 20:20,16/Apr/19 09:33,14/Jul/23 05:51,18/Nov/10 01:37,0.7.0 rc 1,,,,0,,,,,,"An SSTable waiting to be streamed will be GC'd and deleted from disk if there are no references being held to its SSTableReader. While streaming an SSTable, we should hold an SSTR reference.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Nov/10 21:10;stuhood;0001-Add-SSTable-reference-to-PendingFile-to-prevent-GC-of-.txt;https://issues.apache.org/jira/secure/attachment/12459636/0001-Add-SSTable-reference-to-PendingFile-to-prevent-GC-of-.txt",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20290,,,Thu Nov 18 03:16:35 UTC 2010,,,,,,,,,,"0|i0g75j:",92589,,jbellis,,jbellis,Critical,,,,,,,,,,,,,,,,,"15/Nov/10 22:03;jbellis;doesn't passing sstable make the descriptor param redundant?;;;","15/Nov/10 22:25;stuhood;> doesn't passing sstable make the descriptor param redundant?
There is another constructor that passes only the descriptor.;;;","18/Nov/10 01:37;jbellis;committed;;;","18/Nov/10 03:16;hudson;Integrated in Cassandra-0.7 #14 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/14/])
    retain reference to PendingFile sstables
patch by Stu Hood; reviewed by jbellis for CASSANDRA-1749
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flush before repair,CASSANDRA-1748,12479991,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,thobbs,stuhood,stuhood,15/Nov/10 20:04,16/Apr/19 09:33,14/Jul/23 05:51,19/Dec/10 03:33,0.7.0 rc 3,,,,0,,,,,,"We don't currently flush before beginning a validation compaction, meaning that depending on the state of the memtables, we might end up with content on disk that is as different as a single memtable can make it (potentially, very different).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Dec/10 22:23;thobbs;1748-trunk.txt;https://issues.apache.org/jira/secure/attachment/12466172/1748-trunk.txt","13/Dec/10 20:02;thobbs;1748.txt;https://issues.apache.org/jira/secure/attachment/12466166/1748.txt",,,,,,,,,,,,,2.0,thobbs,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20289,,,Mon Dec 20 04:46:49 UTC 2010,,,,,,,,,,"0|i0g75b:",92588,,stuhood,,stuhood,Normal,,,,,,,,,,,,,,,,,"13/Dec/10 20:02;thobbs;Attached patch flushes inside of CompactionManager's doValidationCompaction() so that both the repairing node and its neighbors will flush before building Merkle trees.;;;","13/Dec/10 21:39;stuhood;This fails to build against trunk, but looks reasonable otherwise.;;;","13/Dec/10 22:23;thobbs;1748-trunk.txt should apply against trunk.;;;","13/Dec/10 22:46;jbellis;would switching validation to use range scans be a better solution?  that way you would automatically get everything in the memtables, without having to flush-and-re-scan.;;;","15/Dec/10 00:44;thobbs;Do you mean something like using CFS.getRangeSlice()?  The main problem I see is you can't iterate over the rows one-by-one with that in its current state as it returns a List; I'm not familiar with how that works, so I don't know how easy it would be to make an Iterator version.  Or is there something else you were referring to?;;;","15/Dec/10 00:51;jbellis;CFS.gRS is a pretty thin layer over RowIterator.;;;","15/Dec/10 01:01;thobbs;Ah, right, I see that now.  I don't see why it couldn't be done, then.  Do you want me to go ahead with that (and open a new ticket)?;;;","15/Dec/10 01:47;stuhood;> would switching validation to use range scans be a better solution?
We don't have a way to send a memtable to another node, so if we included it in what we validate, it might not actually end up being sent to the other node unless it was flushed at some point. So I don't think doing this would buy us much, and it is a significantly larger change. The goal is really just to repair at a ""point in time"", and flushing before repair gives us that, imo.;;;","19/Dec/10 03:33;jbellis;committed;;;","20/Dec/10 04:46;hudson;Integrated in Cassandra-0.7 #97 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/97/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
truncate is not secondary index-aware,CASSANDRA-1747,12479981,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,15/Nov/10 17:44,16/Apr/19 09:33,14/Jul/23 05:51,17/Nov/10 23:10,0.7.0 rc 1,,Feature/2i Index,,0,,,,,,we need to drop the index data files as well as the base CF ones on truncate.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Nov/10 22:05;jbellis;1747-v2.txt;https://issues.apache.org/jira/secure/attachment/12459834/1747-v2.txt","17/Nov/10 19:39;jbellis;1747.txt;https://issues.apache.org/jira/secure/attachment/12459818/1747.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20288,,,Thu Nov 18 00:16:35 UTC 2010,,,,,,,,,,"0|i0g753:",92587,,gdusbabek,,gdusbabek,Normal,,,,,,,,,,,,,,,,,"17/Nov/10 19:39;jbellis;patch that marks index files compacted as well as base CF.

should be safe b/c we flush index memtables at the same time as base data (while holding the flush lock).;;;","17/Nov/10 21:16;gdusbabek;Will this futz with the liveSize information in SSTableTracker?;;;","17/Nov/10 21:19;jbellis;in the sense that markCompacted updates liveSize, yes;;;","17/Nov/10 21:54;gdusbabek;right, but you're sending it sstables that it doesn't track that belong to the indexes.  Won't that give an incorrect size?;;;","17/Nov/10 22:05;jbellis;ah, you are right.  it needs to markCompacted each group w/ the cfs it came from.  v2 attached.;;;","17/Nov/10 22:21;gdusbabek;+1 on v2.;;;","17/Nov/10 23:10;jbellis;committed, thanks;;;","18/Nov/10 00:16;hudson;Integrated in Cassandra-0.7 #13 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/13/])
    truncate includes secondary indexes
patch by jbellis; reviewed by gdusbabek for CASSANDRA-1747
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
index scan should treat not-present columns as not matching index expressions,CASSANDRA-1745,12479922,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,14/Nov/10 18:49,16/Apr/19 09:33,14/Jul/23 05:51,17/Nov/10 20:11,0.7.0 rc 1,,,,0,,,,,,"As reported on the mailing list,

{code}
I created a column family and added index on column A,B,C. 

Now I insert three rows. 

row1 : A=123, B=456, C=789 
row2 : A=123, C=789 
row3 : A=123, B=789, C=789 

Now if I perform an indexed query for A=123 and B=456, both row1 and row2 are returned. 
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Nov/10 18:53;jbellis;1745.txt;https://issues.apache.org/jira/secure/attachment/12459567/1745.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20287,,,Thu Nov 18 00:16:35 UTC 2010,,,,,,,,,,"0|i0g74n:",92585,,stuhood,,stuhood,Normal,,,,,,,,,,,,,,,,,"17/Nov/10 19:55;stuhood;+1
null is a tricky beast, but since we don't have a ""not equal"" expression yet, this appears to be the correct behaviour.;;;","17/Nov/10 20:11;jbellis;committed;;;","18/Nov/10 00:16;hudson;Integrated in Cassandra-0.7 #13 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/13/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
clear endpoint cache after updating keyspace metadata,CASSANDRA-1741,12479850,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,13/Nov/10 04:51,16/Apr/19 09:33,14/Jul/23 05:51,15/Nov/10 14:54,0.7.0 rc 1,,,,0,,,,,,"If the replication factor or strategy (or options) change, we need to clear the cache so it can be repopulated with the new options. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Nov/10 04:51;jbellis;1741.txt;https://issues.apache.org/jira/secure/attachment/12459516/1741.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20285,,,Mon Nov 15 14:54:37 UTC 2010,,,,,,,,,,"0|i0g73r:",92581,,gdusbabek,,gdusbabek,Low,,,,,,,,,,,,,,,,,"15/Nov/10 14:41;gdusbabek;+1;;;","15/Nov/10 14:54;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bootstrapping nodes do not reject range slice requests,CASSANDRA-1739,12479839,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,tilgovi,tilgovi,tilgovi,12/Nov/10 23:00,16/Apr/19 09:33,14/Jul/23 05:51,14/Nov/10 12:33,0.6.9,,,,0,,,,,,ReadVerbHandler rejects the request if the node is bootstrapping. I think RangeSliceVerbHandler should probably do the same.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Nov/10 23:01;tilgovi;0001-reject-range-req-if-bootstrapping-CASSANDRA-1739.patch;https://issues.apache.org/jira/secure/attachment/12459494/0001-reject-range-req-if-bootstrapping-CASSANDRA-1739.patch",,,,,,,,,,,,,,1.0,tilgovi,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20284,,,Sun Nov 14 12:33:13 UTC 2010,,,,,,,,,,"0|i0g73b:",92579,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"13/Nov/10 01:58;jbellis;Are you seeing other nodes route range scans to the bootstrapping node, or is this just covering your bases?;;;","13/Nov/10 02:36;tilgovi;Covering bases.
I'm pretty new to the codebase. What avoids this happening normally? I guess the node is not considered a ""live endpoint"" while bootstrapping?

Similar code is in the ReadVerbHandler and StorageProxy's readLocal(). I wasn't sure what was redundant and what wasn't.;;;","14/Nov/10 12:33;jbellis;committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConcurrentModificationException when updating column family metadata,CASSANDRA-1736,12479813,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,bterm,bterm,12/Nov/10 17:31,16/Apr/19 09:33,14/Jul/23 05:51,23/Nov/10 15:26,0.7.0 rc 1,,,,0,,,,,,"From cli
> update column family Tweet with column_metadata=[{column_name:state, validation_class:UTF8Type}]
> set Tweet [x][state] = TX
> get Tweet where state = TX
No index columns present
> update column family Tweet with column_metadata=[{column_name:state, index_type:0, validation_class:UTF8Type}]
null
> list Tweet
java.net.SocketException: Broken pipe


ERROR [MigrationStage:1] 2010-11-12 09:12:28,618 AbstractCassandraDaemon.java (line 90) Fatal exception in thread Thread[Migra$
java.util.ConcurrentModificationException
        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)
        at java.util.HashMap$KeyIterator.next(HashMap.java:828)
        at org.apache.cassandra.db.ColumnFamilyStore.snapshot(ColumnFamilyStore.java:1495)
        at org.apache.cassandra.db.migration.UpdateColumnFamily.beforeApplyModels(UpdateColumnFamily.java:76)
        at org.apache.cassandra.db.migration.Migration.apply(Migration.java:109)
        at org.apache.cassandra.thrift.CassandraServer$2.call(CassandraServer.java:672)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
ERROR [pool-1-thread-5] 2010-11-12 09:12:28,636 CustomTThreadPoolServer.java (line 175) Thrift error occurred during processin$
org.apache.thrift.protocol.TProtocolException: Required field 'why' was not present! Struct: InvalidRequestException(why:null)
        at org.apache.cassandra.thrift.InvalidRequestException.validate(InvalidRequestException.java:340)
        at org.apache.cassandra.thrift.InvalidRequestException.write(InvalidRequestException.java:309)
        at org.apache.cassandra.thrift.Cassandra$system_update_column_family_result.write(Cassandra.java:26764)
        at org.apache.cassandra.thrift.Cassandra$Processor$system_update_column_family.process(Cassandra.java:3605)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:2555)
        at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Nov/10 02:41;jbellis;1736-v2.txt;https://issues.apache.org/jira/secure/attachment/12459872/1736-v2.txt","14/Nov/10 19:33;jbellis;1736.txt;https://issues.apache.org/jira/secure/attachment/12459568/1736.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20282,,,Sat Nov 20 03:12:00 UTC 2010,,,,,,,,,,"0|i0g72n:",92576,,gdusbabek,,gdusbabek,Normal,,,,,,,,,,,,,,,,,"13/Nov/10 03:06;jbellis;This is a regression caused by treating the compaction marker as a component (CASSANDRA-1471, CASSANDRA-1544).  The CME comes when compaction modifies the components set while snapshot is iterating over them; since snapshot begins by flushing, this is actually fairly likely to happen (especially with non-JNA snapshots, i.e., slow ones).

IMO the best fix to this would be to stop treating the compaction marker as a component and make the components set Unmodifiable to close off that avenue of bugs in the future.;;;","13/Nov/10 03:15;jbellis;One reason I don't think compaction marker belongs in components is that as this bug highlights, we could end up with the marker as part of a snapshot.  Which would cause a more subtle bug.  Here is the order of events:

{code}
My CFS has sstables A B C.
Flush introduces sstable D.
We begin compacting A B C D.
We begin iterating A B C D for snapshot.
During the iteration, compaction finishes producing sstable E.  A B C D are marked compacted.
snapshot finishes, with (say) C D marked compacted.
{code}

Now, the sstable tracker guarantees that we see a consistent view of the sstables -- we will either exactly one of  {A B C D} or {E}.  But by mixing the compaction marker in as a component we now have a snapshot that implies that A and B were live but C and D were compacted, and if we take that snapshot as-is and promote it to live data, when we restart Cassandra will purge C and D since they were marked compacted.

We could band-aid this in a number of ways but I think the less fragile approach is to treat the compaction marker as something separate from components.;;;","14/Nov/10 19:33;jbellis;patch along the above lines;;;","15/Nov/10 18:39;stuhood;This patch adds the isCompacted method, but it isn't called anywhere, which raises the question: who might call that method in the future, or care that an SSTable is compacted?

Also, SSTable.delete() will fail if the SSTable is not marked compacted, for instance if the second branch of the 'if' in CFStore is triggered.;;;","15/Nov/10 19:49;jbellis;bq. This patch adds the isCompacted method, but it isn't called anywhere

I will remove it.

bq. SSTable.delete() will fail if the SSTable is not marked compacted

If you're referring to 

{code}
            FileUtils.delete(desc.filenameFor(Component.COMPACTED_MARKER));
{code}

I changed that to not use deleteWithConfirm for exactly that reason.;;;","18/Nov/10 02:37;jbellis;v2 removes boolean and replaces with assert that we're not instantiating a compacted SSTableReader;;;","19/Nov/10 17:19;gdusbabek;+1;;;","19/Nov/10 20:05;hudson;Integrated in Cassandra-0.7 #19 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/19/])
    fix race between snapshot andcompaction
patch by jbellis; reviewed by gdusbabek for CASSANDRA-1736
;;;","20/Nov/10 03:12;hudson;Integrated in Cassandra-0.7 #22 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/22/])
    avoid attempting to delete compacted sstables twice on restart
patch by jbellis to fix regression introduced by CASSANDRA-1736
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New subcolumn resurrect deleted subcolumns,CASSANDRA-1734,12479769,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,wenjun@appoji.com,wenjun@appoji.com,12/Nov/10 03:43,16/Apr/19 09:33,14/Jul/23 05:51,15/Nov/10 14:24,0.7.0 rc 1,,,,0,,,,,,"The followings are the conversation I had with jbellis on IRC:
have a question on deletion of super column....deletion of SuperColumn works fine....but when I add any new sub-column, the 'old' sub-columns reappear..how can I tell they are tombstoned
the 'old' sub-columns still have all the data in place, including timestamp
and the timestamp is older than markDeletaAt of the super column
<jbellis> appoji: right.  that is expected.  the subcolumns won't be tombstoned, the supercolumn tombstone should supress them.
<jbellis> shouldn't*
<jbellis> appoji: but writing a new subcolumn should resurrect the others.  can you submit a test case?

I am able to reproduce it with cli as followings:

1.  create column family UserGroup with column_type = 'Super' and gc_grace=5 and comparator = 'AsciiType' and subcomparator = 'BytesType'
2. set UserGroup ['100'] ['memberList']['paul']=''
3. del UserGroup ['100'] ['memberList']
4. wait for 5 seconds and ""list UserGroup"" does not return any data, which is correct
5. set UserGroup ['100'] ['memberList']['andrew']=''
6. now ""list UserGroup"" returns 2 sub-columns ('paul' and 'andrew')

here is server log for step 6:

DEBUG 22:40:52,378 range_slice
DEBUG 22:40:52,379 RangeSliceCommand{keyspace='Appoji', column_family='UserGroup
1', super_column=null, predicate=SlicePredicate(slice_range:SliceRange(start:80
01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 65 5F 73 6C 69 63 65 73 00 00 00 28
 0C 00 01 0B 00 03 00 00 00 0A 55 73 65 72 47 72 6F 75 70 31 00 0C 00 02 0C 00 0
2 0B 00 01 00 00 00 00, finish:80 01 00 01 00 00 00 10 67 65 74 5F 72 61 6E 67 6
5 5F 73 6C 69 63 65 73 00 00 00 28 0C 00 01 0B 00 03 00 00 00 0A 55 73 65 72 47
72 6F 75 70 31 00 0C 00 02 0C 00 02 0B 00 01 00 00 00 00 0B 00 02 00 00 00 00, r
eversed:false, count:100)), range=[0,0], max_keys=100}
DEBUG 22:40:52,380 restricted single token match for query [0,0]
DEBUG 22:40:52,381 local range slice
DEBUG 22:40:52,382 collecting 0 of 100: SuperColumn(memberList -delete at 128953
3231194000- [616e64726577:false:0@1289533250404000,7061756c:false:0@128953321401
5000,])
DEBUG 22:40:52,383 scanned DecoratedKey(9839004666223652184852086760848439587, 3
13030)

",Windows7-64,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Nov/10 09:36;jbellis;1734.txt;https://issues.apache.org/jira/secure/attachment/12459550/1734.txt","15/Nov/10 14:08;tjake;1734_v2.txt;https://issues.apache.org/jira/secure/attachment/12459603/1734_v2.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19366,,,Mon Nov 15 14:24:15 UTC 2010,,,,,,,,,,"0|i0g727:",92574,,tjake,,tjake,Low,,,,,,,,,,,,,,,,,"14/Nov/10 09:36;jbellis;patch to add removeDeleted call to getRangeSlices (list) as it is for getColumnFamily (get);;;","15/Nov/10 14:08;tjake;The patch doesn't account for already deleted rows, where cf if null.

I've addressed this in the next patch, +1 with this change.;;;","15/Nov/10 14:24;jbellis;committed v2;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
get_range_slices doesn't return key from start_key in KeyRange any more,CASSANDRA-1733,12479768,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,tjake,arya,arya,12/Nov/10 02:51,16/Apr/19 09:33,14/Jul/23 05:51,13/Nov/10 03:19,0.7.0 rc 1,,,,0,,,,,,"The following is a test case which used to work for me before, but after upgrading to trunk it fails:

-Insert 50 or so keys to StandardByUUID1 CF in Keyspace1
-Try using get_range_slices with a KeyRange that has one of those keys you inserted earlier as its start_key with a count of 20

You will get 20 rows, but you won't get the row with specified start_key

Expected Result: you should get 20 rows back with the specified start_key as one of the rows

I am suing Random Partitioner with RF2 and CL1. I understand that Random Partitioner will not give you keys in order, but the behavior before at least returned a random subset including the row with specified start_key.

Please investigate.

-Arya

","Cent OS 5.4
Cassandra Trunk from November 11th at 2pm",tjake,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Nov/10 03:13;tjake;1733_v1.txt;https://issues.apache.org/jira/secure/attachment/12459515/1733_v1.txt",,,,,,,,,,,,,,1.0,tjake,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20281,,,Sat Nov 13 16:26:08 UTC 2010,,,,,,,,,,"0|i0g71z:",92573,,,,,Normal,,,,,,,,,,,,,,,,,"12/Nov/10 17:30;stuhood;The ranges to query are properly generated in StorageProxy:
{quote}
[228...,0] are [[228...,333...], (333...,0]]
{quote}

But ColumnFamilyStore.getRangeSlice creates DecoratedKeys from the tokens of the Range with null keys: null keys now sort after valid keys, so the first key isn't properly included.;;;","12/Nov/10 17:33;stuhood;Also, we need a testcase this time.;;;","12/Nov/10 19:08;jbellis;I would think it would make more sense for null keys to sort before valid keys, so that a token X would match all rows with that token rather than none.;;;","12/Nov/10 22:11;tjake;Why do we have a test ColumnFamilyStoreTest:testSkipStartKey() which validates the first key isn't included? ;;;","12/Nov/10 22:37;arya;I traced it to revision 906272 which is a result of CASSANDRA-759. Although, it says it will skip the start_key and that was committed in Feb, but I have been using Cassandra Trunk since April and it always worked the opposite. !!;;;","13/Nov/10 01:51;jbellis;bq. Why do we have a test ColumnFamilyStoreTest:testSkipStartKey() which validates the first key isn't included? 

A Range object (which Hadoop splits generate) is start-exclusive.  A Bounds object (which normal user scan queries generate) is start-inclusive.;;;","13/Nov/10 03:11;tjake;Patch includes fix and test case.

ColumnFamilyStore creates a startWith and stopAt DK with null key. 
This will need to be addressed in CASSANDRA-1034

1) For range queries, changed the check to skip start key to be only on token.  

2) Since null key sorts last,  I changed startWith to use a empty byte buffer as key which sorts before all other keys.

;;;","13/Nov/10 03:19;jbellis;This has passed my level of comfort for 0.7.0.  Fixed by reverting CASSANDRA-1720.  Let's fix it ""right"" for CASSANDRA-1034 in trunk and possibly backport to 0.7.1 later.;;;","13/Nov/10 16:26;tjake;Yeah, that's good.  You may want to keep add the unit test so we have one here on out;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nodetool move throws Assertion Error,CASSANDRA-1732,12479762,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,tjake,arya,arya,12/Nov/10 00:34,16/Apr/19 09:33,14/Jul/23 05:51,19/Nov/10 14:34,0.7.0 rc 1,,,,0,,,,,,"Started from a clean slate 3 node cluster. I first started 1 node and bootstrapped the second and third node into the cluster. I created some Keyspaces and inserted some test data, I ended up with this ring:

[agoudarzi@cas-test1 ~]$ nodetool --host localhost ring
Address         Status State   Load            Token                                       
                                       142685436305748685139980028665762955655    
10.50.26.133    Up     Normal  160.51 KB       57614844575514069274136376807820902791      
10.50.26.134    Up     Normal  160.51 KB       100150140440631377207058202736791929223     
10.50.26.132    Up     Normal  165.48 KB       142685436305748685139980028665762955655     

Now I wanted to test manual moving nodes to balanced tokens:
stage1:agoudarzi:~:$ python test.py 3
56713727820156410577229101238628035242
113427455640312821154458202477256070484
170141183460469231731687303715884105727

So I did nodetool move on 10.50.26.132:
[agoudarzi@cas-test1 ~]$ nodetool --host localhost move 56713727820156410577229101238628035242

All went fine. 
[agoudarzi@cas-test1 ~]$ nodetool --host localhost ring
Address         Status State   Load            Token                                       
                                       100150140440631377207058202736791929223    
10.50.26.132    Up     Normal  603.03 KB       56713727820156410577229101238628035242      
10.50.26.133    Up     Normal  15.18 MB        57614844575514069274136376807820902791      
10.50.26.134    Up     Normal  15.19 MB        100150140440631377207058202736791929223     

Now I wanted to move the second node 10.50.26.133:

[agoudarzi@cas-test2 ~]$ nodetool --host localhost move 113427455640312821154458202477256070484
Exception in thread ""main"" java.lang.AssertionError
	at org.apache.cassandra.service.StorageService.getLocalToken(StorageService.java:1128)
	at org.apache.cassandra.service.StorageService.startLeaving(StorageService.java:1527)
	at org.apache.cassandra.service.StorageService.move(StorageService.java:1666)
	at org.apache.cassandra.service.StorageService.move(StorageService.java:1641)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:111)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:45)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:226)
	at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)
	at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:251)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:857)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:795)
	at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1449)
	at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:90)
	at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1284)
	at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1382)
	at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:807)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:322)
	at sun.rmi.transport.Transport$1.run(Transport.java:177)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.Transport.serviceCall(Transport.java:173)
	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:553)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:808)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:667)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)

 I am attacking the logs for my 3 nodes. For your reference I refer to these IPs as these nodes:

node1: 10.50.26.132
node2: 10.50.26.133
node3: 10.50.26.134

I have seen similar exception being thrown in CASSANDRA-1670.

Please investigate.

-Arya
","CentOS 5.4
Cassandra Trunk SVN Revision #1034158",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/10 01:52;tjake;1732_v1.txt;https://issues.apache.org/jira/secure/attachment/12459963/1732_v1.txt","12/Nov/10 00:36;arya;node1.log;https://issues.apache.org/jira/secure/attachment/12459409/node1.log","12/Nov/10 00:36;arya;node2.log;https://issues.apache.org/jira/secure/attachment/12459410/node2.log","12/Nov/10 00:36;arya;node3.log;https://issues.apache.org/jira/secure/attachment/12459411/node3.log",,,,,,,,,,,4.0,tjake,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20280,,,Fri Nov 19 15:12:34 UTC 2010,,,,,,,,,,"0|i0g71r:",92572,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"14/Nov/10 18:54;jbellis;Does this work on 0.6.8?;;;","19/Nov/10 01:52;tjake;Attached fix.

in 0.7 bootstrapping a clean node takes a slightly different code path due to the fact that there are no non-system CFs defined.  This new code wasn't setting the nodes token.

This seems to be the same issue as CASSANDRA-1738;;;","19/Nov/10 14:34;jbellis;committed, combining tokenMetadata_.updateNormalToken + SystemTable.updateToken into SS.setToken call;;;","19/Nov/10 15:12;hudson;Integrated in Cassandra-0.7 #16 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/16/])
    fix for bootstrap when no non-system tables are defined
patch by tjake; reviewed by jbellis for CASSANDRA-1732
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"cli ""list"" gives unhelpful error when not authenticated",CASSANDRA-1731,12479746,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,xedin,jbellis,jbellis,11/Nov/10 20:32,16/Apr/19 09:33,14/Jul/23 05:51,11/Nov/10 21:03,0.7.0 rc 1,,Legacy/Tools,,0,,,,,,"{code}
[default@unknown] list Userline
Using default limit of 100
null
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Nov/10 20:44;xedin;CASSANDRA-1731.patch;https://issues.apache.org/jira/secure/attachment/12459379/CASSANDRA-1731.patch",,,,,,,,,,,,,,1.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20279,,,Thu Nov 11 21:03:39 UTC 2010,,,,,,,,,,"0|i0g71j:",92571,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"11/Nov/10 21:03;jbellis;committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fat clients are never removed,CASSANDRA-1730,12479741,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,11/Nov/10 19:17,16/Apr/19 09:33,14/Jul/23 05:51,03/Dec/10 21:05,0.6.9,,,,0,,,,,,"After a failed bootstrap, these lines repeat infinitely:

 INFO [Timer-0] 2010-11-11 01:58:32,708 Gossiper.java (line 406) FatClient /10.104.73.164 has been silent for 3600000ms, removing from gossip
 INFO [GMFD:1] 2010-11-11 01:59:03,685 Gossiper.java (line 591) Node /10.104.73.164 is now part of the cluster

Changing the IP on the node but using the same token causes a conflict, requiring either a full cluster restart or changing the token.  This is especially easy to run into in practice in a virtual environment such as ec2.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Dec/10 20:18;brandon.williams;1730.txt;https://issues.apache.org/jira/secure/attachment/12465270/1730.txt",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20278,,,Sat Dec 11 07:35:12 UTC 2010,,,,,,,,,,"0|i0g71b:",92570,,,,,Normal,,,,,,,,,,,,,,,,,"23/Nov/10 19:50;jbellis;is this related to CASSANDRA-1518?;;;","23/Nov/10 19:53;brandon.williams;I don't think so since this was encountered on 0.6;;;","03/Dec/10 20:18;brandon.williams;The problem here is that node A removes the fat client, but node B's timeout hasn't been exceeded yet, so it still has it.  RING_DELAY elapses, and B propagates the fat client back to A, and when B does remove it A will do the inverse.  Part of the problem here appears to be that the FD is adaptive and RING_DELAY is static, and since both occurrences of this I know of have been on ec2, I suspect somehow the difference between all nodes marking the client as dead has exceeded RING_DELAY.  Since by way of CASSANDRA-644 the 1h timeout for fatclients appears to have been chosen arbitrarily, I think we should reduce this to RING_DELAY / 2, giving justRemovedEndpoints plenty of leeway to prevent re-gossiping the fatclient to other nodes that have already removed it and evicted it from jRE.  Trivial patch attached. ;;;","03/Dec/10 20:22;jbellis;+1;;;","03/Dec/10 21:05;brandon.williams;Committed.;;;","03/Dec/10 22:01;hudson;Integrated in Cassandra-0.6 #16 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/16/])
    Reduce FatClient timeout to RING_DELAY / 2.  Patch by brandonwilliams, reviewed by jbellis for CASSANDRA-1730.
;;;","07/Dec/10 20:30;hudson;Integrated in Cassandra #615 (See [https://hudson.apache.org/hudson/job/Cassandra/615/])
    ;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix misuse of DataOutputBuffer.getData in AntiEntropyService,CASSANDRA-1729,12479731,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,stuhood,stuhood,stuhood,11/Nov/10 17:29,16/Apr/19 09:33,14/Jul/23 05:51,19/Nov/10 17:06,0.6.9,,,,0,,,,,,"As reported by Schubert Zhang, AntiEntropyService is ignoring the length of the input buffer.
{code:java}
byte[] rowhash = FBUtilities.hash(""SHA-256"", row.key.key.getBytes(), row.buffer.getData());
{code}

While this isn't affecting our accuracy, it would break validation if we started reusing buffers in CompactedRow. This issue has already been fixed in 0.7.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Nov/10 17:38;stuhood;0001-Remove-varargs-from-FBUtilities.hash-and-correctly-use.txt;https://issues.apache.org/jira/secure/attachment/12459367/0001-Remove-varargs-from-FBUtilities.hash-and-correctly-use.txt",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20277,,,Fri Nov 19 17:55:58 UTC 2010,,,,,,,,,,"0|i0g713:",92569,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"19/Nov/10 17:06;jbellis;committed;;;","19/Nov/10 17:55;hudson;Integrated in Cassandra-0.6 #9 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/9/])
    Fix misuse of DataOutputBuffer.getData in AntiEntropyService
patch by Stu Hood; reviewed by jbellis for CASSANDRA-1729
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Read repair IndexOutOfBoundsException,CASSANDRA-1727,12479656,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,10/Nov/10 23:22,16/Apr/19 09:33,14/Jul/23 05:51,11/Nov/10 00:35,0.6.8,0.7.0 rc 1,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Nov/10 00:09;jbellis;1727-v2.txt;https://issues.apache.org/jira/secure/attachment/12459302/1727-v2.txt","10/Nov/10 23:34;jbellis;1727.txt;https://issues.apache.org/jira/secure/attachment/12459296/1727.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20275,,,Thu Nov 11 00:35:18 UTC 2010,,,,,,,,,,"0|i0g70n:",92567,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"10/Nov/10 23:22;jbellis;Originally reported on CASSANDRA-1719,

{code}
ERROR 20:14:11,591 Uncaught exception in thread Thread[CACHETABLE-TIMER-3,5,main]
java.lang.RuntimeException: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
at org.apache.cassandra.service.ConsistencyChecker$DataRepairHandler.callMe(ConsistencyChecker.java:186)
at org.apache.cassandra.service.ConsistencyChecker$DataRepairHandler.callMe(ConsistencyChecker.java:141)
at org.apache.cassandra.utils.ExpiringMap$CacheMonitor.run(ExpiringMap.java:105)
at java.util.TimerThread.mainLoop(Timer.java:534)
at java.util.TimerThread.run(Timer.java:484)
Caused by: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
at java.util.ArrayList.rangeCheck(ArrayList.java:571)
at java.util.ArrayList.get(ArrayList.java:349)
at org.apache.cassandra.service.ReadResponseResolver.resolve(ReadResponseResolver.java:131)
at org.apache.cassandra.service.ReadResponseResolver.resolve(ReadResponseResolver.java:45)
at org.apache.cassandra.service.ConsistencyChecker$DataRepairHandler.callMe(ConsistencyChecker.java:182)
... 4 more
{code}

{code}
ERROR 20:17:08,688 Uncaught exception in thread Thread[CACHETABLE-TIMER-8,5,main]
java.lang.RuntimeException: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
at org.apache.cassandra.service.ConsistencyChecker$DataRepairHandler.callMe(ConsistencyChecker.java:186)
at org.apache.cassandra.service.ConsistencyChecker$DataRepairHandler.callMe(ConsistencyChecker.java:141)
at org.apache.cassandra.utils.ExpiringMap$CacheMonitor.run(ExpiringMap.java:105)
at java.util.TimerThread.mainLoop(Timer.java:512)
at java.util.TimerThread.run(Timer.java:462)
Caused by: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0
at java.util.ArrayList.RangeCheck(ArrayList.java:547)
at java.util.ArrayList.get(ArrayList.java:322)
at org.apache.cassandra.service.ReadResponseResolver.resolve(ReadResponseResolver.java:131)
at org.apache.cassandra.service.ReadResponseResolver.resolve(ReadResponseResolver.java:45)
at org.apache.cassandra.service.ConsistencyChecker$DataRepairHandler.callMe(ConsistencyChecker.java:182)
... 4 more
{code};;;","10/Nov/10 23:34;jbellis;Fix for regression from CASSANDRA-1622.;;;","11/Nov/10 00:09;jbellis;v2 also fixes the local response;;;","11/Nov/10 00:18;brandon.williams;+1;;;","11/Nov/10 00:35;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
word_count/pig loadfunc don't match the ColumnFamilyInputFormat ByteBuffer signature,CASSANDRA-1725,12479620,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,tjake,jeromatron,jeromatron,10/Nov/10 18:32,16/Apr/19 09:33,14/Jul/23 05:51,10/Nov/10 21:09,0.7.0 rc 1,,,,0,,,,,,"In recent commits, ColumnFamilyInputFormat's signature has changed to use ByteBuffers.  This signature needs to match the word_count example and the pig load func.  There are a few options:
1) The ColumnFamilyInputFormat signature itself didn't need to change - it could translate from byte[] to ByteBuffer internally.
2) Change the word_count and pig load func to use ByteBuffer
3) Just use the AvroColumnFamilyInputFormat.

I think option 1 would be best for now since that's less of a change.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Nov/10 19:34;tjake;1725_v1.txt;https://issues.apache.org/jira/secure/attachment/12459270/1725_v1.txt",,,,,,,,,,,,,,1.0,tjake,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20274,,,Wed Nov 10 21:09:13 UTC 2010,,,,,,,,,,"0|i0g707:",92565,,jeromatron,,jeromatron,Normal,,,,,,,,,,,,,,,,,"10/Nov/10 18:36;jeromatron;Also, would be nice to have the pig load func as part of core so that we aren't bitten by this.;;;","10/Nov/10 19:34;tjake;Tested both pig and word_count now work;;;","10/Nov/10 20:10;jeromatron;tested both - work fine.

+1

hopefully this won't change again in the future - so that people's cassandra+hadoop code doesn't have to change much.;;;","10/Nov/10 21:09;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unbounded key range only ever scans first node in ring,CASSANDRA-1722,12479555,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,jbellis,jbellis,10/Nov/10 03:20,16/Apr/19 09:33,14/Jul/23 05:51,10/Nov/10 14:31,0.6.8,0.7.0 rc 1,,,0,,,,,,"{code:Java}
        List<AbstractBounds> ranges = getRestrictedRanges(new Bounds(leftToken, p.getMinimumToken()));
{code}

when called with empty start key this means we have a Bounds(minToken, minToken), which hits the getRR special case

{code:Java}
        // special case for bounds containing exactly 1 token
        if (queryRange instanceof Bounds && queryRange.left.equals(queryRange.right))
        {
            if (logger.isDebugEnabled())
                logger.debug(""restricted single token match for query "" + queryRange);
            return Collections.singletonList(queryRange);
        }
{code}

Looks like this broke as a side effect of CASSANDRA-1442.  Prior to that a bounds from [T, minToken] was considered ""up to infinity"" by getRR so would span multiple nodes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Nov/10 04:58;stuhood;0001-Add-guard-to-the-Bounds-special-case-to-treat-min-rang.txt;https://issues.apache.org/jira/secure/attachment/12459221/0001-Add-guard-to-the-Bounds-special-case-to-treat-min-rang.txt",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20272,,,Thu Nov 11 22:18:19 UTC 2010,,,,,,,,,,"0|i0g6zj:",92562,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"10/Nov/10 04:58;stuhood;Guard the ""exact one token"" special case from the minimum token: a minimum token range should wrap.;;;","10/Nov/10 14:31;jbellis;committed, thanks!;;;","11/Nov/10 22:15;stuhood;This actually affects get_range_slices as well: querying a key range for start_key='' and end_key='' results in an empty bounds. jbellis backported it to the 0.6 branch.;;;","11/Nov/10 22:18;jbellis;Also committed to 0.6.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DecoratedKey equals() only tests Token,CASSANDRA-1720,12479458,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,tjake,tjake,tjake,09/Nov/10 04:23,16/Apr/19 09:33,14/Jul/23 05:51,11/Nov/10 02:52,0.7.0 rc 1,,,,0,,,,,,"I'm working on a new Partitioner for Lucandra that lets many keys share the same token.

When I use this partitioner SliceQueryFilter class returns all rows that match key with the same Token.  This isn't correct in my mind. 
Tokens should only be used to route a Key in the ring.  DecoratedKey equals() hashCode() and compare() should consider Token *and* Key

Thoughts?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Nov/10 16:05;stuhood;1034_v1.txt;https://issues.apache.org/jira/secure/attachment/12459163/1034_v1.txt",,,,,,,,,,,,,,1.0,tjake,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20271,,,Mon Feb 21 16:02:37 UTC 2011,,,,,,,,,,"0|i0g6z3:",92560,,stuhood,,stuhood,Low,,,,,,,,,,,,,,,,,"09/Nov/10 04:48;jbellis;let's move this to CASSANDRA-1034;;;","09/Nov/10 16:04;stuhood;+1 on the patch originally from 1034;;;","11/Nov/10 02:52;jbellis;committed; see CASSANDRA-1034 for further comments;;;","21/Feb/11 16:02;jbellis;(reverted b/c of CASSANDRA-1733);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra should chdir / when daemonizing,CASSANDRA-1718,12479400,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,thepaul,thepaul,08/Nov/10 19:40,16/Apr/19 09:33,14/Jul/23 05:51,20/Jan/11 16:11,0.7.1,,Packaging,,0,,,,,,"Common practice when daemonizing is to cd / to avoid pinning a filesystem.  For example, if the oper happens to start Cassandra (by itself, or with a manual jsvc invocation, or with the initscript) in /mnt/usb-storage, and there is something mounted there, then the oper will not be able to unmount the usb device that was mounted at that location, since the cassandra process has it open as its cwd.

evidence that this isn't being done already:

{noformat}
~% sudo lsof -p 9775 | awk '$4==""cwd""'
jsvc    9775 cassandra  cwd    DIR                8,1     4096 147675 /home/paul/packages/cassandra/trunk
{noformat}

(That instance was invoked using the Debian initscript.)

Obviously chdir(""/"") isn't necessary when not daemonizing, although it shouldn't hurt either.

If there are concerns about Cassandra having an ongoing ability to open filenames relative to its original working directory, then it should be sufficient just to do a ""cd /"" in the initscript before starting Cassandra.  That case, at least, is particularly important.","Debian squeeze, Cassandra 0.7.0-beta3 and trunk (r1032649)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jan/11 16:32;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1718-switch-to-home-directory-on-startup.txt;https://issues.apache.org/jira/secure/attachment/12468136/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1718-switch-to-home-directory-on-startup.txt","14/Jan/11 20:21;urandom;ASF.LICENSE.NOT.GRANTED--v2-0001-CASSANDRA-1718-chdir-on-startup.txt;https://issues.apache.org/jira/secure/attachment/12468399/ASF.LICENSE.NOT.GRANTED--v2-0001-CASSANDRA-1718-chdir-on-startup.txt",,,,,,,,,,,,,2.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20270,,,Thu Jan 20 16:44:06 UTC 2011,,,,,,,,,,"0|i0g6yn:",92558,,,,,Low,,,,,,,,,,,,,,,,,"08/Nov/10 19:47;jbellis;tagging fix-for 0.7.1 because I don't want to risk any more breakage for 0.7.0;;;","07/Dec/10 17:49;urandom;Huh. I thought jsvc was doing this (and I want to say that it _was_ at some point). It really seems like it ought to be.

bq. If there are concerns about Cassandra having an ongoing ability to open filenames relative to its original working directory, then it should be sufficient just to do a ""cd /"" in the initscript before starting Cassandra. That case, at least, is particularly important.

We should consider it a bug if anything here relies on relative paths (and I don't think it does).;;;","11/Jan/11 20:00;jbellis;Note: this means hprof and err files will be created in /, since they are dumped in CWD.;;;","12/Jan/11 15:58;thepaul;Maybe best would be to chdir() to cassandra's data directory, then. It should be ok to pin that. But definitely we want it to be predictable, not ""whatever directory the admin was in the last time she started it up"".;;;","12/Jan/11 16:27;jbellis;bq. Maybe best would be to chdir() to cassandra's data directory

I like that idea.;;;","12/Jan/11 16:34;urandom;Is there some way to tell the JVM to put its  detritus elsewhere?  Barring that, /var/lib/cassandra is an improvement over, ""wherever"".;;;","12/Jan/11 16:42;thepaul;+1 this patch;;;","12/Jan/11 16:43;jbellis;bq. Is there some way to tell the JVM to put its detritus elsewhere?

http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html lists -XX:HeapDumpPath but nothing for a JVM crash log that I see.;;;","14/Jan/11 02:52;thepaul;-XX:ErrorFile ?;;;","14/Jan/11 03:10;jbellis;Bingo.;;;","20/Jan/11 16:11;urandom;Did.;;;","20/Jan/11 16:44;hudson;Integrated in Cassandra-0.7 #182 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/182/])
    chdir / on startup

Patch by eevans for CASSANDRA-1718
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
More schema migration race conditions,CASSANDRA-1715,12479261,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,gdusbabek,jbellis,jbellis,05/Nov/10 21:12,16/Apr/19 09:33,14/Jul/23 05:51,19/Nov/10 17:04,0.7.0 rc 1,,,,0,,,,,,"Related to CASSANDRA-1631.

This is still a bug with schema updates to an existing CF, since reloadCf is doing a unload/init cycle. So flushing + compaction is an issue there as well. Here is a stacktrace from during an index creation where it stubbed its toe on an incomplete sstable from an in-progress compaction (path names anonymized):
{code}
INFO [CompactionExecutor:1] 2010-11-02 16:31:00,553 CompactionManager.java (line 224) Compacting [org.apache.cassandra.io.sstable.SSTableReader(path='Standard1-e-6-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='Standard1-e-7-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='Standard1-e-8-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='Standard1-e-9-Data.db')]
...
ERROR [MigrationStage:1] 2010-11-02 16:31:10,939 ColumnFamilyStore.java (line 244) Corrupt sstable Standard1-tmp-e-10-<>=[Data.db, Index.db]; skipped
java.io.EOFException
        at org.apache.cassandra.utils.FBUtilities.skipShortByteArray(FBUtilities.java:308)
        at org.apache.cassandra.io.sstable.SSTable.estimateRowsFromIndex(SSTable.java:231)
        at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:286)
        at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:202)
        at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:235)
        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:443)
        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:431)
        at org.apache.cassandra.db.Table.initCf(Table.java:335)
        at org.apache.cassandra.db.Table.reloadCf(Table.java:343)
        at org.apache.cassandra.db.migration.UpdateColumnFamily.applyModels(UpdateColumnFamily.java:89)
        at org.apache.cassandra.db.migration.Migration.apply(Migration.java:158)
        at org.apache.cassandra.thrift.CassandraServer$2.call(CassandraServer.java:672)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
...
 INFO [CompactionExecutor:1] 2010-11-02 16:31:31,970 CompactionManager.java (line 303) Compacted to Standard1-tmp-e-10-Data.db.  213,657,983 to 213,657,983 (~100% of original) bytes for 626,563 keys.  Time: 31,416ms.
{code}

There is also a race between schema modification and streaming.",,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Nov/10 23:25;gdusbabek;ASF.LICENSE.NOT.GRANTED--v3-0001-take-drop-off-CompactionManager.txt;https://issues.apache.org/jira/secure/attachment/12459653/ASF.LICENSE.NOT.GRANTED--v3-0001-take-drop-off-CompactionManager.txt","15/Nov/10 23:25;gdusbabek;ASF.LICENSE.NOT.GRANTED--v3-0002-compaction-lock.txt;https://issues.apache.org/jira/secure/attachment/12459654/ASF.LICENSE.NOT.GRANTED--v3-0002-compaction-lock.txt","15/Nov/10 23:25;gdusbabek;ASF.LICENSE.NOT.GRANTED--v3-0003-migration-uses-locks.txt;https://issues.apache.org/jira/secure/attachment/12459655/ASF.LICENSE.NOT.GRANTED--v3-0003-migration-uses-locks.txt","15/Nov/10 23:25;gdusbabek;ASF.LICENSE.NOT.GRANTED--v3-0004-handle-moved-dropped-CF-prior-to-pending-compaction-st.txt;https://issues.apache.org/jira/secure/attachment/12459656/ASF.LICENSE.NOT.GRANTED--v3-0004-handle-moved-dropped-CF-prior-to-pending-compaction-st.txt","15/Nov/10 23:25;gdusbabek;ASF.LICENSE.NOT.GRANTED--v3-0005-CFS.reload-assumes-metadata-is-mutable.txt;https://issues.apache.org/jira/secure/attachment/12459657/ASF.LICENSE.NOT.GRANTED--v3-0005-CFS.reload-assumes-metadata-is-mutable.txt","15/Nov/10 23:25;gdusbabek;ASF.LICENSE.NOT.GRANTED--v3-0007-updateColumnFamily-uses-reload-remove-unneccesary-stru.txt;https://issues.apache.org/jira/secure/attachment/12459659/ASF.LICENSE.NOT.GRANTED--v3-0007-updateColumnFamily-uses-reload-remove-unneccesary-stru.txt","15/Nov/10 23:25;gdusbabek;ASF.LICENSE.NOT.GRANTED--v3-0008-perform-index-maintenance-outside-of-migration-locks-d.txt;https://issues.apache.org/jira/secure/attachment/12459660/ASF.LICENSE.NOT.GRANTED--v3-0008-perform-index-maintenance-outside-of-migration-locks-d.txt","15/Nov/10 23:25;gdusbabek;ASF.LICENSE.NOT.GRANTED--v3-0009-use-avro-structures-inside-UpdateColumnFamily.txt;https://issues.apache.org/jira/secure/attachment/12459661/ASF.LICENSE.NOT.GRANTED--v3-0009-use-avro-structures-inside-UpdateColumnFamily.txt","15/Nov/10 23:25;gdusbabek;ASF.LICENSE.NOT.GRANTED--v3-0010-remove-unused-fields-in-DropColumnFamily-DropKeyspace.txt;https://issues.apache.org/jira/secure/attachment/12459662/ASF.LICENSE.NOT.GRANTED--v3-0010-remove-unused-fields-in-DropColumnFamily-DropKeyspace.txt","18/Nov/10 10:05;jbellis;v3-0006-replace-modifiable-CFM-members-with-private-fields-a.patch;https://issues.apache.org/jira/secure/attachment/12459906/v3-0006-replace-modifiable-CFM-members-with-private-fields-a.patch","18/Nov/10 10:06;jbellis;v3-0011-make-addIndex-asynchronous-and-race-proof.patch;https://issues.apache.org/jira/secure/attachment/12459907/v3-0011-make-addIndex-asynchronous-and-race-proof.patch","19/Nov/10 14:23;jbellis;v3-0012-remove-locks-from-UpdateColumnFamily.patch;https://issues.apache.org/jira/secure/attachment/12460004/v3-0012-remove-locks-from-UpdateColumnFamily.patch",,,12.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20269,,,Tue Nov 23 02:15:03 UTC 2010,,,,,,,,,,"0|i0g6xz:",92555,,,,,Critical,,,,,,,,,,,,,,,,,"08/Nov/10 23:25;gdusbabek;Be prepared to throw up a little.

This approach puts a lock around CompactionManager. Migrations have to acquire it and Table.flushLock before proceeding.  Special care had to be taking when reloading a CFS since it places blocking jobs on the compaction manager.  This patch should handle the streaming race as well (when the directory specified in a Descriptor is no longer valid).;;;","08/Nov/10 23:33;jbellis;Also, out of curiosity, what were the main complications w/ mutable CFS.metadata?;;;","08/Nov/10 23:48;gdusbabek;bq. what were the main complications w/ mutable CFS.metadata?

There were a couple things. A new memtable would need to know about the updated meta settings for thresholds.  The timing here is tricky because of flushing (chances are you would have just flushed and have an empty memtable in anyway, but one can't be too sure).  Other things... Make sure secondary indexes are dealt with properly on updates (e.g.: not reloaded needlessly).  Efficiently dealing with SSTableReader instances--certain classes up updates wouldn't require messing with them at all, but others would (when files move).  Ideally, it would be nice to repoint a few instances of SSTable at new data files and have all caches, stats, etc. remain intact.;;;","09/Nov/10 02:02;jbellis;UpdateColumnFamily doesn't acquireLocks().  (Shouldn't Migration do that so the subclasses don't have to?)

bq. A new memtable would need to know about the updated meta settings for thresholds. The timing here is tricky because of flushing (chances are you would have just flushed and have an empty memtable in anyway, but one can't be too sure).

This gets a little messy code-wise (because we allow overriding memtable settings at runtime) but not too bad.  At worst we just set the CFS values to the new migration values during application.  I don't see any timing issues (Memtable.isThresholdViolated checks w/ the CFS each time, it doesn't cache locally).

bq. Make sure secondary indexes are dealt with properly on updates (e.g.: not reloaded needlessly).
 
Writing code to detect when indexes are added/dropped is a pain compared to just rebuilding it from scratch, but efficiency-wise it seems like a win. At least mutating you can avoid redoing the index sampling every time.  Stopping updates in their tracks while we reload, to change read_repair_chance, is really brutal.  (If UpdateCF doesn't actually need to acquireLocks then never mind, but I think it does.)

bq. Efficiently dealing with SSTableReader instances--certain classes up updates wouldn't require messing with them at all, but others would (when files move). 

What is making files move here?
;;;","09/Nov/10 02:10;gdusbabek;bq. What is making files move here?
Renaming. Sorry.  I know we'll need to implement it eventually, so I can't stop thinking about it. That one doesn't matter in this context.;;;","09/Nov/10 14:03;gdusbabek;bq. UpdateColumnFamily doesn't acquireLocks().
It does on line 82 in my checkout.
bq. Shouldn't Migration do that so the subclasses don't have to?
It doesn't make sense to lock on the Add* methods, but I agree it might be easier just to do the locking in the superclass. What do you think?;;;","10/Nov/10 16:21;gdusbabek;v2 shows what the CFS/CFM reload approach would probably look like for UpdateColumnFamily.  Unfortunately it touches a lot of code and might not be warranted at this late stage in the beta cycle.  

If left for 0.7.1, I need to explain that it changes the serialization format for Migrations in a non-backwards compatible way, which is not desirable.  The same kind of work would have to be done for the other Migration subclasses.

This is mainly a demonstration, but one thing I'd definitely change is to use the avro CfDef in the UpdateColumnFamily constructor instead of the thrift version.;;;","14/Nov/10 21:25;jbellis;The v2 approach looks great.  I think the main improvement we need is to not do blocking flushes while the locks are held.  For the purposes of creating a new memtable a nonblocking flush is fine.  For creating indexes we'll need to set up a callback to do the index building after the flush completes.  (We used to have code that took a callback arg as part of the flush call, I think I took it out but it should be relatively easy to resurrect.)  I agree that it touches a lot of code, but the core changes (i.e. not one-line things like encapsulating gcgraceseconds that are messy but not dangerous) aren't much larger than v1.  The huge improvement over waiting to re-sample indexes after UpdateCF is worth it imo.

I'm also fine with saying that changing the CFS will blow away any JMX-applied changes and reset values to what the new CFM says the should be.  But if you are happy with the Default* approach I am too.

bq. If left for 0.7.1, I need to explain that it changes the serialization format for Migrations in a non-backwards compatible way, which is not desirable

Is this saying that we'd need to tell beta3 users to rebuild their schemas if this goes in?  I am fine with that, I just want to make sure I understand.;;;","15/Nov/10 13:35;gdusbabek;bq. Is this saying that we'd need to tell beta3 users to rebuild their schemas if this goes in? I am fine with that, I just want to make sure I understand.
Yes, exactly.

I'll go ahead and finish this patch in the v2 direction.;;;","15/Nov/10 23:27;gdusbabek;0008 addresses the flushes-within-locks brought up by jonathan.  0009 and 0010 are cleanup.;;;","18/Nov/10 10:08;jbellis;new version of 06 to rebase.

11 makes addIndex asynchronous which unclogs the post-flush executor (which is single-threaded for safety, so a long index build would mean we don't clean up any commitlogs until it's done) and also makes restarting when a new index is not yet complete friendlier.

I don't think we need the locks on Update anymore since we're keeping the same Tracker and so forth so 12 removes that.  locks are still needed for Drop.

What do you think?;;;","18/Nov/10 19:49;gdusbabek;I think update still needs to acquire the locks for the case when secondary indexes are dropped.  The locking could conceivably be pushed down to the point in CFS when the indexes are dropped though, at which point we'd need to remove the assert from the beginning of CFS.reload() and make the members that get reset in reload() volatile (minCompactionThreshold, maxCompactionThreshold, etc.).;;;","18/Nov/10 19:59;gdusbabek;0012 causes several unit tests to fail.  You might want to take a closer look at it.;;;","19/Nov/10 14:23;jbellis;new 0012.

bq. the locking could conceivably be pushed down to the point in CFS when the indexes are dropped 

right, this is what 0011 does.  more accurately, it uses CSLM to avoid an explicit lock.

bq. at which point we'd need to remove the assert from the beginning of CFS.reload() and make the members that get reset in reload() volatile (minCompactionThreshold, maxCompactionThreshold, etc.). 

done.

bq. 0012 causes several unit tests to fail

one was the assert, one was an unrelated commitlog bug that got exposed by something unrelated.  fixed.;;;","19/Nov/10 14:57;gdusbabek;bq. right, this is what 0011 does. more accurately, it uses CSLM to avoid an explicit lock.
My argument was that it wasn't safe to call indexCfs.removeAllSSTables() without the flush lock, but it looks like SSTableTracker is properly synchronized to avoid any problems with flushing.  No problem here.

+1 I'll commit this shortly.;;;","19/Nov/10 17:04;gdusbabek;committed.;;;","19/Nov/10 20:05;hudson;Integrated in Cassandra-0.7 #19 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/19/])
    ;;;","20/Nov/10 12:48;hudson;Integrated in Cassandra #602 (See [https://hudson.apache.org/hudson/job/Cassandra/602/])
    remove locks from UpdateColumnFamily. patch by jbellis, reviewed by gdusbabek. CASSANDRA-1715
make addIndex asynchronous and race proof. patch by jbellis, reviewed by gdusbabek. CASSANDRA-1715
remove unused fields in DropColumnFamily, DropKeyspace. patch by gdusbabek, reviewe by jbellis. CASSANDRA-1715
use avro structures inside UpdateColumnFamily. patch by gdusbabek, reviewe by jbellis. CASSANDRA-1715
perform index maintenance outside of migration locks during CF update. patch by gdusbabek, reviewe by jbellis. CASSANDRA-1715
updateColumnFamily uses reload, remove unneccesary structures, fix bugs. patch by gdusbabek, reviewe by jbellis. CASSANDRA-1715
replace modifiable CFM members with private fields and public getters. patch by gdusbabek, reviewe by jbellis. CASSANDRA-1715
CFS.reload() assumes metadata is mutable. patch by gdusbabek, reviewe by jbellis. CASSANDRA-1715
handle moved/dropped CF prior to pending compaction/streams. patch by gdusbabek, reviewe by jbellis. CASSANDRA-1715
migration uses locks. patch by gdusbabek, reviewe by jbellis. CASSANDRA-1715
compaction lock. patch by gdusbabek, reviewe by jbellis. CASSANDRA-1715
take drop off CompactionManager. patch by gdusbabek, reviewe by jbellis. CASSANDRA-1715
;;;","23/Nov/10 01:32;tjake;During testing I hit this section of code:

CFMetaData.java:662 
{code}
  // remove the ones leaving.
        for (ByteBuffer indexName : toRemove)
            column_metadata.remove(indexName);
{code}

but column_metadata is defined as:

{code}
        this.column_metadata = Collections.unmodifiableMap(column_metadata);
{code}

So remove() will throw an exception.
;;;","23/Nov/10 02:07;jbellis;can you open a new ticket for that?;;;","23/Nov/10 02:15;tjake;CASSANDRA-1768;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Windows batch files use incorrect paths,CASSANDRA-1713,12479195,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,vloncar,vloncar,vloncar,05/Nov/10 12:42,16/Apr/19 09:33,14/Jul/23 05:51,09/Nov/10 16:05,0.6.8,0.7.0 rc 1,Packaging,,0,,,,,,"Windows .bat files (with the exception of cassandra.bat) use %CD% to set CASSANDRA_HOME, and since that is incorrect, they fail to start with ClassNotFoundException.",Windows,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Nov/10 12:43;vloncar;windows-batch-fix.patch;https://issues.apache.org/jira/secure/attachment/12458902/windows-batch-fix.patch",,,,,,,,,,,,,,1.0,vloncar,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20268,,,Tue Nov 09 16:05:10 UTC 2010,,,,,,,,,,"0|i0g6xj:",92553,,bcoverston,,bcoverston,Low,,,,,,,,,,,,,,,,,"08/Nov/10 22:02;bcoverston;+1 this looks good. Thanks!;;;","08/Nov/10 23:38;jbellis;what is the trick to apply?  fails for me against 0.7 and 0.6;;;","09/Nov/10 09:10;vloncar;I created the patch with diff, and tested it with patch tool, both from GnuWin32 package. It works on both 0.6 and 0.7, although on 0.6 there is one line of offset (it still applies successfully). I also noticed that cassandra.bat in 0.7 sets CASSANDRA_CONF, and i dont see it being used (conf dir gets on classpath a few lines later, so this seems redundant). I tested without it, and it appears to work normally. Should i also include that in the patch?

On a related note, what is needed to bring cassandra up to par on windows? I know there are some JNA enhancements, and now direct IO which are Linux-only, but there are probably more I am not aware of. Maybe opening a ticket to track these wouldn't be a bad idea?;;;","09/Nov/10 16:05;jbellis;committed.

bq. what is the trick to apply

for the record: dos2unix bin/*.bat; patch; unix2dos bin/*.bat.  If there is a way to get patch to deal with targets with CLRF line endings, I couldn't find it.  (It deals w/ CLRF in the _patch_ just fine.)

bq. I also noticed that cassandra.bat in 0.7 sets CASSANDRA_CONF, and i dont see it being used

removed in the merge to 0.7

bq. what is needed to bring cassandra up to par on windows? I know there are some JNA enhancements, and now direct IO which are Linux-only

I think that's about it really (besides CASSANDRA-292).  The JNA stuff is all in CLibrary -- extracting the higher-level code to another class, and using CLibrary/WindowsLibrary (what is the equivalent of libc?) from that depending on platform is probably the way to go.

bq. Maybe opening a ticket to track these

I'd say open a ticket if you're going to work on it. :);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Creating a SuperColumnFamily other than BytesType results in incorrect comparator types ,CASSANDRA-1712,12479178,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,ceocoder,ceocoder,05/Nov/10 08:00,16/Apr/19 09:33,14/Jul/23 05:51,08/Nov/10 21:06,0.7.0 rc 1,,Legacy/Tools,,0,,,,,,"CF 1
    ColumnFamily: CFCli (Super)
      Columns sorted by: org.apache.cassandra.db.marshal.LongType/org.apache.cassandra.db.marshal.UTF8Type
      Subcolumns sorted by: org.apache.cassandra.db.marshal.LongType

was created with cli using 

create column family CFCli with column_type= 'Super' and comparator= 'LongType' and subcomparator='UTF8Type'

 CF 2
 ColumnFamily: CFYaml (Super)
      Columns sorted by: org.apache.cassandra.db.marshal.LongType/org.apache.cassandra.db.marshal.UTF8Type
      Subcolumns sorted by: org.apache.cassandra.db.marshal.LongType

was created with yaml using 

  column_families:
        - name: CFYaml
          column_type: Super
          compare_with: LongType
          compare_subcolumns_with: UTF8Type

In both cases Subcolumn comparator was defined as UTF8Type but CF was created with subcomparatortype of LongType

",ubuntu using 0.7.0 beta 3 bin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20267,,,Mon Nov 08 21:06:06 UTC 2010,,,,,,,,,,"0|i0g6xb:",92552,,,,,Low,,,,,,,,,,,,,,,,,"05/Nov/10 08:03;mdennis;{quote}
(03:00:59 AM) ceocoder1: I tried adding column using cli and my client (scromium) each time it fails with ""shit"" can not be converted to Long where shit is value of subcolumn
(03:01:07 AM) ceocoder1: thanks
(03:01:27 AM) ceocoder1: i meant name of subcolumn
(03:02:03 AM) mdennis: that sounds a lot worse than just an output bug
(03:02:09 AM) ceocoder1: y
(03:02:12 AM) mdennis: it sounds like it actually reversed them
(03:02:19 AM) ceocoder1: regular columns are fine
(03:02:24 AM) ceocoder1: just supercolumns
(03:02:44 AM) mdennis: it's karma saying people shouldn't use super columns
{quote};;;","05/Nov/10 12:17;jbellis;what does ""show keyspaces"" on the cli say the comparators are?;;;","05/Nov/10 17:54;ceocoder;Output of show keyspaces

Keyspace: system:
  Replication Factor: 1
  Column Families:
    ColumnFamily: IndexInfo
    ""indexes that have been completed""
      Columns sorted by: org.apache.cassandra.db.marshal.UTF8Type
      Row cache size / save period: 0.0/0
      Key cache size / save period: 0.01/3600
      Memtable thresholds: 0.571875/122/60
      GC grace seconds: 0
      Compaction min/max thresholds: 4/32
    ColumnFamily: Schema
    ""current state of the schema""
      Columns sorted by: org.apache.cassandra.db.marshal.UTF8Type
      Row cache size / save period: 0.0/0
      Key cache size / save period: 0.01/3600
      Memtable thresholds: 0.571875/122/60
      GC grace seconds: 0
      Compaction min/max thresholds: 4/32
    ColumnFamily: Migrations
    ""individual schema mutations""
      Columns sorted by: org.apache.cassandra.db.marshal.TimeUUIDType
      Row cache size / save period: 0.0/0
      Key cache size / save period: 0.01/3600
      Memtable thresholds: 0.571875/122/60
      GC grace seconds: 0
      Compaction min/max thresholds: 4/32
    ColumnFamily: LocationInfo
    ""persistent metadata for the local node""
      Columns sorted by: org.apache.cassandra.db.marshal.BytesType
      Row cache size / save period: 0.0/0
      Key cache size / save period: 0.01/3600
      Memtable thresholds: 0.571875/122/60
      GC grace seconds: 0
      Compaction min/max thresholds: 4/32
    ColumnFamily: HintsColumnFamily (Super)
    ""hinted handoff data""
      Columns sorted by: org.apache.cassandra.db.marshal.BytesType/org.apache.cassandra.db.marshal.BytesType
      Subcolumns sorted by: org.apache.cassandra.db.marshal.BytesType
      Row cache size / save period: 0.0/0
      Key cache size / save period: 0.01/3600
      Memtable thresholds: 0.571875/122/60
      GC grace seconds: 0
      Compaction min/max thresholds: 4/32
Keyspace: Skunk:
  Replication Factor: 1
  Column Families:
    ColumnFamily: CFYaml (Super)
      Columns sorted by: org.apache.cassandra.db.marshal.LongType/org.apache.cassandra.db.marshal.UTF8Type
      Subcolumns sorted by: org.apache.cassandra.db.marshal.LongType
      Row cache size / save period: 1000.0/0
      Key cache size / save period: 10000.0/3600
      Memtable thresholds: 0.29/255/59
      GC grace seconds: 864000
      Compaction min/max thresholds: 4/32
    ColumnFamily: CFCli (Super)
      Columns sorted by: org.apache.cassandra.db.marshal.LongType/org.apache.cassandra.db.marshal.UTF8Type
      Subcolumns sorted by: org.apache.cassandra.db.marshal.LongType
      Row cache size / save period: 0.0/0
      Key cache size / save period: 200000.0/3600
      Memtable thresholds: 0.571875/122/60
      GC grace seconds: 864000
      Compaction min/max thresholds: 4/32
Keyspace: Lucandra:
  Replication Factor: 1
  Column Families:
    ColumnFamily: Documents
      Columns sorted by: org.apache.cassandra.db.marshal.BytesType
      Row cache size / save period: 0.0/0
      Key cache size / save period: 200000.0/3600
      Memtable thresholds: 0.571875/122/60
      GC grace seconds: 864000
      Compaction min/max thresholds: 4/32
    ColumnFamily: TermInfo (Super)
      Columns sorted by: org.apache.cassandra.db.marshal.BytesType/org.apache.cassandra.db.marshal.BytesType
      Subcolumns sorted by: org.apache.cassandra.db.marshal.BytesType
      Row cache size / save period: 0.0/0
      Key cache size / save period: 200000.0/3600
      Memtable thresholds: 0.571875/122/60
      GC grace seconds: 864000
      Compaction min/max thresholds: 4/32
;;;","05/Nov/10 19:34;jbellis;Oh, I see.  It's printing the correct comparator/subcomparator types, then there is an additional line with the comparator type incorrectly listed as the subcomparator.  Fixed in r1031741.;;;","05/Nov/10 19:59;ceocoder;For 

ColumnFamily: CFYaml (Super)
Columns sorted by: org.apache.cassandra.db.marshal.LongType/org.apache.cassandra.db.marshal.UTF8Type
Subcolumns sorted by: org.apache.cassandra.db.marshal.LongType

set CFYaml['newrow'][1234567890]['column'] = 'value'
'column' could not be translated into a LongType.

I think type of ['column'] is UTF8Type not sure why I'm getting translated into LongType error.
;;;","05/Nov/10 20:51;jbellis;Pavel, could you have a look at this second part?;;;","05/Nov/10 21:01;xedin;sure! I will start with this issue right after I will finish 1470.;;;","08/Nov/10 21:06;jbellis;this is working fine for me in latest 0.7 code:

{code}
[default@unknown] create keyspace KS1
cfff16aa-eb7b-11df-b5e1-e700f669bcfc
[default@unknown] use KS1
Authenticated to keyspace: KS1
[default@KS1] create column family CFCli with column_type= 'Super' and comparator= 'LongType' and subcomparator='UTF8Type'
d4d6684b-eb7b-11df-b5e1-e700f669bcfc
[default@KS1] set CFCli['newrow'][1234567890]['column'] = 'value'
Value inserted.
{code}
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cli doesn't handle non-string column names well,CASSANDRA-1701,12478959,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jancona,jancona,jancona,03/Nov/10 05:21,16/Apr/19 09:33,14/Jul/23 05:51,03/Nov/10 16:42,,,,,0,,,,,,"cassandra-cli has several bugs when using column names that aren't strings. Attached is a patch that updates CliTest to show the problems and fixes CliClient by properly converting non-string column and sub-column values passed to the GET, SET and COUNT commands.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Nov/10 05:22;jancona;cassandra-cli-non-string-column-names.patch;https://issues.apache.org/jira/secure/attachment/12458714/cassandra-cli-non-string-column-names.patch",,,,,,,,,,,,,,1.0,jancona,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20266,,,Wed Nov 03 16:42:01 UTC 2010,,,,,,,,,,"0|i0g6uv:",92541,,xedin,,xedin,Normal,,,,,,,,,,,,,,,,,"03/Nov/10 14:58;xedin;This looks good to me, all .getBytes() replaced with columnNameAsByteArray methods which is how it should be + tests added.;;;","03/Nov/10 16:42;jbellis;committed.  thanks, Jim!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
mapreduce support is broken,CASSANDRA-1700,12478945,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,jeromatron,jeromatron,03/Nov/10 01:16,16/Apr/19 09:33,14/Jul/23 05:51,16/Nov/10 15:16,0.6.9,0.7.0 rc 1,,,0,,,,,,Running from a vanilla download of beta3 src.  Tried the word count example and it's broken.  Attaching the stack trace.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Nov/10 05:08;stuhood;0001-Add-testcase-for-wrapping-range-on-member-token.patch;https://issues.apache.org/jira/secure/attachment/12458713/0001-Add-testcase-for-wrapping-range-on-member-token.patch","03/Nov/10 03:36;jeromatron;server_log.txt;https://issues.apache.org/jira/secure/attachment/12458706/server_log.txt","03/Nov/10 01:16;jeromatron;stacktrace.txt;https://issues.apache.org/jira/secure/attachment/12458699/stacktrace.txt",,,,,,,,,,,,3.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20265,,,Tue Nov 16 16:05:59 UTC 2010,,,,,,,,,,"0|i0g6un:",92540,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"03/Nov/10 03:23;jbellis;The server stacktrace would be more useful than the client one.;;;","03/Nov/10 03:36;jeromatron;Attaching server-side errors.;;;","03/Nov/10 03:55;jbellis;possibly caused by CASSANDRA-1442 which happened during beta3.

looks like the assert
{code}
        assert range instanceof Bounds
               || (!((Range)range).isWrapAround() || range.right.equals(StorageService.getPartitioner().getMinimumToken()))
               : range;
{code}

is failing.  it may no longer be a valid assert.;;;","03/Nov/10 05:08;stuhood;Somehow in all those testcases on 1442 I didn't test the one case that Hadoop uses: a wrapping range centered on a member token. Attaching a patch to add a testcase and fix.;;;","03/Nov/10 14:09;jbellis;committed, thanks!;;;","16/Nov/10 15:05;jbellis;also broken on 0.6 since we backported https://issues.apache.org/jira/browse/CASSANDRA-1722;;;","16/Nov/10 15:16;jbellis;backported fix in r1035656;;;","16/Nov/10 16:05;hudson;Integrated in Cassandra-0.6 #5 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/5/])
    backport CASSANDRA-1700
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Startup can fail if DNS lookup fails for seed node,CASSANDRA-1697,12478906,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,appodictic,appodictic,02/Nov/10 16:21,16/Apr/19 09:33,14/Jul/23 05:51,02/Nov/10 17:13,0.6.7,0.7.0 rc 1,,,0,,,,,,"This might fall into one of those WONT FIX scenarios, since not many things are going to work well with flaky DNS. This has only happened to me once, but I someone might be interested in the stack trace. In this case cdbsd01.hadoop.pvt is one of my seed nodes.

{noformat}
 INFO [main] 2010-11-02 11:52:00,141 CLibrary.java (line 43) JNA not found. Native methods will be disabled.
 INFO [main] 2010-11-02 11:52:00,421 DatabaseDescriptor.java (line 246) DiskAccessMode ismmap, indexAccessMode is mmap
ERROR [main] 2010-11-02 11:52:25,591 CassandraDaemon.java (line 232) Exception encountered during startup.
java.lang.ExceptionInInitializerError
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:72)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:214)
Caused by: java.lang.RuntimeException: java.net.UnknownHostException: cdbsd01.hadoop.pvt
	at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:551)
	... 2 more
Caused by: java.net.UnknownHostException: cdbsd01.hadoop.pvt
	at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$1.lookupAllHostAddr(InetAddress.java:850)
	at java.net.InetAddress.getAddressFromNameService(InetAddress.java:1201)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1154)
	at java.net.InetAddress.getAllByName(InetAddress.java:1084)
	at java.net.InetAddress.getAllByName(InetAddress.java:1020)
	at java.net.InetAddress.getByName(InetAddress.java:970)
	at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:540)
	... 2 more
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Nov/10 16:36;jbellis;1697.txt;https://issues.apache.org/jira/secure/attachment/12458646/1697.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20264,,,Tue Nov 02 17:13:26 UTC 2010,,,,,,,,,,"0|i0g6tz:",92537,,gdusbabek,,gdusbabek,Low,,,,,,,,,,,,,,,,,"02/Nov/10 16:31;jbellis;Yeah, sorry -- this is why we recommend using IP addresses instead of hostnames for seeds.;;;","02/Nov/10 16:36;jbellis;Patch to generate a more human-friendly error message attached.;;;","02/Nov/10 17:06;gdusbabek;+1;;;","02/Nov/10 17:13;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix jna errno reporting,CASSANDRA-1694,12478855,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,02/Nov/10 05:20,16/Apr/19 09:33,14/Jul/23 05:51,02/Nov/10 18:29,0.6.7,0.7.0 rc 1,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Nov/10 17:21;jbellis;1694-take-2.txt;https://issues.apache.org/jira/secure/attachment/12458652/1694-take-2.txt","02/Nov/10 05:59;jbellis;1694-v3.txt;https://issues.apache.org/jira/secure/attachment/12458613/1694-v3.txt","02/Nov/10 05:39;jbellis;jna-3.2.7.jar;https://issues.apache.org/jira/secure/attachment/12458611/jna-3.2.7.jar","02/Nov/10 05:20;jbellis;jna.patch;https://issues.apache.org/jira/secure/attachment/12458608/jna.patch",,,,,,,,,,,4.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20262,,,Tue Nov 02 18:29:18 UTC 2010,,,,,,,,,,"0|i0g6tb:",92534,,brandon.williams,,brandon.williams,Low,,,,,,,,,,,,,,,,,"02/Nov/10 05:55;jbellis;v2 adds support for crappy old jna versions;;;","02/Nov/10 06:09;brandon.williams;+1.  Needs jna 3.2.7 to compile, but will run (with inferior logging) with lesser jna versions.;;;","02/Nov/10 06:12;jbellis;committed;;;","02/Nov/10 17:19;jbellis;This causes
{code}
ERROR 12:11:56,633 Exception encountered during startup.
java.lang.NoClassDefFoundError: com/sun/jna/LastErrorException
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:67)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:224)
Caused by: java.lang.ClassNotFoundException: com.sun.jna.LastErrorException
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
{code}

when jna is not present at runtime.  reverted for now.;;;","02/Nov/10 17:22;jbellis;-take-2 patch adds a pre-emptive call to getLastError in an attempt to fix the problem a different way.
{code}
            // calling getLastError involves system calls that can reset errno, so you don't
            // want the first time you call it to be when you actually have an error to diagnose
{code};;;","02/Nov/10 17:27;brandon.williams;Take-2 has no effect for me regardless of jna version.;;;","02/Nov/10 18:29;jbellis;re-committed v3 with catches changed to look like this instead:
{code}
        catch (RuntimeException e)
        {
            if (!(e instanceof LastErrorException))
                throw e;

            ... handle errno ...
        }
{code};;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
gen-thrift-py can fail but claims success,CASSANDRA-1692,12478832,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,mdennis,mdennis,mdennis,01/Nov/10 19:53,16/Apr/19 09:33,14/Jul/23 05:51,01/Nov/10 22:44,0.7.0 rc 1,,Legacy/Tools,,0,,,,,,"{code}
Buildfile: /home/mdennis/mdev/cassandra-0.7.0-beta2/build.xml

gen-thrift-py:
     [echo] Generating Thrift Python code from /home/mdennis/mdev/cassandra-0.7.0-beta2/interface/cassandra.thrift ....
     [exec] 
     [exec] [FAILURE:/home/mdennis/mdev/cassandra-0.7.0-beta2/interface/cassandra.thrift:374] error: identifier ONE is unqualified!
     [exec] Result: 1

BUILD SUCCESSFUL
Total time: 1 second
{code}

""BUILD SUCCESSFUL"" is not the phrase I would use to describe the outcome of the command in this case :P",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Nov/10 21:02;mdennis;1692-trunk.txt;https://issues.apache.org/jira/secure/attachment/12458582/1692-trunk.txt",,,,,,,,,,,,,,1.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20261,,,Mon Nov 01 22:44:13 UTC 2010,,,,,,,,,,"0|i0g6sv:",92532,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"01/Nov/10 19:54;mdennis;To be clear, I know the problem that causes it to fail; the complaint is that it claimed success;;;","01/Nov/10 20:51;jbellis;Do you know how to fix it?

""ant gen-thrift-py"" is a convenience for developers only, I'm not going to lose much sleep over it not knowing how to handle an out of date thrift compiler.;;;","01/Nov/10 21:02;mdennis;yes, I know how to fix it (patch attached);;;","01/Nov/10 22:44;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Repair blocking forever when RF=1,CASSANDRA-1691,12478827,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,mbulman,mbulman,01/Nov/10 19:15,16/Apr/19 09:33,14/Jul/23 05:51,01/Nov/10 22:39,0.7.0 rc 1,,Legacy/Tools,,1,,,,,,"Tested on single and multi-node, RF=1.  Repair runs but never reports that it's complete, hence the blocking forever.",,mbulman,thepaul,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Nov/10 22:01;stuhood;0001-Complete-the-session-early-if-it-has-no-content.patch;https://issues.apache.org/jira/secure/attachment/12458587/0001-Complete-the-session-early-if-it-has-no-content.patch",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20260,,,Mon Nov 01 22:39:33 UTC 2010,,,,,,,,,,"0|i0g6sn:",92531,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"01/Nov/10 20:49;jbellis;pretty sure single-node repair is special cased to be a no-op.;;;","01/Nov/10 21:37;mbulman;It definitely does _something_ for single-node.  ""computing ranges.."" followed by ""GC for copy"";;;","01/Nov/10 21:41;stuhood;Will post a patch soon.;;;","01/Nov/10 22:01;stuhood;Checks for an empty neighbor list and completes early.;;;","01/Nov/10 22:06;stuhood;Er, this isn't tested yet... give me one more second.

EDIT: Looks good now.;;;","01/Nov/10 22:23;jbellis;does 0.6 need this?;;;","01/Nov/10 22:28;stuhood;I'm not sure anything ""needs"" this, and the code is sufficiently different that I don't think backporting to 0.6 is worthwhile.;;;","01/Nov/10 22:39;jbellis;committed to 0.7 + trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
o.a.c.dht.AbstractBounds missing serialVersionUID,CASSANDRA-1686,12478703,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,urandom,urandom,29/Oct/10 22:00,16/Apr/19 09:33,14/Jul/23 05:51,29/Oct/10 22:12,0.6.7,0.7.0 rc 1,Legacy/Tools,,0,,,,,,"o.a.c.dht.AbstractBounds does not have a  serialVersionUID set, and as a result, tools that make use of getRangeToEndpointMap() on the StorageService mbean must be from the exact same build or they fail with an java.io.InvalidClassException.  This is very inconvenient.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Oct/10 22:01;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1686-assign-a-serialVersionUID.txt;https://issues.apache.org/jira/secure/attachment/12458455/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1686-assign-a-serialVersionUID.txt",,,,,,,,,,,,,,1.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20259,,,Wed Nov 03 20:51:29 UTC 2010,,,,,,,,,,"0|i0g6rj:",92526,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"29/Oct/10 22:04;jbellis;+1;;;","29/Oct/10 22:12;urandom;committed.;;;","30/Oct/10 12:48;hudson;Integrated in Cassandra #581 (See [https://hudson.apache.org/hudson/job/Cassandra/581/])
    CASSANDRA-1686: assign a serialVersionUID

Patch by eevans
;;;","03/Nov/10 20:51;jbellis;committed to 0.6 branch as well;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
IntegerType.toString() handles ByteBuffer incorrectly,CASSANDRA-1681,12478635,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jancona,jancona,jancona,29/Oct/10 01:41,16/Apr/19 09:33,14/Jul/23 05:51,29/Oct/10 02:05,0.7.0 rc 1,,,,0,,,,,,"IntegerType.getString doesn't correctly extract the byte array from the ByteBuffer passed to it. This causes incorrect results in cassandra-cli as described in [CASSANDRA-1680|https://issues.apache.org/jira/browse/CASSANDRA-1680].",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Oct/10 01:41;jancona;integer-type-byte-buffer.patch;https://issues.apache.org/jira/secure/attachment/12458304/integer-type-byte-buffer.patch",,,,,,,,,,,,,,1.0,jancona,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20257,,,Fri Oct 29 02:05:57 UTC 2010,,,,,,,,,,"0|i0g6qf:",92521,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"29/Oct/10 02:05;jbellis;committed, with a slight change to call byteBufferToByteArray directly.  thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ByteBuffer bug in ExpiringColumn.updateDigest() ,CASSANDRA-1679,12478619,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,tjake,tjake,tjake,28/Oct/10 20:40,16/Apr/19 09:33,14/Jul/23 05:51,28/Oct/10 21:31,0.7.0 rc 1,,,,0,,,,,,"The MessageDigest calls in ExpringColumn change the position of the bytebuffer.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Oct/10 20:41;tjake;1679_v1.txt;https://issues.apache.org/jira/secure/attachment/12458274/1679_v1.txt",,,,,,,,,,,,,,1.0,tjake,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20255,,,Thu Oct 28 21:31:22 UTC 2010,,,,,,,,,,"0|i0g6pz:",92519,,,,,Normal,,,,,,,,,,,,,,,,,"28/Oct/10 21:31;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
describe_schema_versions does not list downed hosts,CASSANDRA-1678,12478609,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,appodictic,appodictic,28/Oct/10 18:15,16/Apr/19 09:33,14/Jul/23 05:51,02/Nov/10 14:05,0.7.0 rc 1,,Legacy/CQL,,0,,,,,,"According to the description unreachable hosts should be listed. It does not seem like they are.
{noformat}
 map<string, list<string>> describe_schema_versions()

  [java] key:c3f38ebc-e1c5-11df-95a0-e700f669bcfc
     [java] 	127.0.0.2
     [java] 	127.0.0.3
     [java] 	127.0.0.4
     [java] 	127.0.0.1

Address         Status State   Load            Token                                       
                                       105444142448428656124184491892431731479    
127.0.0.3       Up     Normal  56.53 KB        43021486531749787992103274496183765897      
127.0.0.1       Up     Normal  56.24 KB        49910048177093876350019363877113991186      
127.0.0.5       Down   Normal  52.49 KB        64377498999076014343862177049497951437      
127.0.0.2       Up     Normal  65.27 KB        84713069031498515281943177906254878023      
127.0.0.4       Up     Normal  55.95 KB        105444142448428656124184491892431731479
{noformat}

The code looks like this:
{noformat}
 Cassandra.Client client = fcw.getClient();
    Map<String,List<String>> sv =client.describe_schema_versions();
    for (Map.Entry<String,List<String>> mapEntry: sv.entrySet()){
      System.out.println(""key:""+mapEntry.getKey());
      for (String listForKey : mapEntry.getValue()){
        System.out.println(""\t""+listForKey);
      }
    }
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Nov/10 13:15;gdusbabek;ASF.LICENSE.NOT.GRANTED--v4-0001-include-dead-hosts-in-unreachable.txt;https://issues.apache.org/jira/secure/attachment/12458631/ASF.LICENSE.NOT.GRANTED--v4-0001-include-dead-hosts-in-unreachable.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,699,,,Wed Nov 03 12:49:55 UTC 2010,,,,,,,,,,"0|i0g6pr:",92518,,,,,Low,,,,,,,,,,,,,,,,,"28/Oct/10 18:30;jbellis;Odd, I see the code trying to add the missing hosts in describeSchemaVersions:

{code}
            results.put(DatabaseDescriptor.INITIAL_VERSION.toString(), missingHostNames);
{code}

But IMO the right fix is to avoid that entirely and do the simple thing instead:

{code}
  /**
   * for each schema version present in the cluster, returns a list of nodes at that version.
   * hosts that do not respond will not be included.
   * the cluster is all on the same version if the size of the map is 1 and the
   * length of the list	in that map value is the number of nodes in the cluster.
   */
{code};;;","29/Oct/10 04:53;appodictic;Yes changing the description would ""Fix"" the problem. At minimum the description should match what the method actually does. I imagine this is used by applications that want to ensure the schema is in place before doing writes. Ignoring downed hosts could be misleading, as users would have to ensure the list size matches the size it should be. You could view that as a separate problem but I think users would want both in one method.;;;","29/Oct/10 19:16;gdusbabek;the 'missing hosts' Jonathan referred to were the live hosts that did not respond to the version query.  There could be other missing hosts that getLiveMembers() didn't return because they were down.

Would it suit everybody if we included the unreachable members at version=DD.INITIAL_VERSION?;;;","29/Oct/10 19:28;jbellis;wfm, although not having a distinction between ""responded that he was at INITIAL_VERSION"" and ""didn't respond"" feels a little unsavory.;;;","29/Oct/10 19:33;gdusbabek;Since they're just strings I could just give them the value ""UNREACHABLE""?;;;","29/Oct/10 19:41;jbellis;+1;;;","29/Oct/10 20:01;appodictic;+1;;;","29/Oct/10 21:31;jbellis;seems to me it would be simpler to just loop through all hosts after versions are received; if host is not in ackedhosts then add it to the unreachable set.  this avoids problems caused by FD moving a node from live to dead or vice versa between requests being sent and processed.;;;","01/Nov/10 22:57;jbellis;minor point: allHosts can be replaced with Iterables.concat(live, unreachable)

is the ""check for version disagreement"" loop still useful now?;;;","02/Nov/10 13:17;gdusbabek;The check is still useful for logging the disagreeing hosts.  When the feature was first created I seem to recall someone wanting it to be logged (didn't make sense to me).

v4 uses the Iterables call.;;;","02/Nov/10 14:00;jbellis;+1;;;","03/Nov/10 12:49;hudson;Integrated in Cassandra #585 (See [https://hudson.apache.org/hudson/job/Cassandra/585/])
    include dead hosts in unreachable. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1678
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Avoid dropping messages off the client request path,CASSANDRA-1676,12478591,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,28/Oct/10 15:36,16/Apr/19 09:33,14/Jul/23 05:51,01/Nov/10 04:07,0.6.7,0.7.0 rc 1,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Oct/10 00:31;jbellis;1676-v2.txt;https://issues.apache.org/jira/secure/attachment/12458496/1676-v2.txt","28/Oct/10 15:37;jbellis;1676.txt;https://issues.apache.org/jira/secure/attachment/12458255/1676.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20254,,,Fri Jan 07 10:01:25 UTC 2011,,,,,,,,,,"0|i0g6pb:",92516,,stuhood,,stuhood,Normal,,,,,,,,,,,,,,,,,"29/Oct/10 04:31;jbellis;Brandon, can you beat up a cluster badly enough to start dropping repair messages like this, now that http://issues.apache.org/jira/browse/CASSANDRA-1677 shows what exactly we're dropping?  AS mentioned in CASSANDRA-1674 we're not really sure what is happening here so I don't want to commit this until we understand that better.;;;","31/Oct/10 00:31;jbellis;rebased and updated post-CASSANDRA-1685 to never drop INTERNAL_RESPONSE messages;;;","31/Oct/10 21:36;stuhood;It doesn't look like CASSANDRA-1685 actually made it in to trunk, so this doesn't compile.;;;","31/Oct/10 23:11;jbellis;patch is against 0.7.;;;","01/Nov/10 03:24;stuhood;+1;;;","01/Nov/10 04:07;jbellis;committed, w/ the slight modification for 0.6 of not dropping any _RESPONSE calls at all since CASSANDRA-1685 isn't backported there.  should be a mostly academic difference since REQUEST_RESPONSE should be essentially instantaneous.;;;","07/Jan/11 10:01;rantav;This bug fixes the ""hanged bootstrap"" problem some which some clusters would see when bootstrapping new nodes. 
See the following threads for more details 
http://www.mail-archive.com/user@cassandra.apache.org/msg07106.html
http://www.mail-archive.com/user@cassandra.apache.org/msg08379.html
http://www.mail-archive.com/user@cassandra.apache.org/msg08441.html;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Repair using abnormally large amounts of disk space,CASSANDRA-1674,12478581,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,jbellis,jbellis,28/Oct/10 14:38,16/Apr/19 09:33,14/Jul/23 05:51,18/Nov/10 01:06,0.6.9,0.7.0 rc 1,,,1,,,,,,"I'm watching a repair on a 7 node cluster.  Repair was sent to one node; the node had 18G of data.  No other node has more than 28G.  The node where the repair initiated is now up to 261G with 53/60 AES tasks outstanding.

I have seen repair take more space than expected on 0.6 but nothing this extreme.

Other nodes in the cluster are occasionally logging
WARN [ScheduledTasks:1] 2010-10-28 08:31:14,305 MessagingService.java (line 515) Dropped 7 messages in the last 1000ms

The cluster is quiesced except for the repair.  Not sure if the dropped messages are contributing the the disk space (b/c of retries?).",,chipdude,johanoskarsson,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Nov/10 19:30;stuhood;0001-Only-repair-the-intersecting-portion-of-a-differing-ra.txt;https://issues.apache.org/jira/secure/attachment/12459816/0001-Only-repair-the-intersecting-portion-of-a-differing-ra.txt","17/Nov/10 19:30;stuhood;for-0.6-0001-Only-repair-the-intersecting-portion-of-a-differing-ra.txt;https://issues.apache.org/jira/secure/attachment/12459817/for-0.6-0001-Only-repair-the-intersecting-portion-of-a-differing-ra.txt",,,,,,,,,,,,,2.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20253,,,Thu Nov 18 01:46:01 UTC 2010,,,,,,,,,,"0|i0g6ov:",92514,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"28/Oct/10 14:38;jbellis;(this is rc1 snapshot, btw);;;","28/Oct/10 15:40;jbellis;bq. WARN [ScheduledTasks:1] 2010-10-28 08:31:14,305 MessagingService.java (line 515) Dropped 7 messages in the last 1000ms

Created CASSANDRA-1676 for this.;;;","28/Oct/10 15:47;stuhood;I haven't tested the theory, but various messages are executed in the single threaded MISC stage.;;;","28/Oct/10 16:05;jbellis;it doesn't have to be single threaded to drop messages, it just has to not run the verbhandler until RPC_TIMEOUT after the message was received.

In practice though I don't see any place where the verbhandler would be blocking or otherwise slow, including the ones running on MISC.;;;","01/Nov/10 04:08;jbellis;so we have CASSANDRA-1685 and CASSANDRA-1676 committed now, but I don't think those are the root cause here since for them to cause lots of disk space usage repair would have to retry dropped requests which I don't see it doing.  (is this correct?);;;","12/Nov/10 03:10;jbellis;Here is one way to reproduce something similar, at least.

I start with 1 node, and put 1M rows on it.  Then I add a 2nd node, then a third, then run cleanup.  So I have 25% 50% 25% of the 1M rows on those 3 machines:

{code}
$ nodetool -h localhost -p 8080 ring
Address         Status State   Load            Token                                       
                                       164074424718159380631425626216484638578    
127.0.0.2       Up     Normal  95.39 MB        36509681143663337709904175976843745575      
127.0.0.1       Up     Normal  190.72 MB       121466565577718822332569289829746132598     
127.0.0.3       Up     Normal  95.4 MB         164074424718159380631425626216484638578     
{code}

I increase the RF to 2, and run repair against .2:

{code}
Address         Status State   Load            Token                                       
                                       164074424718159380631425626216484638578    
127.0.0.2       Up     Normal  381.41 MB       36509681143663337709904175976843745575      
127.0.0.1       Up     Normal  381.41 MB       121466565577718822332569289829746132598     
127.0.0.3       Up     Normal  190.75 MB       164074424718159380631425626216484638578     
{code}

Let's call the ranges of data that .2, .1, and .3 originally had R, G, and B.  Post repair, .2 should have RB but it has RGB.  Node 1 should have GB but it also has RGB.

Cleanup puts things in the expected state:
{code}
Address         Status State   Load            Token                                       
                                       164074424718159380631425626216484638578    
127.0.0.2       Up     Normal  190.74 MB       36509681143663337709904175976843745575      
127.0.0.1       Up     Normal  285.61 MB       121466565577718822332569289829746132598     
127.0.0.3       Up     Normal  190.75 MB       164074424718159380631425626216484638578     
{code}

This is reproducible against 0.6 as well as 0.7.;;;","17/Nov/10 02:03;stuhood;After finding the differences for all data held on both nodes, repair was not limiting the repaired area to the ranges that the nodes had in common. jbellis: In your example above, because the nodes had no data in common to start with, the MerkleTree was determining that they were different for (0,0], but rather than intersecting the different range with the range of responsibility they had in common, it was repairing all of (0,0].

Attaching a patch for 0.7 to only repair the intersecting ranges.;;;","17/Nov/10 02:04;stuhood;I started rebasing this for 0.6, but noticed some odd behaviour in the 0.6 branch: in what cases would SS.getLocalToken not equal the RHS of SS.getLocalPrimaryRange?;;;","17/Nov/10 02:35;chipdude;Surely something that can overflow disks, even when below 50% usage, is worthy of fix before 0.7.0 is released...;;;","17/Nov/10 03:10;stuhood;Chip: agreed. While it was broken before 0.7, it's a small enough fix that we should try to get it in 0.7.0;;;","17/Nov/10 08:56;jbellis;bq. in what cases would SS.getLocalToken not equal the RHS of SS.getLocalPrimaryRange? 

at a guess, some test is mocking up a TokenMetadata that isn't consistent w/ localtoken;;;","17/Nov/10 19:30;stuhood;Patches for 0.6 and 0.7/trunk: ready for review.;;;","17/Nov/10 20:08;jbellis;committed, but I think there is a bug.  With a similar setup to the above (200K keys instead of 1M), the pre-RF change setup is

{code}
Address         Status State   Load            Token                                       
                                       106239986353888428655683112465158427815    
127.0.0.2       Up     Normal  37.97 MB        21212647344528771789748883276744400257      
127.0.0.3       Up     Normal  18.98 MB        63523312719601176253752035031089272162      
127.0.0.1       Up     Normal  19.05 MB        106239986353888428655683112465158427815     
{code}

post-repair is
{code}
Address         Status State   Load            Token                                       
                                       106239986353888428655683112465158427815    
127.0.0.2       Up     Normal  57.01 MB        21212647344528771789748883276744400257      
127.0.0.3       Up     Normal  56.94 MB        63523312719601176253752035031089272162      
127.0.0.1       Up     Normal  19.07 MB        106239986353888428655683112465158427815     
{code}

So eyeballing it looks reasonable.  But when I kill node 2 and run

{code}$ python contrib/py_stress/stress.py -n 200000 -o read{code}

I get a ton of key-not-found exceptions, indicating that not all the data on 2 got replicated to 3.;;;","17/Nov/10 20:37;hudson;Integrated in Cassandra-0.6 #7 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/7/])
    limit repaired ranges to what the nodes have in common
patch by Stu Hood; reviewed by jbellis for CASSANDRA-1674
;;;","18/Nov/10 01:06;jbellis;the not-found was because i only repaired .2, but the RF increase meant requests to .1 thought they could find the .3 data locally.  not a bug.  Thanks to Stu for pointing this out on IRC.;;;","18/Nov/10 01:46;stuhood;This still needs to be committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hinted HandOff are not delivered correctly following change to ByteBuffer,CASSANDRA-1672,12478557,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,slebresne,slebresne,slebresne,28/Oct/10 09:20,16/Apr/19 09:33,14/Jul/23 05:51,28/Oct/10 10:51,0.7 beta 3,,,,0,,,,,,"In trunk (rc1-snapshot), I get a Fatal Exception during hints delivery, the exception being: 
java.lang.RuntimeException: Corrupted hint name java.nio.HeapByteBuffer[pos=0 lim=22 cap=22]

This is due to a misuse of the 3rd parameter of ArrayUtils.lastIndexOf.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Oct/10 09:21;slebresne;0001-Fix-hinted-handoff.patch;https://issues.apache.org/jira/secure/attachment/12458239/0001-Fix-hinted-handoff.patch",,,,,,,,,,,,,,1.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20252,,,Thu Oct 28 10:51:42 UTC 2010,,,,,,,,,,"0|i0g6of:",92512,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"28/Oct/10 10:51;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cannot move a node,CASSANDRA-1670,12478510,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,mdennis,mdennis,27/Oct/10 22:28,16/Apr/19 09:33,14/Jul/23 05:51,03/Nov/10 13:12,0.7.0 rc 1,,,,0,,,,,,"two node cluster (node0, node1).  node0 is listed as the only seed on both nodes.  Listen addresses explicitly set to an IP on both nodes. No initial token, no autobootstrap (but see below).  Bring up the ring.  Everything is fine on both nodes.

decom node1.  verify decom completed correctly by reading the logs on both nodes.  rm all data/logs on node1.  bring node1 up again.

One of two things happen:

* node0 thinks it is in a ring by itself, node1 thinks both nodes are in the ring.
* both node0 and node1 think they are in rings by themselves

If you restart node0 after decom, it appears to work normally.

Similar issues seem to present if you kill node1 (either when autobootstrapping before it completes or after it is in the ring) and removetoken.

",RAX,mbulman,thepaul,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Nov/10 15:59;gdusbabek;1670-0.6.txt;https://issues.apache.org/jira/secure/attachment/12458550/1670-0.6.txt","01/Nov/10 16:28;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-code-that-tidied-Gossiper.justRemovedEndpoints_-was-no.txt;https://issues.apache.org/jira/secure/attachment/12458552/ASF.LICENSE.NOT.GRANTED--v1-0001-code-that-tidied-Gossiper.justRemovedEndpoints_-was-no.txt",,,,,,,,,,,,,2.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20250,,,Wed Nov 03 13:07:03 UTC 2010,,,,,,,,,,"0|i0g6nz:",92510,,,,,Normal,,,,,,,,,,,,,,,,,"29/Oct/10 21:38;mbulman;Because move is decommission+bootstrap, the same behavior occurs when moving node1 as well.;;;","01/Nov/10 15:54;gdusbabek;Looks like this bug goes all the way back to 0.6.;;;","01/Nov/10 15:59;gdusbabek;The code that removes endpoints from Gossiper.justRemovedEndpoints after RING_DELAY was only getting called if the endpoint had a state attached to it.  Since state is removed for decommissioned nodes, the code was never getting called. ;;;","01/Nov/10 16:06;jbellis;how does moving the removal out of the for loop fix the state-attached-to-it problem?;;;","01/Nov/10 16:38;gdusbabek;When a node is decommissioned, it gets added to justRemovedEndpoints_, but removed from endpointStateMap_.  The old code will only remove a node from justRemovedEndpoints_ if it currently exists in endpointStateMap_.  If the node stays in justRemovedEndpoints_ (which it will currently), it can never be recognized as part of the ring because of the check in Gossiper.handleNewJoin().;;;","01/Nov/10 22:47;mbulman;Running from nodetool as well as ripcord decommission code (direct call to StorageService) gets:

Exception in thread ""main"" java.lang.AssertionError
        at org.apache.cassandra.service.StorageService.getLocalToken(StorageService.java:1128)
        at org.apache.cassandra.service.StorageService.startLeaving(StorageService.java:1527)
        at org.apache.cassandra.service.StorageService.decommission(StorageService.java:1546)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:616)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:111)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:45)
        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:226)
        at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)
        at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:251)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:857)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:795)
        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1450)
        at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:90)
        at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1285)
        at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1383)
        at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:807)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:616)
        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:322)
        at sun.rmi.transport.Transport$1.run(Transport.java:177)
        at java.security.AccessController.doPrivileged(Native Method)
        at sun.rmi.transport.Transport.serviceCall(Transport.java:173)
        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:553)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:808)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:667)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636);;;","02/Nov/10 14:11;gdusbabek;Mike, can you provide a more complete log?  That trace is unrelated to the patch and likely indicates a different problem.;;;","02/Nov/10 15:24;mbulman;That's all I get.  The only other thing I can add is that the node being decommissioned logs ""DECOMMISSIONING"" when level is set to DEBUG, and that the exception comes back almost immediately.  fwiw, I'm running this on r1029870 of the .7 branch;;;","02/Nov/10 15:34;gdusbabek;There should be more. What I'm looking for is some indication that the node is not in the middle of a bootstrap operation, which would trigger this exception.;;;","02/Nov/10 16:34;mbulman;INFO 15:48:22,176 Joining: getting load information                                                                                                                                                                        
 INFO 15:48:22,177 Sleeping 90000 ms to wait for load information...
DEBUG 15:48:23,053 GC for ParNew: 12 ms, 15822112 reclaimed leaving 15102720 used; max is 1268449280                                                                                                                        
DEBUG 15:48:23,166 attempting to connect to /184.106.231.n0
 INFO 15:48:23,553 Node /184.106.231.n0 is now part of the cluster                                                                                                                                                         
DEBUG 15:48:23,554 Resetting pool for /184.106.231.n0
DEBUG 15:48:23,559 Node /184.106.231.n0 state normal, token 104110673354167092736227093944218730763                                                                                                                        
DEBUG 15:48:23,559 New node /184.106.231.n0 at token 104110673354167092736227093944218730763
DEBUG 15:48:23,559 clearing cached endpoints                                                                                                                                                                                
DEBUG 15:48:24,167 attempting to connect to /184.106.231.n0
DEBUG 15:48:24,169 Disseminating load info ...                                                                                                                                                                              
 INFO 15:48:24,554 InetAddress /184.106.231.n0 is now UP
 INFO 15:48:24,554 Started hinted handoff for endpoint /184.106.231.n0                                                                                                                                                  
 INFO 15:48:24,557 Finished hinted handoff of 0 rows to endpoint /184.106.231.n0
DEBUG 15:49:24,169 Disseminating load info ...                                                                                                                                                                              
DEBUG 15:49:39,106 GC for ParNew: 16 ms, 16111512 reclaimed leaving 85537648 used; max is 1268449280
DEBUG 15:49:52,177 ... got load info                                                                                              
 INFO 15:49:52,177 Joining: getting bootstrap token
DEBUG 15:49:52,183 attempting to connect to /184.106.231.n0                                                                                                                                                                
DEBUG 15:49:52,191 Processing response on a callback from 270@/184.106.231.n0
 INFO 15:49:52,192 New token will be 19040081623932476870383442086276677899 to assume load from /184.106.231.n0                                                                                                             
DEBUG 15:49:52,193 clearing cached endpoints
DEBUG 15:49:52,194 Will try to load mx4j now, if it's in the classpath                                                                                                                                                      
 INFO 15:49:52,194 Will not load MX4J, mx4j-tools.jar is not in the classpath
 INFO 15:49:52,220 Binding thrift service to /0.0.0.0:9160                                                                                                                                                                  
 INFO 15:49:52,222 Using TFramedTransport with a max frame size of 15728640 bytes.
 INFO 15:49:52,226 Listening for thrift clients...                                                                                                                                                                          
DEBUG 15:50:24,170 Disseminating load info ...
DEBUG 15:50:52,247 DECOMMISSIONING                                                                                                                                                                                          
DEBUG 15:51:24,170 Disseminating load info ...
DEBUG 15:52:24,171 Disseminating load info ...                                                                                                                                                                              


From n0:

root@ripcord:/usr/src/cassandra/branches/cassandra-0.7# bin/nodetool -h 184.106.231.n0  ring                                                                                                                           
Address         Status State   Load            Token
                                       104110673354167092736227093944218730763                                                                                                                                             
184.106.228.n1 Up     Normal  5.3 KB          19040081623932476870383442086276677899
184.106.231.n0 Up     Normal  10.27 KB        104110673354167092736227093944218730763                                                                                                                                     

root@ripcord:/usr/src/cassandra/branches/cassandra-0.7# bin/nodetool -h 184.106.228.n1 decommission 
     <TRACE FROM MY PREVIOUS COMMENT>

root@ripcord:/usr/src/cassandra/branches/cassandra-0.7# bin/nodetool -h 184.106.231.n0 ring
Address         Status State   Load            Token                                       
                                       104110673354167092736227093944218730763    
184.106.228.n1 Up     Normal  5.3 KB          19040081623932476870383442086276677899      
184.106.231.n0 Up     Normal  10.27 KB        104110673354167092736227093944218730763     
;;;","02/Nov/10 22:25;mbulman;Ok got it working properly.  Patch fixes the issue described.

As a node, that patch doesn't work in 0.7 branch because justRemovedEndPoints_ (.6) is now justRemovedEndpoints (.7).  Not sure how you guys handle that, but the change is simple enough.;;;","02/Nov/10 22:58;jbellis;bq. The old code will only remove a node from justRemovedEndpoints_ if it currently exists in endpointStateMap_

Isn't it ""remove from jRE if _any_ [other] node exists in eSM?""  Which means this is only a bug in 2-node clusters?

+1 if so, just trying to understand.;;;","03/Nov/10 13:07;gdusbabek;bq. sn't it ""remove from jRE if any [other] node exists in eSM?"" Which means this is only a bug in 2-node clusters?
Yes. good observation.  I'll only bother committing this to 0.7/trunk then.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
logging error on C* startup: Nodes /10.194.241.188 and /10.194.241.188 have the same token 85070591730234615865843651857942052863,CASSANDRA-1666,12478413,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,mdennis,mdennis,27/Oct/10 01:44,16/Apr/19 09:33,14/Jul/23 05:51,28/Oct/10 14:47,0.7 beta 3,,,,0,,,,,,"When restarting my cluster, I noticed that a

{code}Nodes /10.194.241.188 and /10.194.241.188 have the same token 85070591730234615865843651857942052863{code} error message.  Notice the IPs are the same.  The cluster came up fine and nodetool ring shows all nodes up so it's likely just a logging error.
",EC2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Oct/10 11:42;jbellis;1666.txt;https://issues.apache.org/jira/secure/attachment/12458245/1666.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20249,,,Thu Oct 28 14:47:46 UTC 2010,,,,,,,,,,"0|i0g6n3:",92506,,gdusbabek,,gdusbabek,Low,,,,,,,,,,,,,,,,,"28/Oct/10 12:44;gdusbabek;+1;;;","28/Oct/10 14:47;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JMX threads leak in NodeProbe,CASSANDRA-1665,12478392,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,billa,billa,billa,26/Oct/10 20:32,16/Apr/19 09:33,14/Jul/23 05:51,26/Oct/10 23:12,0.7.0 rc 2,,Legacy/Tools,,0,,,,,,There is a JMX threads leak in NodeProbe.  It creates and uses a JMXConnector but never calls its close() method.  I am working on a patch which add a close() method to NodeProbe  that calls JMXConnector.close().,,dehora,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Oct/10 21:59;billa;trunk-1665.txt;https://issues.apache.org/jira/secure/attachment/12458109/trunk-1665.txt",,,,,,,,,,,,,,1.0,billa,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20248,,,Tue Oct 26 23:12:00 UTC 2010,,,,,,,,,,"0|i0g6mv:",92505,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"26/Oct/10 21:59;billa;I have added a close() method to NodeProbe.  I have also added a close() method that calls NodeProbe.close() to ClusterCmd since it creates its own private instance of NodeProbe in its constructors..;;;","26/Oct/10 23:12;jbellis;committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RPM spec file should create saved_caches directory,CASSANDRA-1662,12478253,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,drevell,drevell,drevell,25/Oct/10 18:07,16/Apr/19 09:33,14/Jul/23 05:51,26/Oct/10 13:06,0.7.0 rc 2,,Packaging,,0,,,,,,"After installing the 0.6.6 RPM from rpm.riptano.com, the directories /var/lib/cassandra/data and /var/lib/cassandra/commitlog exist, but /var/lib/cassandra saved_caches does not exist. Cassandra fails to startup with ""java.io.IOException: unable to mkdirs /var/lib/cassandra/saved_caches"".

After manually creating /var/lib/cassandra/saved_caches, Cassandra can start.",CentOS 5 64-bit,brandon.williams,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Oct/10 18:08;drevell;spec-0.6.6.diff;https://issues.apache.org/jira/secure/attachment/12457986/spec-0.6.6.diff",,,,,,,,,,,,,,1.0,drevell,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20246,,,Wed Oct 27 12:49:21 UTC 2010,,,,,,,,,,"0|i0g6m7:",92502,,brandon.williams,,brandon.williams,Low,,,,,,,,,,,,,,,,,"26/Oct/10 13:06;brandon.williams;Committed since this is the correct thing to do, however it's unclear to me why cassandra couldn't make the directory since it should own /var/lib/cassandra.;;;","27/Oct/10 12:49;hudson;Integrated in Cassandra #578 (See [https://hudson.apache.org/hudson/job/Cassandra/578/])
    RPM spec file creates saved_caches directory.  Patch by Dave Revell, reviewed by brandonwilliams for CASSANDRA-1662
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use of ByteBuffer limit() must account for arrayOffset(),CASSANDRA-1661,12478239,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,tjake,tjake,tjake,25/Oct/10 15:06,16/Apr/19 09:33,14/Jul/23 05:51,26/Oct/10 03:14,0.7 beta 3,,,,0,,,,,,"There are a few places in the code where it loops across a byte buffers backing array wrong:


        for (int i=bytes.position()+bytes.arrayOffset(); i<bytes.limit(); i++)

This is incorrect as the limit() does not account for arrayOffset()

              for (int i=bytes.position()+bytes.arrayOffset(); i<bytes.limit()+bytes.arrayOffset(); i++)

is the correct code.

There is also a few places where the unit tests would fail if we used non wrapped byte arrays.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Oct/10 15:07;tjake;1661_v1.txt;https://issues.apache.org/jira/secure/attachment/12457974/1661_v1.txt","25/Oct/10 18:31;tjake;1661_v2.txt;https://issues.apache.org/jira/secure/attachment/12457989/1661_v2.txt",,,,,,,,,,,,,2.0,tjake,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20245,,,Tue Oct 26 03:14:43 UTC 2010,,,,,,,,,,"0|i0g6lz:",92501,,stuhood,,stuhood,Normal,,,,,,,,,,,,,,,,,"25/Oct/10 15:09;stuhood;Regarding failing unit tests: a utility function that calls the allocator from 1651 would probably shorten the code and catch a lot of these.;;;","25/Oct/10 15:21;tjake;good idea, I'll address it with that ticket;;;","25/Oct/10 16:24;stuhood;* A few of the loops involving direct array access (in particular the one in RandomPartitioner) could be simplified with judicious use of mark() and get()
* Adding the follow function and using it in the tests would clarify things a lot: CFSTest looks like it exploded.
{code:java}public static ByteBuffer bytes(String s) { return ByteBuffer.wrap(s.getBytes(UTF_8)); }{code}
* Converting BytesToken to ByteBuffer storage would clean up a ton of special casing (should probably be tackled in a separate issue though)
* ByteBufferTest is literally a test of ByteBuffers: I don't think it should be in C*

Thanks!;;;","25/Oct/10 16:29;jbellis;bq. simplified with judicious use of mark() and get()

I worry that we're going to introduce very very tricky bugs if we don't treat position as immutable.  If BB/Thrift were sane about using offset to represent the start of what we're allowed to mess with, that would be another story, but it's not -- Thrift uses wrap to generate the BB it gives us, so position is the only indication we have of what a given BB is supposed to cover.

bq. ByteBufferTest is literally a test of ByteBuffers: I don't think it should be in C*

OTOH ByteBuffer is a tricky enough API (see: this ticket :) that I don't mind having BBT as an illustration of what is going on if not exactly a test.

Maybe docstring in BBUtil instead of actual tests?;;;","25/Oct/10 16:30;jbellis;bq. Converting BytesToken to ByteBuffer storage

As background, this is an artifact of MerkleTree requiring serializable Tokens.  Using byte[] there was the easiest way to get that.  (Not necessarily the best, I agree.);;;","25/Oct/10 16:32;tjake;  * A few of the loops involving direct array access (in particular the one in RandomPartitioner) could be simplified with judicious use of mark() and get()
   *A previous version of the BB patch did exactly this, but Johnathan thought it would be better to treat ByteBuffers as immutable so avoid changing position and mark.*


  * Adding the follow function and using it in the tests would clarify things a lot: CFSTest looks like it exploded.
     *I agree this is a mess, if you think it should be fixed in this patch ok, but it seems like a small issue.*

  * Converting BytesToken to ByteBuffer storage would clean up a ton of special casing (should probably be tackled in a separate issue though)
     *I had also done this in a previous patch but it broke MerkleTree serialization*

  * ByteBufferTest is literally a test of ByteBuffers: I don't think it should be in C
     *I put it in there incase others have questions about how ByteBuffers work.*

 ;;;","25/Oct/10 16:40;jbellis;bq. Adding the follow function and using it in the tests would clarify things a lot

+1 doing this.;;;","25/Oct/10 16:43;stuhood;> better to treat ByteBuffers as immutable so avoid changing position and mark
In cases where the buffer should be immutable, you'd need to duplicate() it first.

> should be fixed in this patch ok, but it seems like a small issue
It's a small function: waiting any longer to add it isn't worth it, imo.

> I put it in there incase others have questions about how ByteBuffers work.
I'm out-numbered on this one I guess.;;;","25/Oct/10 18:31;tjake;New version:

  * Puts BB test in BBUtil javadoc
  * Cleans up tests with new BBUtil call
  * Fixes Pig and word count;;;","25/Oct/10 18:43;stuhood;+1 All that is left is nitpicks, which you can choose to ignore:

> Cleans up tests with new BBUtil call
A static import might be the last bit of sugar to make this a real win.

Code style dictates that there should be spaces around operators.;;;","26/Oct/10 03:14;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Config converter should set framed transport by default,CASSANDRA-1659,12478166,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,stuhood,stuhood,23/Oct/10 23:12,16/Apr/19 09:33,14/Jul/23 05:51,24/Oct/10 01:10,0.7 beta 3,,,,0,,,,,,"Our built in clients require the framed transport, so it makes sense to enable it by default in the config converter.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/10 23:13;stuhood;1659.txt;https://issues.apache.org/jira/secure/attachment/12457913/1659.txt",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20244,,,Sun Oct 24 12:48:58 UTC 2010,,,,,,,,,,"0|i0g6lj:",92499,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"24/Oct/10 01:10;jbellis;committed;;;","24/Oct/10 12:48;hudson;Integrated in Cassandra #575 (See [https://hudson.apache.org/hudson/job/Cassandra/575/])
    update Converter to switch default thrift mode to framed.  patch by Stu Hood; reviewed by jbellis for CASSANDRA-1659
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hinted handoff does not replay data,CASSANDRA-1656,12478159,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,23/Oct/10 18:21,16/Apr/19 09:33,14/Jul/23 05:51,26/Oct/10 11:00,0.6.7,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/10 18:22;jbellis;1656.txt;https://issues.apache.org/jira/secure/attachment/12457906/1656.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20243,,,Tue Oct 26 11:01:19 UTC 2010,,,,,,,,,,"0|i0g6kv:",92496,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"23/Oct/10 19:47;brandon.williams;+1;;;","26/Oct/10 11:00;jbellis;committed;;;","26/Oct/10 11:01;jbellis;(as noted on the mailing list, this does not affect 0.7);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Config converter fails,CASSANDRA-1655,12478153,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,stuhood,stuhood,stuhood,23/Oct/10 16:27,16/Apr/19 09:33,14/Jul/23 05:51,23/Oct/10 17:37,0.7 beta 3,,Legacy/Tools,,0,,,,,,"Trying to run the config converter for an 0.6.6 -> 0.7.0-rc1 upgrade failed with the following exception:
{code:java}
stuhood@stu-laptop:~/src/cassandra/apache-cassandra-0.7.0-rc1$ bin/config-converter storage-conf.xml cassandra.yaml
WARN : Thrift uses framed Transport by default in 0.7! Setting TFramedTransportSize to 0MB (disabled).
Exception in thread ""main"" java.lang.ExceptionInInitializerError
	at org.apache.cassandra.config.CFMetaData.<clinit>(CFMetaData.java:63)
	at org.apache.cassandra.config.Converter.readTablesFromXml(Converter.java:77)
	at org.apache.cassandra.config.Converter.loadPreviousConfig(Converter.java:308)
	at org.apache.cassandra.config.Converter.main(Converter.java:359)
Caused by: java.lang.RuntimeException: java.lang.NullPointerException
	at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:389)
	... 4 more
Caused by: java.lang.NullPointerException
	at org.apache.cassandra.config.KSMetaData.<init>(KSMetaData.java:50)
	at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:349)
	... 4 more
Exception in thread ""PERIODIC-COMMIT-LOG-SYNCER"" java.lang.NoClassDefFoundError: Could not initialize class org.apache.cassandra.config.DatabaseDescriptor
	at org.apache.cassandra.db.commitlog.CommitLog$2.run(CommitLog.java:136)
	at java.lang.Thread.run(Thread.java:619)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/10 16:38;stuhood;0001-Move-static-methods-needed-for-config-conversion-to-.patch;https://issues.apache.org/jira/secure/attachment/12457904/0001-Move-static-methods-needed-for-config-conversion-to-.patch",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20242,,,Sun Oct 24 12:48:59 UTC 2010,,,,,,,,,,"0|i0g6kn:",92495,,jbellis,,jbellis,Critical,,,,,,,,,,,,,,,,,"23/Oct/10 16:38;stuhood;CFMetaData was using DatabaseDescriptor during construction.;;;","23/Oct/10 17:37;jbellis;committed, thanks!;;;","24/Oct/10 12:48;hudson;Integrated in Cassandra #575 (See [https://hudson.apache.org/hudson/job/Cassandra/575/])
    avoid initializing DatabaseDescriptor during CFMetadata construction.  patch by Stu Hood; reviewed by jbellis for CASSANDRA-1655
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
removetoken is broken,CASSANDRA-1650,12478109,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,nickmbailey,brandon.williams,brandon.williams,22/Oct/10 19:44,16/Apr/19 09:33,14/Jul/23 05:51,22/Oct/10 21:14,0.7 beta 3,,,,0,,,,,,"When running removetoken on a dead node, it hangs forever.  The debug log shows:

DEBUG 19:45:53,794 Node /10.179.111.137 ranges [(115049868157599339472315320703867977321,62676456546693435176060154681903071729]]
DEBUG 19:45:53,795 Range (115049868157599339472315320703867977321,62676456546693435176060154681903071729] will be responsibility of cassandra-1/10.179.65.102
DEBUG 19:45:53,798 Pending ranges:
cassandra-1/10.179.65.102:(115049868157599339472315320703867977321,62676456546693435176060154681903071729]

DEBUG 19:45:53,798 Node /10.179.111.137 ranges [(115049868157599339472315320703867977321,62676456546693435176060154681903071729]]
DEBUG 19:45:53,799 Range (115049868157599339472315320703867977321,62676456546693435176060154681903071729] will be responsibility of cassandra-1/10.179.65.102
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Oct/10 21:05;nickmbailey;0001-Don-t-wait-for-confirmation-when-replication-factor-.patch;https://issues.apache.org/jira/secure/attachment/12457872/0001-Don-t-wait-for-confirmation-when-replication-factor-.patch",,,,,,,,,,,,,,1.0,nickmbailey,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20240,,,Sat Oct 23 12:49:04 UTC 2010,,,,,,,,,,"0|i0g6jb:",92489,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"22/Oct/10 20:03;nickmbailey;So removetoken blocks for all new replicas to confirm they have the data for the node being removed.  You can actually run ""removetoken status"" to see which nodes are being waited on.  Since a dropped confirm message or stream request could cause it to block forever you can run ""removetoken force"" to finish a removal already in progress.  

There could be a bug here as well or possibly a dropped message?

There should probably be new documentation about this in the wiki.;;;","22/Oct/10 20:06;brandon.williams;My RF is 1, so there are no replicas to block for.  Here's the status output:

RemovalStatus: Removing token (62676456546693435176060154681903071729). Waiting for replication confirmation from [cassandra-1/10.179.65.102].

It seems to be waiting for confirmation from itself.;;;","22/Oct/10 20:07;brandon.williams;Also, force does not work:

Exception in thread ""main"" java.lang.UnsupportedOperationException: Node /10.179.111.137 is already being removed.
;;;","22/Oct/10 21:05;nickmbailey;When replication factor is 1 it is impossible to recover data so we shouldn't wait for confirmation.;;;","22/Oct/10 21:14;brandon.williams;+1, committed.;;;","23/Oct/10 12:49;hudson;Integrated in Cassandra #574 (See [https://hudson.apache.org/hudson/job/Cassandra/574/])
    Don't wait for confirmation when removing token and RF=1.  Patch by Nick Bailey, reviewed by brandonwilliams for CASSANDRA-1650
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Queries on system keyspace over thrift api all fail,CASSANDRA-1649,12478089,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,thepaul,thepaul,22/Oct/10 16:37,16/Apr/19 09:33,14/Jul/23 05:51,22/Oct/10 21:17,0.7 beta 3,,Legacy/CQL,,0,,,,,,"as far as I can tell, any calls to get, get_slice, get_range_slices, get_count, etc on any ColumnFamily in the ""system"" keyspace results in an error like the following:

{noformat}
ERROR 16:29:41,278 Internal error processing get
java.lang.AssertionError: No replica strategy configured for system
        at org.apache.cassandra.service.StorageService.getReplicationStrategy(StorageService.java:315)
        at org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:1459)
        at org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:1447)
        at org.apache.cassandra.service.StorageService.findSuitableEndpoint(StorageService.java:1493)
        at org.apache.cassandra.service.StorageProxy.weakRead(StorageProxy.java:245)
        at org.apache.cassandra.service.StorageProxy.readProtocol(StorageProxy.java:224)
        at org.apache.cassandra.thrift.CassandraServer.readColumnFamily(CassandraServer.java:131) 
        at org.apache.cassandra.thrift.CassandraServer.get(CassandraServer.java:324)
        at org.apache.cassandra.thrift.Cassandra$Processor$get.process(Cassandra.java:2655)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:2555)
        at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
{noformat}

Might be only when this is done over the thrift api.  I don't even know how to use the avro api or query in any other way.  But at least this sort of thing used to work around a week ago.","Debian Squeeze, cassandra svn HEAD (r1026380)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Oct/10 20:55;thepaul;1649-system-test.txt;https://issues.apache.org/jira/secure/attachment/12457870/1649-system-test.txt","22/Oct/10 18:48;jbellis;1649.txt;https://issues.apache.org/jira/secure/attachment/12457859/1649.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20239,,,Sat Oct 23 12:49:05 UTC 2010,,,,,,,,,,"0|i0g6j3:",92488,,thepaul,,thepaul,Low,,,,,,,,,,,,,,,,,"22/Oct/10 18:48;jbellis;moves strategy creation into Table instantiation so it can't be out of sync;;;","22/Oct/10 20:55;thepaul;An addition to test/system/test_thrift_server.py which makes sure queries to the system keyspace can be made;;;","22/Oct/10 21:17;jbellis;test passes both with and without this patch, so the problem must be subtle, but I still think this patch has a good chance of stopping it.  committed.;;;","23/Oct/10 12:49;hudson;Integrated in Cassandra #574 (See [https://hudson.apache.org/hudson/job/Cassandra/574/])
    move strategy creation into Table instantiation so it can't be out of sync
patch by jbellis; tested by Paul Cannon for CASSANDRA-1649
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CliTest crashing intermittently,CASSANDRA-1648,12478071,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,xedin,jbellis,jbellis,22/Oct/10 14:37,16/Apr/19 09:33,14/Jul/23 05:51,26/Oct/10 23:20,0.7 beta 3,,Legacy/Tools,,0,,,,,,"About 50% of the time I get

{code}
$ ant test -Dtest.name=CliTest
...
    [junit] Test org.apache.cassandra.cli.CliTest FAILED (crashed)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Oct/10 15:49;xedin;CASSANDRA-1648.patch;https://issues.apache.org/jira/secure/attachment/12458077/CASSANDRA-1648.patch",,,,,,,,,,,,,,1.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20238,,,Wed Oct 27 08:44:46 UTC 2010,,,,,,,,,,"0|i0g6iv:",92487,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"22/Oct/10 15:06;xedin;I got such a thing few times too - this happens because EmbeddedCassandraService fails to start sometimes for no reason... Thats why I though it would be better to ask user to start server by hand first...;;;","26/Oct/10 23:05;jbellis;Does just extending CleanupHelper fix it?;;;","26/Oct/10 23:20;jbellis;Yes, CleanupHelper ftw.

Thanks for figuring out the problem!;;;","27/Oct/10 08:44;xedin;Yes, this is what was needed and I overlooked that we have CleanupHelper, sorry...;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Using QUORUM and replication factor of 1 now causes a timeout exception,CASSANDRA-1646,12478042,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,jbellis,tnine,tnine,22/Oct/10 02:56,16/Apr/19 09:33,14/Jul/23 05:51,22/Oct/10 13:59,0.7 beta 3,,,,0,,,,,,See the attached path to the python thrift tests.  On the source from 2010-10-14 20:00 UTC this passed.  From the latest HEAD as of today this fails. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Oct/10 03:01;tnine;test_quorum.patch;https://issues.apache.org/jira/secure/attachment/12457814/test_quorum.patch",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20237,,,Fri Oct 22 13:59:53 UTC 2010,,,,,,,,,,"0|i0g6if:",92485,,,,,Critical,,,,,,,,,,,,,,,,,"22/Oct/10 03:01;tnine;Patch file to update function tests.;;;","22/Oct/10 13:59;jbellis;caused by bad merge from CASSANDRA-1622.  thanks for the test case!  fixed in r1026327.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bootstrapping new node causes RowMutationVerbHandler Couldn't find cfId,CASSANDRA-1645,12478033,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,bterm,bterm,21/Oct/10 21:26,16/Apr/19 09:33,14/Jul/23 05:51,28/Oct/10 21:25,0.7.0 rc 1,,,,0,,,,,,"Existing 0.7.0-beta2 cluster adding 1 new node with no data data on it. Enable bootstrapping and start new node and received stream of Couldn't find cfId, added keyspaces via cli and errors stopped. Node did not bootstrap.


ERROR [MUTATION_STAGE:6] 2010-10-21 15:46:58,950 RowMutationVerbHandler.java (line 81) Error in row mutation
org.apache.cassandra.db.UnserializableColumnFamilyException: Couldn't find cfId=1011
        at org.apache.cassandra.db.ColumnFamilySerializer.deserialize(ColumnFamilySerializer.java:113)
        at org.apache.cassandra.db.RowMutationSerializer.defreezeTheMaps(RowMutation.java:365)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:375)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:333)
        at org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:49)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
ERROR [MUTATION_STAGE:21] 2010-10-21 15:46:58,950 RowMutationVerbHandler.java (line 81) Error in row mutation
org.apache.cassandra.db.UnserializableColumnFamilyException: Couldn't find cfId=1011
        at org.apache.cassandra.db.ColumnFamilySerializer.deserialize(ColumnFamilySerializer.java:113)
        at org.apache.cassandra.db.RowMutationSerializer.defreezeTheMaps(RowMutation.java:365)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:375)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:333)
        at org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:49)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
ERROR [MUTATION_STAGE:31] 2010-10-21 15:46:58,950 RowMutationVerbHandler.java (line 81) Error in row mutation
org.apache.cassandra.db.UnserializableColumnFamilyException: Couldn't find cfId=1016
        at org.apache.cassandra.db.ColumnFamilySerializer.deserialize(ColumnFamilySerializer.java:113)
        at org.apache.cassandra.db.RowMutationSerializer.defreezeTheMaps(RowMutation.java:365)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:375)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:333)
        at org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:49)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
ERROR [MUTATION_STAGE:4] 2010-10-21 15:46:58,950 RowMutationVerbHandler.java (line 81) Error in row mutation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Oct/10 21:31;stuhood;1645.diff;https://issues.apache.org/jira/secure/attachment/12457873/1645.diff","28/Oct/10 21:20;gdusbabek;ASF.LICENSE.NOT.GRANTED--v2-0001-FBU.decodeToUtf8-duplicates-the-BB-so-other-threads-ca.txt;https://issues.apache.org/jira/secure/attachment/12458280/ASF.LICENSE.NOT.GRANTED--v2-0001-FBU.decodeToUtf8-duplicates-the-BB-so-other-threads-ca.txt","28/Oct/10 21:20;gdusbabek;ASF.LICENSE.NOT.GRANTED--v2-0002-BytesToken.convertByteBuffer-duplicates-the-BB-so-othe.txt;https://issues.apache.org/jira/secure/attachment/12458281/ASF.LICENSE.NOT.GRANTED--v2-0002-BytesToken.convertByteBuffer-duplicates-the-BB-so-othe.txt",,,,,,,,,,,,3.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20236,,,Fri Oct 29 15:41:25 UTC 2010,,,,,,,,,,"0|i0g6i7:",92484,,,,,Normal,,,,,,,,,,,,,,,,,"21/Oct/10 21:35;jbellis;is this reproducible for you?  if so, can you try the latest nightly build?  (https://hudson.apache.org/hudson/job/Cassandra/lastSuccessfulBuild/artifact/cassandra/build/);;;","22/Oct/10 17:41;brandon.williams;Can't reproduce against trunk, this is was likely fixed sometime after beta2.;;;","22/Oct/10 20:48;brandon.williams;Reproduced upgrading beta2 to trunk.  The underlying cause is that there is a problem deserializing the schema, but the bootstrap continues on anyway and then doesn't know about the CFs when it's done.

 INFO 20:43:00,007 Sleeping 90000 ms to wait for load information...
ERROR 20:43:00,291 Error in ThreadPoolExecutor
java.lang.ClassCastException: org.apache.avro.generic.GenericData$Record cannot be cast to org.apache.cassandra.avro.KsDef
        at org.apache.cassandra.db.migration.avro.AddKeyspace.put(AddKeyspace.java:24)
        at org.apache.avro.generic.GenericDatumReader.setField(GenericDatumReader.java:152)
        at org.apache.avro.generic.GenericDatumReader.readRecord(GenericDatumReader.java:142)
        at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:114)
        at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:118)
        at org.apache.avro.generic.GenericDatumReader.readRecord(GenericDatumReader.java:142)
        at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:114)
        at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:105)
        at org.apache.cassandra.io.SerDeUtils.deserializeWithSchema(SerDeUtils.java:98)
        at org.apache.cassandra.db.migration.Migration.deserialize(Migration.java:262)
        at org.apache.cassandra.db.DefinitionsUpdateResponseVerbHandler.doVerb(DefinitionsUpdateResponseVerbHandler.java:57)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
ERROR 20:43:00,293 Fatal exception in thread Thread[ReadStage:1,5,main]
java.lang.ClassCastException: org.apache.avro.generic.GenericData$Record cannot be cast to org.apache.cassandra.avro.KsDef
        at org.apache.cassandra.db.migration.avro.AddKeyspace.put(AddKeyspace.java:24)
        at org.apache.avro.generic.GenericDatumReader.setField(GenericDatumReader.java:152)
        at org.apache.avro.generic.GenericDatumReader.readRecord(GenericDatumReader.java:142)
        at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:114)
        at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:118)
        at org.apache.avro.generic.GenericDatumReader.readRecord(GenericDatumReader.java:142)
        at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:114)
        at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:105)
        at org.apache.cassandra.io.SerDeUtils.deserializeWithSchema(SerDeUtils.java:98)
        at org.apache.cassandra.db.migration.Migration.deserialize(Migration.java:262)
        at org.apache.cassandra.db.DefinitionsUpdateResponseVerbHandler.doVerb(DefinitionsUpdateResponseVerbHandler.java:57)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)


;;;","22/Oct/10 21:43;brandon.williams;+1, committed.;;;","23/Oct/10 12:49;hudson;Integrated in Cassandra #574 (See [https://hudson.apache.org/hudson/job/Cassandra/574/])
    Return correct SpecificDatumReader for schema records.  Patch by Stu Hood, reviewed by brandonwilliams for CASSANDRA-1645.
;;;","27/Oct/10 22:30;bterm;upgraded thrift to 0.5.0, upgraded cassandra to 0.7.0-rc1, removed all data and logs. used default configuration other than changing ip addresses. started cassandra and created keyspaces via cli and started sending data to cassandra. 


ERROR [MutationStage:19] 2010-10-27 17:21:46,739 RowMutationVerbHandler.java (line 83) Error in row mutation
org.apache.cassandra.db.UnserializableColumnFamilyException: Couldn't find cfId=1018
        at org.apache.cassandra.db.ColumnFamilySerializer.deserialize(ColumnFamilySerializer.java:112)
        at org.apache.cassandra.db.RowMutationSerializer.defreezeTheMaps(RowMutation.java:368)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:378)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:336)
        at org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:52)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
ERROR [MutationStage:25] 2010-10-27 17:21:46,739 RowMutationVerbHandler.java (line 83) Error in row mutation
org.apache.cassandra.db.UnserializableColumnFamilyException: Couldn't find cfId=1013
        at org.apache.cassandra.db.ColumnFamilySerializer.deserialize(ColumnFamilySerializer.java:112)
        at org.apache.cassandra.db.RowMutationSerializer.defreezeTheMaps(RowMutation.java:368)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:378)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:336)
        at org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:52)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
ERROR [MutationStage:27] 2010-10-27 17:21:46,739 RowMutationVerbHandler.java (line 83) Error in row mutation
org.apache.cassandra.db.UnserializableColumnFamilyException: Couldn't find cfId=1018
        at org.apache.cassandra.db.ColumnFamilySerializer.deserialize(ColumnFamilySerializer.java:112)
        at org.apache.cassandra.db.RowMutationSerializer.defreezeTheMaps(RowMutation.java:368)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:378)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:336)
        at org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:52)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
ERROR [MutationStage:18] 2010-10-27 17:21:46,739 RowMutationVerbHandler.java (line 83) Error in row mutation
org.apache.cassandra.db.UnserializableColumnFamilyException: Couldn't find cfId=1013
        at org.apache.cassandra.db.ColumnFamilySerializer.deserialize(ColumnFamilySerializer.java:112)
        at org.apache.cassandra.db.RowMutationSerializer.defreezeTheMaps(RowMutation.java:368)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:378)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:336)
        at org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:52)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
ERROR [MutationStage:14] 2010-10-27 17:21:46,739 RowMutationVerbHandler.java (line 83) Error in row mutation
org.apache.cassandra.db.UnserializableColumnFamilyException: Couldn't find cfId=1018
        at org.apache.cassandra.db.ColumnFamilySerializer.deserialize(ColumnFamilySerializer.java:112)
        at org.apache.cassandra.db.RowMutationSerializer.defreezeTheMaps(RowMutation.java:368)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:378)
        at org.apache.cassandra.db.RowMutationSerializer.deserialize(RowMutation.java:336)
        at org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:52)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619);;;","28/Oct/10 14:17;bterm;steps taken to reproduced it on latest trunk (r1028108):
Stop all running instances of cassandra. remove all files from data and log directories. build source from trunk or grab rc1. change cassandra.yaml seed list, thrift ip addresses and partitioner (using ordered). Start all nodes and watch logs to ensure they cluster. use cassandra-cli on node1 to configure keyspaces with a replication factor of 3, all column families are using comparator = bytestype. start sending data to the cluster (using N python clients). Errors start occurring for RowMutationVerbHandler.java Error in row mutation ...;;;","28/Oct/10 21:13;jbellis;+1 for duplicate fix;;;","29/Oct/10 15:41;hudson;Integrated in Cassandra #580 (See [https://hudson.apache.org/hudson/job/Cassandra/580/])
    BytesToken.convertByteBuffer duplicates the BB so other threads can trust its position. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1645
FBU.decodeToUtf8 duplicates the BB so other threads can trust its position. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1645
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Commitlog.recover can delete the commitlog segment instance() just created,CASSANDRA-1644,12478025,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,jbellis,jbellis,jbellis,21/Oct/10 19:51,16/Apr/19 09:33,14/Jul/23 05:51,21/Oct/10 23:14,0.7 beta 3,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Oct/10 19:53;jbellis;1644.txt;https://issues.apache.org/jira/secure/attachment/12457778/1644.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20235,,,Fri Oct 22 12:52:28 UTC 2010,,,,,,,,,,"0|i0g6hz:",92483,,gdusbabek,,gdusbabek,Critical,,,,,,,,,,,,,,,,,"21/Oct/10 20:09;jbellis;As the comment says:

+                // we used to try to avoid instantiating commitlog (thus creating an empty segment ready for writes)
+                // until after recover was finished.  this turns out to be fragile; it is less error-prone to go
+                // ahead and allow writes before recover(), and just skip active segments when we do.
;;;","21/Oct/10 20:29;gdusbabek;+1;;;","21/Oct/10 23:14;jbellis;committed;;;","22/Oct/10 12:52;hudson;Integrated in Cassandra #573 (See [https://hudson.apache.org/hudson/job/Cassandra/573/])
    fix commitlog recovery deleting the newly-created segment as well as the old ones
patch by jbellis; reviewed by gdusbabek for CASSANDRA-1644
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Endpoint cache for a token should be part of AbstractReplicationStrategy and not Snitch,CASSANDRA-1643,12478014,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,khichrishi,khichrishi,21/Oct/10 18:31,16/Apr/19 09:33,14/Jul/23 05:51,21/Oct/10 20:55,0.7 beta 3,,,,0,,,,,,"There is a single DynamicEndpointSnitch object for all ReplicationStrategy objects. This DynamicEndpointSnitch object contains a single IEndpointSnitch subsnitch object. This subsnitch object contains the Endpoint cache for a token. Thus there is a single endpoint cache for all ReplicationStrategy objects. This implies that replica nodes for a Token as returned by the Cache would be same irrespective of the ReplicationStrategy object. This is a bug, the Endpoint cache should be a part of ""AbstractReplicationStrategy"" object rather than the IEndpointSnitch object.
",,,,,,,,,,,86400,86400,,0%,86400,86400,,,,,,,,,,,,,,"21/Oct/10 20:37;jbellis;1643-v2.txt;https://issues.apache.org/jira/secure/attachment/12457780/1643-v2.txt","21/Oct/10 19:28;jbellis;1643.txt;https://issues.apache.org/jira/secure/attachment/12457775/1643.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20234,,,Fri Oct 22 12:52:29 UTC 2010,,,,,,,,,,"0|i0g6hr:",92482,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"21/Oct/10 20:19;brandon.williams;SimpleStrategyTest is broken:

    [junit] Testsuite: org.apache.cassandra.locator.SimpleStrategyTest
    [junit] Tests run: 4, Failures: 1, Errors: 0, Time elapsed: 0.591 sec
    [junit]
    [junit] Testcase: tryBogusTable(org.apache.cassandra.locator.SimpleStrategyTest):   FAILED
    [junit] No replica strategy configured for SomeBogusTableThatDoesntExist
    [junit] junit.framework.AssertionFailedError: No replica strategy configured for SomeBogusTableThatDoesntExist
    [junit]     at org.apache.cassandra.service.StorageService.getReplicationStrategy(StorageService.java:254)
    [junit]     at org.apache.cassandra.locator.SimpleStrategyTest.tryBogusTable(SimpleStrategyTest.java:48)
    [junit]
    [junit]
    [junit] Test org.apache.cassandra.locator.SimpleStrategyTest FAILED
;;;","21/Oct/10 20:37;jbellis;fixed test;;;","21/Oct/10 20:44;brandon.williams;+1;;;","21/Oct/10 20:55;jbellis;committed;;;","22/Oct/10 12:52;hudson;Integrated in Cassandra #573 (See [https://hudson.apache.org/hudson/job/Cassandra/573/])
    move endpoint cache from snitch to strategy
patch by jbellis; reviewed by brandonwilliams for CASSANDRA-1643
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"JOIN verb was removed, breaking serialization by ordinal.",CASSANDRA-1642,12477992,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,gdusbabek,gdusbabek,21/Oct/10 14:09,16/Apr/19 09:33,14/Jul/23 05:51,21/Oct/10 14:24,0.7 beta 3,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Oct/10 14:12;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-put-SS.JOIN-verb-back-in-to-keep-ordinals-in-alignment.txt;https://issues.apache.org/jira/secure/attachment/12457755/ASF.LICENSE.NOT.GRANTED--v1-0001-put-SS.JOIN-verb-back-in-to-keep-ordinals-in-alignment.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20233,,,Thu Oct 21 14:55:51 UTC 2010,,,,,,,,,,"0|i0g6hj:",92481,,,,,Low,,,,,,,,,,,,,,,,,"21/Oct/10 14:17;jbellis;+1;;;","21/Oct/10 14:55;hudson;Integrated in Cassandra #572 (See [https://hudson.apache.org/hudson/job/Cassandra/572/])
    put JOIN verb back. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1642
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
auto-guessed memtable sizes are too high,CASSANDRA-1641,12477951,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,21/Oct/10 05:22,16/Apr/19 09:33,14/Jul/23 05:51,21/Oct/10 17:10,0.7 beta 3,,,,0,,,,,,"I've seen two cases now of the memtable sizes being too large, causing OOMing.  Too-small memtables hurt performance, but too-large hurts worse when you start GC storming.",,dehora,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Oct/10 05:26;jbellis;1641.txt;https://issues.apache.org/jira/secure/attachment/12457722/1641.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20232,,,Fri Oct 22 12:52:28 UTC 2010,,,,,,,,,,"0|i0g6hb:",92480,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"21/Oct/10 05:26;jbellis;I'd like to introduce a dependency on number of user CFs, but that's not available until after we've picked a value.  So this cuts the size by half, which feels scientific because on the old default 1GB heap size this gives us memtable throughput of 64MB, which is also the old default.;;;","21/Oct/10 17:04;brandon.williams;+1;;;","21/Oct/10 17:10;jbellis;committed;;;","22/Oct/10 12:52;hudson;Integrated in Cassandra #573 (See [https://hudson.apache.org/hudson/job/Cassandra/573/])
    reduce automaticallychosen memtablesizes by 50%
patch by jbellis; reviewed by brandonwilliams for CASSANDRA-1641
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in StorageService when cluster is first being created,CASSANDRA-1639,12477942,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,,davew,davew,21/Oct/10 00:40,16/Apr/19 09:33,14/Jul/23 05:51,22/Oct/10 14:52,0.7 beta 3,,Legacy/Tools,,0,,,,,,"Saw this exception on the 0.7.0-beta2 version of cassandra right after bringing up a cluster and trying to get the number of live nodes.

java.lang.NullPointerException
        at org.apache.cassandra.service.StorageService.stringify(StorageService.java:1151)
        at org.apache.cassandra.service.StorageService.getLiveNodes(StorageService.java:1138)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27)
        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)
        at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:65)
        at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:216)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:666)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:638)
        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1404)
        at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:72)
        at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1265)
        at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1360)
        at javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:600)
        at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:305)
        at sun.rmi.transport.Transport$1.run(Transport.java:159)
        at java.security.AccessController.doPrivileged(Native Method)
        at sun.rmi.transport.Transport.serviceCall(Transport.java:155)
        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)


I fixed this by adding some null checks to the stringify methods 

    private Set<String> stringify(Collection<InetAddress> endpoints)
    {
        Set<String> stringEndpoints = new HashSet<String>();
        for (InetAddress ep : endpoints)
        {
        	if(ep != null) {
        		stringEndpoints.add(ep.getHostAddress());
        	}
        }
        return stringEndpoints;
    }

    private List<String> stringify(List<InetAddress> endpoints)
    {
        List<String> stringEndpoints = new ArrayList<String>();
        for (InetAddress ep : endpoints)
        {
        	if(ep != null) {
        		stringEndpoints.add(ep.getHostAddress());
        	}
        }
        return stringEndpoints;
    }

After adding those checks, then I got more reasonable/realistic errors from a different part of the code since the service wasn't up yet as the cluster was still initializing:

Caused by: javax.management.InstanceNotFoundException: org.apache.cassandra.service:type=StorageService
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1094)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:662)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:638)
        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1404)
        at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:72)
        at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1265)
        at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1360)
        at javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:600)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:305)
        at sun.rmi.transport.Transport$1.run(Transport.java:159)
        at java.security.AccessController.doPrivileged(Native Method)
        at sun.rmi.transport.Transport.serviceCall(Transport.java:155)
        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
        at sun.rmi.transport.StreamRemoteCall.exceptionReceivedFromServer(StreamRemoteCall.java:255)
        at sun.rmi.transport.StreamRemoteCall.executeCall(StreamRemoteCall.java:233)
        at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:142)
        at com.sun.jmx.remote.internal.PRef.invoke(Unknown Source)
        at javax.management.remote.rmi.RMIConnectionImpl_Stub.getAttribute(Unknown Source)
        at javax.management.remote.rmi.RMIConnector$RemoteMBeanServerConnection.getAttribute(RMIConnector.java:878)
        at javax.management.MBeanServerInvocationHandler.invoke(MBeanServerInvocationHandler.java:263)
",Windows XP,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20230,,,Fri Oct 22 14:52:30 UTC 2010,,,,,,,,,,"0|i0g6gv:",92478,,,,,Low,,,,,,,,,,,,,,,,,"22/Oct/10 14:52;jbellis;looks like this is fixed in the latest nightly -- should not be possible for getLiveNodes to pass a null list to stringify.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
initMetadata does not load partitioner from disk,CASSANDRA-1638,12477915,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,lenn0x,lenn0x,lenn0x,20/Oct/10 20:23,16/Apr/19 09:33,14/Jul/23 05:51,29/Oct/10 13:46,0.6.7,,,,0,,,,,,"The function initMetadata() in org/apache/cassandra/db/SystemTable.java does not add the PARTITIONER constant to columns. So when the NamesQueryFilter runs, it will never pull the value from disk. This makes this portion of the code always null:

        if (partitionerColumn == null)
        {
            Column c = new Column(PARTITIONER, partitioner.getBytes(""UTF-8""), TimestampClock.ZERO);
            cf.addColumn(c);
            logger.info(""Saved partitioner not found. Using "" + partitioner);
        }",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Oct/10 20:25;lenn0x;0001-Fixed-initMetadata-to-load-on-disk-PARTITIONER-confi.patch;https://issues.apache.org/jira/secure/attachment/12457706/0001-Fixed-initMetadata-to-load-on-disk-PARTITIONER-confi.patch",,,,,,,,,,,,,,1.0,lenn0x,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20229,,,Fri Oct 29 13:46:07 UTC 2010,,,,,,,,,,"0|i0g6gn:",92477,,,,,Low,,,,,,,,,,,,,,,,,"22/Oct/10 20:58;gdusbabek;+1;;;","29/Oct/10 13:46;gdusbabek;Committed. 

0.7 and trunk didn't need changes.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cli not picking up type annotation on set,CASSANDRA-1635,12477874,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,xedin,jbellis,jbellis,20/Oct/10 14:40,16/Apr/19 09:33,14/Jul/23 05:51,20/Oct/10 21:11,0.7 beta 3,,Legacy/Tools,,0,,,,,,"{code}
[default@Keyspace1] create column family Users
create column family Users
737c7a71-dc56-11df-8240-e700f669bcfc
[default@Keyspace1] set Users[jsmith][first] = 'John'
set Users[jsmith][first] = 'John'
Value inserted.
[default@Keyspace1] set Users[jsmith][last] = 'Smith'
set Users[jsmith][last] = 'Smith'
Value inserted.
[default@Keyspace1] set Users[jsmith][age] = long(42)
set Users[jsmith][age] = long(42)
Value inserted.
[default@Keyspace1] get Users[jsmith]
get Users[jsmith]
=> (column=6c617374, value=Smith, timestamp=1287584999695000)
=> (column=6669727374, value=John, timestamp=1287584990126000)
=> (column=616765, value=^@^@^@^@^@^@^@*, timestamp=1287585014593000)
Returned 3 results.
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Oct/10 20:44;xedin;CASSANDRA-1635-v2.patch;https://issues.apache.org/jira/secure/attachment/12457707/CASSANDRA-1635-v2.patch","20/Oct/10 17:14;xedin;CASSANDRA-1635.patch;https://issues.apache.org/jira/secure/attachment/12457681/CASSANDRA-1635.patch",,,,,,,,,,,,,2.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20228,,,Thu Oct 21 14:55:52 UTC 2010,,,,,,,,,,"0|i0g6fz:",92474,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"20/Oct/10 17:14;xedin;Please check after 1615 committed.;;;","20/Oct/10 19:24;jbellis;post-1615 I get

{code}
=> (column=626972746864617465, value=?, timestamp=1287602501548000)
{code}

Also, I noticed that it's actually sending

{code}
        thriftClient_.system_update_column_family(columnFamily);
{code}

when I use a conversion function.  this is not right, we should only issue system_update_column_family for ""update column family"" statements, anything else we infer should stay local.;;;","20/Oct/10 20:00;xedin;my test (after applied CASSANDRA-1635.patch to the latest trunk):
{code}
[default@KS1] create column family Users with comparator=UTF8Type and column_metadata=[{column_name:first, validation_class:UTF8Type}, {column_name:last, validation_class:UTF8Type}]
412367d6-dc83-11df-bf47-e700f669bcfc
[default@KS1] set Users[jsmith][first] = 'John'
Value inserted.
[default@KS1] set Users[jsmith][last] = 'Smith'
Value inserted.
[default@KS1] set Users[jsmith][age] = long(42)
Value inserted.
[default@KS1] get Users[jsmith]
=> (column=last, value=Smith, timestamp=1287604215498000)
=> (column=first, value=John, timestamp=1287604214111000)
=> (column=age, value=42, timestamp=1287604216661000)
Returned 3 results.
{code}

I use UTF8Type here manually because default comparator for column names is BytesType. Results you get are very weird... 

if you mean convertValueByFunction method then it has boolean withUpdate argument which used to determine if system update is need, I have also added polymorphic convertValueByFunction 3 arguments: columnFamily, columnName and tree argument, which calls convertValueByFunction with withUpdate set to false.
;;;","20/Oct/10 20:16;jbellis;bq. my test (after applied CASSANDRA-1635.patch to the latest trunk): 

Ah, I thought when you said ""Please check after 1615 committed"" that 1615 was supposed to fix it.  I do see value working correctly after 1635 patch.  committed.

bq. convertValueByFunction method then it has boolean withUpdate argument which used to determine if system update is need, I have also added polymorphic convertValueByFunction 3 arguments: columnFamily, columnName and tree argument, which calls convertValueByFunction with withUpdate set to false.

something is definitely buggy, when I watch the server log I can see it applying the schema migration after the long() set.

fundamentally side effects to thriftclient have no business in the convertValue method.  update local schema? yes. update server schema? no.;;;","20/Oct/10 20:44;xedin;Sorry for my misleading comment :/ now updates for column defs are performed only locally except ""update column family"" statement.;;;","20/Oct/10 21:11;jbellis;perfect, committed.;;;","21/Oct/10 14:55;hudson;Integrated in Cassandra #572 (See [https://hudson.apache.org/hudson/job/Cassandra/572/])
    avoid updating server schema except for explicit 'update column family'.  patch by Pavel Yaskevich; reviewed by jbellis for CASSANDRA-1635
fix cli value conversion, update readme
patch by Pavel Yaskevich and jbellis for CASSANDRA-1635
cli support for index queries
patch by Pavel Yaskevich; reviewed by jbellis for CASSANDRA-1635
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dropping column families and keyspaces races with compaction and flushing,CASSANDRA-1631,12477746,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,19/Oct/10 14:10,16/Apr/19 09:33,14/Jul/23 05:51,05/Nov/10 21:12,0.7 beta 3,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1585,,,,"19/Oct/10 21:14;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-fix-drop-race-with-compaction.txt;https://issues.apache.org/jira/secure/attachment/12457596/ASF.LICENSE.NOT.GRANTED--v1-0001-fix-drop-race-with-compaction.txt","19/Oct/10 21:14;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0002-fix-drop-race-with-flush.txt;https://issues.apache.org/jira/secure/attachment/12457597/ASF.LICENSE.NOT.GRANTED--v1-0002-fix-drop-race-with-flush.txt",,,,,,,,,,,,,2.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20226,,,Fri Nov 05 21:12:51 UTC 2010,,,,,,,,,,"0|i0g6f3:",92470,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"19/Oct/10 21:29;jbellis;i don't think 02 actually prevents an update that is making its way through the system pre-drop from causing a flush after the lock is released.  probably setting the memtable to frozen while we hold the lock would fix this.;;;","19/Oct/10 21:37;gdusbabek;The null check in CFS.maybeSwitchMemtable was intended to handle that, i.e., if the flush goes through after the drop, it ends up doing nothing because the CF def can't be found.;;;","20/Oct/10 01:45;jbellis;ah, right.  +1;;;","20/Oct/10 15:14;hudson;Integrated in Cassandra #571 (See [https://hudson.apache.org/hudson/job/Cassandra/571/])
    fix drop race with flush. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1631
fix drop race with compaction. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1631
;;;","04/Nov/10 15:56;jbellis;This is still a bug with schema updates to an existing CF, since reloadCf is doing a unload/init cycle.  So flushing + compaction is an issue there as well.  Here is a stacktrace from during an index creation where it stubbed its toe on an incomplete sstable from an in-progress compaction (path names anonymized):

{code}
 INFO [CompactionExecutor:1] 2010-11-02 16:31:00,553 CompactionManager.java (line 224) Compacting [org.apache.cassandra.io.sstable.SSTableReader(path='Standard1-e-6-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='Standard1-e-7-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='Standard1-e-8-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='Standard1-e-9-Data.db')]
...
ERROR [MigrationStage:1] 2010-11-02 16:31:10,939 ColumnFamilyStore.java (line 244) Corrupt sstable Standard1-tmp-e-10-<>=[Data.db, Index.db]; skipped
java.io.EOFException
        at org.apache.cassandra.utils.FBUtilities.skipShortByteArray(FBUtilities.java:308)
        at org.apache.cassandra.io.sstable.SSTable.estimateRowsFromIndex(SSTable.java:231)
        at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:286)
        at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:202)
        at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:235)
        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:443)
        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:431)
        at org.apache.cassandra.db.Table.initCf(Table.java:335)
        at org.apache.cassandra.db.Table.reloadCf(Table.java:343)
        at org.apache.cassandra.db.migration.UpdateColumnFamily.applyModels(UpdateColumnFamily.java:89)
        at org.apache.cassandra.db.migration.Migration.apply(Migration.java:158)
        at org.apache.cassandra.thrift.CassandraServer$2.call(CassandraServer.java:672)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
...
 INFO [CompactionExecutor:1] 2010-11-02 16:31:31,970 CompactionManager.java (line 303) Compacted to Standard1-tmp-e-10-Data.db.  213,657,983 to 213,657,983 (~100% of original) bytes for 626,563 keys.  Time: 31,416ms.
{code};;;","04/Nov/10 19:57;gdusbabek;This isn't going to be as simple as it was last time (shifting work on to the CompactionManager and blocking).  Part of the unload/init code, you guessed it, shifts work of the CompactionManager and blocks (index creation to be precise).  

I'm looking into ways of doing this that don't involve deadlock or refactoring large pieces of code.  Part of the problem is that we've started treating the CompactionManager as a way to synchronize access to sstables.  The problem with that is that it is very course and the jobs submitted to it do a lot more things that pure FS work.;;;","05/Nov/10 15:03;gdusbabek;Realized streaming can be affected by drop/renames as well.;;;","05/Nov/10 21:12;jbellis;created CASSANDRA-1715 for these new bugs;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
system_rename_* methods need to be removed until we can solve compaction and flush races.,CASSANDRA-1630,12477742,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,19/Oct/10 13:36,16/Apr/19 09:33,14/Jul/23 05:51,19/Oct/10 14:26,0.7 beta 3,,Legacy/CQL,,0,,,,,,,,arya,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1585,,,,"19/Oct/10 14:09;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-remvove-system_rename-methods-from-API.-thift-avro-cha.txt;https://issues.apache.org/jira/secure/attachment/12457550/ASF.LICENSE.NOT.GRANTED--v1-0001-remvove-system_rename-methods-from-API.-thift-avro-cha.txt","19/Oct/10 14:09;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0002-remove-system_rename-methods-from-API.txt;https://issues.apache.org/jira/secure/attachment/12457551/ASF.LICENSE.NOT.GRANTED--v1-0002-remove-system_rename-methods-from-API.txt","19/Oct/10 14:09;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0003-disable-system_renam-ing-in-the-cli.txt;https://issues.apache.org/jira/secure/attachment/12457552/ASF.LICENSE.NOT.GRANTED--v1-0003-disable-system_renam-ing-in-the-cli.txt","19/Oct/10 14:09;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0004-Deprecate-RenameColumnFamily-and-RenameKeyspace.txt;https://issues.apache.org/jira/secure/attachment/12457553/ASF.LICENSE.NOT.GRANTED--v1-0004-Deprecate-RenameColumnFamily-and-RenameKeyspace.txt",,,,,,,,,,,4.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20225,,,Wed Oct 20 15:14:26 UTC 2010,,,,,,,,,,"0|i0g6ev:",92469,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"19/Oct/10 14:21;jbellis;+1;;;","20/Oct/10 15:14;hudson;Integrated in Cassandra #571 (See [https://hudson.apache.org/hudson/job/Cassandra/571/])
    remvove system_rename* methods from API. thift/avro changes. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1630
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RedHat init script status is a no-op,CASSANDRA-1628,12477654,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,addumb,addumb,addumb,18/Oct/10 17:37,16/Apr/19 09:33,14/Jul/23 05:51,19/Oct/10 00:10,0.6.7,0.7 beta 3,,,0,,,,,,"The current bare-bones init script is a little too bare-bones. The ""status"" argument make a successful no-op, which can be pretty misleading.",RedHat-like Linux,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Oct/10 18:03;addumb;redhat-status-usage.patch;https://issues.apache.org/jira/secure/attachment/12457465/redhat-status-usage.patch","18/Oct/10 17:38;addumb;redhat-status.patch;https://issues.apache.org/jira/secure/attachment/12457461/redhat-status.patch",,,,,,,,,,,,,2.0,addumb,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20223,,,Tue Oct 19 14:15:02 UTC 2010,,,,,,,,,,"0|i0g6ef:",92467,,brandon.williams,,brandon.williams,Low,,,,,,,,,,,,,,,,,"18/Oct/10 17:38;addumb;Do a pretty minimal status check.;;;","18/Oct/10 18:03;addumb;Also include the status option in the Usage section.;;;","18/Oct/10 18:14;zznate;Works as advertised: 
# /etc/init.d/cassandra status
cassandra (pid  1101) is running...

After shutdown:
# /etc/init.d/cassandra status
cassandra is stopped
;;;","19/Oct/10 00:10;brandon.williams;Committed.;;;","19/Oct/10 14:15;hudson;Integrated in Cassandra #570 (See [https://hudson.apache.org/hudson/job/Cassandra/570/])
    Redhat init script prints the status when asked.  Patch by Adam Gray, reviewed by brandonwilliams for CASSANDRA-1628.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BUG: secondaryIndexes AND multiple index expressions can cause timesouts,CASSANDRA-1623,12477501,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jasontanner,jasontanner,15/Oct/10 19:59,16/Apr/19 09:33,14/Jul/23 05:51,18/Oct/10 20:42,0.7 beta 3,,,,0,,,,,,"1. Given this Column Family definition

    Column Family Name: Requests
      Column Family Type: Standard
      Column Sorted By: org.apache.cassandra.db.marshal.UTF8Type
      Column Metadata:
        Column Name: requested
          Validation Class: org.apache.cassandra.db.marshal.UTF8Type
          Index Type: KEYS
        Column Name: requestor
          Validation Class: org.apache.cassandra.db.marshal.UTF8Type
          Index Type: KEYS

If I have an entry that has the following column/value pairs:

""request-uuid1"" : [  { ""requested"",""person-uuid1"" }, { ""requestor"",""person-uuid2""}, { ""is_confirmed"",""true"" } ]

If I do an index lookup (pseudo coded) :

get_index_slices( Connection,
                                 ColumnParent.column_family=""Requests"",
                                 [ { ""requested"",""eq"", ""person-uuid1"" }, { ""is_confirmed"",""eq"", ""false"" } ],      % Index Expressions
                                 """",100,   % StartKey, KeyCount
                                 """","""",false,100   % StartCol, EndCol, Reversed, ColCount )

for ""requested"" = ""person-uuid1"" and ""is_confirmed"" = false 

then I get the following entries in my log and the request times out along with all other requests on all clients.

DEBUG [pool-1-thread-10] 2010-10-15 19:00:27,878 CassandraServer.java (line 531) scan
DEBUG [pool-1-thread-10] 2010-10-15 19:00:27,897 StorageProxy.java (line 563) restricted single token match for query [0,0]
DEBUG [pool-1-thread-10] 2010-10-15 19:00:27,897 StorageProxy.java (line 649) scan ranges are [0,0]
DEBUG [pool-1-thread-10] 2010-10-15 19:00:27,925 StorageProxy.java (line 669) reading org.apache.cassandra.db.IndexScanCommand@42a6eb from 52@localhost/127.0.0.1
DEBUG [ReadStage:2] 2010-10-15 19:00:27,931 SliceQueryFilter.java (line 121) collecting 0 of 1: null:false:0@1287103291
DEBUG [ReadStage:2] 2010-10-15 19:00:27,933 SliceQueryFilter.java (line 121) collecting 0 of 2147483647: is_confirmed:false:4@1287103291
DEBUG [ReadStage:2] 2010-10-15 19:00:27,934 SliceQueryFilter.java (line 121) collecting 1 of 2147483647: request_type:false:6@1287103291
DEBUG [ReadStage:2] 2010-10-15 19:00:27,935 SliceQueryFilter.java (line 121) collecting 2 of 2147483647: requested:false:58@1287103291
DEBUG [ReadStage:2] 2010-10-15 19:00:27,935 SliceQueryFilter.java (line 121) collecting 3 of 2147483647: requested_network:false:57@1287103291
DEBUG [ReadStage:2] 2010-10-15 19:00:27,936 SliceQueryFilter.java (line 121) collecting 4 of 2147483647: requestor:false:58@1287103291
DEBUG [ReadStage:2] 2010-10-15 19:00:27,937 SliceQueryFilter.java (line 121) collecting 5 of 2147483647: requestor_network:false:57@1287103291
DEBUG [ReadStage:2] 2010-10-15 19:00:27,942 SliceQueryFilter.java (line 121) collecting 0 of 1: null:false:0@1287103291
DEBUG [ReadStage:2] 2010-10-15 19:00:27,943 SliceQueryFilter.java (line 121) collecting 0 of 1: null:false:0@1287103291
DEBUG [ReadStage:2] 2010-10-15 19:00:27,945 SliceQueryFilter.java (line 121) collecting 0 of 1: null:false:0@1287103291
DEBUG [ReadStage:2] 2010-10-15 19:00:27,946 SliceQueryFilter.java (line 121) collecting 0 of 1: null:false:0@1287103291
 this last line repeats forever until I stop the server.

If instead I do the lookup where both terms match or just the last term matches then nothing goes wrong, I get a valid (empty or otherwise) result set.

It only seems to happen if the 2nd expression does not match.

I am using the very latest code from trunk.


Jason
                                       ",centos 5.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Oct/10 15:05;jbellis;1623.txt;https://issues.apache.org/jira/secure/attachment/12457452/1623.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20221,,,Tue Oct 19 14:15:04 UTC 2010,,,,,,,,,,"0|i0g6db:",92462,,jasontanner,,jasontanner,Normal,,,,,,,,,,,,,,,,,"18/Oct/10 15:05;jbellis;Patch attached with fix and unit test demonstrating the problem.;;;","18/Oct/10 20:26;jasontanner;Patch tested on my install and it resolved my issue.;;;","18/Oct/10 20:42;jbellis;committed;;;","19/Oct/10 14:15;hudson;Integrated in Cassandra #570 (See [https://hudson.apache.org/hudson/job/Cassandra/570/])
    fix potential infinite loop in 2ary index queries
patch by jbellis; tested by Jason Tanner for CASSANDRA-1623
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
statistics not created after streaming data,CASSANDRA-1620,12477420,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,15/Oct/10 04:25,16/Apr/19 09:33,14/Jul/23 05:51,18/Oct/10 17:43,0.7 beta 3,,,,0,,,,,,"after loadbalance operation, cfstats NPEs:

Exception in thread ""main"" java.lang.NullPointerException
        at org.apache.cassandra.db.ColumnFamilyStore.getMinRowSize(ColumnFamilyStore.java:332)
        at sun.reflect.GeneratedMethodAccessor36.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27)
        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)
        at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:65)
        at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:216)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:666)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:638)
        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1404)
        at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:72)
        at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1265)
        at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1360)
        at javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:600)
        at sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:305)
        at sun.rmi.transport.Transport$1.run(Transport.java:159)
        at java.security.AccessController.doPrivileged(Native Method)
        at sun.rmi.transport.Transport.serviceCall(Transport.java:155)
        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Oct/10 16:34;jbellis;1620-2.txt;https://issues.apache.org/jira/secure/attachment/12457344/1620-2.txt","16/Oct/10 02:09;jbellis;1620.txt;https://issues.apache.org/jira/secure/attachment/12457318/1620.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20220,,,Tue Oct 19 14:15:04 UTC 2010,,,,,,,,,,"0|i0g6cn:",92459,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"15/Oct/10 23:24;jbellis;root cause is SSTableWriter.Builder not creating the stats file post-stream.;;;","16/Oct/10 02:09;jbellis;patch to avoid NPEs when stats file does not exist (upgrading from 0.6).

should still add stats to post-stream build operation since we're iterating through the data file to build the index anyway.;;;","16/Oct/10 16:34;jbellis;-2 (applies on top of original) adds stats build post-stream.  please test :);;;","18/Oct/10 17:26;brandon.williams;+1;;;","18/Oct/10 17:43;jbellis;committed;;;","19/Oct/10 14:15;hudson;Integrated in Cassandra #570 (See [https://hudson.apache.org/hudson/job/Cassandra/570/])
    compute next row position before changing the file pointer.  patch by jbellis for CASSANDRA-1620
build stats post-stream
patch by jbellis; reviewed by brandonwilliams for CASSANDRA-1620
avoid null SSTable stat histograms
patch by jbellis; reviewed by brandonwilliams for CASSANDRA-1620
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BufferUnderflowException occurs in RowMutationVerbHandler,CASSANDRA-1617,12477257,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,moores,moores,13/Oct/10 17:01,16/Apr/19 09:33,14/Jul/23 05:51,20/Oct/10 19:18,0.7 beta 3,,,,0,,,,,,"There might be a bug in hinted handoff?

I have a cluster of 8, replication factor of 3, doing reads/writes with QUORUM.
I have a single thread doing reads/writes of about 2kb across all nodes, running about 200hps.
When I shut down one node, within a few seconds I start seeing some very big recent write latencies, 4-5 seconds.
I looked at the system.log on the node with the adjacent token to the node that I shut down, and see a bad looking BufferUnderflowException:

INFO [WRITE-kv2-app02.dev.real.com/172.27.109.32] 2010-10-12 12:13:36,712 
OutboundTcpConnection.java (line 115) error writing to 
kv2-app02.dev.real.com/172.27.109.32
 INFO [WRITE-kv2-app02.dev.real.com/172.27.109.32] 2010-10-12 12:13:50,336 
OutboundTcpConnection.java (line 115) error writing to 
kv2-app02.dev.real.com/172.27.109.32
 INFO [Timer-0] 2010-10-12 12:14:22,792 Gossiper.java (line 196) InetAddress 
/172.27.109.32 is now dead.
ERROR [MUTATION_STAGE:1315] 2010-10-12 12:14:24,917 
DebuggableThreadPoolExecutor.java (line 103) Error in ThreadPoolExecutor
java.nio.BufferUnderflowException
        at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:127)
        at java.nio.ByteBuffer.get(ByteBuffer.java:675)
        at 
org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:62)
        at 
org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at 
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at 
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
ERROR [MUTATION_STAGE:1315] 2010-10-12 12:14:24,918 
AbstractCassandraDaemon.java (line 88) Fatal exception in thread 
Thread[MUTATION_STAGE:1315,5,main]
java.nio.BufferUnderflowException
        at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:127)
        at java.nio.ByteBuffer.get(ByteBuffer.java:675)
        at 
org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:62)
        at 
org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at 
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at 
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
ERROR [MUTATION_STAGE:1605] 2010-10-12 12:14:28,919 
DebuggableThreadPoolExecutor.java (line 103) Error in ThreadPoolExecutor
java.nio.BufferUnderflowException
        at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:127)
        at java.nio.ByteBuffer.get(ByteBuffer.java:675)
        at 
org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:62)
        at 
org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at 
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at 
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
....
....

I restarted the previously stopped node, and the system recovers, but with a 
few more underlflow exceptions:

 INFO [GOSSIP_STAGE:1] 2010-10-12 12:15:44,537 Gossiper.java (line 594) Node 
/172.27.109.32 has restarted, now UP again
 INFO [HINTED-HANDOFF-POOL:1] 2010-10-12 12:15:44,537 HintedHandOffManager.java 
(line 196) Started hinted handoff for endpoint /172.27.109.32
 INFO [GOSSIP_STAGE:1] 2010-10-12 12:15:44,537 StorageService.java (line 643) 
Node /172.27.109.32 state jump to normal
 INFO [HINTED-HANDOFF-POOL:1] 2010-10-12 12:15:44,538 HintedHandOffManager.java 
(line 252) Finished hinted handoff of 0 rows to endpoint /172.27.109.32
 INFO [GOSSIP_STAGE:1] 2010-10-12 12:15:44,538 StorageService.java (line 650) 
Will not change my token ownership to /172.27.109.32
ERROR [MUTATION_STAGE:1635] 2010-10-12 12:15:45,083 
DebuggableThreadPoolExecutor.java (line 103) Error in ThreadPoolExecutor
java.nio.BufferUnderflowException
        at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:127)
        at java.nio.ByteBuffer.get(ByteBuffer.java:675)
        at 
org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:62)
        at 
org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at 
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at 
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)","Centos 5.4, jdk 1.6.0_20-b02, 16 core xeon, 8 node cluster",gdusbabek,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Oct/10 18:55;brandon.williams;1617.txt;https://issues.apache.org/jira/secure/attachment/12457691/1617.txt",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20219,,,Thu Oct 21 14:55:50 UTC 2010,,,,,,,,,,"0|i0g6bz:",92456,,,,,Normal,,,,,,,,,,,,,,,,,"14/Oct/10 20:42;jbellis;did you upgrade this cluster from 0.6?;;;","14/Oct/10 21:20;moores;Yea we stopped using 0.6 a while back.  All data was created from scratch with 0.7-beta2.;;;","15/Oct/10 20:25;franklovecchio;We have the nightly build as of yesterday of 0.7 beta 2, and now get the error below when trying to insert a record:  (CLI sytax is something like set CF ['something']['something1']['something2'] = 'value' )

ERROR [MutationStage:2278] 2010-10-15 20:09:39,523 DebuggableThreadPoolExecutor.java (line 103) Error in ThreadPoolExecutor
java.nio.BufferUnderflowException
    at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:145)
    at java.nio.ByteBuffer.get(ByteBuffer.java:692)
    at org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:62)
    at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
    at java.lang.Thread.run(Thread.java:636)
ERROR [MutationStage:2278] 2010-10-15 20:09:39,524 AbstractCassandraDaemon.java (line 88) Fatal exception in thread Thread[MutationStage:2278,5,main]
java.nio.BufferUnderflowException
    at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:145)
    at java.nio.ByteBuffer.get(ByteBuffer.java:692)
    at org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:62)
    at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
    at java.lang.Thread.run(Thread.java:636);;;","18/Oct/10 23:35;brandon.williams;In CASSANDRA-1439, we changed the hint destinations from fixed-length encoding to variable-length encoding (by converting UTF-8, to make OPP happy.)  We neglected to frame the message, however.  Patch adds framing and fixes a debug message that is broken.;;;","20/Oct/10 03:35;jbellis;use FBUtilities.read/writeShortByteArray?;;;","20/Oct/10 16:49;brandon.williams;Updated.;;;","20/Oct/10 17:48;jbellis;writeshortbytearray applied to oldhint will create a new length ""frame,"" i think you just want to use out.writeFully(old) or something like that;;;","20/Oct/10 18:55;brandon.williams;Good catch.  Updated to fix that, and name the oldHint variable more aptly so it's clearer why this is done.;;;","20/Oct/10 19:13;jbellis;+1;;;","20/Oct/10 19:18;brandon.williams;Committed.;;;","21/Oct/10 14:55;hudson;Integrated in Cassandra #572 (See [https://hudson.apache.org/hudson/job/Cassandra/572/])
    Add framing to hint destinations.  Patch by brandonwilliams, reviewed by jbellis for CASSANDRA-1617
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
index created from cli does not show up in keyspace metadata,CASSANDRA-1613,12477206,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,xedin,jbellis,jbellis,13/Oct/10 03:44,16/Apr/19 09:33,14/Jul/23 05:51,14/Oct/10 18:05,0.7 beta 3,,Legacy/Tools,,0,,,,,,"create column family Category with comparator=UTF8Type and column_metadata=[{column_name:level, validation_class:IntegerType, index_type:0, index_name:CategoryLevelIdx}]

succeeds, but after this
'show keyspaces' does not reveal the presence of the index. Only the column family is shown.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Oct/10 10:41;xedin;CASSANDRA-1613.patch;https://issues.apache.org/jira/secure/attachment/12457146/CASSANDRA-1613.patch",,,,,,,,,,,,,,1.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20218,,,Fri Oct 15 13:23:18 UTC 2010,,,,,,,,,,"0|i0g6b3:",92452,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"14/Oct/10 10:41;xedin;new format example:

{code}
    Column Family Name: Category {
      Column Family Type: Standard
      Column Sorted By: org.apache.cassandra.db.marshal.UTF8Type
      Column Metadata {
        Column Name: level {
          Validation Class: org.apache.cassandra.db.marshal.IntegerType
          Index Name: CategoryLevelIdx
          Index Type: KEYS
        }
      }
   }
{code};;;","14/Oct/10 18:03;jbellis;committed, w/ minor changes to formatting to prefer colons + indentation to {}.  python influence. :);;;","14/Oct/10 18:23;xedin;ok, nice :);;;","15/Oct/10 13:23;hudson;Integrated in Cassandra #566 (See [https://hudson.apache.org/hudson/job/Cassandra/566/])
    include CF metadata in cli 'show keyspaces'.  patch by Pavel Yaskevich; reviewed by jbellis for CASSANDRA-1613
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cli support for strategy_options,CASSANDRA-1612,12477205,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,xedin,jbellis,jbellis,13/Oct/10 03:43,16/Apr/19 09:33,14/Jul/23 05:51,13/Oct/10 13:52,0.7 beta 3,,Legacy/Tools,,0,,,,,,"[default@unknown] create keyspace MyCollections with placement_strategy='org.apache.cassandra.locator.NetworkTopologyStrategy' and strategy_options=[{DC1:2, DC2:2}] and replication_factor=4
No enum const class org.apache.cassandra.cli.CliClient$AddKeyspaceArgument.STRATEGY_OPTIONS
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Oct/10 13:34;xedin;CASSANDRA-1612.patch;https://issues.apache.org/jira/secure/attachment/12457064/CASSANDRA-1612.patch",,,,,,,,,,,,,,1.0,xedin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20217,,,Thu Oct 14 12:49:50 UTC 2010,,,,,,,,,,"0|i0g6av:",92451,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"13/Oct/10 13:34;xedin;Help is updated also.;;;","13/Oct/10 13:52;jbellis;committed.

but let's not litter local variables w/ unnecessary final keywords.;;;","13/Oct/10 14:00;xedin;Understood.;;;","14/Oct/10 12:49;hudson;Integrated in Cassandra #565 (See [https://hudson.apache.org/hudson/job/Cassandra/565/])
    cli support for strategy_options.
patch by Pavel Yaskevich; reviewed by jbellis for CASSANDRA-1612
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cluster restart re-adds removed tokens,CASSANDRA-1609,12477154,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,nickmbailey,nickmbailey,12/Oct/10 16:49,16/Apr/19 09:33,14/Jul/23 05:51,13/Oct/10 15:57,0.7 beta 3,,,,0,,,,,,"After a cluster restart one of our nodes began reporting tokens that had been removed a good while ago (week or more) in it's nodetool ring output.  This probably has something to do with our change to persist the ring in CASSANDRA-1518 and removetoken changes in CASSANDRA-1216. The node didn't actually gossip the removed tokens so they showed up in TMD but not gossip.

Additionally all nodes began reporting a node that had been removed maybe an hour ago.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/10 21:54;jbellis;1609.txt;https://issues.apache.org/jira/secure/attachment/12457019/1609.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20215,,,Thu Oct 14 12:49:47 UTC 2010,,,,,,,,,,"0|i0g6a7:",92448,,nickmbailey,,nickmbailey,Normal,,,,,,,,,,,,,,,,,"12/Oct/10 17:24;nickmbailey;So the first 4 tokens were removed using decomission and the last one using removetoken. It doesn't look like either of those processes remove nodes from the saved state. The nodes then show up in nodetool ring but not gossip since they don't actually have an application state to begin with.;;;","12/Oct/10 19:09;nickmbailey;So it looks like we don't remove tokens from the system table when we decomission which leads to the following scenario:

# Node A has token 1
# Node A loadbalance to token 2
# Node A dies
# Node A removed
# Cluster restart
# Node A reappears with token 1 since that was never removed/overwritten in the system table.

At least i think thats how its happening. Not sure about one of our nodes seeing the four decomissioned tokens and the others not.;;;","12/Oct/10 21:54;jbellis;ring state management is a mess.  token removal happens in 3 places:

 1) node receives decommission notice (STATE_LEFT)
 2) node receives removetoken notice, piggy-backed on STATE_NORMAL
 3) node coordinates removetoken (gossiper will not trigger notifications for state changes that initiated locally, so this needs to be handled separately from 2)

2) was updating the SystemTable w/ the removal but the others were not.

patch attached to move this logic into excise() method and call from all 3 places.;;;","13/Oct/10 03:38;nickmbailey; * handleStateLeft wasn't actually removing the endpoint from gossip before. Was that an oversight or intended?
 * you removed a check from handleStateLeft to make sure the token was a member before removing it.  Intentional?
;;;","13/Oct/10 15:14;jbellis;bq. handleStateLeft wasn't actually removing the endpoint from gossip before

right, that was a bug.

bq. you removed a check from handleStateLeft to make sure the token was a member

yes, we skip the check everywhere else because either way the result is the same.  there's no meaningful action we can take if the check fails so it's redundant.;;;","13/Oct/10 15:53;nickmbailey;+1;;;","13/Oct/10 15:57;jbellis;committed;;;","14/Oct/10 12:49;hudson;Integrated in Cassandra #565 (See [https://hudson.apache.org/hudson/job/Cassandra/565/])
    fix removing tokens from SystemTable on decommission and removetoken.
patch by jbellis; reviewed by Nick Bailey for CASSANDRA-1609
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Thrift CfDef incomplete; missing row/key_save_period_in_seconds",CASSANDRA-1606,12477075,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jhermes,jhermes,jhermes,11/Oct/10 21:38,16/Apr/19 09:33,14/Jul/23 05:51,13/Oct/10 17:41,0.7 beta 3,,,,0,,,,,,"Missed from CASSANDRA-1417.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Oct/10 17:23;jhermes;1606.txt;https://issues.apache.org/jira/secure/attachment/12457085/1606.txt",,,,,,,,,,,,,,1.0,jhermes,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20214,,,Thu Oct 14 12:49:47 UTC 2010,,,,,,,,,,"0|i0g69j:",92445,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"13/Oct/10 17:23;jhermes;Patch adds the vars into the thrift CfDef, and cleans up/finishes CFMetaData.;;;","13/Oct/10 17:41;jbellis;committed;;;","14/Oct/10 12:49;hudson;Integrated in Cassandra #565 (See [https://hudson.apache.org/hudson/job/Cassandra/565/])
    add row/key cache save periods to CfDef.
patch by Jon Hermes; reviewed by jbellis for CASSANDRA-1606
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RemoveToken waits for dead nodes,CASSANDRA-1605,12477046,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,nickmbailey,nickmbailey,nickmbailey,11/Oct/10 17:59,16/Apr/19 09:33,14/Jul/23 05:51,12/Oct/10 15:10,0.7 beta 3,,Legacy/Tools,,0,,,,,,RemoveToken will wait for replication confirmation from nodes that are down.   It should only wait for live nodes.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/10 19:46;nickmbailey;0001-Use-failure-detector-when-detecting-new-nodes.patch;https://issues.apache.org/jira/secure/attachment/12456885/0001-Use-failure-detector-when-detecting-new-nodes.patch",,,,,,,,,,,,,,1.0,nickmbailey,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20213,,,Thu Oct 14 12:49:49 UTC 2010,,,,,,,,,,"0|i0g69b:",92444,,,,,Normal,,,,,,,,,,,,,,,,,"11/Oct/10 19:46;nickmbailey;Updated to use the failure detector when determining who to wait for.;;;","12/Oct/10 15:10;jbellis;committed w/ inline of getNewEndpoints since neither the name nor the javadoc was an accurate description of what it did anymore;;;","14/Oct/10 12:49;hudson;Integrated in Cassandra #565 (See [https://hudson.apache.org/hudson/job/Cassandra/565/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Database Descriptor has log message that mashes words,CASSANDRA-1604,12477040,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,appodictic,appodictic,appodictic,11/Oct/10 16:26,16/Apr/19 09:33,14/Jul/23 05:51,11/Oct/10 16:45,0.6.7,0.7 beta 3,,,0,,,,,,"-                logger.info(""DiskAccessMode is"" + conf.disk_access_mode + "", indexAccessMode is "" + indexAccessMode );
+                logger.info(""DiskAccessMode is "" + conf.disk_access_mode + "", indexAccessMode is "" + indexAccessMode );",,,,,,,,,,,3600,3600,,0%,3600,3600,,,,,,,,,,,,,,"11/Oct/10 16:28;appodictic;cassandra-1604-1-patch.txt;https://issues.apache.org/jira/secure/attachment/12456872/cassandra-1604-1-patch.txt",,,,,,,,,,,,,,1.0,appodictic,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20212,,,Mon Oct 11 16:45:27 UTC 2010,,,,,,,,,,"0|i0g693:",92443,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"11/Oct/10 16:45;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"get_range_slices always returns super columns that's been removed/restored, regardless of count value in slicerange",CASSANDRA-1591,12476722,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,hujn,hujn,07/Oct/10 00:06,16/Apr/19 09:33,14/Jul/23 05:51,22/Nov/10 19:29,0.6.9,0.7.0 rc 1,,,0,,,,,,"I'm seeing cases where the count in slicerange predicate is not respected. This is only happening for super columns. I'm running Cassandra 0.6.4 in a single node.

Steps to reproduce, using the Keyspace1.Super1 CF:
* insert three super columns, bar1 bar 2, and bar3, under the same key
* delete bar1
* insert bar1 again
* run a get_range_slices on Super1, with start=bar1, finish=bar3, and count=1
* I expected only bar1 to be returned, but both both bar1 and bar2 are returned. bar3 isn't, though. so count is somewhat respected.

perl code to reproduce is attached
when I tried the same test on a standard CF it worked. only super CF seem to have this problem.","CentOS 5.4, single Cassandra node ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Oct/10 21:25;thobbs;1591-0.6-reproduce.txt;https://issues.apache.org/jira/secure/attachment/12457299/1591-0.6-reproduce.txt","22/Nov/10 18:43;jbellis;1591.txt;https://issues.apache.org/jira/secure/attachment/12460194/1591.txt","07/Oct/10 00:10;hujn;test.pl;https://issues.apache.org/jira/secure/attachment/12456559/test.pl",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19368,,,Mon Nov 22 22:01:02 UTC 2010,,,,,,,,,,"0|i0g65z:",92429,,tjake,,tjake,Low,,,,,,,,,,,,,,,,,"15/Oct/10 21:25;thobbs;Attached patch at least partially reproduces using system tests.;;;","22/Nov/10 18:43;jbellis;the deleted supercolumn w/ a live subcolumn wasn't being included in the count.  this patch adds an isLive method to fix this:

+     * For a simple column, live == !isMarkedForDelete.
+     * For a supercolumn, live means it has at least one subcolumn whose timestamp is greater than the
+     * supercolumn deleted-at time.
;;;","22/Nov/10 19:18;tjake;LGTM +1;;;","22/Nov/10 22:01;hudson;Integrated in Cassandra-0.6 #11 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/11/])
    fix live-column-count of slice ranges including tombstoned supercolumn with live subcolumn
patch by jbellis and Tyler Hobbs; reviewed by tjake for CASSANDRA-1591
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pig loadfunc fails with java.io.FileNotFoundException: ...:.../job.jar!/storage-conf.xml,CASSANDRA-1590,12476720,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,tv42,tv42,06/Oct/10 23:05,16/Apr/19 09:33,14/Jul/23 05:51,12/Nov/10 21:51,0.6.9,,,,0,,,,,,"Trying to run the example job from contrib/pig (after fixing it to start at all in the first place; details later) results in this:


2010-10-06 15:43:32,117 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - (Name: Store(hdfs://localhost/tmp/temp-1257182404/tmp1075428643:org.apache.pig.builtin.BinStorage) - 1-60 Operator Key: 1-60)
2010-10-06 15:43:32,164 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.CombinerOptimizer - Choosing to move algebraic foreach to combiner
2010-10-06 15:43:32,224 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 3
2010-10-06 15:43:32,224 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 3
2010-10-06 15:43:32,302 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2010-10-06 15:43:40,356 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job
2010-10-06 15:43:40,450 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.
2010-10-06 15:43:40,457 [Thread-12] WARN  org.apache.hadoop.mapred.JobClient - Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2010-10-06 15:43:40,950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete
2010-10-06 15:43:41,038 [Thread-12] INFO  org.apache.cassandra.config.DatabaseDescriptor - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
2010-10-06 15:43:41,211 [Thread-12] WARN  org.apache.cassandra.config.DatabaseDescriptor - KeysCachedFraction is deprecated: use KeysCached instead.
2010-10-06 15:43:41,232 [Thread-12] WARN  org.apache.cassandra.config.DatabaseDescriptor - KeysCachedFraction is deprecated: use KeysCached instead.
2010-10-06 15:43:42,305 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_201010061447_0008
2010-10-06 15:43:42,305 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - More information at: http://localhost:50030/jobdetails.jsp?jobid=job_201010061447_0008
2010-10-06 15:44:15,025 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 33% complete
2010-10-06 15:44:17,037 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete
2010-10-06 15:44:17,037 [main] ERROR org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map reduce job(s) failed!
2010-10-06 15:44:17,067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Failed!
2010-10-06 15:44:17,199 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 2997: Unable to recreate exception from backed error: Error: java.lang.RuntimeException: java.io.FileNotFoundException: /var/lib/hadoop-0.20/cache/hadoop/mapred/local/taskTracker/jobcache/job_201010061447_0008/attempt_201010061447_0008_m_000000_0/work/file:/var/lib/hadoop-0.20/cache/hadoop/mapred/local/taskTracker/jobcache/job_201010061447_0008/jars/job.jar!/storage-conf.xml (No such file or directory)
Details at logfile: /home/tv/casspig/cassandra/contrib/pig/pig_1286405010154.log

Contents of that pig_*.log:


Backend error message
---------------------
Error: java.lang.RuntimeException: java.io.FileNotFoundException: /var/lib/hadoop-0.20/cache/hadoop/mapred/local/taskTracker/jobcache/job_201010061447_0008/attempt_201010061447_0008_m_000000_0/work/file:/var/lib/hadoop-0.20/cache/hadoop/mapred/local/taskTracker/jobcache/job_201010061447_0008/jars/job.jar!/storage-conf.xml (No such file or directory)
	at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:542)
	at org.apache.cassandra.hadoop.ConfigHelper.getThriftPort(ConfigHelper.java:188)
	at org.apache.cassandra.hadoop.ColumnFamilyRecordReader$RowIterator.<init>(ColumnFamilyRecordReader.java:118)
	at org.apache.cassandra.hadoop.ColumnFamilyRecordReader$RowIterator.<init>(ColumnFamilyRecordReader.java:104)
	at org.apache.cassandra.hadoop.ColumnFamilyRecordReader.initialize(ColumnFamilyRecordReader.java:93)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader.initialize(PigRecordReader.java:133)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:418)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:620)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
	at org.apache.hadoop.mapred.Child.main(Child.java:170)
Caused by: java.io.FileNotFoundException: /var/lib/hadoop-0.20/cache/hadoop/mapred/local/taskTracker/jobcache/job_201010061447_0008/attempt_201010061447_0008_m_000000_0/work/file:/var/lib/hadoop-0.20/cache/hadoop/mapred/local/taskTracker/jobcache/job_201010061447_0008/jars/job.jar!/storage-conf.xml (No such file or directory)
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:106)
	at java.io.FileInputStream.<init>(FileInputStream.java:66)
	at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:70)
	at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:161)
	at com.sun.org.apache.xerces.internal.impl.XMLEntityManager.setupCurrentEntity(XMLEntityManager.java:653)
	at com.sun.org.apache.xerces.internal.impl.XMLVersionDetector.determineDocVersion(XMLVersionDetector.java:186)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:772)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:737)
	at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:119)
	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:235)
	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:284)
	at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:208)
	at org.apache.cassandra.utils.XMLUtils.<init>(XMLUtils.java:43)
	at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:167)
	... 9 more

Pig Stack Trace
---------------
ERROR 2997: Unable to recreate exception from backed error: Error: java.lang.RuntimeException: java.io.FileNotFoundException: /var/lib/hadoop-0.20/cache/hadoop/mapred/local/taskTracker/jobcache/job_201010061447_0008/attempt_201010061447_0008_m_000000_0/work/file:/var/lib/hadoop-0.20/cache/hadoop/mapred/local/taskTracker/jobcache/job_201010061447_0008/jars/job.jar!/storage-conf.xml (No such file or directory)

org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1066: Unable to open iterator for alias topnames
	at org.apache.pig.PigServer.openIterator(PigServer.java:607)
	at org.apache.pig.tools.grunt.GruntParser.processDump(GruntParser.java:544)
	at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:241)
	at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:162)
	at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:138)
	at org.apache.pig.tools.grunt.Grunt.run(Grunt.java:75)
	at org.apache.pig.Main.main(Main.java:380)
Caused by: org.apache.pig.backend.executionengine.ExecException: ERROR 2997: Unable to recreate exception from backed error: Error: java.lang.RuntimeException: java.io.FileNotFoundException: /var/lib/hadoop-0.20/cache/hadoop/mapred/local/taskTracker/jobcache/job_201010061447_0008/attempt_201010061447_0008_m_000000_0/work/file:/var/lib/hadoop-0.20/cache/hadoop/mapred/local/taskTracker/jobcache/job_201010061447_0008/jars/job.jar!/storage-conf.xml (No such file or directory)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.Launcher.getErrorMessages(Launcher.java:231)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.Launcher.getStats(Launcher.java:175)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:270)
	at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.execute(HExecutionEngine.java:308)
	at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1007)
	at org.apache.pig.PigServer.store(PigServer.java:697)
	at org.apache.pig.PigServer.openIterator(PigServer.java:590)
	... 6 more
================================================================================


I'm attaching a tarball with everything needed to reproduce this, see the run script there.",Ubuntu 10.04 with Hadoop from Cloudera CDH3b2,jeromatron,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Oct/10 23:06;tv42;casspig.tgz;https://issues.apache.org/jira/secure/attachment/12456553/casspig.tgz","11/Nov/10 18:38;tv42;p1590.diff;https://issues.apache.org/jira/secure/attachment/12459368/p1590.diff",,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20210,,,Tue Nov 16 01:01:09 UTC 2010,,,,,,,,,,"0|i0g65r:",92428,,,,,Normal,,,,,,,,,,,,,,,,,"06/Oct/10 23:06;tv42;A script with some auxiliary files to reproduce said problem from scratch. Assumes a working Hadoop installation, pseudo-distributed mode is fine.;;;","13/Oct/10 22:55;jeromatron;It works if you manually build pig and put your storage-conf.xml in the jar, but there is something wrong with how it's trying to find the storage-conf.xml.  It shouldn't matter with 0.7 since it's only using hadoop vars or env vars (CASSANDRA-1322).  However, it needs to be addressed in 0.6.x so that it's more usable.;;;","11/Nov/10 18:38;tv42;This seems to be the right fix; URIs/URLs are loaded from jars, just filenames are not.;;;","12/Nov/10 21:51;brandon.williams;Committed, thanks!;;;","14/Nov/10 12:38;jbellis;Did this make it into 0.6.8?;;;","16/Nov/10 01:01;brandon.williams;Not quite.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
suggest avoiding broken openjdk6 on Debian as build-dep,CASSANDRA-1575,12475803,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,scode,scode,04/Oct/10 20:28,16/Apr/19 09:33,14/Jul/23 05:51,06/Oct/10 21:13,0.6.6,0.7 beta 3,Packaging,,0,,,,,,"I ran into this myself and then today someone was reporting having the same problem on IRC; there is a packaging bug in openjdk6 in lenny:

   http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=501487

The effect is that when ant tries to download files over SSL, it fails complaining about:

   ""java.security.InvalidAlgorithmParameterException: the trustAnchors parameter must be non-empty""

It turns out this works fine with the Sun JVM. I'm attaching a patch which makes Cassandra build on both lenny and squeeze; however, I am not sure whether other platforms may be negatively affected. The patch just requires an openjdk sufficiently new that the lenny openjdk won't quality. If there are other platforms where we do want an older openjdk, this patch might break that.

In addition, I removed the ""java6-sdk"" as a sufficient dependency because that resolved to openjdk-6-jdk on lenny.

I think it's a good idea to consider changing this just to decrease the initial threshold of adoption for those trying to build from source.

So: This does fix the build issue on lenny, and doesn't seem to break squeeze, but I cannot promise anything about e.g. ubuntu.

For the record, I'm also attaching a small self-contained test case which, when run, tries to download one of the offending pom files. It can be used to easily test weather the SSL download with work with a particular JVM.",Debian lenny,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/10 20:30;scode;Trunk1575Test.java;https://issues.apache.org/jira/secure/attachment/12456317/Trunk1575Test.java","04/Oct/10 20:29;scode;trunk-1575.txt;https://issues.apache.org/jira/secure/attachment/12456316/trunk-1575.txt",,,,,,,,,,,,,2.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20209,,,Wed Oct 06 22:33:17 UTC 2010,,,,,,,,,,"0|i0g62n:",92414,,urandom,,urandom,Low,,,,,,,,,,,,,,,,,"04/Oct/10 21:44;scode;And I should stress that this will presumably only help normalized build environments that install build dependencies as required. It doesn't help a user trying to 'ant build', nor a user trying to 'debuild' and happens to have other JDK:s installed, but I'm not sure how to address that in a clean fashion.

Maybe add a note under ""requirements"" in the README?

(I realize this is catering to a very specific platform, but lenny is presumably pretty common.);;;","06/Oct/10 21:13;urandom;First off, thanks for the report, and the background research on it.

To summarize this issue for others, the openjdk-6 package in Lenny is missing the cacerts keystore needed to establish ""trust"" with SSL enabled servers.  I'm guessing this is because it was stripped from Sun's original code dump, because later versions of the package depend on ca-certificates-java which simply maintains a keystore made up of the Debian installed CAs.

Where this creates a problem for Cassandra is in the retrieval of build dependencies with Ivy, where those deps are located on SSL-enabled remote servers. This _only_ occurs on Lenny though, later versions are fine.

As to the attached patch, I'm not convinced that the cure here isn't worse than the disease.  Here' s why:

* The problem is only with building a Debian source package, and only on Lenny.  I believe this to be a small subset of all users.
* The situation isn't impossible for those that want to build the source package on Lenny.  They simply need to install sun-java6 first (or set it to default using update-alternatives if openjdk-6 is already installed).
* The attached patch will result in an uninstallable package for anyone who doesn't have the non-free repository enabled.  This is everyone who went through the default installation process.
* Unattended installs of sun-java6 (think chef, puppet, et. al.) are difficult at best because the package prompts for user acceptance of the license.
* If possible, we want to use the same packaging for all versions of Debian and derivatives, and there has been a lot of talk of removing the sun packages from archives. 

I think it'd be better to simply document this at http://wiki.apache.org/cassandra/DebianPackaging and leave things as they are.  If you disagree, feel free to reopen the report.;;;","06/Oct/10 22:33;scode;Sounds reasonable.

That said, maybe the set of people who would try 'ant build' on lenny is significantly larger than those building Debian packages with debuild. For those, a note in README might be helpful.

But again I realize this is catering to a very specific problem. Maybe it's just not worth it.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bootstrapping is broken,CASSANDRA-1574,12475799,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,nickmbailey,nickmbailey,nickmbailey,04/Oct/10 20:06,16/Apr/19 09:33,14/Jul/23 05:51,04/Oct/10 22:08,0.7 beta 3,,,,0,,,,,,Bootstrap doesn't block for streaming requests which means nodetool move isn't blocking.  More importantly bootstrap fails to call finishBootstrapping if no stream requests are ever made. This means its impossible to perform moves if you have no keyspaces.,,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/10 20:24;nickmbailey;0001-Updated-bootstrapping-to-block.patch;https://issues.apache.org/jira/secure/attachment/12456314/0001-Updated-bootstrapping-to-block.patch","04/Oct/10 21:14;jbellis;1574-v2.txt;https://issues.apache.org/jira/secure/attachment/12456324/1574-v2.txt",,,,,,,,,,,,,2.0,nickmbailey,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20208,,,Tue Oct 05 13:25:31 UTC 2010,,,,,,,,,,"0|i0g62f:",92413,,jbellis,,jbellis,Critical,,,,,,,,,,,,,,,,,"04/Oct/10 20:24;nickmbailey;Updated to block with a latch. If nothing is going to be streamed waiting on the latch will return immediately and finish the bootstrap.;;;","04/Oct/10 21:14;jbellis;v2 removes the unnecessary bootstrapNodes variable, renames startBootstrap to bootstrap to emphasize it is blocking now, and updates storageService to be aware of this blocking nature;;;","04/Oct/10 21:55;nickmbailey;You have a comment in StorageService that spells ""finished"" as ""finishec"". Besides that looks good to me.;;;","04/Oct/10 22:08;jbellis;fixed + committed;;;","05/Oct/10 13:25;hudson;Integrated in Cassandra #556 (See [https://hudson.apache.org/hudson/job/Cassandra/556/])
    fix moving nodes with no keyspaces defined
patch by Nick Bailey and jbellis for CASSANDRA-1574
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
StreamOut fails to start an empty stream,CASSANDRA-1573,12475792,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,jbellis,nickmbailey,nickmbailey,04/Oct/10 18:53,16/Apr/19 09:33,14/Jul/23 05:51,04/Oct/10 22:06,0.7 beta 3,,,,0,,,,,,StreamOut only starts a stream if there are actually files to transfer. This means callbacks will never get called for streams that don't actually have anything to transfer.,,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/10 18:54;nickmbailey;0001-Remove-empty-list-check-from-StreamOut.patch;https://issues.apache.org/jira/secure/attachment/12456306/0001-Remove-empty-list-check-from-StreamOut.patch","04/Oct/10 20:58;jbellis;1573-v2.txt;https://issues.apache.org/jira/secure/attachment/12456321/1573-v2.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20207,,,Tue Oct 05 13:25:32 UTC 2010,,,,,,,,,,"0|i0g627:",92412,,nickmbailey,,nickmbailey,Critical,,,,,,,,,,,,,,,,,"04/Oct/10 18:54;nickmbailey;There is an empty check in begin() anyway so no need for the check in StreamOut.;;;","04/Oct/10 20:57;jbellis;There is no reason to go through the target node, which is what session.begin will do, when there is nothing to transfer to it.  Attached is an alternate patch that simply skips to session.close when there is nothing to do.;;;","04/Oct/10 21:55;nickmbailey;Looks good to me.;;;","04/Oct/10 22:06;jbellis;committed;;;","05/Oct/10 13:25;hudson;Integrated in Cassandra #556 (See [https://hudson.apache.org/hudson/job/Cassandra/556/])
    fix unbootstrap when no data is present in a transfer range
patch by jbellis; reviewed by Nick Bailey for CASSANDRA-1573
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Secondary Indexes aren't updated when removing whole row,CASSANDRA-1571,12475744,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,xodut,xodut,04/Oct/10 09:17,16/Apr/19 09:33,14/Jul/23 05:51,06/Oct/10 17:19,0.7 beta 3,,Feature/2i Index,,0,,,,,,"When I remove a whole row in a CF
del SomeColumnFamily['row']

SI is not updated and get_indexed_slices still returns the deleted row.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Oct/10 16:02;jbellis;1571.txt;https://issues.apache.org/jira/secure/attachment/12456398/1571.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20206,,,Wed Oct 06 17:19:39 UTC 2010,,,,,,,,,,"0|i0g61r:",92410,,stuhood,,stuhood,Normal,,,,,,,,,,,,,,,,,"05/Oct/10 17:05;stuhood;* {{EDIT: Ignore this line: noticed that you try it both ways.}} ColumnFamilyStoreTest uses deletion.value() to confirm that the value was actually removed, but a column that has been deleted and GCd does not contain the original column: the original column contained 'x0000000000000001' and the deletion contains 'x4cab5aad'
* In Table.ignoreObsoleteMutations, is there a way to avoid cloning the CF for each column? Perhaps adding all columns to a single clone, and then collecting them back out?
* Can you add a quickie Javadoc to explain the readCurrent, ignoreObsolete and applyIndex steps?;;;","06/Oct/10 17:19;jbellis;committed w/ suggested improvements;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nodeprobe help message is missing option to compact specific keyspace,CASSANDRA-1568,12475718,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,appodictic,appodictic,appodictic,03/Oct/10 18:17,16/Apr/19 09:33,14/Jul/23 05:51,04/Oct/10 14:36,0.7 beta 3,,Legacy/Tools,,0,,,,,,"{noformat}
-                ""%nAvailable commands: ring, info, version, cleanup, compact, cfstats, snapshot [snapshotname], clearsnapshot, "" +
-                ""tpstats, flush, drain, repair, decommission, move, loadbalance, removetoken [status|force]|[token], "" +
+                ""%nAvailable commands: ring, info, version, cleanup, compact [keyspacename], cfstats, snapshot [snapshotname], "" +
+                ""clearsnapshot, tpstats, flush, drain, repair, decommission, move, loadbalance, removetoken [status|force]|[token], "" +
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Oct/10 18:18;appodictic;cassandra-1568.patch.txt;https://issues.apache.org/jira/secure/attachment/12456254/cassandra-1568.patch.txt",,,,,,,,,,,,,,1.0,appodictic,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20205,,,Tue Oct 05 13:25:31 UTC 2010,,,,,,,,,,"0|i0g613:",92407,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"03/Oct/10 18:18;appodictic;Corrects help message;;;","04/Oct/10 14:36;jbellis;committed, thanks!;;;","05/Oct/10 13:25;hudson;Integrated in Cassandra #556 (See [https://hudson.apache.org/hudson/job/Cassandra/556/])
    mention optional keyspace name in nodetool compact help message.  patch by ecapriolo; reviewed by jbellis for CASSANDRA-1568
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
incomplete sstables for System keyspace are not scrubbed before opening it,CASSANDRA-1564,12475568,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,01/Oct/10 03:18,16/Apr/19 09:33,14/Jul/23 05:51,01/Oct/10 20:30,0.7 beta 3,,,,0,,,,,,(From CASSANDRA-1477),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Oct/10 03:18;jbellis;1564.txt;https://issues.apache.org/jira/secure/attachment/12456079/1564.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20203,,,Sat Oct 02 12:56:27 UTC 2010,,,,,,,,,,"0|i0g607:",92403,,gdusbabek,,gdusbabek,Normal,,,,,,,,,,,,,,,,,"01/Oct/10 20:16;gdusbabek;+1;;;","01/Oct/10 20:30;jbellis;committed;;;","02/Oct/10 12:56;hudson;Integrated in Cassandra #553 (See [https://hudson.apache.org/hudson/job/Cassandra/553/])
    scrub System keyspace before opening it
patch by jbellis; reviewed by gdusbabek for CASSANDRA-1564
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Disallow bootstrapping to a token that is already owned by a live node,CASSANDRA-1561,12475517,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,30/Sep/10 16:54,16/Apr/19 09:33,14/Jul/23 05:51,07/Oct/10 15:41,0.6.6,0.7 beta 3,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Sep/10 16:54;jbellis;1561.txt;https://issues.apache.org/jira/secure/attachment/12456027/1561.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20200,,,Thu Oct 07 15:41:11 UTC 2010,,,,,,,,,,"0|i0g5zj:",92400,,gdusbabek,,gdusbabek,Low,,,,,,,,,,,,,,,,,"30/Sep/10 16:57;jbellis;btw, we're already checking for this on node move/loadbalance:

{code}
        if (token != null && tokenMetadata_.sortedTokens().contains(token))
            throw new IOException(""target token "" + token + "" is already owned by another node"");
{code};;;","07/Oct/10 15:11;gdusbabek;+1;;;","07/Oct/10 15:41;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
describe_keyspace() should include strategy_options,CASSANDRA-1560,12475456,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jhermes,thobbs,thobbs,29/Sep/10 23:19,16/Apr/19 09:33,14/Jul/23 05:51,30/Sep/10 01:17,0.7 beta 3,,,,0,,,,,,describe_keyspace() does not include the strategy_options in the returned KsDef,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Sep/10 00:31;jhermes;1560.txt;https://issues.apache.org/jira/secure/attachment/12455955/1560.txt",,,,,,,,,,,,,,1.0,jhermes,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,633,,,Thu Sep 30 12:48:05 UTC 2010,,,,,,,,,,"0|i0g5zb:",92399,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"30/Sep/10 00:31;jhermes;If more things get added to KSMetaData (which shouldn't happen), then it would be worthwhile to abstract this to KSMetaData.convertToThrift().;;;","30/Sep/10 01:17;jbellis;committed;;;","30/Sep/10 12:48;hudson;Integrated in Cassandra #551 (See [https://hudson.apache.org/hudson/job/Cassandra/551/])
    add strategy options to describe_keyspace output.  patch by jhermes; reviewed by jbellis for CASSANDRA-1560
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ColumnFamilyStore masking IOException from FileUtils as IOError,CASSANDRA-1557,12475385,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,amorton,amorton,29/Sep/10 08:02,16/Apr/19 09:33,14/Jul/23 05:51,07/Oct/10 20:59,0.7 beta 3,,Legacy/CQL,,0,,,,,,"The code in ColumnFamilyStore.snapshot() line 1368 is catching an IOException from the call to FileUtils.createHardLink() and wrapping it in an IOError. However the code in TruncateVerbHandler:56 is looking for the IOException. This can result  in the client not getting a response to a truncate() API call. 

When running on a machine with very low memory I attempted to truncate a CF with few rows, the following error occurred in the logs.

ERROR [MUTATION_STAGE:25] 2010-09-29 16:44:39,341 AbstractCassandraDaemon.java (line 88) Fatal exception in thread Thread[MUTATION_STAGE:25,5,main]
java.io.IOError: java.io.IOException: Cannot run program ""ln"": java.io.IOException: error=12, Cannot allocate memory
        at org.apache.cassandra.db.ColumnFamilyStore.snapshot(ColumnFamilyStore.java:1368)
        at org.apache.cassandra.db.ColumnFamilyStore.truncate(ColumnFamilyStore.java:1511)
        at org.apache.cassandra.db.Table.truncate(Table.java:633)
        at org.apache.cassandra.db.TruncateVerbHandler.doVerb(TruncateVerbHandler.java:54)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at javautil.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.io.IOException: Cannot run program ""ln"": java.io.IOException: error=12, Cannot allocate memory
        at java.lang.ProcessBuilder.start(ProcessBuilder.java:460)
        at org.apache.cassandra.io.util.FileUtils.createHardLinkWithExec(FileUtils.java:263)
        at org.apache.cassandra.io.util.FileUtils.createHardLink(FileUtils.java:229)
        at org.apache.cassandra.db.ColumnFamilyStore.snapshot(ColumnFamilyStore.java:1360)
        ... 7 more
Caused by: java.io.IOException: java.io.IOException: error=12, Cannot allocate memory
        at java.lang.UNIXProcess.<init>(UNIXProcess.java:148)
        at java.lang.ProcessImpl.start(ProcessImpl.java:65)
        at java.lang.ProcessBuilder.start(ProcessBuilder.java:453)
        ... 10 more

On the client I got this:

  File ""/tech/home//git_home/trojan/trojan/cassandra/Cassandrapy"", line 846, in truncate
    self.recv_truncate()
  File ""/tech/home//git_home/trojan/trojan/cassandra/Cassandra.py"", line 857, in recv_truncate
    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
  File ""/tech/home//git_home/trojan/trojan/thrift/protocol/TBinaryProtocol.py"", line 126, in readMessageBegin
    sz = self.readI32()
<snip>
    chunk = self.read(sz-have)
  File ""/tech/home//git_home/trojan/trojan/thrift/transport/TSocket.py"", line 92, in read
    buff = self.handle.recv(sz)
timeout: timed out",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Oct/10 16:38;jbellis;1557.txt;https://issues.apache.org/jira/secure/attachment/12456133/1557.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20199,,,Thu Oct 07 20:59:42 UTC 2010,,,,,,,,,,"0|i0g5yn:",92396,,amorton,,amorton,Low,,,,,,,,,,,,,,,,,"01/Oct/10 16:38;jbellis;patch allows snapshot IOException to propagate up to TruncateVerbHandler;;;","07/Oct/10 20:59;amorton;Looks good to me.

Tested by throwing an IOException from CFS.snapshot(). TruncateVerbHandler caught it and logged the error, the client returned immediately without an error being raised. 

One small thing I noticed was that ColumnFamilyStore.truncate() wraps all exceptions from forceBlockingFlush() in an IOException..

        try
        {
            forceBlockingFlush();
        }
        catch (Exception e)
        {
            throw new IOException(e);
        }

but all other functions that call forceBlockingFlush (e..g snapshot or addIndex) catch the two exceptions it throws and wrap them differently
            try
            {
                forceBlockingFlush();
            }
            catch (ExecutionException e)
            {
                throw new RuntimeException(e);
            }
            catch (InterruptedException e)
            {
                throw new AssertionError(e);
            }
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
InvalidRequestException(why='') returned from system_add_keyspace when strategy_class not found,CASSANDRA-1556,12475384,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,amorton,amorton,amorton,29/Sep/10 07:50,16/Apr/19 09:33,14/Jul/23 05:51,06/Oct/10 18:47,0.7 beta 3,,Legacy/CQL,,0,,,,,,"In thrift/CassandraServer system_add_keyspace() the strategy_class string from the KsDef is used to load a class. The ClassNotFoundError is then caught and used to build an InvalidRequestException. If the strategy_class is missing or empty, the error returned to the client is 

(python)
InvalidRequestException: InvalidRequestException(why='')

or 

InvalidRequestException: InvalidRequestException(why='foo')",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Oct/10 02:20;amorton;1556-amorton.txt;https://issues.apache.org/jira/secure/attachment/12456463/1556-amorton.txt","01/Oct/10 21:29;jbellis;1556.txt;https://issues.apache.org/jira/secure/attachment/12456160/1556.txt",,,,,,,,,,,,,2.0,amorton,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20198,,,Tue Oct 12 14:03:56 UTC 2010,,,,,,,,,,"0|i0g5yf:",92395,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"01/Oct/10 21:29;jbellis;Odd that the CNFE would not include a message.  Does this patch work better?;;;","06/Oct/10 02:11;amorton;I noticed system_update_keyspace uses FBUtilities.<T>classForName() which prints out pretty error messages, e.g. 

InvalidRequestException(why=""Unable to find keyspace replication strategy class 'InvalidStrategyClass': is the CLASSPATH set correctly?"")

Have created a patch to use that in both the thrift and avro CassandraServer, will upload.;;;","06/Oct/10 02:20;amorton;modified CassandraServer for thrift and avro to use FBUtilities.classForName() to get the strategy class for system_add_keyspace, was already doing it for system_update_keyspace;;;","06/Oct/10 18:47;jbellis;committed, thanks!;;;","12/Oct/10 14:03;hudson;Integrated in Cassandra #563 (See [https://hudson.apache.org/hudson/job/Cassandra/563/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
extend authorization to column families,CASSANDRA-1554,12475364,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,urandom,urandom,urandom,28/Sep/10 23:46,16/Apr/19 09:33,14/Jul/23 05:51,06/Oct/10 15:20,0.7 beta 3,,,,0,,,,,,"Authorization is now based on a hierarchy of resources, but the hierarchy only extends as far as keyspaces.  At the very least, it should be possible to implement an authority that can distinguish between the creation, modification and deletion of column families, and reading and writing the data contained in them.",,stuhood,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1271,,,,,"05/Oct/10 14:33;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1554-refactor-SimpleAuthority-for-CF-resourc.txt;https://issues.apache.org/jira/secure/attachment/12456386/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1554-refactor-SimpleAuthority-for-CF-resourc.txt","05/Oct/10 14:33;urandom;ASF.LICENSE.NOT.GRANTED--v1-0002-refactor-ClientState-and-RPC-for-CF-authorizations.txt;https://issues.apache.org/jira/secure/attachment/12456387/ASF.LICENSE.NOT.GRANTED--v1-0002-refactor-ClientState-and-RPC-for-CF-authorizations.txt","05/Oct/10 14:33;urandom;ASF.LICENSE.NOT.GRANTED--v1-0003-CF-access-test-for-SimpleAuthority.txt;https://issues.apache.org/jira/secure/attachment/12456388/ASF.LICENSE.NOT.GRANTED--v1-0003-CF-access-test-for-SimpleAuthority.txt","06/Oct/10 05:36;stuhood;v1-0004-minimize-object-creation.txt;https://issues.apache.org/jira/secure/attachment/12456478/v1-0004-minimize-object-creation.txt",,,,,,,,,,,4.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20197,,,Tue Oct 12 14:03:56 UTC 2010,,,,,,,,,,"0|i0g5xz:",92393,,,,,Normal,,,,,,,,,,,,,,,,,"29/Sep/10 17:30;stuhood;Targetting to 0.7.0: CF creation can be dangerous, and RAX needs to be able to lock it down.;;;","05/Oct/10 14:36;urandom;See attached.;;;","06/Oct/10 05:36;stuhood;* I think we need to minimize object creation in ClientState.hasColumnFamilyAccess: this was the intention of the member ArrayList<Object> in ClientState before, but I think it's more important now that it's called for every CF touch. Attaching an 0004 which we can consider in a different issue if you want.

Thanks for working on this Eric... much appreciated.;;;","06/Oct/10 15:20;urandom;committed.;;;","12/Oct/10 14:03;hudson;Integrated in Cassandra #563 (See [https://hudson.apache.org/hudson/job/Cassandra/563/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
enable/disable HH via JMX,CASSANDRA-1550,12475318,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,28/Sep/10 17:20,16/Apr/19 09:33,14/Jul/23 05:51,30/Sep/10 16:59,0.6.6,0.7 beta 3,Legacy/Tools,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Sep/10 16:16;jbellis;1550.txt;https://issues.apache.org/jira/secure/attachment/12456023/1550.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20196,,,Wed Mar 02 21:42:10 UTC 2011,,,,,,,,,,"0|i0g5x3:",92389,,brandon.williams,,brandon.williams,Low,,,,,,,,,,,,,,,,,"30/Sep/10 16:17;jbellis;(patch vs 0.6);;;","30/Sep/10 16:23;brandon.williams;+1;;;","30/Sep/10 16:59;jbellis;committed;;;","25/Feb/11 07:33;nar3ndra;Cassandra 0.7.2/trunk. The default constructor in StorageProxy is private. As a result the Operations cannot be executed from JMX. Hence, this change is not working.;;;","25/Feb/11 15:54;jbellis;the StorageProxy mbean is created once requests start arriving;;;","02/Mar/11 21:42;nar3ndra;Even though the load is on and read/writes happening, I don't see ""operations"" component on Jconsole. To clarify further, I see only Jconsole->MBeans->org.apache.cassandra.db.StorageProxy.Attributes. I don't see Jconsole->MBeans->org.apache.cassandra.db.StorageProxy.Operations. As a result I cannot operation like enable/disable HH. And all this while read/writes are happening on the node.

Am I missing something here?;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cli craps its pants and dies when 'gc_grace_seconds' is used in cf creation,CASSANDRA-1549,12475251,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,thepaul,thepaul,thepaul,27/Sep/10 22:52,16/Apr/19 09:33,14/Jul/23 05:51,28/Sep/10 01:40,0.7 beta 2,,Legacy/Tools,,0,,,,,,"{noformat}
trunk$ bin/cassandra-cli --host localhost
Connected to: ""Test Cluster"" on localhost/9160
Welcome to cassandra CLI.

Type 'help' or '?' for help. Type 'quit' or 'exit' to quit.
[default@unknown] use Keyspace1
Authenticated to keyspace: Keyspace1
[default@Keyspace1] create column family cfname with gc_grace_seconds=86400
Exception in thread ""main"" java.lang.AssertionError
        at org.apache.cassandra.cli.CliClient.executeAddColumnFamily(CliClient.java:817)
        at org.apache.cassandra.cli.CliClient.executeCLIStmt(CliClient.java:105)
        at org.apache.cassandra.cli.CliMain.processCLIStmt(CliMain.java:230)
        at org.apache.cassandra.cli.CliMain.main(CliMain.java:302)
{noformat}

it's just a missing ""break;"" statement in CliClient.java.",encountered on Debian Squeeze with Cassandra from HEAD (r1001931),,,,,,,,,,300,300,,0%,300,300,,,,,,,,,,,,,,"27/Sep/10 22:56;thepaul;0000-fix-cassandra-cli-gc_grace_seconds.patch;https://issues.apache.org/jira/secure/attachment/12455771/0000-fix-cassandra-cli-gc_grace_seconds.patch",,,,,,,,,,,,,,1.0,thepaul,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20195,,,Tue Sep 28 13:31:32 UTC 2010,,,,,,,,,,"0|i0g5wv:",92388,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"27/Sep/10 22:56;thepaul;dumbest patch evar;;;","28/Sep/10 01:40;jbellis;committed;;;","28/Sep/10 13:31;hudson;Integrated in Cassandra #549 (See [https://hudson.apache.org/hudson/job/Cassandra/549/])
    fix setting gc_grace_secondsvia CLI.
patch by Paul Cannon; reviewed by jbellis for CASSANDRA-1549
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"renaming a keyspace, then trying to use original name again makes errorations",CASSANDRA-1548,12475250,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,thepaul,thepaul,27/Sep/10 22:41,16/Apr/19 09:33,14/Jul/23 05:51,28/Sep/10 14:58,0.7 beta 2,,,,0,,,,,,"My test case does the following:

* Create a keyspace with at least one CF in it.
* Rename that keyspace
* Create a new keyspace with the same original name, containing a CF with the same name as earlier.

The second keyspace creation receives an error (although the keyspace does get created):

{{javax.management.InstanceAlreadyExistsException: org.apache.cassandra.db:type=ColumnFamilies,keyspace=keyspacename,columnfamily=cfname}}

After that point, trying to do almost anything with the new keyspace will generate the same error- even trying to drop it. This persists until cassandra itself is restarted.

One supposes that some JMX thing is lacking reregistration upon keyspace rename.","encountered on Debian squeeze, with cassandra from HEAD (r1001931).  effects can be seen with both Telephus and Pycassa as clients; probably any.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/10 07:08;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-ensure-that-a-table-unloads-CFS-instances-when-they-ar.txt;https://issues.apache.org/jira/secure/attachment/12455809/ASF.LICENSE.NOT.GRANTED--v1-0001-ensure-that-a-table-unloads-CFS-instances-when-they-ar.txt","27/Sep/10 22:45;thepaul;test_case_1548.py;https://issues.apache.org/jira/secure/attachment/12455770/test_case_1548.py",,,,,,,,,,,,,2.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20194,,,Wed Sep 29 12:47:31 UTC 2010,,,,,,,,,,"0|i0g5wn:",92387,,,,,Low,,,,,,,,,,,,,,,,,"27/Sep/10 22:45;thepaul;a test case which tickles this bug, using pycassa;;;","28/Sep/10 13:48;jbellis;+1;;;","28/Sep/10 14:58;gdusbabek;committed.;;;","29/Sep/10 12:47;hudson;Integrated in Cassandra #550 (See [https://hudson.apache.org/hudson/job/Cassandra/550/])
    ensure that a table unloads CFS instances when they are cleared. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1548
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
lost+found directories cause problems for cassandra,CASSANDRA-1547,12475245,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,mdennis,mdennis,mdennis,27/Sep/10 21:40,16/Apr/19 09:33,14/Jul/23 05:51,05/Oct/10 14:06,0.6.6,,,,0,,,,,,ext3/4 make lost+found directories at the root of the file system.  if you then point C* at the root of the FS (e.g. you have a mount point of /cassandra_data and/or /cassandra_commitlog) C* thinks lost+found is a keyspace and spews.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/10 16:13;mdennis;1547-cassandra-0.6.txt;https://issues.apache.org/jira/secure/attachment/12456293/1547-cassandra-0.6.txt",,,,,,,,,,,,,,1.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20193,,,Tue Oct 05 14:06:02 UTC 2010,,,,,,,,,,"0|i0g5wf:",92386,,gdusbabek,,gdusbabek,Low,,,,,,,,,,,,,,,,,"28/Sep/10 20:21;jbellis;didn't we used to have code to ignore files starting with . (mostly for the benefit of OS X)?;;;","28/Sep/10 20:24;gdusbabek;We still do, but I believe it is only inside the KS directories.;;;","04/Oct/10 14:53;gdusbabek;Matt, what error do you see.  To test, I created a lost+found dir inside my data dir and didn't have any problems.;;;","04/Oct/10 16:12;mdennis;I wasn't able to get a copy of the stack trace at the time, but it looks like it's just the commitlog directly and not the data directory too.

{code}
 INFO 10:32:24,958 JNA not found. Native methods will be disabled.
 INFO 10:32:25,152 DiskAccessMode 'auto' determined to be standard, indexAccessMode is standard
 INFO 10:32:25,607 Sampling index for /var/lib/cassandra/data/system/LocationInfo-1-Data.db
 INFO 10:32:25,639 Sampling index for /var/lib/cassandra/data/system/LocationInfo-2-Data.db
 INFO 10:32:25,702 Sampling index for /var/lib/cassandra/data/Keyspace1/Standard1-1-Data.db
 INFO 10:32:25,889 Replaying /var/lib/cassandra/commitlog/CommitLog-1286206104383.log, /var/lib/cassandra/commitlog/lost+found
java.io.FileNotFoundException: /var/lib/cassandra/commitlog/lost+found (Is a directory)
	at java.io.RandomAccessFile.open(Native Method)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:212)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:98)
	at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:144)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:186)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:173)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:114)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:214)
 INFO 10:32:25,913 Finished reading /var/lib/cassandra/commitlog/CommitLog-1286206104383.log
ERROR 10:32:25,916 Exception encountered during startup.
java.io.FileNotFoundException: /var/lib/cassandra/commitlog/lost+found (Is a directory)
	at java.io.RandomAccessFile.open(Native Method)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:212)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:98)
	at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:144)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:186)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:173)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:114)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:214)
Exception encountered during startup.
{code}
;;;","04/Oct/10 16:13;mdennis;it looks like 0.7 doesn't have this problem;;;","05/Oct/10 12:37;gdusbabek;We still want to avoid any hidden files.

EDIT: Duh.  And this patch does avoid them.;;;","05/Oct/10 12:39;gdusbabek;+1;;;","05/Oct/10 14:06;gdusbabek;+1 committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NullPointerException on startup after upgrade,CASSANDRA-1545,12475072,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,jhermes,bterm,bterm,24/Sep/10 19:33,16/Apr/19 09:33,14/Jul/23 05:51,27/Sep/10 22:38,0.7 beta 2,,,,0,,,,,,"Running a cluster on trunk of 0.7.0beta-2 and updated to tip of trunk. On startup of node got the following NullPointerException. Was using r997774 and switched to r1000247

ERROR [main] 2010-09-22 12:30:14,110 AbstractCassandraDaemon.java (line 216) Exception encountered during startup.
java.lang.NullPointerException
    at org.apache.cassandra.config.CFMetaData.inflate(CFMetaData.java:373)
    at org.apache.cassandra.config.KSMetaData.inflate(KSMetaData.java:118)
    at org.apache.cassandra.db.DefsTable.loadFromStorage(DefsTable.java:106)
    at org.apache.cassandra.config.DatabaseDescriptor.loadSchemas(DatabaseDescriptor.java:441)
    at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:109)
    at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:54)
    at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:199)
    at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:133)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Sep/10 21:21;jhermes;namechanges.txt;https://issues.apache.org/jira/secure/attachment/12455758/namechanges.txt","27/Sep/10 21:55;jhermes;nullprimitive.txt;https://issues.apache.org/jira/secure/attachment/12455763/nullprimitive.txt",,,,,,,,,,,,,2.0,jhermes,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20192,,,Tue Sep 28 13:31:33 UTC 2010,,,,,,,,,,"0|i0g5vz:",92384,,stuhood,,stuhood,Critical,,,,,,,,,,,,,,,,,"24/Sep/10 19:34;jhermes;Current working theory: looks like CASSANDRA-1437 rears it head, as it did in CASSANDRA-891.;;;","24/Sep/10 22:34;jbellis;At worst blowing away your schema definitions in the system keyspace and recreating them should fix.;;;","25/Sep/10 00:35;jhermes;Yeah, I'm not sure what's causing the NPE after looking at the config and doing some debug testing.
If this is seen from beta1-> or from 0.6.5->, then it would be a major bug, but from an arbitrary trunk to current trunk is not so important.;;;","25/Sep/10 00:40;jbellis;right, we've broken stuff at various revisions, and i don't think we can necessarily fix that retroactively.  as long as beta1 -> beta2 works i think we're fine.;;;","27/Sep/10 21:21;jhermes;Going from beta1 to trunk has several problems.
The first of which is that we stored the old classnames for o.a.c.locator and are now reading them out and failing to find the matching classes.
We have special case logic in DD to fix this, so it's being pushed into CFMetaData.inflate().

Now I can repro this bug from beta1 ->.;;;","27/Sep/10 21:55;jhermes;Was trying to jam a null into an int and not an Integer.
That was subtle.;;;","27/Sep/10 21:56;jhermes;After both patches, on-disk from beta1 is read safely by beta2.;;;","27/Sep/10 22:20;stuhood;+1
Works for me with the definitions in our default cassandra.yaml.;;;","27/Sep/10 22:38;jbellis;pulled the replace ops into KSMD.convertOldStrategyName and committed;;;","27/Sep/10 22:38;bterm;+1 
looks good;;;","28/Sep/10 13:31;hudson;Integrated in Cassandra #549 (See [https://hudson.apache.org/hudson/job/Cassandra/549/])
    fix reading beta1 schema from beta2.  patch by jhermes; reviewed by Stu Hood and jbellis for CASSANDRA-1545
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Compacted SSTables not properly removed,CASSANDRA-1544,12475051,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,stuhood,stuhood,24/Sep/10 15:58,16/Apr/19 09:33,14/Jul/23 05:51,26/Sep/10 22:27,0.7 beta 2,,,,0,,,,,,It looks like SSTableDeletingReference isn't doing its job... SSTable.conditionalDelete is never being called for sstables that have been marked compacted.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Sep/10 23:42;stuhood;1544-add-compacted-component.diff;https://issues.apache.org/jira/secure/attachment/12455581/1544-add-compacted-component.diff",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20191,,,Mon Sep 27 13:10:07 UTC 2010,,,,,,,,,,"0|i0g5vr:",92383,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"25/Sep/10 23:42;stuhood;Oopsie: the in-memory list of components didn't match the on-disk list.;;;","26/Sep/10 22:27;jbellis;committed;;;","27/Sep/10 13:10;hudson;Integrated in Cassandra #548 (See [https://hudson.apache.org/hudson/job/Cassandra/548/])
    add compaction marker to in-memory list of components.  patch by Stu Hood; reviewed by jbellis for CASSANDRA-1544
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Data directories not being properly scrubbed,CASSANDRA-1542,12475000,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,stuhood,stuhood,24/Sep/10 02:57,16/Apr/19 09:33,14/Jul/23 05:51,28/Sep/10 05:43,0.7 beta 2,,,,0,,,,,,"AbstractCassandraDaemon is trying to scrub data directories once the server has already been initialized (CASSANDRA-1477, r997490).

To reproduce, delete a single component of an SSTable and restart.",,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/10 05:39;gdusbabek;ASF.LICENSE.NOT.GRANTED--v2-0001-do-not-intialize-table-instances-when-loading-schema.-.txt;https://issues.apache.org/jira/secure/attachment/12455799/ASF.LICENSE.NOT.GRANTED--v2-0001-do-not-intialize-table-instances-when-loading-schema.-.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20189,,,Tue Sep 28 13:31:31 UTC 2010,,,,,,,,,,"0|i0g5vb:",92381,,stuhood,,stuhood,Low,,,,,,,,,,,,,,,,,"27/Sep/10 06:50;gdusbabek;The only problem I saw is that we were calling Table.open() for each table as part of DD.loadSchemas().  This made it impossible to scrub the data directories *after* we find out about the tables but *before* they are initialized.  We were already calling Table.open() in AbstractCassandraDaemon, so I decided to remove the call from DD.

That being said, stack traces in logs are still alarming for users.  Since the reason behind FNFE is well understood, I decided to modify ACD.setup() to catch it specifically and emit the error sans trace.  FWIW, CFS.scrubDataDirectories() does seem to be doing its job correctly.

This patch addresses those two items.

One question I have is if we should detect missing bloom filters and row indexes and proactively rebuild them.  I can't think of a case where this would happen in real life, so this would end up being a courtesy for people manually moving files around.  We probably shouldn't encourage this.;;;","27/Sep/10 15:55;jbellis;I don't know that ""corrupt sstable"" is really that much less scary than a stack trace. :);;;","27/Sep/10 18:45;stuhood;> One question I have is if we should detect missing bloom filters and row indexes and proactively rebuild them.
Might be a cool feature to add at some point: would probably be more useful for recovery of corrupted filters/indexes than for missing ones.

+1 Looks good.;;;","28/Sep/10 05:43;gdusbabek;Committed with a less intimidating error message. ;;;","28/Sep/10 13:31;hudson;Integrated in Cassandra #549 (See [https://hudson.apache.org/hudson/job/Cassandra/549/])
    do not intialize table instances when loading schema. complain less loudly when there is a missing sstable component. patch by gdusbabek, reviewed by stuhood. CASSANDRA-1542
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KEYS indexes recreated after first restart,CASSANDRA-1541,12474997,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,stuhood,stuhood,24/Sep/10 02:09,16/Apr/19 09:33,14/Jul/23 05:51,01/Oct/10 17:56,0.7 beta 3,,,,0,,,,,,"I made sure I waited at least {{commitlog_sync_period_in_ms}}, but the {{SystemTable.isIndexBuilt}} flag doesn't appear to be sticking after a call to system_add_column_family (via CASSANDRA-1531). During the first restart after creation, the index is recreated, logging: ""Creating index"" and ""Index _ complete"" again. The second restart works as it should.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Oct/10 16:05;jbellis;1541.txt;https://issues.apache.org/jira/secure/attachment/12456128/1541.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20188,,,Sat Oct 02 12:56:26 UTC 2010,,,,,,,,,,"0|i0g5v3:",92380,,stuhood,,stuhood,Normal,,,,,,,,,,,,,,,,,"01/Oct/10 16:05;jbellis;table.open is called before commitlog replay.  patch adds flush to INDEX_CF in setIndexBuilt so the flag is visible before log replay next restart.;;;","01/Oct/10 17:52;stuhood;+1
(required a bit of manual rebasing, but the spirit is correct).;;;","01/Oct/10 17:56;jbellis;rebased & committed;;;","02/Oct/10 12:56;hudson;Integrated in Cassandra #553 (See [https://hudson.apache.org/hudson/job/Cassandra/553/])
    flush index built flag so we can read it before log replay
patch by jbellis; reviewed by Stu Hood for CASSANDRA-1541
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cfstats is broken,CASSANDRA-1540,12474972,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,23/Sep/10 19:36,16/Apr/19 09:33,14/Jul/23 05:51,23/Sep/10 21:23,0.7 beta 2,,,,0,,,,,,"There appears to be a problem reading the cache stats:

bin/nodetool -h cassandra-6 cfstats
Keyspace: org.apache.cassandra.db.Table@620a3d3b
        Read Count: 9
        Read Latency: 2.563222222222222 ms.
        Write Count: 11
        Write Latency: 0.1572727272727273 ms.
        Pending Tasks: 0
                Column Family: LocationInfo
                SSTable count: 1
                Space used (live): 4886
                Space used (total): 4886
                Memtable Columns Count: 6
                Memtable Data Size: 179
                Memtable Switch Count: 1
                Read Count: 4
                Read Latency: 5.369 ms.
                Write Count: 8
                Write Latency: 0.210 ms.
                Pending Tasks: 0
Exception in thread ""main"" java.lang.reflect.UndeclaredThrowableException
        at $Proxy5.getCapacity(Unknown Source)
        at org.apache.cassandra.tools.NodeCmd.printColumnFamilyStats(NodeCmd.java:326)
        at org.apache.cassandra.tools.NodeCmd.main(NodeCmd.java:439)
Caused by: javax.management.InstanceNotFoundException: org.apache.cassandra.db:type=Caches,keyspace=org.apache.cassandra.db.Table@620a3d3b,cache=LocationInfoKeyCache
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1118)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:679)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:672)
        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1426)
        at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:90)
        at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1284)
        at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1382)
        at javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:619)
        at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:616)
        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:322)
        at sun.rmi.transport.Transport$1.run(Transport.java:177)
        at java.security.AccessController.doPrivileged(Native Method)
        at sun.rmi.transport.Transport.serviceCall(Transport.java:173)
        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:553)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:808)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:667)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
        at sun.rmi.transport.StreamRemoteCall.exceptionReceivedFromServer(StreamRemoteCall.java:273)
        at sun.rmi.transport.StreamRemoteCall.executeCall(StreamRemoteCall.java:251)
        at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:160)
        at com.sun.jmx.remote.internal.PRef.invoke(Unknown Source)
        at javax.management.remote.rmi.RMIConnectionImpl_Stub.getAttribute(Unknown Source)
        at javax.management.remote.rmi.RMIConnector$RemoteMBeanServerConnection.getAttribute(RMIConnector.java:885)
        at javax.management.MBeanServerInvocationHandler.invoke(MBeanServerInvocationHandler.java:280)
        ... 3 more
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Sep/10 20:34;brandon.williams;1540.txt;https://issues.apache.org/jira/secure/attachment/12455412/1540.txt",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20187,,,Fri Sep 24 12:47:04 UTC 2010,,,,,,,,,,"0|i0g5uv:",92379,,,,,Normal,,,,,,,,,,,,,,,,,"23/Sep/10 20:34;brandon.williams;Patch to register the mbean name correctly.;;;","23/Sep/10 21:17;jbellis;+1;;;","23/Sep/10 21:23;brandon.williams;Committed.;;;","24/Sep/10 12:47;hudson;Integrated in Cassandra #545 (See [https://hudson.apache.org/hudson/job/Cassandra/545/])
    Register CFS Mbean with the correct keyspace name.  Patch by brandonwilliams, reviewed by jbellis for CASSANDRA-1540
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ExpiringColumn wrongly inherits Column.getMarkedForDeleteAt,CASSANDRA-1539,12474925,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,slebresne,slebresne,slebresne,23/Sep/10 12:25,16/Apr/19 09:33,14/Jul/23 05:51,24/Sep/10 15:30,0.7 beta 2,,,,0,,,,,,"An ExpiringColumn could be 'markedAsDeleted', but Column.getMarkedForDeleteAt() always throw an exception.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Sep/10 12:26;slebresne;0001-Add-correct-getMarkedForDeleteAt-method-to-ExpiringC.patch;https://issues.apache.org/jira/secure/attachment/12455374/0001-Add-correct-getMarkedForDeleteAt-method-to-ExpiringC.patch","24/Sep/10 08:42;slebresne;0001-v2-Add-correct-getMarkedForDeleteAt-method-to-ExpiringC.patch;https://issues.apache.org/jira/secure/attachment/12455473/0001-v2-Add-correct-getMarkedForDeleteAt-method-to-ExpiringC.patch",,,,,,,,,,,,,2.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20186,,,Sat Sep 25 12:47:14 UTC 2010,,,,,,,,,,"0|i0g5un:",92378,,jbellis,,jbellis,Critical,,,,,,,,,,,,,,,,,"23/Sep/10 16:22;jbellis;is this something we can add a unit test for?;;;","24/Sep/10 08:42;slebresne;v2 adds a unit test (with a 2 seconds sleep :( );;;","24/Sep/10 15:30;jbellis;committed;;;","25/Sep/10 12:47;hudson;Integrated in Cassandra #546 (See [https://hudson.apache.org/hudson/job/Cassandra/546/])
    treat expired columns as deleted.  patch by Sylvain Lebresne; reviewed by jbellis for CASSANDRA-1539
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0.7 on Windows,CASSANDRA-1538,12474921,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,vloncar,jbellis,jbellis,23/Sep/10 11:03,16/Apr/19 09:33,14/Jul/23 05:51,11/Oct/10 14:20,0.7 beta 3,,Packaging,,0,,,,,,"bat file needs to be told to look for log4j-server.properties

anything else?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/10 09:52;vloncar;add-log4j-path-to-bat.patch;https://issues.apache.org/jira/secure/attachment/12455824/add-log4j-path-to-bat.patch",,,,,,,,,,,,,,1.0,vloncar,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20185,,,Wed Sep 29 12:47:30 UTC 2010,,,,,,,,,,"0|i0g5uf:",92377,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"28/Sep/10 09:52;vloncar;Here is a trivial patch to add log4j configuration to cassandra.bat. Any chance of this getting in before 0.7.0-beta2 so the few of us on windows don't have to think about it anymore?;;;","28/Sep/10 14:54;jbellis;committed;;;","29/Sep/10 12:47;hudson;Integrated in Cassandra #550 (See [https://hudson.apache.org/hudson/job/Cassandra/550/])
    point log4j to log4j-server.properties in cassandra.bat.  patch by Vladimir Loncar; reviewed by jbellis for CASSANDRA-1538
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Detect use of secondary indexes with TTL'd columns,CASSANDRA-1536,12474897,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,stuhood,stuhood,23/Sep/10 02:55,16/Apr/19 09:33,14/Jul/23 05:51,28/Sep/10 04:26,0.7 beta 2,,Feature/2i Index,,0,,,,,,"We don't currently make any provisions for using TTL'd columns with secondary indexes. A reasonable temporary solution would be to fail inserts of TTL'd entries for indexed columns.

A longer term solution might be to record/detect the presence of expiring columns for an expression, and use that information to require post filtering in CFS.scan.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Sep/10 02:48;stuhood;0001-Use-TTL-d-index-entries-for-TTL-d-values.patch;https://issues.apache.org/jira/secure/attachment/12455792/0001-Use-TTL-d-index-entries-for-TTL-d-values.patch",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20184,,,Tue Sep 28 13:31:32 UTC 2010,,,,,,,,,,"0|i0g5tz:",92375,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"23/Sep/10 21:42;stuhood;In KEYS indexes, the entry could be made to the index with a TTL as well, and KEYS_BITMAP indexes require post filtering anyway, so this might actually be an easy fix.;;;","28/Sep/10 02:48;stuhood;Patch to use the TTL from an indexed value for its index entry.;;;","28/Sep/10 04:26;jbellis;committed;;;","28/Sep/10 13:31;hudson;Integrated in Cassandra #549 (See [https://hudson.apache.org/hudson/job/Cassandra/549/])
    support TTL'd index values.
patch by Stu Hood; reviewed by jbellis for CASSANDRA-1536
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Repair doesn't do anything when a CF isn't specified,CASSANDRA-1535,12474874,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,22/Sep/10 21:44,16/Apr/19 09:33,14/Jul/23 05:51,23/Sep/10 04:14,0.7 beta 2,,,,0,,,,,,"Invoking repair on a node does not work.  With RF > 1 all I get is:

INFO 15:04:59,987 Waiting for repair requests to: []

And nothing happens.",,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Sep/10 01:25;brandon.williams;1535.txt;https://issues.apache.org/jira/secure/attachment/12455338/1535.txt",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20183,,,Thu Sep 23 12:47:41 UTC 2010,,,,,,,,,,"0|i0g5tr:",92374,,,,,Normal,,,,,,,,,,,,,,,,,"23/Sep/10 01:25;brandon.williams;The simplest thing to do is repair all CFs when only a KS is specified.;;;","23/Sep/10 02:18;stuhood;+1
Thanks Brandon!;;;","23/Sep/10 04:14;brandon.williams;Committed.;;;","23/Sep/10 12:47;hudson;Integrated in Cassandra #544 (See [https://hudson.apache.org/hudson/job/Cassandra/544/])
    Repair should repair all CFs when no CFs are specified.  Patch by brandonwilliams reviewed by Stu Hood for CASSANDRA-1535
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
errors reading while bootstrapping,CASSANDRA-1534,12474870,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,brandon.williams,brandon.williams,22/Sep/10 20:56,16/Apr/19 09:33,14/Jul/23 05:51,23/Sep/10 19:28,0.7 beta 2,,,,0,,,,,,"I loaded a 4 node cluster with 1M rows from stress.py, decommissioned a node, and then began bootstrapping it while performing constant reads against the others with stress.py.  After sleeping for 90s, the bootstrapping node started throwing many errors like this:

ERROR 16:51:48,667 Fatal exception in thread Thread[READ_STAGE:1270,5,main]
java.lang.RuntimeException: Cannot service reads while bootstrapping!
        at org.apache.cassandra.db.ReadVerbHandler.doVerb(ReadVerbHandler.java:67)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)

And I began receiving timeout errors with stress.py.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Sep/10 16:21;jbellis;1534.txt;https://issues.apache.org/jira/secure/attachment/12455385/1534.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20182,,,Fri Sep 24 12:47:05 UTC 2010,,,,,,,,,,"0|i0g5tj:",92373,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"22/Sep/10 20:58;jbellis;has bootstrap-after-decom ever worked?  i think we leave data in the system table that's going to confuse things;;;","22/Sep/10 21:06;brandon.williams;I rm'd everything after decom.;;;","22/Sep/10 21:21;jbellis;does bs against a vanilla no-decom cluster work?;;;","22/Sep/10 21:33;brandon.williams;No, same problem.;;;","23/Sep/10 16:21;jbellis;patch attached that makes new node properly announce its bootstrap status.;;;","23/Sep/10 18:46;brandon.williams;+1;;;","23/Sep/10 19:28;jbellis;committed;;;","24/Sep/10 12:47;hudson;Integrated in Cassandra #545 (See [https://hudson.apache.org/hudson/job/Cassandra/545/])
    fix setting bootstrap status on startup.
patch by jbellis; reviewed by brandonwilliams for CASSANDRA-1534
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
word count contrib module broken as a result of removing Clock interface,CASSANDRA-1529,12474767,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jeromatron,jeromatron,jeromatron,21/Sep/10 22:50,16/Apr/19 09:33,14/Jul/23 05:51,22/Sep/10 02:05,0.7 beta 2,,,,0,,,,,,Just needs a quick patch.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Sep/10 22:51;jeromatron;0001-Remove-clock-usage.patch;https://issues.apache.org/jira/secure/attachment/12455205/0001-Remove-clock-usage.patch",,,,,,,,,,,,,,1.0,jeromatron,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20181,,,Wed Sep 22 02:05:32 UTC 2010,,,,,,,,,,"0|i0g5sf:",92368,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"22/Sep/10 02:05;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cassandra holds a socket in CLOSE_WAIT on the storage port,CASSANDRA-1528,12474752,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,brandon.williams,brandon.williams,brandon.williams,21/Sep/10 20:18,16/Apr/19 09:33,14/Jul/23 05:51,21/Sep/10 21:17,0.6.6,0.7 beta 2,,,0,,,,,,"To repro: telnet to 7000, disconnect.  You have a socket in CLOSE_WAIT that will stay there until the server is restarted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Sep/10 20:54;brandon.williams;1528.txt;https://issues.apache.org/jira/secure/attachment/12455190/1528.txt",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20180,,,Tue Sep 21 21:17:27 UTC 2010,,,,,,,,,,"0|i0g5s7:",92367,,,,,Low,,,,,,,,,,,,,,,,,"21/Sep/10 20:51;brandon.williams;Apparently, we should actually close sockets when we say we do.  Patch to do so.;;;","21/Sep/10 21:12;zznate;Verified before and after via telnet. Patch applies clean. ;;;","21/Sep/10 21:17;brandon.williams;Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ensure compaction thresholds are sane,CASSANDRA-1527,12474746,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jhermes,jbellis,jbellis,21/Sep/10 19:45,16/Apr/19 09:33,14/Jul/23 05:51,27/Sep/10 22:10,0.7 beta 2,,Legacy/CQL,,0,,,,,,"make sure min <= max and neither is negative.

also make sure that min=max=0 works (this is ""no compaction"")",,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Sep/10 21:07;jhermes;1527-unoopsed.txt;https://issues.apache.org/jira/secure/attachment/12455751/1527-unoopsed.txt","27/Sep/10 20:29;jhermes;1527.txt;https://issues.apache.org/jira/secure/attachment/12455748/1527.txt",,,,,,,,,,,,,2.0,jhermes,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20179,,,Tue Sep 28 13:31:31 UTC 2010,,,,,,,,,,"0|i0g5rb:",92363,,,,,Low,,,,,,,,,,,,,,,,,"22/Sep/10 22:33;jhermes;Because there are now too many ways to invalidate a metadata, I'm going to enumerate them.

1) Creation:
- First and foremost, catching these boundaries on the constructor fixes the case where the config is invalid. The config is read and DD.readTablesFromYaml() creates a CFMD for each CF.
- This also catches 'schematool import', which hits SS.loadSchemasFromYaml() which hits DD.readTablesFromYaml() in the same way.
- This also catches creation of an avro CfDef and loading it (generally, this is because we serialized it incorrectly). Calling CFMD.inflate(avro cfdef) will hit the constructor as well.

2) Modification:
- Throwing a runtime exception on the JMX CFS.setMin/MaxCompactionThreshold() methods will suffice to stop this invalidation point. This could be done a bit more kindly.
- Catching these boundaries on CFMD.apply(avro/thrift def) limits the case where someone makes a def and then pushes it in. This is ALSO caught by the constructor.

Now, bad things. A constructor throwing a ConfigurationException is not the nicest thing in the world. These would be internal errors, as thrift/avro aren't always involved.;;;","24/Sep/10 21:19;jhermes;Can't deal with the constructor throwing an exception, it's just too ugly.

Current patch:
# Adding validation to readTablesFromYaml()/loadSchemas() is pretty, and catches the erroneous config. This is necessarily different than the same validation for add/update API calls, as this is parsed and deflated immediately.
# Explode on invalid JMX poking. To counter this, made disableAutoCompaction() pokeable (previously internal). This should help avoid the case where one goes to disable via JMX, sets max = 0 < min, and kills the node.
# Leave inflate alone. If we deflate it incorrectly, then 1) was wrong.
# CFMetaData has a validateMinMaxCTs() for both avro and thrift. When updating a CF, the method is called in CFMetaData.apply(). When adding a CF, the method is called in CassandraServer.convertToCFMetaData(). (This is duplicated based on protocol because there is no interface for ""a CfDef"" to deal with both avro and thrift at the same time, much in same way all the other methods in CFMetaData are duplicated.)
# Check that apply validates correctly in DefsTest.;;;","24/Sep/10 21:33;jhermes;Now, for min=max=0, estimating the compactions _will currently_ explode if min == max.

Estimated compactions are the sum of all (1 + size_i / thresholdrange) for i in SSTables with size > min. What do we want the estimated compactions to be when min == max (or thresholdrange=0)?
Furthermore, do we want to be estimating compactions when minor compactions are disabled?;;;","27/Sep/10 20:06;jbellis;bq. Estimated compactions are the sum of all (1 + size_i / thresholdrange) for i in SSTables with size > min

that looks buggy to me.  doesn't estimate of

                n += Math.ceil((double)sstables.size() / maxct);

make more sense?

bq. do we want to be estimating compactions when minor compactions are disabled

no;;;","27/Sep/10 20:29;jhermes;min=max is fine, min=0 || max=0 is fine.;;;","27/Sep/10 21:07;jhermes;Patch error caused loss of code. That was unfortunate.;;;","27/Sep/10 21:09;jbellis;can you add unit or system tests demonstrating rejection of invalid configurations?;;;","27/Sep/10 21:12;jbellis;nvm, I see it in DefsTest.

what is the commented-out code for in DD?  is that a todo that should be cleaned up?;;;","27/Sep/10 21:24;jhermes;Oh, missed one!
The comments should be removed, the rest is valid.;;;","27/Sep/10 22:10;jbellis;committed;;;","28/Sep/10 13:31;hudson;Integrated in Cassandra #549 (See [https://hudson.apache.org/hudson/job/Cassandra/549/])
    sanity checks for compaction thresholds.  
patch by jhermes; reviewed by jbellis for CASSANDRA-1527
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Methods removed from FileUtils break CassandraServiceDataCleaner in contrib/javautils,CASSANDRA-1522,12474614,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,zznate,zznate,zznate,20/Sep/10 17:14,16/Apr/19 09:33,14/Jul/23 05:51,20/Sep/10 18:47,0.7 beta 2,,,,0,,,,,,CassandraServiceDataCleaner relied on methods in FileUtils that were removed in revision: 998464,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Sep/10 17:15;zznate;1522.patch;https://issues.apache.org/jira/secure/attachment/12455059/1522.patch",,,,,,,,,,,,,,1.0,zznate,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20178,,,Mon Sep 20 18:47:29 UTC 2010,,,,,,,,,,"0|i0g5kv:",92334,,,,,Normal,,,,,,,,,,,,,,,,,"20/Sep/10 17:15;zznate;re-adds removed methods, leaving other changes internal intact;;;","20/Sep/10 18:47;brandon.williams;+1, Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stress.py's multiget option sends increasingly inefficient queries as more test data is inserted,CASSANDRA-1520,12474520,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,brandon.williams,zznate,zznate,19/Sep/10 05:58,16/Apr/19 09:33,14/Jul/23 05:51,20/Sep/10 18:38,0.7 beta 2,,,,0,,,,,,"MultiGetter's key list sizes should be broken up better for more efficient queries. Setting an initial value that breaks up the key list into N sub lists (where N is the number of threads) yielded more efficient queries. (The choice of thread count here was a stop-gap for demonstration purposes. End result should probably be chunk-size config option with a sane default).

Pre patch:
---
python stress.py -o multiget -t 25 -n 250000 -c 5
total,interval_op_rate,interval_key_rate,avg_latency,elapsed_time
6,0,6000,8.6109764576,10
10,0,4000,18.6666852832,20
17,0,7000,27.4705835751,30
23,0,6000,36.6091703971,41
25,0,2000,41.8415510654,42

Post patch:
---
python mstress.py -o multiget -t 25 -n 250000 -c 5
total,interval_op_rate,interval_key_rate,avg_latency,elapsed_time
172,17,6880,1.44215503127,10
314,14,5680,1.8667214538,20
466,15,6080,1.69888155084,31
624,15,6320,1.55442555947,41
625,0,40,0.0914790630341,41",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/10 22:21;brandon.williams;1520-v2.txt;https://issues.apache.org/jira/secure/attachment/12454999/1520-v2.txt","19/Sep/10 05:59;zznate;1520.patch;https://issues.apache.org/jira/secure/attachment/12454965/1520.patch",,,,,,,,,,,,,2.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20177,,,Mon Sep 20 18:38:29 UTC 2010,,,,,,,,,,"0|i0g5kf:",92332,,brandon.williams,,brandon.williams,Low,,,,,,,,,,,,,,,,,"19/Sep/10 07:28;zznate;Moved priority down to minor. ;;;","19/Sep/10 21:01;brandon.williams;Committed as is, since multiget was fairly poor.  Number of threads as a stopgap probably isn't too bad, but ultimately I think providing a config option for the number of keys is best, so the user knows exactly what's going on.;;;","19/Sep/10 22:17;brandon.williams;Updated patch to reuse the rangecount variable so we don't have to use another option, and also apply the logic to supercolumns.;;;","20/Sep/10 14:37;hudson;Integrated in Cassandra #541 (See [https://hudson.apache.org/hudson/job/Cassandra/541/])
    Optimize multiget in stress.py.  Patch by Nate McCall, reviewed by brandonwilliams for CASSANDRA-1520
;;;","20/Sep/10 18:29;zznate;1520v2 looks good as well. new -g usage works well to find the slice sweet spot. 
For the record: had to apply patch to file previous to commit though, thus some merge handjiving will be needed.;;;","20/Sep/10 18:38;brandon.williams;Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BufferUnderflowExceptions,CASSANDRA-1513,12474434,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,wr0ngway,wr0ngway,17/Sep/10 19:48,16/Apr/19 09:33,14/Jul/23 05:51,28/Dec/10 15:49,,,,,0,,,,,,"Seeing a number of these in my log when running a trunk build from 9/11/2010
No idea how to duplicate it, hopefully you can make sense of it from the stack trace

ERROR [MUTATION_STAGE:19] 2010-09-14 02:24:50,704 DebuggableThreadPoolExecutor.
java (line 102) Error in ThreadPoolExecutorjava.nio.BufferUnderflowException
        at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:145)
        at java.nio.ByteBuffer.get(ByteBuffer.java:692)
        at org.apache.cassandra.db.RowMutationVerbHandler.doVerb(RowMutationVerbHandler.java:62)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:50)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)

","Ubuntu 10.04.1, 1.6.0_18-b18",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20175,,,Tue Dec 28 15:49:45 UTC 2010,,,,,,,,,,"0|i0g5iv:",92325,,,,,Normal,,,,,,,,,,,,,,,,,"17/Sep/10 20:09;wr0ngway;Actually, I can get these pretty regularly (in my cluster anyway) - quite a few happen on some nodes when I restart a specific node
;;;","28/Dec/10 15:49;jbellis;believe this was one of our thrift 0.5 upgrade bugs.  should be fixed in latest 0.7 rc;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra will replay the last mutation in a commitlog when it shouldn't,CASSANDRA-1512,12474406,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,17/Sep/10 17:15,16/Apr/19 09:33,14/Jul/23 05:51,20/Sep/10 22:17,0.6.6,0.7 beta 2,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Sep/10 17:17;jbellis;1512.txt;https://issues.apache.org/jira/secure/attachment/12454868/1512.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20174,,,Mon Sep 20 22:17:34 UTC 2010,,,,,,,,,,"0|i0g5in:",92324,,gdusbabek,,gdusbabek,Low,,,,,,,,,,,,,,,,,"17/Sep/10 17:17;jbellis;patch against trunk;;;","17/Sep/10 17:19;jbellis;(also removes CommitLogTest.testCleanup b/c it's useless);;;","18/Sep/10 15:52;jbellis;Re testCleanup, it's useless because counting the commitlog segments is a very fragile thing to test.  Every time we start doing more with system tables it breaks.  RecoveryManager[23]Test are more robust.;;;","20/Sep/10 13:02;gdusbabek;+1. ;;;","20/Sep/10 22:17;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CassandraServiceDataCleaner doesn't remove subdirectories properly,CASSANDRA-1509,12474242,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,btoddb,btoddb,btoddb,16/Sep/10 03:05,16/Apr/19 09:33,14/Jul/23 05:51,18/Sep/10 10:38,0.7 beta 2,,,,0,,,,,,"CassandraServiceDataCleaner.cleanDir assumes all files in the directory are normal files, not directories.  Suggested fix is to change FileUtils.delete(dirFile.listFiles()) to FileUtils.deleteRecursive(f) to remove recursively which will delete all data files.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Sep/10 03:06;btoddb;patch-delete-recursive.txt;https://issues.apache.org/jira/secure/attachment/12454736/patch-delete-recursive.txt",,,,,,,,,,,,,,1.0,btoddb,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20172,,,Sat Sep 18 12:48:21 UTC 2010,,,,,,,,,,"0|i0g5hz:",92321,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"16/Sep/10 03:06;btoddb;patch to change to a recursive delete which will remove directories and all their files;;;","18/Sep/10 10:38;jbellis;committed;;;","18/Sep/10 12:48;hudson;Integrated in Cassandra #539 (See [https://hudson.apache.org/hudson/job/Cassandra/539/])
    make contrib CassandraServiceDataCleaner recursive.  patch by B. Todd Burruss; reviewed by jbellis for CASSANDRA-1509
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
only attempt to set size on Linux (for portability),CASSANDRA-1508,12474213,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,scode,scode,scode,15/Sep/10 20:53,16/Apr/19 09:33,14/Jul/23 05:51,16/Sep/10 13:43,0.7 beta 2,,Packaging,,0,,,,,,"-Xss128k causes the JVM to refuse to start or crash on 64 bit FreeBSD 8 (this goes for two wildly differing openjdk 1.6:es and for the current openjdk7 branch). Attaching patch to only pass -Xss on Linux.

The motivation here is that out-of-the-box behavior is important for first-comers, and for people in production on a non-Linux platform where -Xss128k would work are presumably committed enough that they can tweak this themselves.
",,scode,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/10 20:54;scode;trunk-1508.txt;https://issues.apache.org/jira/secure/attachment/12454698/trunk-1508.txt",,,,,,,,,,,,,,1.0,scode,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20171,,,Fri Sep 17 13:55:35 UTC 2010,,,,,,,,,,"0|i0g5hr:",92320,,brandon.williams,,brandon.williams,Low,,,,,,,,,,,,,,,,,"16/Sep/10 13:43;brandon.williams;Committed.  Out of curiosity, was it crashing due the the recursion limit being exceeded?;;;","16/Sep/10 14:45;scode;To be honest I have not investigated (due to the nature of the crash there's no crashdump or anything to investigate stack trace). I believe it's a general issue with the JDK on the platform. Even just ""java -Xss128k"" (without running anything but trying to elicit help) crashes.

My suspicion is that it is simply something general having more to do with a non-default stack size, or some arbitrary minimum limit, rather than actually eating the stack in Java code. But it's speculation at this point.
;;;","17/Sep/10 13:55;hudson;Integrated in Cassandra #538 (See [https://hudson.apache.org/hudson/job/Cassandra/538/])
    only attempt to set thread stack size on Linux.  Patch by Peter Schuller, reviewed by brandonwilliams for CASSANDRA-1508
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
make adaptive heap size calculation portable,CASSANDRA-1507,12474211,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,scode,scode,scode,15/Sep/10 20:27,16/Apr/19 09:33,14/Jul/23 05:51,15/Sep/10 20:37,0.7 beta 2,,,,0,,,,,,"The adaptive heap size calculation is dependent on the 'free' tool which is typically available on Linux machines (GNU toolset) but not others.

I'm attaching a patch which makes FreeBSD specifically supported as well as falling back to static 1024m default if the operating system is unrecognized.
",,scode,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/10 20:35;scode;trunk-1507-v2.txt;https://issues.apache.org/jira/secure/attachment/12454695/trunk-1507-v2.txt","15/Sep/10 20:29;scode;trunk-1507.txt;https://issues.apache.org/jira/secure/attachment/12454694/trunk-1507.txt",,,,,,,,,,,,,2.0,scode,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20170,,,Fri Sep 17 13:55:35 UTC 2010,,,,,,,,,,"0|i0g5hj:",92319,,,,,Low,,,,,,,,,,,,,,,,,"15/Sep/10 20:35;scode;Slightly modified patch. I accidentally included the version where FreeBSD was mis-spelled (I used it for testing the fallback case).;;;","15/Sep/10 20:37;brandon.williams;+1, committed.  Thanks!;;;","17/Sep/10 13:55;hudson;Integrated in Cassandra #538 (See [https://hudson.apache.org/hudson/job/Cassandra/538/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AssertionError in MessagingService.receive for READ_REPAIR verb,CASSANDRA-1493,12473820,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,johanoskarsson,johanoskarsson,johanoskarsson,10/Sep/10 16:11,16/Apr/19 09:33,14/Jul/23 05:51,12/Sep/10 13:58,0.7 beta 2,,,,0,,,,,,"Read repair messages are causing an assertion error in MessagingService. Looks like the enum introduced in CASSANDRA-1465 is missing a verb?

Added two lines of debug output, so lines are a bit off:
DEBUG [pool-1-thread-1] 2010-09-10 15:39:23,555 MessagingService.java (line 373) Verb: READ_REPAIR
DEBUG [pool-1-thread-1] 2010-09-10 15:39:23,555 MessagingService.java (line 374) MessageType: null
ERROR [pool-1-thread-1] 2010-09-10 15:39:23,555 Cassandra.java (line 1744) Internal error processing get
java.lang.AssertionError
        at org.apache.cassandra.net.MessagingService.receive(MessagingService.java:376)
        at org.apache.cassandra.net.MessagingService.sendOneWay(MessagingService.java:285)
        at org.apache.cassandra.service.ReadResponseResolver.maybeScheduleRepairs(ReadResponseResolver.java:163)
        at org.apache.cassandra.service.ReadResponseResolver.resolve(ReadResponseResolver.java:116)
        at org.apache.cassandra.service.ReadResponseResolver.resolve(ReadResponseResolver.java:43)
        at org.apache.cassandra.service.QuorumResponseHandler.get(QuorumResponseHandler.java:89)
        at org.apache.cassandra.service.StorageProxy.strongRead(StorageProxy.java:430)
        at org.apache.cassandra.service.StorageProxy.readProtocol(StorageProxy.java:266)
        at org.apache.cassandra.thrift.CassandraServer.readColumnFamily(CassandraServer.java:113)
        at org.apache.cassandra.thrift.CassandraServer.get(CassandraServer.java:317)
        at org.apache.cassandra.thrift.Cassandra$Processor$get.process(Cassandra.java:1734)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:1634)
        at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Sep/10 21:53;johanoskarsson;CASSANDRA-1493.patch;https://issues.apache.org/jira/secure/attachment/12454338/CASSANDRA-1493.patch",,,,,,,,,,,,,,1.0,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20165,,,Sun Sep 12 13:58:16 UTC 2010,,,,,,,,,,"0|i0g5ef:",92305,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"10/Sep/10 21:53;johanoskarsson;Adding the read repair verb seems to have fixed it.;;;","10/Sep/10 23:48;jbellis;+1;;;","12/Sep/10 13:58;johanoskarsson;Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Upgrade from 0.6.3 to 0.6.5, exception when replay commitlog",CASSANDRA-1492,12473815,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,apache.zli,apache.zli,10/Sep/10 15:28,16/Apr/19 09:33,14/Jul/23 05:51,13/Sep/10 13:30,0.6.6,,,,0,,,,,,"When start cassandra 0.6.5 with commitlog of 0.6.3, got exception when replay the commitlog. 

ERROR 15:14:16,174 Exception encountered during startup.
org.apache.cassandra.db.marshal.MarshalException: invalid UTF8 bytes [-84, 16, 10, -105]
	at org.apache.cassandra.db.marshal.UTF8Type.getString(UTF8Type.java:43)
	at org.apache.cassandra.db.Column.getString(Column.java:215)
	at org.apache.cassandra.db.marshal.AbstractType.getColumnsString(AbstractType.java:85)
	at org.apache.cassandra.db.ColumnFamily.toString(ColumnFamily.java:334)
	at org.apache.commons.lang.ObjectUtils.toString(ObjectUtils.java:241)
	at org.apache.commons.lang.StringUtils.join(StringUtils.java:3073)
	at org.apache.commons.lang.StringUtils.join(StringUtils.java:3133)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:241)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:173)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:114)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:214)
","Linux, jdk 1.6",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Sep/10 04:04;jbellis;1492.txt;https://issues.apache.org/jira/secure/attachment/12454356/1492.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20164,,,Mon Sep 13 13:30:27 UTC 2010,,,,,,,,,,"0|i0g5e7:",92304,,gdusbabek,,gdusbabek,Normal,,,,,,,,,,,,,,,,,"10/Sep/10 15:49;gdusbabek;Commit logs are typically not compatible across minor versions.  You should drain your node before upgrading and restarting it.;;;","10/Sep/10 16:38;apache.zli;Tested again. Drained 0.6.3 commitlog with Cassandra 0.6.3, then start Cassandra 0.6.5 and works. 
Then stop Cassandra 0.6.5 and start Cassandra 0.6.5 again. Same exception. 

I shouldn't remove all data file and recreate a new node with minor version upgrade. Right?

;;;","10/Sep/10 19:27;jbellis;commitlog is supposed to be compatible w/in minor versions.  this looks like one of those ""something is declared UTF8Type, that should be bytestype"" things.  STATUS_CF is UTF8Type in current 0.6, is that a bug?;;;","10/Sep/10 20:52;gdusbabek;Probably. It's a BytesType in trunk.;;;","11/Sep/10 04:04;jbellis;patch to switch to bytestype.

agreed that if you have this in your commitlog already, deleting the commitlog file is the best fix.;;;","13/Sep/10 12:46;gdusbabek;+1;;;","13/Sep/10 13:30;jbellis;committed.

(blowing away the CL isn't a permanent fix if you have a node in your cluster w/ a non-UTF8 IP.  you'll probably need to apply this patch.);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in calculating QUORUM,CASSANDRA-1487,12473700,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jigneshdhruv,jigneshdhruv,jigneshdhruv,09/Sep/10 16:34,16/Apr/19 09:33,14/Jul/23 05:51,11/Sep/10 01:00,0.7 beta 2,,,,0,,,,,,"Hello,

It seems that there is a bug in calculating QUORUM in src/java/org/apache/cassandra/service/QuorumResponseHandler.java

Currently the QUORUM formula in place will return correct QUORUM if replication factor <= 3. However if you have a Replication Factor > 3, it will return incorrect result.

-----------------------
--- src/java/org/apache/cassandra/service/QuorumResponseHandler.java    (revision 995482)
+++ src/java/org/apache/cassandra/service/QuorumResponseHandler.java    (working copy)
@@ -109,7 +109,7 @@
             case ANY:
                 return 1;
             case QUORUM:
-                return (DatabaseDescriptor.getQuorum(table)/ 2) + 1;
+                return DatabaseDescriptor.getQuorum(table);
             case ALL:
                 return DatabaseDescriptor.getReplicationFactor(table);
             default:
-------------------
In QuorumResponseHandler:determineBlockFor()
DatabaseDescriptor.getQuorum(table) is already returning a quorum value which is further divided by 2 and a one is added.

So say if your RF=6, it is suppose to check 4 replicas, (6/2)+1=4 but it ends up checking only 3 replicas as DatabaseDescriptor.getQuorum returns 4, so determineBlockFor will return (4/2)+1=3.

Let me know if you have any questions.

Jignesh",,scode,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Sep/10 20:20;jigneshdhruv;QuorumResponseHandler.java.patch;https://issues.apache.org/jira/secure/attachment/12454235/QuorumResponseHandler.java.patch",,,,,,,,,,,,,,1.0,jigneshdhruv,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20163,,,Sat Sep 11 01:00:11 UTC 2010,,,,,,,,,,"0|i0g5d3:",92299,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"09/Sep/10 19:34;kingryan;You should attach patches rather than pasting them.;;;","09/Sep/10 20:20;jigneshdhruv;QuoromResponseHandler Patch.;;;","09/Sep/10 20:21;jigneshdhruv;Attached patch for QuorumResponseHandler.java.;;;","11/Sep/10 01:00;jbellis;committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
API Version Mismatch,CASSANDRA-1484,12473633,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,arya,arya,08/Sep/10 23:02,16/Apr/19 09:33,14/Jul/23 05:51,08/Sep/10 23:12,0.7 beta 2,,Legacy/CQL,,0,,,,,,"Updated to Cassandra Trunk and Thrift Trunk. API versions mismatch when describe_version() is called. 

AssertionError: Thrift API version mismatch. (Client: 14, Server: 13)

This causes some API clients that do version validation like pycassa to fail. 
","CentOS 5.2
Trunk Wed. Sep 8th",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20162,,,Wed Sep 08 23:12:29 UTC 2010,,,,,,,,,,"0|i0g5cf:",92296,,,,,Low,,,,,,,,,,,,,,,,,"08/Sep/10 23:12;jbellis;fixed in r995280;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CFMetaData.convertToThrift makes subcomparator_type empty string instead of null,CASSANDRA-1480,12473524,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jhermes,jeromatron,jeromatron,08/Sep/10 03:27,16/Apr/19 09:33,14/Jul/23 05:51,13/Sep/10 19:22,0.7 beta 2,,Legacy/CQL,,0,,,,,,"As a result of CASSANDRA-891 adding a CFMetaData.convertToThrift method, the values such as subcomparator_type are defaulted to empty string instead of null.  That makes it so, for example, in ColumnFamilyRecordReader, in its RowIterator, the check for only null is insufficient.  It also needs to check for a blank value.

After a discussion about it in IRC, Jonathan said it was probably easier to just change the creation to give a null value instead of empty string.",,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1425,CASSANDRA-891,,,"13/Sep/10 18:56;jhermes;1480.txt;https://issues.apache.org/jira/secure/attachment/12454470/1480.txt",,,,,,,,,,,,,,1.0,jhermes,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20160,,,Mon Sep 13 19:22:51 UTC 2010,,,,,,,,,,"0|i0g5bj:",92292,,jeromatron,,jeromatron,Normal,,,,,,,,,,,,,,,,,"13/Sep/10 16:19;jhermes;(This code is only touched in describe keyspace(s) in the API.)
Attaching a debugger shows the subcomparator_type of the result of the call to be null (as expected) until it gets sent, at which point the result is then converted to the empty string.
I'm not sure when this behaviour changed, but it appears to be systemic and not a simple error.

It would be less time to change the code to accept the empty string (which may come up naturally anyway) than it would be to continue debugging thrift.;;;","13/Sep/10 16:24;jeromatron;I kind of wondered if it would be complicated like that based on how thrift handled it.  It's a one line change to fix it in ColumnFamilyRecordReader.  I didn't know if it would affect anything else similarly.  Hopefully system/unit tests catch a lot of that.  We could do some simple searches in the code for null checks I suppose - and in those cases, if they're strings, do a o.a.commons.lang.StringUtils.isNotBlank instead.  Not sure if it's worth it though since that could have other side effects.;;;","13/Sep/10 16:41;jhermes;To pose a related question: assume the user sets the subcomparator_type (or the comparator or the validator or the default_validator) to the empty string. All perfectly legal, as the empty string is a valid string.
What should they expect to see? Right now it's a stack trace.;;;","13/Sep/10 17:41;jbellis;This is not a bug; subcomparator_type has a default of """", so if you leave it null (i.e., unspecified), it gets changed to its default.

Removing the default should restore the old behavior.

Defaults on reconciler and comment should also be removed.;;;","13/Sep/10 17:52;jhermes;Massive palm to the face.
Testing now.;;;","13/Sep/10 18:56;jhermes;convertToCFMetaData had to be changed as well, it was expecting subcomparator to default to empty string. I don't think this was a recent change; instead it looks more like we changed our assumption about the default.

In any event, subcomp, reconciler, and comment all default to null now and all tests/methods are working correctly.;;;","13/Sep/10 19:14;jeromatron;Ran the word count again with the 1480.txt patch.  It no longer gets the exception and completes properly now.;;;","13/Sep/10 19:22;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
drop/recreate column family race condition,CASSANDRA-1477,12473494,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,gdusbabek,btoddb,btoddb,07/Sep/10 21:21,16/Apr/19 09:33,14/Jul/23 05:51,15/Sep/10 20:39,0.7 beta 2,,,,0,,,,,,"using 0.7 latest from trunk as of few minutes ago.  1 client, 1 node

i have the scenario where i want to drop a column family and recreate it 
- unit testing for instance, is a good reason you may want to do this 
(always start fresh).

the problem i observe is that if i do the following:

1 - drop the column family
2 - recreate it
3 - read data from a key that existed before dropping, but doesn't exist now

if those steps happen fast enough, i will get the old row - definitely 
no good.

if they happen slow enough, get_slice throws:

""org.apache.thrift.TApplicationException: Internal error processing 
get_slice""

.. and on the server i see:

2010-09-07 13:53:48,086 ERROR 
[org.apache.cassandra.thrift.Cassandra$Processor] (pool-1-thread-4:) - 
Internal error processing get_slice
java.lang.RuntimeException: java.util.concurrent.ExecutionException: 
java.io.IOError: java.io.FileNotFoundException: 
cassandra-data/data/Queues/test_1283892789285_Waiting-e-1-Data.db (No 
such file or directory)
     at 
org.apache.cassandra.service.StorageProxy.weakRead(StorageProxy.java:275)
     at 
org.apache.cassandra.service.StorageProxy.readProtocol(StorageProxy.java:218)
     at 
org.apache.cassandra.thrift.CassandraServer.readColumnFamily(CassandraServer.java:114)
     at 
org.apache.cassandra.thrift.CassandraServer.getSlice(CassandraServer.java:220)
     at 
org.apache.cassandra.thrift.CassandraServer.multigetSliceInternal(CassandraServer.java:299)
     at 
org.apache.cassandra.thrift.CassandraServer.get_slice(CassandraServer.java:260)
     at 
org.apache.cassandra.thrift.Cassandra$Processor$get_slice.process(Cassandra.java:2795)
     at 
org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:2651)
     at 
org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
     at 
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
     at 
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
     at java.lang.Thread.run(Thread.java:619)
Caused by: java.util.concurrent.ExecutionException: java.io.IOError: 
java.io.FileNotFoundException: 
cassandra-data/data/Queues/test_1283892789285_Waiting-e-1-Data.db (No 
such file or directory)
     at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
     at java.util.concurrent.FutureTask.get(FutureTask.java:83)
     at 
org.apache.cassandra.service.StorageProxy.weakRead(StorageProxy.java:271)
     ... 11 more
Caused by: java.io.IOError: java.io.FileNotFoundException: 
cassandra-data/data/Queues/test_1283892789285_Waiting-e-1-Data.db (No 
such file or directory)
     at 
org.apache.cassandra.io.util.BufferedSegmentedFile.getSegment(BufferedSegmentedFile.java:68)
     at 
org.apache.cassandra.io.sstable.SSTableReader.getFileDataInput(SSTableReader.java:509)
     at 
org.apache.cassandra.db.columniterator.SSTableSliceIterator.<init>(SSTableSliceIterator.java:49)
     at 
org.apache.cassandra.db.filter.SliceQueryFilter.getSSTableColumnIterator(SliceQueryFilter.java:65)
     at 
org.apache.cassandra.db.filter.QueryFilter.getSSTableColumnIterator(QueryFilter.java:76)
     at 
org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:961)
     at 
org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:856)
     at 
org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:826)
     at org.apache.cassandra.db.Table.getRow(Table.java:321)
     at 
org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:63)
     at 
org.apache.cassandra.service.StorageProxy$weakReadLocalCallable.call(StorageProxy.java:737)
     at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
     at java.util.concurrent.FutureTask.run(FutureTask.java:138)
     ... 3 more
Caused by: java.io.FileNotFoundException: 
cassandra-data/data/Queues/test_1283892789285_Waiting-e-1-Data.db (No 
such file or directory)
     at java.io.RandomAccessFile.open(Native Method)
     at java.io.RandomAccessFile.<init>(RandomAccessFile.java:212)
     at java.io.RandomAccessFile.<init>(RandomAccessFile.java:98)
     at 
org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:142)
     at 
org.apache.cassandra.io.util.BufferedSegmentedFile.getSegment(BufferedSegmentedFile.java:62)
     ... 15 more

","1 Node cluster, latest code from 0.7 trunk",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/10 19:34;gdusbabek;ASF.LICENSE.NOT.GRANTED--v4-0001-revert-r996974.-fix-by-adding-a-switch-to-files-to-all.txt;https://issues.apache.org/jira/secure/attachment/12454689/ASF.LICENSE.NOT.GRANTED--v4-0001-revert-r996974.-fix-by-adding-a-switch-to-files-to-all.txt","15/Sep/10 19:34;gdusbabek;ASF.LICENSE.NOT.GRANTED--v4-0002-move-directory-scrubbing-to-startup.txt;https://issues.apache.org/jira/secure/attachment/12454690/ASF.LICENSE.NOT.GRANTED--v4-0002-move-directory-scrubbing-to-startup.txt","15/Sep/10 19:34;gdusbabek;ASF.LICENSE.NOT.GRANTED--v4-0003-avro-system-tests.txt;https://issues.apache.org/jira/secure/attachment/12454691/ASF.LICENSE.NOT.GRANTED--v4-0003-avro-system-tests.txt","13/Sep/10 23:28;btoddb;RaceConditionTest.java;https://issues.apache.org/jira/secure/attachment/12454499/RaceConditionTest.java",,,,,,,,,,,4.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20159,,,Fri Sep 17 13:55:34 UTC 2010,,,,,,,,,,"0|i0g5av:",92289,,jbellis,,jbellis,Critical,,,,,,,,,,,,,,,,,"09/Sep/10 12:27;gdusbabek;On the ML you indicated you had a unit tests that was producing this failure.  Is it possible for you to attach it to this ticket?  I would like to include it in our tests.;;;","09/Sep/10 17:05;btoddb;it uses Pelops at the moment.  lemme see if i can rework it for raw thrift.;;;","13/Sep/10 23:28;btoddb;using latest trunk code as of now

The attached JUnit (method testRaceTooFast) illustrates the problem of data still existing even though the column family has been dropped and recreated, but no data inserted.

However, I cannot make the test fail by throwing ""org.apache.thrift.TApplicationException: Internal error processing get_slice"" as i indicate before because the first problem above never corrects itself.  The data file never goes away no matter how long i wait.  not sure what i was doing different in my app, or possibly code changed.  i no longer do it this way in my app so not sure.

in addition, i tried to drop the keyspace between tests to make sure the keyspace was ""clear"" and this returns ""InvalidRequestException(why:java.io.IOException: Unable to create compaction marker)"" when the keyspace does exist, but i guess i dropped the column family during the previous test and caused it grief.  not sure.

good luck!;;;","14/Sep/10 15:14;gdusbabek;I see now (I can reproduce this fwiw).  We changed the way to cleanup after dropped CFs at the end of August.  Prior to that, we blocked on deletion, but now just mark the CF compacted and wait for normal cleanup to do it's thing.

In hindsight, I'm not sure if this was the best approach.  If we allow creating, dropping, then recreating in rapid succession we should support it better.;;;","14/Sep/10 15:24;jbellis;why do sstables-marked-compacted have any effect on anything?  isn't that a relatively simple fix?;;;","14/Sep/10 15:29;gdusbabek;I'm not sure.  Is it as simple as changing CFS.files() to ignore those that have compacted markers?;;;","14/Sep/10 15:35;jbellis;either that, or have it clean out the compacted ones before doing its filtering;;;","14/Sep/10 15:35;jbellis;(ignoring is probably safer since it's possible for a file to be marked compacted, but still open for a reader in progress);;;","14/Sep/10 16:03;jbellis;+1;;;","14/Sep/10 16:49;btoddb;the patch fixes the first problem, but the second method, testRaceSlowEnoughToCauseException, in the attached unit test still throws the following from get_slice:

InvalidRequestException(why:java.io.IOException: Unable to create compaction marker)
    at org.apache.cassandra.thrift.Cassandra$system_drop_column_family_result.read(Cassandra.java:22872)
    at org.apache.cassandra.thrift.Cassandra$Client.recv_system_drop_column_family(Cassandra.java:1342)
    at org.apache.cassandra.thrift.Cassandra$Client.system_drop_column_family(Cassandra.java:1317)
    at RaceConditionTest.testRaceSlowEnoughToCauseException(RaceConditionTest.java:87)

on the server side i see this:

10/09/14 09:46:32 ERROR thrift.CassandraDaemon: Uncaught exception in thread Thread[MIGRATION_STAGE:1,5,main]
java.util.concurrent.ExecutionException: java.io.IOError: java.io.IOException: Unable to create compaction marker
	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
	at java.util.concurrent.FutureTask.get(FutureTask.java:83)
	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:87)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
Caused by: java.io.IOError: java.io.IOException: Unable to create compaction marker
	at org.apache.cassandra.io.sstable.SSTableReader.markCompacted(SSTableReader.java:484)
	at org.apache.cassandra.io.sstable.SSTableTracker.replace(SSTableTracker.java:76)
	at org.apache.cassandra.db.ColumnFamilyStore.removeAllSSTables(ColumnFamilyStore.java:711)
	at org.apache.cassandra.db.Table.dropCf(Table.java:271)
	at org.apache.cassandra.db.migration.DropColumnFamily.applyModels(DropColumnFamily.java:94)
	at org.apache.cassandra.db.migration.Migration.apply(Migration.java:157)
	at org.apache.cassandra.thrift.CassandraServer$1.call(CassandraServer.java:644)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	... 2 more
Caused by: java.io.IOException: Unable to create compaction marker
	at org.apache.cassandra.io.sstable.SSTableReader.markCompacted(SSTableReader.java:480)
	... 11 more
;;;","14/Sep/10 17:01;btoddb;i should point out that testRaceSlowEnoughToCauseException runs fine in isolation, but run the junit class as a whole and it will fail.;;;","14/Sep/10 20:14;gdusbabek;Setting this to blocker. The bug is such that valid sstables can be deleted when the compaction markers stick around after a CF is dropped and recreated.

The fix is to check for a compaction marker when a sstable is created and delete it if it's there.;;;","14/Sep/10 20:58;jbellis;somehow we're getting into a situation where there is X.compacted but no other sign of X?;;;","14/Sep/10 21:48;gdusbabek;The exception happens because the compaction marker exists but the deletion executor hasn't done its thing.  It's easy to visualize:
* A keyspace is created along with a column family.  sstables are written.
* That keyspace is dropped. compacted markers are written.
* That keyspace and column family are recreated.  Meanwhile, no files have been deleted.
* As part of re-Table.open()ing it, CFS.scrubDataDirectories() is called but doesn't scrub the compacted markers because of those are now excluded by files() * (I'm pretty sure this wasn't working, or wasn't working like we expect, in the first place, since B.Todd was getting the error before applying the patch).
* Newly created sstables match the names of the compaction markers and will be possibly deleted if timing is bad.

Two fixes come to mind:
1. keep the first patch that has already been committed and make AddKeyspace ensure that data directories, if they exist, are empty.
2. revert the last patch and make AddColumnFamily ensure that its data directory, if it exists, is empty.

I favor option 2.;;;","14/Sep/10 21:56;jbellis;this seems like a race-prone thing to do in the first place since it's not valid to remove a data file that has a reader open to it...

verifying empty data directories on KS creation is fine but what is the analogue for CFs?  and how do you tell the client ""sorry, you're SOL"" if it's not empty?;;;","15/Sep/10 13:53;gdusbabek;You're right.  I was trying to take a shortcut.  

The real problem is that CFS.files() is being used for two things: determine valid files to read from and also count the files to determine generation.  It can't determine the right generation if it doesn't include the invalid files (compacted), but if it includes the invalid files, we read data we shouldn't.;;;","15/Sep/10 13:56;jbellis;I think you've nailed it.;;;","15/Sep/10 15:17;hudson;Integrated in Cassandra #536 (See [https://hudson.apache.org/hudson/job/Cassandra/536/])
    ensure that compacted sstables are excluded from newly instantiated readers. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1477
;;;","15/Sep/10 15:19;jbellis;don't we also need to change scrub to only run at server start to avoid race-with-reader?;;;","15/Sep/10 18:33;gdusbabek;Yes. v3 addresses that.;;;","15/Sep/10 18:42;jbellis;+1

(in patch 2, CFS.all() may offer a small simplification.);;;","15/Sep/10 19:37;gdusbabek;Your suggestion on patch 2 made me realize that the scrubbing should happen pior to populating the instances in CFS.  v4 fixes that.;;;","15/Sep/10 20:14;btoddb;seems like these patches are fixing the issues i found;;;","15/Sep/10 20:31;jbellis;+1;;;","15/Sep/10 20:39;gdusbabek;new and improved fix committed.;;;","17/Sep/10 13:55;hudson;Integrated in Cassandra #538 (See [https://hudson.apache.org/hudson/job/Cassandra/538/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"replication factor exceeds number of endpoints, when attempting to join a new node (but cluster has enough running nodes to fulfill RF)",CASSANDRA-1467,12473291,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,blanquer,blanquer,03/Sep/10 23:24,16/Apr/19 09:33,14/Jul/23 05:51,13/Sep/10 16:11,0.6.6,0.7 beta 2,,,0,,,,,,"What happens here the following:
* given a healthy running cluster of 2 nodes (it used to be 3 but I manually killed one down)
* with a Keyspace having a ReplicationFactor of 2
* (this cluster is operational, loaded with data and working well)

 as soon as I want to bring up a new 3rd node:
* the node is detected by the current cluster
* but as soon as it tries to initiate bootstrap sequence it dies with:  replication factor (2) exceeds number of endpoints (1)

I believe this is similar to #1343, but not quite the same, since the keyspace and everything is already created, and I'm not attempting any modification. This is purely bringing a new node up.

One extra tidbit of information, in case it's important...maybe it is not: 
I have only set 1 seed node configured (this is a test setup). And when the new node starts coming up (before the crash) its nodetool ring only reports the seed one.

From the new node coming up (before it crashes):
root@node1-3:~# nodetool -h localhost -p 8080 ring
Address         Status State   Load            Token                                       
10.250.106.111  Up     Normal  116.3 GB        0          < = this the only configured seed node

From one of the other running nodes (this is the real status of the cluster):
root@node1-2:~# nodetool -h localhost -p 8080 ring
Address         Status State   Load            Token                                       
                                       113416112894748789872342756657008344878    
10.250.106.111  Up     Normal  116.3 GB        0                                           
10.215.195.81   Up     Normal  116.31 GB       56713727820156410577229101238628035242      
10.246.65.221   Up     Joining 7.63 KB         113416112894748789872342756657008344878     


Here's the full boot trace of the node is trying to join:
Java HotSpot(TM) Client VM warning: Can't detect initial thread stack location - find_vma failed
Create RMI registry on port 8081
Get the platform's MBean server
Initialize the environment map
Create an RMI connector server
Start the RMI connector server on port 8081
 INFO 22:32:50,448 Loading settings from /etc/cassandra/cassandra.yaml
DEBUG 22:32:50,537 Syncing log with a period of 10000
 INFO 22:32:50,538 DiskAccessMode 'auto' determined to be standard, indexAccessMode is standard
DEBUG 22:32:50,548 setting auto_bootstrap to true
DEBUG 22:32:50,702 Starting CFS Statistics
DEBUG 22:32:50,710 key cache capacity for Statistics is 1
DEBUG 22:32:50,711 Starting CFS Schema
DEBUG 22:32:50,712 key cache capacity for Schema is 1
DEBUG 22:32:50,712 Starting CFS Migrations
DEBUG 22:32:50,713 key cache capacity for Migrations is 1
DEBUG 22:32:50,713 Starting CFS LocationInfo
DEBUG 22:32:50,713 key cache capacity for LocationInfo is 1
DEBUG 22:32:50,714 Starting CFS HintsColumnFamily
DEBUG 22:32:50,714 key cache capacity for HintsColumnFamily is 1
 INFO 22:32:50,736 Couldn't detect any schema definitions in local storage.
 INFO 22:32:50,737 Found table data in data directories. Consider using JMX to call org.apache.cassandra.service.StorageService.loadSchemaFromYaml().
DEBUG 22:32:50,738 opening keyspace system
 INFO 22:32:50,757 Cassandra version: 
 INFO 22:32:50,757 Thrift API version: 10.0.0
 INFO 22:32:50,758 Saved Token not found. Using 113416112894748789872342756657008344878
 INFO 22:32:50,758 Saved ClusterName not found. Using SOMETHING 
 INFO 22:32:50,763 Creating new commitlog segment /mnt/cassandra/commitlog/CommitLog-1283553170763.log
DEBUG 22:32:50,767 Estimating compactions for LocationInfo
DEBUG 22:32:50,768 Estimating compactions for HintsColumnFamily
DEBUG 22:32:50,768 Estimating compactions for Migrations
DEBUG 22:32:50,768 Estimating compactions for Schema
DEBUG 22:32:50,768 Estimating compactions for Statistics
DEBUG 22:32:50,769 Checking to see if compaction of LocationInfo would be useful
DEBUG 22:32:50,769 Checking to see if compaction of HintsColumnFamily would be useful
DEBUG 22:32:50,769 Checking to see if compaction of Migrations would be useful
DEBUG 22:32:50,769 Checking to see if compaction of Schema would be useful
DEBUG 22:32:50,769 Checking to see if compaction of Statistics would be useful
 INFO 22:32:50,779 switching in a fresh Memtable for LocationInfo at CommitLogContext(file='/mnt/cassandra/commitlog/CommitLog-1283553170763.log', position=276)
 INFO 22:32:50,782 Enqueuing flush of Memtable-LocationInfo@18721294(192 bytes, 4 operations)
 INFO 22:32:50,783 Writing Memtable-LocationInfo@18721294(192 bytes, 4 operations)
 INFO 22:32:50,897 Completed flushing /mnt/ebs/data/system/LocationInfo-e-1-Data.db
DEBUG 22:32:50,898 Checking to see if compaction of LocationInfo would be useful
DEBUG 22:32:50,898 Discarding 0
DEBUG 22:32:50,899 discard completed log segments for CommitLogContext(file='/mnt/cassandra/commitlog/CommitLog-1283553170763.log', position=276), column family 0.
DEBUG 22:32:50,899 Marking replay position 276 on commit log CommitLogSegment(/mnt/cassandra/commitlog/CommitLog-1283553170763.log)
 INFO 22:32:50,908 Starting up server gossip
 INFO 22:32:50,928 Joining: getting load information
 INFO 22:32:50,928 Sleeping 90000 ms to wait for load information...
DEBUG 22:32:50,940 attempting to connect to node1-1.domain.com/10.250.106.111
DEBUG 22:32:51,044 attempting to connect to node1-1.domain.com/10.250.106.111
DEBUG 22:32:51,045 attempting to connect to /10.215.195.81
 INFO 22:32:51,051 Node /10.215.195.81 is now part of the cluster
DEBUG 22:32:51,051 Resetting pool for /10.215.195.81
DEBUG 22:32:51,052 Token 113416112894748789872342756657008344877 removed manually (endpoint was unknown)
 INFO 22:32:51,052 Node /10.250.106.111 is now part of the cluster
DEBUG 22:32:51,053 Resetting pool for /10.250.106.111
DEBUG 22:32:51,053 Node /10.250.106.111 state normal, token 0
DEBUG 22:32:51,053 clearing cached endpoints
DEBUG 22:32:51,171 Applying AddKeyspace from /10.250.106.111
DEBUG 22:32:51,188 Applying migration 77e97d6c-b625-11df-8596-318df8b646e8
 INFO 22:32:51,189 switching in a fresh Memtable for Migrations at CommitLogContext(file='/mnt/cassandra/commitlog/CommitLog-1283553170763.log', position=7417)
 INFO 22:32:51,189 Enqueuing flush of Memtable-Migrations@18093512(4938 bytes, 1 operations)
 INFO 22:32:51,189 Writing Memtable-Migrations@18093512(4938 bytes, 1 operations)
 INFO 22:32:51,194 switching in a fresh Memtable for Schema at CommitLogContext(file='/mnt/cassandra/commitlog/CommitLog-1283553170763.log', position=7417)
 INFO 22:32:51,194 Enqueuing flush of Memtable-Schema@27402470(1784 bytes, 3 operations)
 INFO 22:32:51,274 Completed flushing /mnt/ebs/data/system/Migrations-e-1-Data.db
DEBUG 22:32:51,274 Checking to see if compaction of Migrations would be useful
DEBUG 22:32:51,275 Discarding 2
DEBUG 22:32:51,275 discard completed log segments for CommitLogContext(file='/mnt/cassandra/commitlog/CommitLog-1283553170763.log', position=7417), column family 2
.
DEBUG 22:32:51,275 Marking replay position 7417 on commit log CommitLogSegment(/mnt/cassandra/commitlog/CommitLog-1283553170763.log)
 INFO 22:32:51,275 Writing Memtable-Schema@27402470(1784 bytes, 3 operations)
 INFO 22:32:51,388 Completed flushing /mnt/ebs/data/system/Schema-e-1-Data.db
DEBUG 22:32:51,389 Checking to see if compaction of Schema would be useful
DEBUG 22:32:51,389 Discarding 3
DEBUG 22:32:51,389 discard completed log segments for CommitLogContext(file='/mnt/cassandra/commitlog/CommitLog-1283553170763.log', position=7417), column family 3
.
DEBUG 22:32:51,389 Marking replay position 7417 on commit log CommitLogSegment(/mnt/cassandra/commitlog/CommitLog-1283553170763.log)
DEBUG 22:32:51,406 Starting CFS MyColumnFamily
DEBUG 22:32:51,406 key cache capacity for MyColumnFamily is 200000
 INFO 22:32:51,407 Creating new commitlog segment /mnt/cassandra/commitlog/CommitLog-1283553171407.log
DEBUG 22:32:51,604 attempting to connect to node1-1.domain.com/10.250.106.111
 INFO 22:32:51,622 InetAddress /10.215.195.81 is now UP
 INFO 22:32:51,623 InetAddress /10.250.106.111 is now UP
 INFO 22:32:51,623 Started hinted handoff for endpoint /10.215.195.81
 INFO 22:32:51,631 Finished hinted handoff of 0 rows to endpoint /10.215.195.81
 INFO 22:32:51,632 Started hinted handoff for endpoint /10.250.106.111
 INFO 22:32:51,632 Finished hinted handoff of 0 rows to endpoint /10.250.106.111
DEBUG 22:32:51,918 GC for ParNew: 14 ms, 20561696 reclaimed leaving 149257720 used; max is 902627328
DEBUG 22:32:51,919 GC for ConcurrentMarkSweep: 73 ms, 4178480 reclaimed leaving 8520856 used; max is 902627328
DEBUG 22:32:52,924 Disseminating load info ...
DEBUG 22:32:53,929 attempting to connect to /10.215.195.81
DEBUG 22:32:54,925 GC for ConcurrentMarkSweep: 73 ms, 212034048 reclaimed leaving 15214608 used; max is 902627328
DEBUG 22:33:52,931 Disseminating load info ...
DEBUG 22:34:20,929 ... got load info
 INFO 22:34:20,929 Joining: getting bootstrap token
DEBUG 22:34:20,931 token manually specified as 113416112894748789872342756657008344878
 INFO 22:34:20,932 Joining: sleeping 30000 ms for pending range setup
 INFO 22:34:50,935 Bootstrapping
DEBUG 22:34:50,935 Beginning bootstrap process
java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.commons.daemon.support.DaemonLoader.load(DaemonLoader.java:160)
Caused by: java.lang.IllegalStateException: replication factor (2) exceeds number of endpoints (1)
        at org.apache.cassandra.locator.RackUnawareStrategy.calculateNaturalEndpoints(RackUnawareStrategy.java:57)
        at org.apache.cassandra.locator.AbstractReplicationStrategy.getRangeAddresses(AbstractReplicationStrategy.java:195)
        at org.apache.cassandra.dht.BootStrapper.getRangesWithSources(BootStrapper.java:155)
        at org.apache.cassandra.dht.BootStrapper.startBootstrap(BootStrapper.java:73)
        at org.apache.cassandra.service.StorageService.startBootstrap(StorageService.java:467)
        at org.apache.cassandra.service.StorageService.initServer(StorageService.java:408)
        at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:134)
        at org.apache.cassandra.service.AbstractCassandraDaemon.init(AbstractCassandraDaemon.java:57)
        ... 5 more
Cannot load daemon
Service exit with a return value of 3
",I'm using 0.7 beta1. Built from: http://www.apache.org/dyn/closer.cgi?path=/cassandra/0.7.0/apache-cassandra-0.7.0-beta1-src.tar.gz  using dpkg-buildpackage from it.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Sep/10 21:09;gdusbabek;1467-0.6.txt;https://issues.apache.org/jira/secure/attachment/12454241/1467-0.6.txt","09/Sep/10 21:07;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-expose-endpoint-states-to-jmx.txt;https://issues.apache.org/jira/secure/attachment/12454238/ASF.LICENSE.NOT.GRANTED--v1-0001-expose-endpoint-states-to-jmx.txt","09/Sep/10 21:07;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0002-remove-unused-code-from-SLB.txt;https://issues.apache.org/jira/secure/attachment/12454239/ASF.LICENSE.NOT.GRANTED--v1-0002-remove-unused-code-from-SLB.txt","09/Sep/10 21:07;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0003-broadcast-removetoken-using-MOVE-NORMAL-to-preserve-th.txt;https://issues.apache.org/jira/secure/attachment/12454240/ASF.LICENSE.NOT.GRANTED--v1-0003-broadcast-removetoken-using-MOVE-NORMAL-to-preserve-th.txt",,,,,,,,,,,4.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20157,,,Mon Sep 13 16:11:48 UTC 2010,,,,,,,,,,"0|i0g58n:",92279,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"03/Sep/10 23:58;gdusbabek;Did the node you were trying to bootstrap already have schema defined?;;;","04/Sep/10 00:23;blanquer;No, it was a blank node. 
I've just wiped the data and commit log dirs clean, and restarted cassandra again with the same result.

Here's the start of the system.log:
 INFO [main] 2010-09-04 00:19:19,744 DatabaseDescriptor.java (line 120) Loading settings from /etc/cassandra/cassandra.yaml
DEBUG [main] 2010-09-04 00:19:19,923 DatabaseDescriptor.java (line 163) Syncing log with a period of 10000
 INFO [main] 2010-09-04 00:19:19,923 DatabaseDescriptor.java (line 171) DiskAccessMode 'auto' determined to be standard, indexAccessMode is standard
DEBUG [main] 2010-09-04 00:19:19,933 DatabaseDescriptor.java (line 311) setting auto_bootstrap to true
DEBUG [main] 2010-09-04 00:19:20,122 ColumnFamilyStore.java (line 149) Starting CFS Statistics
DEBUG [main] 2010-09-04 00:19:20,188 SSTableTracker.java (line 110) key cache capacity for Statistics is 1
DEBUG [main] 2010-09-04 00:19:20,189 ColumnFamilyStore.java (line 149) Starting CFS Schema
DEBUG [main] 2010-09-04 00:19:20,190 SSTableTracker.java (line 110) key cache capacity for Schema is 1
DEBUG [main] 2010-09-04 00:19:20,191 ColumnFamilyStore.java (line 149) Starting CFS Migrations
DEBUG [main] 2010-09-04 00:19:20,191 SSTableTracker.java (line 110) key cache capacity for Migrations is 1
DEBUG [main] 2010-09-04 00:19:20,191 ColumnFamilyStore.java (line 149) Starting CFS LocationInfo
DEBUG [main] 2010-09-04 00:19:20,192 SSTableTracker.java (line 110) key cache capacity for LocationInfo is 1
DEBUG [main] 2010-09-04 00:19:20,193 ColumnFamilyStore.java (line 149) Starting CFS HintsColumnFamily
DEBUG [main] 2010-09-04 00:19:20,193 SSTableTracker.java (line 110) key cache capacity for HintsColumnFamily is 1
 INFO [main] 2010-09-04 00:19:20,223 DatabaseDescriptor.java (line 442) *Couldn't detect any schema definitions in local storage.*
 INFO [main] 2010-09-04 00:19:20,224 DatabaseDescriptor.java (line 468) Found table data in data directories. Consider using JMX to call org.apache.cassandra.service.StorageService.loadSchemaFromYaml().
DEBUG [main] 2010-09-04 00:19:20,227 CassandraDaemon.java (line 115) opening keyspace system
 INFO [main] 2010-09-04 00:19:20,247 StorageService.java (line 342) Cassandra version:
 INFO [main] 2010-09-04 00:19:20,247 StorageService.java (line 343) Thrift API version: 10.0.0
 INFO [main] 2010-09-04 00:19:20,248 SystemTable.java (line 202) Saved Token not found. Using 113416112894748789872342756657008344878
 INFO [main] 2010-09-04 00:19:20,249 SystemTable.java (line 208) Saved ClusterName not found. ......
;;;","07/Sep/10 21:30;gdusbabek;It took some trying, but I can reproduce this now.;;;","09/Sep/10 16:21;gdusbabek;Reproduced in 0.6 (mostly).  The bootstrap still happens because we don't enforce the RF restriction that we do now.  When the fourth node is brought up and bootstrapped, it sees the the ring minus the coordinator node from the removetoken operation.

I've got a patch worked up for trunk.  I'll port it to 0.6 and attach shortly.;;;","09/Sep/10 18:31;gdusbabek;The first two patches are housekeeping.  Exposing the endpoint states via jmx was helpful for troubleshooting.
The third patch changes gossip so that the removetoken information is broadcast as part of a MOVE,NORMAL instead of MOVE,LEFT.  This means that we no longer have to distinguish between MOVE,LEFT,leaving and MOVE,LEFT,removetoken, so I removed that distinction.  

Valid MOVE operations are now these:
MOVE,NORMAL,token[,<other command>,<other token>]
MOVE,LEFT,token
MOVE,BOOTSTRAPPING,token
MOVE,LEAVING,token

If this patch goes into 0.6 as is, it alters gossip enough so that if a removetoken, decommission or loadbalance are in progress during the rolling upgrade, bad things might happen (the wrong handlers could be called).;;;","09/Sep/10 21:09;gdusbabek;comments MOVE state transitions.;;;","13/Sep/10 14:25;jbellis;+1;;;","13/Sep/10 16:11;gdusbabek;committed 0.6 and trunk (0.7);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Failed bootstrap can cause NPE in batch_mutate on every node, taking down the entire cluster",CASSANDRA-1463,12473282,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,ketralnis,ketralnis,03/Sep/10 20:50,16/Apr/19 09:33,14/Jul/23 05:51,04/Sep/10 20:34,0.6.6,0.7 beta 2,,,0,,,,,,"In adding a node to the cluster, the bootstrap failed (still investigating the cause). An hour later, the entire cluster failed, preventing any writes from being accepted. This exception started being printed to the logs:

{quote}
 INFO [Timer-0] 2010-09-03 12:23:33,282 Gossiper.java (line 402) FatClient /10.251.243.191 has been silent for 3600000ms, removing from gossip
ERROR [Timer-0] 2010-09-03 12:23:33,318 Gossiper.java (line 99) Gossip error
java.util.ConcurrentModificationException
        at java.util.Hashtable$Enumerator.next(Hashtable.java:1048)
        at org.apache.cassandra.gms.Gossiper.doStatusCheck(Gossiper.java:383)
        at org.apache.cassandra.gms.Gossiper$GossipTimerTask.run(Gossiper.java:93)
        at java.util.TimerThread.mainLoop(Timer.java:534)
        at java.util.TimerThread.run(Timer.java:484)
ERROR [pool-1-thread-69153] 2010-09-03 12:23:33,857 Cassandra.java (line 1659) Internal error processing batch_mutate
java.lang.NullPointerException
        at org.apache.cassandra.gms.FailureDetector.isAlive(FailureDetector.java:135)
        at org.apache.cassandra.locator.AbstractReplicationStrategy.getHintedEndpoints(AbstractReplicationStrategy.java:85)
        at org.apache.cassandra.service.StorageProxy.mutateBlocking(StorageProxy.java:204)
        at org.apache.cassandra.thrift.CassandraServer.batch_mutate(CassandraServer.java:415)
        at org.apache.cassandra.thrift.Cassandra$Processor$batch_mutate.process(Cassandra.java:1651)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:1166)
        at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
ERROR [pool-1-thread-69154] 2010-09-03 12:23:33,869 Cassandra.java (line 1659) Internal error processing batch_mutate
java.lang.NullPointerException
        at org.apache.cassandra.gms.FailureDetector.isAlive(FailureDetector.java:135)
        at org.apache.cassandra.locator.AbstractReplicationStrategy.getHintedEndpoints(AbstractReplicationStrategy.java:85)
        at org.apache.cassandra.service.StorageProxy.mutateBlocking(StorageProxy.java:204)
        at org.apache.cassandra.thrift.CassandraServer.batch_mutate(CassandraServer.java:415)
        at org.apache.cassandra.thrift.Cassandra$Processor$batch_mutate.process(Cassandra.java:1651)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:1166)
        at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
{quote}

After a large number of iterations of that (at least thousands), the printed exception was shortened (this shortening is what made me mistakenly file #1462) to

{quote}
ERROR [pool-1-thread-68869] 2010-09-03 12:39:22,857 Cassandra.java (line 1659) Internal error processing batch_mutate
java.lang.NullPointerException
ERROR [pool-1-thread-68869] 2010-09-03 12:39:22,883 Cassandra.java (line 1659) Internal error processing batch_mutate
java.lang.NullPointerException
ERROR [pool-1-thread-68869] 2010-09-03 12:39:22,894 Cassandra.java (line 1659) Internal error processing batch_mutate
java.lang.NullPointerException
ERROR [pool-1-thread-68970] 2010-09-03 12:39:22,985 Cassandra.java (line 1659) Internal error processing batch_mutate
java.lang.NullPointerException
ERROR [pool-1-thread-68970] 2010-09-03 12:39:23,084 Cassandra.java (line 1659) Internal error processing batch_mutate
java.lang.NullPointerException
{quote}

Rolling a restart over the cluster fixed it, but every node had to be restarted before it started accepting writes again.",,brandon.williams,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Sep/10 04:14;jbellis;1463-v2.txt;https://issues.apache.org/jira/secure/attachment/12453859/1463-v2.txt","04/Sep/10 15:02;jbellis;1463-v3.txt;https://issues.apache.org/jira/secure/attachment/12453867/1463-v3.txt","03/Sep/10 21:10;jbellis;1463.txt;https://issues.apache.org/jira/secure/attachment/12453827/1463.txt",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20154,,,Mon Dec 27 23:30:11 UTC 2010,,,,,,,,,,"0|i0g57r:",92275,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"03/Sep/10 20:56;brandon.williams;Fixed in 0.7 by CASSANDRA-757, but the approach we took for 0.6 was CASSANDRA-1289.  My guess is so many batch_mutate errors were being logged, logging consumed all the cpu before the gossiper timer could run again, which would have solved it.  I'm not sure how to solve this in 0.6 in a less invasive way than the 0.7 approach.;;;","03/Sep/10 21:10;jbellis;the CME is a red herring, the real problem is the NPE (caused by the IP being cleared out of the gossip records as indicated in the log, but not out of the pending ranges)

attached patch should fix the NPE, looking at how much of a bitch it would be to fix the root cause (the PR orphan);;;","04/Sep/10 03:30;jbellis;v2 adds an onRemove callback to the gossiper interface, to do the remove from TokenMetadata.;;;","04/Sep/10 03:31;jbellis;patch is against 0.6, i will handle rebase to 0.7 afterwards;;;","04/Sep/10 04:01;brandon.williams;v2 fails to compile:     [javac] /srv/cassandra/src/java/org/apache/cassandra/service/StorageLoadBalancer.java:49: org.apache.cassandra.service.StorageLoadBalancer is not abstract and does not override abstract method onRemove(java.net.InetAddress) in org.apache.cassandra.gms.IEndPointStateChangeSubscriber
;;;","04/Sep/10 04:14;jbellis;corrected v2.  (is it just me or is ""ant"" w/o ""clean"" getting worse at dependency discovery as we add more classes?);;;","04/Sep/10 05:32;brandon.williams;v2 produces this:


 INFO 05:26:36,245 FatClient /10.179.65.102 has been silent for 3600000ms, removing from gossip
ERROR 05:26:36,247 Uncaught exception in thread Thread[Timer-0,5,main]
java.lang.AssertionError
        at org.apache.cassandra.locator.TokenMetadata.removeEndpoint(TokenMetadata.java:192)
        at org.apache.cassandra.service.StorageService.onRemove(StorageService.java:879)
        at org.apache.cassandra.gms.Gossiper.removeEndPoint(Gossiper.java:221)
        at org.apache.cassandra.gms.Gossiper.doStatusCheck(Gossiper.java:407)
        at org.apache.cassandra.gms.Gossiper$GossipTimerTask.run(Gossiper.java:93)
        at java.util.TimerThread.mainLoop(Timer.java:534)
        at java.util.TimerThread.run(Timer.java:484)

But that is all I see, with constant insert pressure.;;;","04/Sep/10 15:02;jbellis;v3 removes obsolete assertion and adds call to calculatePendingRanges in onRemove.;;;","04/Sep/10 18:28;brandon.williams;Looks good now. +1;;;","04/Sep/10 20:34;jbellis;committed;;;","27/Dec/10 23:30;hudson;Integrated in Cassandra-0.7 #121 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/121/])
    Java-based stress util.  Patch by Pavel Yaskevich, reviewed by
brandonwilliams for CASSANDRA-1463
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SSTable cleanup killed by IllegalStateException,CASSANDRA-1458,12473181,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,cgist,cgist,02/Sep/10 19:51,16/Apr/19 09:33,14/Jul/23 05:51,07/Sep/10 18:33,0.6.6,0.7 beta 2,,,0,,,,,,"Compacted SSTables were not being deleted even after a forced GC. The following stack traces were observed:

ERROR [SSTABLE-CLEANUP-TIMER] 2010-09-01 15:54:07,254 CassandraDaemon.java (line 85) Uncaught exception in thread Thread[SSTABLE-CLEANUP-TIMER,5,main]
java.lang.IllegalStateException: Task already scheduled or cancelled
        at java.util.Timer.sched(Timer.java:380)
        at java.util.Timer.schedule(Timer.java:192)
        at org.apache.cassandra.io.sstable.SSTableDeletingReference$CleanupTask.run(SSTableDeletingReference.java:86)
        at java.util.TimerThread.mainLoop(Timer.java:534)
        at java.util.TimerThread.run(Timer.java:484)

ERROR [SSTABLE-DELETER] 2010-09-01 16:20:22,587 CassandraDaemon.java (line 85) Uncaught exception in thread Thread[SSTABLE-DELETER,5,main]
java.lang.IllegalStateException: Timer already cancelled.
        at java.util.Timer.sched(Timer.java:376)
        at java.util.Timer.schedule(Timer.java:192)
        at org.apache.cassandra.io.sstable.SSTableDeletingReference.cleanup(SSTableDeletingReference.java:70)
        at org.apache.cassandra.io.sstable.SSTableReader$1$1.run(SSTableReader.java:85)
        at java.lang.Thread.run(Thread.java:636)

If the SSTableDeletingReference$CleanupTask cannot delete a file, it reschedules itself for later. TimerTasks (which CleanupTask subclasses) are intended to be scheduled only once and will cause an IllegalStateException in the timer when it tries to schedule itself again. The exception causes timer to effectively cancel itself and the next attempt to schedule a task will cause an IllegalStateException in the SSTABLE-DELETER.

It appears this could be fixed by scheduling a new CleanupTask instead of the same one that failed (SSTableDeletingReference.java:86).","trunk from 2010-08-31
Linux 2.6.18-164.2.1.el5.plus #1 SMP x86_64
OpenJDK 64-Bit Server VM (build 1.6.0-b09)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Sep/10 14:41;jbellis;1458.txt;https://issues.apache.org/jira/secure/attachment/12454019/1458.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20151,,,Tue Sep 07 18:33:33 UTC 2010,,,,,,,,,,"0|i0g56n:",92270,,stuhood,,stuhood,Low,,,,,,,,,,,,,,,,,"02/Sep/10 22:27;jbellis;what was causing the original failure to delete?;;;","02/Sep/10 22:49;jbellis;I suspect retrying the delete is simply bogus -- if there is a race condition that would make the delete fail, we need to fix that; I can't think of another reason delete would succeed later after failing initially.

btw, are you running Windows?;;;","03/Sep/10 02:14;cgist;The cause of the failed delete is unknown. I was running Linux as in the updated environment.;;;","07/Sep/10 14:41;jbellis;patch attached;;;","07/Sep/10 14:44;jbellis;(patch is against 0.7; I will backport to 0.6 as well);;;","07/Sep/10 18:33;jbellis;+1'd by Stu in IRC. committed to 0.6 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
avro get_range_slices should default to CL.ONE,CASSANDRA-1456,12473167,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jeromatron,jeromatron,jeromatron,02/Sep/10 17:46,16/Apr/19 09:33,14/Jul/23 05:51,02/Sep/10 17:52,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Sep/10 17:47;jeromatron;0001-Adding-default-for-CL.ONE-for-get_range_slices.patch;https://issues.apache.org/jira/secure/attachment/12453705/0001-Adding-default-for-CL.ONE-for-get_range_slices.patch",,,,,,,,,,,,,,1.0,jeromatron,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20149,,,Thu Sep 02 17:52:35 UTC 2010,,,,,,,,,,"0|i0g567:",92268,,,,,Normal,,,,,,,,,,,,,,,,,"02/Sep/10 17:47;jeromatron;Added patch to make default in method itself, as defaults in IDL don't work like they do in thrift.;;;","02/Sep/10 17:52;brandon.williams;committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hadoop streaming -> Cassandra ColumnFamilyOutputFormat not respecting partitioner,CASSANDRA-1455,12473166,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,stuhood,mrflip,mrflip,02/Sep/10 17:42,16/Apr/19 09:33,14/Jul/23 05:51,04/Sep/10 18:20,,,,,0,,,,,,"The Hadoop streaming shim (hadoop streaming client => avro => ColumnFamilyOutputFormat => cassandra ring) is only connecting to one or a couple clients on the ring.  With 24 hadoop clients launched,  ` sudo netstat -antp | grep 9160 | wc -l ` gave 24 on one machine, and only 1-3 on any other node.

I'll attach the script and runner I used.","Ubuntu lucid ; Hadoop 0.20.1 CDH3b1 ; Cassandra 0.7beta1 + #1368, 1358, 1322, 1315 + patch to allow flat StreamingMutation avro schema",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Sep/10 17:45;mrflip;avromapper.rb;https://issues.apache.org/jira/secure/attachment/12453703/avromapper.rb","02/Sep/10 17:45;mrflip;streamer.sh;https://issues.apache.org/jira/secure/attachment/12453704/streamer.sh",,,,,,,,,,,,,2.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20148,,,Sat Sep 04 18:20:06 UTC 2010,,,,,,,,,,"0|i0g55z:",92267,,,,,Critical,,,,,,,,,,,,,,,,,"02/Sep/10 17:45;mrflip;Note that in its current state requires a patch to use flat avro schema.;;;","03/Sep/10 06:20;stuhood;Flip: could you try out the fix from CASSANDRA-1434?;;;","03/Sep/10 12:20;mrflip;I tried it with the first rev of the patches, no success; I see there was a second rev and I'll give that a shot in a bit.;;;","03/Sep/10 14:38;mrflip;I had a look at the code. I'm not really set up to debug Java atm, but did a finger trace thru.

In storeDescribedRing in RingCache, line 37 reads
 host = range.endpoints.get(0)
AFAICT, it's outside the loop over endpoints. Is it possible that host needs to be set inside the loop from the endpoints map?

flip
----
http://infochimps.org
Find any dataset in the world




;;;","03/Sep/10 17:26;stuhood;> host = range.endpoints.get(0)
Aha... good eye Flip. Looks like I broke that in 1322: so it is only collecting the primary endpoints. That makes the ""alternate through replicas of a range"" fix on 1434 moot, but you should still be seeing an even number of connections to all the nodes in your cluster.

I'll roll another 1434, but I don't have any other ideas here at the moment: in tests against a RF=1 12 node cluster (with OPP even), I saw an equal number of connections to all nodes, even with the above bug.;;;","04/Sep/10 18:20;mrflip;The combination of patches now shows inbound connections on all hosts in the ring. Thanks Stu!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
avronateSubcolumns was assuming an avro array.,CASSANDRA-1454,12473158,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,gdusbabek,gdusbabek,02/Sep/10 16:39,16/Apr/19 09:33,14/Jul/23 05:51,02/Sep/10 16:47,0.7 beta 2,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Sep/10 16:39;gdusbabek;ASF.LICENSE.NOT.GRANTED--v0-0001-avronateSubcolumns-was-assuming-avro-array.txt;https://issues.apache.org/jira/secure/attachment/12453693/ASF.LICENSE.NOT.GRANTED--v0-0001-avronateSubcolumns-was-assuming-avro-array.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20147,,,Thu Sep 02 16:41:52 UTC 2010,,,,,,,,,,"0|i0g55r:",92266,,,,,Low,,,,,,,,,,,,,,,,,"02/Sep/10 16:41;urandom;lgtm; +1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Memtable flush causes bad ""reversed"" get_slice",CASSANDRA-1450,12472952,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,thobbs,thobbs,31/Aug/10 17:14,16/Apr/19 09:33,14/Jul/23 05:51,05/Sep/10 03:31,0.7 beta 2,,,,2,,,,,,"If columns are inserted into a row before and after a memtable flush, a get_slice() after the flush with reversed=True will return incorrect results.  See attached patch to reproduce.",Cassandra Trunk,bhoyt,brandon.williams,phuongcsa,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Sep/10 14:52;jbellis;1450.txt;https://issues.apache.org/jira/secure/attachment/12453781/1450.txt","31/Aug/10 17:14;thobbs;reversed_slice_reproduce.txt;https://issues.apache.org/jira/secure/attachment/12453524/reversed_slice_reproduce.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20146,,,Sun Sep 05 03:31:40 UTC 2010,,,,,,,,,,"0|i0g54v:",92262,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"03/Sep/10 14:52;jbellis;patch applies reversed flag during collation from different data sources and makes QF.getColumnComparator package-private to make it more difficult to make the same mistake again.  unit test added to TableTest.;;;","03/Sep/10 16:05;brandon.williams;+1, though maybe the flush in the test should be explicit since it's not immediately obvious it will occur after 20 ops.;;;","05/Sep/10 03:31;jbellis;committed, w/ test adjusted as suggested;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SimpleAuthenticator MD5 support,CASSANDRA-1447,12472895,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,rnirmal,stuhood,stuhood,31/Aug/10 01:06,16/Apr/19 09:33,14/Jul/23 05:51,29/Sep/10 04:54,0.6.6,0.7 beta 2,,,0,,,,,,"...is broken, or not working as expected. Needs a look before 0.7.0.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Sep/10 20:15;rnirmal;0001-Fixed-MD5-support-in-SimpleAuthenticator.patch;https://issues.apache.org/jira/secure/attachment/12455074/0001-Fixed-MD5-support-in-SimpleAuthenticator.patch",,,,,,,,,,,,,,1.0,rnirmal,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20144,,,Wed Sep 29 04:54:32 UTC 2010,,,,,,,,,,"0|i0g547:",92259,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"08/Sep/10 01:52;stuhood;From Peter Nerg on CASSANDRA-1474:
{quote}
When running the SimpleAuthenticator in MD5 mode it will try to compare the plain text password with a MD5 digest from the passwd.properties file.
However the password in the property file is already a MD5 digest thus it's now digested twice.
Code snippet
""
case MD5:
authenticated = MessageDigest.isEqual(password.getBytes(), MessageDigest.getInstance(""MD5"").digest(props.getProperty(username).getBytes()));
break;
""
{quote};;;","25/Sep/10 23:58;jbellis;committed;;;","26/Sep/10 12:47;hudson;Integrated in Cassandra #547 (See [https://hudson.apache.org/hudson/job/Cassandra/547/])
    fix SimpleAuthenticator MD5 support
patch by Nirmal Ranganathan; reviewed by jbellis for CASSANDRA-1447
;;;","28/Sep/10 17:13;jbellis;re-opening for backport to 0.6;;;","29/Sep/10 04:54;jbellis;done for 0.6.6 too;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cli still relies on cassandra.in.sh instead of cassandra-env.sh,CASSANDRA-1446,12472890,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,brandon.williams,brandon.williams,30/Aug/10 22:45,16/Apr/19 09:33,14/Jul/23 05:51,31/Aug/10 03:15,0.6.6,0.7 beta 2,,,0,,,,,,"When we switched to cassandra-env.sh, we neglected to change the cli as well.  This leads to people unable to launch to the client due to heap size, and not having any idea how to change the heap for the cli itself.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20143,,,Sun Sep 12 19:39:05 UTC 2010,,,,,,,,,,"0|i0g53z:",92258,,,,,Low,,,,,,,,,,,,,,,,,"30/Aug/10 23:26;urandom;cassandra-cli never used the set of arguments from cassandra.in.sh which included (among other things) the heap size.  This was on purpose, the memory requirements of the CLI should be negligible, and there is definitely no correlation to the memory needed by the server. 

Do you know of a specific problem here? Can you provide any specifics?;;;","31/Aug/10 00:06;brandon.williams;The specific problem I'm seeing here is that the user can launch cassandra itself, but doesn't have enough memory to launch cassandra-cli afterwards, and there isn't an intuitive way to change cassandra-cli's heap.  I see cassandra-cli's script specifically trying to include cassandra.in.sh, though, on second look, it does not appear to be doing anything with it.  Maybe we should just remove the cassandra.in.sh cruft.;;;","31/Aug/10 02:57;urandom;{quote}
The specific problem I'm seeing here is that the user can launch cassandra itself, but doesn't have enough memory to launch cassandra-cli afterwards, and there isn't an intuitive way to change cassandra-cli's heap.
{quote}

Interesting.  I would have thought the default max heap size would be something... reasonable, but on my machine it seems to be 987MB (the hell?!).

Anyway, I just checked in a change that sets this to 256MB.  I don't know if that's the optimal value but it's considerably less than the almost-a-gig default.  The only reason it would ever need to be bigger than say 16MB is to buffer larger responses, and 256MB seems like a gracious plenty for any practical use of our CLI.

{quote}
I see cassandra-cli's script specifically trying to include cassandra.in.sh, though, on second look, it does not appear to be doing anything with it. Maybe we should just remove the cassandra.in.sh cruft.
{quote}

It is using it though, it's using it to setup the classpath; cassandra.in.sh is basically the common code for setting the classpath in all of those scripts.;;;","31/Aug/10 03:02;brandon.williams;256M works for me, but let's put this in 0.6 too.;;;","31/Aug/10 03:15;urandom;committed new max heap to 0.6 and trunk;;;","12/Sep/10 19:39;hudson;Integrated in Cassandra #533 (See [https://hudson.apache.org/hudson/job/Cassandra/533/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Get Range Slices is broken,CASSANDRA-1442,12472820,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,stuhood,molezam,molezam,29/Aug/10 20:18,16/Apr/19 09:33,14/Jul/23 05:51,09/Oct/10 01:37,0.6.6,0.7 beta 3,,,0,,,,,,"HI,
We just recently tried to use 0.6.4 and 0.6.5 in our production environment and
had some serious problem.
The getRangeSlices functionality is broken.
We have a cluster of 5 machines.
We use getRangeSlices to iterate over all of the keys in a cf (2062 keys total).
We are using OrderPreservingPartitioner.
We use getRangeSlices with KeyRange using keys (not tokens).
If we set the requestBlockCount (aka: KeyRange.setCount()) to a number
greater than 2062 we get all keys in one shot (all is good).
If we try to fetch the keys in smaller blocks (requestBlockCount=100)
we get BAD RESULTS.
We get only 800 unique keys back.
We start with (startKey="""" and endKey="""") then, after each iteration, we use the lastKey to set the startKey for the next page.
Except on first page, we always skip the first item of the page (knowing that it is a repeat, the last one, of the prior page).
To get the lastKey we tried two strategies: [1] set the lastKey to the last item in the page, and [2] use String.compareTo to get the largest ley. Neither strategy worked.
Our keys are strings (obviously the only option in 0.6) that represent numbers.
Some Sample keys are: (in correct lexi order)
-1
11113
11457
6831
7035
8060
8839
------
This code (without any changes) was working correctly under 0.6.3 (we
got same response from getRangeSlices if using requestBlockCounts of
10,000 or 100).
We tried it under 0.6.4 and 0.6.5 and it stopped working.
We reverted back to 0.6.3 and (again, without changing the code) it
started working again.
------
I tried inserting all the keys into a test cluster of one (1 machine) and it worked fine.
So this must be related to how the page is build in a cluster of more than 1 nodes.
We have a cluster of 5 nodes with replication factor of 3.",Linux - CentOs,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1505,,,,,"02/Oct/10 07:14;stuhood;0001-Add-tests-for-StorageProxy.getRestrictedRanges.patch;https://issues.apache.org/jira/secure/attachment/12456179/0001-Add-tests-for-StorageProxy.getRestrictedRanges.patch","02/Oct/10 07:14;stuhood;0002-Allow-ringIterator-to-include-the-minimum-token-and-.patch;https://issues.apache.org/jira/secure/attachment/12456180/0002-Allow-ringIterator-to-include-the-minimum-token-and-.patch","02/Oct/10 07:14;stuhood;0003-Split-the-queryRange-by-ring-and-minimum-tokens.patch;https://issues.apache.org/jira/secure/attachment/12456181/0003-Split-the-queryRange-by-ring-and-minimum-tokens.patch","02/Oct/10 07:17;stuhood;0004-Remove-restrictTo-and-unwrap.patch;https://issues.apache.org/jira/secure/attachment/12456182/0004-Remove-restrictTo-and-unwrap.patch","08/Oct/10 19:56;stuhood;for-trunk-0001-Add-tests-for-StorageProxy.getRestrictedRanges.patch;https://issues.apache.org/jira/secure/attachment/12456723/for-trunk-0001-Add-tests-for-StorageProxy.getRestrictedRanges.patch","08/Oct/10 19:56;stuhood;for-trunk-0002-Allow-ringIterator-to-include-the-minimum-token-and-.patch;https://issues.apache.org/jira/secure/attachment/12456724/for-trunk-0002-Allow-ringIterator-to-include-the-minimum-token-and-.patch","08/Oct/10 19:56;stuhood;for-trunk-0003-Split-the-queryRange-by-ring-and-minimum-tokens.patch;https://issues.apache.org/jira/secure/attachment/12456725/for-trunk-0003-Split-the-queryRange-by-ring-and-minimum-tokens.patch","08/Oct/10 19:57;stuhood;for-trunk-0004-Remove-AbstractBounds.restrictTo.patch;https://issues.apache.org/jira/secure/attachment/12456726/for-trunk-0004-Remove-AbstractBounds.restrictTo.patch",,,,,,,8.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20140,,,Sat Oct 09 01:37:06 UTC 2010,,,,,,,,,,"0|i0g533:",92254,,jbellis,,jbellis,Critical,,,,,,,,,,,,,,,,,"02/Oct/10 07:17;stuhood;0001 Adds tons of unit tests for StorageProxy.getRestrictedRanges
0002 Adds a flag to TokenMetadata.ringIterator to include the minimum token, to allow for cleaner iteration over split points
0003 Implement getRestrictedRanges using ringIterator and a new AbstractBounds.split method
0004 Remove old implementations;;;","02/Oct/10 07:19;stuhood;Patch applies to 0.6, but the tests should be forward ported.;;;","04/Oct/10 15:42;jbellis;02 seems like it shouldn't be necessary for a correct solution.  thoughts?;;;","04/Oct/10 15:54;stuhood;> 02 seems like it shouldn't be necessary for a correct solution. thoughts?
I don't see a cleaner alternative... finding the correct place to insert the minimum token without the support of the iterator implementation would mean peeking on it to see whether the next token wrapped. This solution is much shorter, and likely to have applications elsewhere in the codebase.;;;","08/Oct/10 19:57;stuhood;Attaching a port of this patch to trunk.;;;","09/Oct/10 01:37;jbellis;committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OPP makes HH unhappy,CASSANDRA-1439,12472648,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,jbellis,jbellis,26/Aug/10 21:47,16/Apr/19 09:33,14/Jul/23 05:51,27/Aug/10 19:42,0.7 beta 2,,,,0,,,,,,"as reported multiple times on the mailing list and IRC:

ERROR [HINTED-HANDOFF-POOL:1] 2010-08-26 15:58:20,310 CassandraDaemon.java (line 82) Uncaught exception in thread Thread[HINTED-HANDOFF-POOL:1,5,main]
java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.RuntimeException: The provided key was not UTF8 encoded.
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:87)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.RuntimeException: java.lang.RuntimeException: The provided key was not UTF8 encoded.
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        ... 2 more
Caused by: java.lang.RuntimeException: The provided key was not UTF8 encoded.
        at org.apache.cassandra.dht.OrderPreservingPartitioner.getToken(OrderPreservingPartitioner.java:169)
        at org.apache.cassandra.dht.OrderPreservingPartitioner.decorateKey(OrderPreservingPartitioner.java:41)
        at org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:199)
        at org.apache.cassandra.db.HintedHandOffManager.access$000(HintedHandOffManager.java:78)
        at org.apache.cassandra.db.HintedHandOffManager$1.runMayThrow(HintedHandOffManager.java:296)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 6 more
Caused by: java.nio.charset.MalformedInputException: Input length = 1
        at java.nio.charset.CoderResult.throwException(CoderResult.java:260)
        at java.nio.charset.CharsetDecoder.decode(CharsetDecoder.java:781)
        at org.apache.cassandra.utils.FBUtilities.decodeToUTF8(FBUtilities.java:483)
        at org.apache.cassandra.dht.OrderPreservingPartitioner.getToken(OrderPreservingPartitioner.java:165)
        ... 11 more",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Aug/10 19:04;brandon.williams;1439.txt;https://issues.apache.org/jira/secure/attachment/12453261/1439.txt",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20139,,,Fri Aug 27 19:42:34 UTC 2010,,,,,,,,,,"0|i0g52f:",92251,,,,,Normal,,,,,,,,,,,,,,,,,"27/Aug/10 19:04;brandon.williams;Patch to always use UTF-8 for hint keys.;;;","27/Aug/10 19:27;jbellis;+1 (w/ update to CHANGES);;;","27/Aug/10 19:42;brandon.williams;Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CommitLogHeader raises an AssertionError during  startup,CASSANDRA-1435,12472560,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,amorton,amorton,26/Aug/10 06:52,16/Apr/19 09:33,14/Jul/23 05:51,31/Aug/10 14:58,0.7 beta 2,,,,0,,,,,,"On a cluster that was pretty sick due to CASSANDRA-1416 and CASSANDRA-1432 I got the error below when starting up a node. The node failed to start.

After retrying the node started. 
ERROR [main] 2010-08-26 14:59:22,315 AbstractCassandraDaemon.java (line 107) Exception encountered during startup.
java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError
        at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:549)
        at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:339)
        at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:174)
        at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:120)
        at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:90)
        at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:224)
Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:545)
        ... 5 more
Caused by: java.lang.RuntimeException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError
        at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegments(CommitLog.java:408)
        at org.apache.cassandra.db.ColumnFamilyStore$2.runMayThrow(ColumnFamilyStore.java:445)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 6 more
Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegments(CommitLog.java:400)
        ... 8 more
Caused by: java.lang.AssertionError
        at org.apache.cassandra.db.commitlog.CommitLogHeader$CommitLogHeaderSerializer.serialize(CommitLogHeader.java:157)
        at org.apache.cassandra.db.commitlog.CommitLogHeader.writeCommitLogHeader(CommitLogHeader.java:124)
        at org.apache.cassandra.db.commitlog.CommitLogSegment.writeHeader(CommitLogSegment.java:70)
        at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegmentsInternal(CommitLog.java:450)
        at org.apache.cassandra.db.commitlog.CommitLog.access$300(CommitLog.java:75)
        at org.apache.cassandra.db.commitlog.CommitLog$6.call(CommitLog.java:394)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at org.apache.cassandra.db.commitlog.PeriodicCommitLogExecutorService$1.runMayThrow(PeriodicCommitLogExecutorService.java:52)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 1 more
",,johanoskarsson,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1376,,,,,,,"30/Aug/10 22:30;jbellis;ASF.LICENSE.NOT.GRANTED--0001-avoid-attempting-to-keep-CL-header-constant-size-schem.txt;https://issues.apache.org/jira/secure/attachment/12453471/ASF.LICENSE.NOT.GRANTED--0001-avoid-attempting-to-keep-CL-header-constant-size-schem.txt","30/Aug/10 22:30;jbellis;ASF.LICENSE.NOT.GRANTED--0002-r-m-forceNewSegment.txt;https://issues.apache.org/jira/secure/attachment/12453472/ASF.LICENSE.NOT.GRANTED--0002-r-m-forceNewSegment.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20137,,,Sun Sep 12 19:39:05 UTC 2010,,,,,,,,,,"0|i0g51j:",92247,,gdusbabek,,gdusbabek,Normal,,,,,,,,,,,,,,,,,"26/Aug/10 22:08;jbellis;a write during a schema change could cause adding an entry to the CLH dirty map, which the assert was dutifully noticing.

attached solution is to simply allow the map to grow; we can do this because we previously moved the header to a separate file, so restricting it to the same amount of bytes is no longer important.

does this mean we can drop all the forcenewsegment calls in the migration code?;;;","27/Aug/10 13:31;gdusbabek;>does this mean we can drop all the forcenewsegment calls in the migration code?
If the CLH is no longer bounded, yes.;;;","27/Aug/10 13:59;jbellis;-2 removes forcenewsegment.  (shouldn't be necessary for drain, either);;;","31/Aug/10 13:58;gdusbabek;+1;;;","31/Aug/10 14:55;jbellis;committed;;;","12/Sep/10 19:39;hudson;Integrated in Cassandra #533 (See [https://hudson.apache.org/hudson/job/Cassandra/533/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ColumnFamilyOutputFormat performs blocking writes for large batches,CASSANDRA-1434,12472542,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,stuhood,stuhood,25/Aug/10 23:20,16/Apr/19 09:33,14/Jul/23 05:51,27/Sep/10 22:30,0.7 beta 2,,,,0,,,,,,"By default, ColumnFamilyOutputFormat batches {{mapreduce.output.columnfamilyoutputformat.batch.threshold}} or {{Long.MAX_VALUE}} mutations, and then performs a blocking write.",,,,,,,,,,,,,,,,,,,CASSANDRA-1368,,,,,,,,,,,"08/Sep/10 00:16;stuhood;0001-Switch-away-from-Multimap-and-fix-regression-introdu.patch;https://issues.apache.org/jira/secure/attachment/12454059/0001-Switch-away-from-Multimap-and-fix-regression-introdu.patch","08/Sep/10 00:16;stuhood;0002-Improve-concurrency-and-add-basic-retries-by-attempt.patch;https://issues.apache.org/jira/secure/attachment/12454060/0002-Improve-concurrency-and-add-basic-retries-by-attempt.patch","19/Sep/10 00:42;stuhood;0003-Switch-RingCache-back-to-multimap.patch;https://issues.apache.org/jira/secure/attachment/12454961/0003-Switch-RingCache-back-to-multimap.patch","19/Sep/10 00:42;stuhood;0004-Replace-Executor-with-map-of-threads.patch;https://issues.apache.org/jira/secure/attachment/12454962/0004-Replace-Executor-with-map-of-threads.patch","19/Sep/10 15:44;jbellis;1434-v3.txt;https://issues.apache.org/jira/secure/attachment/12454975/1434-v3.txt","22/Sep/10 15:00;jbellis;1434-v4.txt;https://issues.apache.org/jira/secure/attachment/12455273/1434-v4.txt","22/Sep/10 20:51;jbellis;1434-v5.txt;https://issues.apache.org/jira/secure/attachment/12455309/1434-v5.txt","27/Sep/10 20:43;jbellis;1434-v6.txt;https://issues.apache.org/jira/secure/attachment/12455749/1434-v6.txt","27/Sep/10 21:18;jbellis;1434-v7.txt;https://issues.apache.org/jira/secure/attachment/12455757/1434-v7.txt",,,,,,9.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20136,,,Mon Sep 27 22:30:29 UTC 2010,,,,,,,,,,"0|i0g51b:",92246,,stuhood,,stuhood,Normal,,,,,,,,,,,,,,,,,"30/Aug/10 07:31;mrflip;The blocking behavior is causing 'broken pipe' errors (even with relatively small batch sizes) when cassandra latency is high. (This is afaict not network latency but response latency due to a compaction or flush, etc.)

It also makes the whole cluster resonate: one slow node blocks many writers, which then all unblock at the same time, write bursts of enough size to cause a compaction or GC, etc simultaneously on every node. This means adding more writers doesn't work around the blocking write;;;","03/Sep/10 06:19;stuhood;0001 and 0003 are minor fixes, but 0002:
* Avoids blocking processing for writes (but only 2 * batchSize mutations may be in memory at a time, so we may still block)
* Changes the default batchSize to 2^14
* Rotates through possible endpoints for a range per flush, which should more evenly distribute client connections when there are small numbers of keys in play

One issue we haven't tackled yet is how to handle failures: I've reopened CASSANDRA-1264 to handle that.;;;","03/Sep/10 06:24;stuhood;Doh... this applies atop CASSANDRA-1368.;;;","03/Sep/10 17:43;stuhood;0004 collects all replicas for each range in RingCache, which I broke in 1322 (previously, we were completely rebuilding the tokenmap using a replication strategy, which would have recreated the lost information).;;;","06/Sep/10 16:13;jbellis;why the double-flushing in close()?  can you add a comment for that?;;;","06/Sep/10 16:18;jbellis;committed 01.  declining to apply 03; in general refactoring out a method that is called in a single place obscures control flow rather than clarifies it.  04 looks ok but i'm not sure to what degree it depends on 02 (see above) so leaving alone for now.;;;","06/Sep/10 20:10;mrflip;Right now the code does { buffer n mutations, holding each  acc. to its endpoint. After n writes, check that all endpoint writes are finished, and dispatch to each endpoint its share of the n mutations }

This is non-blocking at the socket level but ends up being blocking at the app level, and the wide variance in size has bad effects on gc at the cassandra end.

I think the ColumnFamilyRecordWriter would see a speedup & improved stability with  { buffer mutations, holding each acc. to its endpoint. When an endpoint has seen n writes, check that any previous write has finished, and dispatch to this endpoint a full buffer of N mutations }.;;;","08/Sep/10 00:16;stuhood;0001 is changes to the RingCache that survived from v1: it fixes the bug in ringcache that was handled by pre-0004, and removes the multimap.

0002 is a completely revamped ColumnFamilyRecordWriter: nothing from the original patch survived.
* Launches a client thread per unique range, which is responsible for communicating with endpoint replicas for that range.
** The client threads receives mutations for the range from the parent thread on a bounded queue.
** Client threads will attempt to send a full batch of mutations to its replicas in order: this means that each batch gets up to RF retries before failing, but without any failures, connections will always be made to the first replica.
* The parent thread loops trying to offer to queues for client threads, and checks that they are still alive (and fails if they aren't).
* For a N node cluster, up to (2 * N * batchSize) mutations will be in memory at once, so the default batchSize was lowered to 4096.

Fairly well tested against a 12 node cluster: no obvious races or bottlenecks.;;;","08/Sep/10 15:16;jbellis;why is switching from Multimap<Range, InetAddress> to Map<Range, List<InetAddress>> an improvement?;;;","16/Sep/10 14:50;stuhood;Sent via e-mail while I was on vacation:
{quote}
I wanted to dodge object creation, but I guess I assumed that Multimap created Set and Collection facades for every call. Also, there didn't appear to be a way to iterate over unique keys without a facade.
{quote};;;","18/Sep/10 13:16;jbellis;Had a look at 02. Still don't understand your objection to using Multimap -- use ListMultimap if you want to preserve ordering.  It's noticeably cleaner than Map<X, List<Y>>, and the Guava guys are very careful about performance.

Also, 02 kind of abuses an executor when a map of threads would be clearer as to what is going on, while not requiring much more code.  ""Send this message"" is a good task to submit to an executor; ""run an infinite loop pulling messages off a public queue"" is not.;;;","19/Sep/10 00:42;stuhood;Adding 0003 and 0004 with the requested changes: exception handling was also improved a bit.;;;","19/Sep/10 15:44;jbellis;I squashed and added code to keep CFRW from slamming Cassandra with spikes of load: it keeps a pooled connection, and sends mutations one at a time over that.  This is only a trivial amount of overhead compared to using a large batch, since we're not reconnecting for each message.  (The main advantage of using a larger batch is that it gives you an idempotent group of work to replay if necessary, which doesn't matter here.  Under the hood it takes the same code path.)

Also attempted to distinguish between recoverable errors and non- in the exception handling.;;;","19/Sep/10 17:45;stuhood;* ArrayBlockingQueue.isEmpty will kill client threads if their queue is ever empty
* Interrupt handling doesn't seem like a clearer solution for killing client threads: what happens when an interrupt in received during a mutation?
* I don't like the idea of indefinite retries: pretending that the cluster is never unavailable sidesteps Hadoop's own retry system
* As mentioned in IRC, batchSize == 1 does not seem like a good value to hardcode. Any amount of overhead becomes measurable when you are sending small enough values: mutations containing a single integer might increase in size X fold for instance;;;","19/Sep/10 18:17;jbellis;bq. ArrayBlockingQueue.isEmpty will kill client threads if their queue is ever empty

it's while (run || isEmpty).  am i missing something?

bq. what happens when an interrupt in received during a mutation

nothing. InterruptedException is only thrown at well-defined points (one of the few times checked exceptions have done me a favor), and blocking socket send is not one of them.  the JDK uses this pattern to shut down threadpoolexecutors.

bq. I don't like the idea of indefinite retries

the idea is it tries each endpoint, then throws if they all fail. (if !iter.hasnext() then throw)

bq. batchSize == 1 does not seem like a good value to hardcode

as described above, batching > 1 is a misfeature that has been demonstrated to cause badness in practice.;;;","19/Sep/10 18:28;stuhood;> it's while (run || isEmpty). am i missing something?
Ah, sorry.

> the idea is it tries each endpoint, then throws if they all fail. (if !iter.hasnext() then throw)
Gotcha. I missed that part because there doesn't appear to be a way for the parent thread to figure out that a client died, so I assumed that the clients never died. Does it need an UncaughtExceptionHandler that alerts the parent thread? This was what was accomplished by using offer() rather than put() in the previous version.

> as described above, batching > 1 is a misfeature that has been demonstrated to cause badness in practice.
In Cassandra, or in general?;;;","19/Sep/10 18:33;jbellis;> Does it need an UncaughtExceptionHandler that alerts the parent thread?

Probably.  What should the parent thread do?

> In Cassandra, or in general?

In Cassandra.  Flip spent several days in the user IRC channel trying to deal with the load spikes.;;;","19/Sep/10 18:44;stuhood;> Probably. What should the parent thread do?
Probably what the previous version did.

> In Cassandra. Flip spent several days in the user IRC channel trying to deal with the load spikes.
Does changing this patch solve his problem, or are we assuming that?;;;","22/Sep/10 15:00;jbellis;v4 attached to throw IOException on put or stopNicely if the thread has errored out;;;","22/Sep/10 16:35;stuhood;* There is a race condition in put() between {{!run}} and the put itself
* Exceptions thrown by child threads will be logged, but not reported to the Hadoop frontend, since they aren't what kill the parent thread

I'm -0 on v3 and v4: but I'll add a 0005 to separate queue size from batch size, so that we can tune down the batch size for Flip.;;;","22/Sep/10 16:46;jbellis;i'm -1 on batching at all.;;;","22/Sep/10 20:51;jbellis;v5 uses a small batch size and eagerly sends out ""incomplete"" batches if the reducer falls behind;;;","23/Sep/10 01:22;stuhood;* ColumnFamilyOutputFormat.createAuthenticatedClient calls socket.open, so the second open in RangeClient is getting {{TTransportException: Socket already connected}}
* Logging a NPE for the first batch is pretty ugly
* The default batchSize was increased back up to Long.MAX_VALUE: it should probably be significantly lower (32~128) for the reasons you've mentioned;;;","27/Sep/10 20:43;jbellis;v6.

bq. There is a race condition in put() between !run and the put itself

not really.  the check in put is just an attempt to abort earlier if possible.

bq. Exceptions thrown by child threads will be logged, but not reported to the Hadoop frontend

saved actual exceptions.

bq. the second open in RangeClient is getting TTransportException: Socket already connected

fixed

bq. Logging a NPE for the first batch is pretty ugly

nothing is logged.  the alternatives strike me as uglier.

bq. The default batchSize was increased back up to Long.MAX_VALUE

fixed;;;","27/Sep/10 21:10;stuhood;This patch includes a change CompactionManager.java.

>> There is a race condition in put() between !run and the put itself
> not really. the check in put is just an attempt to abort earlier if possible.
put() is called from the parent thread: it isn't interrupted by the child thread, so it will block indefinitely if an exception occurs between lastException != null and the blocking put(). Unlikely, but...

----

Other than those two nitpicks, +1: tested against a 12 node cluster and saw smooth network utilization.;;;","27/Sep/10 21:18;jbellis;v7

bq. This patch includes a change CompactionManager.java

fixed

bq.  it will block indefinitely if an exception occurs between lastException != null and the blocking put()

you're right.  fixed;;;","27/Sep/10 22:00;stuhood;+1;;;","27/Sep/10 22:30;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nodetool cfstats broken on TRUNK,CASSANDRA-1433,12472528,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jjordan,jjordan,25/Aug/10 21:58,16/Apr/19 09:33,14/Jul/23 05:51,02/Sep/10 22:22,0.7 beta 2,,Tool/nodetool,,0,,,,,,"""nodetool -h localhost cfstats"" doesn't print anything.  Other commands work fine.
",windows and linux apache-cassandra-2010-08-23_13-57-40-bin.tar.gz,arya,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Aug/10 21:25;jbellis;1433.txt;https://issues.apache.org/jira/secure/attachment/12453171/1433.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20135,,,Sun Sep 12 19:39:04 UTC 2010,,,,,,,,,,"0|i0g513:",92245,,gdusbabek,,gdusbabek,Low,,,,,,,,,,,,,,,,,"25/Aug/10 22:00;jhermes;Confirmed this does not work on head right now either.
Ubuntu 10.04, sun-jdk-1.6


For cfstats to print -NOTHING-, then the cfstoreMap in NodeCmd must be empty, which means the iterator must also come back empty.;;;","26/Aug/10 21:25;jbellis;patch fixes ColumnFamilyStoreMBeanIterator to use new type name;;;","02/Sep/10 17:41;gdusbabek;+1;;;","02/Sep/10 22:22;jbellis;committed;;;","12/Sep/10 19:39;hudson;Integrated in Cassandra #533 (See [https://hudson.apache.org/hudson/job/Cassandra/533/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
java.util.NoSuchElementException when returning a node to the cluster,CASSANDRA-1432,12472526,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,amorton,amorton,25/Aug/10 21:40,16/Apr/19 09:33,14/Jul/23 05:51,26/Aug/10 22:14,0.6.6,0.7 beta 2,,,0,,,,,,"I'm running the v0.7-beta1 in a 4 nodes cluster and just doing some simple testing. One of the nodes had been down (machine off, unclean shutdown) for an hour or so not sure how many writes were going on, when I bought it back up this message appears in the other 3 nodes...


INFO [GOSSIP_STAGE:1] 2010-08-25 19:29:51,199 Gossiper.java (line 584) Node /192.168.34.27 has restarted, now UP again
 INFO [HINTED-HANDOFF-POOL:1] 2010-08-25 19:29:51,200 HintedHandOffManager.java (line 191) Started hinted handoff for endpoint /192.168.34.27
 INFO [GOSSIP_STAGE:1] 2010-08-25 19:29:51,201 StorageService.java (line 636) Node /192.168.34.27 state jump to normal
 INFO [GOSSIP_STAGE:1] 2010-08-25 19:29:51,201 StorageService.java (line 643) Will not change my token ownership to /192.168.34.27
ERROR [HINTED-HANDOFF-POOL:1] 2010-08-25 19:29:51,640 CassandraDaemon.java (line 82) Uncaught exception in thread Thread[HINTED-HANDOFF-POOL:1,5,main]
java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.util.NoSuchElementException
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:87)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.RuntimeException: java.util.NoSuchElementException
        at orgapache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        ... 2 more
Caused by: java.util.NoSuchElementException
        at java.util.concurrent.ConcurrentSkipListMap.lastKey(ConcurrentSkipListMap.java:1981)
        at java.util.concurrent.ConcurrentSkipListMap$KeySet.last(ConcurrentSkipListMap.java:2331)
        at org.apache.cassandra.db.HintedHandOffManager.sendMessage(HintedHandOffManager.java:121)
        at org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:218)
        at org.apache.cassandra.db.HintedHandOffManager.access$000(HintedHandOffManager.java:78)
        at org.apache.cassandra.db.HintedHandOffManager$1.runMayThrow(HintedHandOffManager.java:296) not sure how many writes were going on
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 6 more

On the machine that was off (34.27) there are no errors in the logs, and here are the entries for around the same time...

 INFO [main] 2010-08-25 19:29:50,679 CommitLog.java (line 340) Recovery complete
 INFO [main] 2010-08-25 19:29:50,769 CommitLog.java (line 180) Log replay complete
 INFO [main] 2010-08-25 19:29:50,797 StorageService.java (line 342) Cassandra version: 0.7.0-beta1-SNAPSHOT
 INFO [main] 2010-08-25 19:29:50,797 StorageService.java (line 343) Thrift API version: 10.0.0
 INFO [main] 2010-08-25 19:29:50,813 SystemTable.java (line 240) Saved Token found: 85070591730234615865843651857942052864
 INFO [main] 2010-08-25 19:29:50,813 SystemTable.java (line 257) Saved ClusterName found: FOO
 INFO [main] 2010-08-25 19:29:50,813 SystemTable.java (line 272) Saved partitioner not found. Using org.apache.cassandra.dht.RandomPartitioner
 INFO [main] 2010-08-25 19:29:50,814 ColumnFamilyStore.java (line 422) switching in a fresh Memtable for LocationInfo at CommitLogContext(file='/local1/junkbox/cassandra/commitlog/CommitLog-12827213897
70.log', position=41336)
 INFO [main] 2010-08-25 19:29:50,814 ColumnFamilyStore.java (line 706) Enqueuing flush of Memtable-LocationInfo@916236367(95 bytes, 2 operations)
 INFO [FLUSH-WRITER-POOL:1] 2010-08-25 19:29:50,815 Memtable.java (line 150) Writing Memtable-LocationInfo@916236367(95 bytes, 2 operations)
 INFO [FLUSH-WRITER-POOL:1] 2010-08-25 19:29:50,873 Memtable.java (line 157) Completed flushing /local1/junkbox/cassandra/data/system/LocationInfo-e-6-Data.db
 INFO [main] 2010-08-25 19:29:50,917 StorageService.java (line 374) Starting up server gossip
 INFO [main] 2010-08-25 19:29:51,093 ColumnFamilyStore.java (line 1239) Loaded 0 rows into the Super2 cache
 INFO [main] 2010-08-25 19:29:51,170 CassandraDaemon.java (line 153) Binding thrift service to /0.0.0.0:9160
 INFO [main] 2010-08-25 19:29:51,174 CassandraDaemon.java (line 167) Using TFramedTransport with a max frame size of 15728640 bytes.
 INFO [GOSSIP_STAGE:1] 2010-08-25 19:29:51,198 Gossiper.java (line 578) Node /192.168.34.28 is now part of the cluster
 INFO [GOSSIP_STAGE:1] 2010-08-25 19:29:51,199 Gossiper.java (line 578) Node /192.168.34.29 is now part of the cluster
 INFO [GOSSIP_STAGE:1] 2010-08-25 19:29:51,199 Gossiper.java (line 578) Node /192.168.34.26 is now part of the cluster
 INFO [main] 2010-08-25 19:29:51,204 CassandraDaemon.java (line 208) Listening for thrift clients...
 INFO [main] 2010-08-25 19:29:51,210 Mx4jTool.java (line 73) Will not load MX4J, mx4j-tools.jar is not in the classpath
 INFO [HINTED-HANDOFF-POOL:1] 2010-08-25 19:29:51,417 HintedHandOffManager.java (line 191) Started hinted handoff for endpoint /192.168.34.28
 INFO [GOSSIP_STAGE:1] 2010-08-25 19:29:51,417 Gossiper.java (line 570) InetAddress /192.168.34.28 is now UP
 INFO [HINTED-HANDOFF-POOL:1] 2010-08-25 19:29:51,418 HintedHandOffManager.java (line 247) Finished hinted handoff of 0 rows to endpoint /192.168.34.28
 INFO [HINTED-HANDOFF-POOL:1] 2010-08-25 19:29:51,855 HintedHandOffManager.java (line 191) Started hinted handoff for endpoint /192.168.34.29
 INFO [GOSSIP_STAGE:1] 2010-08-25 19:29:51,855 Gossiper.java (line 570) InetAddress /192.168.34.29 is now UP
 INFO [HINTED-HANDOFF-POOL:1] 2010-08-25 19:29:51,860 HintedHandOffManager.java (line 247) Finished hinted handoff of 0 rows to endpoint /192.168.34.29
 INFO [HINTED-HANDOFF-POOL:1] 2010-08-25 19:29:52,930 HintedHandOffManager.java (line 191) Started hinted handoff for endpoint /192.168.34.26
 INFO [GOSSIP_STAGE:1] 2010-08-25 19:29:52,930 Gossiper.java (line 570) InetAddress /192.168.34.26 is now UP
 INFO [HINTED-HANDOFF-POOL:1] 2010-08-25 19:29:52,930 HintedHandOffManager.java (line 247) Finished hinted handoff of 0 rows to endpoint /192.168.34.26

I ran a repair on all the nodes and this was all that they each logged 
 INFO [manual-repair-fe7c5abb-bb0a-4415-aa75-0d72ba4e7f1b] 2010-08-25 19:49:24,194 AntiEntropyService.java (line 803) Waiting for repair requests to: []

The cluster seemed OK and kept on working.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Aug/10 21:36;jbellis;1432-06.txt;https://issues.apache.org/jira/secure/attachment/12453173/1432-06.txt","26/Aug/10 21:37;jbellis;1432-trunk.txt;https://issues.apache.org/jira/secure/attachment/12453174/1432-trunk.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20134,,,Thu Aug 26 22:14:56 UTC 2010,,,,,,,,,,"0|i0g50v:",92244,,brandon.williams,,brandon.williams,Low,,,,,,,,,,,,,,,,,"26/Aug/10 06:41;amorton;I think this is stopping the HH and AE from running. 

I did the following:
- stopped a node
- deleted commit log and data dir for the keyspace 
- turned the node on 
- ran repair 

Then saw similar messages in the logs, with the repairing node logging the Waiting for repair requests to: [] message. No data was sent to the node. 

So my last comment about ""cluster seemed ok"" is probably wrong. 
;;;","26/Aug/10 07:52;stuhood;> Waiting for repair requests to: [] message.
This would imply that that node thinks the replication factor is 1, and that it therefore doesn't need to request trees.;;;","26/Aug/10 21:39;jbellis;the HH paging code doesn't handle zero columns found for the row, which could happen if cleanup removes the rows before they are handed off or if they are tombstoned and aged out during compaction.

patches attached for 0.6 and trunk;;;","26/Aug/10 22:05;brandon.williams;+1;;;","26/Aug/10 22:14;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SSTable statistics causing intermittent CL test failures in trunk.,CASSANDRA-1430,12472490,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,gdusbabek,gdusbabek,25/Aug/10 15:40,16/Apr/19 09:33,14/Jul/23 05:51,06/Sep/10 22:51,0.7 beta 2,,,,0,,,,,,"    [junit] Testcase: testCleanup(org.apache.cassandra.db.CommitLogTest):	FAILED
    [junit] 2 != 1
    [junit] junit.framework.AssertionFailedError: 2 != 1
    [junit] 	at org.apache.cassandra.db.CommitLogTest.testCleanup(CommitLogTest.java:69)
    [junit] 
    [junit] 

I see this 1-2 times a day.",,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Sep/10 01:08;brandon.williams;1430.txt;https://issues.apache.org/jira/secure/attachment/12453855/1430.txt",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20132,,,Sun Sep 12 19:39:07 UTC 2010,,,,,,,,,,"0|i0g50f:",92242,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"25/Aug/10 20:40;gdusbabek;To prove that I'm not hallucinating: http://ci.apache.org/builders/cassandra-trunk/builds/437/steps/compile/logs/stdio;;;","27/Aug/10 20:42;jbellis;this is caused by sstable statistics being written after the flush (see ssTableWriter.closeAndOpenReader)

is it time to admit that storing sstable info, in sstables, wasn't a good idea?;;;","27/Aug/10 20:44;jbellis;(this isn't just a test issue, i'm pretty sure it could bork drain, too);;;","27/Aug/10 22:20;gdusbabek;>is it time to admit that storing sstable info, in sstables, wasn't a good idea?
What if statistics operations ran on its own stage that could be halted at critical moments (flushing, for example).

;;;","27/Aug/10 22:33;jbellis;it already feels like a rather ugly set of workarounds, and maybe it's time to cut our losses;;;","27/Aug/10 22:43;gdusbabek;I can't disagree.  CASSANDRA-1382 should be on the list of things that get reverted when we figure out a better way of statistics.;;;","27/Aug/10 22:57;jbellis;Let's just create an EstimatedHistogram serializer and write out one for each of the row sizes and column counts.  SSTable.components will have to be updated.;;;","03/Sep/10 23:04;brandon.williams;Patch to remove sstable stats from the system table, and make them their own sstable component.;;;","04/Sep/10 00:51;jbellis;I'm getting build errors in a couple test classes;;;","04/Sep/10 01:08;brandon.williams;Oops, I'd forgotten about more tests being added due to CASSANDRA-1155's problems.  Patch updated to fix tests.;;;","04/Sep/10 01:29;jbellis;+1;;;","04/Sep/10 03:32;brandon.williams;Committed.;;;","06/Sep/10 19:30;jbellis;this broke StreamingTransferTest (easy to miss in the ant output because it is a timeout rather than a failure);;;","06/Sep/10 22:51;jbellis;fixed by CASSANDRA-1471;;;","12/Sep/10 19:39;hudson;Integrated in Cassandra #533 (See [https://hudson.apache.org/hudson/job/Cassandra/533/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The dynamic snitch can't be used with network topology strategies,CASSANDRA-1429,12472473,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,slebresne,slebresne,25/Aug/10 13:27,16/Apr/19 09:33,14/Jul/23 05:51,25/Aug/10 16:00,0.6.6,0.7 beta 2,,,0,,,,,,also ported to 0.6 and committed there,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/10 13:27;slebresne;0001-Make-DynamicEndpointSnitch-a-subclass-of-AbstractNet.patch;https://issues.apache.org/jira/secure/attachment/12453033/0001-Make-DynamicEndpointSnitch-a-subclass-of-AbstractNet.patch","25/Aug/10 14:06;jbellis;1429-v2.txt;https://issues.apache.org/jira/secure/attachment/12453040/1429-v2.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20131,,,Wed Aug 25 16:00:32 UTC 2010,,,,,,,,,,"0|i0g507:",92241,,slebresne,,slebresne,Normal,,,,,,,,,,,,,,,,,"25/Aug/10 14:05;jbellis;this breaks DES, the whole point is that it uses a different sort than ANTS.

the right fix is to get rid of the obsolete casts in the Strategy classes, the methods they want are all on IES now.

attached.;;;","25/Aug/10 15:25;slebresne;I agree the second patch is a better alternative. But I think that the casts to AbstractNetworkTopologySnitch in DatacenterWriteResponseHandler.java, /DatacenterSyncWriteResponseHandler.java and DatacenterQuorumResponseHandler.java should also go away.;;;","25/Aug/10 16:00;jbellis;(for the record, as discussed in IRC, I was wrong about Sylvain's original patch breaking DES)

Committed v2 w/ above changes;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rejecting keyspace creation when RF > N is incorrect,CASSANDRA-1428,12472428,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,moonpolysoft,moonpolysoft,24/Aug/10 23:29,16/Apr/19 09:33,14/Jul/23 05:51,06/Oct/10 19:36,0.7 beta 3,,,,0,,,,,,"The behavior introduced in this patch http://www.mail-archive.com/commits@cassandra.apache.org/msg05913.html is incorrect.

Disallowing keyspace creation when RF > N is semantically incorrect and makes both scaling a cluster up and down more difficult than it should be.  This is compounded by the current lack of any API methods to change the replication factor.  Most dynamo style systems allow RF to be set > N for smaller clusters.  The cluster will behave as if RF = N until enough nodes are added such that RF < N.",,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1343,,,,,"05/Oct/10 11:15;jbellis;1428.txt;https://issues.apache.org/jira/secure/attachment/12456378/1428.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20130,,,Tue Oct 12 14:03:55 UTC 2010,,,,,,,,,,"0|i0g4zz:",92240,,gdusbabek,,gdusbabek,Low,,,,,,,,,,,,,,,,,"25/Aug/10 13:08;gdusbabek;>Most dynamo style systems allow RF to be set > N for smaller clusters.
Implementing this would add substantial complexity to the replication and bootstrap code.  It's a trade-off not currently worth the flexibility imo.

I am in favor of allowing the creation of keyspaces with RF > N though (letting high CL reads/writes fail).  This worked fine until r959726 changed RackUnawareStrategy (now SimpleStrategy) to throw IllegalStateException when N < RF.  I argued (unsuccessfully) that the throw should happen elsewhere, or at least it shouldn't care when there was no data to bootstrap.

fwiw, modifying the replication factor (and other CF and KS properties) is on its way.  See CASSANDRA-1285.  It will be ready when 0.7 ships.;;;","21/Sep/10 15:41;jbellis;Wait, how is ""allowing the creation of keyspaces with RF > N"" that you are in favor of different from ""allow[ing] RF to be set > N"" that you are not?;;;","21/Sep/10 15:42;jbellis;incidently, in r999469 I changed this from using live node count as N to using total known cluster members as N.;;;","21/Sep/10 16:04;gdusbabek;I interpreted ""RF to be set > N for smaller clusters"" as meaning, ""let high-CL writes succeed even though we don't have enough nodes to support the RF when N is small.""  I don't think we should allow that.

From an syspop pov, I think we should allow the creation of keyspaces where RF > N.  There is no harm in this for new keyspaces where there is nothing to stream.
;;;","21/Sep/10 16:28;jbellis;I see, you want to allow creating the KS, but not writing to it.  (Is this what you want too, Cliff?)

My reasoning for wanting to prevent creation was, if we're not going to allow writing to it, better to fail early rather than surprise people later on.  But I am okay with taking that check out if the cure is worse than the disease.

I definitely think the semantics of actually trying to allow writes in a RF > N situation are unclear and would rather avoid that.;;;","21/Sep/10 16:36;moonpolysoft;This ticket was specifically in reference to creation of a keyspace with RF > N.  Since all of the schema stuff now is the responsibility of an api client instead of a config, it would require clients to make different schemas say if they were in a testing environment with fewer machines than production.

;;;","30/Sep/10 02:24;jbellis;So we all agree that creation is fine, so let's allow that.  (Less sure that Cliff agrees that we should reject writes that can't satisfy the RF, but I won't argue that point unless there's actually something to disagree about. :);;;","05/Oct/10 12:56;gdusbabek;How about a system test that verifies that a keyspace with RF > N can be created?  With this patch SS.loadSchemaFromYAML() doesn't work when RF > N.;;;","06/Oct/10 19:36;jbellis;added test and fixed loadSchemaFromYAML which was doing a separate check.;;;","12/Oct/10 14:03;hudson;Integrated in Cassandra #563 (See [https://hudson.apache.org/hudson/job/Cassandra/563/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
multiget_count() should not take a keyspace arg,CASSANDRA-1422,12472286,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jhermes,cgist,cgist,23/Aug/10 19:09,16/Apr/19 09:33,14/Jul/23 05:51,24/Aug/10 14:44,0.7 beta 2,,,,0,,,,,,"With the addition of set_keyspace(), things that are scoped by keyspace should no longer take keyspace args.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Aug/10 21:49;jhermes;1422.txt;https://issues.apache.org/jira/secure/attachment/12452861/1422.txt",,,,,,,,,,,,,,1.0,jhermes,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20128,,,Tue Aug 24 14:44:22 UTC 2010,,,,,,,,,,"0|i0g4yn:",92234,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"23/Aug/10 21:49;jhermes;Remove one line from cassandra.thrift.
Change keyspace arg to keySpace.get() in CassandraServer#multiget_count.
Change test to not pass in a keyspace arg.

Thrift API version needs to be bumped.;;;","24/Aug/10 14:44;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SStableSliceIterator leaks FDs,CASSANDRA-1416,12472125,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,20/Aug/10 20:33,16/Apr/19 09:33,14/Jul/23 05:51,20/Aug/10 20:43,0.7 beta 2,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Aug/10 20:34;jbellis;1416.txt;https://issues.apache.org/jira/secure/attachment/12452661/1416.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20127,,,Sat Aug 21 11:14:31 UTC 2010,,,,,,,,,,"0|i0g4xb:",92228,,brandon.williams,,brandon.williams,Normal,,,,,,,,,,,,,,,,,"20/Aug/10 20:39;brandon.williams;+1;;;","20/Aug/10 20:43;jbellis;committed;;;","21/Aug/10 11:14;hudson;Integrated in Cassandra #518 (See [https://hudson.apache.org/hudson/job/Cassandra/518/])
    fix FD leak in single-row slicepredicate queries.
patch by jbellis; reviewed by brandonwilliams for CASSANDRA-1416
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
EstimatedHistogram.max is buggy,CASSANDRA-1413,12472062,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,20/Aug/10 06:56,16/Apr/19 09:33,14/Jul/23 05:51,25/Aug/10 20:36,0.7 beta 2,,,,0,,,,,,"EH.max returns the largest bucket floor, which will will be LESS than the largest value added to the histogram, which is not the usual behavior expected of a method called max.",,brandon.williams,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Aug/10 22:13;brandon.williams;0002_adjust_EH_sizes.txt;https://issues.apache.org/jira/secure/attachment/12452866/0002_adjust_EH_sizes.txt","20/Aug/10 06:58;jbellis;1413.txt;https://issues.apache.org/jira/secure/attachment/12452610/1413.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20126,,,Wed Aug 25 20:36:16 UTC 2010,,,,,,,,,,"0|i0g4wn:",92225,,brandon.williams,,brandon.williams,Low,,,,,,,,,,,,,,,,,"20/Aug/10 18:46;brandon.williams;Isn't the ISE being thrown here going to get raised in CFS when cfstats is called?;;;","20/Aug/10 19:03;jbellis;Dunno, that's why I wanted you to review.  You sized those EHes. :)

Isn't the ""right"" solution just to make them large enough?

Open to other ideas.;;;","23/Aug/10 22:13;brandon.williams;I think we need to adjust the sizes a bit.  Bump the column count EH to 114, giving us a max of about 2.4B columns (113 allows for 1996099046), and bump the row size EH to 150, allowing for almost a 1.7T row.  It's theoretically possible to make a row larger than that, but I think having cfstats throw an exception will be the least of the user's problems at that point.;;;","25/Aug/10 20:36;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FBUtilities.hexToBytes() doesn't accommodate odd-length strings.,CASSANDRA-1411,12472038,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,gdusbabek,gdusbabek,19/Aug/10 20:49,16/Apr/19 09:33,14/Jul/23 05:51,19/Aug/10 21:02,0.7 beta 2,,,,0,,,,,,"This is a problem when a user specifies ByteOrderedPartitioner with an odd-length initial token (like ""0"").",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/10 20:53;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-FBUtilities.hexToBytes-doesn-t-handle-odd-length-strin.txt;https://issues.apache.org/jira/secure/attachment/12452572/ASF.LICENSE.NOT.GRANTED--v1-0001-FBUtilities.hexToBytes-doesn-t-handle-odd-length-strin.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20124,,,Sat Aug 21 11:14:34 UTC 2010,,,,,,,,,,"0|i0g4w7:",92223,,,,,Low,,,,,,,,,,,,,,,,,"19/Aug/10 20:56;jhermes;+1 anti-annoyance patch.;;;","20/Aug/10 15:56;messi;Good ol' well-thought pragmatism? Why sanitize user input and adjust the token when you can hide errors by making core functions more flexible.;;;","20/Aug/10 16:02;gdusbabek;Erroring on odd-lengthed, yet still valid hex values is neither pragmatic or very useful.  hex 0 is dec 0, hex 101 is dec 257, so is hex 0101; let's just handle them.;;;","21/Aug/10 11:14;hudson;Integrated in Cassandra #518 (See [https://hudson.apache.org/hudson/job/Cassandra/518/])
    FBUtilities.hexToBytes doesn't handle odd-length strings. patch by Gary Dusbabek, reviewed by Jon Hermes. CASSANDRA-1411
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nodetool drain attempts to delete a deleted file,CASSANDRA-1408,12471949,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,brandon.williams,jhermes,jhermes,18/Aug/10 21:49,16/Apr/19 09:33,14/Jul/23 05:51,10/Dec/10 17:36,0.6.9,0.7 beta 2,,,0,,,,,,"Running `nodetool drain` presented me with a pretty stack-trace.
The drain itself finished successfully and nothing showed up in the system.log.

{noformat}
$ bin/nodetool -h 127.0.0.1 -p 8080 drain
Exception in thread ""main"" java.lang.AssertionError: attempted to delete non-existing file CommitLog-1282166457787.log
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:40)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:178)
	at org.apache.cassandra.service.StorageService.drain(StorageService.java:1653)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)
	at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:120)
	at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:262)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:836)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:761)
	at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1427)
	at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:72)
	at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1265)
	at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1360)
	at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:788)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:305)
	at sun.rmi.transport.Transport$1.run(Transport.java:159)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.Transport.serviceCall(Transport.java:155)
	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
{noformat}",sun-jdk-1.6/Ubuntu 10.04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Dec/10 22:50;brandon.williams;1408-0.6.txt;https://issues.apache.org/jira/secure/attachment/12465949/1408-0.6.txt","07/Sep/10 14:15;jbellis;1408.txt;https://issues.apache.org/jira/secure/attachment/12454016/1408.txt",,,,,,,,,,,,,2.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20123,,,Fri Dec 10 18:48:42 UTC 2010,,,,,,,,,,"0|i0g4vj:",92220,,gdusbabek,,gdusbabek,Low,,,,,,,,,,,,,,,,,"18/Aug/10 21:57;jbellis;this may be a problem in 0.6 as well.;;;","02/Sep/10 22:42;jbellis;why are we even calling CommitLog.recover() during drain?;;;","03/Sep/10 12:54;gdusbabek;No good reason that I can think of.  At the time I remember the complaint was that shutting down left uncommitted updates in the CL, but flushing solves that.;;;","03/Sep/10 14:26;jbellis;I think the recover can be necessary b/c we don't shut down mutations until after the flushes.  Attached patch fixes ordering there (and adds wait on postFlushExecutor for maximum correctness).

(As for the error on recover() itself, that is/will be addressed in CASSANDRA-1348.);;;","07/Sep/10 13:45;gdusbabek;patch needs rebase.;;;","07/Sep/10 14:15;jbellis;rebased;;;","07/Sep/10 15:52;gdusbabek;+1;;;","07/Sep/10 16:27;jbellis;committed;;;","19/Sep/10 02:30;phuongcsa;java.lang.AssertionError: attempted to delete non-existing file Walls-e-25-Statistics.db
        at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:43)
        at org.apache.cassandra.io.sstable.SSTable.deleteIfCompacted(SSTable.java:135)
        at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:174)
        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:343)
        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:309)
        at org.apache.cassandra.db.Table.initCf(Table.java:296)
        at org.apache.cassandra.db.Table.<init>(Table.java:245)
        at org.apache.cassandra.db.Table.open(Table.java:104)
        at org.apache.cassandra.config.DatabaseDescriptor.loadSchemas(DatabaseDescriptor.java:461)
        at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:105)
        at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:98)
        at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:216)


I have installed this patch, however bug is not resolved.

Cassandra 0.7 beta1, Ubuntu 10.04;;;","09/Dec/10 22:35;brandon.williams;Reopened for backport to 0.6;;;","09/Dec/10 23:26;lenn0x;Brandon,

I verified this with 0.6 branch. Error occurs without patch. Applied with patch, no more errors. Thx!;;;","10/Dec/10 16:33;jbellis;+1;;;","10/Dec/10 17:36;brandon.williams;Committed.;;;","10/Dec/10 18:48;hudson;Integrated in Cassandra-0.6 #22 (See [https://hudson.apache.org/hudson/job/Cassandra-0.6/22/])
    correct ordering of drain operations so CL.recover is no longer necessary.  Patch by jbellis and brandonwilliams, reviewed by jbellis for CASSANDRA-1408
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
debian init script could be more consistent w/ bin/cassandra,CASSANDRA-1407,12471941,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,urandom,urandom,urandom,18/Aug/10 20:17,16/Apr/19 09:33,14/Jul/23 05:51,18/Aug/10 21:11,0.7 beta 2,,Packaging,,0,,,,,,"With the introduction of conf/cassandra-env.sh it should be possible to eliminate the separately maintained /etc/default/cassandra.  The init script should also use a JAVA_HOME derived from the java binary in PATH (if it exists), both because this is how things work in Debian (_the_ Java is the one chosen by alternatives), and because this is how bin/cassandra works as well.

Patches to follow.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/10 20:20;urandom;ASF.LICENSE.NOT.GRANTED--v2-0001-CASSANDRA-1407-refactor-assigment-of-JAVA_HOME-in-init.txt;https://issues.apache.org/jira/secure/attachment/12452452/ASF.LICENSE.NOT.GRANTED--v2-0001-CASSANDRA-1407-refactor-assigment-of-JAVA_HOME-in-init.txt","18/Aug/10 20:20;urandom;ASF.LICENSE.NOT.GRANTED--v2-0002-CASSANDRA-1407-use-conf-cassandra-env.sh-in-place-of-d.txt;https://issues.apache.org/jira/secure/attachment/12452453/ASF.LICENSE.NOT.GRANTED--v2-0002-CASSANDRA-1407-use-conf-cassandra-env.sh-in-place-of-d.txt",,,,,,,,,,,,,2.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20122,,,Sat Aug 21 11:14:37 UTC 2010,,,,,,,,,,"0|i0g4vb:",92219,,,,,Normal,,,,,,,,,,,,,,,,,"18/Aug/10 20:58;brandon.williams;+1;;;","18/Aug/10 21:11;urandom;committed.;;;","21/Aug/10 11:14;hudson;Integrated in Cassandra #518 (See [https://hudson.apache.org/hudson/job/Cassandra/518/])
    use conf/cassandra-env.sh in place of defaults

Patch by eevans; reviewed by Brandon Williams for CASSANDRA-1407
refactor assigment of JAVA_HOME in init script

Path by eevans; review by Brandon Williams for CASSANDRA-1407
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Dropping column families doesn't clean up secondary indexes,CASSANDRA-1406,12471923,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,gdusbabek,gdusbabek,18/Aug/10 16:58,16/Apr/19 09:33,14/Jul/23 05:51,27/Aug/10 20:20,0.7 beta 2,,Feature/2i Index,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Aug/10 18:22;gdusbabek;0003-extract-unload-out-of-drop.patch;https://issues.apache.org/jira/secure/attachment/12453257/0003-extract-unload-out-of-drop.patch","26/Aug/10 21:07;jbellis;ASF.LICENSE.NOT.GRANTED--0001-replace-CF-graveyard-with-CFS.removeAllSSTables-which-.txt;https://issues.apache.org/jira/secure/attachment/12453167/ASF.LICENSE.NOT.GRANTED--0001-replace-CF-graveyard-with-CFS.removeAllSSTables-which-.txt","26/Aug/10 21:07;jbellis;ASF.LICENSE.NOT.GRANTED--0002-include-secondary-indexes-in-CF-and-KS-renaming.txt;https://issues.apache.org/jira/secure/attachment/12453168/ASF.LICENSE.NOT.GRANTED--0002-include-secondary-indexes-in-CF-and-KS-renaming.txt",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20121,,,Fri Aug 27 20:20:55 UTC 2010,,,,,,,,,,"0|i0g4v3:",92218,,gdusbabek,,gdusbabek,Normal,,,,,,,,,,,,,,,,,"26/Aug/10 17:41;jbellis;patch replaces CF graveyard with CFS.removeAllSSTables (which is recursive to handle 2ary index files);;;","26/Aug/10 18:39;gdusbabek;putting the deletion in Table.dropCF() is risky wrt KS and CF renames.  It won't hurt anything right now because the delete tries to remove the old files.  If that side-effect ever went away we'd be deleting valid files.  As it stands with this patch we'd be trying to do cleanup of sstables that have had their files moved out from underneath them, which probably isn't the best thing to try.

Is this a good ticket to lump in that RenameKeyspace and RenameColumnFamily don't address secondary indices, or should that be a new one?;;;","26/Aug/10 21:01;jbellis;otoh, requiring the caller who calls dropCf to also call other methods to finish the job is poor encapsulation, and implementing rename as drop + add is itself an implementation detail.  neither approach is completely satisfactory imo.

02 adds support for 2ary indexes in the rename methods.;;;","26/Aug/10 21:07;jbellis;(tweaked DefsTest to not require renaming to leave an empty directory behind for the old name);;;","27/Aug/10 18:22;gdusbabek;dropCf was intended to unload a CFS from a table instance as indicated in its comment.  0003 cleans the interface up so that renaming acts on files like drop does.;;;","27/Aug/10 18:23;gdusbabek;+1, but I'd like 0003 to be included.;;;","27/Aug/10 20:20;jbellis;committed w/ 03;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CFMetaData id gets out of sync,CASSANDRA-1403,12471843,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,17/Aug/10 20:32,16/Apr/19 09:33,14/Jul/23 05:51,17/Aug/10 21:44,0.7 beta 2,,,,0,,,,,,"stand up two nodes.
load a KS + cf on A.
add another CF on A.
Let the cluster quiesce.
add a CF on B.

You get the out of sync error.  I'm pretty sure this is because AddColumnFamily doesn't CFM.fixMaxId() like AddKeyspace does.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/10 20:58;gdusbabek;ASF.LICENSE.NOT.GRANTED--v0-0001-fix-max-id-after-adding-a-column-family.txt;https://issues.apache.org/jira/secure/attachment/12452322/ASF.LICENSE.NOT.GRANTED--v0-0001-fix-max-id-after-adding-a-column-family.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20120,,,Wed Aug 18 13:13:50 UTC 2010,,,,,,,,,,"0|i0g4uf:",92215,,,,,Normal,,,,,,,,,,,,,,,,,"17/Aug/10 21:20;stuhood;+1
I expect that cfId generation is going to need to change significantly to allow for concurrent schema changes.;;;","17/Aug/10 21:40;gdusbabek;It will need to act like a distributed counter.;;;","18/Aug/10 13:13;hudson;Integrated in Cassandra #517 (See [https://hudson.apache.org/hudson/job/Cassandra/517/])
    fix max id after adding a column family. patch by gdusbabek, reviewed by stuhood. CASSANDRA-1403
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
indexed writes fail with exception,CASSANDRA-1402,12471824,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,urandom,urandom,17/Aug/10 17:16,16/Apr/19 09:33,14/Jul/23 05:51,13/Sep/10 04:46,0.7 beta 2,,,,0,,,,,,"Indexed writes fail with an ArrayIndexOutOfBoundsException depending on the length of the key:


{noformat}
java.lang.RuntimeException: java.lang.ArrayIndexOutOfBoundsException: -95
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)
Caused by: java.lang.ArrayIndexOutOfBoundsException: -95
	at org.apache.cassandra.db.Table.apply(Table.java:379)
	at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:196)
	at org.apache.cassandra.service.StorageProxy$1.runMayThrow(StorageProxy.java:194)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
	... 3 more
{noformat}

The patch that follows updates ColumnFamilyStoreTest to demonstrate.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/10 20:31;jbellis;1402.txt;https://issues.apache.org/jira/secure/attachment/12452310/1402.txt","17/Aug/10 17:17;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1402-make-test-case-fail-with-ArrayIndexOutO.txt;https://issues.apache.org/jira/secure/attachment/12452294/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1402-make-test-case-fail-with-ArrayIndexOutO.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20119,,,Wed Aug 18 13:13:51 UTC 2010,,,,,,,,,,"0|i0g4u7:",92214,,,,,Normal,,,,,,,,,,,,,,,,,"17/Aug/10 20:31;jbellis;that was embarassing.;;;","17/Aug/10 20:56;urandom;LGTM. +1;;;","18/Aug/10 13:13;hudson;Integrated in Cassandra #517 (See [https://hudson.apache.org/hudson/job/Cassandra/517/])
    fix sharded lock hashing on index write path.  patch by jbellis; reviewed by eevans for CASSANDRA-1402
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLI addColumnFamily - setting read_repair_chance modifies the keys_cache_size instead,CASSANDRA-1399,12471759,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,rnirmal,rnirmal,rnirmal,16/Aug/10 22:43,16/Apr/19 09:33,14/Jul/23 05:51,17/Aug/10 15:20,0.7 beta 2,,Legacy/Tools,,0,,,,,,"case KEY_CACHE_SIZE:
                cfDef.setKey_cache_size(Double.parseDouble(mValue));
                break;

case READ_REPAIR_CHANCE:
                cfDef.setKey_cache_size(Double.parseDouble(CliUtils.unescapeSQLString(mValue)));
                break;

Also it would be good to add gc_grace_seconds for this operation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Aug/10 22:55;rnirmal;0001-1399-CliClient-fixed-read_repair_chance-case.patch;https://issues.apache.org/jira/secure/attachment/12452225/0001-1399-CliClient-fixed-read_repair_chance-case.patch",,,,,,,,,,,,,,1.0,rnirmal,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20117,,,Wed Aug 18 13:13:47 UTC 2010,,,,,,,,,,"0|i0g4tj:",92211,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"17/Aug/10 15:20;jbellis;committed;;;","18/Aug/10 13:13;hudson;Integrated in Cassandra #517 (See [https://hudson.apache.org/hudson/job/Cassandra/517/])
    fix setting read_repair_chance from CLI addColumnFamily.  patch by Nirmal Ranganathan; reviewed by jbellis for CASSANDRA-1399
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Blank listen_address/rpc_address no longer binds based on hostname,CASSANDRA-1394,12471650,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,brandon.williams,brandon.williams,15/Aug/10 20:11,16/Apr/19 09:33,14/Jul/23 05:51,16/Aug/10 16:49,0.7 beta 2,,,,0,,,,,,"With the switch to yamlbeans, if I make listen_address or rpc_address blank, they bind to localhost.  Instead, they should bind to whatever hostname and /etc/hosts point at.  This makes it much easier to use a unified config across a cluster.  Also, yamlbeans doesn't respect the 'null' keyword, which should be the same as a blank value, but is instead treated as a literal string.  This makes programmatic generation of the config file difficult.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20115,,,Tue Aug 17 12:59:50 UTC 2010,,,,,,,,,,"0|i0g4sf:",92206,,,,,Normal,,,,,,,,,,,,,,,,,"16/Aug/10 16:49;jbellis;reverted the yamlbeans switch.;;;","17/Aug/10 12:59;hudson;Integrated in Cassandra #516 (See [https://hudson.apache.org/hudson/job/Cassandra/516/])
    revert switch to yamlbeans.  patch by jbellis; reviewed by Jon Hermes for CASSANDRA-1394
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
nodetool cfstats does not update after adding new cfs through API,CASSANDRA-1385,12471485,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,arya,arya,13/Aug/10 02:41,16/Apr/19 09:33,14/Jul/23 05:51,18/Aug/10 19:16,0.7 beta 2,,,,0,,,,,,Start a 3 node cluster. Add a new Keyspace with API. Then add more CFs to that Keyspace. ndoetool cfstats will only show you the CF which was originally part of KsDef creation and not the CfDefs that were added later.,"CentOS 5.2
Trunc",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/10 16:26;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-make-CFS-constructor-responsible-for-registering-mbean.txt;https://issues.apache.org/jira/secure/attachment/12452414/ASF.LICENSE.NOT.GRANTED--v1-0001-make-CFS-constructor-responsible-for-registering-mbean.txt","18/Aug/10 17:03;gdusbabek;ASF.LICENSE.NOT.GRANTED--v3-0001-make-CFS-responsible-for-registering-unregistering-mbe.txt;https://issues.apache.org/jira/secure/attachment/12452422/ASF.LICENSE.NOT.GRANTED--v3-0001-make-CFS-responsible-for-registering-unregistering-mbe.txt","18/Aug/10 19:11;gdusbabek;ASF.LICENSE.NOT.GRANTED--v4-0001-make-CFS-responsible-for-registering-unregistering-mbe.txt;https://issues.apache.org/jira/secure/attachment/12452436/ASF.LICENSE.NOT.GRANTED--v4-0001-make-CFS-responsible-for-registering-unregistering-mbe.txt","18/Aug/10 19:11;gdusbabek;ASF.LICENSE.NOT.GRANTED--v4-0002-remove-underscores-from-CFS-members.txt;https://issues.apache.org/jira/secure/attachment/12452437/ASF.LICENSE.NOT.GRANTED--v4-0002-remove-underscores-from-CFS-members.txt",,,,,,,,,,,4.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20114,,,Sat Aug 21 11:14:33 UTC 2010,,,,,,,,,,"0|i0g4qf:",92197,,,,,Low,,,,,,,,,,,,,,,,,"18/Aug/10 16:28;jbellis;do we want the ""hidden"" index CFSes exposed as mbeans?  if we do we probably want them in a different place in the jmx heirarchy to avoid confusion.;;;","18/Aug/10 16:46;gdusbabek;They weren't previously, but I think it makes good sense to expose them.  It would be easy to segregate them by mbean name if we assume that any CFS with a LocalPartitioner is an internal and should be grouped in ""org.apache.cassandra.db:type=InternalCFS"" or something like that.  The other (more ugly) approach would be to use a flag to indicate hidden/internal CFSs.;;;","18/Aug/10 16:49;jbellis;+1 LocalPartitioner approach;;;","18/Aug/10 18:16;jbellis;are the ""if (mbs.isRegistered(nameObj))"" checks actually necessary or just old code?

should we take this opportunity to s/ColumnFamilyStores/ColumnFamilies/ (and IndexCFS/IndexColumnFamlies) in the mbean names?;;;","18/Aug/10 19:12;gdusbabek;If 'if' was old code.  

I also took the liberty of removing the underscores from member variables.;;;","18/Aug/10 19:14;jbellis;+1;;;","18/Aug/10 19:16;gdusbabek;fixed.;;;","21/Aug/10 11:14;hudson;Integrated in Cassandra #518 (See [https://hudson.apache.org/hudson/job/Cassandra/518/])
    CHANGES.txt for CASSANDRA-1385
remove underscores from CFS members. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1385
make CFS responsible for registering/unregistering mbeans. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1385
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ERROR [MIGRATION-STAGE:1] Previous Version Mistmatch,CASSANDRA-1384,12471466,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,arya,arya,12/Aug/10 22:04,16/Apr/19 09:33,14/Jul/23 05:51,16/Aug/10 19:26,0.7 beta 2,,,,0,,,,,,"I fired up a 3 node cluster. I created few keyspaces using API and inserted to them with no problem. Now I tried to add more CFs to one of those existing Keyspaces in a loop. I got the following exception:

ERROR [MIGRATION-STAGE:1] 2010-08-12 14:46:40,493 CassandraDaemon.java (line 82) Uncaught exception in thread Thread[MIGRATION-STAGE:1,5,main]
java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.cassandra.config.ConfigurationException: Previous version mismatch. cannot apply.
	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)
	at java.util.concurrent.FutureTask.get(FutureTask.java:111)
	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:87)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1118)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)
Caused by: java.lang.RuntimeException: org.apache.cassandra.config.ConfigurationException: Previous version mismatch. cannot apply.
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	... 2 more
Caused by: org.apache.cassandra.config.ConfigurationException: Previous version mismatch. cannot apply.
	at org.apache.cassandra.db.migration.Migration.apply(Migration.java:101)
	at org.apache.cassandra.db.DefinitionsUpdateResponseVerbHandler$1.runMayThrow(DefinitionsUpdateResponseVerbHandler.java:70)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
	... 6 more

The above exception is logged in the log of node in which I send the request to and not other seeds. It is noteworthy that my schem_agreement is stuck in a disagreed state:

Array
(
    [1775e847-a658-11df-960f-7d867dfef3ae] => Array
        (
            [0] => 10.50.26.134
        )

    [163d874a-a65b-11df-aef0-d73a63bafff3] => Array
        (
            [0] => 10.50.26.133
        )

    [14869031-a658-11df-8553-930ba61048ac] => Array
        (
            [0] => 10.50.26.132
        )

)

And this does not change. Affect is that some keyspaces would not respond to reads any more giving Internal Error:

ERROR [pool-1-thread-26] 2010-08-12 14:50:57,034 Cassandra.java (line 2988) Internal error processing batch_mutate
java.lang.AssertionError
	at org.apache.cassandra.locator.AbstractReplicationStrategy.getNaturalEndpoints(AbstractReplicationStrategy.java:91)
	at org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:1289)
	at org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:1277)
	at org.apache.cassandra.service.StorageProxy.mutateBlocking(StorageProxy.java:193)
	at org.apache.cassandra.thrift.CassandraServer.doInsert(CassandraServer.java:474)
	at org.apache.cassandra.thrift.CassandraServer.batch_mutate(CassandraServer.java:438)
	at org.apache.cassandra.thrift.Cassandra$Processor$batch_mutate.process(Cassandra.java:2980)
	at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:2499)
	at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)

In my CF creation, I block for CF creation of the same name and not different names. 

Please advice.
","CentOS 5.2
Trunc August 12th, 2010 at 1:30pm",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Aug/10 16:06;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-trap-ConfigExceptions-so-they-don-t-become-RTEs.txt;https://issues.apache.org/jira/secure/attachment/12452032/ASF.LICENSE.NOT.GRANTED--v1-0001-trap-ConfigExceptions-so-they-don-t-become-RTEs.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20113,,,Tue Aug 17 12:59:51 UTC 2010,,,,,,,,,,"0|i0g4q7:",92196,,,,,Normal,,,,,,,,,,,,,,,,,"13/Aug/10 15:03;gdusbabek;I think the problem is that the exception is not being handled properly.  Cassandra is throwing a RuntimeException, which is bad because this is a totally recoverable situation.;;;","13/Aug/10 16:09;gdusbabek;Arya: I wasn't able to replicate your problem, but I think I understand it enough to provide this fix.  Can you please apply and test it?

Basically, a ConfigurationException which Cassandra can recover from is percolating up and getting re-thrown as a RuntimeException, which is bad.;;;","13/Aug/10 16:41;jbellis;what causes the first type?

+                                    logger.info(""Migration not applied "" + ex.getMessage());

should that be error instead of info?;;;","13/Aug/10 18:09;gdusbabek;>what causes the first type?
Trying to apply the same migration twice.  This happens as a result of gossip.  I was dropping them silently before, but figured a log message would be ok.;;;","13/Aug/10 19:27;jbellis;let's comment that and move it to debug then.  +1 otherwise;;;","13/Aug/10 19:46;gdusbabek;ok.  I'm going to hold off on committing this until I hear back from Arya.;;;","13/Aug/10 22:46;arya;I updated my trunc with revision #985305 which includes your change and looks good to me. I tried it few times and I could not get the exception any more. +1;;;","14/Aug/10 12:48;hudson;Integrated in Cassandra #514 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/514/])
    revert last change (committed wrong branch CASSANDRA-1384)
;;;","16/Aug/10 19:26;gdusbabek;committed.;;;","17/Aug/10 12:59;hudson;Integrated in Cassandra #516 (See [https://hudson.apache.org/hudson/job/Cassandra/516/])
    trap ConfigExceptions so they don't become RTEs. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1384
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Race condition leads to FileNotFoundException on startup,CASSANDRA-1382,12471371,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,rzotter,rzotter,12/Aug/10 04:08,16/Apr/19 09:33,14/Jul/23 05:51,17/Aug/10 18:12,0.7 beta 2,,,,0,,,,,,"On startup LocationInfo file is deleted then attempted to be read from.

Steps to reproduce: Kill then quickly restart

Switching to ParallelGC to avoid CMS/CompressedOops incompatibility
INFO 17:05:08,680 DiskAccessMode isstandard, indexAccessMode is mmap
 INFO 17:05:08,786 Sampling index for /var/lib/cassandra/data/system/Schema-e-1-<>
 INFO 17:05:08,797 Sampling index for /var/lib/cassandra/data/system/Schema-e-2-<>
 INFO 17:05:08,807 Sampling index for /var/lib/cassandra/data/system/Migrations-e-1-<>
 INFO 17:05:08,833 Sampling index for /var/lib/cassandra/data/system/Schema-e-1-<>
 INFO 17:05:08,834 Sampling index for /var/lib/cassandra/data/system/Schema-e-2-<>
 INFO 17:05:08,839 Sampling index for /var/lib/cassandra/data/system/Migrations-e-1-<>
 INFO 17:05:08,862 Sampling index for /var/lib/cassandra/data/system/Schema-e-1-<>
 INFO 17:05:08,864 Sampling index for /var/lib/cassandra/data/system/Schema-e-2-<>
 INFO 17:05:08,876 Sampling index for /var/lib/cassandra/data/system/Migrations-e-1-<>
 INFO 17:05:08,885 Sampling index for /var/lib/cassandra/data/system/LocationInfo-e-17-<>
 INFO 17:05:08,892 Sampling index for /var/lib/cassandra/data/system/Schema-e-1-<>
 INFO 17:05:08,893 Sampling index for /var/lib/cassandra/data/system/Schema-e-2-<>
 INFO 17:05:08,897 Sampling index for /var/lib/cassandra/data/system/Migrations-e-1-<>
 INFO 17:05:08,901 Sampling index for /var/lib/cassandra/data/system/LocationInfo-e-17-<>
 INFO 17:05:08,906 Sampling index for /var/lib/cassandra/data/system/Schema-e-1-<>
 INFO 17:05:08,909 Sampling index for /var/lib/cassandra/data/system/Schema-e-2-<>
 INFO 17:05:08,918 Sampling index for /var/lib/cassandra/data/system/Migrations-e-1-<>
 INFO 17:05:08,922 Sampling index for /var/lib/cassandra/data/system/LocationInfo-e-17-<>
 INFO 17:05:08,928 Creating new commitlog segment /var/lib/cassandra/commitlog/CommitLog-1281571508928.log
 INFO 17:05:08,933 Deleted /var/lib/cassandra/data/system/LocationInfo-e-16-Data.db
 INFO 17:05:08,936 Deleted /var/lib/cassandra/data/system/LocationInfo-e-15-Data.db
 INFO 17:05:08,936 Sampling index for /var/lib/cassandra/data/system/LocationInfo-e-16-<>
ERROR 17:05:08,937 Corrupt file /var/lib/cassandra/data/system/LocationInfo-e-16-Data.db; skipped
java.io.FileNotFoundException: /var/lib/cassandra/data/system/LocationInfo-e-16-Index.db (No such file or directory)
    at java.io.RandomAccessFile.open(Native Method)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:212)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:98)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:142)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:137)
    at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:289)
    at org.apache.cassandra.io.sstable.SSTableReader.internalOpen(SSTableReader.java:197)
    at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:176)
    at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:208)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:342)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:308)
    at org.apache.cassandra.db.Table.<init>(Table.java:245)
    at org.apache.cassandra.db.Table.open(Table.java:102)
    at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:196)
    at org.apache.cassandra.db.StatisticsTable.deleteSSTableStatistics(StatisticsTable.java:81)
    at org.apache.cassandra.io.sstable.SSTable.deleteIfCompacted(SSTable.java:136)
    at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:202)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:342)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:308)
    at org.apache.cassandra.db.Table.<init>(Table.java:245)
    at org.apache.cassandra.db.Table.open(Table.java:102)
    at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:196)
    at org.apache.cassandra.db.StatisticsTable.deleteSSTableStatistics(StatisticsTable.java:81)
    at org.apache.cassandra.io.sstable.SSTable.deleteIfCompacted(SSTable.java:136)
    at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:202)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:342)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:308)
    at org.apache.cassandra.db.Table.<init>(Table.java:245)
    at org.apache.cassandra.db.Table.open(Table.java:102)
    at org.apache.cassandra.db.SystemTable.checkHealth(SystemTable.java:121)
    at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:93)
    at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:90)
    at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:224)
 INFO 17:05:08,947 Deleted /var/lib/cassandra/data/system/LocationInfo-e-14-Data.db
 INFO 17:05:08,947 Sampling index for /var/lib/cassandra/data/system/LocationInfo-e-17-<>
 INFO 17:05:08,948 Sampling index for /var/lib/cassandra/data/system/LocationInfo-e-15-<>
ERROR 17:05:08,948 Corrupt file /var/lib/cassandra/data/system/LocationInfo-e-15-Data.db; skipped
java.io.FileNotFoundException: /var/lib/cassandra/data/system/LocationInfo-e-15-Index.db (No such file or directory)
    at java.io.RandomAccessFile.open(Native Method)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:212)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:98)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:142)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:137)
    at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:289)
    at org.apache.cassandra.io.sstable.SSTableReader.internalOpen(SSTableReader.java:197)
    at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:176)
    at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:208)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:342)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:308)
    at org.apache.cassandra.db.Table.<init>(Table.java:245)
    at org.apache.cassandra.db.Table.open(Table.java:102)
    at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:196)
    at org.apache.cassandra.db.StatisticsTable.deleteSSTableStatistics(StatisticsTable.java:81)
    at org.apache.cassandra.io.sstable.SSTable.deleteIfCompacted(SSTable.java:136)
    at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:202)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:342)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:308)
    at org.apache.cassandra.db.Table.<init>(Table.java:245)
    at org.apache.cassandra.db.Table.open(Table.java:102)
    at org.apache.cassandra.db.SystemTable.checkHealth(SystemTable.java:121)
    at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:93)
    at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:90)
    at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:224)
 INFO 17:05:08,950 Sampling index for /var/lib/cassandra/data/system/LocationInfo-e-16-<>
ERROR 17:05:08,951 Corrupt file /var/lib/cassandra/data/system/LocationInfo-e-16-Data.db; skipped
java.io.FileNotFoundException: /var/lib/cassandra/data/system/LocationInfo-e-16-Index.db (No such file or directory)
    at java.io.RandomAccessFile.open(Native Method)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:212)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:98)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:142)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:137)
    at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:289)
    at org.apache.cassandra.io.sstable.SSTableReader.internalOpen(SSTableReader.java:197)
    at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:176)
    at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:208)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:342)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:308)
    at org.apache.cassandra.db.Table.<init>(Table.java:245)
    at org.apache.cassandra.db.Table.open(Table.java:102)
    at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:196)
    at org.apache.cassandra.db.StatisticsTable.deleteSSTableStatistics(StatisticsTable.java:81)
    at org.apache.cassandra.io.sstable.SSTable.deleteIfCompacted(SSTable.java:136)
    at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:202)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:342)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:308)
    at org.apache.cassandra.db.Table.<init>(Table.java:245)
    at org.apache.cassandra.db.Table.open(Table.java:102)
    at org.apache.cassandra.db.SystemTable.checkHealth(SystemTable.java:121)
    at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:93)
    at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:90)
    at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:224)
 INFO 17:05:08,970 Deleted /var/lib/cassandra/data/system/LocationInfo-e-13-Data.db
 INFO 17:05:08,971 Sampling index for /var/lib/cassandra/data/system/LocationInfo-e-14-<>
ERROR 17:05:08,971 Corrupt file /var/lib/cassandra/data/system/LocationInfo-e-14-Data.db; skipped
java.io.FileNotFoundException: /var/lib/cassandra/data/system/LocationInfo-e-14-Index.db (No such file or directory)
    at java.io.RandomAccessFile.open(Native Method)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:212)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:98)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:142)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:137)
    at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:289)
    at org.apache.cassandra.io.sstable.SSTableReader.internalOpen(SSTableReader.java:197)
    at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:176)
    at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:208)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:342)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:308)
    at org.apache.cassandra.db.Table.<init>(Table.java:245)
    at org.apache.cassandra.db.Table.open(Table.java:102)
    at org.apache.cassandra.db.SystemTable.checkHealth(SystemTable.java:121)
    at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:93)
    at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:90)
    at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:224)
 INFO 17:05:08,972 Sampling index for /var/lib/cassandra/data/system/LocationInfo-e-17-<>
 INFO 17:05:08,973 Sampling index for /var/lib/cassandra/data/system/LocationInfo-e-15-<>
ERROR 17:05:08,973 Corrupt file /var/lib/cassandra/data/system/LocationInfo-e-15-Data.db; skipped
java.io.FileNotFoundException: /var/lib/cassandra/data/system/LocationInfo-e-15-Index.db (No such file or directory)
    at java.io.RandomAccessFile.open(Native Method)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:212)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:98)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:142)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:137)
    at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:289)
    at org.apache.cassandra.io.sstable.SSTableReader.internalOpen(SSTableReader.java:197)
    at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:176)
    at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:208)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:342)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:308)
    at org.apache.cassandra.db.Table.<init>(Table.java:245)
    at org.apache.cassandra.db.Table.open(Table.java:102)
    at org.apache.cassandra.db.SystemTable.checkHealth(SystemTable.java:121)
    at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:93)
    at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:90)
    at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:224)
 INFO 17:05:08,974 Sampling index for /var/lib/cassandra/data/system/LocationInfo-e-16-<>
ERROR 17:05:08,974 Corrupt file /var/lib/cassandra/data/system/LocationInfo-e-16-Data.db; skipped
java.io.FileNotFoundException: /var/lib/cassandra/data/system/LocationInfo-e-16-Index.db (No such file or directory)
    at java.io.RandomAccessFile.open(Native Method)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:212)
    at java.io.RandomAccessFile.<init>(RandomAccessFile.java:98)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:142)
    at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:137)
    at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:289)
    at org.apache.cassandra.io.sstable.SSTableReader.internalOpen(SSTableReader.java:197)
    at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:176)
    at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:208)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:342)
    at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:308)
    at org.apache.cassandra.db.Table.<init>(Table.java:245)
    at org.apache.cassandra.db.Table.open(Table.java:102)
    at org.apache.cassandra.db.SystemTable.checkHealth(SystemTable.java:121)
    at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:93)
    at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:90)
    at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:224)
 INFO 17:05:08,996 Loading schema version acc5646a-a59d-11df-83fb-e700f669bcfc
 WARN 17:05:09,158 Schema definitions were defined both locally and in cassandra.yaml. Definitions in cassandra.yaml were ignored.
 INFO 17:05:09,164 Replaying /var/lib/cassandra/commitlog/CommitLog-1281571453475.log, /var/lib/cassandra/commitlog/CommitLog-1281571508928.log
 INFO 17:05:09,172 Finished reading /var/lib/cassandra/commitlog/CommitLog-1281571453475.log
 INFO 17:05:09,172 Finished reading /var/lib/cassandra/commitlog/CommitLog-1281571508928.log
 INFO 17:05:09,173 switching in a fresh Memtable for LocationInfo at CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1281571508928.log', position=592)
 INFO 17:05:09,183 Enqueuing flush of Memtable-LocationInfo@137493297(17 bytes, 1 operations)
 INFO 17:05:09,183 Writing Memtable-LocationInfo@137493297(17 bytes, 1 operations)
 INFO 17:05:09,184 switching in a fresh Memtable for Statistics at CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1281571508928.log', position=592)
 INFO 17:05:09,184 Enqueuing flush of Memtable-Statistics@86823325(0 bytes, 0 operations)
 INFO 17:05:09,265 Completed flushing /var/lib/cassandra/data/system/LocationInfo-e-18-Data.db
 INFO 17:05:09,273 Writing Memtable-Statistics@86823325(0 bytes, 0 operations)
 INFO 17:05:09,352 Completed flushing /var/lib/cassandra/data/system/Statistics-e-1-Data.db
 INFO 17:05:09,353 Recovery complete ",,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Aug/10 20:48;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-separate-CFS-dir-cleanup-from-CFS-instantiation.txt;https://issues.apache.org/jira/secure/attachment/12451948/ASF.LICENSE.NOT.GRANTED--v1-0001-separate-CFS-dir-cleanup-from-CFS-instantiation.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20112,,,Wed Aug 18 13:13:49 UTC 2010,,,,,,,,,,"0|i0g4pr:",92194,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"12/Aug/10 18:13;gdusbabek;When there are compacted files to delete, initializing the system table tries to delete its statistics, which results in trying to initialize the system table.  The statistics deletion needs to happen outside of the CFS initialization.;;;","12/Aug/10 20:49;gdusbabek;Another approach to this fix would have been us have an initialization stage and make sure that CFS creation and statistics clean up happen on it. The stats cleanup would be submitted at the end of the stage while a CFS was being initialized.;;;","13/Aug/10 16:51;jbellis;it looks like this patch says we only delete statistics for sstables that had .compacted files left hanging around on the next restart, which won't be the case if they got cleaned up by the GC hook;;;","13/Aug/10 17:52;gdusbabek;It was the same way before.  SSTable.deleteIfCompacted() is the only method that calls StatisticsTable.deleteSSTableStatistics().  The only place SST.deleteIfCompacted() gets called is from the CFS constructor which is called during init.;;;","17/Aug/10 16:34;jbellis;+1;;;","18/Aug/10 13:13;hudson;Integrated in Cassandra #517 (See [https://hudson.apache.org/hudson/job/Cassandra/517/])
    missed CHANGES.txt for CASSANDRA-1382
separate CFS dir cleanup from CFS instantiation. fixes race condition. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1382
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add then drop Keyspace without putting anything in it causes exception,CASSANDRA-1378,12471309,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,jjordan,jjordan,11/Aug/10 15:33,16/Apr/19 09:33,14/Jul/23 05:51,13/Aug/10 18:01,0.7 beta 2,,,,0,,,,,,"The following from python causes an exception on apache-cassandra-2010-08-10_13-08-19-bin.tar.gz and a bunch of earlier builds in the 0.7 line:
        socket = TSocket.TSocket(host, 9160)
        transport = TTransport.TFramedTransport(socket)
        protocol = TBinaryProtocol.TBinaryProtocolAccelerated(transport)
        client = Cassandra.Client(protocol)
        transport.open()
        try:
            client.describe_keyspace(dbName)
        except NotFoundException, e:
            keyspaceDef = KsDef(name=dbName,
 
strategy_class='org.apache.cassandra.locator.RackUnawareStrategy',
                                replication_factor=replicationFactor,
                                cf_defs=[])
            client.set_keyspace('system')
            client.system_add_keyspace(keyspaceDef)

        try:
            client.describe_keyspace(dbName)
            client.set_keyspace('system')
            client.system_drop_keyspace(dbName)
        except NotFoundException, e:
            pass

The system_drop_keyspace throws:
InvalidRequestException(why='java.util.concurrent.ExecutionException:
java.lang.NullPointerException')

If I put a system_add_column_family in the middle it doesn't crash.
I think this broke sometime after apache-cassandra-2010-07-06_13-27-21",Single node.  Both Linux and Windows.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Aug/10 14:33;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-handle-graveyard-cleanups-gracefully-when-there-is-not.txt;https://issues.apache.org/jira/secure/attachment/12451903/ASF.LICENSE.NOT.GRANTED--v1-0001-handle-graveyard-cleanups-gracefully-when-there-is-not.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20111,,,Sat Aug 14 12:48:36 UTC 2010,,,,,,,,,,"0|i0g4ov:",92190,,,,,Low,,,,,,,,,,,,,,,,,"12/Aug/10 14:11;gdusbabek;full error:


ERROR [CompactionExecutor:1] 2010-08-12 08:59:31,088 CassandraDaemon.java (line 82) Uncaught exception in thread Thread[CompactionExecutor:1,5,main]
java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
	at java.util.concurrent.FutureTask.get(FutureTask.java:83)
	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:87)
	at org.apache.cassandra.db.CompactionManager$CompactionExecutor.afterExecute(CompactionManager.java:650)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:637)
Caused by: java.lang.NullPointerException
	at org.apache.cassandra.db.CompactionManager$1.call(CompactionManager.java:90)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	... 2 more
ERROR [MIGRATION-STAGE:1] 2010-08-12 08:59:31,089 CassandraDaemon.java (line 82) Uncaught exception in thread Thread[MIGRATION-STAGE:1,5,main]
java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
	at java.util.concurrent.FutureTask.get(FutureTask.java:83)
	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:87)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:637)
Caused by: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at org.apache.cassandra.db.migration.Migration.cleanupDeadFiles(Migration.java:246)
	at org.apache.cassandra.db.migration.DropKeyspace.applyModels(DropKeyspace.java:86)
	at org.apache.cassandra.db.migration.Migration.apply(Migration.java:156)
	at org.apache.cassandra.thrift.CassandraServer$2.call(CassandraServer.java:722)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	... 2 more
Caused by: java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
	at java.util.concurrent.FutureTask.get(FutureTask.java:83)
	at org.apache.cassandra.db.migration.Migration.cleanupDeadFiles(Migration.java:238)
	... 8 more
Caused by: java.lang.NullPointerException
	at org.apache.cassandra.db.CompactionManager$1.call(CompactionManager.java:90)
	... 5 more
;;;","13/Aug/10 16:44;jbellis;+1;;;","14/Aug/10 12:48;hudson;Integrated in Cassandra #514 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/514/])
    handle graveyard cleanups gracefully when there is nothing to delete. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1378
trap ConfigExceptions so they don't become RTEs. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1378
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE aborts streaming operations for keyspaces with hyphens ('-') in their names,CASSANDRA-1377,12471303,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,bhoyt,bhoyt,11/Aug/10 14:54,16/Apr/19 09:33,14/Jul/23 05:51,12/Aug/10 21:40,0.6.5,0.7 beta 2,,,0,,,,,,"When streaming starts for operations such as repair or bootstrap, it will fail due to an NPE if they rows are in a keyspace that has a hyphen in its name.  One workaround for this issue would be to not use keyspace names containing hyphens.  It would be even nicer if streaming worked for keyspace names with hyphens, since keyspaces named like that seem to be fine in all other ways.

To reproduce:
 1. With a multi-node ring, load up a keyspace with a hyphen in its name
 2. Add some data to that keyspace
 3. nodetool repair

Expected results:
Repair operations complete normally

Actual results:
Repair operations don't complete normally.  The stacktrace below is correlated with the repair request.  

 INFO [AE-SERVICE-STAGE:1] 2010-06-30 14:11:29,744 AntiEntropyService.java (line 619) Performing streaming repair of 1 ranges to /10.255.0.20 for (my-keyspace,AColumnFamily)
ERROR [MESSAGE-DESERIALIZER-POOL:1] 2010-06-30 14:11:30,034 DebuggableThreadPoolExecutor.java (line 101) Error in ThreadPoolExecutor
java.lang.NullPointerException
        at org.apache.cassandra.streaming.StreamInitiateVerbHandler.getNewNames(StreamInitiateVerbHandler.java:154)
        at org.apache.cassandra.streaming.StreamInitiateVerbHandler.doVerb(StreamInitiateVerbHandler.java:76)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:40)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)",,eonnen,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Aug/10 12:59;gdusbabek;1377-0.6-check-for-dashes.txt;https://issues.apache.org/jira/secure/attachment/12452925/1377-0.6-check-for-dashes.txt","12/Aug/10 17:03;gdusbabek;1377-0.6.txt;https://issues.apache.org/jira/secure/attachment/12451925/1377-0.6.txt","12/Aug/10 17:02;gdusbabek;ASF.LICENSE.NOT.GRANTED--v1-0001-disallow-invalid-ks-cf-names.txt;https://issues.apache.org/jira/secure/attachment/12451923/ASF.LICENSE.NOT.GRANTED--v1-0001-disallow-invalid-ks-cf-names.txt","24/Aug/10 03:02;eonnen;CAS-1377-1.patch;https://issues.apache.org/jira/secure/attachment/12452887/CAS-1377-1.patch","24/Aug/10 03:42;eonnen;CAS-1377-2.patch;https://issues.apache.org/jira/secure/attachment/12452889/CAS-1377-2.patch","23/Aug/10 21:51;eonnen;CAS-1377.patch;https://issues.apache.org/jira/secure/attachment/12452863/CAS-1377.patch",,,,,,,,,6.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20110,,,Tue Aug 24 13:40:09 UTC 2010,,,,,,,,,,"0|i0g4on:",92189,,,,,Normal,,,,,,,,,,,,,,,,,"12/Aug/10 02:40;gdusbabek;We currently disallow hyphens in CF names.  It sounds like we need to disallow it in KS names too.;;;","12/Aug/10 05:15;jbellis;I vote for disallowing everything but \w characters - [a-zA-Z0-9_] ;;;","12/Aug/10 17:03;gdusbabek;0001 is for trunk, 1377-0.6 is for 0.6.;;;","12/Aug/10 18:36;jbellis;+1;;;","14/Aug/10 12:48;hudson;Integrated in Cassandra #514 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/514/])
    disallow invalid ks+cf names. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1377
;;;","21/Aug/10 11:14;hudson;Integrated in Cassandra #518 (See [https://hudson.apache.org/hudson/job/Cassandra/518/])
    CHANGES.txt and NEWS.txt update explaining the ramifications of CASSANDRA-1377
;;;","23/Aug/10 19:00;gdusbabek;eonnen in #cassandra has made a compelling argument that committing this to 0.6 breaks some backwards compatibility.  I am inclined to agree if the amount of work to handle dashes during streaming is trivial.;;;","23/Aug/10 19:11;jbellis;We really need some ""reserved"" characters in keyspace/CF names.  You can make a case that restricting them to \w is going too far in the other direction, but hyphens have always been reserved, and letting them pass in keyspaces was definitely a bug that was going to bite us (see: this issue).;;;","23/Aug/10 19:15;jbellis;(One of the reasons I'd like to restrict to \w is that makes us not have to deal with people reporting bugs from Thrift strings being utf8-encoded in some languages and not in others.);;;","23/Aug/10 21:48;eonnen;We have a multi-tenant deployment hosting multiple customers, each with multiple deployments of our upstream software (think test/prod). For each customer deployment, we've had a UUID identifying the instance since before the dawn of time, or at least since before Cassandra :)

Up until this change, using a keyspace-UUID mapping worked perfectly, especially after set_keyspace was added to the lower-level client API which allowed us to have pools for a given customer with different customers able to have different throughput to a point.

In hopes of getting this relaxed just a bit to allow ""-"", I've attached a fix for the bug in 0.6.0 tested with a keyspace name of ""e610eed7-c6be-449b-ad2c-562f35d75528"" which is a Type4 UUID. If you can broaden the limit here just a bit, we'll be good. I don't think it's all that unrealistic that users will want to have a keyspace correspond to real artifacts in their system (although I don't feel the same about CF names). This would at least broaden things just enough to allow UUIDs at that level.

While I understand the need to limit what goes into the name of the keyspace and why, it's too restrictive for my needs and I'll argue against it at least and try and patch my way out of it as long as you'll listen.

Happy to do the same for 0.7.0 if you're receptive.;;;","23/Aug/10 21:51;eonnen;Fixes NPE with ""-"" in Keyspace names, re-allows using them at the DatabaseDescriptor.;;;","24/Aug/10 02:08;jbellis;committed Erik's patch to 0.6 and trunk.

I still think we need to make some explicit rules about reserved characters but I agree that 0.6.5 is not the place to make that change.;;;","24/Aug/10 03:02;eonnen;This patch lightens the restriction on KS names to allow ""-"" in addition to \\w bringing in line the functionality w/ the 0.6 patch submitted earlier.;;;","24/Aug/10 03:05;eonnen;Thanks Jonathan. I added one additional patch to relax things slightly in 0.7 trunk. Tested with a nodetool loadbalance and nodetool move with a two node ring and both worked fine. Lots of changes in the streaming code between 0.6 and 0.7 and it looks like the broken code didn't move forward into 0.7 near as I can tell in reading though it.;;;","24/Aug/10 03:42;eonnen;Forgot to attach test in CAS-1377-1.patch;;;","24/Aug/10 12:59;gdusbabek;Puts hyphen check back into CF definition.;;;","24/Aug/10 13:37;jbellis;+1 hyphens-in-CF check;;;","24/Aug/10 13:40;gdusbabek;committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OrderPreservingPartitioner with type validated indexed columns causes ClassCastException,CASSANDRA-1373,12471158,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,thobbs,thobbs,10/Aug/10 01:28,16/Apr/19 09:33,14/Jul/23 05:51,17/Aug/10 17:06,0.7 beta 2,,,,0,,,,,,"If OrderPreservingPartitioner is used and you have an indexed column with a type validator, using batch_mutate to insert column values (like pycassa does) on the same key and indexed column causes a ClassCastException to be thrown the *second* time you execute it.  That is, the first batch_mutate succeeds, but the following ones fail.  CollatedOrderPreservingPartitioner seems to avoid this problem.  Also, it appears that the row key is being compared to the column value at some point using the validator's Comparator class (such as LongType) which is where the actual exception is thrown.

Stack trace below:
{noformat}
java.lang.RuntimeException: java.lang.ClassCastException: java.lang.String cannot be cast to [B
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to [B
	at org.apache.cassandra.db.marshal.LongType.compare(LongType.java:27)
	at org.apache.cassandra.dht.LocalToken.compareTo(LocalToken.java:45)
	at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:82)
	at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:37)
	at java.util.concurrent.ConcurrentSkipListMap.doPut(ConcurrentSkipListMap.java:878)
	at java.util.concurrent.ConcurrentSkipListMap.putIfAbsent(ConcurrentSkipListMap.java:1893)
	at org.apache.cassandra.db.Memtable.resolve(Memtable.java:127)
	at org.apache.cassandra.db.Memtable.put(Memtable.java:119)
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:508)
	at org.apache.cassandra.db.Table.applyCF(Table.java:452)
	at org.apache.cassandra.db.Table.apply(Table.java:409)
	at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:196)
	at org.apache.cassandra.service.StorageProxy$2.runMayThrow(StorageProxy.java:276)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
	... 3 more
{noformat}",Cassandra Trunk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Aug/10 22:35;jbellis;1373.txt;https://issues.apache.org/jira/secure/attachment/12452221/1373.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20108,,,Wed Aug 18 13:13:48 UTC 2010,,,,,,,,,,"0|i0g4nr:",92185,,thobbs,,thobbs,Normal,,,,,,,,,,,,,,,,,"16/Aug/10 22:35;jbellis;correct patch attached.;;;","16/Aug/10 23:01;thobbs;New stacktrace with patch 1373.txt (2010-08-16 06:35 PM) applied:

\\
{noformat}
java.lang.RuntimeException: java.lang.ClassCastException: java.lang.String cannot be cast to [B
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to [B
	at org.apache.cassandra.db.marshal.LongType.compare(LongType.java:28)
	at org.apache.cassandra.dht.LocalToken.compareTo(LocalToken.java:45)
	at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:82)
	at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:37)
	at java.util.concurrent.ConcurrentSkipListMap.findPredecessor(ConcurrentSkipListMap.java:685)
	at java.util.concurrent.ConcurrentSkipListMap.doPut(ConcurrentSkipListMap.java:864)
	at java.util.concurrent.ConcurrentSkipListMap.putIfAbsent(ConcurrentSkipListMap.java:1893)
	at org.apache.cassandra.db.Memtable.resolve(Memtable.java:127)
	at org.apache.cassandra.db.Memtable.put(Memtable.java:119)
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:508)
	at org.apache.cassandra.db.Table.applyCF(Table.java:452)
	at org.apache.cassandra.db.Table.apply(Table.java:409)
	at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:196)
	at org.apache.cassandra.service.StorageProxy$1.runMayThrow(StorageProxy.java:194)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
	... 3 more
{noformat};;;","17/Aug/10 17:03;thobbs;Patch was not exercised correctly last time.  The patch does fix the issue, now.;;;","17/Aug/10 17:06;jbellis;committed;;;","18/Aug/10 13:13;hudson;Integrated in Cassandra #517 (See [https://hudson.apache.org/hudson/job/Cassandra/517/])
    fix updating index when value is changed.  patch by jbellis; tested by Tyler Hobbs for CASSANDRA-1373
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AsynchResult does not respect TimeUnit in get(),CASSANDRA-1362,12470899,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,hemartin,hemartin,hemartin,05/Aug/10 12:51,16/Apr/19 09:33,14/Jul/23 05:51,05/Aug/10 13:12,0.7 beta 1,,,,0,,,,,,"When waiting for a blocking get in AsynchResult, the parameter {{TimeUnit tu}} is ignored. The passed parameter {{long timeout}} is assumed to be milliseconds. Attached you will find my quick fix to convert {{timeout}} to milliseconds with respect to {{tu}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Aug/10 12:53;hemartin;trunk-982452.txt;https://issues.apache.org/jira/secure/attachment/12451326/trunk-982452.txt",,,,,,,,,,,,,,1.0,hemartin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20105,,,Sun Aug 08 13:52:23 UTC 2010,,,,,,,,,,"0|i0g4lb:",92174,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"05/Aug/10 12:52;hemartin;Patch to convert {{timeout}} parameter to milliseconds.;;;","05/Aug/10 13:12;jbellis;committed to trunk;;;","08/Aug/10 13:52;hudson;Integrated in Cassandra #510 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/510/])
    add TimeUnit.convert call to AsyncResult.  patch by Martin Hentschel; reviewed by jbellis for CASSANDRA-1362
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"nosetests are busted because ""Not enough live nodes to support this keyspace""",CASSANDRA-1360,12470834,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,04/Aug/10 20:25,16/Apr/19 09:33,14/Jul/23 05:51,05/Aug/10 18:25,0.7 beta 1,,,,0,,,,,,"the keyspaces created by nosetests should all have RF=1.

I'm pretty sure some of the keyspaces can be removed altogether.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/10 20:44;gdusbabek;0001-remove-unneccessary-keyspaces-from-nosetests.patch;https://issues.apache.org/jira/secure/attachment/12451264/0001-remove-unneccessary-keyspaces-from-nosetests.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20104,,,Sun Aug 08 13:52:23 UTC 2010,,,,,,,,,,"0|i0g4kv:",92172,,,,,Normal,,,,,,,,,,,,,,,,,"04/Aug/10 20:44;gdusbabek;Removes Keyspace3 and Keyspace4.;;;","05/Aug/10 18:22;jbellis;+1;;;","08/Aug/10 13:52;hudson;Integrated in Cassandra #510 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/510/])
    remove unneccessary keyspaces from nosetests. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1360
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
get rid of internode directory,CASSANDRA-1357,12470811,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,04/Aug/10 15:54,16/Apr/19 09:33,14/Jul/23 05:51,05/Aug/10 17:47,0.7 beta 1,,,,0,,,,,,code should generate to src/gen-java.  the genavro file should be renamed and located in interface.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Aug/10 14:08;gdusbabek;0001-remove-internode-directory-and-change-destination-fo.patch;https://issues.apache.org/jira/secure/attachment/12451332/0001-remove-internode-directory-and-change-destination-fo.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20102,,,Sun Aug 08 13:52:17 UTC 2010,,,,,,,,,,"0|i0g4k7:",92169,,,,,Normal,,,,,,,,,,,,,,,,,"04/Aug/10 16:15;jbellis;src/avro would also make sense for the genavro file, imo;;;","04/Aug/10 16:52;gdusbabek;I didn't include the paranamer task on the avro generated to src/gen-java.  It's not clear that it is required.;;;","04/Aug/10 19:05;stuhood;> src/avro would also make sense for the genavro file, imo
Agreed: putting the private protocol definition in src/avro, leaving public protocols in interface/ and generating code for all protocols into src/gen-java would make sense.;;;","05/Aug/10 14:07;gdusbabek;Rebased because of CASSANDRA-1356.;;;","05/Aug/10 16:38;stuhood;+1 Thanks Gary!;;;","08/Aug/10 13:52;hudson;Integrated in Cassandra #510 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/510/])
    remove internode directory and change destination for generated avro code. patch by gdusbabek, reviewed by stuhood. CASSANDRA-1357
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""ant"" always compiles at least 36 files, even if no changes were made",CASSANDRA-1356,12470810,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,messi,jbellis,jbellis,04/Aug/10 15:38,16/Apr/19 09:33,14/Jul/23 05:51,05/Aug/10 13:45,0.7 beta 1,,Packaging,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Aug/10 02:39;messi;correct-src-path.patch;https://issues.apache.org/jira/secure/attachment/12451297/correct-src-path.patch",,,,,,,,,,,,,,1.0,messi,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20101,,,Sun Aug 08 13:52:16 UTC 2010,,,,,,,,,,"0|i0g4jz:",92168,,,,,Normal,,,,,,,,,,,,,,,,,"05/Aug/10 13:45;gdusbabek;+1 committed.;;;","08/Aug/10 13:52;hudson;Integrated in Cassandra #510 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/510/])
    adjust src paths. patch by Folke Behrens, reviewed by Gary Dusbabek. CASSANDRA-1356
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Static CFMetaData objects are using the wrong constructor.,CASSANDRA-1354,12470764,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,03/Aug/10 21:29,16/Apr/19 09:33,14/Jul/23 05:51,04/Aug/10 12:39,0.7 beta 1,,,,0,,,,,,"This means they are getting assigned ids > 1000.  Static CFMs should be using the private constructor that uses a specific cfid that is <1000

I'm pretty sure they just need to be getting a readRepairChance=0.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/10 21:42;gdusbabek;0001-use-correct-constructor-when-creating-static-CFM-ins.patch;https://issues.apache.org/jira/secure/attachment/12451166/0001-use-correct-constructor-when-creating-static-CFM-ins.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20100,,,Wed Aug 04 13:25:35 UTC 2010,,,,,,,,,,"0|i0g4jj:",92166,,stuhood,,stuhood,Normal,,,,,,,,,,,,,,,,,"04/Aug/10 00:27;jbellis;+1, but for the record, what badness happens when the static CFs get part of the ""public pool"" of ids?;;;","04/Aug/10 12:38;gdusbabek;The next time we create a static CFM (like we did with StatisticsCf) it would use an ID that is already used by a regular column family that just hasn't been loaded yet.  ;;;","04/Aug/10 13:25;hudson;Integrated in Cassandra #509 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/509/])
    use correct constructor when creating static CFM instances. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1354
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
commit log recovery is broken when the CL contains mutations to CFs that have been dropped,CASSANDRA-1353,12470756,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,03/Aug/10 19:51,16/Apr/19 09:33,14/Jul/23 05:51,04/Aug/10 14:37,0.7 beta 1,,,,0,,,,,,"This was working, so the fix should include a RecoveryManager test that checks for regressions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/10 13:34;gdusbabek;0001-skip-CL-rows-that-have-unrecoverable-row-mutations.patch;https://issues.apache.org/jira/secure/attachment/12451222/0001-skip-CL-rows-that-have-unrecoverable-row-mutations.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20099,,,Sun Aug 08 13:52:26 UTC 2010,,,,,,,,,,"0|i0g4jb:",92165,,mdennis,,mdennis,Normal,,,,,,,,,,,,,,,,,"03/Aug/10 20:01;gdusbabek;Connected to the target VM, address: '127.0.0.1:49379', transport: 'socket'
 INFO 14:55:18,246 [main] Loading settings from /Users/gary.dusbabek/codes/apache/git-trunk/out/production/conf1/cassandra.yaml
DEBUG 14:55:18,658 [main] Syncing log with a period of 10000
 INFO 14:55:18,658 [main] DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
DEBUG 14:55:18,683 [main] setting auto_bootstrap to true
DEBUG 14:55:18,913 [main] Starting CFS Statistics
DEBUG 14:55:18,939 [main] Starting CFS Schema
DEBUG 14:55:19,028 [main] Starting CFS Migrations
DEBUG 14:55:19,042 [main] Starting CFS LocationInfo
DEBUG 14:55:19,056 [main] Starting CFS HintsColumnFamily
 INFO 14:55:19,133 [main] Loading schema version b72d969e-9f37-11df-903b-e700f669bcfc
DEBUG 14:55:19,153 [main] collecting 0 of 2147483647: Avro/Schema:false:1368@1280864748965
DEBUG 14:55:19,154 [main] collecting 1 of 2147483647: Keyspace1:false:62@1280864748965
 WARN 14:55:19,600 [main] Schema definitions were defined both locally and in cassandra.yaml. Definitions in cassandra.yaml were ignored.
 INFO 14:55:19,615 [main] Replaying /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280862145661.log, /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280864632989.log, /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280864746190.log, /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280864747315.log, /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280864748249.log, /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280864748880.log, /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280864749601.log, /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280864798401.log
DEBUG 14:55:19,642 [main] Replaying /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280862145661.log starting at 276
DEBUG 14:55:19,642 [main] Reading mutation at 276
DEBUG 14:55:19,788 [main] replaying mutation for system.[B@7848fbc0: {ColumnFamily(LocationInfo [B:false:1@1280862146155,])}
DEBUG 14:55:19,835 [main] Reading mutation at 424
DEBUG 14:55:19,836 [main] replaying mutation for system.[B@764d2b11: {ColumnFamily(LocationInfo [;;;","03/Aug/10 20:39;gdusbabek;It's easy to detect when a given cfid is gone, but without the old metadata, it is difficult to know how many bytes to skip over (since clock serialization length will vary, as will the column serialization length).;;;","03/Aug/10 20:58;gdusbabek;We'd generate even more garbage if we pre-serialized the CF and them framed it with a length field (so we could skip over the data).  

One alternative I can think of is to keep and 'attic' of dropped column family definitions in the system table so that it can be consulted in order to read old row mutations.  This is ugly though.;;;","03/Aug/10 21:13;jbellis;we are including the length of the entire serialized record in CLS.write already.  (this is the value that recover reads in as serializedSize).  so we should just be able to skip to the next one w/o any extra changes (possibly by having RowMutation deserialize throw a ColumnFamilyNotFoundException, or something like that).;;;","04/Aug/10 00:25;jbellis;WARN freaks people out, especially dozens of WARNs which is what's likely to happen here.

It's more work, by if you make UCFE take just a CFID as a parameter and expose it, then recover can collect a count of rows skipped per CFID and log one message (i would vote for INFO but WARN is ok) at the end of the process.;;;","04/Aug/10 12:46;gdusbabek;Updated patch to log less.;;;","04/Aug/10 13:34;gdusbabek;No really, I uploaded the file this time.  This patch makes the changes Jonathan suggested.;;;","04/Aug/10 13:54;jbellis;+1

the log message might be more helpful as something like

Skipped %d mutations from unknown (probably removed) CF id %d;;;","08/Aug/10 13:52;hudson;Integrated in Cassandra #510 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/510/])
    skip CL rows that have unrecoverable row mutations. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1353
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update py_stress to reflect udpated KsDef params,CASSANDRA-1352,12470747,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,rnirmal,rnirmal,rnirmal,03/Aug/10 18:11,16/Apr/19 09:33,14/Jul/23 05:51,03/Aug/10 20:41,0.7 beta 1,,,,0,,,,,,"The following occurs while running stress.py. 

Traceback (most recent call last):
  File ""stress.py"", line 387, in <module>
    make_keyspaces()
  File ""stress.py"", line 160, in make_keyspaces
    client.system_add_keyspace(keyspace)
  File ""/Users/nirmal.ranganathan/Documents/workspace/cassandra.git/interface/thrift/gen-py/cassandra/Cassandra.py"", line 1288, in system_add_keyspace
    self.send_system_add_keyspace(ks_def)
  File ""/Users/nirmal.ranganathan/Documents/workspace/cassandra.git/interface/thrift/gen-py/cassandra/Cassandra.py"", line 1295, in send_system_add_keyspace
    args.write(self._oprot)
  File ""/Users/nirmal.ranganathan/Documents/workspace/cassandra.git/interface/thrift/gen-py/cassandra/Cassandra.py"", line 5745, in write
    oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
SystemError: Objects/dictobject.c:1562: bad argument to internal function

KsDef added an extra parameter and needs to be updated here.",,brandon.williams,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/10 20:20;rnirmal;1352-v2.patch;https://issues.apache.org/jira/secure/attachment/12451152/1352-v2.patch","03/Aug/10 18:22;rnirmal;1352.patch;https://issues.apache.org/jira/secure/attachment/12451142/1352.patch",,,,,,,,,,,,,2.0,rnirmal,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20098,,,Wed Aug 04 13:25:34 UTC 2010,,,,,,,,,,"0|i0g4j3:",92164,,,,,Low,,,,,,,,,,,,,,,,,"03/Aug/10 19:37;brandon.williams;This is the second time we've had to fix this.  Can we change the ks/cf definitions to use kwargs as much as possible to avoid any future problems?;;;","03/Aug/10 20:20;rnirmal;Good thought, I've updated v2 to use kwargs.;;;","03/Aug/10 20:41;brandon.williams;Thanks!  Committed.;;;","04/Aug/10 13:25;hudson;Integrated in Cassandra #509 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/509/])
    Use keyword args for CfDef/KsDef to futureproof.  Patch by  Nirmal Ranganathan, reviewed by brandonwilliams for CASSANDRA-1352
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Avro Schema Swap,CASSANDRA-1351,12470732,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,stuhood,stuhood,stuhood,03/Aug/10 15:58,16/Apr/19 09:33,14/Jul/23 05:51,03/Aug/10 17:21,0.7 beta 1,,,,0,,,,,,"Due to misreading Avro's docs, I swapped the Schema parameters to Avro's schema resolver.

The schema resolver allows for backwards compatibility by accepting a writer's (ser.) and reader's (deser.) schema, and resolving them to determine which fields to add or ignore. The reader's schema was not being set correctly, which was breaking backwards compatibility (although not the disk format).",,arya,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/10 15:58;stuhood;0001-Specify-the-readers-schema-as-different-from-the-wri.patch;https://issues.apache.org/jira/secure/attachment/12451130/0001-Specify-the-readers-schema-as-different-from-the-wri.patch",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20097,,,Wed Aug 04 13:25:33 UTC 2010,,,,,,,,,,"0|i0g4iv:",92163,,,,,Critical,,,,,,,,,,,,,,,,,"03/Aug/10 16:17;stuhood;Also, I opened AVRO-603 to handle clarifying these docs.;;;","03/Aug/10 17:21;gdusbabek;+1 committed (I left testKSMetaDataSerialization() in);;;","04/Aug/10 13:25;hudson;Integrated in Cassandra #509 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/509/])
    specify schema used to read serialized migrations. patch by stuhood, reviewed by gdusbabek. CASSANDRA-1351
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DynamicEndpointSnitch is defeated by the caching done in Strategy,CASSANDRA-1350,12470730,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,jbellis,jbellis,03/Aug/10 14:56,16/Apr/19 09:33,14/Jul/23 05:51,12/Aug/10 14:41,0.7 beta 2,,,,0,,,,,,"can we move the caching into AbstractEndpointSnitch instead?

also: AES.register appears to never be called.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Aug/10 17:43;gdusbabek;0001-move-endpoint-cache-from-ARS-to-AES.patch;https://issues.apache.org/jira/secure/attachment/12451348/0001-move-endpoint-cache-from-ARS-to-AES.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20096,,,Sat Aug 14 12:48:35 UTC 2010,,,,,,,,,,"0|i0g4in:",92162,,,,,Normal,,,,,,,,,,,,,,,,,"05/Aug/10 17:44;gdusbabek;I noticed that DynamicEndpointSnitch doesn't worry much about invalidating windows (and scores) from nodes that are decommissioned.  Is that on purpose?;;;","07/Aug/10 14:08;jbellis;won't those be taken care of by the every-10-minutes global invalidate?;;;","09/Aug/10 14:57;gdusbabek;Their latencies are cleared, but the scores and windows are never removed.  It's a minor point, but updateScores() could be a little more efficient if it didn't have to consider decommissioned nodes.;;;","11/Aug/10 17:21;brandon.williams;The latencies being cleared is the most important part.  At the next interval, if no more latency data is received for that node, updateScores() going to calculate a score for an empty deque, which means the score() function is just to going to do a size check and return 0, which is pretty cheap, so I'm not sure it's worth the extra complexity of notifying the snitch about decommissioned nodes.;;;","12/Aug/10 14:07;jbellis;+1 Gary's patch;;;","14/Aug/10 12:48;hudson;Integrated in Cassandra #514 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/514/])
    move endpoint cache from ARS to AES. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1350
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"DynamicEndpointSnitch should implement AbstractRackAwareSnitch, not AbstractEndpointSnitch",CASSANDRA-1349,12470719,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,slebresne,slebresne,03/Aug/10 12:32,16/Apr/19 09:33,14/Jul/23 05:51,03/Aug/10 15:50,0.7 beta 1,,,,0,,,,,,Everything's in the summary I believe,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/10 12:33;slebresne;1349-Make-DynamicEndpointSnitch-implements-AbstractRackAw.patch;https://issues.apache.org/jira/secure/attachment/12451119/1349-Make-DynamicEndpointSnitch-implements-AbstractRackAw.patch","03/Aug/10 15:42;slebresne;1349-Remove-test-for-AbstractRackAwareSnitch-in-rack-awar.patch;https://issues.apache.org/jira/secure/attachment/12451129/1349-Remove-test-for-AbstractRackAwareSnitch-in-rack-awar.patch",,,,,,,,,,,,,2.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20095,,,Wed Aug 04 13:25:31 UTC 2010,,,,,,,,,,"0|i0g4if:",92161,,,,,Low,,,,,,,,,,,,,,,,,"03/Aug/10 14:53;jbellis;the right fix is to remove the instanceof check in DatacenterShardStrategy instead ;;;","03/Aug/10 15:49;slebresne;You're right. Attaching patch that just do that. I guess it would nice to get an InvalidRequestException when you try to insert a keyspace with a strategy incompatible with your snitch. But maybe the first move would be to make the snitch configuration per keyspace ?;;;","03/Aug/10 15:50;jbellis;committed
;;;","03/Aug/10 15:55;jbellis;I don't think it makes sense for ""which node is closer"" to depend on what keyspace you're talking about;;;","04/Aug/10 13:25;hudson;Integrated in Cassandra #509 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/509/])
    remove instanceof checks for AbstractRackAwareSnitch.  patch by Sylvain Lebresne; reviewed by jbellis for CASSANDRA-1349
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failed to delete commitlog when restarting service,CASSANDRA-1348,12470702,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,vjevdokimov,vjevdokimov,03/Aug/10 08:42,16/Apr/19 09:33,14/Jul/23 05:51,07/Sep/10 16:25,0.6.6,0.7 beta 2,,,0,,,,,,"When restarting any Cassandra node we've got exception:

ERROR 09:42:27,869 Exception encountered during startup.
java.io.IOException: Failed to delete C:\cassandra\data\commitlog\CommitLog-1280817512228.log
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:45)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:177)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:120)
	at org.apache.cassandra.service.AbstractCassandraDaemon.init(AbstractCassandraDaemon.java:57)
	at org.apache.cassandra.contrib.windows.service.WindowsService.start(Unknown Source)
	at org.apache.cassandra.contrib.windows.service.WindowsService.main(Unknown Source)
 INFO 09:42:27,869 Exception encountered during startup.
 INFO 09:42:27,869 Cassandra Service Finished: Tue Aug 03 09:42:27 EEST 2010

Aftrer exception was thrown and Cassandra didn't started, within commitlog directory there's only one file: CommitLog-1280817512228.log
and no CommitLog-1280817512228.log.header. Looks like CommitLog-1280817512228.log was a new file, not the last one after stopping service.

After few restarts .log file is deleted and Cassandra is working fine until next restart.",Windows Server 2008 R2 64bit,vjevdokimov,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Sep/10 15:24;jbellis;1348-2.txt;https://issues.apache.org/jira/secure/attachment/12454023/1348-2.txt","03/Aug/10 15:15;jbellis;1348.txt;https://issues.apache.org/jira/secure/attachment/12451125/1348.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20094,,,Tue Sep 07 16:25:49 UTC 2010,,,,,,,,,,"0|i0g4i7:",92160,,gdusbabek,,gdusbabek,Low,,,,,,,,,,,,,,,,,"03/Aug/10 15:16;jbellis;windows gets pissy when you try to delete an open file.  this patch closes it before the delete.;;;","03/Aug/10 15:38;gdusbabek;+1;;;","03/Aug/10 15:48;jbellis;committed;;;","04/Aug/10 13:25;hudson;Integrated in Cassandra #509 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/509/])
    close commitlog reader before deleting it
patch by jbellis; reviewed by gdusbabek for CASSANDRA-1348
;;;","03/Sep/10 08:49;vjevdokimov;Still could happen with 0.7 beta 1. Not always, but happens.;;;","03/Sep/10 14:18;jbellis;new stacktrace?;;;","04/Sep/10 07:58;vjevdokimov; INFO 13:38:04,311 Received start command
 INFO 13:38:04,311 Cassandra Service Starting: Fri Sep 03 13:38:04 CEST 2010
 INFO 13:38:04,467 DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
 INFO 13:38:04,592 Sampling index for D:\cassandra\data\data\system\Statistics-e-501-<>
 INFO 13:38:04,639 Sampling index for D:\cassandra\data\data\system\Statistics-e-502-<>
 INFO 13:38:04,670 Sampling index for D:\cassandra\data\data\system\Schema-e-1-<>
 INFO 13:38:04,670 Sampling index for D:\cassandra\data\data\system\Schema-e-2-<>
 INFO 13:38:04,670 Sampling index for D:\cassandra\data\data\system\Schema-e-3-<>
 INFO 13:38:04,701 Sampling index for D:\cassandra\data\data\system\Migrations-e-1-<>
 INFO 13:38:04,701 Sampling index for D:\cassandra\data\data\system\Migrations-e-2-<>
 INFO 13:38:04,701 Sampling index for D:\cassandra\data\data\system\Migrations-e-3-<>
 INFO 13:38:04,717 Sampling index for D:\cassandra\data\data\system\LocationInfo-e-9-<>
 INFO 13:38:04,717 Sampling index for D:\cassandra\data\data\system\LocationInfo-e-10-<>
 INFO 13:38:04,717 Sampling index for D:\cassandra\data\data\system\LocationInfo-e-11-<>
 INFO 13:38:04,717 Sampling index for D:\cassandra\data\data\system\HintsColumnFamily-e-24-<>
 INFO 13:38:04,732 Sampling index for D:\cassandra\data\data\system\HintsColumnFamily-e-25-<>
 INFO 13:38:04,732 Sampling index for D:\cassandra\data\data\system\HintsColumnFamily-e-26-<>
 INFO 13:38:04,732 Sampling index for D:\cassandra\data\data\system\HintsColumnFamily-e-28-<>
 INFO 13:38:04,732 Sampling index for D:\cassandra\data\data\system\HintsColumnFamily-e-30-<>
 INFO 13:38:04,732 Sampling index for D:\cassandra\data\data\system\HintsColumnFamily-e-33-<>
 INFO 13:38:04,763 Loading schema version 6e908998-aa17-11df-bf55-cacedb26d926
 INFO 13:38:05,013 Sampling index for D:\cassandra\data\data\BehavioralTargeting\CookieTrackingSetupMemberships-e-25-<>
 INFO 13:38:07,588 Sampling index for D:\cassandra\data\data\BehavioralTargeting\CookieTrackingSetupMemberships-e-150-<>
 INFO 13:38:10,837 Sampling index for D:\cassandra\data\data\BehavioralTargeting\CookieTrackingSetupMemberships-e-279-<>
 INFO 13:38:14,550 Sampling index for D:\cassandra\data\data\BehavioralTargeting\CookieTrackingSetupMemberships-e-412-<>
 INFO 13:38:17,747 Sampling index for D:\cassandra\data\data\BehavioralTargeting\CookieTrackingSetupMemberships-e-461-<>
 INFO 13:38:18,948 Creating new commitlog segment E:/cassandra/data/commitlog\CommitLog-1283513898948.log
 INFO 13:38:18,964 Deleted D:\cassandra\data\data\BehavioralTargeting\CookieTrackingSetupMemberships-e-470-Data.db
 INFO 13:38:18,964 Deleted D:\cassandra\data\data\BehavioralTargeting\CookieTrackingSetupMemberships-e-479-Data.db
 INFO 13:38:18,979 Deleted D:\cassandra\data\data\BehavioralTargeting\CookieTrackingSetupMemberships-e-492-Data.db
 INFO 13:38:18,979 Deleted D:\cassandra\data\data\BehavioralTargeting\CookieTrackingSetupMemberships-e-497-Data.db
 INFO 13:38:18,979 Sampling index for D:\cassandra\data\data\BehavioralTargeting\CookieTrackingSetupMemberships-e-498-<>
 INFO 13:38:20,118 Replaying E:\cassandra\data\commitlog\CommitLog-1283513833929.log, E:\cassandra\data\commitlog\CommitLog-1283513898948.log
 INFO 13:38:20,134 E:\cassandra\data\commitlog\CommitLog-1283513833929.log.header incomplete, missing or corrupt.  Everything is ok, don't panic.  CommitLog will be replayed from the beginning
 INFO 13:38:20,150 Finished reading E:\cassandra\data\commitlog\CommitLog-1283513833929.log
 INFO 13:38:20,150 Finished reading E:\cassandra\data\commitlog\CommitLog-1283513898948.log
 INFO 13:38:20,150 switching in a fresh Memtable for Statistics at CommitLogContext(file='E:/cassandra/data/commitlog\CommitLog-1283513898948.log', position=592)
 INFO 13:38:20,165 Enqueuing flush of Memtable-Statistics@1582759704(15004 bytes, 4 operations)
 INFO 13:38:20,165 Writing Memtable-Statistics@1582759704(15004 bytes, 4 operations)
 INFO 13:38:20,508 Completed flushing D:\cassandra\data\data\system\Statistics-e-503-Data.db
 INFO 13:38:20,508 Recovery complete
ERROR 13:38:20,508 Exception encountered during startup.
java.io.IOException: Failed to delete E:\cassandra\data\commitlog\CommitLog-1283513898948.log
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:45)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:178)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:120)
	at org.apache.cassandra.service.AbstractCassandraDaemon.init(AbstractCassandraDaemon.java:57)
	at org.apache.cassandra.contrib.windows.service.WindowsService.start(Unknown Source)
	at org.apache.cassandra.contrib.windows.service.WindowsService.main(Unknown Source)
 INFO 13:38:20,555 Exception encountered during startup.
 INFO 13:38:20,555 Cassandra Service Finished: Fri Sep 03 13:38:20 CEST 2010
;;;","07/Sep/10 15:24;jbellis;it logs ""Finished reading"" which means it's successfully closed the reader, so there's nothing in Cassandra blocking the delete.  patch -2 makes failure to delete a non-fatal error.;;;","07/Sep/10 15:27;jbellis;backported try/finally from original patch to 0.6.  (failure to delete is already non-fatal there.);;;","07/Sep/10 15:49;gdusbabek;+1 on the new patch.;;;","07/Sep/10 16:25;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
gossip throws IllegalStateException,CASSANDRA-1343,12470543,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,gdusbabek,gdusbabek,30/Jul/10 19:34,16/Apr/19 09:33,14/Jul/23 05:51,03/Aug/10 18:37,0.7 beta 1,,,,0,,,,,,"when starting a second node, gossip throws IllegalStateException when KS with RF>1 defined on an existing 1-node cluster.

we should be able to define keyspaces on a cluster of any size.",,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1191,CASSANDRA-1428,,,,"03/Aug/10 18:23;gdusbabek;0001-complain-if-there-aren-t-enough-nodes-to-support-req.patch;https://issues.apache.org/jira/secure/attachment/12451143/0001-complain-if-there-aren-t-enough-nodes-to-support-req.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20090,,,Fri Sep 03 23:28:09 UTC 2010,,,,,,,,,,"0|i0g4h3:",92155,,,,,Low,,,,,,,,,,,,,,,,,"30/Jul/10 19:43;gdusbabek;/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/bin/java -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:54219,suspend=y,server=n -ea -Xms128M -Xmx1G -XX:TargetSurvivorRatio=90 -XX:+AggressiveOpts -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+HeapDumpOnOutOfMemoryError -XX:SurvivorRatio=128 -XX:MaxTenuringThreshold=0 -Dcom.sun.management.jmxremote.port=8081 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcassandra -Dcassandra-foreground=yes -Dlog4j.configuration=log4j-server.properties -Dmx4jport=9081 -Dfile.encoding=MacRoman -classpath /System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/deploy.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/dt.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/javaws.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/jce.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/management-agent.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/plugin.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/sa-jdi.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/../Classes/alt-rt.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/../Classes/charsets.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/../Classes/classes.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/../Classes/dt.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/../Classes/jce.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/../Classes/jconsole.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/../Classes/jsse.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/../Classes/laf.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/../Classes/management-agent.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/../Classes/ui.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/ext/apple_provider.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/ext/dnsns.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/ext/localedata.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/ext/sunjce_provider.jar:/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/lib/ext/sunpkcs11.jar:/Users/gary.dusbabek/codes/apache/git-trunk/out/production/conf1:/Users/gary.dusbabek/codes/apache/git-trunk/out/production/core:/Users/gary.dusbabek/codes/apache/git-trunk/lib/jackson-mapper-asl-1.4.0.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/log4j-1.2.14.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/antlr-3.1.3.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/clhm-production.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/commons-cli-1.1.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/jetty-6.1.21.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/jackson-core-asl-1.4.0.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/slf4j-log4j12-1.5.8.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/hadoop-core-0.20.1.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/jug-2.0.0.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/slf4j-api-1.5.8.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/jetty-util-6.1.21.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/commons-collections-3.2.1.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/jline-0.9.94.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/servlet-api-2.5-20081211.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/high-scale-lib.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/commons-codec-1.2.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/commons-lang-2.4.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/libthrift-r959516.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/json-simple-1.1.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/snakeyaml-1.6.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/avro-1.3.3~cust2.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/guava-r05.jar:/Users/gary.dusbabek/codes/apache/git-trunk/lib/avro-1.3.3-sources~cust1.jar:/Users/gary.dusbabek/codes/apache/git-trunk/build/lib/jars/junit-4.6.jar:/Users/gary.dusbabek/codes/apache/git-trunk/out/production/thrift:/Users/gary.dusbabek/codes/apache/git-trunk/out/production/avro:/Users/gary.dusbabek/codes/apache/git-trunk/out/production/ext:/Applications/IntelliJ IDEA 9.0.1.app/lib/idea_rt.jar org.apache.cassandra.thrift.CassandraDaemon
Connected to the target VM, address: '127.0.0.1:54219', transport: 'socket'
 INFO 13:42:52,352 [main] Loading settings from /Users/gary.dusbabek/codes/apache/git-trunk/out/production/conf1/cassandra.yaml
DEBUG 13:42:52,613 [main] Syncing log with a period of 10000
 INFO 13:42:52,613 [main] DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
DEBUG 13:42:52,628 [main] setting auto_bootstrap to true
DEBUG 13:42:52,768 [main] Starting CFS Statistics
DEBUG 13:42:52,786 [main] Starting CFS Schema
DEBUG 13:42:52,788 [main] Starting CFS Migrations
DEBUG 13:42:52,800 [main] Starting CFS LocationInfo
DEBUG 13:42:52,844 [main] Starting CFS HintsColumnFamily
 INFO 13:42:52,891 [main] Couldn't detect any schema definitions in local storage.
 INFO 13:42:52,891 [main] Found table data in data directories. Consider using JMX to call org.apache.cassandra.service.StorageService.loadSchemaFromYaml().
 INFO 13:42:52,900 [main] Replaying /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515326767.log
DEBUG 13:42:52,902 [main] Replaying /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515326767.log starting at 276
DEBUG 13:42:52,903 [main] Reading mutation at 276
DEBUG 13:42:52,910 [main] replaying mutation for system.[B@5f9299f5: {ColumnFamily(LocationInfo [B:false:1@1280515327074,])}
 INFO 13:42:52,945 [main] Finished reading /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515326767.log
DEBUG 13:42:52,946 [main] Finished waiting on mutations from recovery
 INFO 13:42:52,947 [main] Creating new commitlog segment /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log
 INFO 13:42:52,953 [main] switching in a fresh Memtable for LocationInfo at CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log', position=0)
 INFO 13:42:52,966 [main] Enqueuing flush of Memtable-LocationInfo@828432489(17 bytes, 1 operations)
 INFO 13:42:52,968 [FLUSH-WRITER-POOL:1] Writing Memtable-LocationInfo@828432489(17 bytes, 1 operations)
 INFO 13:42:53,050 [FLUSH-WRITER-POOL:1] Completed flushing /Users/gary.dusbabek/cass-configs/trunk/node1/data/system/LocationInfo-e-2-Data.db
DEBUG 13:42:53,095 [CompactionExecutor:1] Checking to see if compaction of LocationInfo would be useful
DEBUG 13:42:53,096 [MEMTABLE-POST-FLUSHER:1] Discarding 1000
DEBUG 13:42:53,098 [COMMIT-LOG-WRITER] discard completed log segments for CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log', position=0), column family 1000.
DEBUG 13:42:53,098 [COMMIT-LOG-WRITER] Marking replay position 0 on commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log)
 INFO 13:42:53,100 [main] Recovery complete
DEBUG 13:42:53,101 [main] Deleting CommitLog-1280515326767.log
 INFO 13:42:53,102 [main] Log replay complete
DEBUG 13:42:53,116 [CompactionExecutor:1] Estimating compactions for HintsColumnFamily
DEBUG 13:42:53,117 [CompactionExecutor:1] Estimating compactions for LocationInfo
DEBUG 13:42:53,117 [CompactionExecutor:1] Estimating compactions for Schema
DEBUG 13:42:53,117 [CompactionExecutor:1] Estimating compactions for Migrations
DEBUG 13:42:53,117 [CompactionExecutor:1] Estimating compactions for Statistics
DEBUG 13:42:53,117 [CompactionExecutor:1] Checking to see if compaction of HintsColumnFamily would be useful
 INFO 13:42:53,117 [main] Cassandra version: 0.7.0-SNAPSHOT
 INFO 13:42:53,117 [main] Thrift API version: 9.0.0
DEBUG 13:42:53,117 [CompactionExecutor:1] Checking to see if compaction of LocationInfo would be useful
DEBUG 13:42:53,118 [CompactionExecutor:1] Checking to see if compaction of Schema would be useful
DEBUG 13:42:53,118 [CompactionExecutor:1] Checking to see if compaction of Migrations would be useful
DEBUG 13:42:53,118 [CompactionExecutor:1] Checking to see if compaction of Statistics would be useful
 INFO 13:42:53,118 [main] Saved Token found: 127492708246848026497487109173721015738
 INFO 13:42:53,119 [main] Saved ClusterName found: Test Cluster
 INFO 13:42:53,119 [main] Saved partitioner not found. Using org.apache.cassandra.dht.RandomPartitioner
 INFO 13:42:53,120 [main] switching in a fresh Memtable for LocationInfo at CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log', position=276)
 INFO 13:42:53,120 [main] Enqueuing flush of Memtable-LocationInfo@1780804346(95 bytes, 2 operations)
 INFO 13:42:53,120 [FLUSH-WRITER-POOL:1] Writing Memtable-LocationInfo@1780804346(95 bytes, 2 operations)
 INFO 13:42:53,282 [FLUSH-WRITER-POOL:1] Completed flushing /Users/gary.dusbabek/cass-configs/trunk/node1/data/system/LocationInfo-e-3-Data.db
DEBUG 13:42:53,283 [MEMTABLE-POST-FLUSHER:1] Discarding 1000
DEBUG 13:42:53,306 [COMMIT-LOG-WRITER] discard completed log segments for CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log', position=276), column family 1000.
DEBUG 13:42:53,306 [COMMIT-LOG-WRITER] Marking replay position 276 on commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log)
DEBUG 13:42:53,307 [CompactionExecutor:1] Checking to see if compaction of LocationInfo would be useful
 INFO 13:42:53,335 [main] Starting up server gossip
DEBUG 13:42:53,381 [main] clearing cached endpoints
DEBUG 13:42:53,590 [main] Will try to load mx4j now, if it's in the classpath
 INFO 13:42:53,591 [main] Will not load MX4J, mx4j-tools.jar is not in the classpath
DEBUG 13:42:54,344 [GC inspection] GC for ParNew: 13 ms, 224224 reclaimed leaving 92832088 used; max is 1211826176
DEBUG 13:42:54,345 [GC inspection] GC for ConcurrentMarkSweep: 71 ms, 67203872 reclaimed leaving 25628216 used; max is 1211826176
DEBUG 13:42:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:43:20,282 [MIGRATION-STAGE:1] Applying migration 5300795b-9c0a-11df-8af1-e700f669bcfc
 INFO 13:43:20,284 [MIGRATION-STAGE:1] switching in a fresh Memtable for Migrations at CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log', position=11790)
 INFO 13:43:20,284 [MIGRATION-STAGE:1] Enqueuing flush of Memtable-Migrations@19614086(5585 bytes, 1 operations)
 INFO 13:43:20,284 [FLUSH-WRITER-POOL:1] Writing Memtable-Migrations@19614086(5585 bytes, 1 operations)
 INFO 13:43:20,284 [MIGRATION-STAGE:1] switching in a fresh Memtable for Schema at CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log', position=11790)
 INFO 13:43:20,285 [MIGRATION-STAGE:1] Enqueuing flush of Memtable-Schema@1088945411(2768 bytes, 3 operations)
DEBUG 13:43:20,419 [GC inspection] GC for ParNew: 13 ms, 147440 reclaimed leaving 105343544 used; max is 1211826176
DEBUG 13:43:20,427 [GC inspection] GC for ConcurrentMarkSweep: 72 ms, 75573104 reclaimed leaving 29770440 used; max is 1211826176
 INFO 13:43:20,432 [FLUSH-WRITER-POOL:1] Completed flushing /Users/gary.dusbabek/cass-configs/trunk/node1/data/system/Migrations-e-1-Data.db
DEBUG 13:43:20,433 [CompactionExecutor:1] Checking to see if compaction of Migrations would be useful
 INFO 13:43:20,433 [FLUSH-WRITER-POOL:1] Writing Memtable-Schema@1088945411(2768 bytes, 3 operations)
DEBUG 13:43:20,433 [MEMTABLE-POST-FLUSHER:1] Discarding 1002
DEBUG 13:43:20,433 [COMMIT-LOG-WRITER] discard completed log segments for CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log', position=11790), column family 1002.
DEBUG 13:43:20,433 [COMMIT-LOG-WRITER] Marking replay position 11790 on commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log)
 INFO 13:43:20,595 [FLUSH-WRITER-POOL:1] Completed flushing /Users/gary.dusbabek/cass-configs/trunk/node1/data/system/Schema-e-1-Data.db
DEBUG 13:43:20,602 [MEMTABLE-POST-FLUSHER:1] Discarding 1003
DEBUG 13:43:20,602 [COMMIT-LOG-WRITER] discard completed log segments for CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log', position=11790), column family 1003.
DEBUG 13:43:20,602 [COMMIT-LOG-WRITER] Marking replay position 11790 on commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log)
DEBUG 13:43:20,608 [MIGRATION-STAGE:1] Starting CFS Super1
DEBUG 13:43:20,609 [MIGRATION-STAGE:1] Starting CFS Standard2
DEBUG 13:43:20,610 [MIGRATION-STAGE:1] Starting CFS Super2
DEBUG 13:43:20,611 [MIGRATION-STAGE:1] Starting CFS Standard1
DEBUG 13:43:20,612 [MIGRATION-STAGE:1] Starting CFS Super3
DEBUG 13:43:20,612 [MIGRATION-STAGE:1] Starting CFS StandardByUUID1
DEBUG 13:43:20,613 [CompactionExecutor:1] Checking to see if compaction of Schema would be useful
 INFO 13:43:20,626 [COMMIT-LOG-WRITER] Creating new commitlog segment /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515400626.log
DEBUG 13:43:20,657 [MIGRATION-STAGE:1] Applying migration 53580f3c-9c0a-11df-8af1-e700f669bcfc
 INFO 13:43:20,660 [MIGRATION-STAGE:1] switching in a fresh Memtable for Migrations at CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515400626.log', position=12779)
 INFO 13:43:20,660 [MIGRATION-STAGE:1] Enqueuing flush of Memtable-Migrations@193189276(6998 bytes, 1 operations)
 INFO 13:43:20,660 [MIGRATION-STAGE:1] switching in a fresh Memtable for Schema at CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515400626.log', position=12779)
 INFO 13:43:20,661 [MIGRATION-STAGE:1] Enqueuing flush of Memtable-Schema@2084371115(4181 bytes, 4 operations)
 INFO 13:43:20,661 [FLUSH-WRITER-POOL:1] Writing Memtable-Migrations@193189276(6998 bytes, 1 operations)
 INFO 13:43:20,815 [FLUSH-WRITER-POOL:1] Completed flushing /Users/gary.dusbabek/cass-configs/trunk/node1/data/system/Migrations-e-2-Data.db
 INFO 13:43:20,816 [FLUSH-WRITER-POOL:1] Writing Memtable-Schema@2084371115(4181 bytes, 4 operations)
DEBUG 13:43:20,855 [CompactionExecutor:1] Checking to see if compaction of Migrations would be useful
DEBUG 13:43:20,856 [MEMTABLE-POST-FLUSHER:1] Discarding 1002
DEBUG 13:43:20,864 [COMMIT-LOG-WRITER] discard completed log segments for CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515400626.log', position=12779), column family 1002.
DEBUG 13:43:20,864 [COMMIT-LOG-WRITER] Not safe to delete commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log); dirty is 1000, 1003, 
DEBUG 13:43:20,864 [COMMIT-LOG-WRITER] Marking replay position 12779 on commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515400626.log)
 INFO 13:43:21,040 [FLUSH-WRITER-POOL:1] Completed flushing /Users/gary.dusbabek/cass-configs/trunk/node1/data/system/Schema-e-2-Data.db
DEBUG 13:43:21,041 [CompactionExecutor:1] Checking to see if compaction of Schema would be useful
DEBUG 13:43:21,041 [MEMTABLE-POST-FLUSHER:1] Discarding 1003
DEBUG 13:43:21,041 [COMMIT-LOG-WRITER] discard completed log segments for CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515400626.log', position=12779), column family 1003.
DEBUG 13:43:21,041 [COMMIT-LOG-WRITER] Not safe to delete commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log); dirty is 1000, 
DEBUG 13:43:21,042 [COMMIT-LOG-WRITER] Marking replay position 12779 on commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515400626.log)
DEBUG 13:43:21,044 [MIGRATION-STAGE:1] Starting CFS Super1
DEBUG 13:43:21,050 [MIGRATION-STAGE:1] Starting CFS Standard2
DEBUG 13:43:21,051 [MIGRATION-STAGE:1] Starting CFS Super2
DEBUG 13:43:21,052 [MIGRATION-STAGE:1] Starting CFS Standard1
DEBUG 13:43:21,053 [MIGRATION-STAGE:1] Starting CFS Super3
DEBUG 13:43:21,058 [MIGRATION-STAGE:1] Starting CFS StandardByUUID1
 INFO 13:43:21,061 [COMMIT-LOG-WRITER] Creating new commitlog segment /Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515401061.log
 INFO 13:43:21,073 [RMI TCP Connection(2)-10.6.34.56] switching in a fresh Memtable for LocationInfo at CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515401061.log', position=5708)
 INFO 13:43:21,081 [RMI TCP Connection(2)-10.6.34.56] Enqueuing flush of Memtable-LocationInfo@300139206(17 bytes, 1 operations)
 INFO 13:43:21,082 [FLUSH-WRITER-POOL:1] Writing Memtable-LocationInfo@300139206(17 bytes, 1 operations)
 INFO 13:43:21,093 [RMI TCP Connection(2)-10.6.34.56] switching in a fresh Memtable for Schema at CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515401061.log', position=5708)
 INFO 13:43:21,100 [RMI TCP Connection(2)-10.6.34.56] Enqueuing flush of Memtable-Schema@972791731(4181 bytes, 4 operations)
 INFO 13:43:21,235 [FLUSH-WRITER-POOL:1] Completed flushing /Users/gary.dusbabek/cass-configs/trunk/node1/data/system/LocationInfo-e-4-Data.db
 INFO 13:43:21,235 [FLUSH-WRITER-POOL:1] Writing Memtable-Schema@972791731(4181 bytes, 4 operations)
DEBUG 13:43:21,239 [MEMTABLE-POST-FLUSHER:1] Discarding 1000
DEBUG 13:43:21,240 [COMMIT-LOG-WRITER] discard completed log segments for CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515401061.log', position=5708), column family 1000.
 INFO 13:43:21,240 [COMMIT-LOG-WRITER] Discarding obsolete commit log:CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515372947.log)
DEBUG 13:43:21,243 [CompactionExecutor:1] Checking to see if compaction of LocationInfo would be useful
DEBUG 13:43:21,439 [GC inspection] GC for ParNew: 7 ms, 350704 reclaimed leaving 105776848 used; max is 1211826176
DEBUG 13:43:21,439 [GC inspection] GC for ConcurrentMarkSweep: 114 ms, 75637088 reclaimed leaving 30139760 used; max is 1211826176
 INFO 13:43:21,450 [CompactionExecutor:1] Compacting [org.apache.cassandra.io.sstable.SSTableReader(path='/Users/gary.dusbabek/cass-configs/trunk/node1/data/system/LocationInfo-e-1-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='/Users/gary.dusbabek/cass-configs/trunk/node1/data/system/LocationInfo-e-2-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='/Users/gary.dusbabek/cass-configs/trunk/node1/data/system/LocationInfo-e-3-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='/Users/gary.dusbabek/cass-configs/trunk/node1/data/system/LocationInfo-e-4-Data.db')]
DEBUG 13:43:21,465 [CompactionExecutor:1] Expected bloom filter size : 1024
DEBUG 13:43:21,466 [COMMIT-LOG-WRITER] Not safe to delete commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515400626.log); dirty is 1003, 1002, 
DEBUG 13:43:21,469 [COMMIT-LOG-WRITER] Marking replay position 5708 on commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515401061.log)
DEBUG 13:43:21,471 [FILEUTILS-DELETE-POOL:1] Deleting CommitLog-1280515372947.log.header
DEBUG 13:43:21,473 [FILEUTILS-DELETE-POOL:1] Deleting CommitLog-1280515372947.log
 INFO 13:43:21,484 [FLUSH-WRITER-POOL:1] Completed flushing /Users/gary.dusbabek/cass-configs/trunk/node1/data/system/Schema-e-3-Data.db
DEBUG 13:43:21,486 [MEMTABLE-POST-FLUSHER:1] Discarding 1003
DEBUG 13:43:21,489 [COMMIT-LOG-WRITER] discard completed log segments for CommitLogContext(file='/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515401061.log', position=5708), column family 1003.
DEBUG 13:43:21,495 [COMMIT-LOG-WRITER] Not safe to delete commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515400626.log); dirty is 1002, 
DEBUG 13:43:21,496 [COMMIT-LOG-WRITER] Marking replay position 5708 on commit log CommitLogSegment(/Users/gary.dusbabek/cass-configs/trunk/node1/commitlog/CommitLog-1280515401061.log)
 INFO 13:43:22,016 [CompactionExecutor:1] Compacted to /Users/gary.dusbabek/cass-configs/trunk/node1/data/system/LocationInfo-tmp-e-5-Data.db.  913 to 492 (~53% of original) bytes for 2 keys.  Time: 554ms.
DEBUG 13:43:22,016 [CompactionExecutor:1] Checking to see if compaction of Schema would be useful
DEBUG 13:43:22,016 [CompactionExecutor:1] Checking to see if compaction of LocationInfo would be useful
DEBUG 13:43:22,439 [GC inspection] GC for ParNew: 11 ms, 1461000 reclaimed leaving 109998456 used; max is 1211826176
DEBUG 13:43:22,439 [GC inspection] GC for ConcurrentMarkSweep: 87 ms, 75576552 reclaimed leaving 34421904 used; max is 1211826176
DEBUG 13:43:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:44:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:45:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:46:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:47:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:48:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:49:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:50:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:51:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:52:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:53:55,374 [Timer-1] Disseminating load info ...
DEBUG 13:54:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:55:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:56:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:57:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:58:55,373 [Timer-1] Disseminating load info ...
DEBUG 13:59:55,374 [Timer-1] Disseminating load info ...
DEBUG 14:00:55,379 [Timer-1] Disseminating load info ...
DEBUG 14:01:55,380 [Timer-1] Disseminating load info ...
DEBUG 14:02:55,381 [Timer-1] Disseminating load info ...
DEBUG 14:03:55,382 [Timer-1] Disseminating load info ...
DEBUG 14:04:55,383 [Timer-1] Disseminating load info ...
DEBUG 14:05:55,383 [Timer-1] Disseminating load info ...
DEBUG 14:06:55,383 [Timer-1] Disseminating load info ...
DEBUG 14:07:55,383 [Timer-1] Disseminating load info ...
DEBUG 14:08:55,383 [Timer-1] Disseminating load info ...
DEBUG 14:09:36,781 [GC inspection] GC for ParNew: 1 ms, 21480096 reclaimed leaving 22127704 used; max is 1211826176
DEBUG 14:09:55,383 [Timer-1] Disseminating load info ...
DEBUG 14:10:55,384 [Timer-1] Disseminating load info ...
DEBUG 14:11:55,384 [Timer-1] Disseminating load info ...
DEBUG 14:12:55,385 [Timer-1] Disseminating load info ...
DEBUG 14:13:55,385 [Timer-1] Disseminating load info ...
DEBUG 14:14:55,385 [Timer-1] Disseminating load info ...
DEBUG 14:15:55,384 [Timer-1] Disseminating load info ...
DEBUG 14:16:55,384 [Timer-1] Disseminating load info ...
DEBUG 14:17:55,384 [Timer-1] Disseminating load info ...
DEBUG 14:18:55,384 [Timer-1] Disseminating load info ...
DEBUG 14:19:55,385 [Timer-1] Disseminating load info ...
DEBUG 14:20:55,385 [Timer-1] Disseminating load info ...
DEBUG 14:21:55,386 [Timer-1] Disseminating load info ...
DEBUG 14:22:06,144 [ROW-READ-STAGE:3] Their data definitions are old. Sending updates since 00000000-0000-1000-0000-000000000000
DEBUG 14:22:06,166 [ROW-READ-STAGE:3] collecting 0 of 1000: 5300795b-9c0a-11df-8af1-e700f669bcfc:false:5554@1280515400281
DEBUG 14:22:06,166 [ROW-READ-STAGE:3] collecting 1 of 1000: 53580f3c-9c0a-11df-8af1-e700f669bcfc:false:6967@1280515400638
DEBUG 14:22:06,169 [WRITE-/127.0.0.2] attempting to connect to /127.0.0.2
DEBUG 14:22:06,992 [WRITE-/127.0.0.2] attempting to connect to /127.0.0.2
 INFO 14:22:07,349 [GOSSIP_STAGE:1] Node /127.0.0.2 is now part of the cluster
DEBUG 14:22:07,349 [GOSSIP_STAGE:1] Resetting pool for /127.0.0.2
DEBUG 14:22:07,893 [WRITE-/127.0.0.2] attempting to connect to /127.0.0.2
 INFO 14:22:07,980 [HINTED-HANDOFF-POOL:1] Started hinted handoff for endpoint /127.0.0.2
 INFO 14:22:07,980 [GOSSIP_STAGE:1] InetAddress /127.0.0.2 is now UP
 INFO 14:22:07,985 [HINTED-HANDOFF-POOL:1] Finished hinted handoff of 0 rows to endpoint /127.0.0.2
DEBUG 14:22:55,386 [Timer-1] Disseminating load info ...
DEBUG 14:23:35,990 [MESSAGE-DESERIALIZER-POOL:1] Running  on default stage
DEBUG 14:23:36,913 [GOSSIP_STAGE:1] Node /127.0.0.2 state bootstrapping, token 61078635599166706937511052402724559481
ERROR 14:23:36,915 [GOSSIP_STAGE:1] Error in ThreadPoolExecutor
java.lang.IllegalStateException: replication factor (3) exceeds number of endpoints (1)
	at org.apache.cassandra.locator.RackUnawareStrategy.calculateNaturalEndpoints(RackUnawareStrategy.java:61)
	at org.apache.cassandra.locator.AbstractReplicationStrategy.getAddressRanges(AbstractReplicationStrategy.java:180)
	at org.apache.cassandra.locator.AbstractReplicationStrategy.getAddressRanges(AbstractReplicationStrategy.java:207)
	at org.apache.cassandra.service.StorageService.calculatePendingRanges(StorageService.java:786)
	at org.apache.cassandra.service.StorageService.calculatePendingRanges(StorageService.java:767)
	at org.apache.cassandra.service.StorageService.handleStateBootstrap(StorageService.java:607)
	at org.apache.cassandra.service.StorageService.onChange(StorageService.java:569)
	at org.apache.cassandra.gms.Gossiper.doNotifications(Gossiper.java:721)
	at org.apache.cassandra.gms.Gossiper.applyApplicationStateLocally(Gossiper.java:686)
	at org.apache.cassandra.gms.Gossiper.applyStateLocally(Gossiper.java:640)
	at org.apache.cassandra.gms.GossipDigestAckVerbHandler.doVerb(GossipDigestAckVerbHandler.java:61)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:41)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:637)
ERROR 14:23:36,916 [GOSSIP_STAGE:1] Uncaught exception in thread Thread[GOSSIP_STAGE:1,5,main]
java.lang.IllegalStateException: replication factor (3) exceeds number of endpoints (1)
	at org.apache.cassandra.locator.RackUnawareStrategy.calculateNaturalEndpoints(RackUnawareStrategy.java:61)
	at org.apache.cassandra.locator.AbstractReplicationStrategy.getAddressRanges(AbstractReplicationStrategy.java:180)
	at org.apache.cassandra.locator.AbstractReplicationStrategy.getAddressRanges(AbstractReplicationStrategy.java:207)
	at org.apache.cassandra.service.StorageService.calculatePendingRanges(StorageService.java:786)
	at org.apache.cassandra.service.StorageService.calculatePendingRanges(StorageService.java:767)
	at org.apache.cassandra.service.StorageService.handleStateBootstrap(StorageService.java:607)
	at org.apache.cassandra.service.StorageService.onChange(StorageService.java:569)
	at org.apache.cassandra.gms.Gossiper.doNotifications(Gossiper.java:721)
	at org.apache.cassandra.gms.Gossiper.applyApplicationStateLocally(Gossiper.java:686)
	at org.apache.cassandra.gms.Gossiper.applyStateLocally(Gossiper.java:640)
	at org.apache.cassandra.gms.GossipDigestAckVerbHandler.doVerb(GossipDigestAckVerbHandler.java:61)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:41)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:637)
DEBUG 14:23:55,387 [Timer-1] Disseminating load info ...
 INFO 14:24:07,913 [WRITE-/127.0.0.2] error writing to /127.0.0.2
DEBUG 14:24:08,912 [WRITE-/127.0.0.2] attempting to connect to /127.0.0.2
 INFO 14:24:12,913 [Timer-0] InetAddress /127.0.0.2 is now dead.
DEBUG 14:24:12,914 [Timer-0] Resetting pool for /127.0.0.2
DEBUG 14:24:19,913 [WRITE-/127.0.0.2] attempting to connect to /127.0.0.2
DEBUG 14:24:30,913 [WRITE-/127.0.0.2] attempting to connect to /127.0.0.2
DEBUG 14:24:41,925 [WRITE-/127.0.0.2] attempting to connect to /127.0.0.2
Disconnected from the target VM, address: '127.0.0.1:54219', transport: 'socket'

Process finished with exit code 255
;;;","30/Jul/10 22:48;gdusbabek;solution: bring all nodes up, then load schema.;;;","30/Jul/10 22:50;gdusbabek;On second thought, I think the right solution is to disallow KS creation when the number of live nodes cannot support the replication factor.;;;","03/Aug/10 18:33;jbellis;+1;;;","04/Aug/10 13:25;hudson;Integrated in Cassandra #509 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/509/])
    complain if there aren't enough nodes to support requested RF. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1343
;;;","03/Sep/10 23:28;blanquer;the same or something similar is still happening in beta1
I've opened a ticket that results in the same error message, however I believe it is different since it doesn't happen when trying to create a KS but when bringing up a new node:
https://issues.apache.org/jira/browse/CASSANDRA-1467;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
making cassandra-cli friendlier to scripts,CASSANDRA-1340,12470478,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,urandom,urandom,29/Jul/10 22:43,16/Apr/19 09:33,14/Jul/23 05:51,30/Jul/10 21:07,0.7 beta 1,,Legacy/Tools,,0,,,,,,"It is currently possible (and useful) to execute bulk commands with cassandra-cli using shell redirection. However, there is  no mechanism for handling errors, and the same output seen in an interactive session is echoed to the terminal.

The patch that follows accepts a new argument, (--batch), which:
* disables initialization of the history file
* suppresses output (stdout only)
* exits on error with status 2 for invalid syntax, 4 for invalid requests, and 8 for everything else.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jul/10 22:44;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1340.-cassandra-cli-batch-processing-mode.txt;https://issues.apache.org/jira/secure/attachment/12450870/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1340.-cassandra-cli-batch-processing-mode.txt",,,,,,,,,,,,,,1.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20088,,,Sat Jul 31 12:51:02 UTC 2010,,,,,,,,,,"0|i0g4gf:",92152,,,,,Low,,,,,,,,,,,,,,,,,"29/Jul/10 23:37;jbellis;+1;;;","30/Jul/10 21:07;urandom;committed.;;;","31/Jul/10 12:51;hudson;Integrated in Cassandra #505 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/505/])
    CASSANDRA-1340. cassandra-cli: batch processing mode

Passing --batch on the command line causes normal output to be suppressed,
and errors to be fatal. Useful for executing bulk commands in a script ala:

   bin/cassandra-cli < commands.txt

Patch by eevans for CASSANDRA-1340
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cfstats shows deleted cfs,CASSANDRA-1334,12470463,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,arya,arya,29/Jul/10 19:00,16/Apr/19 09:33,14/Jul/23 05:51,03/Aug/10 20:14,0.7 beta 1,,,,0,,,,,,"cfstats shows deleted CFs inside the keyspace after the CF was deleted from the keyspace using thrift service call system_drop_column_family

Steps to Reproduce:
1. Setup a 3 node cluster with clean slate from trunc;
2. create a keyspace with rf=2 and a standard cf using service call system_add_keyspace
3. create another cf with system_add_column_family
4. batch_mutate some rows into the new column family you created in step 3
5. call describe_keyspace to get a list of cfs inside your KS
6. iterate through the result and call system_drop_column_family for each
7. look at cfstats result. it is still showing the very first cf we create in step 2 in the list","CentOS 5.2
trunk",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/10 19:53;gdusbabek;0001-unregiter-CF-mbeans-when-a-CF-is-dropped.patch;https://issues.apache.org/jira/secure/attachment/12451149/0001-unregiter-CF-mbeans-when-a-CF-is-dropped.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20087,,,Wed Aug 04 13:25:31 UTC 2010,,,,,,,,,,"0|i0g4fb:",92147,,,,,Normal,,,,,,,,,,,,,,,,,"03/Aug/10 19:56;jbellis;should we add a CFS.getMBeanName to remove the potential for that code getting out of sync w/ the register?

+1 otherwise;;;","03/Aug/10 20:02;gdusbabek;yeah. that makes good sense.  I'll put it in when I commit.;;;","04/Aug/10 13:25;hudson;Integrated in Cassandra #509 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/509/])
    unregister CF mbean when a CF is dropped. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1334
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cli cannot connect ,CASSANDRA-1333,12470395,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,arya,arya,29/Jul/10 00:06,16/Apr/19 09:33,14/Jul/23 05:51,29/Jul/10 01:49,0.7 beta 1,,,,0,,,,,,"I cannot connect to any of my nodes using Cassandra-CLI. I think this has happened about 2 weeks ago:

[agoudarzi@cas-test1 bin]$ cassandra-cli --host 10.50.26.132 --port 9160 --debug
Exception retrieving information about the cassandra node, check you have connected to the thrift port.
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:84)
	at org.apache.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)
	at org.apache.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:84)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:369)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:295)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:202)
	at org.apache.cassandra.thrift.Cassandra$Client.recv_describe_cluster_name(Cassandra.java:1117)
	at org.apache.cassandra.thrift.Cassandra$Client.describe_cluster_name(Cassandra.java:1103)
	at org.apache.cassandra.cli.CliMain.connect(CliMain.java:164)
	at org.apache.cassandra.cli.CliMain.main(CliMain.java:255)
Welcome to cassandra CLI.

Type 'help' or '?' for help. Type 'quit' or 'exit' to quit.
[default@unknown] exit                     

However using Thrift PHP Client I have no problem connecting and executing describe_cluster_name().

I have configured Cassandra RPC port and IP as follows:

# The address to bind the Thrift RPC service to
rpc_address: 10.50.26.132
# port for Thrift to listen on
rpc_port: 9160

Steps to Reproduce:
1. Start from a clean setup;
2. Run py_stress to insert some keys and create the default keyspace;
3. Try connecting using cassandra-cli like command above. You'll get the Exception.
","CentOS 5.2
trunk",arya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20086,,,Mon Nov 22 02:07:24 UTC 2010,,,,,,,,,,"0|i0g4f3:",92146,,,,,Normal,,,,,,,,,,,,,,,,,"29/Jul/10 00:17;arya;More Info:

The server log says my client is old! But I am using the latest build from trunc:

ERROR [pool-1-thread-22] 2010-07-28 17:09:54,688 CustomTThreadPoolServer.java (line 175) Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:211)
	at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:2587)
	at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)
;;;","29/Jul/10 01:49;jbellis;fixed in r980285.  thanks!;;;","21/Nov/10 13:05;jpartogi;Is this broken in 0.7.0-beta3 again?

I am getting this error when trying to connect from CLI:
[default@unknown] connect localhost/9160 
Exception retrieving information about the cassandra node, check you have connected to the thrift port.

Cassandra is running and thrift is bound to port 9160;;;","22/Nov/10 02:07;jbellis;No. Probably you are running server in un-framed mode; cli defaults to trying to connect w/ framed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Scan results out of order,CASSANDRA-1332,12470387,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,drevell,drevell,28/Jul/10 22:43,16/Apr/19 09:33,14/Jul/23 05:51,06/Aug/10 00:50,0.7 beta 1,,,,0,,,,,,"After inserting 10 keys ('0', '1', ... '9') and running scan() with start_key='' and count=7, scan() returns the keys  ['7', '3', '6', '5', '0', '8', '2']. When I scan() again with start_key='2' and count=7, I get the keys  ['2', '1', '9', '4', '7']. Notice that key ""7"" appears in both result sets, and the relative order of keys ""7"" and ""2"" is inconsistent between the two scan results. 

I see the problem when running on a 4-node cluster. When I run on a 1-node cluster, the problem does not occur. So the attached system test always passes, since system tests use a 1-node cluster, so the test doesn't actually demonstrate the problem.

A standalone Python program that reproduces the problem is at: http://pastebin.com/FwitG4wf","CentOS 5, Java 1.6.0, Cassandra trunk as of 28 July 2010",drevell,hammer,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jul/10 22:54;drevell;scan_test.patch;https://issues.apache.org/jira/secure/attachment/12450766/scan_test.patch",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20085,,,Fri Aug 06 00:50:39 UTC 2010,,,,,,,,,,"0|i0g4ev:",92145,,,,,Normal,,,,,,,,,,,,,,,,,"28/Jul/10 22:54;drevell;System test that reproduces the problem on a 4-node cluster;;;","29/Jul/10 00:25;brandon.williams;FWIW, Dave also told me that increasing the CL doesn't help, so it's not a consistency issue.;;;","29/Jul/10 01:43;jbellis;is this also present in 0.6.4?;;;","29/Jul/10 01:52;drevell;It isn't present in exactly the same form in 0.6.4 because scan() is new in 0.7. Would it be worth testing 0.6.4 get_range_slices and looking for similar behavior?;;;","29/Jul/10 17:29;drevell;Bisecting the SVN history shows that this worked in r966733 but became broken in r966742. Both of those revisions are dated July 22.;;;","05/Aug/10 20:50;jbellis;I believe this is fixed by the changes to StorageProxy made in CASSANDRA-1156.  Can you re-test?;;;","05/Aug/10 20:50;jbellis;I note that scan wasn't supposed to really work at all across multiple nodes, prior to 1156. :);;;","05/Aug/10 23:07;drevell;jbellis: I can't retest, scan() no longer exists (in cassandra.thrift).;;;","05/Aug/10 23:34;jbellis;get_range_slices is un-deprecated instead;;;","06/Aug/10 00:12;drevell;It seems fixed. After updating to r982821 and running the same test, it now passes (with scan switched to get_range_slices).;;;","06/Aug/10 00:50;jbellis;Great, thanks for the help!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AssertionError: discard at CommitLogContext(file=...) is not after last flush at  ...,CASSANDRA-1330,12470364,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,vilda,vilda,28/Jul/10 17:26,16/Apr/19 09:33,14/Jul/23 05:51,02/Oct/10 05:05,0.6.6,0.7 beta 3,,,0,,,,,,"Looks related to CASSANDRA-936?

ERROR [MEMTABLE-POST-FLUSHER:1] 2010-07-28 11:39:36,909 CassandraDaemon.java (line 83) Uncaught exception in thread Thread[MEMTABLE-POST-FLUSHER:1,5,main]
java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard at CommitLogContext(file='/srv/cassandra/commitlog/CommitLog-1280331567364.log', position=181) is not after last flush at 563
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)
        at java.util.concurrent.FutureTask.get(FutureTask.java:111)
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:86)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1118)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
Caused by: java.lang.RuntimeException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard at CommitLogContext(file='/srv/cassandra/commitlog/CommitLog-1280331567364.log', position=181) is not after last flush at 563
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
        at java.util.concurrent.FutureTask.run(FutureTask.java:166)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        ... 2 more
Caused by: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard at CommitLogContext(file='/srv/cassandra/commitlog/CommitLog-1280331567364.log', position=181) is not after last flush at 563
        at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegments(CommitLog.java:373)
        at org.apache.cassandra.db.ColumnFamilyStore$1.runMayThrow(ColumnFamilyStore.java:371)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 6 more
Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard at CommitLogContext(file='/srv/cassandra/commitlog/CommitLog-1280331567364.log', position=181) is not after last flush at 563
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)
        at java.util.concurrent.FutureTask.get(FutureTask.java:111)
        at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegments(CommitLog.java:365)
        ... 8 more
Caused by: java.lang.AssertionError: discard at CommitLogContext(file='/srv/cassandra/commitlog/CommitLog-1280331567364.log', position=181) is not after last flush at 563
        at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegmentsInternal(CommitLog.java:394)
        at org.apache.cassandra.db.commitlog.CommitLog.access$300(CommitLog.java:70)
        at org.apache.cassandra.db.commitlog.CommitLog$6.call(CommitLog.java:359)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
        at java.util.concurrent.FutureTask.run(FutureTask.java:166)
        at org.apache.cassandra.db.commitlog.PeriodicCommitLogExecutorService$1.runMayThrow(PeriodicCommitLogExecutorService.java:52)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 1 more
",Java 1.6 / Linux,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Oct/10 17:25;jbellis;1330.txt;https://issues.apache.org/jira/secure/attachment/12456141/1330.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20083,,,Sat Oct 02 05:05:47 UTC 2010,,,,,,,,,,"0|i0g4ef:",92143,,mdennis,,mdennis,Normal,,,,,,,,,,,,,,,,,"01/Oct/10 17:25;jbellis;This really is essentially the same scenario as CASSANDRA-936.  (See my 3rd-from-the-bottom comment for background and a diagram.)

The part my analysis in 936 is missing is that the CL holds mutations from many columnfamilies, so the position of the first turnOn in a given CF may be arbitrarily high depending on how many mutations happened to other CFs first.  (Similarly, the flush context may also be arbitrarily high, although it's more likely to be low because this scenario can't occur once each CF has been flushed once in the new segment.)

Given the turnOn-for-first-write-to-CF-in-new-segment behavior (which is what keeps us from having to replay the entirety of any not-completely-flushed segement), I don't think we can usefully assert anything about the flush context vs the dirty position.  This patch removes it -- and changes CLS.lastFlushedAt to CLS.cfDirtiedAt (which is what it has already been renamed to in 0.7) to make it more clear that flushing isn't the only thing that affects the header positions.;;;","02/Oct/10 02:55;mdennis;+1;;;","02/Oct/10 05:05;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
contrib/pig's cassandra.yaml is out of date,CASSANDRA-1326,12470290,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jeromatron,jeromatron,jeromatron,27/Jul/10 19:39,16/Apr/19 09:33,14/Jul/23 05:51,27/Jul/10 19:50,0.7 beta 1,,,,0,,,,,,It just needs updating.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/10 19:39;jeromatron;fix_pig.patch;https://issues.apache.org/jira/secure/attachment/12450620/fix_pig.patch",,,,,,,,,,,,,,1.0,jeromatron,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20081,,,Wed Jul 28 12:52:00 UTC 2010,,,,,,,,,,"0|i0g4dj:",92139,,,,,Normal,,,,,,,,,,,,,,,,,"27/Jul/10 19:50;brandon.williams;Committed.;;;","28/Jul/10 12:52;hudson;Integrated in Cassandra #502 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/502/])
    Update contrib/pig's cassandra.yaml for trunk.  Patch by Jeremy Hanna reviewed by brandonwilliams for CASSANDRA-1326
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
digest mismatches are processed serially,CASSANDRA-1323,12470224,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,27/Jul/10 02:32,16/Apr/19 09:33,14/Jul/23 05:51,27/Jul/10 03:45,0.6.4,,,,0,,,,,,for multiget situations this can dramatically increase latency.  need to parallelize these.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/10 02:33;jbellis;1323.txt;https://issues.apache.org/jira/secure/attachment/12450550/1323.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20080,,,Tue Jul 27 03:45:36 UTC 2010,,,,,,,,,,"0|i0g4cv:",92136,,,,,Low,,,,,,,,,,,,,,,,,"27/Jul/10 02:52;brandon.williams;+1;;;","27/Jul/10 03:45;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CommitLogTest and RecoveryManager2Test is failing in trunk,CASSANDRA-1318,12470134,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,mdennis,mdennis,mdennis,26/Jul/10 06:00,16/Apr/19 09:33,14/Jul/23 05:51,27/Jul/10 04:03,0.7 beta 1,,,,0,,,,,,"{code}
test:
     [echo] running unit tests
    [junit] WARNING: multiple versions of ant detected in path for junit 
    [junit]          jar:file:/usr/share/ant/lib/ant.jar!/org/apache/tools/ant/Project.class
    [junit]      and jar:file:/home/mdennis/mdev/trunkclean/build/lib/jars/ant-1.6.5.jar!/org/apache/tools/ant/Project.class
    [junit] Testsuite: org.apache.cassandra.db.CommitLogTest
    [junit] Tests run: 12, Failures: 1, Errors: 0, Time elapsed: 0.937 sec
    [junit] 
    [junit] Testcase: testCleanup(org.apache.cassandra.db.CommitLogTest):	FAILED
    [junit] null
    [junit] junit.framework.AssertionFailedError
    [junit] 	at org.apache.cassandra.db.CommitLogTest.testCleanup(CommitLogTest.java:66)
    [junit] 
    [junit] 
    [junit] Test org.apache.cassandra.db.CommitLogTest FAILED

BUILD FAILED
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/10 03:59;mdennis;1318-trunk.patch;https://issues.apache.org/jira/secure/attachment/12450556/1318-trunk.patch",,,,,,,,,,,,,,1.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20079,,,Tue Jul 27 13:41:07 UTC 2010,,,,,,,,,,"0|i0g4br:",92131,,,,,Low,,,,,,,,,,,,,,,,,"26/Jul/10 06:04;mdennis;It appears that when we started keeping persistent stats (CASSANDRA-1155) we ended up writing more than the half the segment size chosen by the test to the commit log causing it to fail.;;;","26/Jul/10 13:08;jbellis;wouldn't adding a flush to the system keyspace be a less fragile fix?;;;","26/Jul/10 13:47;jbellis;RecoveryManager2Test is also failing from the same 1155 commit, may be something similar;;;","26/Jul/10 17:42;mdennis;RecoveryManager2Test is nonde;;;","27/Jul/10 03:38;mdennis;Adding a flush to CommitLogTest doesn't help because forceBlockingFlush() eventually calls discardCompletedSegmentsInternal() which re-dirties the column family in case a write happens concurrently with the flush (e.g. CommitLog:411).;;;","27/Jul/10 04:03;jbellis;committed, minus the CLH commented-out code;;;","27/Jul/10 13:41;hudson;Integrated in Cassandra #501 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/501/])
    fix commitlog tests post-1135.  patch by mdennis; reviewed by jbellis for CASSANDRA-1318
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
StorageProxy ignores snitch when determining whether to do a local read,CASSANDRA-1317,12470122,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,25/Jul/10 22:38,16/Apr/19 09:33,14/Jul/23 05:51,26/Jul/10 21:23,0.6.4,,,,1,,,,,,this primarily affects CASSANDRA-1314 and to a lesser degree CASSANDRA-981,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jul/10 02:34;jbellis;1317.txt;https://issues.apache.org/jira/secure/attachment/12450438/1317.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20078,,,Thu Jul 29 13:15:18 UTC 2010,,,,,,,,,,"0|i0g4bj:",92130,,,,,Low,,,,,,,,,,,,,,,,,"26/Jul/10 19:53;tupshin;In combination with SimpleSnitch from https://issues.apache.org/jira/browse/CASSANDRA-1314 this patch allows for much better cache utilization resulting in a full order of magnitude decrease in disk reads across my entire cluster.;;;","26/Jul/10 21:23;jbellis;committed.

as a side benefit, it was simplest to refactor things so that local and remote reads in a multiget are done in parallel now (before, we would do all local reads, then all remote ones).;;;","29/Jul/10 13:15;hudson;Integrated in Cassandra #503 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/503/])
    update client_only example for CASSANDRA-1317 changes

Patch by eevans
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Read repair does not always work correctly,CASSANDRA-1316,12470095,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,brandon.williams,brandon.williams,24/Jul/10 23:50,16/Apr/19 09:33,14/Jul/23 05:51,27/Jul/10 16:47,0.6.4,,,,0,,,,,,"Read repair does not always work.  At the least, we allow violation of the CL.ALL contract.  To reproduce, create a three node cluster with RF=3, and json2sstable one of the attached json files on each node.  This creates a row whose key is 'test' with 9 columns, but only 3 columns are on each machine.  If you get_count this row in quick succession at CL.ALL, sometimes you will receive a count of 6, sometimes 9.  After the ReadRepairManager has sent the repairs, you will always get 9, which is the desired behavior.

I have another data set obtained in the wild which never fully repairs for some reason, but it's a bit large to attach (600ish columns per machine.)  I'm still trying to figure out why RR isn't working on this set, but I always get different results when reading at any CL including ALL, no matter how long I wait or how many reads I do.",,brandon.williams,johanoskarsson,sayap,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jul/10 15:24;brandon.williams;001_correct_responsecount_in_RRR.txt;https://issues.apache.org/jira/secure/attachment/12450474/001_correct_responsecount_in_RRR.txt","27/Jul/10 02:41;jbellis;1316-RRM.txt;https://issues.apache.org/jira/secure/attachment/12450552/1316-RRM.txt","26/Jul/10 16:08;jbellis;RRR-v2.txt;https://issues.apache.org/jira/secure/attachment/12450479/RRR-v2.txt","25/Jul/10 20:15;brandon.williams;cassandra-1.json;https://issues.apache.org/jira/secure/attachment/12450423/cassandra-1.json","25/Jul/10 20:15;brandon.williams;cassandra-2.json;https://issues.apache.org/jira/secure/attachment/12450424/cassandra-2.json","25/Jul/10 20:15;brandon.williams;cassandra-3.json;https://issues.apache.org/jira/secure/attachment/12450425/cassandra-3.json",,,,,,,,,6.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20077,,,Sat Dec 11 07:35:22 UTC 2010,,,,,,,,,,"0|i0g4bb:",92129,,,,,Normal,,,,,,,,,,,,,,,,,"24/Jul/10 23:53;brandon.williams;I tried to bisect this issue and went as far back as 0.4.2 without finding a successful version.  I will see if the data that never repairs can be scrubbed so I can attach it to this ticket for debugging.;;;","25/Jul/10 00:02;brandon.williams;It looks like the key difference between the real data and the toy data that is attached is that the real data has the key in multiple sstables.  If left this way, RR never fully works, but if I force a compaction then it succeeds.;;;","25/Jul/10 20:18;brandon.williams;Updated json files illustrate one possible scenario:  nodes 1 and 2 have a column, and node 3 has the column tombstoned with the same timestamp.  It looks like tombstones aren't taking precedence.;;;","26/Jul/10 15:24;brandon.williams;Patch to solve one problem: use derterminBlockFor to set the correct response count passed to RRR, so CL.ALL works.;;;","26/Jul/10 16:08;jbellis;v2 updates QRH arguments to use responseCount as well, even though it's ignored;;;","26/Jul/10 22:11;brandon.williams;Committed RRRv2.;;;","27/Jul/10 02:41;jbellis;patch that simplifies debugging by removing ReadRepairManager which is mostly 100-odd lines of obfuscation around MessagingService.sendOneWay.  (backport from CASSANDRA-1077 which was applied to trunk two months ago);;;","27/Jul/10 16:47;jbellis;Brandon's first patch fixing reads at CL.ALL turns out to be the only bug.  The rest is obscure-but-valid behavior when expired tombstones haven't been replicated across the cluster (i.e., the tombstones exist on some nodes, but not all).  Let me give an example:

say node A has columns x and y, where x is an expired tombstone with timestamp T1, and node B has live column x, at time T2 where T2 < T1.

if you read at ALL you will see x from B and y from A.  you will _not_ see x from A -- since it is expired, it is no longer relevant off-node.  thus, the ALL read will send a repair of column x to A, since it was ""missing.""

But next time you read from A the tombstone will supress the newly-written copy of x-from-B still, because its timestamp is higher.  So the replicas won't converge.

This is not a bug, because the design explicitly allows that behavior when tombstones expire before being propagated to all nodes; see http://wiki.apache.org/cassandra/DistributedDeletes.  The best way to avoid this of course is to run repair frequently enough to ensure that tombstones are propagated within GCGraceSeconds of being written.

But if you do find yourself in this situation, you have two options to get things to converge again:

1) the simplest option is to simply perform a major compaction on each node, which will eliminate all expired tombstones.

2) but if you want to propagate as many of the tombstones as possible first, increase your GCGraceSeconds setting everywhere (requires rolling restart), and perform a full repair as described in http://wiki.apache.org/cassandra/Operations.  After the repair is complete you can put GCGraceSeconds back to what it was.
;;;","11/Dec/10 07:35;hudson;Integrated in Cassandra-0.7 #70 (See [https://hudson.apache.org/hudson/job/Cassandra-0.7/70/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ColumnFamilyOutputFormat should use client API objects,CASSANDRA-1315,12470089,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,stuhood,stuhood,24/Jul/10 18:20,16/Apr/19 09:33,14/Jul/23 05:51,25/Aug/10 20:53,0.7 beta 2,,,,0,,,,,,"ColumnFamilyOutputFormat currently takes IColumns as its input, meaning that users need to understand Cassandra's internals reasonably well in order to use it, and need to hardcode things like the comparator type and clock type into their MapReduce jobs.

Instead, CFOutputFormat should take either Thrift or Avro objects, which are familiar interfaces for users.",,johanoskarsson,,,,,,,,,,,,,,,,,CASSANDRA-1322,CASSANDRA-1342,CASSANDRA-1368,,,,,,,,,"24/Aug/10 19:46;stuhood;0001-Use-Avro-objects-as-input-to-CFOutputFormat.patch;https://issues.apache.org/jira/secure/attachment/12452959/0001-Use-Avro-objects-as-input-to-CFOutputFormat.patch","24/Aug/10 19:46;stuhood;0002-Allow-multiple-mutations-per-key-to-arrive-during-in.patch;https://issues.apache.org/jira/secure/attachment/12452960/0002-Allow-multiple-mutations-per-key-to-arrive-during-in.patch",,,,,,,,,,,,,2.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20076,,,Wed Aug 25 20:53:11 UTC 2010,,,,,,,,,,"0|i0g4b3:",92128,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"26/Jul/10 19:49;stuhood;I've got a patch for this, but it needs more testing... should get it on here before midweek.;;;","05/Aug/10 23:16;stuhood;Adding 1322 as a dependency, since both change approximately the same code.;;;","05/Aug/10 23:17;stuhood;Ports the OutputFormat to Avro objects.;;;","08/Aug/10 07:07;stuhood;Add 0002 to allow mutations for keys to arrive during separate write calls, rather than clobbering existing keys.;;;","12/Aug/10 19:08;jbellis;committed 0001

looks like 0002 brace placement is wrong, seems that the mutationsByKey.put(key, cfMutation) should happen if cfMutation != null as well.  similarly for the step below that.;;;","12/Aug/10 19:24;jbellis;reverted commit of 0001 after looking at CASSANDRA-1368 more.

I'm less and less convinced that we're going to move go Avro as our ""main"" interface, and unless we are, we shouldn't be adding public dependencies on it.

I don't buy the argument that ""Hadoop people already know Avro"" because there's basically nothing here that's a standard Hadoop Avro class, and using a Thrift StreamingMutation class would be much the same as an Avro one.;;;","13/Aug/10 16:08;stuhood;> and using a Thrift StreamingMutation class would be much the same as an Avro one.
In order to use Thrift, you would need to generate code for your dynamic language, and then distribute it to all of the nodes in your Hadoop cluster: either as a library that you update for each Cassandra version, or as a JAR'd script dependency. Not the end of the world, I suppose, but more difficult then distributing only the protocol file.

Having worked with Avro on a few tickets now, I'm willing to get behind it 100% as a replacement for Thrift.;;;","13/Aug/10 22:14;jbellis;bq. In order to use Thrift, you would need to generate code for your dynamic language, and then distribute it to all of the nodes in your Hadoop cluster: either as a library that you update for each Cassandra version, or as a JAR'd script dependency. Not the end of the world, I suppose, but more difficult then distributing only the protocol file. 

How is that different from having to distribute the Avro library for whatever streaming processor language you are using, other than the codegen step?;;;","13/Aug/10 22:23;stuhood;> other than the codegen step?
Just the codegen step. If you don't have root access to your cluster for instance, you would need to JAR the Thrift generated code and then use a relative import to pull it in.

If the real question we're debating is whether we are still considering switching Cassandra 100% to Avro before 1.0, then we should probably discuss that elsewhere. When I began this ticket, I was under the impression that that was a sure thing.;;;","14/Aug/10 12:48;hudson;Integrated in Cassandra #514 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/514/])
    use Avro objects in ColumnFamilyOutputFormat.  patch by Stu Hood; reviewed by jbellis for CASSANDRA-1315
;;;","16/Aug/10 20:20;jbellis;bq. if the real question we're debating is whether we are still considering switching Cassandra 100% to Avro before 1.0, then we should probably discuss that elsewhere. When I began this ticket, I was under the impression that that was a sure thing.

This has never been a sure thing, and we're way behind schedule on what we had planned.

Offering both Thrift and Avro here would be fine, that's similar to what our migration path to Avro was planned to be like anyway.  But even if we were going to switch 100% to Avro we're several releases away from where that should be the only interface.;;;","23/Aug/10 15:43;stuhood;> Offering both Thrift and Avro here would be fine
Hm, I think I could get behind that... aside from proliferation concerns. We'd be signing up for a ThriftColumnFamilyOutputFormat and an AvroC..F..O..F.., one of which wrapped the other.;;;","24/Aug/10 19:46;stuhood;Rebase the existing patchset for trunk: I'll be tackling the Avro/Thrift duality sometime soon, but this isn't it.;;;","25/Aug/10 20:53;jbellis;Stu convinced me that due to the direction the Hadoop project is moving, demand for a Thrift api is likely to be low.  Committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
make cache sizes in CfDef Strings again so we can use %s of rows in the CF as in 0.6,CASSANDRA-1313,12470053,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jhermes,jbellis,jbellis,23/Jul/10 22:21,16/Apr/19 09:33,14/Jul/23 05:51,13/Aug/10 15:56,0.7 beta 2,,,,0,,,,,,"(note, this was reverted for 0.7 in CASSANDRA-1394)",,py4fun,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Aug/10 20:56;jhermes;1313-SY.txt;https://issues.apache.org/jira/secure/attachment/12451370/1313-SY.txt","05/Aug/10 20:58;jhermes;1313-YB.txt;https://issues.apache.org/jira/secure/attachment/12451373/1313-YB.txt","05/Aug/10 20:56;jhermes;snakeyaml-percentToFloat.txt;https://issues.apache.org/jira/secure/attachment/12451371/snakeyaml-percentToFloat.txt","05/Aug/10 20:56;jhermes;snakeyaml-r1131-dev.jar;https://issues.apache.org/jira/secure/attachment/12451372/snakeyaml-r1131-dev.jar","05/Aug/10 20:47;jhermes;yamlbeans-1.04.jar;https://issues.apache.org/jira/secure/attachment/12451368/yamlbeans-1.04.jar",,,,,,,,,,5.0,jhermes,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20075,,,Sat Aug 14 12:48:35 UTC 2010,,,,,,,,,,"0|i0g4an:",92126,,,,,Low,,,,,,,,,,,,,,,,,"28/Jul/10 21:44;jhermes;Simply making \{rows,keys\}_cached strings instead of doubles is problematic. The current code looks for 'double \{rows,keys\}_cached', and changing every lookup is a non-trivial chunk of code. The lookup would also take extra cycles (or just two extra cycles if the first lookups cache the String->Double operation).

Loading a String into a Double from the YAML using snakeyaml directly has proven difficult:
* Getters and setters on the Config/RawKS/RawCF beans are never called, so there is no immediate hook.
* Telling the constructor in DD that ""50%"" should be a double does not help the constructor parse the string into a double -- snakeyaml explodes.
* Pushing the values into a String on the bean, then populating the double from the string leaves extra variables around. Also, these extra variables have to be named something different than \{rows,keys\}_cached, which means extra work in our 0.6->0.7 Converter.
* Pushing the values into a String on a FooConfig, then generating Config from FooConfig works, but means two passes on the load and hard to maintain later. 
* *Finally,* change the snakeyaml code directly. Whenever it sees a number followed by a percent, it should correctly construct a FloatType (be it Float, Double, or BigDecimal according to destination).

I decided the best fix is to effect a change in snakeyaml as outlined above (and tracked at: http://code.google.com/p/snakeyaml/issues/detail?id=75 ).

Attached are 3 things:
- The patch to snakeyaml trunk, named snakeyaml-percentToFloat.txt,
- The lib built from trunk after patch applied, named snakeyaml-r1131-dev1.jar,
- and a patch for C trunk (changes conf/cassandra.yaml and test/conf/cassandra.yaml), named 1313.txt.

With this, the values legal for \{rows,keys\}_cached is a literal (1000, 0.5, 0) or a string (""1000"", ""50%"", ""0%""). As before, a value between [0,1] is a fraction of the total, and all larger values are absolute. Because this is a change to the parser, you can also give percents anywhere else a double is expected (read_repair_chance: '72.25%' if you want).

Should this change not be accepted, one of the above methods can be employed in our code, or I can override-in all the functionality of the patch (though the code will look like a trainwreck).;;;","28/Jul/10 21:46;jhermes;Attached debugging patch to print the values of \{rows,keys\}_cached to STDOUT when the config is first loaded.
Named snakeyaml-output.patch.;;;","28/Jul/10 23:18;mdennis;+1 on the approach.  I'd like to see snakeyaml adopt this patch.;;;","29/Jul/10 02:53;jbellis;I like this, too.  Nice work.;;;","30/Jul/10 15:14;py4fun;You do not need to patch SnakeYAML to achieve the goal. SnakeYAML has the following feature: any scalar which matches a given regular expression can be constructed with some custom code.
Examples can be found in the tests.

We shall think twice before we patch SnakeYAML. Appending '%' to a number is not a common pattern. It is not part of the YAML specification. Other users may be confused when they get Float when they expect String

-
Andrey 
;;;","05/Aug/10 20:47;jhermes;Replacing snakeyaml with yamlbeans.

Status:
M       conf/cassandra.yaml
D       src/java/org/apache/cassandra/utils/SkipNullRepresenter.java
M       src/java/org/apache/cassandra/tools/NodeProbe.java
M       src/java/org/apache/cassandra/tools/SchemaTool.java
M       src/java/org/apache/cassandra/service/StorageService.java
M       src/java/org/apache/cassandra/service/StorageServiceMBean.java
M       src/java/org/apache/cassandra/config/DatabaseDescriptor.java
M       src/java/org/apache/cassandra/config/Config.java
M       src/java/org/apache/cassandra/config/Converter.java
M       src/java/org/apache/cassandra/config/RawColumnFamily.java
M       NOTICE.txt
D       lib/snakeyaml-1.6.jar
A       lib/yamlbeans-1.04.jar

Reading the config and loading keyspaces works properly.
Exporting keyspaces (using schematool) works properly given a target output file.
Converting from 0.6 to 0.7 has no diff from using snakeyaml.;;;","05/Aug/10 20:56;jhermes;Re-attaching snakeyaml approach.;;;","05/Aug/10 20:58;jhermes;And lastly fixing 1313-YB.txt to remove debug statements.;;;","06/Aug/10 13:46;py4fun;Jon, may I kindly ask you to clarify your decision ?

1)  you requested to change SnakeYAML without clear message what other users (not only Cassandra) will gain from such a change
2) I have provided you with a solution (http://code.google.com/p/snakeyaml/source/browse/src/test/java/examples/CustomImplicitResolverTest.java) which you can copy-and-paste to your code with minimum effort. You did not give any feedback back to the SnakeYAML community (http://code.google.com/p/snakeyaml/issues/detail?id=75). Why the solution did not work ?
3) using YamlBeans does not actually solve your problem. As far as I can see you introduced ""These getters/setters allow us to read X% in as a double"". The same can be done with SnakeYAML
4) Be aware that SnakeYAML implements complete 1.1 YAML specification and it has many other unique features not available in YamlBeans.


I strongly believe that communication is the best way to quickly solve the issues. SnakeYAML is open for suggestions and we are glad to help others to use the library. But we also expect that the community explains the decision and help us to improve SnakeYAML where it needs to be improved.;;;","06/Aug/10 16:24;jhermes;1) I've made it painfully clear why I offered the patch to the community.
2) I have many good solutions now. This has been a solved problem for a while. There is a reason why snakeyaml-75 is marked as an Enhancement, not a Bug.
3,4) Switching to YamlBeans was not because I couldn't solve the problem without it, but because the code is much easier to read, smaller, and removed many lines of our code.

If you still desire clarification, feel free to e-mail me. Unless there are complications on this defect, I'm considering it finished and moving on to other things. As for snakeyaml-75, I'm leaving it open to be closed as Invalid at your discretion.;;;","13/Aug/10 15:56;jbellis;committed, w/ removal of commented-out snakeyaml code and printStackTrace calls;;;","14/Aug/10 12:48;hudson;Integrated in Cassandra #514 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/514/])
    add back percentage option for cache size configuration, and replace SnakeYAML with YamlBeans.  patch by Jon Hermes; reviewed by jbellis for CASSANDRA-1313
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Disallow KS definition with RF > # of nodes,CASSANDRA-1310,12469974,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,zznate,arya,arya,23/Jul/10 01:15,16/Apr/19 09:33,14/Jul/23 05:51,29/Jul/10 15:59,0.7 beta 1,,,,0,,,,,,"Cassandra 0.7 allows user to create Keyspaces with Replication Factor >  number of endpoints causing in java.lang.IllegalStateException: replication factor (2) exceeds number of endpoints (1) exception in nodetool and Internal Errors on Thrift making the node useless.

Steps to Reproduce:

From a clean setup of Cassandra:
1. Start a single node out of cluster of 3. This means my configuration has the other two nodes in the seeds list, but have not restarted them yet;
2. Use Thrift API (I am using PHP) and create a Keyspace with replication factor 2;
3. The command executes with no exception or error;
4. Now try writing to it, you will get TException with Internal Error message;
5. Try nodetool ring and you will get Exception:

Exception in thread ""main"" java.lang.IllegalStateException: replication factor (2) exceeds number of endpoints (1)
	at org.apache.cassandra.locator.RackUnawareStrategy.calculateNaturalEndpoints(RackUnawareStrategy.java:61)
	at org.apache.cassandra.locator.AbstractReplicationStrategy.getNaturalEndpoints(AbstractReplicationStrategy.java:87)
	at org.apache.cassandra.service.StorageService.constructRangeToEndpointMap(StorageService.java:536)
	at org.apache.cassandra.service.StorageService.getRangeToAddressMap(StorageService.java:522)
	at org.apache.cassandra.service.StorageService.getRangeToEndpointMap(StorageService.java:496)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:111)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:45)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:226)
	at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)
	at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:251)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:857)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:795)
	at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1449)
	at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:90)
	at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1284)
	at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1382)
	at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:807)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:322)
	at sun.rmi.transport.Transport$1.run(Transport.java:177)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.Transport.serviceCall(Transport.java:173)
	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:553)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:808)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:667)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)

Expected:

1. Either step 3 should not let you create the KS with RF 2 and 1 node in ring, or there should be a peaceful way for Cassandra to recover from IllegalStateException and replicate once other nodes become available.","CentOS 5.1
Trunc July 22nd",zznate,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jul/10 22:49;zznate;1310-v2.txt;https://issues.apache.org/jira/secure/attachment/12450765/1310-v2.txt","26/Jul/10 18:02;zznate;trunk-1310.txt;https://issues.apache.org/jira/secure/attachment/12450497/trunk-1310.txt",,,,,,,,,,,,,2.0,zznate,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20074,,,Fri Jul 30 13:37:48 UTC 2010,,,,,,,,,,"0|i0g4a7:",92124,,,,,Normal,,,,,,,,,,,,,,,,,"26/Jul/10 08:34;zznate;Patch validates on RF being less than the number of nodes and that the KsDef.name and CsDef.keyspace match when providing a KsDef to system_add_keyspace on CassandraServer;;;","26/Jul/10 18:02;zznate;Removed thrift validation method as nothing else really needs to validate on KsDef ;;;","27/Jul/10 14:48;gdusbabek;I think we should allow the creation of keyspaces even when there aren't enough nodes to support the specified replication factor.  For example, it should be allowable for an operator to bring up a single node in a new cluster, define all the keyspaces and then start bringing up new nodes to populate the cluster.

Throwing IllegalStateException is a special case that should probably be handled in NodeTool (gently output the error string and die).;;;","27/Jul/10 16:32;zznate;That makes sense to me. I would like to have a check on CsDef.keyspace = KsDef.name though. I hit that in a test case and it cause a really obtuse NPE. ;;;","28/Jul/10 21:14;gdusbabek;Nate: feel free to resubmit the patch for keyspace checks.  Also, having nodetool print just the error (not the whole stack trace) might be more user-friendly.;;;","28/Jul/10 22:49;zznate;Just validates CsDef vs. KsDef have the same keyspace. Includes NodeCmd patch that prints an error msg instead of the stack trace.;;;","29/Jul/10 15:59;gdusbabek;committed.;;;","30/Jul/10 13:37;hudson;Integrated in Cassandra #504 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/504/])
    print a more friendly error when printRing gets IllegalState. Patch by Nate McCall, reviewed by Gary Dusbabek. CASSANDRA-1310
check for ks/cf keyspace name agreement. Patch by Nate McCall, reviewed by Gary Dusbabek. CASSANDRA-1310
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LegacySSTableTest breaks when run from a svn checkout,CASSANDRA-1309,12469940,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,stuhood,jbellis,jbellis,22/Jul/10 18:47,16/Apr/19 09:33,14/Jul/23 05:51,27/Jul/10 13:25,0.7 beta 1,,,,0,,,,,,"Works fine under git where there is no .svn turd.

    [junit] ------------- Standard Error -----------------
    [junit] Failed to read .svn
    [junit] java.io.FileNotFoundException: /Users/jonathan/projects/cassandra/svn-trunk/test/data/legacy-sstables/.svn/Keyspace1/Standard1-.svn-0-Index.db (No such file or directory)
    [junit] 	at java.io.RandomAccessFile.open(Native Method)
    [junit] 	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:212)
    [junit] 	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:98)
    [junit] 	at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:142)
    [junit] 	at org.apache.cassandra.io.util.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:137)
    [junit] 	at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:256)
    [junit] 	at org.apache.cassandra.io.sstable.SSTableReader.internalOpen(SSTableReader.java:187)
    [junit] 	at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:170)
    [junit] 	at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:150)
    [junit] 	at org.apache.cassandra.io.sstable.LegacySSTableTest.testVersion(LegacySSTableTest.java:102)
    [junit] 	at org.apache.cassandra.io.sstable.LegacySSTableTest.testVersions(LegacySSTableTest.java:95)
    [junit] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    [junit] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    [junit] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    [junit] 	at java.lang.reflect.Method.invoke(Method.java:597)
    [junit] 	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
    [junit] 	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
    [junit] 	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
    [junit] 	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
    [junit] 	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
    [junit] 	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
    [junit] 	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
    [junit] 	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:44)
    [junit] 	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:180)
    [junit] 	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:41)
    [junit] 	at org.junit.runners.ParentRunner$1.evaluate(ParentRunner.java:173)
    [junit] 	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
    [junit] 	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
    [junit] 	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
    [junit] 	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
    [junit] 	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
    [junit] 	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
    [junit] 	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1249,,"22/Jul/10 21:26;stuhood;0001-Only-test-valid-version-strings.patch;https://issues.apache.org/jira/secure/attachment/12450221/0001-Only-test-valid-version-strings.patch",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20073,,,Tue Jul 27 13:25:08 UTC 2010,,,,,,,,,,"0|i0g49z:",92123,,,,,Low,,,,,,,,,,,,,,,,,"22/Jul/10 21:26;stuhood;Skips invalid version subdirectories.

Also, it looks like we're missing a few versions in test/data/legacy-sstables: would a committer mind following the instructions in LegacySSTableTest to generate sstables for versions 'c' and 'd'? In the past, I've posted them as git 'data diffs', but I think patch might have dropped them silently.;;;","27/Jul/10 13:25;gdusbabek;+1 committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
EOFException in LazilyCompactedRow,CASSANDRA-1299,12469630,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,jbellis,stuhood,stuhood,19/Jul/10 16:18,16/Apr/19 09:33,14/Jul/23 05:51,19/Jul/10 17:34,0.7 beta 1,,,,0,,,,,,"Post CASSANDRA-270, 'ant clean long-test' fails with an EOFException in LazilyCompactedRow.

{code}java.io.IOError: java.io.EOFException
	at org.apache.cassandra.io.sstable.SSTableIdentityIterator.next(SSTableIdentityIterator.java:103)
	at org.apache.cassandra.io.sstable.SSTableIdentityIterator.next(SSTableIdentityIterator.java:32)
	at org.apache.commons.collections.iterators.CollatingIterator.set(CollatingIterator.java:284)
	at org.apache.commons.collections.iterators.CollatingIterator.least(CollatingIterator.java:326)
	at org.apache.commons.collections.iterators.CollatingIterator.next(CollatingIterator.java:230)
	at org.apache.cassandra.utils.ReducingIterator.computeNext(ReducingIterator.java:68)
	at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:136)
	at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:131)
	at com.google.common.collect.Iterators$7.computeNext(Iterators.java:604)
	at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:136)
	at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:131)
	at org.apache.cassandra.db.ColumnIndexer.serializeInternal(ColumnIndexer.java:76)
	at org.apache.cassandra.db.ColumnIndexer.serialize(ColumnIndexer.java:50)
	at org.apache.cassandra.io.LazilyCompactedRow.<init>(LazilyCompactedRow.java:62)
	at org.apache.cassandra.io.CompactionIterator.getCompactedRow(CompactionIterator.java:135)
	at org.apache.cassandra.io.CompactionIterator.getReduced(CompactionIterator.java:107)
	at org.apache.cassandra.io.CompactionIterator.getReduced(CompactionIterator.java:46)
	at org.apache.cassandra.utils.ReducingIterator.computeNext(ReducingIterator.java:73)
	at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:136)
	at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:131)
	at org.apache.commons.collections.iterators.FilterIterator.setNextObject(FilterIterator.java:183)
	at org.apache.commons.collections.iterators.FilterIterator.hasNext(FilterIterator.java:94)
	at org.apache.cassandra.db.CompactionManager.doCompaction(CompactionManager.java:334)
	at org.apache.cassandra.db.LongCompactionSpeedTest.testCompaction(LongCompactionSpeedTest.java:101)
	at org.apache.cassandra.db.LongCompactionSpeedTest.testCompactionWide(LongCompactionSpeedTest.java:49)
Caused by: java.io.EOFException
	at java.io.RandomAccessFile.readInt(RandomAccessFile.java:725)
	at java.io.RandomAccessFile.readLong(RandomAccessFile.java:758)
	at org.apache.cassandra.db.TimestampClockSerializer.deserialize(TimestampClock.java:128)
	at org.apache.cassandra.db.TimestampClockSerializer.deserialize(TimestampClock.java:119)
	at org.apache.cassandra.db.ColumnSerializer.deserialize(ColumnSerializer.java:90)
	at org.apache.cassandra.db.ColumnSerializer.deserialize(ColumnSerializer.java:31)
	at org.apache.cassandra.io.sstable.SSTableIdentityIterator.next(SSTableIdentityIterator.java:99)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jul/10 17:25;jbellis;1299.txt;https://issues.apache.org/jira/secure/attachment/12449859/1299.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20068,,,Wed Jul 21 12:50:26 UTC 2010,,,,,,,,,,"0|i0g47r:",92113,,,,,Critical,,,,,,,,,,,,,,,,,"19/Jul/10 17:25;jbellis;CASSANDRA-270 exposed a long-standing bug in SSTableUtils where it was writing garbage data while bypassing memtable to assemble its own SSTables by hand.  It needs to limit the data passed to SSTableWriter to the actual valid data in the DataOutputBuffer.  Attached is a patch that takes the simplest approach to this by copying out only the valid data into a separate byte[].  Ideally I'd prefer to remove the append(key, byte[]) method entirely but that will have to wait until we have a BMT replacement.;;;","19/Jul/10 17:28;stuhood;Ha, yea... that would do it. Thanks!

+1;;;","19/Jul/10 17:34;jbellis;committed;;;","21/Jul/10 12:50;hudson;Integrated in Cassandra #496 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/496/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
avoid replaying fully-flushed commitlog segments,CASSANDRA-1298,12469599,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,19/Jul/10 12:45,16/Apr/19 09:33,14/Jul/23 05:51,20/Jul/10 16:28,0.7 beta 1,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jul/10 12:48;jbellis;1298.txt;https://issues.apache.org/jira/secure/attachment/12449836/1298.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20067,,,Wed Jul 21 12:50:28 UTC 2010,,,,,,,,,,"0|i0g47j:",92112,,,,,Low,,,,,,,,,,,,,,,,,"20/Jul/10 02:58;mdennis;+1;;;","20/Jul/10 16:28;jbellis;committed;;;","21/Jul/10 12:50;hudson;Integrated in Cassandra #496 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/496/])
    avoid replaying fully-flushed commitlog segments.  patch by jbellis; reviewed by mdennis for CASSANDRA-1298
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
commitlog recover bug,CASSANDRA-1297,12469585,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,jftan,jftan,jftan,19/Jul/10 09:02,16/Apr/19 09:33,14/Jul/23 05:51,19/Jul/10 12:42,0.6.4,,,,0,,,,,,"class CommitLog.java
when recover log files;
 if one log  file have no dirty , process is break;
{quote}
199  int lowPos = CommitLogHeader.getLowestPosition(clHeader);
 200 if (lowPos == 0)
 201    break;
{quote}

why not continue and read next log file
{quote}
199  int lowPos = CommitLogHeader.getLowestPosition(clHeader);
200 if (lowPos == 0)\{
201   reader.close();
202   continue;
203  \}
{quote}

i am not very sure about that. how can answer?


",,,,,,,,,,,259200,259200,,0%,259200,259200,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jftan,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20066,,,Mon Jul 19 12:42:13 UTC 2010,,,,,,,,,,"0|i0g47b:",92111,,,,,Critical,,,,,,,,,,,,,,,,,"19/Jul/10 12:42;jbellis;you're right, it should continue to the next segment.  fixed in r965457.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MIsc license inclusion booboos with recent index commits,CASSANDRA-1294,12469517,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,zznate,zznate,zznate,17/Jul/10 04:50,16/Apr/19 09:33,14/Jul/23 05:51,17/Jul/10 12:47,0.7 beta 1,,,,0,,,,,,"Noticed some missing license headers, a duped header in one case when going over changes in CASSANDRA-1154",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jul/10 04:52;zznate;trunk-1249-license-headers.txt;https://issues.apache.org/jira/secure/attachment/12449748/trunk-1249-license-headers.txt",,,,,,,,,,,,,,1.0,zznate,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20065,,,Mon Jul 19 14:45:02 UTC 2010,,,,,,,,,,"0|i0g46n:",92108,,,,,Low,,,,,,,,,,,,,,,,,"17/Jul/10 04:52;zznate;the radio button for attachment license is strangely ironic here.;;;","17/Jul/10 12:47;jbellis;committed;;;","17/Jul/10 13:54;messi;Don't add license headers as Javadoc comments.;;;","17/Jul/10 14:40;zznate;Agree with Folke on this in principal, however javadoc seemed to be the most prevalent style in the codebase. Another patch for someone more OCD than myself perhaps. ;;;","17/Jul/10 15:35;jbellis;we do have a mix -- probably an older version of RAT used the javadoc style? new RAT generates non-javadoc'd license headers.  It would be nice to standardize on the latter, but in the meantime, either is fine.;;;","19/Jul/10 14:45;hudson;Integrated in Cassandra #494 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/494/])
    clean up license headers.  patch by Nate McCall for CASSANDRA-1294
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add locking around row cache accesses,CASSANDRA-1293,12469514,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,17/Jul/10 02:16,16/Apr/19 09:33,14/Jul/23 05:51,01/Oct/10 21:22,0.7 beta 3,,,,0,,,,,,"CASSANDRA-1267 means we need to lock around removeDeleted on the row cache entry and the write path where we merge in new columns (otherwise there can be a race where we incorrectly continue to remove a column, that has been updated by the writer thread to be newly relevant)",,jghoman,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Oct/10 20:44;jbellis;1293.txt;https://issues.apache.org/jira/secure/attachment/12456158/1293.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20064,,,Sat Oct 02 12:56:27 UTC 2010,,,,,,,,,,"0|i0g46f:",92107,,brandon.williams,,brandon.williams,Low,,,,,,,,,,,,,,,,,"30/Aug/10 22:16;stuhood;How much of a benefit do we get from the row cache being write-through? It would be really nice not having to lock it... or maybe making the locking and write-throughness an option, via CASSANDRA-1158. It would also be easier to manage cache sizes in terms of bytes if we didn't need to deal with mutations to the row cache.;;;","01/Oct/10 20:44;jbellis;We expect to save [cache hit rate] of a read per write with write-through, since the alternative is to invalidate the cached row at write time and reload it when it's requested again.

Attached patch moves the cache udpate into CFS.apply.;;;","01/Oct/10 21:02;brandon.williams;+1;;;","01/Oct/10 21:17;brandon.williams;No quantifiable difference in write speed with or without this patch.;;;","01/Oct/10 21:22;jbellis;committed;;;","02/Oct/10 12:56;hudson;Integrated in Cassandra #553 (See [https://hudson.apache.org/hudson/job/Cassandra/553/])
    lock row cache updates to prevent race condition
patch by jbellis; reviewed by brandonwilliams for CASSANDRA-1293
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multiple migrations might run at once,CASSANDRA-1292,12469498,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,gdusbabek,stuhood,stuhood,16/Jul/10 21:58,16/Apr/19 09:33,14/Jul/23 05:51,28/Jul/10 18:02,0.7 beta 1,,,,0,,,,,,"The service.MigrationManager class manages a MIGRATION_STAGE where nodes should execute db.migration.Migration instances.

The problem is that the node that a client connects to via Thrift or Avro initiates the migration in their client thread (calls migration.apply). Instead, the Thrift and Avro clients should ensure that the migration occurs in MIGRATION_STAGE, and should block until the migration is applied by the stage.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jul/10 16:12;gdusbabek;0001-run-thrift-and-jmx-migrations-on-to-migration-stage.patch;https://issues.apache.org/jira/secure/attachment/12450713/0001-run-thrift-and-jmx-migrations-on-to-migration-stage.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20063,,,Thu Jul 29 13:14:13 UTC 2010,,,,,,,,,,"0|i0g467:",92106,,,,,Critical,,,,,,,,,,,,,,,,,"27/Jul/10 20:56;gdusbabek;same thing goes for loadSchemaFromYaml();;;","28/Jul/10 17:23;stuhood;+1;;;","29/Jul/10 13:14;hudson;Integrated in Cassandra #503 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/503/])
    run thrift and jmx migrations on migration stage. patch by gdusbabek, reviewed by stuhood. CASSANDRA-1292
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cassandra-cli doesn't use framed transport by default,CASSANDRA-1290,12469491,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jhermes,jhermes,jhermes,16/Jul/10 20:54,16/Apr/19 09:33,14/Jul/23 05:51,16/Jul/10 21:56,0.7 beta 1,,,,0,,,,,,"Spawned by CASSANDRA-475 .
The cli uses non-framed transport, which causes errors on connection that look like:

cli:{noformat}$ bin/cassandra-cli 
Welcome to cassandra CLI.

Type 'help' or '?' for help. Type 'quit' or 'exit' to quit.
[default@unknown] connect 127.0.0.1/9160
Exception retrieving information about the cassandra node, check you have connected to the thrift port.{noformat}

cass:{noformat}ERROR 15:48:12,523 Thrift error occurred during processing of message.
org.apache.thrift.TException: Message length exceeded: 1684370275
	at org.apache.thrift.protocol.TBinaryProtocol.checkReadLength(TBinaryProtocol.java:384)
	at org.apache.thrift.protocol.TBinaryProtocol.readStringBody(TBinaryProtocol.java:350)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:213)
	at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:2519)
	at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:167)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619){noformat}

Changing it to use framed transport fixes this, and it should be using framed transport by default regardless.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jul/10 21:42;jhermes;TRUNK-1290.txt;https://issues.apache.org/jira/secure/attachment/12449708/TRUNK-1290.txt",,,,,,,,,,,,,,1.0,jhermes,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20061,,,Mon Jul 19 14:45:04 UTC 2010,,,,,,,,,,"0|i0g45r:",92104,,,,,Low,,,,,,,,,,,,,,,,,"16/Jul/10 20:57;jbellis;there is a --framed option

should be switched to --unframed;;;","16/Jul/10 20:58;jhermes;This is a one-line (line 32 to be exact) patch with some minor spatial formatting.;;;","16/Jul/10 21:42;jhermes;Yeah, good idea.
Changed the arg to unframed.;;;","16/Jul/10 21:56;jbellis;committed;;;","19/Jul/10 14:45;hudson;Integrated in Cassandra #494 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/494/])
    make cli framed by default.  patch by Jon Hermes; reviewed by jbellis for CASSANDRA-1290
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GossipTimerTask stops running if an Exception occurs,CASSANDRA-1289,12469488,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,wadey,wadey,16/Jul/10 20:29,16/Apr/19 09:33,14/Jul/23 05:51,18/Jul/10 02:10,0.6.4,,,,0,,,,,,"The GossipTimerTask run() method has a try/catch around its body, but it re-throws all Exceptions as RuntimeExceptions. This causes the GossipTimerTask to no longer run (due to the way the underlying Java Timer implementation works), stopping the periodic gossip status checks.

Combine this problem with a bug like CASSANDRA-757 (not yet fixed in 0.6.x) and you get into a state where the server keeps running, but gossip is no longer occurring, preventing node addition / removal from happening.

I see two potential choices:
1) Log the error but don't re-throw it so that the GossipTimerTask will continue to run on its next interval.
2) Shutdown the server, since continuing to run without gossip subtly breaks other functionality / knowledge of other nodes.",,brandon.williams,mojodna,wadey,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jul/10 22:02;brandon.williams;1289.txt;https://issues.apache.org/jira/secure/attachment/12449769/1289.txt",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20060,,,Sun Jul 18 02:09:51 UTC 2010,,,,,,,,,,"0|i0g45j:",92103,,,,,Normal,,,,,,,,,,,,,,,,,"17/Jul/10 21:34;brandon.williams;Patch to catch the exception and log it, as suggested in CASSANDRA-757;;;","18/Jul/10 02:09;jbellis;committed w/ changes since it was simple:

uses .error instead of .warn

uses .error(message, exception) so the entire stack trace will be logged;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rename 'table' -> 'keyspace' in public APIs,CASSANDRA-1287,12469480,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,stuhood,stuhood,16/Jul/10 19:11,16/Apr/19 09:33,14/Jul/23 05:51,23/Jul/10 18:34,0.7 beta 1,,,,0,,,,,,"thrift.CfDef uses the name 'table' rather than 'keyspace'. We need to make sure that all of our public APIs use consistent naming, despite the fact that our private APIs won't change until 0.7 is branched.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jul/10 22:27;stuhood;0001-Rename-CfDef.-table-keyspace.patch;https://issues.apache.org/jira/secure/attachment/12450228/0001-Rename-CfDef.-table-keyspace.patch","22/Jul/10 23:48;jhermes;TRUNK-1287.txt;https://issues.apache.org/jira/secure/attachment/12450239/TRUNK-1287.txt",,,,,,,,,,,,,2.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20059,,,Tue Jul 27 13:41:08 UTC 2010,,,,,,,,,,"0|i0g453:",92101,,,,,Normal,,,,,,,,,,,,,,,,,"21/Jul/10 19:42;jbellis;all this needs is s/table/keyspace/ in interface/cassandra.thrift;;;","22/Jul/10 22:27;stuhood;Renames CfDef.{table => keyspace};;;","22/Jul/10 23:48;jhermes;renamed table to keyspace in interface/cassandra.thrift.
renamed table to keyspace in thrift/CassandraServer.java.
committing updated thrift/gen-java.
updated Thrift API version to ""8.5.0"". (CASSANDRA-1276 has ""8.4.0"");;;","23/Jul/10 18:34;jbellis;committed;;;","27/Jul/10 13:41;hudson;Integrated in Cassandra #501 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/501/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Nodetool ring crashes when no schema is loaded,CASSANDRA-1286,12469470,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,slebresne,slebresne,16/Jul/10 17:04,16/Apr/19 09:33,14/Jul/23 05:51,02/Aug/10 20:22,0.7 beta 1,,Tool/nodetool,,1,,,,,,"Nodetool ring uses SP.getRangeToEndpointMap(null) that tries to retrieve the first non system keyspace.
Hences it crashes (with a IndexOutOfBoundsException) if no schema is loaded.

Should we return a nice little error message or make it work even no schema is loaded ?",,arya,brandon.williams,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/10 15:07;slebresne;1286-Don-t-use-ranges-to-print-the-ring-with-nodetool.patch;https://issues.apache.org/jira/secure/attachment/12451044/1286-Don-t-use-ranges-to-print-the-ring-with-nodetool.patch",,,,,,,,,,,,,,1.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20058,,,Wed Aug 04 13:25:35 UTC 2010,,,,,,,,,,"0|i0g44v:",92100,,,,,Low,,,,,,,,,,,,,,,,,"31/Jul/10 20:18;brandon.williams;FYI: CASSANDRA-1291 is also suffering from a problem with SP.getRangeToEndpointMap(null) when the RF is greater than 1.;;;","01/Aug/10 02:12;dopsun;This becomes a real problem for Cassandra 0.7, because by default, Cassandra 0.7 does not load any key space, and means that cannot use the nodetool to check the newly setup cluster.;;;","02/Aug/10 12:25;gdusbabek;We should be able to get ring data by directly consulting TokenMetadata (no need to collect range information which is what the keyspace argument gives us).;;;","02/Aug/10 15:07;slebresne;Attaching a patch that follows Gary suggestion. It simply exposes the
map of tokens -> endpoint (including the boostrapping ones).

This fixes the ring when no schema is loaded at least.;;;","02/Aug/10 19:30;gdusbabek;Should we deprecate StorageServiceMBean.getPendingRangeToEndpointMap()?;;;","02/Aug/10 19:47;jbellis;No, that's there because people want to use it to connect their clients to the ""right"" machines directly.;;;","02/Aug/10 20:21;gdusbabek;+1 committed.;;;","04/Aug/10 13:25;hudson;Integrated in Cassandra #509 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/509/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
heisenbug in RoundRobinSchedulerTest,CASSANDRA-1279,12469264,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,rnirmal,jbellis,jbellis,14/Jul/10 15:58,16/Apr/19 09:33,14/Jul/23 05:51,03/Aug/10 17:27,0.7 beta 1,,,,0,,,,,,"Occasionally I see this error in the test suite:

    [junit] Testcase: testScheduling(org.apache.cassandra.scheduler.RoundRobinSchedulerTest):	FAILED
    [junit] 
    [junit] junit.framework.AssertionFailedError: 
    [junit] 	at org.apache.cassandra.scheduler.RoundRobinSchedulerTest.testScheduling(RoundRobinSchedulerTest.java:90)
    [junit] 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/10 17:08;rnirmal;1279-v3.patch;https://issues.apache.org/jira/secure/attachment/12451135/1279-v3.patch","20/Jul/10 21:51;rnirmal;Cassandra-1279-v2.patch;https://issues.apache.org/jira/secure/attachment/12449982/Cassandra-1279-v2.patch","20/Jul/10 17:02;rnirmal;Cassandra-1279.patch;https://issues.apache.org/jira/secure/attachment/12449945/Cassandra-1279.patch",,,,,,,,,,,,3.0,rnirmal,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20056,,,Wed Aug 04 13:25:29 UTC 2010,,,,,,,,,,"0|i0g43b:",92093,,,,,Normal,,,,,,,,,,,,,,,,,"20/Jul/10 17:02;rnirmal;Fixed the problem, it's due to the unpredictable thread scheduling. The fixe loads the requests and then lets the scheduler proceed, that way the tests could be somewhat predictable and realize the expected behavior.;;;","20/Jul/10 20:36;jbellis;can you add a comment as to what is going on?

also, adding a package-private method for the test to use would be cleaner than poking through reflection;;;","20/Jul/10 21:51;rnirmal;The test is done with 15 simulated connections, 10 for K1(keyspace), 2 for K2 and 3 for k3. Requests came in the order of K1(1 thru 10), K2(11 thru 12), K3(13 thru15) and the test checked if K2 and K3 requests ran earlier then their request order. With the scheduler starting simultaneously, the requests were pretty much routed in order +/- the jvm thread scheduling order, hence the cause for the bug. 

Now the scheduler is paused still all the requests arrive and placed in their respective queues. When the scheduler is resumed, each pass retrieves one request from each keyspace queue, hence since K2 & K3 have only 2 and 3 requests, they get serviced faster than the order in which they arrived. This test just validates that the requests are RoundRobin and that's what we want to unit test.;;;","20/Jul/10 22:03;jbellis;committed;;;","21/Jul/10 12:50;hudson;Integrated in Cassandra #496 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/496/])
    fix RoundRobinSchedulerTest heisenbug.  patch by Nirmal Ranganathan; reviewed by jbellis for CASSANDRA-1279
;;;","03/Aug/10 15:14;jbellis;looks like this is only mostly fixed.  still getting

    [junit] junit.framework.AssertionFailedError: 
    [junit] 	at org.apache.cassandra.scheduler.RoundRobinSchedulerTest.testScheduling(RoundRobinSchedulerTest.java:93)
    ;;;","03/Aug/10 15:24;rnirmal;Hmm.... looks like I'll have to change the way we test it. ;;;","03/Aug/10 17:08;rnirmal;The scheduler will only have 1 token at anytime and the run/release of each thread is synchronized, effectively running only one thread at a time. So hopefully no threading inconsistencies occur.;;;","03/Aug/10 17:10;jbellis;Is this the point at which we say that ""this is different enough from 'live' code that it's not really a useful test anymore?""  Because I'm okay with that.;;;","03/Aug/10 17:23;rnirmal;Yes I'd say that, because it doesn't reflect the actual concurrency that will take place. So if it's ok we could remove it.;;;","03/Aug/10 17:27;jbellis;removed;;;","04/Aug/10 13:25;hudson;Integrated in Cassandra #509 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/509/])
    r/m RoundRobinSchedulerTest for CASSANDRA-1279; it doesn't appear possible to test concurrency usefully
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Exception while recovering commitlog when debug logging enabled,CASSANDRA-1274,12469178,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,mdennis,johanoskarsson,johanoskarsson,13/Jul/10 17:10,16/Apr/19 09:33,14/Jul/23 05:51,27/Jul/10 12:46,0.6.4,,,,0,,,,,,"On a cluster with debug logging enabled the commit log fails to recover on start. An UTF8 exception is thrown when trying to toString a column from the system column family LocationInfo. That CF is using UTF8Type but I suspect the column name in this specific case is a byte representation of an ip address, and as such not a valid UTF8 string. That column is most perhaps created in SystemTable line 74.

Full exception stack trace:
ERROR [main] 2010-07-13 11:03:17,050 AbstractCassandraDaemon.java (line 107) Exception encountered during startup.
org.apache.cassandra.db.marshal.MarshalException: invalid UTF8 bytes [10, -48, 40, -124]
        at org.apache.cassandra.db.marshal.UTF8Type.getString(UTF8Type.java:43)
        at org.apache.cassandra.db.Column.getString(Column.java:200)
        at org.apache.cassandra.db.marshal.AbstractType.getColumnsString(AbstractType.java:85)
        at org.apache.cassandra.db.ColumnFamily.toString(ColumnFamily.java:393)
        at org.apache.commons.lang.ObjectUtils.toString(ObjectUtils.java:241)
        at org.apache.commons.lang.StringUtils.join(StringUtils.java:3073)
        at org.apache.commons.lang.StringUtils.join(StringUtils.java:3133)
        at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:250)
        at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:171)
        at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:120)
        at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:90)
        at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:221)
",,mojodna,rschildmeijer,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/10 05:38;mdennis;1274-0.6.patch;https://issues.apache.org/jira/secure/attachment/12450563/1274-0.6.patch","27/Jul/10 05:38;mdennis;1274-trunk.patch;https://issues.apache.org/jira/secure/attachment/12450564/1274-trunk.patch",,,,,,,,,,,,,2.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20055,,,Tue Aug 03 20:46:20 UTC 2010,,,,,,,,,,"0|i0g427:",92088,,,,,Low,,,,,,,,,,,,,,,,,"13/Jul/10 17:24;jbellis;in 0.6?;;;","13/Jul/10 17:41;johanoskarsson;This was in trunk from yesterday. It's a modified version, but none of that code should have been touched.;;;","24/Jul/10 01:38;brandon.williams;Jon Hermes presented a theory that you have to be using an IP that has at least one quad over 128, which won't be met by a localhost cluster.  I can reliably reproduce on a real cluster, even in 0.6.;;;","27/Jul/10 05:35;mdennis;Jon Hermes is correct, it has to be invalid UTF8 bytes to trigger this;;;","27/Jul/10 05:38;mdennis;one line patches to change it to BytesType

Once the value is in the log in .6 the node will need to be started witout DEBUG logging to clear out the hints after which the log level can be turned back to DEBUG.

;;;","27/Jul/10 12:46;jbellis;committed;;;","03/Aug/10 16:21;brandon.williams;Just clearing the CL won't help, because the HH cf already exists, so it's not recreated.  Then the problem continues to occur.;;;","03/Aug/10 16:38;jbellis;Isn't the HH CF ""created"" on server startup in DD?  Or did that change in 0.7 too?;;;","03/Aug/10 20:46;mdennis;The meta data is created statically in CfMetaData;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
describe_keyspace not returning reconciler info,CASSANDRA-1273,12469177,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jeromatron,jeromatron,jeromatron,13/Jul/10 17:08,16/Apr/19 09:33,14/Jul/23 05:51,13/Jul/10 17:40,0.7 beta 1,,,,0,,,,,,describe_keyspace should return info on its reconciler.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1047,"13/Jul/10 17:09;jeromatron;add-reconciler-data-patch.txt;https://issues.apache.org/jira/secure/attachment/12449368/add-reconciler-data-patch.txt",,,,,,,,,,,,,,1.0,jeromatron,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,620,,,Wed Jul 14 13:56:14 UTC 2010,,,,,,,,,,"0|i0g41z:",92087,,,,,Low,,,,,,,,,,,,,,,,,"13/Jul/10 17:09;jeromatron;adding patch to return reconciler info to describe_keyspace rval map.;;;","13/Jul/10 17:40;johanoskarsson;Committed, thanks Jeremy!;;;","14/Jul/10 13:56;hudson;Integrated in Cassandra #491 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/491/])
    Change cescribe_keyspace to return reconciler info. Patch by Jeremy Hanna, review by johan. CASSANDRA-1273
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Path not found under Windows 7,CASSANDRA-1270,12469062,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,,szogun1987,szogun1987,12/Jul/10 12:57,16/Apr/19 09:33,14/Jul/23 05:51,28/Dec/10 15:41,,,,,0,,,,,,"I'm not sure that this is bug maybe it is my fault but when I try to run Cassandra using bin\cassandra -f my system returns ""Path not found message"". When i comment ECHO OFF from cassandra.bat I have seen that last line of output contains "".8.jar"";""D:\Cassandra\bin\..\lib\slf4j-log4j12-1.5.8.jar"";""D:\Cassandra\bin\..\build\classes"" ""org.apache.cassandra.thrift.CassandraDaemon""""
D:\Cassandra is my cassandra root directory. Directory ""D:\Casandra\build\classes\org\apache\cassandra\thrift"" contains CassandraDaemon.class, CassandraDaemon$1.class, CassandraDaemon$2.class files.

Apologize for my Vocabulary and Grammar.
","Windows 7 Professional, JRE 1.6",szogun1987,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20054,,,Tue Dec 28 15:42:08 UTC 2010,,,,,,,,,,"0|i0g41b:",92084,,,,,Low,,,,,,,,,,,,,,,,,"28/Dec/10 15:42;jbellis;I believe this is fixed in recent 0.6 releases;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
stress.py stdev option should be float not int,CASSANDRA-1262,12468940,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,brandon.williams,oby1,oby1,09/Jul/10 17:00,16/Apr/19 09:33,14/Jul/23 05:51,11/Jul/10 00:01,0.6.4,,,,0,,,,,,"The option to set the standard deviation parameter for the gaussian key generator defaults to 0.1 but has a type of int in the option parser.  As a result, it's impossible to use non-integer standard deviation values when testing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jul/10 21:28;oby1;cassandra-0.6-1262.txt;https://issues.apache.org/jira/secure/attachment/12449118/cassandra-0.6-1262.txt",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20053,,,Wed Jul 14 13:56:15 UTC 2010,,,,,,,,,,"0|i0g3zj:",92076,,,,,Low,,,,,,,,,,,,,,,,,"09/Jul/10 21:26;oby1;First time contributor - figured this is a simple chance to go through the motions.;;;","11/Jul/10 00:01;brandon.williams;Nice catch Oren!  Committed to 0.6 and trunk.;;;","14/Jul/10 13:56;hudson;Integrated in Cassandra #491 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/491/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
incorrect package name for property_snitch class files,CASSANDRA-1259,12468770,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,urandom,urandom,07/Jul/10 22:44,16/Apr/19 09:33,14/Jul/23 05:51,09/Jul/10 04:43,0.6.4,,,,0,,,,,,"The classes in contrib/property_snitch both have ""src.java"" prepended to them (probably a bug introduced by an IDE).

The attached trivial patch fixes this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/10 22:45;urandom;0001-remove-erroneous-src.java-from-package-name.patch;https://issues.apache.org/jira/secure/attachment/12448931/0001-remove-erroneous-src.java-from-package-name.patch",,,,,,,,,,,,,,1.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20052,,,Fri Jul 09 04:43:09 UTC 2010,,,,,,,,,,"0|i0g3yv:",92073,,,,,Low,,,,,,,,,,,,,,,,,"07/Jul/10 22:59;jbellis;+1;;;","09/Jul/10 04:43;urandom;committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hadoop output SlicePredicate is slow and doesn't work as intended,CASSANDRA-1246,12468445,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,02/Jul/10 15:30,16/Apr/19 09:33,14/Jul/23 05:51,07/Jul/10 13:21,0.7 beta 1,,,,0,,,,,,"The output SlicePredicate is only used to attempt to check that no data exists in the range that we're going to be writing data.  This is 

(a) slow, since it performs get_range_slices across the entire key range, meaning we'll hit every node in the cluster if there is no data (which is supposed to be the normal case)
(b) wrong, since it appears to be intended to use keyList.size to allow data in column X to not interfere with an output to column Y, but that is not how get_range_slices works -- if you have data (or even a tombstone) in any column, you'll get the key back in your result list.  so what you would have to do is scan every key, and check the list of columns returned, which in the case of data actually existing in other columns will be prohibitively slow
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jul/10 15:34;jbellis;1246.txt;https://issues.apache.org/jira/secure/attachment/12448578/1246.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20050,,,Wed Jul 07 13:48:29 UTC 2010,,,,,,,,,,"0|i0g3vz:",92060,,,,,Normal,,,,,,,,,,,,,,,,,"02/Jul/10 15:35;jbellis;patch to remove output SlicePredicate;;;","07/Jul/10 02:48;jeromatron;jonathan - looks fine except the docs.

ColumnFamilyOutputFormat class javadocs as well as its method checkOutputSpecs javadocs both still mention the output slice predicate.;;;","07/Jul/10 13:21;jbellis;committed w/ cleaned up javadoc.  thanks!;;;","07/Jul/10 13:48;hudson;Integrated in Cassandra #488 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/488/])
    r/m Hadoop outputSlicePredicate.  patch by jbellis; reviewed by jhanna for CASSANDRA-1246
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"When loading an AbstractType that does not include an instance field, an unhelpful exception is raised making diagnosis difficult",CASSANDRA-1242,12468314,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,eonnen,eonnen,eonnen,01/Jul/10 01:21,16/Apr/19 09:33,14/Jul/23 05:51,01/Jul/10 22:21,0.7 beta 1,,,,0,,,,,,"0.7.0 changes the contract for creating AbstractTypes. A custom AbstractType defined against 0.6.x will be incompatible and the error messaging around why the comparator is invalid is obtuse and non-obvious. Specifically, when porting a valid AbstractType from 0.6.x to 0.7 that does not include a public static instance field, the thrift system_add_column_family call will throw an exception whose only message is:

InvalidRequestException(why:instance)

No log messages are generated from the server as to the issue so the root cause is non obvious to developers.

I marked as Major because types defined against 0.6.x did not require an ""instance"" field so at a minimum migration of AbstractTypes to 0.7 should document the change in what is expected of AbstractTypes.

Patch attached for better logging and to create a more helpful exception for better communication to the client as to the issue.
",,eonnen,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jul/10 01:23;eonnen;CASSANDRA-1242.patch;https://issues.apache.org/jira/secure/attachment/12448465/CASSANDRA-1242.patch",,,,,,,,,,,,,,1.0,eonnen,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20048,,,Fri Jul 02 13:01:50 UTC 2010,,,,,,,,,,"0|i0g3v3:",92056,,,,,Normal,,,,,,,,,,,,,,,,,"01/Jul/10 22:21;jbellis;committed, thanks!

(I note in our defense that NEWS.txt has mentioned the AbstractType change for several weeks now though :);;;","02/Jul/10 12:47;hudson;Integrated in Cassandra #483 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/483/])
    add friendlier ConfigurationException for malformed AbstractTypes.  patch by Erik Onnen; reviewed by jbellis for CASSANDRA-1242
;;;","02/Jul/10 13:01;jeromatron;Good call Erik - it needed some good feedback like this when people get bitten by the change.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"config file option DiskAccessMode has no-op option ""mmap_index_only""",CASSANDRA-1241,12468307,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,rcoli,rcoli,30/Jun/10 23:35,16/Apr/19 09:33,14/Jul/23 05:51,13/Aug/10 17:12,0.7 beta 2,,Legacy/Documentation and Website,,0,,,,,,"Per http://wiki.apache.org/cassandra/StorageConfiguration :
""
Access mode. mmapped i/o is substantially faster, but only practical on a 64bit machine (which notably does not include EC2 ""small"" instances) or relatively small datasets. ""auto"", the safe choice, will enable mmapping on a 64bit JVM. Other values are ""mmap"", ""mmap_index_only"" (which may allow you to get part of the benefits of mmap on a 32bit machine by mmapping only index files) and ""standard"". (The buffer size settings that follow only apply to standard, non-mmapped i/o.)
""

The actual code referring to ""mmap_index_only"" is in src/java/org/apache/cassandra/config/DatabaseDescriptor.java :
""
 public static enum DiskAccessMode {
        auto,
        mmap,
        mmap_index_only,
        standard,
    }
...
    private static DiskAccessMode diskAccessMode;
    private static DiskAccessMode indexAccessMode;
...
            if (diskAccessMode == DiskAccessMode.auto)
            {
                diskAccessMode = System.getProperty(""os.arch"").contains(""64"") ? DiskAccessMode.mmap : DiskAccessMode.standard;
                indexAccessMode = diskAccessMode;
                logger.info(""Auto DiskAccessMode determined to be "" + diskAccessMode);
            }
            else if (diskAccessMode == DiskAccessMode.mmap_index_only)
            {
                diskAccessMode = DiskAccessMode.standard;
                indexAccessMode = DiskAccessMode.mmap;
            }
            else
            {
                indexAccessMode = diskAccessMode;
            }
""

As indicated by this snippet, IndexAccessMode is set to ""mmap"" if ""mmap_index_only"" is set in the conf file. However it does not appear that IndexAccessMode or getIndexAccessMode() are used by any other cassandra code.

""
~/repos/cassandra$ grep -ri indexAccessMode .
./src/java/org/apache/cassandra/config/DatabaseDescriptor.java:    private static Config.DiskAccessMode indexAccessMode;
./src/java/org/apache/cassandra/config/DatabaseDescriptor.java:                indexAccessMode = conf.disk_access_mode;
./src/java/org/apache/cassandra/config/DatabaseDescriptor.java:                indexAccessMode = Config.DiskAccessMode.mmap;
./src/java/org/apache/cassandra/config/DatabaseDescriptor.java:                indexAccessMode = conf.disk_access_mode;
./src/java/org/apache/cassandra/config/DatabaseDescriptor.java:    public static Config.DiskAccessMode getIndexAccessMode()
./src/java/org/apache/cassandra/config/DatabaseDescriptor.java:        return indexAccessMode;
""

If I understand the code correctly, this means that setting DiskAccessMode to ""mmap_index_only"" is functionally the same as setting it to ""standard."" As people might be tempted to try/test ""mmap_index_only"" as a mode in-between ""standard"" and ""mmap"" in order to mitigate concerns about https://issues.apache.org/jira/browse/CASSANDRA-1214, it would probably be good to either complete the feature or remove the configuration option. I am willing to submit a patch for the latter and fix the docs if that's the decision.
",,appodictic,kingryan,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Aug/10 16:23;jbellis;1241.patch;https://issues.apache.org/jira/secure/attachment/12452034/1241.patch",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20047,,,Sat Aug 14 12:48:32 UTC 2010,,,,,,,,,,"0|i0g3uv:",92055,,stuhood,,stuhood,Low,,,,,,,,,,,,,,,,,"13/Aug/10 16:23;jbellis;patch to restore use of mmap_index_only option;;;","13/Aug/10 16:49;stuhood;+1;;;","13/Aug/10 17:12;jbellis;committed;;;","14/Aug/10 12:48;hudson;Integrated in Cassandra #514 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/514/])
    restore use of mmap_index_only option.  patch by jbellis; reviewed by Stu Hood for CASSANDRA-1241
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cassandra AVRO api is missing system_add_column_family,CASSANDRA-1238,12468180,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,toulmean,next2you,next2you,29/Jun/10 17:45,16/Apr/19 09:33,14/Jul/23 05:51,20/Aug/10 21:37,0.7 beta 2,,,,0,,,,,,"The cassandra.avpr does contain the method system_add_keyspace but is missing the system_add_column_family.

Workaround: have to revert to the thrift API to create column families.
","Mac OSX 10.6.4, Cassandra Trunk, Rev. 958403, java 1.6.0_20",hammer,toulmean,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Aug/10 00:56;toulmean;001-CASSANDRA-1238.patch;https://issues.apache.org/jira/secure/attachment/12452073/001-CASSANDRA-1238.patch","20/Aug/10 21:34;urandom;002-CASSANDRA-1238-errata.patch;https://issues.apache.org/jira/secure/attachment/12452668/002-CASSANDRA-1238-errata.patch","20/Aug/10 06:45;toulmean;002-CASSANDRA-1238.patch;https://issues.apache.org/jira/secure/attachment/12452609/002-CASSANDRA-1238.patch",,,,,,,,,,,,3.0,toulmean,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20044,,,Sat Aug 21 11:14:35 UTC 2010,,,,,,,,,,"0|i0g3u7:",92052,,urandom,,urandom,Normal,,,,,,,,,,,,,,,,,"29/Jun/10 18:08;urandom;Avro support is in-progress and considered experimental. There are still a number of unimplemented RPC methods.

That said, you can create column families and keyspaces at once using {{system_add_keyspace}} but supplying a list of CfDefs (see the system tests for an example of this).;;;","14/Aug/10 00:56;toulmean;Here is a patch that adds this method. It adds the method to the Avro API by patching the Avro protocol and implements the method on CassandraServer, mostly by copy/pasting the code from add_system_keyspace, and using the AddColumnFamily migration to apply the change.

I could not find the tests you were referring to. I would be much more comfortable if that patch came with tests, but I could not spot them in the source code. If you would be so kind as to give me their location, I'd happily contribute tests for this change.;;;","14/Aug/10 01:48;urandom;First off, thanks for taking the time to work on this.

As for the patch, it would be better to model this method after the corresponding one in the Thrift version of CassandraServer, instead of add_system_keyspace().

The tests for this are written in Python and can be found in test/system/test_avro_server.py (let me know if you need help with this).;;;","14/Aug/10 14:27;toulmean;Thanks Eric. I will rework the patch to follow Thrift, and will look at the python tests.;;;","20/Aug/10 06:45;toulmean;Here is a second patch that brings a few new methods to the Avro API. It should cover quite a bit. All tests pass.

This patch is made against the current trunk and ready for review. Enjoy!;;;","20/Aug/10 21:34;urandom;002-CASSANDRA-1238-errata.patch is just here to document the changes I made ontop of 002-CASSANDRA-1238.patch.  This has been committed as one changeset.;;;","20/Aug/10 21:37;urandom;This has been committed with a few changes.  Some of these changes were for conformance with our coding conventions (brace placement, etc), some where normative, but all of them were minor. 

See 002-CASSANDRA-1238-errata.patch for the specific edits I made.

Thanks Antoine!;;;","21/Aug/10 11:14;hudson;Integrated in Cassandra #518 (See [https://hudson.apache.org/hudson/job/Cassandra/518/])
    several new avro rpc method implementations

Patch by Antoine Toulme w/ some changes by eevans for CASSANDRA-1238
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Store AccessLevels externally to IAuthenticator,CASSANDRA-1237,12468077,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,stuhood,stuhood,28/Jun/10 18:29,16/Apr/19 09:33,14/Jul/23 05:51,25/Aug/10 20:43,0.7 beta 2,,,,0,,,,,,"Currently, the concept of authentication (proving the identity of a user) is mixed up with permissions (determining whether a user is able to create/read/write databases). Rather than determining the permissions that a user has, the IAuthenticator should only be capable of authenticating a user, and permissions (specifically, an AccessLevel) should be stored consistently by Cassandra.

EDIT: Adding summary

----

In summary, there appear to be 3 distinct options for how to move forward with authorization. Remember that this ticket is about disconnecting authorization (permissions) from authentication (user/group identification), and its goal is to leave authentication pluggable.

Options:
# Leave authentication and authorization in the same interface. If we choose this option, this ticket is invalid, and CASSANDRA-1271 and CASSANDRA-1320 will add-to/improve IAuthenticator
** Pros:
*** Least change
** Cons:
*** Very little actually implemented by Cassandra: burden is on the backend implementors
*** Each combination of authz and authc backends would require a new implementation (PAM for authc + permissions keyspace for authz, for instance), causing an explosion of implementations
# Separate out a pluggable IAuthority interface to implement authorization
## IAuthenticator interface would be called at login time to determine user/groups membership
## IAuthority would be called at operation time with the user/groups determined earlier, and the required permission for the operation
** Pros:
*** Provides the cleanest separation of concerns
*** Allows plugability for permissions
** Cons:
*** Pluggability of permissions gains limited benefit
*** IAuthority would need to support callbacks for keyspace/cf creation and removal to keep existing keyspaces in sync with their permissions (although technically, option 1 suffers from this as well)
# Separate authorization, but do not make it pluggable
** This option is implemented by the existing patchset by attaching permissions to metadata, but could have an alternative implementation that stores permissions in a permissions keyspace.
** Pros:
*** Cassandra controls the scalability of authorization, and can ensure it does not become a bottleneck
** Cons:
*** Would need to support callbacks for user creation and removal to keep existing users in sync with their permissions",,gdusbabek,rschildmeijer,urandom,,,,,,,,,,,,,,,CASSANDRA-1186,,,,,,,,,,,"28/Jul/10 16:58;stuhood;0001-Consolidate-KSMetaData-mutations-into-copy-methods.patch;https://issues.apache.org/jira/secure/attachment/12450717/0001-Consolidate-KSMetaData-mutations-into-copy-methods.patch","28/Jul/10 16:58;stuhood;0002-Thrift-and-Avro-interface-changes.patch;https://issues.apache.org/jira/secure/attachment/12450718/0002-Thrift-and-Avro-interface-changes.patch","28/Jul/10 16:58;stuhood;0003-Add-user-and-group-access-maps-to-Keyspace-metadata.patch;https://issues.apache.org/jira/secure/attachment/12450719/0003-Add-user-and-group-access-maps-to-Keyspace-metadata.patch","28/Jul/10 16:58;stuhood;0004-Remove-AccessLevel-return-value-from-login-and-retur.patch;https://issues.apache.org/jira/secure/attachment/12450720/0004-Remove-AccessLevel-return-value-from-login-and-retur.patch","28/Jul/10 16:58;stuhood;0005-Move-per-thread-state-into-a-ClientState-object-1-pe.patch;https://issues.apache.org/jira/secure/attachment/12450721/0005-Move-per-thread-state-into-a-ClientState-object-1-pe.patch","28/Jul/10 16:58;stuhood;0006-Apply-access.properties-to-keyspaces-during-an-upgra.patch;https://issues.apache.org/jira/secure/attachment/12450722/0006-Apply-access.properties-to-keyspaces-during-an-upgra.patch","25/Aug/10 02:29;stuhood;sample-usage.patch;https://issues.apache.org/jira/secure/attachment/12453007/sample-usage.patch","29/Jul/10 18:23;messi;simple-jaas-authenticator.patch;https://issues.apache.org/jira/secure/attachment/12450850/simple-jaas-authenticator.patch","25/Aug/10 02:21;stuhood;v2-0001-Remove-AccessLevel-return-value-from-login-since-aut.patch;https://issues.apache.org/jira/secure/attachment/12453002/v2-0001-Remove-AccessLevel-return-value-from-login-since-aut.patch","25/Aug/10 02:29;stuhood;v2-0002-Add-IAuthority-and-split-login-into-authenticate-aut.patch;https://issues.apache.org/jira/secure/attachment/12453005/v2-0002-Add-IAuthority-and-split-login-into-authenticate-aut.patch","25/Aug/10 02:21;stuhood;v2-0003-Factor-out-reflection-based-class-construction.patch;https://issues.apache.org/jira/secure/attachment/12453004/v2-0003-Factor-out-reflection-based-class-construction.patch","25/Aug/10 02:21;stuhood;v2-0004-Add-configuration-for-IAuthority-and-handle-SimpleAu.patch;https://issues.apache.org/jira/secure/attachment/12453003/v2-0004-Add-configuration-for-IAuthority-and-handle-SimpleAu.patch","25/Aug/10 02:29;stuhood;v2-0005-Separate-authentication-and-authorization-into-Clien.patch;https://issues.apache.org/jira/secure/attachment/12453006/v2-0005-Separate-authentication-and-authorization-into-Clien.patch",,13.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20043,,,Wed Aug 25 20:43:17 UTC 2010,,,,,,,,,,"0|i0g3tz:",92051,,urandom,,urandom,Normal,,,,,,,,,,,,,,,,,"20/Jul/10 23:24;stuhood;Patchset to separate permissions from authentication.;;;","20/Jul/10 23:25;stuhood;The set currently uses our old-school KSMetaData serialization, so it will need a rebase when CASSANDRA-1186 makes it in.;;;","21/Jul/10 19:43;stuhood;Rebased post 1186.;;;","21/Jul/10 19:46;stuhood;This should be ready for review.

One thing that might block it getting committed, though, is that we probably need to automate the conversion from 'access.properties' to per-keyspace access maps. Perhaps during loadFromYaml, we could check for the existence of an 'access.properties' file, and apply the properties found there to the new keyspaces?;;;","21/Jul/10 20:40;messi;Failing to authenticate correctly is not an exception. OTOH, accessing a keyspace you're not authorized for is. All RPC methods except ""login"" should throw AuthorizationException.

While you're at it, please look at CASSANDRA-974. I suggest renaming ""login"" to ""authenticate"" and have it return Map<String,String> to make it future-proof for SASL authentication schemes, like DIGEST-MD5.;;;","22/Jul/10 17:15;stuhood;> Failing to authenticate correctly is not an exception.
(Keeping in mind that I didn't change any of the Exception handling/throwing in this patch) I think I agree with the original decision. A failed authentication should be extremely rare, and therefore exceptional.

> All RPC methods except ""login"" should throw AuthorizationException.
Agreed, but out of the scope of this ticket.

> While you're at it, please look at CASSANDRA-974. I suggest renaming ""login"" to ""authenticate""
I'm thinking of the IAuthenticator interface and login() methods as stopgaps until Avro adds support for SASL in their custom protocol (AVRO-341), so I don't think breaking the Thrift API right now is worth it.;;;","22/Jul/10 20:12;stuhood;Rebased for trunk, and added 0006 to handle upgrades by parsing the deprecated 'access.properties' when users call readTablesFromYaml.

This should be ready for review.;;;","26/Jul/10 19:55;stuhood;Rebased for trunk.;;;","27/Jul/10 02:19;messi;Attached patch shows a simple IAuthenticator for JAAS. With JAAS you can configure LoginModules for Unix users or PAM, for LDAP or Kerberos and you can also write your own LoginModule reading passwd.properties files or even column families. In fact, I have a SimpleLoginModule (similar to SimpleAuthenticator) half ready.

This authenticator is also not finished, yet. I submitted it because I hope it's not too late to urge you to make/keep IAuthenticator as lightweight as possible.
The proposed defaultUser() would make IAuthenticators somewhat stateful. Not good.

If you're interested I can open a new issue and submit my JAAS classes there including sample config files and a programmatic JAAS configuration.;;;","27/Jul/10 02:21;messi;By the way, I think the constants USERNAME_KEY and PASSWORD_KEY should go into IAuthenticator because these are common keys used by all authenticators.;;;","27/Jul/10 18:37;gdusbabek;Folke, I'd be interested in seeing your classes (on a separate ticket).;;;","27/Jul/10 18:38;gdusbabek;0003: unavronateAccessMap is checking for null on the wrong variable.
0004: is there a way to not have a default user? I think it adds some noise to the interface.  

Feel free to make breaking changes (no need to support access.properties) if it simplifies things.  Our authentication API has been explicitly 'experimental' from day one.;;;","27/Jul/10 21:29;messi;In AuthenticatedUser.toString(): String.format() is a static method that takes the format as its first parameter.

Again, please drop defaultUser() and put the ""super admin"" status directly into AuthenticatedUser or use a not configurable pseudo group for super admins.;;;","28/Jul/10 16:58;stuhood;* 0003: Fixed unavronateAccessMap null check (good eye!)
* 0004: Moved 'isSuper' onto AuthenticatedUser
* 0004: Fixed static/instance String.format usage
* 0005: Fixed an error where calling set_keyspace before login would fail

----

I can't think of a good way to remove defaultUser: it replaced lots of (authenticator instanceof AllowAllAuthenticator) calls, which existed to check whether it was necessary for the user to login.;;;","28/Jul/10 19:03;messi;I see.

A few suggestions then:
- rename ""AuthenticatedUser"" to just ""User"".
- add ""isAuthenticated"" state to User.
- add package private getter(s) and setter(s) that allow Authenticators to manipulate their User objects.
- add ""User"" as argument to ""login"" (and ""logout""). Authenticators use the credentials to fill in the details.
- rename ""defaultUser"" to ""createUser"" to make it clear that it's a factory method that must always return a (new) User who may or may not already be authenticated.

I know. It's probably too much.;;;","28/Jul/10 21:05;gdusbabek;+1 committed.;;;","29/Jul/10 03:36;jbellis;committing to a users-and-groups approach seems very wrongheaded to me.  the approach of pluggable authenticators to PAM etc seems much better to me (although it's hard to say now since that patch was deleted -- bad practice there...);;;","29/Jul/10 03:50;jbellis;similarly, the AccessLevel change is moving 180 degrees in the wrong direction -- we _want_ to push that into the authenticator rather than hard-coding it somewhere :(;;;","29/Jul/10 13:14;hudson;Integrated in Cassandra #503 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/503/])
    apply access.properties to KSM during loadSchemaFromYaml. patch by stuhood, reviewed by gdusbabek. CASSANDRA-1237
move CS threadlocals into single object. patch by stuhood, reviewed by gdusbabek. CASSANDRA-1237
new IAuthenticator interface. patch by stuhood, reviewed by gdusbabek. CASSANDRA-1237
push access structures into KSM. patch by stuhood, reviewed by gdusbabek. CASSANDRA-1237
put access structures in KsDef. patch by stuhood, reviewed by gdusbabek. CASSANDRA-1237
move KSM modification code into copy methods. patch by stuhood, reviewed by gdusbabek. CASSANDRA-1237
;;;","29/Jul/10 16:29;urandom;On the one hand, decoupling access levels seems like a Good Move, and from that stand-point this is an improvement over the status quo, but I disagree with the decision to bundle the access levels in keyspace definitions.

Wouldn't it be reasonable to create another interface (IAuthority or whatever) and off-load how access levels are persisted to implementations (similar to how it is done with IAuthenticator)?

-1 (in the ASF-sense), I believe this should be rolled back.

EDIT: and I do apologize for coming into this late, as opposed to when it was actively being discussed.;;;","29/Jul/10 16:32;urandom;
{quote}
Attached patch shows a simple IAuthenticator for JAAS. With JAAS you can configure LoginModules for Unix users or PAM, for LDAP or Kerberos and you can also write your own LoginModule reading passwd.properties files or even column families. In fact, I have a SimpleLoginModule (similar to SimpleAuthenticator) half ready.
This authenticator is also not finished, yet. I submitted it because I hope it's not too late to urge you to make/keep IAuthenticator as lightweight as possible.
The proposed defaultUser() would make IAuthenticators somewhat stateful. Not good.

If you're interested I can open a new issue and submit my JAAS classes there including sample config files and a programmatic JAAS configuration.
{quote}

What happened to this? This sounds quite interesting.;;;","29/Jul/10 17:01;stuhood;> the approach of pluggable authenticators to PAM
> we want to push that into the authenticator rather than hard-coding it somewhere
I feel like you're mixing up 'authentication' with 'permissions/authorization'... the reasoning behind this ticket is that backends like PAM aren't designed to provide storage for permissions. Folke's JAAS example is a great example of authentication (and what he coded will still apply post 1237), but I haven't seen any JAAS/PAM backends that implement permissions storage.

> Wouldn't it be reasonable to create another interface (IAuthority or whatever) and off-load how access levels are persisted
I think that would be a mistake, without a working backend that filled the interface. Then, imagine how that backend might fill that interface, and I expect you'll come up with either storing the permissions in their own Keyspace, storing them in a backend specific manner, or attaching them as metadata to the keyspace. The first option is an alternative that should only be implemented once, and therefore shouldn't have an interface. The second could be handled by the IAuthenticator, and is what we have now. The third option is what is implemented here.;;;","29/Jul/10 17:39;urandom;bq. ...the reasoning behind this ticket is that backends like PAM aren't designed to provide storage for permissions.

PAM is a bad example here, and there are plenty of other (more relevant) services and frameworks that do, (think LDAP, radius, tacacs, etc).

bq. I think that would be a mistake, without a working backend that filled the interface.

Right, you'd need at least the equivalent of SimpleAuthenticator.

bq. Then, imagine how that backend might fill that interface, and I expect you'll come up with either storing the permissions in their own Keyspace, storing them in a backend specific manner, or attaching them as metadata to the keyspace. The first option is an alternative that should only be implemented once, and therefore shouldn't have an interface. The second could be handled by the IAuthenticator, and is what we have now. The third option is what is implemented here.

If authorization should be pluggable (I've argued that is should be), then ""backend specific"" is the only option that makes sense.

;;;","29/Jul/10 18:23;messi;I'm sorry I deleted my patch too early. I wanted to open a new ticket but when I looked over my code I thought that it's not ready and I want to work on it over the weekend.

The attached patch adds several classes:
- +JAASAuthenticator:+ an IAuthenticator implemention that uses a LoginContext to request authentication against configured LoginModules. Very simple stuff.
- +SimpleLoginModule:+ LoginModule impl that could replace SimpleAuthenticator.
- +SimpleLoginModuleConfiguration:+ programmatic configuration of LoginModules.
- +User/Group:+ implementations of java.security.Principal added by SimpleLoginModule to the Subject that is passed from the LoginContext to all configured LoginModules.

This is only proof-of-concept code. I hope I have something cleaner and more robust ready by Sunday.;;;","29/Jul/10 18:45;jbellis;I agree that committing this was premature, and also apologize for not looking at it earlier.;;;","29/Jul/10 19:09;stuhood;> If authorization should be pluggable (I've argued that is should be)
I'd be interested in seeing the reasons for making permissions pluggable, if you know where I can find the thread.;;;","29/Jul/10 19:15;gdusbabek;>> If authorization should be pluggable (I've argued that is should be)
>I'd be interested in seeing the reasons for making permissions pluggable, if you know where I can find the thread.

Separation of concerns.  I tried to make the argument yesterday that mixing KS definitions with KS permissions was not the right design.;;;","29/Jul/10 19:25;stuhood;> Separation of concerns. I tried to make the argument yesterday that mixing KS definitions with KS permissions was not the right design.
Separation of concerns is not an argument for making it pluggable (pluggable implies multiple implementations), although it is an argument for storing the permissions somewhere other than in the metadata for the keyspace.;;;","29/Jul/10 19:43;urandom;{quote}
> If authorization should be pluggable (I've argued that is should be)
I'd be interested in seeing the reasons for making permissions pluggable, if you know where I can find the thread.
{quote}

Directory services like LDAP and Active Directory seem like prominent examples of existing systems that people might want to integrate with for authorization, (as well as authentication). And, I'm sure there are plenty of people with existing databases, web services, etc that would appreciate the opportunity to integrate instead of duplicating that information.;;;","29/Jul/10 20:22;messi;I don't think you can make authorization pluggable: authorization is very specific, it requires predefined permissions and/or group/role names, and authz is done at many places in the code. I recommend an authorization infrastructure that does not authorize users directly but groups or roles. An authenticator must return a list of groups a user belongs to and the authz infrastructure renders a list of permissions. In Cassandra you just ask if UserX.isAllowedTo(READ, ""Keyspace1"");;;;","30/Jul/10 13:37;hudson;Integrated in Cassandra #504 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/504/])
    revert 980215, 980217, 980220, 980222, 980225, 980226. CASSANDRA-1237
;;;","16/Aug/10 19:49;stuhood;In summary, there appear to be 3 distinct options for how to move forward with authorization. Remember that this ticket is about disconnecting authorization (permissions) from authentication (user/group identification), and its goal is to leave authentication pluggable.

Options:
# Leave authentication and authorization in the same interface. If we choose this option, this ticket is invalid, and CASSANDRA-1271 and CASSANDRA-1320 will add-to/improve IAuthenticator
** Pros:
*** Least change
** Cons:
*** Very little actually implemented by Cassandra: burden is on the backend implementors
*** Each combination of authz and authc backends would require a new implementation (PAM for authc + permissions keyspace for authz, for instance), causing an explosion of implementations
# Separate out a pluggable IAuthority interface to implement authorization
## IAuthenticator interface would be called at login time to determine user/groups membership
## IAuthority would be called at operation time with the user/groups determined earlier, and the required permission for the operation
** Pros:
*** Provides the cleanest separation of concerns
*** Allows plugability for permissions
** Cons:
*** Pluggability of permissions gains limited benefit
*** IAuthority would need to support callbacks for keyspace/cf creation and removal to keep existing keyspaces in sync with their permissions (although technically, option 1 suffers from this as well)
# Separate authorization, but do not make it pluggable
** This option is implemented by the existing patchset by attaching permissions to metadata, but could have an alternative implementation that stores permissions in a permissions keyspace.
** Pros:
*** Cassandra controls the scalability of authorization, and can ensure it does not become a bottleneck
** Cons:
*** Would need to support callbacks for user creation and removal to keep existing users in sync with their permissions;;;","16/Aug/10 20:24;urandom;The pressing problem is that the current implementation predates dynamically created keyspaces/column families and as a result it's not possible to add/remove keyspaces with auth enabled.  It's also quite late in the 0.7 cycle so ""least change"" from #1 seems quite appealing.;;;","16/Aug/10 20:37;stuhood;> The pressing problem is that the current implementation predates dynamically created keyspaces/column families
Correct.. CASSANDRA-1271 addresses that issue. I think it is too late to make any of these changes in 0.7, so I'm interested in what you think we can/should do for 0.8.;;;","16/Aug/10 22:15;toulmean;I am in favor of 3. I like that it keeps scalability over checking permissions, and I like it is made pluggable for people to integrate with LDAP or their own framework.;;;","16/Aug/10 22:22;urandom;bq. I am in favor of 3. I like that it keeps scalability over checking permissions, and I like it is made pluggable for people to integrate with LDAP or their own framework.

3 is decidedly _not_ pluggable with respect to authorization (only authentication).   Also, there is also nothing to prevent you from implementing a back-end that stored credentials and/or permissions in Cassandra. ;;;","17/Aug/10 20:07;rnirmal;Here's some probable use cases for Authz:
* User A / Group B -> read/write KS1, KS2: read KS3
* User C / Group D -> create/rename/drop KS/CF
* User E -> read/write KS1-CF1, KS1-CF2: read KS1-CF3
* Admin -> add/modify/delete Users/groups/permissions;;;","23/Aug/10 19:27;stuhood;I think it should be possible to implement option #2 before 0.7 final, if we defer implementing the 'callbacks' until we have a backend that can support modifying its permissions (SimpleAuthenticator cannot).

Split {{AccessLevel IAuthenticator.login(String keyspace, Map credentials)}} into:
* {{AuthenticatedUser IAuthenticator.authenticate(Map credentials)}}
** Where AuthenticatedUser is similar to the implementation in the existing patchset, but without a 'isSuper' flag, since the IAuthority should make that decision
* {{AccessLevel IAuthority.authorize(AuthenticatedUser user,  String keyspace)}}
** In CASSANDRA-1320, AccessLevel will be replaced with a Set<Permission>
** In CASSANDRA-1271, keyspace will be replaced with a generic 'resource' hierarchy

Does this sound reasonable?;;;","23/Aug/10 20:04;urandom;bq. Does this sound reasonable?

It sounds reasonable to me.;;;","25/Aug/10 02:29;stuhood;Implementation of option 2:

v2-0001 - Removes AccessLevel return value from login in the client APIs
v2-0002 - Splits IAuthority out of IAuthenticator: SimpleAuthority and SimpleAuthenticator are backwards compatible
v2-0003 - Removes some reflection-centered duplication
v2-0004 - Allows configuration of an IAuthority, and specifies SimpleAuthority for upgraders who have configured SimpleAuthenticator
v2-0005 - Splits the authc/z ThreadLocals out of the CassandraServers and into a ClientState object;;;","25/Aug/10 02:31;stuhood;Optimistically targetting back to 0.7-beta2 (sorry for the flapping).;;;","25/Aug/10 20:43;urandom;committed; thanks!;;;",,,,,,,,,,,,,,,,,,,
"when I start up the cassandra-cli, a ClassNotFoundException occured:java.lang.ClassNotFoundException: org.apache.cassandra.cli.CliMain",CASSANDRA-1236,12468055,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,ialand,ialand,28/Jun/10 13:22,16/Apr/19 09:33,14/Jul/23 05:51,21/Jul/10 16:18,0.6.4,,Legacy/Tools,,0,,,,,,"After start up the cassandra server, I went to the bin/ directory and run the cassandra-cli, but there's an Exception throwed out, I have set the CASSANDRA_HOME system variable,  I don't know why
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/cassandra/cli/CliMain
Caused by: java.lang.ClassNotFoundException: org.apache.cassandra.cli.CliMain
        at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:276)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:251)
        at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:319)",windows XP,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Aug/10 04:59;l0s;cassandra-cli;https://issues.apache.org/jira/secure/attachment/12451744/cassandra-cli",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20042,,,Thu Sep 08 13:02:21 UTC 2011,,,,,,,,,,"0|i0g3tr:",92050,,,,,Low,,,,,,,,,,,,,,,,,"29/Jun/10 04:04;jbellis;Please do not change the issue metadata.;;;","08/Jul/10 14:34;jbellis;can you reproduce in 0.6.3 gary?;;;","21/Jul/10 16:18;gdusbabek;fixed in trunk and 0.6.4.;;;","11/Aug/10 03:33;l0s;I am able to reproduce this in the 0.6.4 binary release.  I get the error when running cassandra-cli from the Cassandra directory as well as from the bin directory.;;;","11/Aug/10 03:56;gdusbabek;Thanks Carlos.  Do you have the know-how to fix the batch file?  If so, would you be willing to do this and attach it to this ticket?  I can take care of the rest.;;;","11/Aug/10 04:59;l0s;Attached is a fix for the Bourne shell script.  It was tested on Cygwin/XP.;;;","11/Aug/10 05:04;l0s;Hi Gary, I actually did not realise that there was a batch file to launch the CLI but I took a look and figured out what needed to be done to the sh script.  I don't know enough about Windows batch programming to fix the bat file.  Anyway, thanks for pointing me in the right direction.  I was just trying to get through the GettingStarted guide on the Wiki.;;;","08/Sep/11 08:25;smartree;Need the CASSANDRA_HOME system variable,
or Run the bat in CMD from Directory of ""CASSANDRA_HOME"">bin\cassandra-cli;;;","08/Sep/11 13:02;jbellis;Smartree, 

1) please submit changes as a patch generated by svn diff

2) adding lib/*.jar is done by cassandra.in.sh (the CASSANDRA_INCLUDE searched for at the beginning of -cli).  There's no need to do it a second time in the cli script.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BytesType and batch mutate causes encoded bytes of non-printable characters to be dropped,CASSANDRA-1235,12468005,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,messi,tnine,tnine,28/Jun/10 03:02,16/Apr/19 09:33,14/Jul/23 05:51,13/Aug/10 17:26,0.6.5,,,,0,,,,,,"When running the two tests, individual column insert works with the values generated.  However, batch insert with the same values causes an encoding failure on the key.  It appears bytes are dropped from the end of the byte array that represents the key value.  See the attached unit test","Java 1.6 sun JDK 
Java(TM) SE Runtime Environment (build 1.6.0_20-b02)
Java HotSpot(TM) 64-Bit Server VM (build 16.3-b01, 

Ubuntu 10.04 64 bit",stuhood,tjake,tnine,univ,uschindler,,,,,,,,,,,,,,CASSANDRA-767,,,,,,,,,,"12/Aug/10 19:56;univ;TestByteKeys.py;https://issues.apache.org/jira/secure/attachment/12451944/TestByteKeys.py","28/Jun/10 03:03;tnine;TestEncodedKeys.java;https://issues.apache.org/jira/secure/attachment/12448170/TestEncodedKeys.java","31/Jul/10 16:28;messi;rowmutation-key-trimming.patch;https://issues.apache.org/jira/secure/attachment/12450963/rowmutation-key-trimming.patch",,,,,,,,,,,,3.0,messi,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20041,,,Fri Aug 13 18:29:49 UTC 2010,,,,,,,,,,"0|i0g3tj:",92049,,,,,Critical,,,,,,,,,,,,,,,,,"28/Jun/10 03:03;tnine;This file demonstrates the broken input.  Notice that the first test passes with clean input.  The second one fails utilizing batch write for the same input keys.;;;","28/Jun/10 15:30;jbellis;Please don't mess with the issue metadata.;;;","28/Jun/10 19:38;tnine;No worries, sorry about that, I just realized the affected version was incorrect.  Where can I look to begin fixing this? Unfortunately this issue has caused our development to a halt since we depend on the functionality of numeric range queries in Lucene/Lucandra.  Ideally I'd like to create a patch that applies to 0.6.2 so we can roll our own build with the patch and get running again.  I'm assuming it's an issue with the thrift server, but I don't want to start tweaking things without a good idea on where I should be looking for this issue.

Here's an example in hex.  The left is what I pass as bytes in UTF-8 for the key, the right is what I get back during get_range_slice.

http://pastebin.com/KM8Ze794
;;;","08/Jul/10 15:27;jbellis;I believe that

                return new String(buffer, 0, len);

will treat buffer as UTF-16, not UTF-8.  you want

                return new String(buffer, 0, len, ""UTF8"");

I'm not at all sure that longToPrefixCoded is going to generate valid UTF-8, either.;;;","08/Jul/10 16:15;uschindler;buffer is char[], so there is no conversion at all, new String(char[]) only copies the char[] to the internal String's char[]. longToPrefixCoded is definitely correct, large parts of Lucene Java are based on this :-)

(from the Lucene Generics and Unicode Policeman);;;","08/Jul/10 19:45;tnine;While I'm in agreement with Uwe, my bigger concern is that two tests that are functionally equivalent return different results based on the mutation operations.  Performing a batch mutate with the same insertion data as a single write should insert and the same bytes.  Unfortunately batch mutate appears to be randomly dropping bytes.  If it were a true UTF8 issue, wouldn't it drop bytes on the single column writes as well batch mutate?;;;","08/Jul/10 20:21;jbellis;That has to be a Thrift bug, then -- the insert and batch_mutate method both end up calling StorageProxy.mutate or mutateBlocking after converting the Thrift objects into RowMutations;;;","26/Jul/10 21:47;todd@spidertracks.co.nz;I'm currently out of the office and will return on 2010-07-27.  If
this is an urgent request, please mail support@spidertracks.com.
;;;","31/Jul/10 16:28;messi;This patch fixes the problem but I don't know if other problems will arise.;;;","01/Aug/10 01:42;jbellis;nice fix.  (It's possible that this would break someone relying on it, but it's clearly broken the way it is.)  committed.;;;","12/Aug/10 19:58;univ;Still experiencing some problems with byte keys. The file ""TestByteKeys.py"" demonstrates the problem.
Tested with revision 984926.;;;","13/Aug/10 17:26;jbellis;0.6 row keys are _strings_ which means they must be utf-8 encoded, although your version of thrift for python doesn't enforce that (see THRIFT-395).;;;","13/Aug/10 18:29;uschindler;For Lucandra/Lucene this is fine, too (at the moment, as all terms are strings here. Even binary numbers are correcty UTF-8 encoded terms).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
loadbalance operation never completes on a 3 node cluster,CASSANDRA-1221,12467688,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,23/Jun/10 12:39,16/Apr/19 09:33,14/Jul/23 05:51,20/Jul/10 17:12,0.6.4,,,,1,,,,,,"Arya Goudarzi reports:

Please confirm if this is an issue and should be reported or I am doing something wrong. I could not find anything relevant on JIRA:

Playing with 0.7 nightly (today's build), I setup a 3 node cluster this way:

 - Added one node;
 - Loaded default schema with RF 1 from YAML using JMX;
 - Loaded 2M keys using py_stress;
 - Bootstrapped a second node;
 - Cleaned up the first node;
 - Bootstrapped a third node;
 - Cleaned up the second node;

I got the following ring:

Address       Status     Load          Range                                      Ring
                                      154293670372423273273390365393543806425
10.50.26.132  Up         518.63 MB     69164917636305877859094619660693892452     |<--|
10.50.26.134  Up         234.8 MB      111685517405103688771527967027648896391    |   |
10.50.26.133  Up         235.26 MB     154293670372423273273390365393543806425    |-->|

Now I ran:

nodetool --host 10.50.26.132 loadbalance

It's been going for a while. I checked the streams

nodetool --host 10.50.26.134 streams
Mode: Normal
Not sending any streams.
Streaming from: /10.50.26.132
  Keyspace1: /var/lib/cassandra/data/Keyspace1/Standard1-tmp-d-3-Data.db/[(0,22206096), (22206096,27271682)]
  Keyspace1: /var/lib/cassandra/data/Keyspace1/Standard1-tmp-d-4-Data.db/[(0,15180462), (15180462,18656982)]
  Keyspace1: /var/lib/cassandra/data/Keyspace1/Standard1-tmp-d-5-Data.db/[(0,353139829), (353139829,433883659)]
  Keyspace1: /var/lib/cassandra/data/Keyspace1/Standard1-tmp-d-6-Data.db/[(0,366336059), (366336059,450095320)]

nodetool --host 10.50.26.132 streams
Mode: Leaving: streaming data to other nodes
Streaming to: /10.50.26.134
  /var/lib/cassandra/data/Keyspace1/Standard1-d-48-Data.db/[(0,366336059), (366336059,450095320)]
Not receiving any streams.

These have been going for the past 2 hours.

I see in the logs of the node with 134 IP address and I saw this:

INFO [GOSSIP_STAGE:1] 2010-06-22 16:30:54,679 StorageService.java (line 603) Will not change my token ownership to /10.50.26.132

So, to my understanding from wikis loadbalance supposed to decommission and re-bootstrap again by sending its tokens to other nodes and then bootstrap again. It's been stuck in streaming for the past 2 hours and the size of ring has not changed. The log in the first node says it has started streaming for the past hours:

INFO [STREAM-STAGE:1] 2010-06-22 16:35:56,255 StreamOut.java (line 72) Beginning transfer process to /10.50.26.134 for ranges (154293670372423273273390365393543806425,69164917636305877859094619660693892452]
 INFO [STREAM-STAGE:1] 2010-06-22 16:35:56,255 StreamOut.java (line 82) Flushing memtables for Keyspace1...
 INFO [STREAM-STAGE:1] 2010-06-22 16:35:56,266 StreamOut.java (line 128) Stream context metadata [/var/lib/cassandra/data/Keyspace1/Standard1-d-48-Data.db/[(0,366336059), (366336059,450095320)]] 1 sstables.
 INFO [STREAM-STAGE:1] 2010-06-22 16:35:56,267 StreamOut.java (line 135) Sending a stream initiate message to /10.50.26.134 ...
 INFO [STREAM-STAGE:1] 2010-06-22 16:35:56,267 StreamOut.java (line 140) Waiting for transfer to /10.50.26.134 to complete
 INFO [FLUSH-TIMER] 2010-06-22 17:36:53,370 ColumnFamilyStore.java (line 359) LocationInfo has reached its threshold; switching in a fresh Memtable at CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1277249454413.log', position=720)
 INFO [FLUSH-TIMER] 2010-06-22 17:36:53,370 ColumnFamilyStore.java (line 622) Enqueuing flush of Memtable(LocationInfo)@1637794189
 INFO [FLUSH-WRITER-POOL:1] 2010-06-22 17:36:53,370 Memtable.java (line 149) Writing Memtable(LocationInfo)@1637794189
 INFO [FLUSH-WRITER-POOL:1] 2010-06-22 17:36:53,528 Memtable.java (line 163) Completed flushing /var/lib/cassandra/data/system/LocationInfo-d-9-Data.db
 INFO [MEMTABLE-POST-FLUSHER:1] 2010-06-22 17:36:53,529 ColumnFamilyStore.java (line 374) Discarding 1000


Nothing more after this line.

Am I doing something wrong?",,anty,arya,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jul/10 15:25;gdusbabek;0.6-conviction-fix.diff;https://issues.apache.org/jira/secure/attachment/12449928/0.6-conviction-fix.diff","20/Jul/10 11:39;gdusbabek;0001-Gossiper-and-FD-never-called-MS.convict-to-shut-down.patch;https://issues.apache.org/jira/secure/attachment/12449920/0001-Gossiper-and-FD-never-called-MS.convict-to-shut-down.patch","15/Jul/10 00:24;arya;system1.log;https://issues.apache.org/jira/secure/attachment/12449507/system1.log","15/Jul/10 00:24;arya;system2.log;https://issues.apache.org/jira/secure/attachment/12449508/system2.log","15/Jul/10 00:24;arya;system3.log;https://issues.apache.org/jira/secure/attachment/12449509/system3.log",,,,,,,,,,5.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20038,,,Wed Jul 21 12:50:25 UTC 2010,,,,,,,,,,"0|i0g3qn:",92036,,,,,Normal,,,,,,,,,,,,,,,,,"14/Jul/10 00:05;arya;Hi Gary,

I was able to reproduce this using today's nightly build. This time i used a smaller data set (500000 keys) and I got the following:

[agoudarzi@cas-test3 scripts]$ nodetool --host 10.50.26.132 ring   
Address         Status State   Load            Token                                       
                                       160348796167900510561059505917619274541    
10.50.26.134    Up     Normal  116.98 MB       32717880524093094169411234083126184860      
10.50.26.132    Up     Leaving 58.58 MB        75101027859180840627831025901565139619      
10.50.26.133    Up     Normal  117.09 MB       160348796167900510561059505917619274541    

[agoudarzi@cas-test3 scripts]$ nodetool --host 10.50.26.132 streams
Mode: Leaving: streaming data to other nodes
Streaming to: /10.50.26.133
   /var/lib/cassandra/data/Keyspace1/Standard1-d-17-Data.db/[(0,54080834)]
Not receiving any streams.
[agoudarzi@cas-test3 scripts]$ nodetool --host 10.50.26.133 streams
Mode: Normal
Not sending any streams.
Not receiving any streams.

From the logs of 10.50.26.132 it seams that it tried to tell 10.50.26.133 to claim its stream:

INFO [STREAM-STAGE:1] 2010-07-13 16:50:35,994 StreamOut.java (line 135) Sending a stream initiate message to /10.50.26.133 ...
INFO [STREAM-STAGE:1] 2010-07-13 16:50:35,994 StreamOut.java (line 140) Waiting for transfer to /10.50.26.133 to complete

But nothing in 133's log acknowledges the receipt of the request from 132 and as you see above it shows that it is getting no streams and this has been going for the past hour or so.

-Arya

;;;","14/Jul/10 21:50;gdusbabek;Arya,  can you supply the nodetool commands you are using that constitute ""cleanup""?  I've tried a few times now and can't get the failure you describe.  In your latest test was .132 the second or third node booted?;;;","14/Jul/10 22:55;arya;132 is node1
133 is node2
134 is node3

Give me some time and I'll regenerate all the commands for you in details. ;;;","15/Jul/10 00:20;arya;Gary, I missed one thing (Step 9-13) where I took a node down and insert. I tested this without step 9-13 and loadbalance worked. Not sure why step 9-13 changes everything. Here are the full production steps (I am also attaching the logs from all 3 nodes if it helps):

This is the ring topology I discuss here:

Node1 10.50.26.132 (Hostname: cas-test1)
Node2 10.50.26.133 (Hostname: cas-test2)
Node3 10.50.26.134 (Hostname: cas-test3)

This run is using today's nightly built from a clean setup.

Step 1: Startup Node1

[agoudarzi@cas-test1 ~]$ sudo /etc/init.d/cassandra start

Step 2: LoadSchemadFromYAML

I go to JConsole and call the function from o.a.c.service StorageService MBeans

Step 3: I insert 500000 keys into Standard1 CF using py_stress

$ python stress.py --num-keys 500000 --threads 8 --nodes 10.50.26.132 --keep-going --operation insert
Keyspace already exists.
total,interval_op_rate,interval_key_rate,avg_latency,elapsed_time
62455,6245,6245,0.00128478354559,10
121893,5943,5943,0.00134767375398,21
184298,6240,6240,0.00128336335573,31
248124,6382,6382,0.00124898537112,42
297205,4908,4908,0.00163303957852,52
340338,4313,4313,0.00189026848124,63
380233,3989,3989,0.00203818801591,73
444452,6421,6421,0.00124198496903,84
500000,5554,5554,0.00114441244599,93

Step 3: Let's Take a Look at Ring

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 ring
Address         Status State   Load            Token                                       
10.50.26.132    Up     Normal  206.05 MB       139380634429053457983268837561452509806     

Step 4: Bootstrap Node 2 into cluster

[agoudarzi@cas-test2 ~]$ sudo /etc/init.d/cassandra start

Step 5: Check the ring
[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Joining 5.84 KB         54081521187303805945240848606999860232      
10.50.26.132    Up     Normal  206.05 MB       139380634429053457983268837561452509806     

Step 6: Check the streams on Node 1

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 streams
Mode: Normal
Streaming to: /10.50.26.133
   /var/lib/cassandra/data/Keyspace1/Standard1-d-5-Data.db/[(0,34658183), (89260032,109057810)]
   /var/lib/cassandra/data/Keyspace1/Standard1-d-6-Data.db/[(0,8746823), (22272929,27264363)]
   /var/lib/cassandra/data/Keyspace1/Standard1-d-8-Data.db/[(0,8749389), (22336617,27264253)]
   /var/lib/cassandra/data/Keyspace1/Standard1-d-9-Data.db/[(0,8235190), (21174782,25822054)]
   /var/lib/cassandra/data/Keyspace1/Standard1-d-7-Data.db/[(0,8642472), (22333239,27264347)]
Not receiving any streams.

Step 7: Check the ring from Node1 and Node2 and make sure they agree

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.132    Up     Normal  233.93 MB       139380634429053457983268837561452509806     
[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.133 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.132    Up     Normal  233.93 MB       139380634429053457983268837561452509806

Step 8: Cleanup Node1

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 cleanup

Step 9: Check the ring agreement again

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.132    Up     Normal  117 MB          139380634429053457983268837561452509806     
[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.133 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.132    Up     Normal  117 MB          139380634429053457983268837561452509806     

Step 9: Let's kill Node 2

[agoudarzi@cas-test2 ~]$ sudo /etc/init.d/cassandra stop 

Step 10: Check the ring on Node 1

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Down   Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.132    Up     Normal  117 MB          139380634429053457983268837561452509806

Step 11: Let's try to insert 500000 more keys expecting lots of unavailable exceptions ad the only replica for some keys is dead and py_stress does not use CLevel.ANY or ZERO

$ python stress.py --num-keys 500000 --threads 8 --nodes 10.50.26.132 --keep-going --operation insert

Keyspace already exists.
UnavailableException()
UnavailableException()
UnavailableException()
....
...
..
.
total,interval_op_rate,interval_key_rate,avg_latency,elapsed_time
500000,2922,2922,0.000816067281446,67

Step 12: Check the ring

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Down   Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.132    Up     Normal  205.35 MB       139380634429053457983268837561452509806     

Node 1 got more data as expected

Step 13: Bring up Node 2 again

[agoudarzi@cas-test2 ~]$ sudo /etc/init.d/cassandra start

Step 14: Check the Ring

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.132    Up     Normal  205.35 MB       139380634429053457983268837561452509806     
[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.133 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.132    Up     Normal  205.35 MB       139380634429053457983268837561452509806

Step 15: Bootstrap Node 3

[agoudarzi@cas-test3 ~]$ sudo /etc/init.d/cassandra start

Step 11: Check Ring 

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.134    Up     Normal  116.68 MB       96565427321648203609592911083606603165      
10.50.26.132    Up     Normal  234 MB          139380634429053457983268837561452509806     
[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.133 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.134    Up     Normal  116.68 MB       96565427321648203609592911083606603165      
10.50.26.132    Up     Normal  234 MB          139380634429053457983268837561452509806     
[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.134 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.134    Up     Normal  116.68 MB       96565427321648203609592911083606603165      
10.50.26.132    Up     Normal  234 MB          139380634429053457983268837561452509806     

Step 12: Cleanup Node 1 (132)

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 cleanup

Step 13: Check Ring

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.134    Up     Normal  116.68 MB       96565427321648203609592911083606603165      
10.50.26.132    Up     Normal  58.89 MB        139380634429053457983268837561452509806     
[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.133 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.134    Up     Normal  116.68 MB       96565427321648203609592911083606603165      
10.50.26.132    Up     Normal  58.89 MB        139380634429053457983268837561452509806     
[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.134 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.134    Up     Normal  116.68 MB       96565427321648203609592911083606603165      
10.50.26.132    Up     Normal  58.89 MB        139380634429053457983268837561452509806     

Looks as expected. Node 1 (132) has the least load. Let's loadbalance it.

Step 14: Loadbalance Node 1

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 loadbalance &
[1] 27457

Step 15: Check Ring

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.134    Up     Normal  116.68 MB       96565427321648203609592911083606603165      
10.50.26.132    Up     Leaving 58.89 MB        139380634429053457983268837561452509806     
[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.133 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.134    Up     Normal  116.68 MB       96565427321648203609592911083606603165      
10.50.26.132    Up     Leaving 58.89 MB        139380634429053457983268837561452509806     
[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.134 ring
Address         Status State   Load            Token                                       
                                       139380634429053457983268837561452509806    
10.50.26.133    Up     Normal  116.94 MB       54081521187303805945240848606999860232      
10.50.26.134    Up     Normal  116.68 MB       96565427321648203609592911083606603165      
10.50.26.132    Up     Leaving 58.89 MB        139380634429053457983268837561452509806     

Step 16: Check the Streams

[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.132 streams
Mode: Leaving: streaming data to other nodes
Streaming to: /10.50.26.133
   /var/lib/cassandra/data/Keyspace1/Standard1-d-17-Data.db/[(0,54278564)]
Not receiving any streams.
[agoudarzi@cas-test1 ~]$ nodetool --host=10.50.26.133 streams
Mode: Normal
Not sending any streams.
Not receiving any streams.

PROBLEM:
Notice 132 says I am streaming to 133 but 133 says ""Not receiving any streams!""  


;;;","15/Jul/10 00:24;arya;Cassandra System Logs for node 1-3;;;","15/Jul/10 20:30;gdusbabek;Thanks Arya. I can reproduce this.  Now just to fix it.;;;","20/Jul/10 11:48;gdusbabek;Several problems on this ticket.
1. MessaingService implemented IFailureDetector and was in charge of shutting down TCP connections during a partition.  However, it was never added to the listeners in FD.  This meant that MS.convict() was never getting called.
2. Under the right conditions (I still don't understand this fully), java sockets still give every indication they are connected even though the host on the other end is down.  A single write will succeed, even though no bytes are sent.  Seriously.  In our case the single write was a StreamInitiateMessage that we then wait forever to be acked the the [dead] remote host.

My solution was to use Gossiper.convict, which calls SS.onDead, to call MS.convict().  I don't think it makes sense to have MS implement IFailureDetector since we treat Gossiper as authoritative with respect to node alive-ness.

I'll spend some time checking this morning, but I suspect we have the same situation in 0.6.;;;","20/Jul/10 15:25;gdusbabek;patch for 0.6.  I couldn't get stress.py to work in my branch, but the same problem should be present.  All tests pass with this patch.;;;","20/Jul/10 16:17;jbellis;+1

(but fix brace placement in onDead please);;;","21/Jul/10 12:50;hudson;Integrated in Cassandra #496 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/496/])
    failure detection wasn't closing sockets. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1221
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
avoid creating a new byte[] for each mutation replayed,CASSANDRA-1219,12467621,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,22/Jun/10 21:41,16/Apr/19 09:33,14/Jul/23 05:51,23/Jun/10 04:07,0.7 beta 1,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jun/10 21:42;jbellis;1219.txt;https://issues.apache.org/jira/secure/attachment/12447745/1219.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20037,,,Wed Jun 23 15:14:38 UTC 2010,,,,,,,,,,"0|i0g3q7:",92034,,,,,Low,,,,,,,,,,,,,,,,,"22/Jun/10 22:02;mdennis;+1 but we should move the alloc outside of the file loop too;;;","23/Jun/10 04:07;jbellis;committed w/ suggested improvement;;;","23/Jun/10 15:14;hudson;Integrated in Cassandra #474 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/474/])
    avoid allocation-per-row in log replay
patch by jbellis; reviewed by mdenns for CASSANDRA-1219
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
removetoken drops node from ring before re-replicating its data is finished,CASSANDRA-1216,12467577,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,nickmbailey,jbellis,jbellis,22/Jun/10 14:28,16/Apr/19 09:33,14/Jul/23 05:51,28/Sep/10 05:56,0.7 beta 2,,,,0,,,,,,this means that if something goes wrong during the re-replication (e.g. a source node is restarted) there is (a) no indication that anything has gone wrong and (b) no way to restart the process (other than the Big Hammer of running repair),,gdusbabek,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Sep/10 20:24;nickmbailey;0001-Modify-removeToken-to-be-similar-to-decommission.patch;https://issues.apache.org/jira/secure/attachment/12455298/0001-Modify-removeToken-to-be-similar-to-decommission.patch","22/Sep/10 20:24;nickmbailey;0002-Additional-tests-for-removeToken.patch;https://issues.apache.org/jira/secure/attachment/12455299/0002-Additional-tests-for-removeToken.patch","27/Sep/10 15:54;nickmbailey;0003-Fixes-from-review.patch;https://issues.apache.org/jira/secure/attachment/12455666/0003-Fixes-from-review.patch",,,,,,,,,,,,3.0,nickmbailey,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20035,,,Tue Sep 28 13:31:34 UTC 2010,,,,,,,,,,"0|i0g3pj:",92031,,gdusbabek,,gdusbabek,Normal,,,,,,,,,,,,,,,,,"02/Jul/10 15:16;nickmbailey;A possible solution I see for this is to keep nodes in the justRemovedEndpoints map in Gossiper until we can verify that replication has completed.  I think we could accomplish verification through a callback on the replicate request.  I'm unsure about what data gets persisted so I don't know if a restart would wipe out the justRemovedEndpoints map;;;","02/Jul/10 16:12;nickmbailey;So clearly that solution would fail in the case of the node that is attempting to retrive the data failing.  Perhaps a better solution is simply not removing the node until replication and done.  Perhaps marking it with a new state?;;;","06/Jul/10 19:41;nickmbailey;It seems like this should follow a pattern similar to decommissioning a node.

* If nodeA has removeToken called on it, it becomes responsible for nodeB, the node to remove
* nodeA sets the MOVE_STATE of nodeB to STATE_REMOVING
* This is gossipped throughout the ring.
* Nodes see this change and fetch any ranges they are becoming responsible for
** After this is complete they will need to notify nodeA somehow that this is complete
* Once nodeA sees all replications have finished, change state of nodeB to STATE_REMOVED
* All nodes then remove nodeB from their ring.;;;","06/Jul/10 19:42;jbellis;agreed;;;","06/Jul/10 21:46;nickmbailey;A side effect of this approach may be that you would need to call removeToken on a node that had seen the token previously.;;;","06/Jul/10 23:19;jbellis;since all tokens will be propagated to all nodes (even ones brought up after the dead node went down), that's not a problem;;;","20/Jul/10 22:37;nickmbailey;* 0001 - changes to make removeToken behave similarly to decomission
* 0002 - fixes to existing tests since the state for STATE_LEFT changed

I am still working on some good unit tests for these changes but these are the changes so far.

The new process for removeToken is basically the one outlined above. One change is that instead of a STATE_REMOVED state it seemed like tokens that are removed should just go into STATE_LEFT similar to nodes that are decommissioned.

One thing I'm not sure of is the timeout values for waiting for replications to stream and for waiting for replication notifications. Currently they are just set arbitrarily in that patch. Need to determine good values for these.
;;;","27/Jul/10 20:53;nickmbailey;Some fixes and tests added.

There is one thing that still needs to be fixed.
 * Currently the call to removeToken blocks either:
 ** until all nodes confirm that they have replicated the data for the dead node.
 ** or a timeout is reached
 * I'm not sure what the timeout for this should be. Additionally when nodes throughout the ring attempt to replicate data there should be a similar timeout before they give up on a source and retry.
 * Also clients may timeout before the timeout is even reached or all the data is replicated. I'm not sure how the user will be able to determine if the remove finished correctly or repair should be run.  
;;;","27/Jul/10 21:39;nickmbailey;Updated 0001 patch. It was missing a class before. Oops.;;;","13/Aug/10 14:36;gdusbabek;Nick, can you rebase?;;;","13/Aug/10 20:11;nickmbailey;Rebased.;;;","13/Aug/10 22:18;nickmbailey;Re-rebased.;;;","17/Aug/10 18:08;gdusbabek;RemoveTest needs some cleanup.
* ReplicationSink doesn't need callCount
* NotificationSink doesn't need hitList
* testRemoveToken and testStartRemoving abuse Gossiper.start().  Consider adding a method to Gossiper that initializes the epstate for a given node.  E.g.: initializeNodeUnsafe(InetAddr addr, int generation).
* (minor nit) I wish there were a way to assert that tmd.getLeavingNodes() actually has nodes in it.
* all the methods throw UnknownHostException, but don't need to (IOException covers it)
* testStartRemoving should assert preconditions before calling ss.onChange (it also makes the same assertion twice).

StorageService:
* (minor nit) a comment describing the distinction between the leaving and removing constants.
* SS.removeToken() shouldn't throw a RuntimeException, as the client won't know what to make of it.  Declare an exception in the interface and throw it in the impl.  I imagine this will be a fairly common case (e.g.: when a node is down).
* SS.setReplicatingNodes and clearReplicatingNodes can be inlined into removeToken. It saves a few lines and obviates a local var.
* SS.replicateTables should probably be merged into SS.restoreReplicaCount.

Was the intent that SS.replicateTables block until the files are transferred?  Because it doesn't.  AFAICT it blocks until the first ack comes back from each source node, which is a good indication that streaming has started, but not that it is finished.

I couldn't verify that the callbacks are ever called.  That happens on the READ_RESPONSE stage and afaict, none of the streaming code path ever puts a task there.  That's a painful interface to follow though, so I might be wrong.;;;","18/Aug/10 19:51;nickmbailey;Yeah I wasn't really understanding that streaming/messaging code at all.

The current StreamOut implementation has a callback concept however.  I think this should be moved into the StreamContext object and then both StreamOut and StreamIn can perform callbacks on actual stream completion.  ;;;","18/Aug/10 20:15;gdusbabek;The StreamOut callback works differently than the MessagingService callback.  Your approach sounds workable.  I don't think it matters where you push the callback to, so long as you make sure it gets executed after the stream is finished.;;;","23/Aug/10 21:12;nickmbailey;bq. (minor nit) I wish there were a way to assert that tmd.getLeavingNodes() actually has nodes in it.

This is what tmd.isLeaving() does

bq. testStartRemoving should assert preconditions before calling ss.onChange (it also makes the same assertion twice).

I'm not sure what preconditions you mean. I added an assertion to make sure there are no endpoints already leaving.

bq. SS.removeToken() shouldn't throw a RuntimeException,

Do you think the UnsupportedOperationExceptions should be removed as well? These existed previously.

I modified the callback support for streaming so that the code should wait for all streams to finish before confirming. I also added a reply to the ReplicationFinishedHandler so the IAsyncResult will be updated.  

Thoughts?

The timeout values for waiting on the latches still need to be updated.
;;;","25/Aug/10 14:51;gdusbabek;> Do you think the UnsupportedOperationExceptions should be removed as well? These existed previously.
My bad; I didn't notice that.  RTE was probably ok.

> I modified the callback support for streaming so that the code should wait for all streams to finish before confirming. I also added a reply to the ReplicationFinishedHandler so the IAsyncResult will be updated
First glance tells me this will work.  I'll run some tests after I'm done reviewing.

> The timeout values for waiting on the latches still need to be updated.
Is this coming in another patch?;;;","25/Aug/10 16:30;gdusbabek;I see this in RemoveTest:


 [junit] Testsuite: org.apache.cassandra.service.RemoveTest
    [junit] Tests run: 4, Failures: 0, Errors: 0, Time elapsed: 1.97 sec
    [junit] 
    [junit] ------------- Standard Error -----------------
    [junit] ERROR 11:27:58,277 Did not find matching ranges on /127.0.0.6
    [junit] ERROR 11:27:58,279 Did not find matching ranges on /127.0.0.6
    [junit] ERROR 11:27:58,280 Did not find matching ranges on /127.0.0.5
    [junit] ERROR 11:27:58,280 Did not find matching ranges on /127.0.0.4
    [junit] ERROR 11:27:58,280 Did not find matching ranges on /127.0.0.2
    [junit] ERROR 11:27:59,264 Did not find matching ranges on /127.0.0.6
    [junit] ERROR 11:27:59,272 Did not find matching ranges on /127.0.0.6
    [junit] ERROR 11:27:59,276 Did not find matching ranges on /127.0.0.5
    [junit] ERROR 11:27:59,279 Did not find matching ranges on /127.0.0.4
    [junit] ERROR 11:27:59,283 Did not find matching ranges on /127.0.0.2
    [junit] ------------- ---------------- ---------------

Is that ok?;;;","25/Aug/10 16:38;nickmbailey;Re: timeouts

Yes I'm just not sure how to approach determining the right values for these.  Depends mostly on the amount of data and network bandwidth.

Re: RemoveTest

Yeah. The message sink in the test immediately responds to the stream request saying there are no files to stream.  This makes the StreamInManager think the data didn't exist remotely.  Doing it that way seems much easier than trying to make the test actually stream something.;;;","25/Aug/10 16:42;gdusbabek;Some questions about the coordinator...  I see that removeToken() is quasi-blocking now, like unbootstrap() (it was fire-and-forget before).  What are the consequences of the coordinator node going down?  Assuming a dead coordinator, would it be Bad for another node to remove-token on the same token while the transfers initiated by the original failed coordinator were in process?  Or assuming the transfers were finished, would a remove-token on a new coordinator generally do little other than get the state to LEFT?

I think I'm of the opinion that removeToken should either block until the transfer is complete (or failed), or should return instantly, and that we need to make sure that subsequent removeToken calls do not upset existing transfers.  Having it return error after a timeout (which is possible in the case of LOTS of data) makes me think we should be doing differently.

Or is the only recourse to repair?;;;","25/Aug/10 17:06;nickmbailey;I believe the only consequences of calling removeToken on another node when the coordinator goes down would be that the entire operation would be repeated. So any data that was transferred before would be transferred again.  I think this is the right behavior since there is no way of knowing what was transferred before the coordinator went down.  

It might be useful to add a 'force' option though.  If the coordinator goes down and the token gets stuck in a REMOVING state you may want to force removal rather than redoing the entire operation. 

It should be possible to remove the timeout so that removeToken blocks until the transfer is completely finished.  The code for streaming in the remote data blocks until all streams are complete and the code for sending a confirmation to the coordinator will keep retrying until it is received or the coordinator dies.  

I think this would work if a check was added so that you can only call removeToken a second time if the coordinator is down.  It wouldn't handle two calls that occurred before the state made its way through gossip though.  

;;;","27/Aug/10 19:06;nickmbailey;After some more thinking I think there are two problems here.

 * The timeout for waiting on a stream to complete - An arbitrary timeout here is not the right way to do this. What we really need is the concept of stream progress. We should be able to verify that a stream is progressing or not and based on that retry it.  CASSANDRA-1438 kind of relates to this problem and could be modified to implement this.  

 * The timeout waiting for nodes to confirm replication - Ideally there could be no timeout here. The problem though is if a node that should be grabbing data goes down permanently, removeToken will wait forever.  I think it's reasonable to have some sort of timeout in this case. A log message/error can indicate which machines were being waited on for replication. An administrator should know if that machine went down or is still streaming. That will determine if repair needs to be run.  The alternative to this I guess would be periodically waking up and checking that the nodes we are waiting on are still alive.  That wouldn't be particularly hard to implement

I don't think returning immediately from the call is the right approach.  That is part of the reason why this ticket is created. In the case that replication fails somewhere, there is no feedback to the user.  At least timing out eventually provides information about which machines we think failed to replicate data.  

As far as multiple remove calls and the coordinator going down.  I think there should be a 'force' option in the case the coordinator goes down and you believe the rest of the nodes completed the operation.  To prevent multiple calls to removeToken there should just be a check to make sure the coordinator is dead before another call can be performed.

So besides those few changes above, I think we should either implement this part way with a time out for stream replication or postpone completion here until we add the concept of stream progress.
;;;","21/Sep/10 19:43;nickmbailey;Patches:
 * 0001
 ** Modifies the removeToken operation to follow a pattern of NORMAL->REMOVING->LEFT, rather than the current pattern of a coordinator node setting its own status to a special cased version of NORMAL.
 ** Fixes a small bug in StreamHeader serialization
 ** Adds the ability to either get the status of a remove operation taking place or force a remove operation to finish immediately
 * 0002
 ** Tests for removing tokens
 ** Move shared code for creating a ring to Util class


Removal Process:
 * Normal Case
 *# Coordinator sets status of failed node to REMOVING
 *# Coordinator blocks on confirmation from other nodes
 *# Any newly responsible nodes stream data
 *# Newly responsible nodes send confirmation once all data has streamed
 *# Coordinator updates status of failed node to LEFT
 *# Done
 * Failure Cases
 ** Coordinator failure
 *** If the coordinator fails the remove operation will need to be retried
 *** This can be done on any node in the cluster.  
 **  Newly responsible node failure
 *** If a newly responsible node fails but comes back up, it should see the REMOVING status in gossip and restart the operation
 *** If a newly responsible node fails permanently or a streaming operation fails and the node stays up, the coordinator will block forever while waiting for confirmation.  The best solution is to force the remove operation to complete and then run repair on the failed node.;;;","22/Sep/10 16:01;nickmbailey;Bah.  Gossip marks the node alive when it receives an updated application state. Reverting it to modifying the coordinator nodes state.;;;","22/Sep/10 20:29;nickmbailey;Ok this should be ready for review now.  The process is:

# Coordinator node modifies its own status to NORMAL - REMOVING to indicate which node is being removed
# Coordinator blocks on removal confirmaton from other nodes
# Newly responsible nodes see this status and begin fetching new data
# Newly responsible nodes notify coordinator they have replicated all data
# Coordinator node updates its own status to NORMAL - REMOVED to indicate the removal is complete
# This causes all nodes to remove the node from gossip/tokenmetadata. 
# Done

Tested this with a 3 node cluster in the cloud, as well as testing the new getStatus and forceRemoval operations.;;;","27/Sep/10 07:58;gdusbabek;This looks good.

1.  There were a few unused local variables in SS.retoreReplicationCount().  Was this just leftovers from a rebase?
2.  SS.handleStateRemoving removes a null check that previously existed for epThatLeft (renamed removeEndpoint).  Was the original null-check pointless or was something missed in the change?
3.  You made a change to StreamHeader that made me think you were running into cases where SH.pendingFiles == null.  Is that true?  Tracing the codepaths makes me think this is not possible.

Don't bother with the cleanup in 1.  I'm more curious about 2 and 3.;;;","27/Sep/10 15:54;nickmbailey;1 and 2 are just errors on my part. I changed 3 because I was under the impression that a stream request to an endpoint that doesn't contain any of the ranges requested would create a header with null for pendingFiles.  I at first wrote one of the tests to behave like that, and got the NPE.  Looks like it changed or was never like that.

Fixed all that in a quick patch and attached it.;;;","28/Sep/10 05:56;gdusbabek;committed.;;;","28/Sep/10 13:31;hudson;Integrated in Cassandra #549 (See [https://hudson.apache.org/hudson/job/Cassandra/549/])
    changes update for CASSANDRA-1216
modify removetoken so that the coordinator relies on replicating nodes for updates. patch by Nick Bailey, reviewed by Gary Dusbabek. CASSANDRA-1216
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
system_drop_keyspace can cause a node to be unstartable,CASSANDRA-1203,12467270,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,mbryant,mbryant,17/Jun/10 21:28,16/Apr/19 09:33,14/Jul/23 05:51,01/Jul/10 16:52,0.7 beta 1,,,,0,,,,,,"calling thriftClient_.system_drop_keyspace(keyspaceName) on a newly created keyspace, then stopping the node renders the node unstartable. Results in the following stacktrace:

10/06/17 14:23:16 ERROR thrift.CassandraDaemon: Fatal exception during initialization
java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readUTF(DataInputStream.java:592)
	at java.io.DataInputStream.readUTF(DataInputStream.java:547)
	at org.apache.cassandra.config.KSMetaData.deserialize(KSMetaData.java:92)
	at org.apache.cassandra.db.DefsTable.loadFromStorage(DefsTable.java:75)
	at org.apache.cassandra.config.DatabaseDescriptor.loadSchemas(DatabaseDescriptor.java:422)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:103)
	at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:90)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:221)

my repro:

start new node with empty data directory
create a new keyspace
drop the keyspace
attempt to restart the node, notice that it fails to start.
",Mac OS X 10.6.3 (10D573) / Darwin 10.3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jun/10 22:00;gdusbabek;0001-handle-schema-loading-when-a-node-has-had-all-keyspa.patch;https://issues.apache.org/jira/secure/attachment/12447752/0001-handle-schema-loading-when-a-node-has-had-all-keyspa.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20033,,,Fri Jul 02 12:47:06 UTC 2010,,,,,,,,,,"0|i0g3mn:",92018,,,,,Normal,,,,,,,,,,,,,,,,,"01/Jul/10 16:04;jbellis;+1

(s/No tables where/No schema definitions were/);;;","02/Jul/10 12:47;hudson;Integrated in Cassandra #483 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/483/])
    handle schema loading when a node has had all keyspaces dropped. Patch by gdusbabek, reviewed by jbellis. CASSANDRA-1203.
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"In a cluster, get_range_slices() does not return all the keys it should",CASSANDRA-1198,12467113,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,cgist,cgist,16/Jun/10 18:26,16/Apr/19 09:33,14/Jul/23 05:51,25/Jun/10 22:12,0.6.3,,,,0,,,,,,"Row iteration with get_range_slices() does not return all keys. This behaviour only occurs with more than one node and depends on how the nodes are located on the ring.

To reproduce, insert some records into a cluster with more than one node. A subsequent row iteration will return fewer records than were inserted. This has been observed when 1) inserting into a single node, bootstrapping a second node then using get_range_slices() and 2) inserting into a cluster of several nodes then using get_range_slices().

This appears to be similar to https://issues.apache.org/jira/browse/CASSANDRA-781","Linux 2.6.18-128.1.10.el5.xs5.5.0.51xen
Java build 1.6.0_17-b04
Cassandra 0.7 2010-06-15 including patch for https://issues.apache.org/jira/browse/CASSANDRA-1130",bryantower,johanoskarsson,joosto,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jun/10 05:51;jbellis;1198.txt;https://issues.apache.org/jira/secure/attachment/12447546/1198.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20031,,,Fri Jun 25 22:12:51 UTC 2010,,,,,,,,,,"0|i0g3lj:",92013,,,,,Normal,,,,,,,,,,,,,,,,,"16/Jun/10 18:39;jbellis;Christopher reported on IRC that he cannot reproduce in 0.6, so this does appear to be a 0.7-only bug.;;;","20/Jun/10 03:58;cgist;It looks like this issue is a regression of https://issues.apache.org/jira/browse/CASSANDRA-1042 so it should in fact affect 0.6.3, though I haven't confirmed.

When doing a row iteration starting from token 0, since the ranges are no longer sorted by ring order after #1042 but by wrap order, the iteration could start with the range to the left of 0. This results in either iterating through fewer than all keys, or iterating through duplicate keys. I have seen the following different behaviour, varying based on the ring tokens, key count and distribution, and range count:
1) too few keys because range slice command had lower count than keys in (z,0] range and subsequent range slice was restricted to only the (z,0] range
2) duplicate keys because range slice command had higher count than keys in (z,0] range and keys in range (z,0] were repeated
3) too few keys because ranges were handled out of token order, eg. (z,0] before (y,z] so no keys in (y,z] were returned

Also it would appear that token ranges passed into get_range_slices() are in fact start inclusive, contrary to the wiki. Is this correct?;;;","20/Jun/10 05:51;jbellis;Excellent work.  Yes, the sort that was removed was in fact necessary (which is stated in the docstring to getRestrictedRanges, but then the sort was done elsewhere so the confusion was understandable).

This patch adds back the sort (this time in gRR) and moves the endpoints-handling to getRangeSlice (where doing just-in-time liveness checking has the added benefit of improving availability for large queries) to make gRR less muddled.

(Token-based range queries are turned into Bounds objects, which are start-inclusive, as opposed to Range objects, which are not.);;;","20/Jun/10 11:52;jeromatron;Oh crumb!

We had fixed the problem manifest in 1045 but overlooked that part of it. Nice catch.

I'll go ahead and try that patch out on the word count example to make sure it works tomorrow.

Thanks Christopher and Jonathan.;;;","21/Jun/10 15:57;jeromatron;Hmmm, I tried latest vanilla 0.6 branch with this patch and the duplicates have come back in the word count example. ;;;","25/Jun/10 22:09;urandom;+1;;;","25/Jun/10 22:12;jbellis;committed.  (CASSANDRA-1042 is re-opened for fixing the original bug.);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove automatic repair sessions,CASSANDRA-1190,12466935,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,stuhood,stuhood,14/Jun/10 21:46,16/Apr/19 09:33,14/Jul/23 05:51,06/Sep/10 18:42,0.7 beta 2,,,,0,,,,,,"Currently both manual and automatic repair sessions use the same timeout value: TREE_STORE_TIMEOUT. This has the very negative effect of setting a maximum time that compaction can take before a manual repair will fail.

For automatic/natural repairs (triggered by two nodes autonomously finishing major compactions around the same time), you want a relatively low TREE_STORE_TIMEOUT value, because trees generated a long time apart will cause a lot of unnecessary repair. The current value is 10 minutes, to optimize for this case.

On the other hand, for manual repairs, TREE_STORE_TIMEOUT needs to be significantly higher. For instance, if a manual repair is triggered for a source node A storing 2 TB of data, and a destination node B with an empty store, then node B needs to wait long enough for node A to finish compacting 2 TB of data, which might take > 12 hours. If a node B times out the local tree before node A sends its tree, then the repair will not occur.",,schubertzhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jun/10 00:00;stuhood;0001-Remove-natural-repair-throttling-in-preparation-for-.patch;https://issues.apache.org/jira/secure/attachment/12448001/0001-Remove-natural-repair-throttling-in-preparation-for-.patch","25/Jun/10 00:00;stuhood;0002-Rename-readonly-compaction-to-validation-and-make-it.patch;https://issues.apache.org/jira/secure/attachment/12448002/0002-Rename-readonly-compaction-to-validation-and-make-it.patch","25/Jun/10 00:00;stuhood;0003-Add-session-info-to-RPCs-to-handle-concurrent-repair.patch;https://issues.apache.org/jira/secure/attachment/12448003/0003-Add-session-info-to-RPCs-to-handle-concurrent-repair.patch","25/Jun/10 19:37;stuhood;for-0.6-0001-Remove-natural-repair-throttling-in-preparation-for-.patch;https://issues.apache.org/jira/secure/attachment/12448087/for-0.6-0001-Remove-natural-repair-throttling-in-preparation-for-.patch","25/Jun/10 19:37;stuhood;for-0.6-0002-Rename-readonly-compaction-to-validation-and-make-it.patch;https://issues.apache.org/jira/secure/attachment/12448088/for-0.6-0002-Rename-readonly-compaction-to-validation-and-make-it.patch",,,,,,,,,,5.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20029,,,Sun Aug 29 19:01:18 UTC 2010,,,,,,,,,,"0|i0g3jr:",92005,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"14/Jun/10 21:52;stuhood;Differentiating manual repairs from automatic repairs will require a network protocol change, so for 0.6, I think we should just bump TREE_STORE_TIMEOUT/NATURAL_REPAIR_FREQUENCY to values like 12/24 hours.

For trunk/0.7, it would make sense to remove the timeout entirely for manual repairs, and to make the timeout for automatic repairs a calculated value based on the size of the column family.;;;","14/Jun/10 22:07;jbellis;I think I'd prefer simply removing automatic repairs.  The probability of it happening by chance are low enough that having it happen once in a while is more confusing than useful.;;;","15/Jun/10 20:02;stuhood;Removing automatic repairs is inline with some other improvements I have in mind, so I'm fine with that.;;;","25/Jun/10 00:00;stuhood;0001 and 0002 remove automatic repairs, and should be safe to apply to 0.6.

0003 adds a session id to tree requests/responses, and should only be applied to 0.7.

Should be ready for review now!;;;","25/Jun/10 14:43;jbellis;committed 0001 to 0.6, but 0002 fails to apply;;;","25/Jun/10 18:38;jbellis;reverted 0001, bumping to 0.6.4;;;","25/Jun/10 19:37;stuhood;Sorry for the delay: 'for-0.6' is rebased to apply to 0.6, and the original set can be applied to trunk.;;;","25/Jun/10 20:35;jbellis;committed;;;","26/Jun/10 13:07;hudson;Integrated in Cassandra #477 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/477/])
    allow multiple repair sessions per node.  patch by Stu Hood; reviewed by jbellis for CASSANDRA-1190
;;;","28/Aug/10 06:01;stuhood;> Removing automatic repairs is inline with some other improvements I have in mind, so I'm fine with that.
The other improvements I had in mind fell through, and I haven't seen any good alternatives to major compactions for repairs. I'm wondering if disabling this was the wisest course of action.;;;","29/Aug/10 19:01;jbellis;Since the automatic repairs couldn't be relied upon, i.e., if you wanted to guarantee repair, you needed to schedule it anyway, I don't see what has really been lost.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
multiget_slice calls do not close files resulting in file descriptor leak,CASSANDRA-1188,12466908,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,mdennis,wr0ngway,wr0ngway,14/Jun/10 15:12,16/Apr/19 09:33,14/Jul/23 05:51,14/Jun/10 17:58,0.7 beta 1,,,,0,,,,,,"Insert  1000 rows into a super column family. Read them back in a loop using multiget_slice. Note leaked file descriptors with lsof:
lsof -p `ps ax | grep [C]assandraDaemon | awk '{print $1}'` | awk '{print $9}' | sort | uniq -c | sort -n | tail -n 5

Looks like SSTableNamesIterator is never closing the files it creates via the sstable ...?

This is similar to CASSANDRA-1178 except for use of multiget_slice instead of get_slice

",Ubuntu 10.04,danielkluesing_bk,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/10 17:17;mdennis;0001-trunk-1188.patch;https://issues.apache.org/jira/secure/attachment/12447042/0001-trunk-1188.patch",,,,,,,,,,,,,,1.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20028,,,Tue Jun 15 12:51:22 UTC 2010,,,,,,,,,,"0|i0g3jb:",92003,,,,,Critical,,,,,,,,,,,,,,,,,"14/Jun/10 17:43;wr0ngway;I ran my tests against this patch and they pass, looks like this cleared up the leak.  Thanks! 

BTW, oddly enough, my tests never fail (i.e. lsof never balloons up) on OS X even before the fix for CASSANDRA-1178, any ideas why that might be?  I'm guessing implementation details of GC or underlying OS are to blame, but don't know enough to say for sure.  Not important, just curious.
;;;","14/Jun/10 17:58;jbellis;committed, with formatting cleanup.

yes, the jdk declares finalizers on file streams to close them if the GC runs in time; as you note, it's implementation-dependent how often that actually happens.;;;","14/Jun/10 18:44;mdennis;not all GC implementations close file descriptors when the objects are collected.  Apparently the one you're using on OSX does.  Curious though, you didn't see *any* ballooning?  If OSX was releasing the descriptors when the objects were collected, I would expect to see a few hundred open files while reading in a loop on OSX and only a handful after the patch.

random thought: It may also be a difference in memmapped IO versus not - perhaps OSX doesn't use it (or isn't configured to)?;;;","14/Jun/10 19:49;wr0ngway;I wasn't really watching it while it was running, just checking the count of open files after.

No idea about memmapped IO in OS X, I didn't explicitly set anything up w.r.t. it anyway...

;;;","15/Jun/10 12:51;hudson;Integrated in Cassandra #466 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/466/])
    close file in SSTableNamesIterator when opened locally.  patch by mdennis; reviewed by jbellis for CASSANDRA-1188
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
read_repair_chance is missing from CfDef,CASSANDRA-1180,12466698,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,arya,arya,10/Jun/10 23:02,16/Apr/19 09:33,14/Jul/23 05:51,15/Jun/10 14:51,0.7 beta 1,,,,0,,,,,,CfDef is missing read_repair_chance if that is going to remain a configuration option in 0.7.,,arya,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/10 14:22;gdusbabek;0001-add-read_repair_chance-to-CfDef.patch;https://issues.apache.org/jira/secure/attachment/12447133/0001-add-read_repair_chance-to-CfDef.patch","15/Jun/10 14:22;gdusbabek;0002-avoid-constructor-proliferation-in-CFM.patch;https://issues.apache.org/jira/secure/attachment/12447134/0002-avoid-constructor-proliferation-in-CFM.patch",,,,,,,,,,,,,2.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20024,,,Tue Jun 15 14:51:59 UTC 2010,,,,,,,,,,"0|i0g3hj:",91995,,,,,Low,,,,,,,,,,,,,,,,,"11/Jun/10 19:39;gdusbabek;Looks like this was taken care of on 2 April as part of CASSANDRA-930;;;","14/Jun/10 20:56;arya;Hi Gary,

The patch in the bug you've mentioned above contains only changes to Java StorageProxy, CFMetaData, and DatabaseDescriptor. However it does not include changes to Interface/cassandra.thrift as of today's trunc. It reads:

/* describes a column family. */
struct CfDef {
    1: required string table,
    2: required string name,
    3: optional string column_type=""Standard"",
    4: optional string clock_type=""Timestamp"",
    5: optional string comparator_type=""BytesType"",
    6: optional string subcomparator_type="""",
    7: optional string reconciler="""",
    8: optional string comment="""",
    9: optional double row_cache_size=0,
    10: optional bool preload_row_cache=0,
    11: optional double key_cache_size=200000
}

Missing read_repair_chance which makes dynamic creation of CFs using the Thrift API to miss that configuration value. My apologies if my original description was not so clear.;;;","15/Jun/10 13:27;jbellis;don't we need some logic to connect the CfDef field with CFMetaData?;;;","15/Jun/10 14:24;gdusbabek;jbellis: oops.  fixed.  The second patch cleans up the constructors in CFMetadata.;;;","15/Jun/10 14:46;jbellis;+1 latest;;;","15/Jun/10 14:51;gdusbabek;Fixed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
split commitlog into header + mutations files,CASSANDRA-1179,12466697,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mdennis,jbellis,jbellis,10/Jun/10 23:02,16/Apr/19 09:33,14/Jul/23 05:51,19/Jun/10 16:09,0.7 beta 1,,,,0,,,,,,"As mentioned in CASSANDRA-1119, it seems possible that a commitlog header could be corrupted by a power loss during update of the header, post-flush.  We could try to make it more robust (by writing the size of the commitlogheader first, and skipping to the end if we encounter corruption) but it seems to me that the most foolproof method would be to split the log into two files: the header, which we'll overwrite, and the data, which is truly append only.  If If the header is corrupt on reply, we just reply the data from the beginning; the header allows us to avoid replaying data redundantly, but it's strictly an optimization and not required for correctness.",,hammer,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/10 21:15;jbellis;1179-v2.txt;https://issues.apache.org/jira/secure/attachment/12447172/1179-v2.txt","15/Jun/10 22:55;mdennis;trunk-1179-v3.txt;https://issues.apache.org/jira/secure/attachment/12447181/trunk-1179-v3.txt","16/Jun/10 19:19;mdennis;trunk-1179-v4.txt;https://issues.apache.org/jira/secure/attachment/12447266/trunk-1179-v4.txt","15/Jun/10 19:17;mdennis;trunk-1179.txt;https://issues.apache.org/jira/secure/attachment/12447163/trunk-1179.txt",,,,,,,,,,,4.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20023,,,Sun Jun 20 12:47:27 UTC 2010,,,,,,,,,,"0|i0g3hb:",91994,,,,,Normal,,,,,,,,,,,,,,,,,"15/Jun/10 21:06;jbellis;made some minor changes, primarily using BRAF in writeCommitLogHeader (you don't get buffering w/ raw FileOutputStream, and BRAF is simpler than doing the FOS/BufferedOutputStream/FileChannel dance).  also added RecoveryManager3Test to test the .header missing entirely.

todo: still needs to delete the .headers after a successful replay as well as the .log.

more severe: after running ""bin/cassandra -f"" and C-c-ing several times in a row, I get

ERROR 16:02:14,537 Exception encountered during startup.
java.lang.ArrayIndexOutOfBoundsException
	at java.lang.System.arraycopy(Native Method)
	at org.apache.cassandra.io.util.BufferedRandomAccessFile.read(BufferedRandomAccessFile.java:332)
	at java.io.RandomAccessFile.readFully(RandomAccessFile.java:381)
	at java.io.RandomAccessFile.readFully(RandomAccessFile.java:361)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:213)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:172)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:120)
	at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:90)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:221)

(This looks like BRAF is throwing AIOOBE when it should really be EOFException)
;;;","15/Jun/10 21:15;jbellis;(fixed trying to be to clever w/ metadata fsync -- we actually do need to include that the first time we write the file);;;","15/Jun/10 22:55;mdennis;trunk-1179-v3.txt deletes header files after successful replay, handle short entries and garbage size writes;;;","16/Jun/10 00:04;mdennis;need to add a test for the corrupted / partially flushed segment;;;","16/Jun/10 01:54;jbellis;I'd rather fix BRAF to generate correct EOFExceptions in case other code runs into this.  (And by removing the EOFException check, we introduce a new bug that if the size int is incomplete, we die again.);;;","16/Jun/10 02:01;jbellis;(actually BRAF.read should be returning -1, so that RAF.readFully throws EOFException);;;","16/Jun/10 19:19;mdennis;{quote}
made some minor changes, primarily using BRAF in writeCommitLogHeader (you don't get buffering w/ raw FileOutputStream, and BRAF is simpler than doing the FOS/BufferedOutputStream/FileChannel dance).
{quote}

FOS doesn't sync on flush/close and as headers are ""optional"" now there is no reason to waste the IO.  Just to be sure I was remembering this correctly, I just now tested it.  It provides 80+% improvement over BRAF, even more on a heavily loaded system.  This was clearly a failure on my part to document it at as such.  The header is so small (56 bytes I think) the OS will cache it just fine and not using buffered output will avoid both the memcopies and GC from the buffers.

{quote}
todo: still needs to delete the .headers after a successful replay as well as the .log.
{quote}

thank you, I hadn't realized there were two places the logs were getting removed.  Done.

{quote}
I'd rather fix BRAF to generate correct EOFExceptions in case other code runs into this. (And by removing the EOFException check, we introduce a new bug that if the size int is incomplete, we die again.)

(actually BRAF.read should be returning -1, so that RAF.readFully throws EOFException) 
{quote}

It was not at EOF, the buffer the data was supposed to be written into was zero length.  There was data in the file, but no where to write it in the buffer (because the size read was 0, new byte[size] resulted in a zero length array was was then supposed to be filled by BRAF.readFully).

I've added tests to catch this problem (as well as other related ones) and also changed BRAF to throw a more reasonable exception (but not EOF).  I believe BRAF.readFully will already throw EOF if it is at the end of the file.

The size of the log entry is now CRCed on it's own.  Whlie testing with random garbage at the end of a commit log, I had written a really large int to the size field which resulted in recover() trying to allocate a massive byte[] and getting OOM.

{quote}
by removing the EOFException check, we introduce a new bug that if the size int is incomplete, we die again.
{quote}

good catch.  I have no idea WTF I was thinking, there was even a comment that warned about it that got removed when the try/catch was removed.  I was probably trying to test something and removed it so it'd spew but forgot to put it back.
;;;","19/Jun/10 16:09;jbellis;committed, minus the BRAF change;;;","20/Jun/10 12:47;hudson;Integrated in Cassandra #471 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/471/])
    split commitlog header into separate file and add size checksum to mutations.  patch by mdennis and jbellis for CASSANDRA-1179
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"get_slice calls do not close files when finished resulting in ""too many open files"" exceptions and rendering C unusable",CASSANDRA-1178,12466596,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mdennis,mdennis,mdennis,09/Jun/10 19:47,16/Apr/19 09:33,14/Jul/23 05:51,11/Jun/10 00:19,0.7 beta 1,,,,0,,,,,,"insert ~100K rows.  Read them back in a loop.  Notice ""too many open files"" exceptions in log.  SSTableSliceIterator is never closing the files.

",,arya,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jun/10 19:49;mdennis;0001-trunk-1178.patch;https://issues.apache.org/jira/secure/attachment/12446719/0001-trunk-1178.patch","10/Jun/10 16:34;mdennis;0002-trunk-1178.patch;https://issues.apache.org/jira/secure/attachment/12446771/0002-trunk-1178.patch",,,,,,,,,,,,,2.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20022,,,Fri Jun 11 12:45:40 UTC 2010,,,,,,,,,,"0|i0g3h3:",91993,,,,,Normal,,,,,,,,,,,,,,,,,"09/Jun/10 23:11;mortazavi;Out of curiosity . . . What is the point, in this patch, in switching import statements around . . . Is there a policy to re-order them? . . . To the extent I can tell, the order of import statements is consistent with what one sees in the other files?

The rest of the fix seems OK to me as long as the ""close"" method in the IColumnIterator interface to SSTableSliceIterator  is used properly to clean up resources . . . (although -- on a different plane -- objects that know, themselves, that they have nothing more to do are more friendly objects to use and harder to design) . . . 




;;;","09/Jun/10 23:59;mdennis;intellij often automatically reorders imports and removes unused ones (they call it ""optimizing imports"").  I just let it do it's thing in this regard (to be honest I've just gotten in the habit of ignoring the import section).

At least for get_slice, close is properly called (as evident by the patch fixing the problem).   It may be the case that for other calls close is not correctly called, I didn't specifically look for such cases but 1) I haven't noticed a problem making other calls and 2) I didn't notice anything in the code while debugging this issue.

In general I agree that self contained objects are better but that doesn't necessarily fit in this case as the open file is really a system resource.  Given the way Java does GC, such resources should be explicitly released.

I discussed this particular case with jbellis and the thought for the original patch that introduced this bug was that some callers would want to reuse an existing file.  In such a case, they would be responsible for closing the file but that meant that SSTableSliceIterator shouldn't close it out from under them.;;;","10/Jun/10 03:52;mortazavi;Sounds reasonable . . . 

It seems to me that he idea is that 

(1) If you pass a non-null file object reference to the constructor, you are the best judge of when to close it. 

(2) If you pass a null, instead, you will have to ask SSTableSliceIterator to clean up after you're done by calling ""close"" on it. 

This is then the semantics of this class when it comes to the file variable. 

I think it may be useful to include this contractual/semantic fact in the javadoc for this class. 

(Side note: It would probably be best not to allow IDE's to change the order of imports from the one that's common everywhere else unless there is a policy by this project to make such reordering. It is better to keep things consistent.)

;;;","10/Jun/10 16:34;mdennis;0002-trunk-1178.patch has suggested JavaDoc changes;;;","11/Jun/10 00:19;jbellis;committed;;;","11/Jun/10 12:45;hudson;Integrated in Cassandra #462 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/462/])
    fix FD leak.  patch by mdennis; reviewed by jbellis for CASSANDRA-1178
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Debian packaging should auto-detect the JVM, not require OpenJDK",CASSANDRA-1174,12466404,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,codahale,codahale,codahale,07/Jun/10 23:22,16/Apr/19 09:33,14/Jul/23 05:51,11/Jun/10 00:47,0.6.3,,,,0,debian,,,,,"The current init.d script for Debian-packaged Cassandra has the OpenJDK's JAVA_HOME hard-coded in, making it impossible to use sun-java6 without modifying the file. Ideally it should use the same sort of auto-detection logic used by other Debian-packaged Java projects to figure out which JVM it should use.

(I have a patch for this that I'll upload shortly.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jun/10 01:14;codahale;0001-Use-tomcat6-s-JVM-detection-code-in-the-Debian-init..patch;https://issues.apache.org/jira/secure/attachment/12446555/0001-Use-tomcat6-s-JVM-detection-code-in-the-Debian-init..patch","11/Jun/10 00:30;codahale;02-0001-Use-tomcat6-s-JVM-detection-code-in-the-Debian-init.patch;https://issues.apache.org/jira/secure/attachment/12446820/02-0001-Use-tomcat6-s-JVM-detection-code-in-the-Debian-init.patch",,,,,,,,,,,,,2.0,codahale,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20018,,,Fri Jun 11 12:45:40 UTC 2010,,,,,,,,,,"0|i0g3g7:",91989,,,,,Low,,,,,,,,,,,,,,,,,"08/Jun/10 01:14;codahale;Adds the JVM detection logic from Debian's tomcat6 package to the Debian init.d script.;;;","11/Jun/10 00:20;jbellis;We probably don't want to include jdk 1.5 directories on the search path, since we require 1.6;;;","11/Jun/10 00:30;codahale;New patch, which chooses between the Sun JRE and the OpenJDK JRE, preferring Sun.;;;","11/Jun/10 00:47;jbellis;committed

(tested and it works for me against openjdk still, but i'm a little puzzled as to why since it chops off the jre/ part of the old path);;;","11/Jun/10 12:45;hudson;Integrated in Cassandra #462 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/462/])
    allow using sun jdk w/ debian init script.  patch by Coda Hale; reviewed by jbellis for CASSANDRA-1174
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Debian packaging refers to now nonexistent DISCLAIMER.txt,CASSANDRA-1173,12466401,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,yosh,yosh,yosh,07/Jun/10 23:08,16/Apr/19 09:33,14/Jul/23 05:51,18/Jun/10 18:52,0.6.3,,,,0,,,,,,Debian packaging refers to now nonexistent DISCLAIMER.txt. Trivial patch attached.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jun/10 23:08;yosh;no-more-disclaimer.patch;https://issues.apache.org/jira/secure/attachment/12446542/no-more-disclaimer.patch",,,,,,,,,,,,,,1.0,yosh,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20017,,,Fri Jun 18 18:52:32 UTC 2010,,,,,,,,,,"0|i0g3fz:",91988,,,,,Low,,,,,,,,,,,,,,,,,"07/Jun/10 23:08;yosh;Trivial patch;;;","18/Jun/10 18:52;urandom;committed; thanks Manish!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
update gc options for debian package,CASSANDRA-1172,12466399,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,jbellis,jbellis,07/Jun/10 23:03,16/Apr/19 09:33,14/Jul/23 05:51,21/Jun/10 14:44,0.6.3,,,,0,,,,,,"/etc/default/cassandra needs the new jvm options from cassandra.in.sh

also, it looks like heap size is also set-able in the init.d script, but it was ignored in favor of the values from /etc/default/cassandra, it would be less confusing to leave those out of the init.d script",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jun/10 19:24;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1172-update-gc-options-for-debian-package.txt;https://issues.apache.org/jira/secure/attachment/12447487/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-1172-update-gc-options-for-debian-package.txt",,,,,,,,,,,,,,1.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20016,,,Mon Jun 21 14:44:33 UTC 2010,,,,,,,,,,"0|i0g3fr:",91987,,,,,Low,,,,,,,,,,,,,,,,,"18/Jun/10 19:29;urandom;bq. /etc/default/cassandra needs the new jvm options from cassandra.in.sh

See attached patch.

bq. also, it looks like heap size is also set-able in the init.d script, but it was ignored in favor of the values from /etc/default/cassandra, it would be less confusing to leave those out of the init.d script

This is standard practice on Debian systems. The defaults file (/etc/default/cassandra) is optional, as are the variables set within. It's probably easier to think of it as a way of overriding the init script, rather than as a canonical source of configuration.;;;","19/Jun/10 03:57;jbellis;+1;;;","21/Jun/10 14:44;urandom;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AES makes Streaming unhappy,CASSANDRA-1169,12466310,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,gdusbabek,jbellis,jbellis,07/Jun/10 03:41,16/Apr/19 09:33,14/Jul/23 05:51,14/Jun/10 18:40,0.6.3,0.7 beta 1,,,0,,,,,,"Streaming service assumes there will only be one stream from S to T at a time for any nodes S and T.  For the original purpose of node movement, this was a reasonable assumption (any node T can only perform one move at a time) but AES throws off streaming tasks much more frequently than that given the right conditions, which will de-sync the fragile file ordering that Streaming assumes (that T knows which files S is going to send, in what order).  Eventually T is expecting file F1 but S sends a smaller file F2, leading to an infinite loop on T while it waits for F1 to finish, and T waits for S to acknowledge F2, which it never will.

For 0.6 maybe the best solution is for AES to manually wait for one of its streaming tasks to finish, before it allows itself to create another.  For 0.7 it would be nice to make Streaming more robust.  The whole 4-stage-ack process seems very fragile, and poking around in parent objects via inetaddress keys makes reasoning about small pieces impossible b/c of encapsulation violations.",,appodictic,gdusbabek,johanoskarsson,schubertzhang,stuhood,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/10 17:55;gdusbabek;1169-2.txt;https://issues.apache.org/jira/secure/attachment/12447046/1169-2.txt","11/Jun/10 14:33;gdusbabek;1169.txt;https://issues.apache.org/jira/secure/attachment/12446866/1169.txt","09/Jun/10 14:32;appodictic;aes.txt;https://issues.apache.org/jira/secure/attachment/12446693/aes.txt",,,,,,,,,,,,3.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20014,,,Mon Jun 14 18:40:07 UTC 2010,,,,,,,,,,"0|i0g3f3:",91984,,,,,Critical,,,,,,,,,,,,,,,,,"07/Jun/10 12:04;gdusbabek;Is this the root cause of the problems being experienced at Digg and by Lu Ming on the ML?;;;","07/Jun/10 14:17;jbellis;I think so.  That's what prompted this ticket.;;;","07/Jun/10 16:53;lenn0x;As mentioned on IRC, we actually saw T sending to S, while anticompaction was running on S using the exact filename as T. We should probably break streaming out to support `stream/<source>/<sstables>`. ;;;","09/Jun/10 14:19;appodictic;I have this problem as well. I have a 5 node cluster. A simple repair on keyspace1 (which has nothing but some test data) streams never complete.;;;","09/Jun/10 14:32;appodictic;I have upgraded to 6.2 because 6.1 streaming would randomly timeout on me. Now, I am still having issues with move, join, repair. Since I was having so many streaming problems I tuned this up in some logs. Over the past few weeks I have spent a lot of time managing my clusters, I try to do these type of operations in the AM so they are less performance impacting, but I have a very low sucess rate with any move,join,repair. I have a building list of nodes to join and ring management that I keep having to put off due to failures. So anything to make these processes less brittle would be a big big deal. Attached is ooutput.
 ;;;","11/Jun/10 14:33;gdusbabek;Ensures that AES streaming happens on the streaming stage and waits for each transfer to complete.;;;","11/Jun/10 15:56;jbellis;you don't need to do that exception dance with futures, it will throw an exception that happened in the background as a wrapped ExecutionException on get (and all our executors are DebuggableTPE, which makes sure the exception gets logged even if get() is never called)

LGTM otherwise;;;","12/Jun/10 08:21;albert_e;StreamOutManager.waitForStreamCompletion() can't block the AES streaming thread if StreamOutManager.condition is signaled once and StreamOutManager has not been removed from streamManagers map. 

Make StreamOutManager.addFilesToStream() synchronized and block the thread if StreamOutManager.files.size() > 0 may be more efficient.;;;","12/Jun/10 08:29;xluke;I have applied your patch to cassandra.
According to my log on StreamOutManager.addFilesToStream() , the function is still called when StreamOutManager.files.size() > 0 
I think the problem is maybe not fixed yet.;;;","12/Jun/10 10:57;xluke;After I applied the above patch,
StreamOutManager.waitForStreamCompletion()  return immediately and StreamOut.transferSSTables do Not  wait for its streaming tasks to finish

27938- INFO [STREAM-STAGE:1] 2010-06-12 17:08:48,810 StreamOut.java (line 132) Sending a stream initiate message to /121.1.1.1...
27939: INFO [STREAM-STAGE:1] 2010-06-12 17:08:48,810 StreamOut.java (line 137) Waiting for transfer to /121.1.1.1 to complete
27940- INFO [STREAM-STAGE:1] 2010-06-12 17:08:48,810 StreamOut.java (line 141) Done with transfer to /121.1.1.1
27941- INFO [AE-SERVICE-STAGE:1] 2010-06-12 17:08:48,811 AntiEntropyService.java (line 641) Finished streaming repair to /121.1.1.1 for (GroupDataStore,Group)
..................................
27982- INFO [STREAM-STAGE:1] 2010-06-12 17:19:22,066 StreamOut.java (line 132) Sending a stream initiate message to /222.222.2.2 ...
27983: INFO [STREAM-STAGE:1] 2010-06-12 17:19:22,066 StreamOut.java (line 137) Waiting for transfer to /222.222.2.2 to complete
27984- INFO [STREAM-STAGE:1] 2010-06-12 17:19:22,066 StreamOut.java (line 141) Done with transfer to /222.222.2.2
27985- INFO [AE-SERVICE-STAGE:1] 2010-06-12 17:19:22,067 AntiEntropyService.java (line 641) Finished streaming repair to /222.222.2.2 for (GroupChat,Topic)
..................................;;;","14/Jun/10 17:55;gdusbabek;Instruct AES to remove active StreamManager when it's finished and reset the condition in SOM any time files are added so that it is a bit more reentrant.;;;","14/Jun/10 17:56;gdusbabek;albert_e: patch 2 adjusts addFilesToStream to reset the condition so that future waiters do wait.
Lu Ming: I believe you were experiencing that problem.;;;","14/Jun/10 18:04;jbellis;won't removing the active SOM bork things, if another stream to that target is going on?;;;","14/Jun/10 18:20;gdusbabek;SOM.remove() checks for that.  (I'm not saying the code is perfect--it's not--but I don't think removing the SOM is going to mess things up.);;;","14/Jun/10 18:20;stuhood;Rather than an 'endpoint->StreamManager' map, we really should have a 'session_id->StreamManager' map.;;;","14/Jun/10 18:26;gdusbabek;Stu: Right.  But I don't think we want to introduce it in 0.6.  I'm hoping just to get things to the point of working and then fix it all in 0.7. ;;;","14/Jun/10 18:34;jbellis;+1 on this patch and do-what-we-can-in-0.6-and-eviscerate-this-crap-in-0.7 in general;;;","14/Jun/10 18:40;gdusbabek;both patches are committed and merged.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
system_drop_column_family() and system_rename_column_family() should not take keyspace args,CASSANDRA-1168,12466308,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,mdennis,benjaminblack,benjaminblack,07/Jun/10 02:25,16/Apr/19 09:33,14/Jul/23 05:51,08/Jun/10 14:17,0.7 beta 1,,,,0,,,,,,"With the addition of set_keyspace(), things that are scoped by keyspace should no longer take keyspace args.  system_add_column_family() is correct in only taking a cf_def.  system_drop_column_family() and system_rename_column_family() should be changed to match.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jun/10 22:37;mdennis;0001-trunk-1168.patch;https://issues.apache.org/jira/secure/attachment/12446539/0001-trunk-1168.patch",,,,,,,,,,,,,,1.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20013,,,Wed Jun 09 13:38:59 UTC 2010,,,,,,,,,,"0|i0g3ev:",91983,,,,,Low,,,,,,,,,,,,,,,,,"07/Jun/10 22:37;mdennis;in addition to system_drop_column_family and system_rename_column_family, the keyspace param was also removed from truncate

Once committed, I'll update the wiki at http://wiki.apache.org/cassandra/API - are there other places that require doc updates? ;;;","08/Jun/10 14:17;gdusbabek;+1 committed!;;;","08/Jun/10 23:42;mdennis;wiki updated;;;","09/Jun/10 13:38;hudson;Integrated in Cassandra #460 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/460/])
    remove keyspace args from some system calls. patch by Matthew Dennis, reviewed by Gary Dusbabek. CASSANDRA-1168
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
race with insufficiently constructed Gossiper,CASSANDRA-1160,12466186,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,mdennis,jbellis,jbellis,04/Jun/10 13:59,16/Apr/19 09:33,14/Jul/23 05:51,10/Jun/10 17:06,0.6.3,0.7 beta 1,,,0,,,,,,"Gossiper.start needs to be integrated into the constructor.  Currently you can have threads using the gossiper instance before start finishes (or even starts?), resulting in tracebacks like this:

ERROR [GMFD:1] 2010-06-02 10:45:49,878 CassandraDaemon.java (line 78) Fatal exception in thread Thread[GMFD:1,5,main]
java.lang.AssertionError
	at org.apache.cassandra.net.Header.<init>(Header.java:56)
	at org.apache.cassandra.net.Header.<init>(Header.java:74)
	at org.apache.cassandra.net.Message.<init>(Message.java:58)
	at org.apache.cassandra.gms.Gossiper.makeGossipDigestAckMessage(Gossiper.java:294)
	at org.apache.cassandra.gms.Gossiper$GossipDigestSynVerbHandler.doVerb(Gossiper.java:935)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:40)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
ERROR [GMFD:2] 2010-06-02 10:45:49,880 CassandraDaemon.java (line 78) Fatal exception in thread Thread[GMFD:2,5,main]
java.lang.AssertionError
	at org.apache.cassandra.net.Header.<init>(Header.java:56)
	at org.apache.cassandra.net.Header.<init>(Header.java:74)
	at org.apache.cassandra.net.Message.<init>(Message.java:58)
	at org.apache.cassandra.gms.Gossiper.makeGossipDigestAckMessage(Gossiper.java:294)
	at org.apache.cassandra.gms.Gossiper$GossipDigestSynVerbHandler.doVerb(Gossiper.java:935)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:40)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)",,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1010,,,,,,,,"07/Jun/10 17:50;mdennis;0001-cassandra-0.6-1160.patch;https://issues.apache.org/jira/secure/attachment/12446505/0001-cassandra-0.6-1160.patch","08/Jun/10 16:04;mdennis;0002-cassandra-0.6-1160.patch;https://issues.apache.org/jira/secure/attachment/12446601/0002-cassandra-0.6-1160.patch","08/Jun/10 21:06;mdennis;0003-cassandra-0.6-1160.patch;https://issues.apache.org/jira/secure/attachment/12446628/0003-cassandra-0.6-1160.patch","10/Jun/10 15:39;mdennis;0004-cassandra-0.6-1160.patch;https://issues.apache.org/jira/secure/attachment/12446768/0004-cassandra-0.6-1160.patch",,,,,,,,,,,4.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20012,,,Thu Jun 10 17:06:55 UTC 2010,,,,,,,,,,"0|i0g3d3:",91975,,,,,Low,,,,,,,,,,,,,,,,,"07/Jun/10 17:50;mdennis;moving start() to Gossiper.<init> causes failures in testClientOnlyMode and I didn't see a way to readily make client/server mode available to Gossiper.<init>

0001-cassandra-0.6-1160.patch delays creation of the Gossiper instance until start is called.  Any thread attempting to obtain a reference to Gossiper before it is started busy waits until it is fully initialized.

I'm not sure I actually like this solution, but thought I would submit for comments/feedback.

If we end up taking this solution, I'll submit a patch for trunk as well.;;;","07/Jun/10 22:26;gdusbabek;What were the failures in testClientOnlyMode?  I'm sure they can be worked around.

I'm not a fan of Gossiper.preRegistrations.  I think it is a code smell that we're not spinning up Gossiper the right way.  What if we were to make Gossiper.start() blocking until we were sure it was in a healthy state (keep in mind the single-node cluster) and then make sure it was called before MessageService.listen()?;;;","07/Jun/10 23:33;mdennis;I should have been more clear about that.  The failures in StorageServiceClientTest are because files from DatabaseDescriptor.getAllDataFileLocations() exist (the test asserts they do not).  This is because when I moved start into <init> I passed the same generation number that that initServer() uses, but initClient (used by the test) passes a generation number based on currentTimeMillis() which doesn't cause the file paths to exist.  It wasn't clear to me there was an easy way to determine what generation to use.

More importantly, this lead me to notice that both StorageService and StorageLoadBalancer are registered with Gossiper before start is called.  If start was moved into <init> I was afraid of introducing new race conditions (e.g. Gossiper starting up, doing things that would have resulted in publications and then later receiving the registration for such publications).

I agree that Gossiper is likely not being spun up correctly.  I think this applies to other things as well (in general things seem to have many interdependencies on boot.  I don't have anything specific to point at, but it feels like there are several race conditions that just happen to usually not be exhibited).

One solution I've used in the past that I like for this in general is that none of the singletons are inited in their own classes, but only by a BootInitializer of sorts that completely controls when the objects are inited/started/created/etc, in particular controlling the order things are done.  A single entry point into the system if you will.  This seems like some work from the point we're at now and probably a bit unnecessary.

Along those lines I had a similar patch that I didn't submit that took a third argument, List<IEndpointStateChangeSubsciber> initialSubscribers.  Each initialSubscriber was registered before the existing code in start was called.  initServer built a list of the StorageService and StorageLoadBalance instances and passed that to start to ensure none of the publications were missed by either service.  Like the 0001-cassandra-0.6-1160.patch references to .instance were replaced with getInstance() calls which busy waited (via yield) until start completed but this meant that StorageService was managing StorageLoadBalancer registrations and that didn't feel right, hence preRegistrations() (so each could manager their own registrations).

So, basically two issues/questions if Gossiper.start moves to Gossiper.<init>:

1) how does Gossiper.<init> get the correct generation number (server v client)?

2) what about missed publications because Gossiper was started before StorageService and/or StorageLoadBalancer got a chance to register?
;;;","08/Jun/10 13:18;gdusbabek;I'm taking a closer look. In the mean time can you rebase your patch?;;;","08/Jun/10 16:04;mdennis;0002-cassandra-0.6-1160.patch is against r952679;;;","08/Jun/10 18:36;mdennis;just FYI, if Gossiper.start() is moved before MessageService.listen() the unit tests show sporadic (~ 1 in 5) errors even though the tests still pass.



{code}
    [junit] ------------- Standard Error -----------------
    [junit] Exception in thread ""ACCEPT-/127.0.0.1"" java.lang.RuntimeException: java.nio.channels.ClosedChannelException
    [junit] 	at org.apache.cassandra.net.MessagingService$SocketThread.run(MessagingService.java:488)
    [junit] Caused by: java.nio.channels.ClosedChannelException
    [junit] 	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:130)
    [junit] 	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
    [junit] 	at org.apache.cassandra.net.MessagingService$SocketThread.run(MessagingService.java:477)
{code}

and

{code}
    [junit] Testsuite: org.apache.cassandra.service.AntiEntropyServiceTest
    [junit] Tests run: 10, Failures: 0, Errors: 0, Time elapsed: 3.282 sec
    [junit] 
    [junit] ------------- Standard Error -----------------
    [junit] ERROR 11:18:22,111 Error in executor futuretask
    [junit] java.util.concurrent.ExecutionException: java.lang.NullPointerException
    [junit] 	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
    [junit] 	at java.util.concurrent.FutureTask.get(FutureTask.java:83)
    [junit] 	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:86)
    [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
    [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    [junit] 	at java.lang.Thread.run(Thread.java:619)
    [junit] Caused by: java.lang.NullPointerException
    [junit] 	at java.util.AbstractCollection.addAll(AbstractCollection.java:303)
    [junit] 	at org.apache.cassandra.service.AntiEntropyService.getNeighbors(AntiEntropyService.java:149)
    [junit] 	at org.apache.cassandra.service.AntiEntropyService$Validator.call(AntiEntropyService.java:491)
    [junit] 	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
    [junit] 	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
    [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    [junit] 	... 2 more
{code};;;","08/Jun/10 19:03;gdusbabek;Intermittent test failures indicate you have a timing problem.

The fact that the assertion (the original intermittent problem) fails because a static class member is null makes me think we're dealing with static initializers firing in the order we don't suspect.  

I'd start by getting the inner classes (the verb handlers) out of Gossiper and into their own classes.  Then there is the race between Gossiper and MessageService.  You could let the gossiper start before the MessageService starts listening, but have the GossipTimerTask check to make sure the MessageService is listening before it sends out any gossip requests.  This still isn't going to protect us in the case of a node getting restarted where other nodes already know about it and and diligently trying to contact what they thought was a dead node.
;;;","08/Jun/10 21:06;mdennis;0003-cassandra-0.6-1160.patch as requested moves inner classes and Gossiper to top level classes and has Gossiper TimerTask busy wait until MessagingService is up;;;","10/Jun/10 13:15;gdusbabek;Last patch is looking good, except you should consider replacing the busy-wait Thread.yield() stuff with a CountDownLatch and a simple MessageService.awaitListen() call or something like that.  My reasoning is that Thread.yeild() behaves differently across platforms and can possibly starve threads running at a lower priority.;;;","10/Jun/10 14:01;jbellis;also consider using SimpleCondition.;;;","10/Jun/10 14:31;gdusbabek;Wouldn't a Condition cause the waiter to block if somehow signalAll() (which in this case would only be called once) was called before await()?  I know it's not likely, but there isn't any such problem with a CountDownLatch.;;;","10/Jun/10 14:57;jbellis;// [SimpleCondition] fulfils the Condition interface without spurious wakeup problems
// (or lost notify problems either: that is, even if you call await()
// _after_ signal(), it will work as desired.)
;;;","10/Jun/10 15:14;gdusbabek;I see.  I figured SimpleCondition was something out of the JDK.

Spurious bikeshed comment:  SimpleCondition.set should be volatile, no?  otherwise set=true ins't guaranteed to be visible to any thread stuck in await().;;;","10/Jun/10 15:27;jbellis;I believe the synchronized keyword takes care of that, but wait/notify are admittedly subtle.  I could be wrong.;;;","10/Jun/10 15:39;mdennis;0004-cassandra-0.6-1160.patch uses a gate to wait until MessagingService is listening;;;","10/Jun/10 15:40;gdusbabek;You're right. synchronized establishes happens-before with respect to object state.;;;","10/Jun/10 17:06;gdusbabek;replaced the latch with a SimpleCondition and committed.  Thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Read operation with ConsistencyLevel.ALL throws exception,CASSANDRA-1152,12466039,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,yukim,yukim,03/Jun/10 02:18,16/Apr/19 09:33,14/Jul/23 05:51,03/Jun/10 14:20,0.6.3,0.7 beta 1,,,0,,,,,,"Read operations which use thrift.CassandraServer#readColumnFamily should allow consistency_level == ALL.
Current implementation just throws InvalidRequestException when consistency level is ALL.
Same thing applies to avro implementation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jun/10 03:36;dylanegan;read_column_family_on_all;https://issues.apache.org/jira/secure/attachment/12446220/read_column_family_on_all","03/Jun/10 03:36;dylanegan;read_column_family_on_all_inline_with_thrift;https://issues.apache.org/jira/secure/attachment/12446219/read_column_family_on_all_inline_with_thrift",,,,,,,,,,,,,2.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20011,,,Thu Jun 03 17:27:20 UTC 2010,,,,,,,,,,"0|i0g3bb:",91967,,,,,Normal,,,,,,,,,,,,,,,,,"03/Jun/10 03:36;dylanegan;Created two patches to alleviate the ALL problem, but one of the patches brings the Avro interface inline with thrift in not supporting CL.ANY on read operations too.

Im not really following the Avro updates, but I assume the interface should be the same.;;;","03/Jun/10 14:20;gdusbabek;Committed.  Thanks for the patch.;;;","03/Jun/10 17:13;dylanegan;Hi Gary,

Just to help me understand, why would the Avro interface be different to the Thrift one in terms of what is supported at the read level.

Cheers,

Dylan.;;;","03/Jun/10 17:21;gdusbabek;My bad.  I intended to remove the CL.ANY block from avro and keep the CL.ALL block out.  CL.ANY isn't in our avro generation file yet.;;;","03/Jun/10 17:27;gdusbabek;Recommitted.  Thanks Dylan!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"pig contrib module not building, other errors",CASSANDRA-1150,12465974,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jeromatron,jeromatron,jeromatron,02/Jun/10 15:53,16/Apr/19 09:33,14/Jul/23 05:51,12/Jun/10 13:09,0.6.3,,,,0,,,,,,"Currently, the pig contrib module fails to build because of dependency issues - it looks like dependencies like hadoop that were at one time in the main cassandra dependency list.

Also, once the dependencies are resolved, there are still errors when running the example pig query in the README.txt in the module.

This ticket would address both of those issues and getting it working both on 0.6.x as well as mainline trunk.",,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1162,,,,"02/Jun/10 17:32;jeromatron;1150-build-0_6.txt;https://issues.apache.org/jira/secure/attachment/12446160/1150-build-0_6.txt","02/Jun/10 17:35;jeromatron;1150-build-trunk.txt;https://issues.apache.org/jira/secure/attachment/12446162/1150-build-trunk.txt","08/Jun/10 20:09;jeromatron;1150-runtime-0_6-patch.txt;https://issues.apache.org/jira/secure/attachment/12446622/1150-runtime-0_6-patch.txt","08/Jun/10 22:06;jeromatron;1150-runtime-trunk.txt;https://issues.apache.org/jira/secure/attachment/12446631/1150-runtime-trunk.txt",,,,,,,,,,,4.0,jeromatron,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20010,,,Sun Jun 13 12:45:40 UTC 2010,,,,,,,,,,"0|i0g3av:",91965,,,,,Low,,,,,,,,,,,,,,,,,"02/Jun/10 16:37;jeromatron;This patch is just for the build portion of the bug.;;;","02/Jun/10 17:29;jbellis;I think I'd rather ""fix"" this by adding the instruction ""rename or symlink your pig jar, to pig.jar"" so we're not pinned to a specific pig version.;;;","02/Jun/10 17:32;jeromatron;Updated to use a wildcard for the pig version, also attaching build fixes for both 0.6 branch and trunk.;;;","02/Jun/10 17:35;jeromatron;Bah - updated the trunk build fix - wishing IDEA wouldn't be buggy about what it included in patches...;;;","04/Jun/10 02:53;jbellis;committed;;;","04/Jun/10 17:20;jeromatron;It is now building at least - resolving this issue as CASSANDRA-1162 will address the other concerns - making it work properly within core and using a demo usage of it in the contrib section.;;;","07/Jun/10 22:51;jeromatron;Reopening since integrating with core will take a while (no mvn repo with pig).;;;","07/Jun/10 23:29;jeromatron;Adding patches for 0.6 branch and trunk.;;;","07/Jun/10 23:31;jeromatron;Adds a default pig script to run based on the README suggestion.  Adds more to the README indicating how to run in local mode since that's the least volatile mode to run in.

Also took out a couple of references to 0.7.0-dev -> 0.7.0.;;;","08/Jun/10 20:09;jeromatron;For both runtime patches:
Fixed the runtime problems with pig. Updated the README.txt for pig and added an example-script.pig. Fixed a few places where it referred to pig 0.7.0-dev.

For trunk:
It was calling the comparator's newInstance where it should use the singleton version.  Fixed that in a few other places as well.  Fixed a couple of comments in WordCountSetup.  Used cassandra.yaml instead of storage-conf.xml.  
Also enabled the executable bit on the word_count, word_count_setup, and pig_cassandra scripts.;;;","08/Jun/10 22:06;jeromatron;Added a bit to the NEWS.txt to let people know about the singleton model for AbstractType extensions.;;;","12/Jun/10 13:09;johanoskarsson;Committed to 0.6 branch and trunk.;;;","13/Jun/10 12:45;hudson;Integrated in Cassandra #464 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/464/])
    Remove references to -dev version of pig, add example script, use comparators singletons. Patch by Jeremy Hanna, review by johan. CASSANDRA-1150
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update stress.py to thrift api changes,CASSANDRA-1148,12465842,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,johanoskarsson,johanoskarsson,johanoskarsson,01/Jun/10 09:35,16/Apr/19 09:33,14/Jul/23 05:51,01/Jun/10 13:28,0.7 beta 1,,,,0,,,,,,The stress.py file was not updated to the CASSANDRA-1070 changes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jun/10 09:42;johanoskarsson;CASSANDRA-1148.patch;https://issues.apache.org/jira/secure/attachment/12446008/CASSANDRA-1148.patch",,,,,,,,,,,,,,1.0,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20009,,,Tue Jun 01 13:28:15 UTC 2010,,,,,,,,,,"0|i0g3af:",91963,,,,,Normal,,,,,,,,,,,,,,,,,"01/Jun/10 09:42;johanoskarsson;Wraps the timestamp in a Clock object.;;;","01/Jun/10 13:16;jbellis;+1;;;","01/Jun/10 13:28;johanoskarsson;Committed to trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra cannot bootstrap when using DatacenterShardStrategy,CASSANDRA-1147,12465832,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mdennis,mdennis,mdennis,01/Jun/10 07:03,16/Apr/19 09:33,14/Jul/23 05:51,14/Jun/10 21:52,0.7 beta 1,,,,0,,,,,,"If C is configured to use DSS, the bootstrap process never completes.
",,kimtea,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/10 21:51;jbellis;0002-1147.txt;https://issues.apache.org/jira/secure/attachment/12447071/0002-1147.txt","01/Jun/10 07:08;mdennis;CASSANDRA-1147.patch;https://issues.apache.org/jira/secure/attachment/12446001/CASSANDRA-1147.patch","01/Jun/10 20:29;mdennis;CASSANDRA-1147.patch2;https://issues.apache.org/jira/secure/attachment/12446061/CASSANDRA-1147.patch2","14/Jun/10 07:31;mdennis;CASSANDRA-1147.patch3;https://issues.apache.org/jira/secure/attachment/12447007/CASSANDRA-1147.patch3","14/Jun/10 17:40;mdennis;CASSANDRA-1147.patch4;https://issues.apache.org/jira/secure/attachment/12447043/CASSANDRA-1147.patch4",,,,,,,,,,5.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20008,,,Tue Jun 15 12:51:23 UTC 2010,,,,,,,,,,"0|i0g3a7:",91962,,,,,Normal,,,,,,,,,,,,,,,,,"01/Jun/10 07:08;mdennis;patch caches endpoints for getNaturalEndpoints (cleared on config or ring change) without requiring dcTokens/loadEndpoints and removes the need for CASSANDRA-1137;;;","01/Jun/10 13:15;jbellis;how does

         assert strategy.getReplicationFactor(""DC1"", table) == 3;

work when you're hardcoding it to 6 in the subclass?;;;","01/Jun/10 14:35;mdennis;different methods.  the assert is for grf(String dc, String table) and corresponds to datacenters.properties the override is for grf(String table) and corresponds to replication_factor in cassandra.yaml;;;","01/Jun/10 15:15;jbellis;could we just make DSS return sum(dc replication for table) as RF(table), for now?

(CASSANDRA-1066 should resolve this eventually by allowing us to move datacenter.properties into cassandra.yaml, and drop the per-table RF for strategies that it doesn't make sense for);;;","01/Jun/10 20:29;mdennis;patch2 against trunk r950215;;;","04/Jun/10 03:06;jbellis;caching natural endpoints seems like something we should put in AbstractReplicationStrategy for everyone.  what do you think?

(Given CASSANDRA-1014 I'm mildly excited about the opportunity to reduce the per-request garbage generated, by not rebuilding a fresh list every time.)

+        //is a new list required each time? (other strats do it)
+        //perhaps just an unmodifiable list?

yes, it's required, because it's going to be passed to sortByProximity.

+            total+=repFactor;

operator spacing please :)

+        System.out.println(""endpoints: "" + endpoints);

r/m this.;;;","14/Jun/10 07:31;mdennis;CASSANDRA-1147.patch3 implements caching and tests for all replication strategies;;;","14/Jun/10 16:20;jbellis;please fix re-ordering imports incorrectly.  correct order is

  * java
  * org.apache.commons 
  * org.apache.slf4j
  * org.junit
  * everything else alphabetically

(http://wiki.apache.org/cassandra/CodeStyle);;;","14/Jun/10 17:40;mdennis;CASSANDRA-1147.patch4 follows coding convention for imports

(note: the patch produced by ""svn diff"" was not originally usable because of the line endings in RackAwareStrategyTest so dos2unix was run on the patch);;;","14/Jun/10 21:51;jbellis;Fix using rack as a key to datacenters map

Fix returning multiple copies of the same endpoint from DSS; refactored calculateNaturalEndpoints to return a Set to make it more clear that this is not allowed

simplified DSS.cNE and made it not put more replicas in a DC than are configured

Use NBHM instead of ConcurrentHM in ARS

Use map.clear instead of AtomicReference + creating a new map in ARS (clear is a very rare operation, better to make that a little slower in exchange for not having to do an extra, fenced dereference on the common ops)

Removed unused unregister method from IEPS

Removed interfaces with a single implementor (ARS)

Cleaned up formatting;;;","14/Jun/10 21:52;jbellis;committed w/ above changes;;;","15/Jun/10 12:51;hudson;Integrated in Cassandra #466 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/466/])
    avoid allowing endpoints computed from old token map to persist after clearCachedEndpoints.  patch by mdennis and jbellis for CASSANDRA-1147
Fix bootstrap with DSS and add endpoint caching.
patch by mdennis and jbellis for CASSANDRA-1147
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Expected both token and generation columns""",CASSANDRA-1146,12465830,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,jbellis,jbellis,01/Jun/10 06:09,16/Apr/19 09:33,14/Jul/23 05:51,07/Jun/10 13:46,0.6.3,0.7 beta 1,,,0,,,,,,"From the mailing list:

{code}
ERROR 16:14:35,975 Exception encountered during startup.
java.lang.RuntimeException: Expected both token and generation columns; found ColumnFamily(LocationInfo [Generation:false:4@4,])
    at org.apache.cassandra.db.SystemTable.initMetadata(SystemTable.java:159)
    at org.apache.cassandra.service.StorageService.initServer(StorageService.java:305)
    at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:99)
    at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:177)
Exception encountered during startup.
{code}

Separately, the same user wrote: ""I added a server to my cluster. It had some junk in the system/LocationInfo files from previous, unsuccessful attempts to add the server to the cluster. (They were unsuccessful because I hadn't opened the port on that computer.)""

Perhaps that is why it was able to create the Generation column but not the Token?
",,schubertzhang,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-521,,,,,,"03/Jun/10 16:48;gdusbabek;0001-detect-partitioner-changes-and-fail-fast.patch;https://issues.apache.org/jira/secure/attachment/12446264/0001-detect-partitioner-changes-and-fail-fast.patch","05/Jun/10 04:59;gdusbabek;v2-0001-detect-partitioner-changes-and-fail-fast.patch;https://issues.apache.org/jira/secure/attachment/12446399/v2-0001-detect-partitioner-changes-and-fail-fast.patch",,,,,,,,,,,,,2.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20007,,,Sun Jun 06 02:20:30 UTC 2010,,,,,,,,,,"0|i0g39z:",91961,,,,,Normal,,,,,,,,,,,,,,,,,"02/Jun/10 14:46;gdusbabek;This is the error you get these days when you go from RP to OPP and back to RP.;;;","02/Jun/10 14:53;gdusbabek;Increasing priority to major since startup doesn't fail after changing partitioners and doing so corrupts your system table.;;;","02/Jun/10 17:24;jbellis;Isn't this the same as that one issue for making system table always OPP, then?

IIRC we decided to wait until we had sstable versioning done, so we could grandfather in old system tables appropriately.;;;","02/Jun/10 17:25;jbellis;Ah, CASSANDRA-521.  I see you're ahead of me again.;;;","02/Jun/10 17:40;gdusbabek;We decided to wait because we promised we wouldn't change the sstable disk format for 0.5

I guess we need to ask that question again for 0.7.

I still think a header is the right way to implement this.;;;","03/Jun/10 16:51;gdusbabek;patch is for trunk, but putting this back to 0.6 shouldn't pose a stability problem or interfere with upgrades.

Biggest change is that partitioner name is stored in system table and ST.initMetadata() flushes system tables after writing.

btw, this patch doesn't interfere with the sstable format.;;;","04/Jun/10 04:19;jbellis;why the change to flushing system tables?  it's in the commitlog, so it will get replayed if necessary.;;;","04/Jun/10 04:24;gdusbabek;The flush is for the case where a new node halts before the initial system CFs can be written to sstables.;;;","04/Jun/10 12:29;jbellis;so it's covered by the commitlog.  (which CD replays before ST ever gets involved on the next restart);;;","04/Jun/10 13:04;gdusbabek;Right, but you don't want to replay the commit log if someone has changed the partitioner, do you?  That would be Bad.  The point of this patch is to detect a partitioner mismatch at the earliest possible moment.  Flushing the CL after updating the system table means that we have to wait for one less restart for the the system sstable files to appear so that we can rely on the mismatch detection code to work.;;;","04/Jun/10 13:44;jbellis;ah, right.  i get it now.

in that case isn't CFS.forceBlockingFlush on STATUS_CF adequate?;;;","04/Jun/10 13:53;gdusbabek;Yes.  I'll make that change.;;;","05/Jun/10 04:59;gdusbabek;New patch only flushes STATUS_CF.;;;","06/Jun/10 02:20;jbellis;+1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reading with CL > ONE returns multiple copies of the same column per key.,CASSANDRA-1145,12465813,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jeromatron,ajslater,ajslater,31/May/10 23:23,16/Apr/19 09:33,14/Jul/23 05:51,05/Aug/10 14:09,0.6.5,,,,0,,,,,,"Testing with 0.6-trunk today:

Reading with CL > ONE returns multiple copies of the same column per key consistent with the replicas queried before return. i.e, for RC=3, a QUORUM read yields 2 copies and an ALL read returns 3.
This is with pycassa get_range() which is using get_range_slice()

I see the same behavior with 0.6.1 and 0.6.2 debs

If my experience is not unique, anyone using get_range_slice is now deluged with duplicate data.
",ubuntu jaunty,ajslater,anty,cw_krebs,johanoskarsson,joosto,schubertzhang,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/10 20:44;jeromatron;0001-Added-a-unit-test.patch;https://issues.apache.org/jira/secure/attachment/12451265/0001-Added-a-unit-test.patch","04/Aug/10 23:45;jeromatron;0001-Sort-keys.patch;https://issues.apache.org/jira/secure/attachment/12451281/0001-Sort-keys.patch","05/Aug/10 12:54;jbellis;1145-v2.txt;https://issues.apache.org/jira/secure/attachment/12451327/1145-v2.txt","31/May/10 23:28;ajslater;bugtest.py;https://issues.apache.org/jira/secure/attachment/12445975/bugtest.py","04/Aug/10 22:03;messi;demo.patch;https://issues.apache.org/jira/secure/attachment/12451271/demo.patch","31/May/10 23:28;ajslater;storage-conf.xml;https://issues.apache.org/jira/secure/attachment/12445976/storage-conf.xml",,,,,,,,,6.0,jeromatron,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20006,,,Thu Aug 05 14:09:20 UTC 2010,,,,,,,,,,"0|i0g39r:",91960,,jbellis,,jbellis,Normal,,,,,,,,,,,,,,,,,"31/May/10 23:28;ajslater;attached is a storage-conf and example python program. 
it requires the python thrift bindings and pycassa: http://github.com/vomjom/pycassa

usage:  ./bugtest.py [TEXT1 TEXT2..]

arguments on the command line are inserted into cassandra and then range_get is used to get and pretty print them, with timestamps.

it counts the multiple copies of the same rows at the end.;;;","31/May/10 23:31;jeromatron;Hi AJ, could you try to replicate it with the latest 0.6 branch just to see if it wasn't fixed by another fix (cassandra-1042)?  Just wondering if it's a the same bug but showing itself in more than one place.

http://svn.apache.org/repos/asf/cassandra/branches/cassandra-0.6/;;;","31/May/10 23:34;ajslater;I saw the same behavior with cassandra-0.6 svn revision 949892;;;","31/May/10 23:40;jeromatron;Okay yeah - that fix was in revision 948934, so it looks like it's a different issue.  Tx.;;;","16/Jun/10 21:18;joosto;We're getting duplicate rows from get_range_slice when NOT using ConsistencyLevel.ONE.  That is to say, when using QUORUM or ALL, we're getting duplicate rows, but when using ONE, we are not. Is this case misnamed?;;;","16/Jun/10 21:25;jbellis;Joost: :) no, it really is a bug

Jeremy: could you have a look?;;;","06/Jul/10 23:45;jeromatron;Hi AJ, taking another look at this.  I'm getting errors when I try to put ('localhost:9160') in the SERVERS variable in bugtest.py.  Specifically, I'm seeing that pycassa is giving a NoServerAvailable exception when trying to connect.  So I'm unable to reproduce the problem.

Can you see if you can get it to run and hopefully replicate the problem just with the localhost?  I'm not sure if I'm just configuring that incorrectly either. ;;;","07/Jul/10 00:00;ajslater;Looks like pycassa has a problem with tuples with one element, which is another problem. So to fix, use a list:

SERVERS= ['localhost:9160']

Also I ran into your NoServerAvailable problem, using localhost:9160.
Cassandra is likely not really listening on 'localhost:9160', try 'myServerName:9160'  or use the exact IP you specify to thrift in storage-conf.xml
;;;","07/Jul/10 02:18;jeromatron;Sweet sassafras - thanks AJ, that was it - matching the localhost in the SERVERS variable to localhost in the rpc address in storage-conf.xml.  Looking at it more now.;;;","04/Aug/10 20:44;jeromatron;Added a unit test that will expose the problem.;;;","04/Aug/10 22:03;messi;CollatingIterator expects both collections to be sorted. See demo.patch.;;;","04/Aug/10 22:26;jeromatron;Folke - you're right.  I'll focus on the creation of the list of rows.  I had thought we looked at the ordering, but I think since they were in the same order, we didn't think twice.  Good catch.;;;","04/Aug/10 23:45;jeromatron;Adding a fix patch that will sort the keys before getRangeSlice uses them to get their associated rows.  That will keep them sorted when they are sent back to the client, for the CollatingIterator.;;;","05/Aug/10 12:54;jbellis;The order we read them in CFS [token order] is the ""right"" order.  Stomping on that will take as back to CASSANDRA-1042 type bugs.  

Does v2 (attached) fix the problem?;;;","05/Aug/10 13:50;jeromatron;Yes - I wondered if what I had done would affect other things, such as reverting other changes.  Thanks.  I could see where the problem was, but wasn't 100% sure where to make the change.  Sounds like they were sorted correctly wrt to token, which our CollatingIterator needed to take into account.

I ran the same tests again that could formerly reproduce the problem (with several permutations) and it fixes the problem.

I also ran `ant test` and `nosetests` to make sure everything else was happy.

+1 from me.;;;","05/Aug/10 14:09;jbellis;committed, with a slight modification to allow the unit test to pass in a different partitioner than the global one;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
batch_mutate Deletion with column family type mismatch causes RuntimeException,CASSANDRA-1139,12465613,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,mdennis,tholzer,tholzer,28/May/10 02:29,16/Apr/19 09:33,14/Jul/23 05:51,04/Jun/10 02:58,0.6.3,,,,0,batch_mutate,Deletion,,,,"When specifying a super column family name inside a Deletion and a standard column family name in the mutations dictionary, we get a RuntimeException in the server and a TimedOutException on the client:

{noformat}
ERROR 14:22:29,757 Error in ThreadPoolExecutor
java.lang.RuntimeException: java.lang.UnsupportedOperationException: This operation is not supported for Super Columns.
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.UnsupportedOperationException: This operation is not supported for Super Columns.
        at org.apache.cassandra.db.SuperColumn.timestamp(SuperColumn.java:137)
        at org.apache.cassandra.db.ColumnSerializer.serialize(ColumnSerializer.java:65)
        at org.apache.cassandra.db.ColumnSerializer.serialize(ColumnSerializer.java:29)
        at org.apache.cassandra.db.ColumnFamilySerializer.serializeForSSTable(ColumnFamilySerializer.java:87)
        at org.apache.cassandra.db.ColumnFamilySerializer.serialize(ColumnFamilySerializer.java:73)
        at org.apache.cassandra.db.RowMutationSerializer.freezeTheMaps(RowMutation.java:337)
        at org.apache.cassandra.db.RowMutationSerializer.serialize(RowMutation.java:349)
        at org.apache.cassandra.db.RowMutationSerializer.serialize(RowMutation.java:322)
        at org.apache.cassandra.db.RowMutation.getSerializedBuffer(RowMutation.java:275)
        at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:200)
        at org.apache.cassandra.service.StorageProxy$3.runMayThrow(StorageProxy.java:310)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 3 more
ERROR 14:22:29,757 Fatal exception in thread Thread[ROW-MUTATION-STAGE:39,5,main]
{noformat}

{noformat}
Traceback (most recent call last):
  File ""./test.py"", line 15, in <module>
    client.batch_mutate(""Keyspace1"", mutations, ConsistencyLevel.QUORUM)
  File ""cassandra/Cassandra.py"", line 771, in batch_mutate
    self.recv_batch_mutate()
  File ""cassandra/Cassandra.py"", line 798, in recv_batch_mutate
    raise result.te
cassandra.ttypes.TimedOutException: TimedOutException()
{noformat}

To reproduce:

{noformat}
from thrift.transport.TSocket import TSocket
from thrift.protocol.TBinaryProtocol import TBinaryProtocol
from cassandra.Cassandra import Client
from cassandra.ttypes import Deletion, Mutation, ConsistencyLevel

if __name__ == ""__main__"":
    tsocket = TSocket('localhost', 9160)
    tsocket.open()
    tprotocol = TBinaryProtocol(tsocket)
    client = Client(tprotocol)
    deletion = Deletion(1, 'supercolumn', None)
    mutation = Mutation(deletion=deletion)
    mutations = { 'key' : { 'Standard1' : [ mutation ] } }
    client.batch_mutate(""Keyspace1"", mutations, ConsistencyLevel.QUORUM)
{noformat}

",Linux & Python 2.6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jun/10 18:58;mdennis;CASSANDRA-0_6-1139.patch;https://issues.apache.org/jira/secure/attachment/12446043/CASSANDRA-0_6-1139.patch","01/Jun/10 18:40;mdennis;CASSANDRA-1139.patch;https://issues.apache.org/jira/secure/attachment/12446039/CASSANDRA-1139.patch",,,,,,,,,,,,,2.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20005,,,Fri Jun 04 02:58:27 UTC 2010,,,,,,,,,,"0|i0g38f:",91954,,,,,Low,,,,,,,,,,,,,,,,,"28/May/10 17:13;jbellis;Looks like converting the given test to a system test (in test_bad_calls) and updating ThriftValidation to catch this is fairly straightforward.;;;","01/Jun/10 18:41;mdennis;patch against trunk r950099;;;","01/Jun/10 18:58;mdennis;0.6 patch against cassandra-0.6 r950198;;;","04/Jun/10 02:58;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Row iteration can stomp start-of-row mark,CASSANDRA-1130,12465398,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,slebresne,jigneshdhruv,jigneshdhruv,25/May/10 18:13,16/Apr/19 09:33,14/Jul/23 05:51,14/Jun/10 18:06,0.7 beta 1,,,,0,,,,,,"Hello,

I am trying to use TTL (timeToLive) feature in SuperColumns.
My usecase is:
- I have a SuperColumn and 3 subcolumns.
- I try to expire data after 60 seconds.

While Cassandra is up and running, I am successfully able to push and read data without any problems. Data compaction and all occurs fine. After inserting say about 100000 records, I stop Cassandra while data is still coming.

On startup Cassandra throws an exception and won't start up. (This happens 1 in every 3 times). Exception varies like:
- EOFException while reading data
- negative value encountered exception
- Heap Space Exception

Cassandra simply won't start up.

Again I get this problem only when I use TTL with SuperColumns. There are no issues with using TTL with regular Columns.

I tried to diagnose the problem and it seems to happen on startup when it sees a Column that is marked Deleted and its trying to read data. Its off by some bytes and hence all these exceptions.

Caused by: java.io.IOException: Corrupt (negative) value length encountered
        at org.apache.cassandra.utils.FBUtilities.readByteArray(FBUtilities.java:317)
        at org.apache.cassandra.db.ColumnSerializer.deserialize(ColumnSerializer.java:84)
        at org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:336)
        at org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:285)
        at org.apache.cassandra.db.filter.SSTableSliceIterator$ColumnGroupReader.getNextBlock(SSTableSliceIterator.java:235)
        at org.apache.cassandra.db.filter.SSTableSliceIterator$ColumnGroupReader.pollColumn(SSTableSliceIterator.java:195)
        ... 18 more


Let me know if you need more information.

Thanks,
Jignesh",,billa,joosto,mdennis,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jun/10 16:53;slebresne;0001-Allow-for-multiple-mark-on-a-file.patch;https://issues.apache.org/jira/secure/attachment/12447039/0001-Allow-for-multiple-mark-on-a-file.patch","14/Jun/10 16:53;slebresne;0002-Unit-test-for-row-iteration.patch;https://issues.apache.org/jira/secure/attachment/12447040/0002-Unit-test-for-row-iteration.patch","27/May/10 21:21;jigneshdhruv;TestSuperColumnTTL.java;https://issues.apache.org/jira/secure/attachment/12445706/TestSuperColumnTTL.java","27/May/10 20:22;slebresne;TestSuperColumnTTL.java;https://issues.apache.org/jira/secure/attachment/12445696/TestSuperColumnTTL.java","28/May/10 17:00;slebresne;cassandra_0.6-Allow_multiple_mark_on_file.diff;https://issues.apache.org/jira/secure/attachment/12445795/cassandra_0.6-Allow_multiple_mark_on_file.diff",,,,,,,,,,5.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20002,,,Tue Jun 22 14:08:08 UTC 2010,,,,,,,,,,"0|i0g36f:",91945,,,,,Normal,,,,,,,,,,,,,,,,,"25/May/10 18:51;slebresne;If you have some script that allows to reproduce, that would be awesome. Alternatively, if you're able to locate the culprit data file and if the infos are not sensible, providing the file could help.

Are you using latest trunk ?;;;","25/May/10 19:06;jigneshdhruv;Yes I am using the latest source code from trunk.

I have a small java application that deals with creating schema and populating data.

This is what I was able to debug till now:
The error occurs during deserialization in ColumnSerializer.

There is an extra int byte that needs to be read before ColumnSerializer.java:84. Value of this extra int byte is ""4"". Not sure what it stands for.

I am not sure from where that byte is set. After reading that byte, I get the localDeletionTime value.

Also this happens when the DELETION_MASK is set on a record. It works fine for records with EXPIRATION_MASK. I am thinking that converting a record from EXPIRY to DELETED is causing this error at startup or something like that.

Let me know if you need more information.

But you should be able to reproduce this if you have a SuperColumn and their subColumns with TTL. Stop and start cassandra after loading some data. It consistently fails to startup 1 out of every 3 times.

Jignesh
;;;","25/May/10 20:37;jigneshdhruv;OK. I think I narrowed it down further..

The bug may be in ""org/apache/cassandra/db/filter/SSTableSliceIterator.java:getNextBlock() method.

See the while loop on line 233.
Out here, its reading 1 column at a time.

As I said before, the problem is when an Column of Type ExpiringColumn becomes DeletedColumn when time has expired.

In that case, once the Supercolumn whose subcolumns are of type ""DELETED"" are read in this while loop, there are some extra bytes that needs to be skipped but instead it goes in the second iteration in the while loop and tries to read the next column and thats where all the problem starts.

Shouldn't the while loop just read one Column at a time and then exit. That is what it does when it reads all the bytes. If I put a ""break statement"" in the end of while loop after reading a column all works fine as the extra bytes are skipped during the next read of a Column.

I am not sure what is the purpose of this while loop? but if we break after reading  1 column at a time, all works fine and cassandra starts up smoothly.

This looks similar to issue
https://issues.apache.org/jira/browse/CASSANDRA-1073

Jignesh;;;","25/May/10 21:19;jigneshdhruv;I did some more testing with the patch that I suggested i.e. skipping extra bytes after reading the column and exiting the while loop worked fine. I am now able to load and start cassandra with SuperColumn data with TTL without any problems.;;;","25/May/10 21:30;jbellis;this sounds like something you could build a unit test for?;;;","25/May/10 21:40;slebresne;But they shouldn't be extra bytes to skip. An expired column becomes a deletedColumn only 
after everything is deserialized. It is expected that we read all and everything that is written.

The while loop you're referring to is here to read all the column (or super columns) that falls 
into one given index range (the index is sparse). If you exit the while loop, you will just potentially 
skip some columns (super columns in your example). That it makes cassandra start may just be 
that it skips the problematic parts. 

I'll try to reproduce this tomorrow (but if you want and can share your test code to make that 
easier, feel free to :)). ;;;","26/May/10 09:22;slebresne;Sorry but I don't seem able to reproduce this.
I've tried a simple test, inserting supercolumns with 100 colums in them, 
each having a TTL (that I varied from 10 seconds to like 3 minutes).
I typically let it insert over 10000 super columns  (so around 1 millions ttled 
columns) and kill it. I run cassandra again, let it compact, kill it again, run again, 
start insertion again, etc... I tried like 20 times, no crashes whatsoever.

I've tried with a trunk of a week or so ago and then with trunk from 1 hour ago. 
Sounds like you have no problem reproducing on your side so .. I don't know.

If you could somehow come up with a unit test that make it crashes or a small 
script test that triggers it, that would be amazing.;;;","26/May/10 17:29;jigneshdhruv;I checked out the latest source code this morning and I am still able to reproduce it.

My usecase is:
- Start Cassandra
- Keep adding SuperColumns with 3 subcolumns within each SuperColumn. Each subcolumn expires in 35 seconds.
- Let cassandra run until you see statements  like ""Deleted  files""
- Stop cassandra and try to start and it will give you all the exceptions that I am talking about.

Also I believe ExpiringColumn contains some more data compared to DeletedColumn. Correct? In my testing I found that length of each DeletedColumn was similar to ExpiringColumn and once a complete DeletedColumn record was read there were some more extra bytes at the end of the record which is causing all this issue?

When you convert a ExpiringColumn to DeletedColumn, is it in place replacement or the old record is marked for deletion by just changing the EXPIRING_MASK to DELETED_MASK.

I will try to produce a junit test case. But one needs to still stop cassandra when one sees some files being deleted. At that point you will see the error that I am talking about.

Jignesh;;;","27/May/10 20:22;slebresne;Sorry but I'm still unable to reproduce.

I'm attaching a small insert script (in java) that, as far as I can see,
seems to do what you say triggers the bug. Could you look if this fails 
on your side. If I haven't understand the steps correctly, would you mind 
updating this test so that it reproduce the bug you see ?
(the script uses raw thrift and requires a very recent trunk)

{quote}
Also I believe ExpiringColumn contains some more data compared to DeletedColumn. Correct? In my testing I found that length of each
DeletedColumn was similar to ExpiringColumn and once a complete DeletedColumn record was read there were some more extra bytes at the 
end of the record which is causing all this issue?
When you convert a ExpiringColumn to DeletedColumn, is it in place replacement or the old record is marked for deletion by just 
changing the EXPIRING_MASK to DELETED_MASK.
{quote}

File on disk are not updated in place. So we never change on disk an
ExpiringColumn to a DeletedColumn. There only is a small optimisation in the
deserialization code that, after having fully deserialize an ExpiringColumn,
will return an equivalent DeletedColumn if the column is expired. But we always
read exactly what we have written (or it's a bug).;;;","27/May/10 21:21;jigneshdhruv;Hello,

I am still able to reproduce the problem consistently. I have attached my JUNIT Test case which reproduces it 1 out of 3 times.

Streps to Reproduce:
- Run it until it inserts atleaset 200000 records or until you see a ""Deleted files"" message on your console.
- Stop cassandra while the data is still coming in.
- Start Cassandra and you should get exceptions.

If you do not get exceptions, without deleting the index repeat the above steps.

Let me know if you are able to reproduce the problem.

Thanks,
Jignesh;;;","27/May/10 22:08;slebresne;Ok, I'm able to reproduce with your test.
I'll have a look at it, thanks;;;","28/May/10 16:01;slebresne;Attached fiie should fix the problem. 

The problem is unrelated to TTL per se but a problem in row iterations so the 
ticket title can be a bit misleading.
Citing irc: 
  ""a columnGroupReader mark the file when it is created. Then it reset() when getting a next block.
   but with the way the row iteration works, a new columnGroupReader is created (and mark the file) before 
   the previous one has retrieved it's block
  (it's because computeNext() create the next SSTableSliceIterator before getReduced() had retrieved the actual 
   column of the previous one)""
The patch allow for each columnGroupReader to have it's own mark on the file

Btw, I was unable to reproduce previously because it's the cache preloading that 
trigged the error and I did not use one in my first tests. 

Thanks Jignesh for helping find this one.;;;","28/May/10 17:00;slebresne;Attached version of the patch rebased against 0.6;;;","28/May/10 17:32;slebresne;Attaching a unit test for trunk that fails without the patch and passes with it.

It doesn't fail in 0.6 though. I suspect this is because getRangeSlice doesn't 
work in the same way in 0.6. So I'm not sure how to reproduce in 0.6. But I'll 
have a better at how it works in 0.6 and see if I can have a unit test for it too.;;;","28/May/10 17:54;jigneshdhruv;Excellent. I guess the changes are in trunk. I will check it out.

Thanks,
Jignesh;;;","30/May/10 01:41;jbellis;This bug is only present in 0.7.;;;","14/Jun/10 16:08;jbellis;Sorry for the delay applying.  Can you rebase to trunk please?;;;","14/Jun/10 16:53;slebresne;No problem, attaching rebased patches;;;","14/Jun/10 18:06;jbellis;committed, thanks!;;;","22/Jun/10 04:06;jbellis;weird, I totally remember committing this (and editing SSTNI to make it apply) but it didn't make it to svn.  Probably I forgot git-svn dcommit somehow.

really committed this time.;;;","22/Jun/10 14:08;hudson;Integrated in Cassandra #473 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/473/])
    fix race condition in SSTable*Iterator.
patch by Sylvain Lebresne; reviewed by jbellis for CASSANDRA-1130
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Using KeysCached=""xx%"" results in Key cache capacity: 1",CASSANDRA-1129,12465392,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,,rantav,rantav,25/May/10 17:23,16/Apr/19 09:33,14/Jul/23 05:51,01/Jun/10 19:26,0.6.3,,,,0,,,,,,"I don't know if this is a general bug or only something related to my instance, but for me (v0.6.1) I've noticed that when defining KeysCached=""50%"" (or KeysCached=""100%"" and I didn't test other values with %) then cfstats reports Key cache capacity: 1

      <ColumnFamily CompareWith=""BytesType"" Name=""KvAds""
        KeysCached=""100%""
        RowsCached=""10000""
        />


                Column Family: KvAds
                SSTable count: 7
                Space used (live): 797535964
                Space used (total): 797535964
                Memtable Columns Count: 42292
                Memtable Data Size: 10514176
                Memtable Switch Count: 24
                Read Count: 2563704
                Read Latency: 4.590 ms.
                Write Count: 1963804
                Write Latency: 0.025 ms.
                Pending Tasks: 0
                Key cache capacity: 1
                Key cache size: 1
                Key cache hit rate: 0.0
                Row cache capacity: 10000
                Row cache size: 10000
                Row cache hit rate: 0.2206178354382234
                Compacted row minimum size: 386
                Compacted row maximum size: 9808
                Compacted row mean size: 616

I'll attach one of the sstable files from this CF",,jhermes,schubertzhang,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,"29/May/10 05:42;jhermes;0001-CASSANDRA1129.patch;https://issues.apache.org/jira/secure/attachment/12445832/0001-CASSANDRA1129.patch","31/May/10 07:26;jhermes;0002-CASSANDRA1129.patch;https://issues.apache.org/jira/secure/attachment/12445907/0002-CASSANDRA1129.patch","01/Jun/10 15:33;jhermes;0003-CASSANDRA1129.patch;https://issues.apache.org/jira/secure/attachment/12446030/0003-CASSANDRA1129.patch","25/May/10 19:04;rantav;KvAds-84.zip;https://issues.apache.org/jira/secure/attachment/12445489/KvAds-84.zip","02/Jun/10 06:42;jhermes;TOTRUNK-2-CASSANDRA1129.patch;https://issues.apache.org/jira/secure/attachment/12446118/TOTRUNK-2-CASSANDRA1129.patch","02/Jun/10 00:50;jhermes;TOTRUNK-CASSANDRA1129.patch;https://issues.apache.org/jira/secure/attachment/12446084/TOTRUNK-CASSANDRA1129.patch",,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20001,,,Fri Jun 04 02:38:45 UTC 2010,,,,,,,,,,"0|i0g367:",91944,,,,,Low,,,,,,,,,,,,,,,,,"25/May/10 17:33;rantav;The smallest sstable file I could find of this CF.;;;","25/May/10 17:37;jbellis;can you include index and filter parts too, as a zip or tarball?;;;","25/May/10 19:04;rantav;zip file with index, data and filter;;;","27/May/10 13:38;jbellis;So to troubleshoot this you would

* check out the 0.6 branch
* add the CF definition above to your conf/storage-conf.xml
* unzip the sstable files into your data/Keyspace1 directory
* set a breakpoint in DatabaseDescriptor.getKeysCachedFor and see why it's calculating 1 instead of the number of rows in the sstable;;;","29/May/10 05:42;jhermes;Status for first patch:
M       test/unit/org/apache/cassandra/db/CompactionsPurgeTest.java
M       test/conf/storage-conf.xml
M       src/java/org/apache/cassandra/db/ColumnFamilyStore.java
M       src/java/org/apache/cassandra/utils/FBUtilities.java
M       src/java/org/apache/cassandra/cache/InstrumentedCache.java
M       src/java/org/apache/cassandra/io/SSTableTracker.java

This bug was two bugs:
# FBUtilities#absoluteFromFraction(double,long) is a bit ambiguous. The method reads 100% as *absolute* 1, so the keyCacheCapacity is always going to be 1. This fix is already in 0.7.
# The bigger bug is that the keyCacheCapacity was not getting changed during runtime. There was a boolean capacityModified that controlled access to the capacity. It gets set true the first time the capacity is modified (read: creation of table/cfstore) and then never goes back to false. By removing this bool, the cache size gets updated on flushes and on compactions correctly.

Also included are tests in CompactionsPurgeTest that shows this fix works for both 50% and 100% (that the keyCacheCapacity changes dynamically).

The update is O(1), so it shouldn't matter for performance that it's being called on every flush and every compaction.;;;","29/May/10 11:59;jbellis;committed the absoluteFromFraction fix.

for the rest, we need to preserve the boolean, but make it only get set when the cache capacity is set manually from JMX (see CASSANDRA-1079);;;","31/May/10 07:26;jhermes;Removed the FBUtil change from patch.

setCapacity(int) changed to setCapacity(int,bool) in both interface and object.
The boolean in the object is now capacityFrozen with the same logic as before.
setCapacity from the automatic update (flushing/compaction) pass in a false to not freeze the capacity afterward, setCapacity from the JMX command pass in a true to do so.

(To remedy a previous statement, the running time is not O(1) overall. It's O(|SSTables|) with constant time per table.);;;","01/Jun/10 14:15;jbellis;instead of overloading setCapacity to be the interface for both normal adjustments and manual overrides, let's split it up.  have setCapacity(value) be the mbean interface, setting a capacitySetManually boolean, and make a method updateCapacity(value) for internal use.  ;;;","01/Jun/10 15:33;jhermes;capacitySetManually is in place.
setCapacity(int), updateCapacity(int) work as described above.;;;","01/Jun/10 19:26;jbellis;committed, thanks!;;;","01/Jun/10 19:31;jbellis;could you submit a version of this patch against trunk, too?;;;","02/Jun/10 00:50;jhermes;Here's the patch for trunk.
The testconf.xml is now a testconf.yaml.
The test itself uses trunk-style clock, decorated keys.

io/SSTableTracker changes go to io/sstable/SSTableTracker.

The other changes patched easily.;;;","02/Jun/10 03:34;jbellis;I'm getting test failures on trunk (but not 0.6):

    [junit] Testcase: testKeyCache50(org.apache.cassandra.db.CacheSizeTest):	FAILED
    [junit] 128
    [junit] junit.framework.AssertionFailedError: 128
    [junit] 	at org.apache.cassandra.db.CacheSizeTest.testKeyCache(CacheSizeTest.java:93)
    [junit] 	at org.apache.cassandra.db.CacheSizeTest.testKeyCache50(CacheSizeTest.java:49)

(I moved it to a separate CacheSizeTest class, in case the others in CompactionsPurgeTest were messing with it.  Didn't help.);;;","02/Jun/10 06:42;jhermes;All right, the difference is between SSTableReader.estimatedKeys() in 0.6 and RowIndexedReader.estimatedKeys() in 0.7 -- RIR increments the size once during estimation whereas SSTR does not.
Knowing this, I'm making the test explicitly catch 128/256.;;;","02/Jun/10 06:53;jhermes;By the way, the RIR increment looks unintentional to me. It might be a bug; I can't see a reason why it gets incremented for CASS-777 when SSTableReader went to RIReader.
If this is the case, then the +1 can be reverted and the test can go back to catching 64/128.;;;","04/Jun/10 02:38;jbellis;committed the original version for trunk, and removed the extra +1 from estimatedKeys.  Thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
sstable2json spews because it uses DatabaseDescriptor before loadSchemas() is called,CASSANDRA-1128,12465390,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,mdennis,mdennis,mdennis,25/May/10 17:14,16/Apr/19 09:33,14/Jul/23 05:51,28/May/10 13:06,0.7 beta 1,,Legacy/Tools,,0,,,,,,sstable2json depends on DatabaseDescriptor for ColumnFamily meta data.  DD requires loadSchemas() is called before the CFMD can be accesed.  nothing in the code path in sstable2json calls loadSchemas().,,gdusbabek,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/10 17:16;mdennis;CASSANDRA-1128.patch;https://issues.apache.org/jira/secure/attachment/12445473/CASSANDRA-1128.patch","27/May/10 20:34;mdennis;CASSANDRA-1128.patch2;https://issues.apache.org/jira/secure/attachment/12445700/CASSANDRA-1128.patch2",,,,,,,,,,,,,2.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,20000,,,Sat May 29 12:45:43 UTC 2010,,,,,,,,,,"0|i0g35z:",91943,,,,,Low,,,,,,,,,,,,,,,,,"25/May/10 17:16;mdennis;patch against -r948111;;;","25/May/10 19:48;gdusbabek;+1

DD.loadSchemas() requires that system tables are present.  I wish there were a better way to do this, but I can't think of one.;;;","25/May/10 19:50;gdusbabek;I'm going to hold off on committing this while I investigate some more.  There's got to be a better way.  Also, I want to make sure that sstableimport isn't broken in the same fundamental way.;;;","25/May/10 21:29;mdennis;let me know if there is anything I can do to help...;;;","26/May/10 14:23;gdusbabek;Matthew, can you add this same fix to SSTableImport as well as a check immediately after the DD.loadSchemas() to verify that >0 non-system tables are defined?  The relevant call is DD.getNonSystemTables().;;;","27/May/10 20:36;mdennis;patch2 against r948964;;;","28/May/10 13:06;gdusbabek;committed with minor revisions.;;;","29/May/10 12:45;hudson;Integrated in Cassandra #449 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/449/])
    have sstable import/export load schema from local storage. Patch by Matthew Dennis, reviewed by Gary Dusbabek. CASSANDRA-1128
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Lack of subcomparator_type will corrupt the keyspace in Thrift system_add_keyspace(),CASSANDRA-1122,12465309,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,arya,arya,24/May/10 21:27,16/Apr/19 09:33,14/Jul/23 05:51,26/May/10 19:04,0.7 beta 1,,,,0,,,,,,"I had a problem earlier where I create a Keyspace by reading the default yaml config shipped with the above cassandra package and after parsing and creating the keyspace with PHP Thrift system_add_keysapce command, I would get 'TException: Error: Internal error processing describe_keyspace ' when trying to get describe_keyspace. In cassandra-cli I get the same error.

The cassandra log shows a null pointed exception:
ERROR [pool-1-thread-39] 2010-05-24 14:17:35,204 Cassandra.java (line 1943) Internal error processing describe_keyspace
java.lang.NullPointerException
	at org.apache.cassandra.thrift.CassandraServer.describe_keyspace(CassandraServer.java:476)
	at org.apache.cassandra.thrift.Cassandra$Processor$describe_keyspace.process(Cassandra.java:1939)
	at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:1276)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)

I traced down the problem to where I define cassandra_CfDef. When the type is Super and subcomparator_type is not set, Thrift code does not set it to any default value but blank """". The command system_add_keyspace() runs with no problem. Whatever happens in Cassandra afterwards, will create a useless keyspace.

Here is my code snippet to generate the exception:

 <?php
$GLOBALS['THRIFT_ROOT'] = '/usr/share/php/Thrift';
require_once $GLOBALS['THRIFT_ROOT'].'/packages/cassandra/Cassandra.php';
require_once $GLOBALS['THRIFT_ROOT'].'/packages/cassandra/cassandra_types.php';
require_once $GLOBALS['THRIFT_ROOT'].'/transport/TSocket.php';
require_once $GLOBALS['THRIFT_ROOT'].'/protocol/TBinaryProtocol.php';
require_once $GLOBALS['THRIFT_ROOT'].'/transport/TFramedTransport.php';
require_once $GLOBALS['THRIFT_ROOT'].'/transport/TBufferedTransport.php';

try {
  // Make a connection to the Thrift interface to Cassandra
  $socket = new TSocket('127.0.0.1', 9160);
  $transport = new TBufferedTransport($socket, 1024, 1024);
  $protocol = new TBinaryProtocolAccelerated($transport);
  $client = new CassandraClient($protocol);
  $transport->open();

  //Try creating some keyspace/column family defs
  $ks = new cassandra_KsDef();
  $ks->name = 'agoudarzi_Keyspace1';
  $ks->strategy_class = 'org.apache.cassandra.locator.RackUnawareStrategy';
  $ks->replication_factor = '1';
  
  //Now add a column family to it
  $cf = new cassandra_CfDef();
  $cf->name = 'Super3';
  $cf->table = 'agoudarzi_Keyspace1';
  $cf->column_type = 'Super';
  $cf->comparator_type = 'LongType';
  $cf->row_cache_size = '0';
  $cf->key_cache_size = '50';
  $cf->comment = 'A column family with supercolumns, whose column names are Longs (8 bytes)';
  $ks->cf_defs[] = $cf;

  $client->system_add_keyspace($ks);
  
  sleep(2);
  
  //Try to check if keyspace description is good
  $client->set_keyspace('agoudarzi_Keyspace1');
  $rs = $client->describe_keyspace('agoudarzi_Keyspace1');

  $transport->close();

} catch (TException $tx) {
   print 'TException: '.$tx->why. ' Error: '.$tx->getMessage() . ""\n"";
}
?>

I think a default subcomparator should be set by thrift or other defensive method be used to prevent this problem.

Please investigate. 

Thanks.","CentOS 5.2 - Linux 2.6.18-164.15.1.el5 #1 SMP Wed Mar 17 11:30:06 EDT 2010 x86_64 x86_64 x86_64 GNU/Linux
apache-cassandra-2010-05-21_13-27-42
Thrift 2.0 with patch https://issues.apache.org/jira/browse/THRIFT-780
PHP 5.2",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/10 18:33;gdusbabek;0001-CFMeta.subcolumncomparator-should-default-to-BytesTy.patch;https://issues.apache.org/jira/secure/attachment/12445574/0001-CFMeta.subcolumncomparator-should-default-to-BytesTy.patch","24/May/10 21:29;arya;test_cass.php;https://issues.apache.org/jira/secure/attachment/12445388/test_cass.php",,,,,,,,,,,,,2.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19999,,,Thu May 27 12:47:29 UTC 2010,,,,,,,,,,"0|i0g34v:",91938,,,,,Normal,,,,,,,,,,,,,,,,,"24/May/10 21:29;arya;The PHP Code to reproduce this exception. ;;;","26/May/10 18:36;gdusbabek;Before CASSANDRA-44, we assumed defaulted CF.subcolumcomparator to BytesType if it wasn't specified on a supercolumn.  We can't have a conditional default in thrift, so make it right on the server.

Includes a system test that could reproduce the error prior to the patch.;;;","26/May/10 18:36;jbellis;+1;;;","27/May/10 12:47;hudson;Integrated in Cassandra #447 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/447/])
    CFMeta.subcolumncomparator should default to BytesType if cftype==Super. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1122
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
detect incomplete commitlogheader,CASSANDRA-1119,12465237,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,mdennis,jbellis,jbellis,24/May/10 02:28,16/Apr/19 09:33,14/Jul/23 05:51,10/Jun/10 17:07,0.6.3,0.7 beta 1,,,0,,,,,,"Kelvin reported:

I just came across a corrupted CL file.  Here's the stacktrace when starting the server:
Listening for transport dt_socket at address: 8888
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.commons.daemon.support.DaemonLoader.load(DaemonLoader.java:160)
Caused by: java.io.EOFException
	at java.io.RandomAccessFile.readInt(RandomAccessFile.java:725)
	at java.io.RandomAccessFile.readLong(RandomAccessFile.java:758)
	at org.apache.cassandra.db.commitlog.CommitLogHeader.readCommitLogHeader(CommitLogHeader.java:145)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:181)
	at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:167)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:95)
	at org.apache.cassandra.thrift.CassandraDaemon.init(CassandraDaemon.java:142)
	... 5 more

He added that the segment is only 6 bytes long, indicating that the header was never completely written.  CLH should catch that EOF and skip the segment when replay is attempted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jun/10 23:29;mdennis;0001-cassandra-0.6-1119.patch;https://issues.apache.org/jira/secure/attachment/12446639/0001-cassandra-0.6-1119.patch","08/Jun/10 23:29;mdennis;0001-trunk-1119.patch;https://issues.apache.org/jira/secure/attachment/12446640/0001-trunk-1119.patch","10/Jun/10 15:52;mdennis;0002-cassandra-0.6-1119.patch;https://issues.apache.org/jira/secure/attachment/12446769/0002-cassandra-0.6-1119.patch","10/Jun/10 15:52;mdennis;0002-trunk-1119.patch;https://issues.apache.org/jira/secure/attachment/12446770/0002-trunk-1119.patch",,,,,,,,,,,4.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19998,,,Thu Jun 10 17:18:35 UTC 2010,,,,,,,,,,"0|i0g347:",91935,,,,,Low,,,,,,,,,,,,,,,,,"10/Jun/10 13:35;gdusbabek;Let's log a WARN when this happens so there is some kind of indication that Bad Stuff exists.;;;","10/Jun/10 14:04;jbellis;well, it's expected behavior if you happen to kill the server at the right time.  maybe INFO.;;;","10/Jun/10 15:52;mdennis;I had not logged anything since it is expected behavior;;;","10/Jun/10 15:53;mdennis;0002 patches log at INFO;;;","10/Jun/10 16:32;jbellis;Is it possible that we could end up with garbage in the commitlog header, if we lose power during the header update post flush?  (i.e., not a brand new segment?)

if so we should probably split the header out into a separate file, and if we can't read the header, start replay of the mutations file from the beginning.  (This could be a new ticket.);;;","10/Jun/10 17:07;gdusbabek;committed.;;;","10/Jun/10 17:18;gdusbabek;Yes, it is possible that the header could be corrupted while writing mutations to the CL (existing CL mutations would be intact).;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
allow overriding existing token owner with a new IP,CASSANDRA-1118,12465236,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,jbellis,jbellis,24/May/10 02:26,16/Apr/19 09:33,14/Jul/23 05:51,07/Jun/10 20:26,0.6.3,0.7 beta 1,,,0,,,,,,"We'd like to support replacing one node with another at the same IP (e.g. when the data is on Amazon's EBS and can easily be mounted to a new host), as noted in CASSANDRA-872.  But in practice this is reported to not work w/o a cluster restart (can't find the ML thread now ... ?)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/10 13:47;gdusbabek;0001-use-start-time-to-resolve-node-token-reassignment-di.patch;https://issues.apache.org/jira/secure/attachment/12446144/0001-use-start-time-to-resolve-node-token-reassignment-di.patch","05/Jun/10 05:10;gdusbabek;v2-0001-use-generation-time-to-resolve-node-token-reassignme.patch;https://issues.apache.org/jira/secure/attachment/12446400/v2-0001-use-generation-time-to-resolve-node-token-reassignme.patch","07/Jun/10 15:02;gdusbabek;v3-0001-use-generation-time-to-resolve-node-token-reassignme.patch;https://issues.apache.org/jira/secure/attachment/12446489/v3-0001-use-generation-time-to-resolve-node-token-reassignme.patch",,,,,,,,,,,,3.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19997,,,Tue Jun 08 12:45:21 UTC 2010,,,,,,,,,,"0|i0g33z:",91934,,,,,Low,,,,,,,,,,,,,,,,,"28/May/10 19:38;gdusbabek;I'm guessing the description should read ""We'd like to support replacing one node with another at *a different* IP..."";;;","28/May/10 20:00;jbellis;Yes, that's right.  (oops.);;;","01/Jun/10 22:15;gdusbabek;Basically for my notes so I don't forget this...

This feature is already implemented, but I see two bugs.  First, there is a flaw in the state logic that assumes any time a node is seen for the first time that is the canonical host for a given token.  It is manifest when NodeB(tokenX) comes online intending to replace NodeA(tokenX).  when B sees A for the first time during the normal course of gossip, B incorrectly assumes that A is replacing it, which messes up B's view of the ring.  Second, partitions are not addressed (Node C, returning from a partition will not see that B has replaced A) and will have an incorrect view of the ring.;;;","02/Jun/10 13:47;gdusbabek;Use start time to resolve node token reassignment disagreement. ;;;","02/Jun/10 13:48;gdusbabek;Patch is against trunk.;;;","04/Jun/10 04:23;jbellis;would it be simpler to use the gossip ""generation"" to detect the more recently started host?;;;","04/Jun/10 04:32;gdusbabek;That would be better.;;;","05/Jun/10 05:10;gdusbabek;Modified patch to use generation time.;;;","06/Jun/10 02:19;jbellis;you can get the generation from endpointstate.heartbeatstate without needing to add an extra applicationstate;;;","07/Jun/10 15:02;gdusbabek;Use heatbeat generation time instead of something different.;;;","07/Jun/10 18:43;jbellis;+1;;;","08/Jun/10 12:45;hudson;Integrated in Cassandra #459 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/459/])
    use generation time to resolve node token reassignment disagreement. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1118
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
describe_ring() throws on single node clusters and/or probably clusters without a replication factor,CASSANDRA-1111,12465029,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,dccwilliams,dccwilliams,20/May/10 14:12,16/Apr/19 09:33,14/Jul/23 05:51,28/May/10 19:28,0.6.3,0.7 beta 1,,,0,describe_ring,exception,replication,,,"You use Thrift to call describe_ring() on a cluster with only a single node. The Thrift connection is broken, and the system.log shows the exception that has been thrown:

ERROR [pool-1-thread-15] 2010-05-20 13:15:24,753 TThreadPoolServer.java (line 259) Error occurred during processing of message.
java.lang.RuntimeException: No replica strategy configured for L1AbuseReports
        at org.apache.cassandra.service.StorageService.getReplicationStrategy(StorageService.java:246)
        at org.apache.cassandra.service.StorageService.constructRangeToEndPointMap(StorageService.java:457)
        at org.apache.cassandra.service.StorageService.getRangeToAddressMap(StorageService.java:443)
        at org.apache.cassandra.service.StorageService.getRangeToEndPointMap(StorageService.java:433)
        at org.apache.cassandra.thrift.CassandraServer.describe_ring(CassandraServer.java:628)
        at org.apache.cassandra.thrift.Cassandra$Processor$describe_ring.process(Cassandra.java:1781)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:1125)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:637)",Mac OS X Snow Leopard,,,,,,,,,,2700,2700,,0%,2700,2700,,,,,,,,,,,,,,"28/May/10 18:28;gdusbabek;1111-0.6.txt;https://issues.apache.org/jira/secure/attachment/12445800/1111-0.6.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,687,,,Mon May 31 09:59:46 UTC 2010,,,,,,,,,,"0|i0g32f:",91927,,,,,Normal,,,,,,,,,,,,,,,,,"21/May/10 16:27;gdusbabek;I'm having difficulty reproducing this problem in branches/cassandra-0.6.  What I comment out <ReplicaPlacementStrategy>, I get the following error on startup:

ERROR 11:26:08,593 Fatal error: Missing replicaplacementstrategy directive for Keyspace1
Bad configuration; unable to start server

I get a similar error when I configure a replicaplacementstrategy, but leave the replicationfactor out.

Is it possible to work up a short test that duplicates this problem?;;;","24/May/10 14:31;gdusbabek;Closing until we better understand how to duplicate the problem.;;;","27/May/10 04:48;tholzer;I can reproduce this with the following:

Linux & Python 2.6.4

{noformat}
from thrift.transport.TSocket import TSocket
from thrift.protocol.TBinaryProtocol import TBinaryProtocol
from cassandra.Cassandra import Client

if __name__ == ""__main__"":
    tsocket = TSocket('localhost', 9160)
    tsocket.open()
    tprotocol = TBinaryProtocol(tsocket)
    client = Client(tprotocol)
    keyspaces = client.describe_keyspaces()
    for keyspace in keyspaces:
        print ""%s"" % client.describe_ring(keyspace)
{noformat}

Output:
{noformat}
[TokenRange(end_token='107294900513650794844962875501795914878', start_token='107294900513650794844962875501795914878', endpoints=['127.0.0.1'])]
Traceback (most recent call last):
  File ""test/t1.py"", line 13, in <module>
    print ""%s"" % client.describe_ring(keyspace)
  File ""cassandra/Cassandra.py"", line 964, in describe_ring
    return self.recv_describe_ring()
  File ""cassandra/Cassandra.py"", line 975, in recv_describe_ring
    (fname, mtype, rseqid) = self._iprot.readMessageBegin()
  File ""thrift/protocol/TBinaryProtocol.py"", line 126, in readMessageBegin
    sz = self.readI32()
  File ""thrift/protocol/TBinaryProtocol.py"", line 203, in readI32
    buff = self.trans.readAll(4)
  File ""thrift/transport/TTransport.py"", line 58, in readAll
    chunk = self.read(sz-have)
  File ""thrift/transport/TSocket.py"", line 94, in read
    raise TTransportException(type=TTransportException.END_OF_FILE, message='TSocket read 0 bytes')
thrift.transport.TTransport.TTransportException: TSocket read 0 bytes
{noformat}

Server log:
{noformat}
ERROR 16:40:55,288 Error occurred during processing of message.
java.lang.RuntimeException: No replica strategy configured for system
        at org.apache.cassandra.service.StorageService.getReplicationStrategy(StorageService.java:246)
        at org.apache.cassandra.service.StorageService.constructRangeToEndPointMap(StorageService.java:457)
        at org.apache.cassandra.service.StorageService.getRangeToAddressMap(StorageService.java:443)
        at org.apache.cassandra.service.StorageService.getRangeToEndPointMap(StorageService.java:433)
        at org.apache.cassandra.thrift.CassandraServer.describe_ring(CassandraServer.java:628)
        at org.apache.cassandra.thrift.Cassandra$Processor$describe_ring.process(Cassandra.java:1781)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:1125)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
{noformat}
;;;","27/May/10 12:48;gdusbabek;Will re-examine using supplied steps.;;;","28/May/10 18:29;gdusbabek;describe_ring(""system"") should be treated as an invalid request since that keyspace has no ring.;;;","28/May/10 18:47;jbellis;+1;;;","31/May/10 09:59;dccwilliams;Hi, fwiw was planning to use describe_ring() in new Pelops Java client library to discover the nodes in a cluster i.e. connection pool starts with a few known nodes then discovers all.

Problem occurred on single node setup on my laptop but I'm guessing that without this working there would be no way to ""know"" there is only one node.

In such cases TokenRange will always map to 1/the same node, but that's still useful information, at least for Pelops;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cassandra does not expire data after setting timeToLive argument for each value,CASSANDRA-1109,12464905,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jigneshdhruv,jigneshdhruv,jigneshdhruv,19/May/10 15:57,16/Apr/19 09:33,14/Jul/23 05:51,19/May/10 23:38,0.7 beta 1,,,,1,,,,,,"Hello,

I downloaded latest cassandra source code from svn trunk. I wanted to test expire data functionality. Using Thrift API, I set timeToLive parameter for each fieldValue, however cassandra ignored it and did not expire any data.

I debugged cassandra's source code and found a bug in src/java/org/apache/cassandra/db/RowMutation.java.

In RowMutation.addColumnOrSuperColumnToRowMutation() method, QueryPath was not setting timeToLive argument. I updated RowMutation.java locally and tested it and then my data expired after 'n' number of seconds.

I wanted to have this fix in the trunk also.

Index: src/java/org/apache/cassandra/db/RowMutation.java
===================================================================
--- src/java/org/apache/cassandra/db/RowMutation.java   (revision 946222)
+++ src/java/org/apache/cassandra/db/RowMutation.java   (working copy)
@@ -295,12 +295,12 @@
         {
             for (org.apache.cassandra.thrift.Column column : cosc.super_column.columns)
             {
-                rm.add(new QueryPath(cfName, cosc.super_column.name, column.name), column.value, column.timestamp);
+                rm.add(new QueryPath(cfName, cosc.super_column.name, column.name), column.value, column.timestamp, column.ttl);
             }
         }
         else
         {
-            rm.add(new QueryPath(cfName, null, cosc.column.name), cosc.column.value, cosc.column.timestamp);
+            rm.add(new QueryPath(cfName, null, cosc.column.name), cosc.column.value, cosc.column.timestamp, cosc.column.ttl);
         }
     }


Thanks,
Jignesh",,billa,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/May/10 17:23;slebresne;0001-System-test-for-1109.patch;https://issues.apache.org/jira/secure/attachment/12444959/0001-System-test-for-1109.patch","19/May/10 16:02;jigneshdhruv;CASSANDRA-1109.patch;https://issues.apache.org/jira/secure/attachment/12444953/CASSANDRA-1109.patch",,,,,,,,,,,,,2.0,jigneshdhruv,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19996,,,Thu May 20 12:42:38 UTC 2010,,,,,,,,,,"0|i0g31z:",91925,,,,,Normal,,,,,,,,,,,,,,,,,"19/May/10 16:02;jigneshdhruv;Patch Submitted.;;;","19/May/10 16:58;slebresne;Indeed, good catch. Thanks

+1 on the patch;;;","19/May/10 17:23;slebresne;And because everything's look better with a system test, adding one;;;","19/May/10 23:38;jbellis;committed.  thanks!;;;","20/May/10 12:42;hudson;Integrated in Cassandra #441 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/441/])
    test + fix for expiring columns.  patch by Jignesh Dhruv and Sylvain Lebresne for CASSANDRA-1109
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DatacenterShardStrategyTest.testProperties fails,CASSANDRA-1107,12464898,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,jbellis,johanoskarsson,johanoskarsson,19/May/10 14:58,16/Apr/19 09:33,14/Jul/23 05:51,19/May/10 15:21,,,,,0,,,,,,"Stacktrace
junit.framework.AssertionFailedError
	at org.apache.cassandra.locator.DatacenterShardStrategyTest.testProperties(DatacenterShardStrategyTest.java:36)

Standard Error
ERROR 12:39:35,968 Could not find end point information for 127.0.0.1, will use default.

http://hudson.zones.apache.org/hudson/job/Cassandra/440/testReport/junit/org.apache.cassandra.locator/DatacenterShardStrategyTest/testProperties/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19995,,,Wed May 19 15:21:01 UTC 2010,,,,,,,,,,"0|i0g31j:",91923,,,,,Critical,,,,,,,,,,,,,,,,,"19/May/10 15:21;jbellis;already fixed in r946192;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DSS rack-awareness doesn't really work,CASSANDRA-1103,12464814,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,18/May/10 17:15,16/Apr/19 09:33,14/Jul/23 05:51,18/May/10 21:56,0.7 beta 1,,,,0,,,,,,CASSANDRA-952 fixed most of the DSS issues but the attempted placement of machines on different racks w/in each DC is poor (comparing each node only to the rack of the 1st replica in that DC rather than all).,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/May/10 17:19;jbellis;ASF.LICENSE.NOT.GRANTED--0001-clean-up-DSS-inline-getNaturalEndpointsInternal-remove.txt;https://issues.apache.org/jira/secure/attachment/12444813/ASF.LICENSE.NOT.GRANTED--0001-clean-up-DSS-inline-getNaturalEndpointsInternal-remove.txt","18/May/10 17:19;jbellis;ASF.LICENSE.NOT.GRANTED--0002-simplify-out-doneDataCenterIter-variable.txt;https://issues.apache.org/jira/secure/attachment/12444814/ASF.LICENSE.NOT.GRANTED--0002-simplify-out-doneDataCenterIter-variable.txt","18/May/10 17:19;jbellis;ASF.LICENSE.NOT.GRANTED--0003-fix-DSS-to-generate-unique-racks-when-possibleb.txt;https://issues.apache.org/jira/secure/attachment/12444815/ASF.LICENSE.NOT.GRANTED--0003-fix-DSS-to-generate-unique-racks-when-possibleb.txt",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19994,,,Thu May 20 12:42:39 UTC 2010,,,,,,,,,,"0|i0g30n:",91919,,,,,Normal,,,,,,,,,,,,,,,,,"18/May/10 17:19;jbellis;03
    fix DSS to generate unique racks when possibleb

02
    simplify out doneDataCenterIter variable

01
    clean up DSS: inline getNaturalEndpointsInternal, remove reload-on-every-call, r/m redundant dcE
;;;","18/May/10 20:06;jeromatron;Looks good, makes it more readable with the refactor.

Two comments:

1) DSS: in loadEndpoints, for dcTokens, could a Collection be used that is naturally sorted so it doesn't have to iterate again through to sort them?
2) should the comment on line 156 really be before line 160 instead where the loop is;;;","18/May/10 21:56;jbellis;committed w/ suggested comment change

cleaning up loadEndpoints is a fine goal for another ticket :);;;","20/May/10 12:42;hudson;Integrated in Cassandra #441 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/441/])
    add back localEndpoints variable to track ""endpoints in this DC"" separately from ""total endpoints selected so far.""  fixes regression introduced in CASSANDRA-1103.  patch by jbellis
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use get_range_slices in stress.py,CASSANDRA-1094,12464579,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,stuhood,stuhood,stuhood,15/May/10 01:42,16/Apr/19 09:33,14/Jul/23 05:51,17/May/10 14:35,0.7 beta 1,,Legacy/Tools,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/May/10 01:43;stuhood;get_range_slices.diff;https://issues.apache.org/jira/secure/attachment/12444556/get_range_slices.diff",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19990,,,Tue May 18 13:31:39 UTC 2010,,,,,,,,,,"0|i0g2yn:",91910,,,,,Low,,,,,,,,,,,,,,,,,"17/May/10 14:35;jbellis;committed;;;","18/May/10 13:31;hudson;Integrated in Cassandra #439 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/439/])
    use get_range_slices in stress.py.  patch by Stu Hood; reviewed by jbellis for CASSANDRA-1094
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BinaryMemtable interface silently dropping data.,CASSANDRA-1093,12464558,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,tjungen,tjungen,14/May/10 20:13,16/Apr/19 09:33,14/Jul/23 05:51,26/Jul/10 14:47,0.6.4,,,,0,,,,,,"I've been attempting to use the Binary Memtable (BMT) interface to load a large number of rows. During my testing, I discovered that on larger loads (~1 million rows), occasionally some of the data never appears in the database. This happens in a non-deterministic manner, as sometimes all the data loads fine, and other times a significant chunk goes missing. No errors are ever logged to indicate a problem. I'm attaching some sample code that approximates my application's usage of Cassandra and explains this bug in more detail.","Linux Centos5, Fedora Core 4. Java HotSpot Server 1.6.0_14. See readme for more details.",hammer,johanoskarsson,stuhood,tjungen,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/10 13:42;jbellis;1093.txt;https://issues.apache.org/jira/secure/attachment/12449452/1093.txt","14/May/10 20:14;tjungen;cassandra_bmt_test.tar.gz;https://issues.apache.org/jira/secure/attachment/12444527/cassandra_bmt_test.tar.gz",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19989,,,Mon Jul 26 14:47:20 UTC 2010,,,,,,,,,,"0|i0g2yf:",91909,,,,,Low,,,,,,,,,,,,,,,,,"14/May/10 20:14;tjungen;Sample code and instructions for how to run. See readme.txt in the archive.;;;","15/May/10 23:56;lenn0x;I've never seen this happen and I've done many imports. At the very end of the import, are you calling nodetool flush <Keyspace> ? ;;;","16/May/10 05:10;lenn0x;Tonight I imported 1M rows and verified all rows existed.;;;","16/May/10 05:16;tjungen;Yes, I'm flushing each node after the import. I've also tried flushing the system keyspace (no effect). As noted in the readme, I would not be surprised if this problem is unique to my hardware/software configuration and isn't an inherent problem with Cassandra's BMT interface.

For what it's worth, I've hacked together a ""workaround"" for this problem by writing SSTables directly (using o.a.c.io.SSTableWriter), copying the generated files to appropriate directories on the nodes, and then restarting the nodes. This solution is bound to result in other bugs, but for now I've verified that there is no lost data with this method.;;;","28/May/10 16:33;jbellis;can you reproduce using Toby's code, Brandon?;;;","28/May/10 18:46;brandon.williams;I can't get it past the generate step without an OOM:


cassandra_bmt_test# java -jar -Xmx4096m build/cassandra-bmt-test.jar generate foo 1000000
Generating data...
Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space
        at java.util.ArrayList.<init>(ArrayList.java:132)
        at java.util.ArrayList.<init>(ArrayList.java:139)
        at CassandraBMTTest.generateData(Unknown Source)
        at CassandraBMTTest.main(Unknown Source)

I'm going to try with < 1M and see if that works.;;;","28/May/10 19:03;tjungen;I've been able to observe the error with a generate parameter of 25,000. Note that the generate step creates the entire randomized data set in memory before writing it to disk, so this test is limited by memory. With a parameter of 25,000 I ran fine with 512MB of heap space, at 100,000 I'd expect you to need around 2GB of heap space. 

The parameter for the generate step corresponds to a ""document"", and each document results in roughly 100 rows.;;;","28/May/10 20:17;brandon.williams;I used 100K ""documents"":

Processed 4547169 values.
Done.
        Missing documents: 0
        Mismatched documents: 0
        Missing index entries: 0
        Wrong-sized index entries: 0
        Mismatched index entries: 0;;;","28/May/10 20:24;tjungen;Looks like everything passed. You may want to re-run from start to finish one or two more times (my error didn't occur consistently), but if it still passes at that point then close this issue as CannotReproduce and I'll attribute the problem to my hardware setup. As mentioned I've found somewhat of a workaround. I'll gladly donate my test code as a possible unit test for BMT if needed. :);;;","28/May/10 21:38;brandon.williams;I did another 100K run and it passed:


Processed 4547169 values.
Done.
        Missing documents: 0
        Mismatched documents: 0
        Missing index entries: 0
        Wrong-sized index entries: 0
        Mismatched index entries: 0

Is it possible you aren't waiting long enough for the flush to complete? (nodetool doesn't block on the flush command, you have to watch the system.log);;;","28/May/10 22:55;tjungen;Yep, I'm waiting until I see the flush message in the log. It reads something like ""BinaryMemtable@7a82b flushed to disk"".

One thing I'm thinking may be causing problems is my nodes being out of sync time-wise. I'll have to verify their clocks, but is it possible that if the clocks differ significantly that values get lost?;;;","04/Jun/10 18:42;brandon.williams;No, that shouldn't happen since the timestamps for columns are supplied by the client.;;;","13/Jul/10 16:33;jbellis;BMT is a very fire-and-forget api, so any failure condition will cause messages to be dropped with no way of knowing.

Probably the most likely one is, under heavy load (network and/or cpu) it's reasonably common for one node in the cluster to be marked ""down"" incorrectly by other nodes in the cluster.  This causes any messages on the MessagingService queue to that node to be dropped summarily, and the pool connection to be re-attempted when the failure detector believes it is ""up"" again.  (See OutboundTcpConnectionPool.reset);;;","13/Jul/10 20:19;tjungen;Thanks for the insight Jonathan. That was my intuition as well, and I observed my cluster periodically marking nodes as down for a second or two. I figured it was random network hiccups, since our network hardware is rather old. It would make sense that these periodic interruptions caused the BMT to lose data.

While looking through the code, I did try to see if I could use BMT with the blocking MessagingService API (in the way the Thrift API works unless ConsistencyLevel.ZERO is specified), but it looks like BMT is hardcoded to be asynchronous. It might be nice for that option to be there, but since this issue appears to only affect me (and I no longer need to use BMT for my purposes), it's a super-low priority suggestion.;;;","13/Jul/10 20:35;brandon.williams;If it is a node is being errantly marked down, in 0.6.3 or later you can try increasing the PhiConvictThreshold configuration directive and see if that helps.  EC2 users are setting it to 10 or 11, 8 is the default.;;;","13/Jul/10 22:10;jbellis;As it happens, Riptano has a client that is running into this too, so I'll take a stab at fixing it. :);;;","14/Jul/10 13:42;jbellis;patch to add response from BinaryVerbHandler, and updates bmt_example to use sendRR;;;","24/Jul/10 02:18;tjungen;Applied and tested the patch, appears to solve the problem. Haven't run multiple tests yet to make sure, but looks good so far. Obviously, this slows down the write, but that's an acceptable loss. It's likely still faster and more efficient than using the thrift API.

I'll be out of my office for the next three weeks, but I'll try to test more when I get back. Feel free to mark as resolved in the mean time.;;;","26/Jul/10 14:47;jbellis;committed, with additional note that wait-for-acks can reduce throughput;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Minor SliceRange documentation fix,CASSANDRA-1085,12464395,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,yosh,yosh,yosh,12/May/10 21:56,16/Apr/19 09:33,14/Jul/23 05:51,17/May/10 14:39,0.6.2,,Legacy/Documentation and Website,,0,,,,,,"Minor doc typo, patch attached",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/May/10 21:58;yosh;doc-fix.patch;https://issues.apache.org/jira/secure/attachment/12444348/doc-fix.patch",,,,,,,,,,,,,,1.0,yosh,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19988,,,Mon May 17 14:39:19 UTC 2010,,,,,,,,,,"0|i0g2wn:",91901,,,,,Low,,,,,,,,,,,,,,,,,"12/May/10 21:59;yosh;Patch applies to both trunk and cassandra-0.6 without trouble.;;;","17/May/10 14:39;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Thrift sockets leak in 0.6 hadoop interface,CASSANDRA-1081,12464359,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,johanoskarsson,riffraff,riffraff,12/May/10 15:59,16/Apr/19 09:33,14/Jul/23 05:51,20/May/10 08:20,0.6.2,,,,0,hadoop,leak,socket,thrift,,"Thrift connections appear not to be closed properly in 0.6 in ColumnFamilyRecordReader, which causes a file descriptor leak on the server and may eventually cause jobs to fail.

This appear to be fixed in 0.7 https://issues.apache.org/jira/browse/CASSANDRA-1017 so it may be worth backporting the patch or add a quick fix to close the Tsockets.",,johanoskarsson,kimtea,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/May/10 15:16;johanoskarsson;CASSANDRA-1081.patch;https://issues.apache.org/jira/secure/attachment/12444944/CASSANDRA-1081.patch",,,,,,,,,,,,,,1.0,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19987,,,Thu May 20 08:20:58 UTC 2010,,,,,,,,,,"0|i0g2vr:",91897,,,,,Low,,,,,,,,,,,,,,,,,"19/May/10 15:16;johanoskarsson;Simple patch that makes sure the socket is closed properly.;;;","19/May/10 19:11;jbellis;+1;;;","20/May/10 08:20;johanoskarsson;Committed to 0.6 branch.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE when no keyspaces section is found in yaml file,CASSANDRA-1080,12464357,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,slebresne,slebresne,12/May/10 15:46,16/Apr/19 09:33,14/Jul/23 05:51,12/May/10 16:15,0.7 beta 1,,,,0,,,,,,Everything's in the summary,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/May/10 15:47;slebresne;0001-Fix-NPE-when-no-keyspaces-section-is-found-in-yaml.patch;https://issues.apache.org/jira/secure/attachment/12444307/0001-Fix-NPE-when-no-keyspaces-section-is-found-in-yaml.patch",,,,,,,,,,,,,,1.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19986,,,Wed May 12 16:14:22 UTC 2010,,,,,,,,,,"0|i0g2vj:",91896,,,,,Low,,,,,,,,,,,,,,,,,"12/May/10 16:14;gdusbabek;+1.  Thanks Sylvain!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cache capacity settings done via nodetool get reset on memtable flushes,CASSANDRA-1079,12464310,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,kingryan,kingryan,12/May/10 00:18,16/Apr/19 09:33,14/Jul/23 05:51,17/May/10 22:33,0.6.2,,,,0,,,,,,"In an experiment we set cache capacities via nodetool. The config file had the KeyCache for this CF at 1000000, we set the RowCache to 10000000 via nodetool.

The next time we flushed a memtable for that CF, the cache capacity settings got reverted to what is in the conf file. We repeated the experiment with the same results.",,schubertzhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/May/10 15:40;jbellis;1079.txt;https://issues.apache.org/jira/secure/attachment/12444694/1079.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19985,,,Mon May 17 22:33:09 UTC 2010,,,,,,,,,,"0|i0g2vb:",91895,,,,,Normal,,,,,,,,,,,,,,,,,"12/May/10 00:33;jbellis;this is working as designed.  the config file is The Source Of Truth for settings it contains.;;;","12/May/10 00:43;kingryan;If we're not going to let the jmx-based setting live longer than one memtable, we should probably remove the ability to set it that way. The current behavior is too surprising.;;;","12/May/10 00:48;jbellis;It's not surprising if you remember that the conf is The Source Of Truth. :)

I'm big on ""there should only be one way to do it"" but restarting to test cache size effects is too painful.;;;","12/May/10 02:58;jmhodges;??I'm big on ""there should only be one way to do it"" but restarting to test cache size effects is too painful.??

I'm confused. Did you mean ""isn't""?;;;","12/May/10 03:35;stuhood;I think the disconnect is that Ryan and Jeff would like to be able to tune cache sizes on a cluster that is receiving writes, which is difficult when it is reset per-memtable.;;;","12/May/10 03:58;jbellis;Oh.  Sometimes I need to read things twice -- yes, it's a bug if it's not persisting between flushes.  (I'm saying that it's not supposed to persist b/t restarts, unless you change the conf file too.);;;","12/May/10 06:12;kingryan;Yes, ""not persisting  between restarts"" is expected, it currently gets reset when at every flush.;;;","12/May/10 17:05;kingryan;It appears the problem is that SSTableTracker's replace method calls updateCacheSizes, which reads the cache settings from DatabaseDescriptor (which doesn't get updated by the jmx command).;;;","17/May/10 15:40;jbellis;patch to not recalculate cache capacity if it's been manually modified;;;","17/May/10 17:04;kingryan;Patch looks good to me.;;;","17/May/10 22:33;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
StreamingService.StreamDestinations never empties,CASSANDRA-1076,12464261,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,stuhood,gdusbabek,gdusbabek,11/May/10 16:41,12/Aug/20 23:02,14/Jul/23 05:51,14/May/10 17:58,0.6.2,0.7 beta 1,,,0,,,,,,"The problem is that StreamOutManager.streamManagers never has anything removed from it.  In order for StreamingService.getDestinations() to work properly, we either need to track hosts differently, or remove from StreamOutManager.streamManagers when we are no longer streaming to a node.

I lean towards the former, as any time we call StreamOutManager.get(), we're back in the same boat.",,stuhood,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-956,,,,"14/May/10 16:33;gdusbabek;0001-remove-from-streamManagers-when-finished.patch;https://issues.apache.org/jira/secure/attachment/12444509/0001-remove-from-streamManagers-when-finished.patch","14/May/10 16:33;gdusbabek;0002-a-better-StreamingServcice.getStatus.patch;https://issues.apache.org/jira/secure/attachment/12444507/0002-a-better-StreamingServcice.getStatus.patch","14/May/10 16:33;gdusbabek;0003-nix-StreamFile.patch;https://issues.apache.org/jira/secure/attachment/12444508/0003-nix-StreamFile.patch",,,,,,,,,,,,3.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19984,,,Fri May 14 16:58:50 UTC 2010,,,,,,,,,,"0|i0g2un:",91892,,,,,Low,,,,,,,,,,,,,,,,,"11/May/10 20:25;gdusbabek;Patch is against trunk.;;;","14/May/10 14:25;gdusbabek;Stu, I noticed you assigned this issue to yourself.  Do you still intend to review the patches?;;;","14/May/10 15:56;stuhood;* The synchronized methods don't seem necessary: all structures are concurrent, and I don't think we need any operations to compose
* getPendingFiles has a race between 'streamManagers.containsKey(host)' and 'get(host)': perhaps just perform a single get, and check for null

Other than that, looks good to me.
;;;","14/May/10 16:33;gdusbabek;fixed those.;;;","14/May/10 16:58;stuhood;+1 Looks good.
Thanks Gary!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use batch_mutate in stress.py,CASSANDRA-1067,12464068,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,stuhood,stuhood,09/May/10 00:21,16/Apr/19 09:33,14/Jul/23 05:51,10/May/10 18:53,0.7 beta 1,,,,0,,,,,,"batch_insert was deprecated in trunk, which broke stress.py.",,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/May/10 00:21;stuhood;0001-Use-batch_mutate.patch;https://issues.apache.org/jira/secure/attachment/12444044/0001-Use-batch_mutate.patch",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19982,,,Mon May 10 18:53:15 UTC 2010,,,,,,,,,,"0|i0g2sn:",91883,,,,,Normal,,,,,,,,,,,,,,,,,"09/May/10 00:21;stuhood;Modifies stress.py to use batch_mutate.;;;","10/May/10 18:49;brandon.williams;+1;;;","10/May/10 18:53;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
tombstone-only rows in sstables can be ignored,CASSANDRA-1063,12464004,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,stuhood,stuhood,07/May/10 16:03,16/Apr/19 09:33,14/Jul/23 05:51,07/May/10 20:09,0.6.2,,,,0,,,,,,"ColumnFamilyStoreTest has two tests that pass, that shouldn't.  These are obscuring bugs in tombstone handling.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/May/10 16:04;stuhood;0001-Remove-implementation-awareness-from-CFSTest.patch;https://issues.apache.org/jira/secure/attachment/12443976/0001-Remove-implementation-awareness-from-CFSTest.patch","07/May/10 18:24;jbellis;1063.txt;https://issues.apache.org/jira/secure/attachment/12443987/1063.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19981,,,Fri May 07 20:09:07 UTC 2010,,,,,,,,,,"0|i0g2rr:",91879,,,,,Normal,,,,,,,,,,,,,,,,,"07/May/10 16:04;stuhood;Patch against 0.6.;;;","07/May/10 18:24;jbellis;There's actually a real bug getting masked here -- the correct answer is not null, but an empty, tombstoned CF.

In fact there are three bugs where we are incorrectly not taking into account row tombstones:

 - we can't just return null if the returnCF is empty, we need to check for tombstones via removeDeleted
 - we can't skip the delete call while building our iterator list, if the column iterator is empty
 - we can't skip deserializing the CF if all the columns in a names predicate are rejected by the bloom filter;;;","07/May/10 18:43;stuhood;+1 for 1063.txt. Good finds!;;;","07/May/10 20:09;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
update contrib/bmt_example to work post-CASSANDRA-44,CASSANDRA-1062,12463992,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,jbellis,jbellis,07/May/10 14:39,16/Apr/19 09:33,14/Jul/23 05:51,19/May/10 12:46,0.7 beta 1,,,,0,,,,,,the main problem is we need to pass an id to new ColumnFamily(...).  Not sure what the right fix is here.,,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/May/10 13:32;gdusbabek;0001-make-CassandraBulkLoader-compile.patch;https://issues.apache.org/jira/secure/attachment/12444790/0001-make-CassandraBulkLoader-compile.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19980,,,Thu May 20 12:42:37 UTC 2010,,,,,,,,,,"0|i0g2rj:",91878,,,,,Low,,,,,,,,,,,,,,,,,"17/May/10 18:13;gdusbabek;I don't see anything that needs to be done here, except maybe some documentation along the lines of ""make sure your schema is set up.""

CBL only accesses the cluster via fat client, which collects schema info via gossip.;;;","17/May/10 19:03;jbellis;the call to the CF constructor no longer compiles;;;","18/May/10 23:58;jbellis;+1;;;","20/May/10 12:42;hudson;Integrated in Cassandra #441 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/441/])
    make CassandraBulkLoader compile. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1062
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Exception when run ""get Keyspace1.Standard1"" command in the CLI",CASSANDRA-1059,12463896,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,jamel.essoussi,jamel.essoussi,06/May/10 16:26,16/Apr/19 09:33,14/Jul/23 05:51,24/May/10 16:05,0.6.2,,Legacy/Tools,,0,bug,cassandra,cassandra-cli,cli,get,"Connected to: ""Test Cluster"" on 10.0.3.44/9160
cassandra> get Keyspace1.Standard1
line 0:-1 mismatched input '<EOF>' expecting '['
Exception in thread ""main"" java.lang.AssertionError
        at org.apache.cassandra.cli.CliClient.executeGet(CliClient.java:331)
        at org.apache.cassandra.cli.CliClient.executeCLIStmt(CliClient.java:74)
        at org.apache.cassandra.cli.CliMain.processCLIStmt(CliMain.java:213)
        at org.apache.cassandra.cli.CliMain.main(CliMain.java:270)",Linux,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/May/10 21:02;urandom;0001-input-errors-causes-cli-to-exit-w-AssertionErrors.txt;https://issues.apache.org/jira/secure/attachment/12445199/0001-input-errors-causes-cli-to-exit-w-AssertionErrors.txt",,,,,,,,,,,,,,1.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19979,,,Mon May 24 16:05:08 UTC 2010,,,,,,,,,,"0|i0g2qv:",91875,,,,,Low,,,,,,,,,,,,,,,,,"06/May/10 16:32;jbellis;this means you gave it an invalid command (you can't ""get"" an entire CF at once) and it didn't know how to give you a human-readable error from that.  ;;;","21/May/10 21:02;urandom;The attached patch replaces the assert for {{get}}, {{set}}, {{del}}, and {{count}} with a return so that fat fingering a command isn't fatal.;;;","24/May/10 15:57;jbellis;+1;;;","24/May/10 16:05;urandom;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Login information stored in threads may be reused.,CASSANDRA-1057,12463842,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,kenmacd,kenmacd,kenmacd,06/May/10 02:25,16/Apr/19 09:33,14/Jul/23 05:51,06/Jun/10 04:53,0.6.3,,,,0,thrift,,,,,"CassandraServer stores the login information in a ThreadLocal<AccessLevel>.

CassandraDaemon starts the server with 64 threads. When the first 64 clients connect they should get their own thread, but after that threads will be reused.

In a quick test I created a Server with 5 threads, and a ThreadLocal<Integer>, and the value is seen by new clients connecting.

Thrift doesn't destroy the threads when a client disconnects. Maybe an option in Thrift would make more sense to make this method usable.",,kenmacd,kingryan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,kenmacd,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19978,,,Sun Jun 06 04:53:08 UTC 2010,,,,,,,,,,"0|i0g2qf:",91873,,,,,Low,,,,,,,,,,,,,,,,,"07/May/10 03:52;kenmacd;One solution would be to create your own TThreadPoolServer so you can replace the ExecutorService with one that overrides the afterExecute() method and clears out the ThreadLocal data.

I'm trying to figure out the best way to accomplish this, but TThreadPoolServer is all private, so the only way to replace the ExecutorService is to copy/paste it, or use reflection.

If you create the ExecutorService in the CassandraDaemon and pass it into the new TThreadPoolServer you'll have access to the CassandraServer to call the logout() method on it (once you write the simple logout to clean the ThreadLocal data).

If I find a good solution I'll post a patch. How against using reflection are you?;;;","07/May/10 04:37;jbellis;I don't see any reason why Thrift wouldn't accept a patch adding a TTPS constructor that takes an ES as an argument.  Want to submit one and ask Bryan for review?  (He's the main java committer.);;;","28/May/10 17:06;jbellis;Any progress on the Thrift front, Kenny?;;;","28/May/10 17:26;kenmacd;Not really. I sent a patch to the thrift-user list, but didn't receive a reply on it. I also cloned the thrift repo on github and was working on this patch:

http://github.com/KenMacD/thrift/commit/0ac9a2dc17326411212a02b201bc7ef969cea9c7

I haven't had a lot of time to look at it lately though. I was going to look at if it made sense to add builder to the other servers. 
Thrift 0.3 is about to come out, so maybe I'll see if I can get them to include a fix before 0.4. 

As a workaround in another project I work on I copied the TThreadPoolServer and was using my own version. You can see my workaround @:

http://github.com/ted/ted/commit/f4784c7adee2ff02bab51f529b190a4b16066e7c

This TThreadPoolServer takes an ExecutorService in which I override the afterExecute() to call my logout() on the thread. Seems to work well.
;;;","28/May/10 18:10;jbellis;It would be nice to have a workaround in Cassandra 0.6.3.  Can you submit a patch with you TTPS modification?;;;","28/May/10 20:06;kenmacd;Sure, I should be able to attach a patch tomorrow morning.;;;","29/May/10 13:16;kenmacd;Patch is available on my GitHub:

http://github.com/KenMacD/cassandra/commit/83e6917b23ca31f354c0baf4aa3dc014268626b2

I only tested it by running on the unit tests, so you'll probably want to give it a more real test.;;;","04/Jun/10 02:59;jbellis;I confess: I couldn't figure out how to get a patch from that link, to apply to apache svn.;;;","04/Jun/10 13:02;kenmacd;:)

Please try this link instead:

http://github.com/KenMacD/cassandra/commit/83e6917b23ca31f354c0baf4aa3dc014268626b2.diff

If that still doesn't work let me know and I'll send you a copy in email.;;;","06/Jun/10 04:53;jbellis;committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
size of row in spanned index entries does not include key bytes,CASSANDRA-1056,12463828,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,05/May/10 22:54,16/Apr/19 09:33,14/Jul/23 05:51,10/May/10 14:36,0.6.2,,,,0,,,,,,"from Anty on the mailing list,

In source code of 0.6.1 ,in SSTableWriter,
private void afterAppend(DecoratedKey decoratedKey, long dataPosition, int dataSize) throws IOException
    {
        String diskKey = partitioner.convertToDiskFormat(decoratedKey);
        bf.add(diskKey);
        lastWrittenKey = decoratedKey;
        long indexPosition = indexFile.getFilePointer();
        indexFile.writeUTF(diskKey);
        indexFile.writeLong(dataPosition);
        if (logger.isTraceEnabled())
            logger.trace(""wrote "" + decoratedKey + "" at "" + dataPosition);
        if (logger.isTraceEnabled())
            logger.trace(""wrote index of "" + decoratedKey + "" at "" + indexPosition);

        indexSummary.maybeAddEntry(decoratedKey, dataPosition, dataSize, indexPosition, indexFile.getFilePointer());
    }
the value of ""dataSize"" is the length of value( column family) ,not including the length of key.

but in  the method  loadIndexFile() of SStableReader
...
    else
                {
                    input.readUTF();
                    nextDataPosition = input.readLong();
                    input.seek(nextIndexPosition);
                }
                indexSummary.maybeAddEntry(decoratedKey, dataPosition, nextDataPosition - dataPosition, indexPosition, nextIndexPosition);
            }
            indexSummary.complete();


the value of nextDataPosition - dataPosition is the length of key and value ,not just the length of value .

",,bendiken,schubertzhang,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/May/10 22:55;jbellis;1056.txt;https://issues.apache.org/jira/secure/attachment/12443790/1056.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19977,,,Mon May 10 14:36:38 UTC 2010,,,,,,,,,,"0|i0g2q7:",91872,,,,,Low,,,,,,,,,,,,,,,,,"05/May/10 22:55;jbellis;unit test + fix;;;","10/May/10 14:34;jbellis;Anty writes on dev list: ""I have reviewed the patch,and have done test on my litter luster, all is good."";;;","10/May/10 14:36;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
isSuper flag in cfstore is wrongly set in 0.7,CASSANDRA-1054,12463809,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,slebresne,slebresne,05/May/10 19:22,16/Apr/19 09:33,14/Jul/23 05:51,05/May/10 19:40,0.7 beta 1,,,,0,,,,,,"In 0.7, following CASSANDRA-16, the isSuper in ColumnFamilyStore is not set correctly (if I'm correct). 
This is because when the model is applied (AddColumnFamily.applyModels()) the columnFamilyStore
is created before the call to DataDescriptor.setTableDefinition. But the createColumnFamilyStore() 
function retrieve the columnType. This thus always return a null that end up in a ""Super"".equals(null)
that always sets the flag to false.
That being said, the isSuper flag of columnFamilyStore is never used. 
I propose thus to get ride of this flag completely since if needed in the future, the column type can 
always be retrieved from the table and cfname directly (the attached patch do just that).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/May/10 19:24;slebresne;0001-Removing-unused-and-wrongly-set-isSuper-flag-in-cfst.patch;https://issues.apache.org/jira/secure/attachment/12443755/0001-Removing-unused-and-wrongly-set-isSuper-flag-in-cfst.patch",,,,,,,,,,,,,,1.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19976,,,Wed May 05 19:40:40 UTC 2010,,,,,,,,,,"0|i0g2pr:",91870,,,,,Low,,,,,,,,,,,,,,,,,"05/May/10 19:40;jbellis;committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Too many splits for ColumnFamily with only a few rows,CASSANDRA-1050,12463697,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,johanoskarsson,joosto,joosto,04/May/10 19:31,16/Apr/19 09:33,14/Jul/23 05:51,25/May/10 07:41,0.7 beta 1,,,,0,hadoop,keyspace,split,,,"ColumnFamilyInputFormat creates splits for the entire Keyspace.  If one ColumnFamily has 100 Million rows and another has only 100 rows, the number of splits will be the 1,526 (assuming 64k rows per split) for either one, since it is based on the total number of unique keys across the whole keyspace, and not on the number of rows in the ColumnFamily.",,anty,bendiken,johanoskarsson,joosto,,,,,,,,,,,,,,,,,,,,,,,,,"24/May/10 20:08;johanoskarsson;CASSANDRA-0.6-1050.patch;https://issues.apache.org/jira/secure/attachment/12445374/CASSANDRA-0.6-1050.patch","21/May/10 14:15;johanoskarsson;CASSANDRA-1050.patch;https://issues.apache.org/jira/secure/attachment/12445169/CASSANDRA-1050.patch",,,,,,,,,,,,,2.0,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19975,,,Tue May 25 13:22:28 UTC 2010,,,,,,,,,,"0|i0g2p3:",91867,,,,,Normal,,,,,,,,,,,,,,,,,"21/May/10 14:15;johanoskarsson;This patch for trunk should help with the problem. Run ant gen-thrift-java as the generated code is not in the patch.
I ran the word count test and that worked, have not had time to try it in the scenario described in the ticket though.;;;","21/May/10 14:32;jeromatron;I wonder if this would address the problem in CASSANDRA-1042.  I'll give it a try and see.;;;","21/May/10 16:59;jeromatron;Johan - I applied this patch on my local trunk and ran the word count on it - I get perfect results on all but the /tmp/wordcount3 - that gets 1006 instead of 1000.  It looks like it resolves many of the issues that were happening with CASSANDRA-1042 though.;;;","24/May/10 15:59;jbellis;+1;;;","24/May/10 20:08;johanoskarsson;Slightly modified version for 0.6;;;","24/May/10 22:45;jbellis;Belatedly realized that if we're changing the [thrift] method signature we should leave it alone in the stable 0.6 series.  let's just commit to trunk.  Sorry about the extra work.;;;","25/May/10 07:41;johanoskarsson;Committed to trunk.;;;","25/May/10 12:32;jbellis;btw, if you build the thrift code with ""ant gen-thrift-java"" it will re-run rat for you to avoid blowing away the apache license headers in the generated code;;;","25/May/10 12:56;hudson;Integrated in Cassandra #445 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/445/])
    Hadoop input format now uses the specified column family to figure out the number of splits instead of the whole keyspace. Patch by johan, review by jbellis. CASSANDRA-1050
;;;","25/May/10 13:22;johanoskarsson;I usually do, but my default thrift installation is 0.2.0 (used in all my other projects) and this required a newer version.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SlicePredicate does not always round-trip correctly,CASSANDRA-1049,12463696,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,04/May/10 19:29,16/Apr/19 09:33,14/Jul/23 05:51,24/May/10 19:45,0.6.2,,,,0,,,,,,,,anty,scottfines,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/May/10 18:59;jbellis;1049-0.6.txt;https://issues.apache.org/jira/secure/attachment/12445367/1049-0.6.txt","04/May/10 19:48;jbellis;1049-test.txt;https://issues.apache.org/jira/secure/attachment/12443620/1049-test.txt","24/May/10 18:11;jbellis;1049.txt;https://issues.apache.org/jira/secure/attachment/12445359/1049.txt","13/May/10 13:50;scottfines;SliceRangeSerializationTest.java;https://issues.apache.org/jira/secure/attachment/12444399/SliceRangeSerializationTest.java",,,,,,,,,,,4.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19974,,,Mon May 24 19:45:54 UTC 2010,,,,,,,,,,"0|i0g2ov:",91866,,,,,Normal,,,,,,,,,,,,,,,,,"04/May/10 19:48;jbellis;converted Mark Schnitzius's example from the ML to a failing unit test;;;","04/May/10 21:37;jbellis;Jeremy reports that he can reproduce using Thrift 0.3 rc, too.;;;","13/May/10 13:48;scottfines;I can confirm that this is also an issue with SliceRange itself, not just with SlicePredicate. I am attaching my UnitTest to this report as well(Though perhaps it should be set as a linked Issue instead).

I'm a bit new to Cassandra, so please let me know if there is something amiss with this unittest.;;;","17/May/10 16:05;jbellis;The bug is, thrift json serialization is broken.

patch to switch to using binary serializer, converted to a hex string.  inefficient but this is not a performance-sensitive method.;;;","24/May/10 16:22;urandom;Can you rebase please?;;;","24/May/10 18:11;jbellis;rebased;;;","24/May/10 18:38;jbellis;rebased to 0.6;;;","24/May/10 18:59;jbellis;0.6 patch w/ unit test;;;","24/May/10 19:30;urandom;+1;;;","24/May/10 19:45;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NameSortTest.testNameSort100 fails,CASSANDRA-1044,12463547,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,johanoskarsson,johanoskarsson,03/May/10 09:09,16/Apr/19 09:33,14/Jul/23 05:51,22/May/10 17:18,,,,,0,,,,,,"The hudson build is failing due to this test failing: NameSortTest.testNameSort100
http://hudson.zones.apache.org/hudson/job/Cassandra/422/testReport/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19971,,,Mon May 03 13:35:42 UTC 2010,,,,,,,,,,"0|i0g2nr:",91861,,,,,Normal,,,,,,,,,,,,,,,,,"03/May/10 13:35;gdusbabek;I went ahead and committed a change to increase the timeout to 60s to see if that helps.  That test takes nowhere near 30s on my development machine though, so I don't know what hudson's problem is.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ColumnFamilyRecordReader returns duplicate rows,CASSANDRA-1042,12463494,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,joosto,joosto,01/May/10 16:18,16/Apr/19 09:33,14/Jul/23 05:51,19/Jul/10 19:53,0.6.5,,,,0,hadoop,mapreduce,,,,"There's a bug in ColumnFamilyRecordReader that appears when processing a single split (which happens in most tests that have small number of rows), and potentially in other cases.  When the start and end tokens of the split are equal, duplicate rows can be returned.

Example with 5 rows:
token (start and end) = 53193025635115934196771903670925341736

Tokens returned by first get_range_slices iteration (all 5 rows):
 16955237001963240173058271559858726497
 40670782773005619916245995581909898190
 99079589977253916124855502156832923443
 144992942750327304334463589818972416113
 166860289390734216023086131251507064403

Tokens returned by next iteration (first token is last token from
previous, end token is unchanged)
 16955237001963240173058271559858726497
 40670782773005619916245995581909898190

Tokens returned by final iteration  (first token is last token from
previous, end token is unchanged)
 [] (empty)

In this example, the mapper has processed 7 rows in total, 2 of which
were duplicates.

",,anty,bryantower,cbiocca,greglu,johanoskarsson,stuhood,,,,,,,,,,,,,,,,,,,,,,,"25/Jun/10 23:41;jeromatron;1042-0_6.txt;https://issues.apache.org/jira/secure/attachment/12448109/1042-0_6.txt","10/Jul/10 19:30;jbellis;1042-test.txt;https://issues.apache.org/jira/secure/attachment/12449166/1042-test.txt","19/Jul/10 15:49;jbellis;1042-v2.txt;https://issues.apache.org/jira/secure/attachment/12449851/1042-v2.txt","27/May/10 16:29;jeromatron;CASSANDRA-1042-trunk.patch.txt;https://issues.apache.org/jira/secure/attachment/12445670/CASSANDRA-1042-trunk.patch.txt","27/May/10 16:29;jeromatron;Cassandra-1042-0_6-branch.patch.txt;https://issues.apache.org/jira/secure/attachment/12445671/Cassandra-1042-0_6-branch.patch.txt","20/May/10 23:32;jeromatron;cassandra.tar.gz;https://issues.apache.org/jira/secure/attachment/12445117/cassandra.tar.gz","01/Jul/10 16:33;jeromatron;duplicate_keys.rtf;https://issues.apache.org/jira/secure/attachment/12448502/duplicate_keys.rtf",,,,,,,,7.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19970,,,Thu Aug 05 12:40:54 UTC 2010,,,,,,,,,,"0|i0g2nb:",91859,,,,,Normal,,,,,,,,,,,,,,,,,"01/May/10 17:02;jbellis;This sounds like something we could make a unit test for, without having to get Hadoop itself involved.;;;","03/May/10 16:38;cbiocca;The basic issue is that the thrift server's return value is sorted by the absolute value of the tokens, while the CassandraRecordReader assumes that the order is the one given by traversal of the range (that is, we get the smallest value greater than start_token in first position, and the greatest value smaller than or equal to end_token in last position. 
Now I don't know which is correct, as the API docs I've looked at don't suggest which order is supposed to be returned, but if the server's implementation is correct, then the record reader needs to iterate over the returned tokens to figure out which one is actually the last token for iteration purposes. Otherwise, switching the server's implementation to return keys in the iteration order will work.;;;","14/May/10 15:02;jeromatron;Hmm, I was able to reproduce this with the contrib/word_count piece on trunk.  It appears to double count rows in ranges that have a single row as well as those that have more - in this case 1000.;;;","14/May/10 22:58;jeromatron;Just some more data - when I use an OrderPreservingPartioner, the word count works fine...;;;","17/May/10 22:25;jeromatron;For the describe_splits call it makes, it returns 3 sub splits, the first of which is a wrapping split.  Sounds like it's buggy on the server side.  Will check with Jonathan.;;;","18/May/10 15:11;jeromatron;Jonathan:

Inputs to client.describe_splits() - ColumnFamilyInputSplit:185:
range.start_token: 85469146195799762548951268272529359452
range.end_token: 85469146195799762548951268272529359452
splitsize: 65536

output:
splits - arraylist<String>:
0: 85469146195799762548951268272529359452
1: 85469146195799762548951268272529359452

Seems like that is the bug right there, but not familiar enough with what it's supposed to do in that case?

Btw, there are only 4 rows in the CF.;;;","18/May/10 21:45;jeromatron;Appears to be something server related in the splits themselves.;;;","20/May/10 23:32;jeromatron;In order to facilitate reproducing the problem, I'm attaching my cassandra data directory tar/gzed up.

There are 4 rows in the cassandra instance.  If you modify WordCountSetup to change TEST_COUNT from 4 to 1, then run WordCount, you will find that Cassandra trunk will count 7 occurrences instead of 4.  You can also debug on the line I mentioned previously to see what describe_splits receives and then outputs.

Just wanted to facilitate reproducing the problem.;;;","26/May/10 23:05;jeromatron;Adding a patch that does the following:

1. Removes an ordering section in StorageProxy that messes with the wrapping range for a get_range_slice call - thereby messing up the order of the records returned.  That led to having the initial wrapping range returned in token order instead of wrapping order.  So there was a second call going from last token as far as natural ordering goes, all the way to the initial start token.  So if the server's token were 5, and there were 10 tokens, it would list 1-10, then 1-5 again.  With this fix, the return order of the tokens is 6-10, then 1-5, which is correct - the order of the wrapped range, then in token order.

2. A few instances of token.toString should have been TokenFactory.toString(token) - fixed.

3. There was a method in StorageService - getStringEndpointMap - that is never call - removed that.

4. Updated WordCountSetup with the latest trunk to use new Clock(System.currentTimeMillis());;;","26/May/10 23:08;jeromatron;Tx to Stu Hood for helping me narrow this down.;;;","26/May/10 23:12;jeromatron;To clarify: to fix the problem - this removes some ordering in StorageProxy.getRangeIterator since getRestricedRanges should already have returned the right thing.;;;","27/May/10 02:03;jbellis;Looks good to me.  Nice work, Jeremy and Stu.

Can you submit a version against 0.6 branch too?;;;","27/May/10 16:29;jeromatron;Attaching patches for 0.6-branch and trunk.;;;","27/May/10 16:31;jeromatron;Jonathan - I updated the trunk patch to not add a couple of unused imports that snuck in while I was messing with WordCount.;;;","27/May/10 16:34;jeromatron;Also - I didn't remove StorageService.getStringEndpointMap in the 0.6 branch version because CassandraServer.get_string_property still calls it.  get_string_property was removed on trunk as part of CASSANDRA-965;;;","27/May/10 18:59;jbellis;committed, thanks!;;;","27/May/10 19:50;jbellis;done;;;","25/Jun/10 18:51;jbellis;re-opening in light of CASSANDRA-1198;;;","25/Jun/10 23:41;jeromatron;Unwrapped the tokens in the first place ensuring that the splits would not contain wraps.  Works fine now.;;;","25/Jun/10 23:41;jeromatron;Attaching new patch.;;;","25/Jun/10 23:43;jeromatron;The patch should apply cleanly to 0.7/trunk as well;;;","26/Jun/10 00:30;stuhood;+1;;;","26/Jun/10 00:33;jbellis;do we have a theory as to why wrapped ranges should cause bugs?

i worry that if we're just trying code out and it seems to work, that we may not be fixing the real problem;;;","26/Jun/10 00:48;jeromatron;Good point.

From what I could tell in this instance, it would go through the input splits and on the last input split, it would have an incorrect last value.  So it would go back through and take that value to the end of the input list.  I would imagine that is where it had wrapped.  I'm not sure why it had the incorrect last value as the last value in the wrapped input split though.  If someone is wiser than I in these matters, please chime in.  But it appears that normalizing how the splits are done so one split does not wrap internally, it solves the problem.

To reproduce easily and with a small dataset: If you don't apply the patch and run the word_count_setup with only 10 values for text3, usually that will be enough to manifest the problem when running wordcount.

Also, I might think that if the wrap could be detected when creating the splits, as with this patch, then it makes sense that wrapping could be detected when reading the rows in the ColumnFamilyRecordReader.  That could be another way to resolve it.  But I think it's sixes when it comes to the solution.

Like I said, I'm not certain why that incorrect ordering happens on the wrapped split.;;;","01/Jul/10 16:33;jeromatron;Adding the output of word count with duplicate tokens.  It appears to happen when the input split contains a wrapped key range.  That's why the updated patch splits wrapped key ranges (fixing the problem).;;;","06/Jul/10 20:16;jeromatron;Sorry if this is redundant but pasting in a thought we had a while ago that motivated the attached patch.  If we make sure that the splits are always in ring order and never wrap, it solves the problem.

""Token ranges may also wrap -- that is, the end token may be less than the start one. Thus, a range from keyX to keyX is a one-element range, but a range from tokenY to tokenY is the full ring.""

It does not say what order they will be in when it wraps.  Some clients assume that the ordering is natural order while the hadoop client interactions assume that it will be ring order.

For example:
-- a list of tokens (1,2,3,4,5,6,7,8,9)
-- a get_range_slice call with start_token = 5, end_token = 5
Natural order meaning token order from start to finish, returning the results (1,2,3,4,5,6,7.8,9).
Ring order or wrapping order meaning it would return the results (5,6,7,8,9,1,2,3,4).;;;","06/Jul/10 20:20;jbellis;the ""correct"" order when tokens are involved is ring order

(when start_key is used instead of start_token, you can't have a wrapping range so it should be moot);;;","10/Jul/10 18:07;jbellis;patching CFIF isn't the answer, we need any client using the API to get the right results;;;","10/Jul/10 19:30;jbellis;it seems that the root of the problem is, as Jeremy said, rows getting returned in token order instead of ring order.  if, in joost's original example, the rows were returned in order of

99079589977253916124855502156832923443
144992942750327304334463589818972416113
166860289390734216023086131251507064403
16955237001963240173058271559858726497
40670782773005619916245995581909898190

then doing an extra query for (40670782773005619916245995581909898190, 53193025635115934196771903670925341736]

would return the desired result of nothing.

but I am unable to reproduce this behavior in a unit test (against 0.6 branch, attached).  trying jeremy's data dir (also against 0.6 branch), I get ""java.io.IOException: Found system table files, but they couldn't be loaded. Did you change the partitioner?"" ;;;","12/Jul/10 01:11;jbellis;Jeremy pointed out that the sorting that removed by the original patch here is sorting in raw token order rather than taking into account the requested start token.  I think that's our problem, although I'm not sure why my unit test isn't running into that.;;;","19/Jul/10 14:41;jbellis;ah, the unit test hits CFS directly instead of going through StorageProxy (where the sort happens)...;;;","19/Jul/10 15:49;jbellis;v2 attached:

 - removes wrapped-range handling from CFS.getRangeSlice, since StorageProxy always unwraps first
 - adds (initially failing) system test exercising wrapped-range path
 - adds sorting of unwrapped, restricted ranges relative to the original query range [this is the bug fix]
;;;","19/Jul/10 19:38;jeromatron;+1;;;","19/Jul/10 19:53;jbellis;committed;;;","05/Aug/10 12:40;jbellis;Backported a related fix from CASSANDRA-1156 to 0.6.5 in r982580;;;",,,,,,,,,,,,,,,,,,,,,,,,,,
read failure during flush,CASSANDRA-1040,12463432,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,jbellis,jbellis,jbellis,30/Apr/10 13:33,16/Apr/19 09:33,14/Jul/23 05:51,07/May/10 21:31,0.7 beta 1,,,,2,,,,,,"Joost Ouwerkerk writes:
	
On a single-node cassandra cluster with basic config (-Xmx:1G)
loop {
  * insert 5,000 records in a single columnfamily with UUID keys and
random string values (between 1 and 1000 chars) in 5 different columns
spanning two different supercolumns
  * delete all the data by iterating over the rows with
get_range_slices(ONE) and calling remove(QUORUM) on each row id
returned (path containing only columnfamily)
  * count number of non-tombstone rows by iterating over the rows
with get_range_slices(ONE) and testing data.  Break if not zero.
}

while this is running, call ""bin/nodetool -h localhost -p 8081 flush KeySpace"" in the background every minute or so.  When the data hits some critical size, the loop will break.",,anty,brandon.williams,greglu,johanoskarsson,joosto,schubertzhang,,,,,,,,,,,,,,,,,,,,,,,"07/May/10 21:14;jbellis;1040.txt;https://issues.apache.org/jira/secure/attachment/12443998/1040.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19969,,,Fri May 07 21:31:52 UTC 2010,,,,,,,,,,"0|i0g2mv:",91857,,,,,Critical,,,,,,,,,,,,,,,,,"06/May/10 03:28;jbellis;Brandon's code to reproduce:

{code}


#!/usr/bin/python
from telephus.protocol import ManagedCassandraClientFactory
from telephus.client import CassandraClient
from twisted.internet import defer

HOST = 'cassandra-6'
PORT = 9160
KEYSPACE = 'Keyspace1'
CF = 'Standard1'
SCF = 'Super1'
colname = 'foo'
scname = 'bar'

@defer.inlineCallbacks
def dostuff(client):
    while True:
        print ""inserting""
        for i in xrange(5000):
            yield client.insert(str(i), CF, 'test', column=colname)
        print ""removing""
        res = yield client.get_range_slice(CF, count=10000)
        for ks in res:
            if len(ks.columns) > 0:
                yield client.remove(ks.key, CF)
        print ""checking""
        res = yield client.get_range_slice(CF, count=10000)
        for ks in res:
            assert len(ks.columns) == 0
        print ""ok""

if __name__ == '__main__':
    from twisted.internet import reactor
    from twisted.python import log
    import sys
    log.startLogging(sys.stdout)

    f = ManagedCassandraClientFactory()
    c = CassandraClient(f, KEYSPACE)
    dostuff(c)
    reactor.connectTCP(HOST, PORT, f)
    reactor.run()
{code}
;;;","06/May/10 03:41;jbellis;Also:

{code}
for x in seq `1 1000`; do bin/nodetool -h `hostname` flush Keyspace1; sleep 5; done
{code};;;","07/May/10 18:32;stuhood;Independent of (but related to) this issue, ColumnFamilyStore.getRangeRows has a race condition in memtable handling. The order of operations that might trigger the problem is:
# Copy memtablesPendingFlush
# (new memtable becomes pending)
# Copy reference to current Memtable

Swapping 3. with 1. would prevent new memtables from being ignored, but would mean we might scan one memtable twice. Making 1. and 3. atomic would remove the race, but is a longer time to hold the lock than we are use to.

EDIT: this description only applies to trunk;;;","07/May/10 21:14;jbellis;Most of this was caused by the bug Stu found for CASSANDRA-1063, which has been committed separately.  Here is a patch to fix the trunk-only part explained above.  (We take the ""allow the original memtable to scanned twice occasionally"" approach, which is the one taken by getTopLevelColumns.);;;","07/May/10 21:26;stuhood;+1 for 1040.txt. Thanks!;;;","07/May/10 21:31;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Not all column families are created,CASSANDRA-1038,12463375,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,brandon.williams,brandon.williams,29/Apr/10 21:17,16/Apr/19 09:33,14/Jul/23 05:51,05/May/10 15:35,0.7 beta 1,,,,0,,,,,,"It seems that not all column families will be created via system_add_keyspace in some cases.  To reproduce:

Run stress.py (with CASSANDRA-1033) inserts (I used 1M) against standard columns.  During this run, both Standard1 and Super1 will be created.

Run stress.py again, this time against super columns.  Due to CASSANDRA-1036 no errors will be visible to the client but can be observed in the log.

You can switch the order and stress supers first, in which case Standard1 will not exist.  If you call describe_keyspace on Keyspace1, it will show both CFs even though only one will work.
",,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/May/10 22:22;gdusbabek;0001-restrict-how-and-when-CFMetaData-objects-are-added-t.patch;https://issues.apache.org/jira/secure/attachment/12443512/0001-restrict-how-and-when-CFMetaData-objects-are-added-t.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19968,,,Wed May 05 15:35:49 UTC 2010,,,,,,,,,,"0|i0g2mf:",91855,,,,,Normal,,,,,,,,,,,,,,,,,"03/May/10 22:22;gdusbabek;The problem was that when the keyspace creation was reattempted, identical CFMetaData objects were created that obliterated the older, correct cfids.

I could have put a check in the private CFMetaData constructor that threw an exception, but decided I'd rather have explicit control over cfIdMap instead.;;;","05/May/10 15:24;jbellis;+1;;;","05/May/10 15:35;gdusbabek;I forgot to include the ticket id in the commit msg, so hudson isn't going to adorn us with the svn rev.  It's r941349 for the curious.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Attempting to mutate a non-existant CF does not propagate an error to the client,CASSANDRA-1036,12463365,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,brandon.williams,brandon.williams,29/Apr/10 19:33,16/Apr/19 09:33,14/Jul/23 05:51,07/May/10 13:58,0.7 beta 1,,,,0,,,,,,"An error gets logged on the server:

ERROR 15:23:21,035 Attempting to mutate non-existant column family Standard1

But nothing is raised on the client side, so it appears the request succeeded.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/May/10 12:35;slebresne;1036-Validate-CF-for-deletion-in-mutation-map.patch;https://issues.apache.org/jira/secure/attachment/12443958/1036-Validate-CF-for-deletion-in-mutation-map.patch","07/May/10 12:47;slebresne;1036-v2-Validate-CF-for-deletion-in-mutation-map.patch;https://issues.apache.org/jira/secure/attachment/12443960/1036-v2-Validate-CF-for-deletion-in-mutation-map.patch",,,,,,,,,,,,,2.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19967,,,Fri May 07 13:58:04 UTC 2010,,,,,,,,,,"0|i0g2lz:",91853,,,,,Low,,,,,,,,,,,,,,,,,"07/May/10 12:35;slebresne;Attached patch should correct the problem.;;;","07/May/10 12:47;slebresne;Oups. Figured that I could add the validation to Avro too. Patch v2 attached.;;;","07/May/10 12:51;gdusbabek;Should we include a system test to verify?;;;","07/May/10 13:00;slebresne;You mean, for the avro part ? I'll have to admit that I'm not up to date on the avro part, 
but the avro system test for batch_mutate has a 
        # FIXME: still need to apply a mutation that deletes
so I was figuring that maybe that wasn't working yet. But I can have a look.;;;","07/May/10 13:14;gdusbabek;No.  I'm referring to test/system/test_thrift_server.py.  There are a few examples in there where a call is made and we expect an exception.  We should have a call like that where we attempt to mutate a non-existent CF and check to make sure an exception is received by the client.

See the usages of ""_expect_exception"".;;;","07/May/10 13:18;slebresne;The patch includes system tests for thrift. Or are those included not the ones you had in mind ?;;;","07/May/10 13:30;gdusbabek;My apologies.  For some reason I was expecting a git-style patch with a  listing of the modified files at the top.  I see the system test now.;;;","07/May/10 13:56;gdusbabek;+1.;;;","07/May/10 13:58;gdusbabek;Thanks for the patch!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove assumption that Key to Token is one-to-one,CASSANDRA-1034,12463287,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,stuhood,stuhood,29/Apr/10 03:21,16/Apr/19 09:33,14/Jul/23 05:51,01/Dec/11 10:14,1.1.0,,,,5,,,,,,"get_range_slices assumes that Tokens do not collide and converts a KeyRange to an AbstractBounds. For RandomPartitioner, this assumption isn't safe, and would lead to a very weird heisenberg.

Converting AbstractBounds to use a DecoratedKey would solve this, because the byte[] key portion of the DecoratedKey can act as a tiebreaker. Alternatively, we could make DecoratedKey extend Token, and then use DecoratedKeys in places where collisions are unacceptable.",,cburroughs,donal,jeromatron,leonardo.stern,mck,stinkymatt,stuhood,tjake,xedin,,,,,,,,,,CASSANDRA-1600,,,,,CASSANDRA-1978,CASSANDRA-1205,,,,"23/Nov/11 16:07;slebresne;0001-Generify-AbstractBounds-v2.patch;https://issues.apache.org/jira/secure/attachment/12504886/0001-Generify-AbstractBounds-v2.patch","30/Nov/11 10:44;slebresne;0001-Generify-AbstractBounds-v3.patch;https://issues.apache.org/jira/secure/attachment/12505606/0001-Generify-AbstractBounds-v3.patch","18/Nov/11 14:20;slebresne;0001-Generify-AbstractBounds.patch;https://issues.apache.org/jira/secure/attachment/12504214/0001-Generify-AbstractBounds.patch","23/Nov/11 16:07;slebresne;0002-Remove-assumption-that-token-and-keys-are-one-to-one-v2.patch;https://issues.apache.org/jira/secure/attachment/12504887/0002-Remove-assumption-that-token-and-keys-are-one-to-one-v2.patch","30/Nov/11 10:44;slebresne;0002-Remove-assumption-that-token-and-keys-are-one-to-one-v3.patch;https://issues.apache.org/jira/secure/attachment/12505607/0002-Remove-assumption-that-token-and-keys-are-one-to-one-v3.patch","18/Nov/11 14:20;slebresne;0002-Remove-assumption-that-token-and-keys-are-one-to-one.patch;https://issues.apache.org/jira/secure/attachment/12504215/0002-Remove-assumption-that-token-and-keys-are-one-to-one.patch","23/Nov/11 16:07;slebresne;0003-unit-test-v2.patch;https://issues.apache.org/jira/secure/attachment/12504888/0003-unit-test-v2.patch","30/Nov/11 10:44;slebresne;0003-unit-test-v3.patch;https://issues.apache.org/jira/secure/attachment/12505608/0003-unit-test-v3.patch","18/Nov/11 14:20;slebresne;0003-unit-test.patch;https://issues.apache.org/jira/secure/attachment/12504216/0003-unit-test.patch","09/Nov/10 05:19;tjake;1034_v1.txt;https://issues.apache.org/jira/secure/attachment/12459138/1034_v1.txt","10/Oct/11 20:42;xedin;CASSANDRA-1034.patch;https://issues.apache.org/jira/secure/attachment/12498465/CASSANDRA-1034.patch",,,,11.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,14985,,,Thu Dec 01 10:14:43 UTC 2011,,,,,,,,,,"0|i0g2lj:",91851,,jbellis,,jbellis,Low,,,,,,,,,,,,,,,,,"29/Apr/10 04:12;jbellis;The problem is that we are using DK both for routing and for local key sorting, partly because it's very convenient to be able to use the ""natural"" compareTo to compare those two kinds of DK.

If the only place we have DK with null key is for the routing case, then the right thing is to convert those usages to raw Tokens and make key non-optional in DK.

i have a nagging feeling that there are more complications though.;;;","29/Apr/10 04:13;stuhood;MD5 collisions are rare enough, so somebody would probably have to write their own partitioner to trigger this.;;;","09/Nov/10 04:54;jbellis;bq. it's very convenient to be able to use the ""natural"" compareTo to compare those two kinds of DK

In particular, we generate (Token, null) DKs for range scans, at least in part because Hadoop thinks in terms of TokenRanges instead of DecoratedKeyRanges.  (Presumably it is still ok to assume that a partitioner generates many more tokens than there are nodes in the cluster; if not, this would need to change.)

We might be able to still do this, if we just say that DK(T, null) always sorts before DK(T, non-null-key) for any given Token T.

I still suspect we're using DK in some places where Token is all we really need.;;;","09/Nov/10 05:19;tjake;Discovered the same issue with a partitioner that shares tokens for many keys.  This patch fixes the issue. all tests pass.;;;","09/Nov/10 16:14;stuhood;Jake's patch is only a partial fix for this problem, so I've moved it to #1720. The core of this ticket is either: changes to the class hierarchy, or changes to ranges.;;;","10/Nov/10 19:07;jbellis;Can you elaborate as to what else needs to be fixed?

As I said above, ""Presumably it is still ok to assume that a partitioner generates many more tokens than there are nodes in the cluster"" so I don't think we need to make Range a DK pair for granularity's sake.;;;","10/Nov/10 19:52;stuhood;> Can you elaborate as to what else needs to be fixed?
I guess the larger problem here is that if a range query asks for 10 rows using a Token range, but there are 1000 rows sharing a particular token, which 10 rows do you return?;;;","10/Nov/10 21:13;jbellis;Okay, so that is a problem because we create DK(Token, null) internally for range queries currently even when using the key-based API.

Once that is fixed I'm fine with saying ""the first 10"" (or if more convenient, ""that's undefined""), since only Hadoop or similar iterate-over-everything approaches should be using Token-based range queries at the API level.  (Again, I'm assuming that there are enough tokens to achieve sufficient granularity, iow, that the number of rows sharing a token is less than the InputSplit size.);;;","03/Mar/11 19:12;slebresne;Attaching a patch that I believe solves this. It makes Range accept both Token and DecoratedKey and makes those two compare together correctly.

It introduces a new marker interface (RingPosition) instead of making DecoratedKey extends Token (for reason explained in the comments of RingPosition but to sum up: I think it's cleaner).

The second patch attached is just a stupid partitioner that use for token the length of the key. It's just for testing and not meant for inclusion. But this shows that with the first patch, you can do correct range query that go from 'the middle of a token' to the 'middle of another one'.

An important note is that this breaks the serialization unit tests, because now an AbstractBounds can use decoratedKeys, and thus serialized AbstractBounds are incompatible with previous version. Not sure how to deal with that though, I though we had a plan for dealing with that but I'll admit I don't remember the details.;;;","16/Mar/11 14:53;slebresne;Patch rebased;;;","24/Mar/11 09:47;slebresne;Rebased patch with code for binary backward compatibility. This still needs the first part of CASSANDRA-2361 to fully pass the serialization unit tests.;;;","25/Mar/11 17:43;jbellis;What is LengthPartitioner for?;;;","25/Mar/11 18:22;slebresne;Oh, it's just a stupid partitioner with tons of collision (and predictable ones) that I used for testing and attached so that other can test too. Not meant for inclusion.;;;","25/Mar/11 18:58;jbellis;Initial feedback:

- I'm a fan of the RingPosition approach
- Less of a fan of pretending that Tokens and DK are equal if the token component of DK is equal.  Shouldn't we force caller to ask Token.equals(DK.token) if that's what they mean? As you pointed out in RP docstring, there is not an is-a relationship there.
- Should we add RP.isToken to encapsulate RP.asDecoratedKey.key == null checks?
- DK docstring is obsolete now
;;;","25/Mar/11 19:24;slebresne;bq. Less of a fan of pretending that Tokens and DK are equal if the token component of DK is equal. Shouldn't we force caller to ask Token.equals(DK.token) if that's what they mean? As you pointed out in RP docstring, there is not an is-a relationship there.

The thing is, we need them to be equal for compareTo() (because we can't have token > keys nor token < keys, otherwise that would mess up our ranges). Then for the equals, the motivation is summed up by the Comparable documentation:
{noformat}
It is strongly recommended (though not required) that natural orderings be consistent with equals. This is so because sorted sets (and sorted maps) without explicit comparators behave ""strangely"" when they are used with elements (or keys) whose natural ordering is inconsistent with equals. In particular, such a sorted set (or sorted map) violates the general contract for set (or map), which is defined in terms of the equals method.
{noformat}
And I do fear that we would get something inconsistent at some point.
But I'm not a super fan either, just felt the less evil of the two choices.
I'm happy with suggestion though and I'll work out the other remarks.

;;;","25/Mar/11 19:39;jbellis;I understand the Comparable docs, but 
- that's primarily concerned w/ compareTo + equals b/t members of the same class
- it's valid to say ""these are tied for sorting purposes, and yet they are not equal""

In other words I'm more worried about subtle bugs if we allow the equals, than if we don't. :)

The Map example is a good one -- if I set

map[token(1)] = foo
map[dk(1, 1)] = bar

I would expect two map entries, not one.  (If you want one, you explicitly use asToken, then there is no ambiguity.)

How about if we add an assert to both equals to make sure we don't pass in the other kind of object?;;;","25/Mar/11 19:44;slebresne;You're right, I'm convinced, it's probably safer to have equals be a true equals.
I'll do the change.;;;","26/Mar/11 10:13;stuhood;I was reaaally hoping we could subclass here... adding RingPosition leads to explicit conversions scattered all over that end up obscuring  implicit conversions.

The hairiest part of subclassing would be renaming all of our Token subclasses with DecoratedKey subclasses, but it cleans up unnecessary references: for example, for a DecoratedKey for ByteOrderPartitioner or LocalPartitioner you have:
{code}
DecoratedKey
   BytesToken token;
      ByteBuffer token;
   ByteBuffer key;
{code}
... while with subclassing you could save two object references:
{code}
DecoratedKey
   ByteBuffer keyAndToken;
{code}

Also, the Comparable dilemma is relatively straightforward with subclassing: Token implements Comparable<Token>, the subclasses override, call super.compare, and if their superclass is equal, fall back to instanceof(myclass) to see whether they can compare the key data.;;;","30/Mar/11 15:21;slebresne;I realize that this is a little more subtle than I first though.

You just cannot compare a Token and a DecoratedKey simply, because a Token is actually a range of keys. Hence dealing with a Range that mixes Token and DecoratedKey correctly is doable, but a bit complicated (typically, it involves declaring multiple different comparison functions). To take quick example, consider that if you mix DK and Token, you must have the following that stands:
{noformat}
    (T(2), T(8)] should not contain DK(T(2), ""foo"") => DK(T(2), ""foo"") < T(2)
    [T(2), T(8)] should contain     DK(T(2), ""foo"") => DK(T(2), ""foo"") >= T(2)
{noformat}
So there is no way to write a compareTo() function dealing with both DK and token.

So I think that it will be simplest to not mix DK and Token in the same ranges. We'll have ranges of Token (for everything related to ring management) and ranges of DK (for rangeSlice and scan). This is what the patch does (and the patch 'generify' AbstractBounds, Range and Bounds (a fair part of the patch) to keep type information around and avoid unnecessary casts all over the place).

We still want to make a rangeSlice/scan over a range of token. To do that, we simply convert a range of Token to a range of DK. This involves declaring for a given token a smallest key and biggest key, and this in turn comes a slight complication related to the minimum token, but the detail are in the docstrings of the patch. I am reasonably confident on that new patch.

(Note that this patch is much bigger than the previous one, but this is mostly due to the generification of Range);;;","30/Mar/11 18:57;jbellis;Can you break the generification out into a separate patch?;;;","01/Apr/11 17:08;slebresne;Generification broken into a separate patch + some tiny code style update;;;","04/Apr/11 16:16;slebresne;Attaching v2 for my second patch. There was some failure in the unit tests for getRestrictedRanges. This fix and improves those test and fix a small bug related to the handling of the minimum value for DecoratedKey.;;;","04/Apr/11 16:18;jbellis;I think we are almost done.  A couple comments:

- DK.isEmpty seems like a bad method name for a Key object -- intuitively, keys are a specific point and should not contain other points except for the obvious identity case.  Would isMinimum be a better name? 
- I don't understand RP.toSplitValue or why DK would throw away information, when calling it.  More generally, I'm unclear why we would have null keys in DK -- shouldn't you use a Token, if you don't have key information?
- using MINIMUM_TOKEN for both sort-before-everything and sort-after-everything values has always been confusing.  Should we introduce a MAXIMUM_TOKEN value to clear that up?;;;","04/Apr/11 21:44;slebresne;Reattaching v2, previous had a stupid mistake, sorry about that.;;;","07/Apr/11 16:24;slebresne;bq. DK.isEmpty seems like a bad method name for a Key object – intuitively, keys are a specific point and should not contain other points except for the obvious identity case. Would isMinimum be a better name?

Actually I don't even like isEmpty for token, so in favor of isMinimum for both DK and token.

bq.  don't understand RP.toSplitValue or why DK would throw away information, when calling it. More generally, I'm unclear why we would have null keys in DK – shouldn't you use a Token, if you don't have key information?

Current patch don't allow to mix token and DK in a range/bounds (because that comes with its whole sets of complications). However getRestrictedRange must be able to break a range of DK based on a node token. So RP.toSplitValue() returns for a given token the value that splits the range: for a token range it's the token itself, but for a DK range, it's the largest DK having this token.
The null keys is related: even though we don't mix DK and token in range, we need to be able to have a range of DK that includes everything from x token to y token. Hence, for a given token t, we need two DK: the smallest DK having t and the biggest DK having t. In the patch, slightly but not totally randomly, I use DK(t, EMPTY_BB) for the smallest key and DK(t, null) for the biggest one, hence the ""need"" for null keys. 

bq. using MINIMUM_TOKEN for both sort-before-everything and sort-after-everything values has always been confusing. Should we introduce a MAXIMUM_TOKEN value to clear that up?

I think that would make wrapping stuffs more complicated. Because then what would be the difference between the following ranges: (MIN, MIN], (MAX, MAX], (MIN, MAX] and (MAX, MIN]. For DK, the code is already enforcing that the we only have one minimum key (that is DK(MIN, EMPTY_BB)) and never ever use DK(MIN, null) because that poses problems. I think a MAX token would make that worst. ;;;","08/Apr/11 20:55;jbellis;bq. RP.toSplitValue() returns for a given token the value that splits the range: for a token range it's the token itself, but for a DK range, it's the largest DK having this token. The null keys is related: even though we don't mix DK and token in range, we need to be able to have a range of DK that includes everything from x token to y token

This feels messy and error-prone to me. I wonder if we haven't found the right approach yet.;;;","09/Apr/11 20:07;stuhood;I agree that using null is a necessary solution here: you need a max value for keys, since they are essentially the ""child"" of a one-token-range. The key range is bounded (since it has parents), but the token range is not, so I agree with sylvain that a MAX_TOKEN is probably not necessary.

One way to remove toSplitValue would be to use DecoratedKey everywhere; DecoratedKey is a compound of the Token and the key blob. The equivalent of today's Token is a DecoratedKey for that token with a null key: it compares greater than all valid child keys, so it contains them.

I hope that it won't muddy the water, but the <empty> as min and <null> as max approach is the same one I took forthe first cut of the file-format, and it worked very well. You can use the min/max values to find the beginning or end of a child range. See [ColumnKey.java|https://github.com/stuhood/cassandra-old/blob/674/src/java/org/apache/cassandra/db/ColumnKey.java#L225]

EDIT: Actually... I'm not so sure about not having MAX_TOKEN... it might actually clean things up quite a bit. Any time a range ends with what use to be the min token, you can make a direct translation to MAX_TOKEN.;;;","09/Jun/11 11:01;slebresne;Patch rebased, this is against trunk.;;;","09/Jun/11 11:32;slebresne;bq. One way to remove toSplitValue would be to use DecoratedKey everywhere;

I'm not saying it's not possible, but I think this is overkill (in the changes it involves). Moreover, all the code that deals with topology really only care about token. That's the right abstraction for those part of the code. So I really (really) doubt using decorated key everywhere would be cleaner. Of course, anyone is free to actually do the experiment and prove me wrong. I also don't think it would remove the need for splitValue, it would just maybe call it differently.

bq. The equivalent of today's Token is a DecoratedKey for that token with a null key

This is only true today because we assume key and token are one-to-one. The goal is to change that. If multiple keys can have the same token (by definition the token is really the hash of a key), then the statement above is false. If a token correspond to an infinite set of key (with is the case with md5 btw, we just ignore it), then replacing a token by given key *cannot* work.

Overall, it could be that there is better way to do this, but having spend some time on this, I have a reasonable confidence on that it fixes the issue at hand without being too disruptive (which is not saying there isn't a few points here and there that couldn't be improved).;;;","20/Aug/11 22:08;mck;What's the status on this? This issue and its relations back to CASSANDRA-2878 are the only reason we're using OPP. I suspect other users setup with both cassandra and hadoop (or brisk) could be in the same boat. Not only does OPP leave an unbalanced ring (i've had a case where all data went to one node because the keys/tokens were longer than normal) it leaves poor performance to hadoop jobs as tasks requirement on data locality has become stricter (w/ CASSANDRA-2388). Apart from the plain preference to be using secondary indexes over OPP.;;;","21/Aug/11 04:20;jbellis;Status is, I'm hoping that someone comes up with a fix that doesn't look error prone.  Otherwise we'll probably end up with merging Sylvain's solution for 1.1.;;;","03/Oct/11 14:08;xedin;I'm thinking of making Token an interface and implementing two classes RoutingToken(token) and QueryToken(token, key) so all current token implementations LocalToken, StringToken, BytesToken, BigIntegerToken are going to extend QueryToken. RoutingToken is going to be used for operations where we don't need a key - bootstrap, midpoint calculation, TokenMetadata class; QueryToken is going to be a replacement for DK, that will allow us to remove DK completely and operate only on the token basis. Thoughts?;;;","03/Oct/11 14:23;slebresne;bq. Thoughts?

From your comment only I don't see right away what you are proposing besides a renaming of Token -> RoutingToken and DecoratedKey -> QueryToken.;;;","10/Oct/11 20:42;xedin;Patch removes DK and IPartitioner.decorateKey(ByteBuffer key), which is replaced by IPartitioner.getToken(ByteBuffer key), Token now takes second parameter - ByteBuffer key. Most of the patch are replacements for DK -> Token and decorateKey -> getToken. All tests (test, test-compression, long-test) pass.

Rebased with the latest trunk (last commit 7624536ae7fea52bcf761c7dea212fe12d2f4586);;;","10/Oct/11 20:57;tjake;At first glancei  like this because it makes the Token first class and the key not required. cleaning up the code below.

{code}
-        DecoratedKey startWith = new DecoratedKey(range.left, null);
-        DecoratedKey stopAt = new DecoratedKey(range.right, null);
+        Token startWith = range.left;
+        Token stopAt = range.right;
{code};;;","11/Oct/11 11:42;slebresne;I have 2 major problems with that patch:

The first one is I really dislike the idea of merging DK into Token (I disliked the idea of merging Token into DK and that roughly the same idea).  First, I fail to see how this is of any help in solving what this ticket is trying to solve. Second, I think it's a very bad use of types. A Token is not a Key. By merging those together we just weaken our type hierarchy, thus getting less insurance from types. Typically, with this patch, a function that really want a DK, could get a Token, i.e getKey() is not guaranteed to return a valid key. Now I know, we are already using 'false' DK by feeding null as a key sometimes. Well, that is ugly and error prone. I don't think generalizing this everywhere while introducing a 300K patch is the right way to go, quite the contrary. Besides, it's inefficient. All the places were we do use only a Token, we'll now have a bigger structure with a useless pointer to the EMPTY_BYTE_BUFFER (granted this has probably little impact, but it's another sign that it's doing it wrong).

The second problem is this doesn't work. This DK->Token really just muddy the water but it doesn't solve anything. What we want is to fix the fact that the code identifies token and keys as a one to one mapping. In particular, this is forced in DK.compareTo(), which only compare the tokens, ignoring the keys.  Fixing that place is easy, and the patch does it, but it's really just a few lines change.

The real problem is that the code make the assumption that key <-> token is one to one in other places. So making DK.compareTo takes key into account breaks other parts. For instance, in RowIteratorFactory, we have this:
{noformat}
return startWith.compareTo(row.getKey()) <= 0
       && (stopAt.isEmpty() || row.getKey().compareTo(stopAt) <= 0);
{noformat}
and say that startWith and stopAt are token only. The semantic is that this is supposed to be inclusive on both bound. With the last patch, this would include keys having the startWith token, but *not* the ones having stopAt as token, because in the patch, a token compares strictly before all of the key having this token (concretely, the attached patch skips keys during range queries).

And this is not the only places in the code where this problem manifest, because this is the symptom of a larger problem. If more than one key can have the same token, then tokens are a range of keys.
If you ask for the range of tokens [1, 4], then you expect that it will return all the keys having token 1, 2, 3 and 4. That excludes having a token comparing strictly before all the keys having this token (or having it compare strictly after all the keys having it as token for that matter). Merging Token and DK just doesn't work.

At the risk of sounding cocky, I really encourage people to have another look at my patch. I do believe that once you've realized what solving this problem entails, it's a solution that strike a reasonable balance in fixing the problem without a entire rewrite of Cassandra.
;;;","11/Oct/11 20:50;tjake;@Sylvain This is all really confusing and I agree the core of the ticket is to make key->token 1:1

The core of the problem initially was explained in CASSANDRA-1733

bq. A Range object (which Hadoop splits generate) is start-exclusive. A Bounds object (which normal user scan queries generate) is start-inclusive.

So by making Token the only way to deal with keys it feels like a more consistent api.  Since Key can be null it needs to be Token that becomes the primary internal class. 

In your impl we now have DK, Token, RingPosition which too me is more confusing than having one Token class.


;;;","12/Oct/11 10:43;slebresne;I'm not sure I'm am completely clear, so allow me to try to improve that. I think there is two issues with the last patch that are largely orthogonal:
  # the patch is broken (again, this is largely not related to the shoving of DK into Token)
  # I believe shoving DK into Token is a bad, error-prone idea that have no tangible advantages

But let's me first focus on the first issue, if only because it involves no opinion whatsoever: I'm either right or wrong that it's broken (but i'm pretty sure I'm right). So let's be concrete and take an example.

The patch ""merges"" Token and DecoratedKey together, so let me take the following notation:
  * t(1, a) for what is the DecoratedKey a of token 1 in current but is is just a Token instance in the patch
  * t(1) for the 'pure' token 1. In other word it's a shortcut for t(1, EMPTY_BYTE_BUFFER) in the attached patch and correspond to just a Token in the current code.
(as a side note, the fact that I have to speak of DecoratedKey and 'pure' token to explain is imo yet another sign than melting everything into Token is a bad idea but I'm diverging)

Since when Token are compared, the token is compared then the key is on token equality, we have t\(n) < t(n, k) whatever the token n and key k are (since t\(n) is t(n, EMPTY_BYTE_BUFFER) and EMPTY_BYTE_BUFFER < k for any valid key k) .

Let's now take an example of multiple keys having the same token and say that I have the following keys in my cluster:
{noformat}
tokens |   1   |     2     |   3
keys   | a | b | c | d | e | f | g
{noformat}
In other words, a and b have the same token 1; c, d and e have the same token 2; ...

The goal for this ticket is to support that situation correctly. Sor for instance, we should have that:
   range_slice(start=t(1), end=t(3)) returns c, d, e, f and g
(because range_slice with tokens is start exclusive).  However, with the attached patch:
   range_slice(start=t(1), end=t(3)) will return a, b, c, d and e

The reason is fairly simple: we have that t(1) < t(1, k) for any k and t(3) < t(3, k) for any k.

Another way to put it is that it breaks our token ranges: if you have a node that owns Range(t(1), t(3)), it's supposed to not contains any key with token 1 and all keys with token 3, but it fails at both.

So it's broken. Now there is something we could be tempted to do. We could make it so that t\(n) > t(n, k) for any token n and any key k. But in turn that would break Bounds (i.e, start inclusive) of 'pure' tokens. I.e, Bounds(t(1), t(2)) is supposed to include all keys with token 1, but if t(1) > t(1, k) for any key k, it won't include it.

One could argue however that this is still solution because I *think* that right now we never really use a Bounds of 'pure' tokens (more precisely, the current code does it, but only in place where we are actually doing a range slice between keys). And I *think* that functions that take a startKey, when fed a 'pure' token only do start exclusive. So I suppose we could assert that we never create Bounds of Token and put some assert here and there (in SSTableReader.getPosition() for instance) and go with that.

But imho this is a bad idea. Because it's fragile and because this is ignoring a problem that may screw us up later. Why not fix it the right way now? What if tomorrow we do want to be able to query all the keys having a given token ? That is, what if we want to query [t(1), t(1)] ? We would not be able to, because if t(1) > t(1, k) for any k, then [t(1), t(1)] don't include anything.

Again, all this is because a token actually correspond to a set of keys (once you acknowledge multiple keys can have the same token), and so if you want to do things correctly, you need for a given token n to have a representation for both:
  * the smallest key having token n
  * the greatest key having token n

With that, you can query all the keys having token n. Without, you can't. That is what my patch does and I believe fairly strongly is the right way to do it.


Alright, that the first thing that a patch to this ticket must deal with. Then there is another thing: the current code only allow for AbstractBounds of Token (by typing), but we want for this patch that once you do a range_slice query with at startKey and endKey, you get a range of keys in ColumnFamilyStore.getRangeSlice(), so that you can precisely answer those queries. That means we must be able to construct AbstractBounds with keys in them. Note that it's basically just a typing problem.

The answer to that of this patch is show DK into Token. So yeah, it fixes that problem, but what I'm arguing is that:
  * It's error-prone and make coding *more* complicated. We're merging object that are not the same thing. Today if a methods takes a Token, you know it won't do anything at the granularity of keys (well today Token and keys have the same granularity but this ticket is supposed to change that). You lose that information if you merge DK and Token. And if a method takes a DecoratedKey, you know that it doesn't expect a Token (more precisely, Typing ensures it). Sure, we do already use a trick in a few places where we create 'fake' DK(null, key). But at the very least, when we do that, we know we're doing something weird, and we are extra careful that methods we call on that fake DK handle that case correctly. If everything is Token, now the signature for a lot of method will suggest it is ok to give a 'pure' Token. So what, all method should defensively assert this is not the case ? This is what types are for.
  * It's a ~300K patch. Sure it's mostly simple changes, but it's still that many changes that could introduce a typo somewhere that causes a bug.
  * It's a tad less efficient because each time we really only care about 'pure' Token (and there is quite a bunch of code that does that), we would allocate a slightly larger structure for no reason. And I'm pretty sure god kills a kitten each time you do that.

The solution to that very same type problem I'm proposing (in my patch) is instead simply to generalize AbstractBound slightly so you can have both AbstractBound of Token and of DecoratedKey. That sound very reasonable to me.  After all we should be able to have AbstractBounds of anything that implements Comparable right ? Well, as it turns out our implementation of AbstractBound needs a little more than that (because our ranges wraps, we need Comparable but with a minimum value for instance) and that is what RingPosition is for.  But it's only a marker interface, and if you look at the code it's actually used in a small number of places, so I admit I fail to see how this make thing much more complicated.;;;","12/Oct/11 11:14;xedin;Can you please define what do you mean by ""pure token""? Aren't we supposed to generate token from key in all situations except initial token in config and middle point between tokens? So if you do a range slice using tokens instead of keys TokenFactory.fromString will force you to use correctly serialized token data which will also include key.

bq. It's error-prone and make coding more complicated. We're merging object that are not the same thing etc...

If token is generated from key than for me it's natural to have a key as member. The thing is that you are enable to create a ""pure"" token, Partitioner will always give you a Token with valid key except for midpoint method so if partitioner is used to generate tokens you are guaranteed to have a valid key in the resulting token instance.

bq. It's a ~300K patch. Sure it's mostly simple changes, but it's still that many changes that could introduce a typo somewhere that causes a bug.

The same thing I can say about your set of patches - it's 198 KB. Aren't we writing tests to catch such bugs?;;;","12/Oct/11 12:23;slebresne;
bq. Can you please define what do you mean by ""pure token""?

In you patch, it's a Token whose key is EMPTY_BYTE_BUFFER (which is *not* a valid row key, hence the 'pure' token name).

bq. Aren't we supposed to generate token from key in all situations except initial token in config and middle point between tokens?

And? Is that not enough? There is tons of place in the code where we manipulate those tokens 'not created from a key' (all the distribution code basically, which is a big part of Cassandra). Moreover, there is also range_slice that accept a range of token.

bq. So if you do a range slice using tokens instead of keys TokenFactory.fromString will force you to use correctly serialized token data which will also include key.

To what is this supposed to be an answer ?

bq. If token is generated from key than for me it's natural to have a key as member. The thing is that you are enable to create a ""pure"" token, Partitioner will always give you a Token with valid key except for midpoint method so if partitioner is used to generate tokens you are guaranteed to have a valid key in the resulting token instance.

But it's not always generated from a key! There is nothing natural to a key member in all the Token object manipulated by TokenMetadata and other, since there is not such key.

bq. The same thing I can say about your set of patches - it's 198 KB. Aren't we writing tests to catch such bugs?

Well, in my patch, 148K of those are a type generification only (that's why I've separated it). Because generics are erased at runtime, as long as it compile, there is *NO* chance this can introduce a bug. As for trusting tests to catch bugs, I think it's being overconfident in tests. But in the end, I'm happily taking back that objection as this is by far the less important.


Let me try to put things graphically, everyone loves a graph: if I draw the set of all keys as this:
{noformat}
[-----------------------------------------------------------------------------[
{noformat}
i.e, the ring but as a line because I'm ignoring wrapping for this.

Now, if I display row keys (decorated or not, that doesn't matter, both are keys), I would have for instance:
{noformat}
[---------------------------|-------|---------------|---------------|---------[
                            k1      k2              k3              k4
{noformat}
A key is a point on the ring.

Now if keys and tokens are a 1 to 1 mapping, then it could be ok to say that a token is a point on the ring, but once it's not the case, then it looks like that:
{noformat}
                                t                     t'              t''
[-------------------------[*|*******|*]----------[**|****]-------[**|******]--[
                            k1      k2              k3              k4
{noformat}
where t is the token for both k1 and k2 (and an infinite number of other keys (actually finite because we're working on a computer)), t' the token of k3 (and an 'infinite' number of other keys), etc...

A token is intrinsically a range, a segment on the ring. Shoving DK and Token into the same class everywhere in the code is saying that we'll use the same class for a point and an interval. How can that be a good idea? How can that not backfire on us and be hard to work with, making it easy to introduce errors?
;;;","12/Oct/11 12:33;tjake;bq. A token is intrinsically a range, a segment on the ring. 

But the whole point of the ticket is to remove this concept. Are you saying that can't be guaranteed?

This should be possible by making a equals consider the token AND key.  The problem with CASSANDRA-1733 is sometimes we don't specify a key since we have have Min token and an intrinsic Max token.  ;;;","12/Oct/11 13:34;slebresne;bq. But the whole point of the ticket is to remove this concept. Are you saying that can't be guaranteed?

There is a misunderstanding. The whole point of this ticket is to *enforce* this concept. A token is a range, a segment on the ring, there is nothing we can do about it. It's like saying the point of the ticket is to remove the concept that a segment is different from a point.

I'm happy to discuss that, and that is clearly where we should start, but I'm pretty sure that the *problem* we want to fix is that the current code is pretending than a segment is equal to a point. The current code is pretending that a token t is the same thing than a key having this token. This only work if there is only one key have a given token, otherwise it's buggy, you identify all keys having the same token as equal, that is the problem.

And saying that you'll change the comparison of DK to include the key and pretending that a token is the same thing that some fictive key that as far as key comparison is concerned would be before any key having the token (which is *exactly* what Pavel's patch is doing) doesn't work either. As I've said earlier with examples.

I'm saying that the right way to fix is to make the code treats Token as a segment (because you know, that's what it is) and a key as a point. Now that, imho, is not of a debatable nature: it's either true or false (and imho clearly true but maybe i'm completely stupid). But at the very least we should agree on that first, even before thinking about how we will code it.

Then, once we agree on the problem, there is the question of how we do it. And then, my second argument is that shoving a token (a segment) and a (decorated) key (a point) into the same class (that we would happen to call Token) is, why probably ""possible"", likely an error-prone, confusing and frankly ugly idea. You can create a class representing both a segment and point, having it work correctly underneath and write code using that, but it will unlikely be beautiful nor easy to use. But it's ""possible"". ;;;","12/Oct/11 13:46;jbellis;bq. The whole point of this ticket is to enforce this concept. A token is a range, a segment on the ring, there is nothing we can do about it.

Right.

Is this still a fair summary of why we want to fix this?

bq. the problem is that we are using DK both for routing and for local key sorting;;;","12/Oct/11 14:31;tjake;My view is a Key requires a Token in our system. I understand that you cant keep multiple keys from mapping to the same token, still I would have liked to see the code deal with Tokens with (optional) keys then a mix of keys and tokens.  I see now this idea is broken in the sense that sorting a list of tokens means different things depending on the context (partitioner bounds vs user defined range)
;;;","12/Oct/11 14:46;slebresne;{quote}
Is this still a fair summary of why we want to fix this?

the problem is that we are using DK both for routing and for local key sorting
{quote}
Hum, I would actually rephrase it with token instead of DK, in the sense that we don't really use DK for routing, DK is a key with it's token ""cached"" to speed up computing it, we're using only the token to route. The problem is we're also using only the token for local key sorting.

But while we could/should be using token to route and the DK for local key sorting, we still need to be able to handle local key *search* by token. And that is imho the difficulty of this ticket (if we always had an actual valid key to do local key search it would be much easier). And we need local search based on tokens because:
  * we allow range_slices on a range of tokens (so this translate ultimately to local search by token)
  * even for range_slices by keys, we still end up splitting the key range by a token in getRestrictedRanges, hence resulting ultimately to a local search by token.
Then the problem is that since a token is a segment and a key (what we're searching for) a point, we can't really compare those, in the sense that a key is not necessarily either stricly greater, equal, or stricly lesser than a token. So you do have to consider both the ""bounds"" of the token, which are now point and that you can compare to keys.;;;","18/Nov/11 14:20;slebresne;Attaching rebased patch (against trunk).

I've slightly refactored the patches too. The first contains only the generification of AbstractBounds. It's obviously a bit ""dumb"" taken alone since it generify but doesn't allow anything else than tokens. The only other noticeable thing is the removal of the Range.compare() method (in favor of the compareTo method of Token). I have no idea what that method was about in the first place. The second patch does the rest of the work and has got some minor cleanups. I've also tried to add some new comments to make it more digestible.  I also include a third patch with a small unit test.

Having spend quite some time thinking about this issue, I do think that this is a good way to fix it, the alternative of allowing to mixing Token and DecoratedKey directly in a Range being (to have pursued it a bit before giving up) much more messy and error prone imho. Now I can't force anyone to like this solution but I also won't rebase this forever.;;;","18/Nov/11 23:51;jbellis;{noformat}
+    public static final DecoratedKey minKey = new DecoratedKey(partitioner.getMinimumToken(), false);
{noformat}

I think I'd rather have these in the partitioner.  (I know partitioner is cluster-global right now but it still feels wrong to ""hoist"" something partitioner dependent out and make it static final.)

{noformat}
+        assert token != null && key != null;
{noformat}

This feels odd when we go ahead and construct DKs with null key anyway in the other constructor.

*Important*: I think my biggest problem with this patch is that a DK may or may not have a key that when given to the partitioner, results in the Token in the DK.  And there's nothing to show that is the case, except that key == null or Empty.  So we're still pretending a Token ""is"" a key, we've just made it more complicated.  Could we update the methods for whose benefits we're performing the Token -> DK conversion, to accept RingPosition instead?

{noformat}
+        return token.hashCode() + (key == null ? 0 : key.hashCode());
{noformat}

I don't see a good reason to not use a ""real"" hashcode implementation (Objects.hashCode is useful here).

{noformat}
+        // null is used as a 'end of range' marker, so DK(t, k) is always before DK(t, null) unless k == null
{noformat}

Still not a huge fan of using null to mean end of range, but I guess I don't have a better suggestion. There's clearly a lot of places in this patch where it's causing special case ugliness though, independent of its status as ""max.""

{noformat}
+        // minimunKey, see Token.upperBoundKey()
{noformat}

typo.  (both occurrences.)

{noformat}
-        T min = (T)current.partitioner.getMinimumToken();
+        T min = (T)current.left.minimumValue(current.partitioner);
{noformat}

I think the positives of making this Generic are outweighed by the negative of implying that minimum value for partitioner X depends on the RingPosition that is returning it.  I think I'd rather accept the casting ugliness of having a Partitioner method that does instanceof checks to return the appropriate type.  

*Serializer code*: How does DK, AB, etc. code deal w/ backwards compatibility issues?  Looks like some (AES) can get by with saying ""we don't support mixed-version streaming"" but others (IndexScanCommand) cannot.

{noformat}
+        assert left.compareTo(right) <= 0 || right.isMinimum(partitioner) : ""["" + left + "","" + right + ""]"";
{noformat}

What if we added a Partitioner reference so we could just ask isMinimum()?

;;;","19/Nov/11 00:03;jbellis;bq. I think my biggest problem with this patch is that a DK may or may not have a key that when given to the partitioner, results in the Token in the DK.

Put another way: in my ideal world, DK.token would be purely an optimization to avoid calling partitioner.getToken(key) over and over.;;;","21/Nov/11 16:54;slebresne;bq. Put another way: in my ideal world, DK.token would be purely an optimization to avoid calling partitioner.getToken(key) over and over.

I understand that, but I think there is two different things and I want to know exactly where the disagreement/problem is.

The first problem, which is imho the core of this ticket, is that the code needs to be able somehow to deal with things like (where I use k for keys and t for tokens, and the term range for either Range or Bounds):
  * Is key k in the range [k', t] (or (t', k''])? Because when you do a range_slice of [k', k''] and there is multiple nodes and [k', k''] spans multiple replica, we will end up requesting all keys in [k', t] (for some t) or (t', k''].
  * Is key k in range (t, t']? Because we're allowed to range query keys by a token range, but also a few other reason, like the fact that during validation compaction we hashes together keys within a token range.
Note that those are not trivial questions, because for instance [k', t], while we intuitively understand what it represents is a weird beast in that is a range a point and a segment?!

Or in other words, as much as I'd like the operations on Tokens and the ones on Keys to be two completely orthogonal sets of operation with no interaction whatsoever, it is not the case and we have to deal with it.

Dealing with the case where we need tokens and we have keys is trivial (we just call Key.getToken() and boom, we're back in the case with only tokens).

The problem is when we fundamentally work on keys, but have only token to start with. Today (i.e. before this ticket), we take a simplification by doing essentially the same thing that in the 'needs token but got keys' case by having a sort of Token.getKey() (it's more ugly in practice, we inline calls to new DecoratedKey(t, null), but that's the same thing). But doing that forces in itself the fact that key an token are in bijection and we want to lift that.

One solution could be to try to keep Token as long as we can, even in places where we really need a key and have the code deal with that. I can understand that on the surface that could look clean, but in practice the code to do that correctly would a pure nightmare. Just trying to implement a Range that would mix token and keys (like the [k', t] range above) is a complete mess.

So what this patch does is realizing that you could characterize the set of keys that a token t represents with only two keys: the smallest key having token t, and the biggest key having token t.

Now, supposing we agree on what is above, the rest is implementation details and that's probably a much simpler discussion. Note that above I'm not talking of DecoratedKey, only key. But the question is, how do you represent those two new keys (for each token). The patch uses special values of the key field of DK to deal with those. I can agree this is not the cleanest thing ever and I'm fine looking for a different encoding, but I just don't have a much better idea, and frankly I don't find that horrible either.

bq. I think I'd rather have these in the partitioner

Good idea.

bq. his feels odd when we go ahead and construct DKs with null key anyway in the other constructor.

The goal here is to avoid constructing one of the two 'fake' keys by accident For that the second constructor is dedicated to their construction and as the commnet says, you're not even supposed to use this second constructor, but use Token.{upper|lower}Bound instead. Actually, the assert should check for the EMPTY_BYTE_BUFFER.

bq. Could we update the methods for whose benefits we're performing the Token -> DK conversion, to accept RingPosition instead?

Frankly, and as argumented above, no, not without *huge* pain. We only do that conversion in places where we will have to do it at some point, and trying to push Tokens deeper would only serve in having operations that make no real sense for Tokens be able to actually deal with Token. As one example, we would have to make Range with a mix of Token and Keys, and frankly that will be a total mess to code.

bq. I don't see a good reason to not use a ""real"" hashcode implementation (Objects.hashCode is useful here)

Not sure I follow but ByteBuffer.hashCode() does hash the content of the buffer if that was what you meant.

bq. There's clearly a lot of places in this patch where it's causing special case ugliness though, independent of its status as ""max.""

Again, I would be open to better encoding. But is there really that much places? The patch tried to make it so that no code outside of DecoratedKey really have to deal with it. If not perfect, I actually think it's better contained that before the patch.

bq. I think the positives of making this Generic are outweighed by the negative of implying that minimum value for partitioner X depends on the RingPosition that is returning it. I think I'd rather accept the casting ugliness of having a Partitioner method that does instanceof checks to return the appropriate type.

I think you're right.

bq. Serializer code: How does DK, AB, etc. code deal w/ backwards compatibility issues?

Basically, old version only understand AbstractBounds of Token, while new version generates/accept AbstractBounds of either token, or keys. When old sends to new and keys are expected, new convert the range/bounds of token as range/bounds of keys. When new sends to old, it converts any range/bounds of keys to range/bounds of token.

bq. What if we added a Partitioner reference so we could just ask isMinimum()?

Do you mean to have the DK to have a reference to the partioner? If so, I agree that it's probably something we should, but it's nothing specific to that patch so I'd rather leave it to another ticket.
;;;","21/Nov/11 18:16;jbellis;bq. in practice, we inline calls to new DecoratedKey(t, null)

Right.  I must be missing something crucial, because that's exactly what it looks like we're still doing in this patch, only with a special constructor.;;;","21/Nov/11 21:17;slebresne;No, no, the patch does use the same think. I merely said that the patch does some attempt at a better encapsulation, as it seems better to use the Token.{upper|lower}BoundKey to creates those fake keys that inlining the call to the constructor all over the code (which we do now). It makes the use of null more of an internal detail of DecoratedKey (not completely, granted, but it's a little bit better). It also makes it simpler to check we don't accidentally construct a DK with a null key by accident (the goal of the assertion in the first DK constructor in the patch).

But let it be clear that I'm not making any claim that this patch ""cleans"" some ugliness in the current code. It mainly try to solve the problem at hand, which is basically to be able to do range_slices and getting the right result even when multiple keys have the same token.

This is not saying it wouldn't be good to fix any current ugliness at the same time if possible, but in truth, I don't find that using special DK to represent special keys is such an ugly hack (not either claiming it's super beautiful, I just don't have a particular hatred of this). Besides, I don't have tons of ideas to fix the issue at end (the priority) and make the code clearly cleaner. And I do think that whatever ugliness the current have, this patch doesn't make it worst.

Anyway, I'll try to see if I can improve the encapsulation of the Token.{upper|lower}BoundKey representation and see if I can come with something slightly cleaner.;;;","21/Nov/11 21:28;jbellis;bq. the patch does some attempt at a better encapsulation, as it seems better to use the Token.{upper|lower}BoundKey to creates those fake keys that inlining the call to the constructor all over the code (which we do now). 

Okay, I'll buy that.  It's an awful lot of code churn for IMO a relatively minor win, but I see where you're going with that.

Help me understand this patchset a different way: which is the part without which CASSANDRA-1600 is impossible?;;;","23/Nov/11 16:06;slebresne;bq. Help me understand this patchset a different way: which is the part without which CASSANDRA-1600 is impossible?

CASSANDRA-1600 requires that the row key range requested be known by CFS.getRangeSlice/search, while today it only gest the corresponding tokens.  We could possibly do what your first patch for CASSANDRA-1600 did and add the keys separately. You'll have to deal with wrapping and such, but that's probably doable.

What this patchset does is make getRangeSlice/search actually take keys, so this greatly simplify CASSANDRA-1600. But CASSANDRA-1600 is probably doable without this, it's just the logical first step before getting a clean implementation. Now for the specific parts, as said we need to be able to have keys for getRangeSlice/search, which basically require the bulk of this patchset (i.e. for CASSANDRA-1600, we could still have DecoratedKey.compareTo() to only compare the tokens and not the keys, but that's probably it)

But truth being told, CASSANDRA-1600 is by far not my main motivation for this. My main motivation is CASSANDRA-1684. For the latter, if we want to do it 'natively', we will have lots of key having the same token, so this ticket is an absolute requirement before even getting started. And there is also the problem of md5 collision :)
;;;","23/Nov/11 16:07;slebresne;I've tried finding a better encapsulation for the 'fake' keys of the patch.  The idea being to restrict DK to 'true' row key, i.e. the ones that can be written on disk and create a new class (Token.KeyBound) to represent the two ""fake"" key for each token representing the smallest/biggest key having the token. To make it work together, they share the new RowPosition interface.

Some of the methods accepts a RowPosition (instead of DecoratedKey) to indicate that it can accept a 'fake' key for purpose of selecting true keys.  So for instance SSTableReader.getPosition() accepts a RowPosition. However, SSTableReader.getCachedPosition() only accepts a DK, because the key cache can only contain a ""true"" row key.

Anyway, I actually end up liking this. With that, we never ever create a DK with a null key (nor even an empty one, which wouldn't be a true key either).  This is more clear and avoids mistakes. Unfortunately the patch got bigger :(
;;;","28/Nov/11 14:49;jbellis;+1 on the KeyBound approach.  This is exactly what I was hoping for.

Returning to a minor point:

bq. bq. I don't see a good reason to not use a ""real"" hashcode implementation (Objects.hashCode is useful here)

bq. Not sure I follow but ByteBuffer.hashCode() does hash the content of the buffer if that was what you meant.

I mean that straight addition is a weak hashcode combination since X + Y is the same as Y + X.  ""return Objects.hashCode(X, Y)"" is an easy way to do it ""right"" with no more code than the weak approach.  Doesn't matter much here but it's good practice imo.

Another nit: should we be using a enum for RowPosition.kind?

Meta observation: I'm glad we're not doing this a week before freeze. :);;;","29/Nov/11 15:10;slebresne;bq. I mean that straight addition is a weak hashcode combination since X + Y is the same as Y + X. ""return Objects.hashCode(X, Y)"" is an easy way to do it ""right"" with no more code than the weak approach. Doesn't matter much here but it's good practice imo.

Make sense. I made the DK hashcode be only based on the key hashcode though (since the token is just a cached value for getToken() :)). The hashCode method of Token.KeyBound don't use Objects.hasCode(), but I really think that in that case it doesn't matter at all and it avoids the boxing of the boolean. I can change it though if that's the only problem remaining.

bq. Another nit: should we be using a enum for RowPosition.kind?

What do you mean exactly by that? Are you talking of the kind use in RowPositionSerializer? To have an enum to distinguish between DK and Token.KeyBound instance of doing the instanceof? If so why not, but I'm not sure it buys us anything.;;;","29/Nov/11 15:24;jbellis;Okay, we can skip the hashcode change if you're worried about boxing.

Yes, that's what I'm referring to for ""kind.""  Seeing code like ""if kind == 0"" means I have to go back to the kind method to see what a return value of 0 means.;;;","30/Nov/11 10:44;slebresne;Attaching v3, rebased and using an enum for the RowPosition kind. I could have changed a few {{assert key instanceof DecoratedKey}} by {{assert key.kind() == RowPosition.Kind.ROW_KEY}} I suppose, but I prefered keeping the instanceof since each time the next line do a cast to DK, so this feels more coherent like that.;;;","30/Nov/11 14:05;jbellis;+1;;;","01/Dec/11 09:25;hudson;Integrated in Cassandra #1229 (See [https://builds.apache.org/job/Cassandra/1229/])
    remove assumption that key and token are in bijection
patch by slebresne; reviewed by jbellis for CASSANDRA-1034

slebresne : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1208993
Files : 
* /cassandra/trunk/CHANGES.txt
* /cassandra/trunk/src/java/org/apache/cassandra/client/RingCache.java
* /cassandra/trunk/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
* /cassandra/trunk/src/java/org/apache/cassandra/cql/QueryProcessor.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/DecoratedKey.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/HintedHandOffManager.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/IndexScanCommand.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/Memtable.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/RangeSliceCommand.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/RowIteratorFactory.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/RowPosition.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/compaction/CompactionManager.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/compaction/LeveledManifest.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/index/SecondaryIndexManager.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/index/SecondaryIndexSearcher.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/index/keys/KeysSearcher.java
* /cassandra/trunk/src/java/org/apache/cassandra/db/marshal/LocalByPartionerType.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/AbstractBounds.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/AbstractByteOrderedPartitioner.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/AbstractPartitioner.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/BootStrapper.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/Bounds.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/IPartitioner.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/LocalPartitioner.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/OrderPreservingPartitioner.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/RandomPartitioner.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/Range.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/RingPosition.java
* /cassandra/trunk/src/java/org/apache/cassandra/dht/Token.java
* /cassandra/trunk/src/java/org/apache/cassandra/hadoop/ColumnFamilyInputFormat.java
* /cassandra/trunk/src/java/org/apache/cassandra/hadoop/ColumnFamilyRecordWriter.java
* /cassandra/trunk/src/java/org/apache/cassandra/io/sstable/IndexSummary.java
* /cassandra/trunk/src/java/org/apache/cassandra/io/sstable/SSTableBoundedScanner.java
* /cassandra/trunk/src/java/org/apache/cassandra/io/sstable/SSTableLoader.java
* /cassandra/trunk/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
* /cassandra/trunk/src/java/org/apache/cassandra/io/sstable/SSTableScanner.java
* /cassandra/trunk/src/java/org/apache/cassandra/locator/AbstractReplicationStrategy.java
* /cassandra/trunk/src/java/org/apache/cassandra/locator/TokenMetadata.java
* /cassandra/trunk/src/java/org/apache/cassandra/net/MessagingService.java
* /cassandra/trunk/src/java/org/apache/cassandra/service/AntiEntropyService.java
* /cassandra/trunk/src/java/org/apache/cassandra/service/StorageProxy.java
* /cassandra/trunk/src/java/org/apache/cassandra/service/StorageService.java
* /cassandra/trunk/src/java/org/apache/cassandra/service/StorageServiceMBean.java
* /cassandra/trunk/src/java/org/apache/cassandra/streaming/StreamIn.java
* /cassandra/trunk/src/java/org/apache/cassandra/streaming/StreamOut.java
* /cassandra/trunk/src/java/org/apache/cassandra/streaming/StreamRequestMessage.java
* /cassandra/trunk/src/java/org/apache/cassandra/streaming/StreamingRepairTask.java
* /cassandra/trunk/src/java/org/apache/cassandra/thrift/CassandraServer.java
* /cassandra/trunk/src/java/org/apache/cassandra/thrift/ThriftValidation.java
* /cassandra/trunk/src/java/org/apache/cassandra/tools/BulkLoader.java
* /cassandra/trunk/src/java/org/apache/cassandra/utils/FBUtilities.java
* /cassandra/trunk/src/java/org/apache/cassandra/utils/MerkleTree.java
* /cassandra/trunk/test/unit/org/apache/cassandra/Util.java
* /cassandra/trunk/test/unit/org/apache/cassandra/db/CleanupTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/db/KeyCollisionTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/db/SerializationsTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/dht/AbstractBoundsTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/dht/BootStrapperTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/dht/PartitionerTestCase.java
* /cassandra/trunk/test/unit/org/apache/cassandra/dht/RangeTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/io/CompactSerializerTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/service/AntiEntropyServiceTestAbstract.java
* /cassandra/trunk/test/unit/org/apache/cassandra/service/MoveTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/service/SerializationsTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/service/StorageProxyTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/streaming/SerializationsTest.java
* /cassandra/trunk/test/unit/org/apache/cassandra/streaming/StreamingTransferTest.java
;;;","01/Dec/11 10:14;slebresne;Committed \o/;;;"
stress.py broken in trunk,CASSANDRA-1033,12463264,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,brandon.williams,brandon.williams,brandon.williams,28/Apr/10 22:05,16/Apr/19 09:33,14/Jul/23 05:51,30/Apr/10 15:36,0.7 beta 1,,,,0,,,,,,"stress.py is broken on trunk, apparently due to the removal of the keyspace argument to thrift calls.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Apr/10 20:10;brandon.williams;1033.txt;https://issues.apache.org/jira/secure/attachment/12443228/1033.txt",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19966,,,Fri Apr 30 15:41:42 UTC 2010,,,,,,,,,,"0|i0g2lb:",91850,,,,,Low,,,,,,,,,,,,,,,,,"29/Apr/10 20:08;brandon.williams;Patch to create keyspaces as needed, login, and remove the keyspace argument to calls.;;;","30/Apr/10 15:36;jbellis;committed (would be nice to check for keyspace before attempting to create, though);;;","30/Apr/10 15:41;jbellis;changed ""print e"" to ""print e.why"" which just gives ""Keyspace already exists.""  good enough for contrib/ :);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix contrib/word_count build in 0.7,CASSANDRA-1030,12463154,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jeromatron,jbellis,jbellis,27/Apr/10 21:38,16/Apr/19 09:33,14/Jul/23 05:51,06/May/10 17:23,0.7 beta 1,,,,0,,,,,,CASSANDRA-44 broke word_count setup (see CASSANDRA-1002) so CASSANDRA-992 and CASSANDRA-1029 can't easily be applied to 0.7 as-is.  This ticket will port those to 0.7 and add schema setup.,,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/May/10 20:58;jeromatron;1030.patch;https://issues.apache.org/jira/secure/attachment/12443632/1030.patch",,,,,,,,,,,,,,1.0,jeromatron,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19965,,,Thu May 06 17:23:58 UTC 2010,,,,,,,,,,"0|i0g2kn:",91847,,,,,Normal,,,,,,,,,,,,,,,,,"30/Apr/10 17:49;jeromatron;Converted from using the fat client to using thrift rpc for the WordCountSetup.  Also fixed a few things that were amiss in the current hadoop stuff with @stuhood. Needs a patch for cassandra-1022 to be able to login on the wordcount itself.;;;","03/May/10 13:50;jbellis;why do we still need the .yaml?;;;","03/May/10 13:55;gdusbabek;I haven't reviewed the patch yet.;;;","03/May/10 14:30;johanoskarsson;Had a quick look at but unfortunately the word count contrib does not compile for me with the patch applied. 
The fix is trivial, but I can't seem to figure out the reason for changing the input format from SortedMap to a LinkedHashMap in the first place?;;;","03/May/10 15:19;jeromatron;@johan: the reason why we changed from SortedMap to LinkedHashMap was that the TreeMap required a comparable object to instantiate (line 234 of ColumnFamilyRecordReader).  Stu suggested just changing it to the LHM so that it didn't require the comparable object.  I'm wondering what it needed to compile - it had compiled fine for me.;;;","03/May/10 15:19;jeromatron;@jonathan: I removed the need for the yaml file for the WordCountSetup class and tried to run it without it for the WordCount but it errored out.  I wasn't sure if that was just the way it had to be or if I could get rid of that.  I think this line (line 91) in WordCount needs to be updated to grab the dynamic mapping:

 this.columnName = context.getConfiguration().get(CONF_COLUMN_NAME);

but I'll take another look.;;;","03/May/10 15:29;jeromatron;I see the compilation problem after updating - it looks like the patch for cassandra-1022 has been committed.  That changes the args required for a thrift rpc client login.  I'll update the patch and see about getting rid of the dependency on the .yaml at the same time.;;;","03/May/10 15:45;jbellis;""context"" is the hadoop job context, nothing to do w/ our yaml.;;;","03/May/10 15:55;jeromatron;@johan: sorry - not because it requires a comparator, but that LinkedHashMap maintains the insertion order.  That was the reason.

@jonathan: right - sorry, yeah.  Was going to look at it and that was the first thing I skimmed that looked promising, but you're right.  Looking at it though.;;;","03/May/10 17:15;jeromatron;@jonathan - I asked Johan about the error when the cassandra.yaml file is not present.  He said it looked like it's required because it gets the host address from the seed that's in the configuration file.  That's in the org.cassandra.hadoop... code - ColumnFamilyInputFormat line 196 for example.  Would you rather the host be configured by the client itself and remove the dependency on cassandra.yaml?;;;","03/May/10 18:48;jeromatron;Updated the patch with compilation fix from cassandra-1022 changes. Also updated ColumnFamilyInputFormat to use LinkedHashMap in addition to the other places where SortedMap had been used.

Waiting to find out if it would be good to have the client provide the host address or if we should still depend on cassandra.yaml for the seed to get to that.;;;","03/May/10 21:17;jbellis;It looks like the main reason we use DatabaseDescriptor is to get comparator information so we can throw SortedMaps around.

Created CASSANDRA-1047 to clean this up.;;;","04/May/10 20:58;jeromatron;Updated to make sure everything works in the wordcount - dynamically finds the comparator based on describing the keyspace itself.;;;","06/May/10 09:50;johanoskarsson;The patch looks good, but I get unexpected output. In the setup code we insert just one ""word1"" in the text1 column. When the word count runs it finds two instances of ""word1"" in the text1 column. This could be due to other changes in trunk, but worth verifying it is not this patch.;;;","06/May/10 16:38;johanoskarsson;The problem with the output is most likely this one CASSANDRA-1042, so will commit this patch as is;;;","06/May/10 17:02;jeromatron;yeah - it looks like the output is the same on 0.6.0's word count as the trunk cassandra-1030 patch output.  so it would seem to be something external that is causing odd output - hopefully cassandra-1042 will fix that.;;;","06/May/10 17:23;johanoskarsson;Committed to trunk. Thanks Jeremy!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in AntiEntropyService.getNeighbors,CASSANDRA-1028,12463120,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,jbellis,jbellis,27/Apr/10 15:25,16/Apr/19 09:33,14/Jul/23 05:51,23/Jul/10 18:03,0.7 beta 1,,,,0,,,,,,"Sometimes, but not always, I see this during a test run:

    [junit] Testsuite: org.apache.cassandra.service.AntiEntropyServiceTest
    [junit] Tests run: 10, Failures: 0, Errors: 0, Time elapsed: 3.189 sec
    [junit] 
    [junit] ------------- Standard Error -----------------
    [junit] ERROR 10:19:09,743 Error in executor futuretask
    [junit] java.util.concurrent.ExecutionException: java.lang.NullPointerException
    [junit] 	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
    [junit] 	at java.util.concurrent.FutureTask.get(FutureTask.java:83)
    [junit] 	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:87)
    [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
    [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    [junit] 	at java.lang.Thread.run(Thread.java:637)
    [junit] Caused by: java.lang.NullPointerException
    [junit] 	at java.util.AbstractCollection.addAll(AbstractCollection.java:303)
    [junit] 	at org.apache.cassandra.service.AntiEntropyService.getNeighbors(AntiEntropyService.java:151)
    [junit] 	at org.apache.cassandra.service.AntiEntropyService.rendezvous(AntiEntropyService.java:176)
    [junit] 	at org.apache.cassandra.service.AntiEntropyService.access$100(AntiEntropyService.java:86)
    [junit] 	at org.apache.cassandra.service.AntiEntropyService$Validator.call(AntiEntropyService.java:487)
    [junit] 	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
    [junit] 	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
    [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    [junit] 	... 2 more
    [junit] ------------- ---------------- ---------------

Ideally it would be nice if this could cause an actual test failure when it happens.  Not sure how feasible that is.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/May/10 18:32;stuhood;0001-Clear-AES-before-begininning-the-next-test.patch;https://issues.apache.org/jira/secure/attachment/12444580/0001-Clear-AES-before-begininning-the-next-test.patch","22/Jul/10 21:15;stuhood;0001-Die-bug-die.patch;https://issues.apache.org/jira/secure/attachment/12450217/0001-Die-bug-die.patch",,,,,,,,,,,,,2.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19964,,,Tue Jul 27 13:41:02 UTC 2010,,,,,,,,,,"0|i0g2k7:",91845,,,,,Normal,,,,,,,,,,,,,,,,,"15/May/10 18:32;stuhood;Since nothing we do with the TokenMetadata is multithreaded, I'm fairly certain this is caused by background tasks left in the AES stage after tests. This patch clears the stage during teardown. 100ish runs of the test seem to confirm that this fixes the problem.;;;","17/May/10 14:50;jbellis;committed, thanks;;;","18/May/10 13:31;hudson;Integrated in Cassandra #439 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/439/])
    block for AES to clear before we teardown the token metadata for the next test.  patch by Stu Hood; reviewed by jbellis for CASSANDRA-1028
;;;","06/Jul/10 04:01;jbellis;Getting this again / still in latest trunk:

    [junit] Exception in thread ""AE-SERVICE-STAGE:1"" java.lang.NullPointerException
    [junit] 	at java.util.AbstractCollection.addAll(AbstractCollection.java:303)
    [junit] 	at org.apache.cassandra.service.AntiEntropyService.getNeighbors(AntiEntropyService.java:164)
    [junit] 	at org.apache.cassandra.service.AntiEntropyService.rendezvous(AntiEntropyService.java:184)
    [junit] 	at org.apache.cassandra.service.AntiEntropyService.access$100(AntiEntropyService.java:84)
    [junit] 	at org.apache.cassandra.service.AntiEntropyService$TreeResponseVerbHandler.doVerb(AntiEntropyService.java:684)
    [junit] 	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:41)
    [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    [junit] 	at java.lang.Thread.run(Thread.java:637)
;;;","22/Jul/10 21:15;stuhood;Double flush AE_SERVICE_STAGE to ensure that tasks triggered by existing tasks are cleared.;;;","23/Jul/10 18:03;jbellis;committed;;;","27/Jul/10 13:41;hudson;Integrated in Cassandra #501 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/501/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
separate assignment of current keyspace from login(),CASSANDRA-1022,12463043,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,todd,urandom,urandom,26/Apr/10 18:35,16/Apr/19 09:33,14/Jul/23 05:51,04/May/10 16:01,0.7 beta 1,,,,0,,,,,,"With the completion of CASSANDRA-714, it is now a requirement that login() be called, even when using the AllowAllAuthenticator (effectively disabling auth), since this is how the current/connected keyspace is set. These two disparate functions (assigning keyspace and authentication) should be disentangled.

I propose that the keyspace argument be removed from calls to {{login()}}, and that a new method ({{use_keyspace(string)}}?), be added.
",,jeromatron,rschildmeijer,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Apr/10 10:16;todd;CASSANDRA-1022.patch;https://issues.apache.org/jira/secure/attachment/12443277/CASSANDRA-1022.patch",,,,,,,,,,,,,,1.0,todd,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19961,,,Sat Jul 03 12:48:09 UTC 2010,,,,,,,,,,"0|i0g2iv:",91839,,,,,Low,,,,,,,,,,,,,,,,,"26/Apr/10 18:45;jbellis;mild preference for set_keyspace here;;;","26/Apr/10 20:42;todd;Since this relates closely with CASSANDRA-714, I'll spend the time logically separating these.;;;","30/Apr/10 10:16;todd;Patch attached.;;;","02/May/10 00:13;urandom;This has been committed with a few changes:

* Fixed some style nits, (braches on newlines, etc). See http://wiki.apache.org/cassandra/CodeStyle.
* Reinstated debug log statement in CassandraServer.login()
* Reinstated css_.debug test when printing stacktrace in the CLI
* Removed unused _login() function from system tests
* Reworded a few error messages.
* Updated contrib/utils/service/CassandraServiceTest for login() change
* Disabled system_add_keyspace() when authentication is enabled (login() requires a keyspace).
* Reset access level (forcing a new login) when keyspace is changed using set_keyspace().

Thanks Todd!
;;;","04/May/10 14:53;tzz;Eric, please remember http://thread.gmane.org/gmane.comp.db.cassandra.user/1038/focus=1404 where you asked me to merge login() with setKeyspace() and now they are pulled apart again.  What has changed?  Shouldn't we be insisting on the ""one keyspace per connection"" concept?  Or has the philosophy changed?

If set_keyspace() is to be used, it should be the one returning an AccessLevel.  login() should return void.  In other words, the AccessLevel is per-keyspace, not per-user.

Also, login() should no longer throw AuthorizationException since it doesn't do authorization, while set_keyspace() should throw it.

Please let me know if I need to implement these changes or if someone else will do it or if there are any questions.

Thanks!;;;","04/May/10 16:01;urandom;{quote}
Eric, please remember http://thread.gmane.org/gmane.comp.db.cassandra.user/1038/focus=1404 where you asked me to merge login() with setKeyspace() and now they are pulled apart again. What has changed? Shouldn't we be insisting on the ""one keyspace per connection"" concept? Or has the philosophy changed?
If set_keyspace() is to be used, it should be the one returning an AccessLevel. login() should return void. In other words, the AccessLevel is per-keyspace, not per-user.
{quote}

I remember; what has changed is (anecdotal) experience with how people are (or more importantly are not) using this, and how well the interface is holding up over time (read: it's not).

Personally,  I am  stronger in my convictions now that we should _not_ be rolling our own AAA, that this is not The Way, and I am seeking to make this (still experimental) API as optional as possible while working toward something better, (AVRO-341).

{quote}
Also, login() should no longer throw AuthorizationException since it doesn't do authorization, while set_keyspace() should throw it.
{quote}

{{set_keyspace()}} is the required call now, {{login()}} works exactly as before only it uses the keyspace specified in {{set_keyspace()}} instead of having one passed in (and {{set_keyspace()}} invalidates any previous {{login()}}).

This was the whole point of this issue, to divorce the function of assigning a keyspace from authentication.

{quote}
Please let me know if I need to implement these changes or if someone else will do it or if there are any questions.
{quote}

I don't see any changes that need to be implemented here.;;;","04/May/10 16:29;tzz;Thanks for explaining.  I didn't understand your motivation earlier.;;;","02/Jul/10 20:31;messi;Commit #940127 introduced a bug in CassandraServer (line 889 in trunk): if statement is empty because of semicolon.;;;","02/Jul/10 21:54;jbellis;removed the semicolon.  thanks!;;;","03/Jul/10 12:48;hudson;Integrated in Cassandra #484 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/484/])
    r/m errant semicolon.  patch by Folke Behrens; reviewed by jbellis for CASSANDRA-1022
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
keys are now byte[] but hashmap cannot have byte[] as keys so they need to be fixed,CASSANDRA-1020,12462918,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,vijay2win@yahoo.com,vijay2win@yahoo.com,vijay2win@yahoo.com,24/Apr/10 04:54,16/Apr/19 09:33,14/Jul/23 05:51,27/Apr/10 15:15,0.7 beta 1,,,26/Apr/10 00:00,0,,,,,,Thrift client calls use hashmap and needs this fix,Linux/Mac Cassandra,rschildmeijer,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Apr/10 20:57;vijay2win@yahoo.com;1020-v1.txt;https://issues.apache.org/jira/secure/attachment/12442896/1020-v1.txt",,,,,,,,,,,,,,1.0,vijay2win@yahoo.com,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19959,,,Tue Apr 27 15:15:07 UTC 2010,,,,,,,,,,"0|i0g2if:",91837,,,,,Critical,,,,,,,,,,,,,,,,,"24/Apr/10 13:52;jbellis;as discussed on IRC, it looks like the only places we use byte[] keys in maps are in CassandraServer where using object identity is OK since we don't need to worry about two different byte[] w/ the same contents;;;","24/Apr/10 16:07;vijay2win@yahoo.com;Thanks Jonathan, but cfamilies.get(command.key) will be fixed in cassandraserver?;;;","24/Apr/10 16:43;jbellis;you're right, that one is still a potential bug.;;;","26/Apr/10 20:57;vijay2win@yahoo.com;This Solves the problem which i noticed earlier... will this work?;;;","27/Apr/10 15:15;jbellis;committed, with a similar patch for avro.CassandraServer;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""java.net.ConnectException: Connection timed out"" in MESSAGE-STREAMING-POOL:1",CASSANDRA-1019,12462907,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,btoddb,btoddb,23/Apr/10 21:12,16/Apr/19 09:33,14/Jul/23 05:51,26/May/10 19:00,0.6.3,0.7 beta 1,,,0,,,,,,"after doing a nodetool repair on a node in my cluster, i see the following exception on 4 out of the 7 nodes.  replication factor is 3.  no compactions happening.  no client traffic to the cluster.  nodetool streams (on one of the nodes not repaired) shows the following which is not ever increasing:

Mode: Normal
Streaming to: /192.168.132.117
   /data/cassandra-data/data/UdsProfiles/stream/UdsProfiles-43-Data.db 0/523088443
Not receiving any streams.


in addition those same four nodes all show AE-SERVICE-STAGE with pending
work, and been showing this for several hours now. each node in the
cluster has less than 2gb, so it should be finished by now.

here is the exception:

2010-04-23 10:08:43,416 ERROR [MESSAGE-STREAMING-POOL:1]
[DebuggableThreadPoolExecutor.java:101] Error in ThreadPoolExecutor
java.lang.RuntimeException: java.net.ConnectException: Connection timed out
at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:619)
Caused by: java.net.ConnectException: Connection timed out
at sun.nio.ch.Net.connect(Native Method)
at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:507)
at org.apache.cassandra.net.FileStreamTask.runMayThrow(FileStreamTask.java:60)
at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
... 3 more
2010-04-23 10:08:43,417 ERROR [MESSAGE-STREAMING-POOL:1]
[CassandraDaemon.java:78] Fatal exception in thread
Thread[MESSAGE-STREAMING-POOL:1,5,main]
java.lang.RuntimeException: java.net.ConnectException: Connection timed out
at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:619)
Caused by: java.net.ConnectException: Connection timed out
at sun.nio.ch.Net.connect(Native Method)
at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:507)
at org.apache.cassandra.net.FileStreamTask.runMayThrow(FileStreamTask.java:60)
at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
... 3 more

",,anty,gdusbabek,mojodna,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,"24/May/10 20:50;stuhood;1019-for-0.6-0001-Add-exponentially-backed-off-retry-to-FileStreamTask.patch;https://issues.apache.org/jira/secure/attachment/12445382/1019-for-0.6-0001-Add-exponentially-backed-off-retry-to-FileStreamTask.patch","24/May/10 20:50;stuhood;1019-for-trunk-0001-Rename-CompletedFileStatus-to-FileStatus-to-indicate.patch;https://issues.apache.org/jira/secure/attachment/12445383/1019-for-trunk-0001-Rename-CompletedFileStatus-to-FileStatus-to-indicate.patch","24/May/10 20:50;stuhood;1019-for-trunk-0002-Rename-StreamCompletionHandler-to-FileStatusHandler-.patch;https://issues.apache.org/jira/secure/attachment/12445384/1019-for-trunk-0002-Rename-StreamCompletionHandler-to-FileStatusHandler-.patch","24/May/10 20:50;stuhood;1019-for-trunk-0003-Rename-StreamCompletionAction-to-Action-and-change-d.patch;https://issues.apache.org/jira/secure/attachment/12445385/1019-for-trunk-0003-Rename-StreamCompletionAction-to-Action-and-change-d.patch","24/May/10 20:52;stuhood;1019-for-trunk-0004-Add-exponentially-backed-off-retry-to-FileStreamTask.patch;https://issues.apache.org/jira/secure/attachment/12445386/1019-for-trunk-0004-Add-exponentially-backed-off-retry-to-FileStreamTask.patch",,,,,,,,,,5.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19958,,,Thu May 27 12:47:28 UTC 2010,,,,,,,,,,"0|i0g2i7:",91836,,,,,Normal,,,,,,,,,,,,,,,,,"25/Apr/10 05:19;jbellis;Stu, could you add some ""retry N (3?  10?) times before aborting the stream"" logic?;;;","25/Apr/10 21:34;stuhood;I should be able to tackle this Tuesday or Wednesday.;;;","26/Apr/10 16:15;btoddb;some more info that may assist.  we have just purchased new machines for our test cluster and we are having lots of trouble with the NICs going down.  this causes an extremely long timeout situation and could have been the catalyst for this problem.

this situation does cause the cluster to behave very poorly because the connection takes several minutes to timeout.  this type of situation makes me want the ability to manually take a node out of the cluster and prevent nodes from gossiping to it.  is this something that has been talked about?;;;","24/May/10 20:50;stuhood;Adds retries with exponential backoff to the connect step in FileStreamTask.;;;","24/May/10 20:52;stuhood;...and a set that does the same thing for trunk. 1019-for-0.6-0001 should be the same as 1019-for-trunk-0004.

The rest of the set performs some cleanups in the Streaming package to give things more appropriate names and document them a little better.;;;","26/May/10 15:41;gdusbabek;+1 on the 0.6 change.  Re trunk: would it make sense to rename FileStatus.STREAM -> FileStatus.RESTREAM?;;;","26/May/10 16:12;stuhood;> Re trunk: would it make sense to rename FileStatus.STREAM -> FileStatus.RESTREAM?
I debated doing that, but since the FileStatus object exists for the lifetime of the transfer it needs to have an initial Action/status that indicates it is streaming.;;;","27/May/10 12:47;hudson;Integrated in Cassandra #447 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/447/])
    rename StreamCompletionAction to Action. patch by stuhood, reviwed by gdusbabek. CASSANDRA-1019
rename StreamCompletionHandler to FileStatusHandler. patch by stuhood, reviwed by gdusbabek. CASSANDRA-1019
rename CompletedFileStatus to FileStatus. patch by stuhood, reviwed by gdusbabek. CASSANDRA-1019
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Exception auto-bootstrapping two nodes nodes at the same time,CASSANDRA-1011,12462730,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,erickt,erickt,22/Apr/10 05:09,16/Apr/19 09:33,14/Jul/23 05:51,14/Jul/10 12:11,0.7 beta 1,,,,0,,,,,,"I've got a small cluster of 3 machines, and after starting the first node (which is the seed), I brought up the other two nodes at the same time. This exception then gets raised on the seed node. Looks like the seed node is assigning the same token to the subnodes at the same time:

ERROR 21:46:49,417 Error in ThreadPoolExecutor
java.lang.RuntimeException: Bootstrap Token collision between /10.0.0.2 and /10.0.0.3 (token Token(bytes[4c617374204d6967726174696f6e])
	at org.apache.cassandra.locator.TokenMetadata.addBootstrapToken(TokenMetadata.java:130)
	at org.apache.cassandra.service.StorageService.handleStateBootstrap(StorageService.java:548)
	at org.apache.cassandra.service.StorageService.onChange(StorageService.java:511)
	at org.apache.cassandra.gms.Gossiper.doNotifications(Gossiper.java:705)
	at org.apache.cassandra.gms.Gossiper.applyApplicationStateLocally(Gossiper.java:670)
	at org.apache.cassandra.gms.Gossiper.applyStateLocally(Gossiper.java:624)
	at org.apache.cassandra.gms.Gossiper$GossipDigestAck2VerbHandler.doVerb(Gossiper.java:1016)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)
ERROR 21:46:49,418 Fatal exception in thread Thread[GMFD:1,5,main]
java.lang.RuntimeException: Bootstrap Token collision between /10.0.0.2 and /10.0.0.3 (token Token(bytes[4c617374204d6967726174696f6e])
	at org.apache.cassandra.locator.TokenMetadata.addBootstrapToken(TokenMetadata.java:130)
	at org.apache.cassandra.service.StorageService.handleStateBootstrap(StorageService.java:548)
	at org.apache.cassandra.service.StorageService.onChange(StorageService.java:511)
	at org.apache.cassandra.gms.Gossiper.doNotifications(Gossiper.java:705)
	at org.apache.cassandra.gms.Gossiper.applyApplicationStateLocally(Gossiper.java:670)
	at org.apache.cassandra.gms.Gossiper.applyStateLocally(Gossiper.java:624)
	at org.apache.cassandra.gms.Gossiper$GossipDigestAck2VerbHandler.doVerb(Gossiper.java:1016)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)
",,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/10 18:10;gdusbabek;0001-fail-bootstrap-if-all-nodes-are-bootstrapping.patch;https://issues.apache.org/jira/secure/attachment/12449372/0001-fail-bootstrap-if-all-nodes-are-bootstrapping.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19955,,,Wed Jul 14 13:56:22 UTC 2010,,,,,,,,,,"0|i0g2gf:",91828,,,,,Low,,,,,,,,,,,,,,,,,"24/Jun/10 18:31;gdusbabek;There is still plenty of window for this to happen, but this should narrow it down some.;;;","24/Jun/10 18:44;jbellis;i don't think the window between when the bootstrapping machine chooses a machine to ask for a token, and when it actually does so (sub ms under any scenario i can think of) is large enough to add the extra check in getBalancedToken.  either way the main danger is that some node has already chosen the same token but we haven't heard about it yet over gossip.

it would be worth checking though in getBootstrapSource that if sorted node zero has a bootstrap target already (i.e., _every_ node already has one), then we should fail the bootstrap (and tell the user to specify an initialtoken manually, or wait for one of the current bootstraps to finish).;;;","12/Jul/10 21:12;gdusbabek;> it would be worth checking though in getBootstrapSource that if sorted node zero has a bootstrap target already (i.e., every node already has one), then we should fail the bootstrap (and tell the user to specify an initialtoken manually, or wait for one of the current bootstraps to finish).

I think I'm missing something.  We don't keep track of whether or not node zero has a bootstrap target, do we?  Nothing I can see in TMD indicates this.;;;","12/Jul/10 22:25;jbellis;metadata.pendingRangeChanges = bootstrap targets, more or less;;;","14/Jul/10 03:45;jbellis;+1;;;","14/Jul/10 13:56;hudson;Integrated in Cassandra #491 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/491/])
    fail bootstrap if all nodes are bootstrapping. patch by gdusbabek, reviewed by jbellis. CASSANDRA-1011
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bad EndpointSnitch config in trunk,CASSANDRA-1009,12462717,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,stuhood,stuhood,22/Apr/10 00:55,16/Apr/19 09:33,14/Jul/23 05:51,22/Apr/10 00:58,0.7 beta 1,,,,0,,,,,,A few config changes made it into trunk for 990/1000 that shouldn't have.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/10 00:56;stuhood;0001-Two-bad-config-changes-slipped-in-with-990.patch;https://issues.apache.org/jira/secure/attachment/12442498/0001-Two-bad-config-changes-slipped-in-with-990.patch",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19953,,,Thu Apr 22 00:58:53 UTC 2010,,,,,,,,,,"0|i0g2fz:",91826,,,,,Normal,,,,,,,,,,,,,,,,,"22/Apr/10 00:56;stuhood;Fixes the default log level, and applies EndpointSnitch changes to the default config.;;;","22/Apr/10 00:58;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Assertion failure loadbalance-ing a ByteOrderedPartitioner cluster,CASSANDRA-1008,12462713,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,erickt,erickt,erickt,21/Apr/10 22:42,16/Apr/19 09:33,14/Jul/23 05:51,24/May/10 17:51,0.7 beta 1,,,,1,,,,,,"This seems to be a similar problem to CASSANDRA-1006:

ERROR [GMFD:4] 2010-04-21 15:37:56,942 CassandraDaemon.java (line 77) Fatal exception in thread Thread[GMFD:4,5,main]
java.lang.NumberFormatException: For input string: ""To""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:481)
	at org.apache.cassandra.utils.FBUtilities.hexToBytes(FBUtilities.java:361)
	at org.apache.cassandra.dht.AbstractByteOrderedPartitioner$1.fromString(AbstractByteOrderedPartitioner.java:133)
	at org.apache.cassandra.service.StorageService.handleStateLeft(StorageService.java:622)
	at org.apache.cassandra.service.StorageService.onChange(StorageService.java:517)
	at org.apache.cassandra.gms.Gossiper.doNotifications(Gossiper.java:705)
	at org.apache.cassandra.gms.Gossiper.applyApplicationStateLocally(Gossiper.java:695)
	at org.apache.cassandra.gms.Gossiper.applyStateLocally(Gossiper.java:624)
	at org.apache.cassandra.gms.Gossiper$GossipDigestAckVerbHandler.doVerb(Gossiper.java:966)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)
",,daniel.spilker@hamburg.de,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Apr/10 23:07;erickt;0001-Use-the-token-factory-to-convert-tokens-to-strings.-.patch;https://issues.apache.org/jira/secure/attachment/12442489/0001-Use-the-token-factory-to-convert-tokens-to-strings.-.patch",,,,,,,,,,,,,,1.0,erickt,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19952,,,Tue May 25 12:56:37 UTC 2010,,,,,,,,,,"0|i0g2fr:",91825,,,,,Low,,,,,,,,,,,,,,,,,"21/Apr/10 23:07;erickt;Potential patch to fix this bug.;;;","24/May/10 16:42;stuhood;+1
Thanks for catching this Erick... sorry it fell through the cracks for such a long time there.;;;","24/May/10 17:51;jbellis;committed, thanks;;;","25/May/10 12:56;hudson;Integrated in Cassandra #445 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/445/])
    convert byte tokens to strings correctly.  patch by Erick Tryzelaar; reviewed by Stu Hood for CASSANDRA-1008
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Exception starting up cluster with ByteOrderedPartitioner without schema set,CASSANDRA-1006,12462502,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,erickt,erickt,19/Apr/10 22:35,16/Apr/19 09:33,14/Jul/23 05:51,20/Apr/10 22:04,0.7 beta 1,,,,0,,,,,,"Testing out the new ByteOrderedPartitioner, I ran into this exception on the tip:

java.lang.NumberFormatException: For input string: ""To""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:481)
	at org.apache.cassandra.utils.FBUtilities.hexToBytes(FBUtilities.java:361)
	at org.apache.cassandra.dht.AbstractByteOrderedPartitioner$1.fromString(AbstractByteOrderedPartitioner.java:133)
	at org.apache.cassandra.dht.BootStrapper$BootstrapTokenCallback.response(BootStrapper.java:246)
	at org.apache.cassandra.net.ResponseVerbHandler.doVerb(ResponseVerbHandler.java:36)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)
ERROR 16:31:21,737 Fatal exception in thread Thread[RESPONSE-STAGE:1,5,main]

It works fine with the RandomPartitioner, however.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Apr/10 02:35;stuhood;0001-Serialize-Tokens-using-TokenFactory.patch;https://issues.apache.org/jira/secure/attachment/12442256/0001-Serialize-Tokens-using-TokenFactory.patch",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19951,,,Tue Apr 20 22:04:29 UTC 2010,,,,,,,,,,"0|i0g2fb:",91823,,,,,Normal,,,,,,,,,,,,,,,,,"19/Apr/10 22:48;erickt;I hacked up my code a bit, and it turns out the line ByteOrderedPartitioner is trying to parse is the string ""Token(bytes[4695b973940d36dce35be8d73832f848])"", which obviously is not a hex string.;;;","20/Apr/10 00:00;erickt;Fyi, turns out this is happening whether or not I've set up the storage configuration.;;;","20/Apr/10 02:35;stuhood;BootStrapper was serializing tokens using toString rather than TokenFactory.toString.;;;","20/Apr/10 22:03;gdusbabek;+1;;;","20/Apr/10 22:04;gdusbabek;committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cli doesn't work with system allowed column family names,CASSANDRA-1005,12462487,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,kingjamm,kingjamm,19/Apr/10 20:34,16/Apr/19 09:33,14/Jul/23 05:51,24/May/10 16:04,0.6.2,,,,0,cassandra-cli,,,,,"Given the following definitions for columns:

<Keyspaces>

<Keyspace Name=""NGram"">

<KeysCachedFraction>0.01</KeysCachedFraction>

<ColumnFamily CompareWith=""UTF8Type"" Name=""1GramR""/>

<ColumnFamily CompareWith=""UTF8Type"" Name=""1GramL""/>

</Keyspaces>

The appropriate keyspaces are created an persisteted on startup. When executing a query or a set operation in the cassandra-cli, you end up with the following error:

******************************************************

cassandra> get NGram.1GramR['hte']

line 1:10 extraneous input '1' expecting Identifier

No such column family: GramR

******************************************************


Following the syntax of the grammer we can see the following:

setStmt
: K_SET columnFamilyExpr '=' value -> ^(NODE_THRIFT_SET columnFamilyExpr value)
;

...

columnFamilyExpr
: table DOT columnFamily '[' rowKey ']'
( '[' a+=columnOrSuperColumn ']'
('[' a+=columnOrSuperColumn ']')?
)?
-> ^(NODE_COLUMN_ACCESS table columnFamily rowKey ($a+)?)
;
...

// syntactic Elements
Identifier
: Letter ( Alnum | '_' )*
;

There is a mismatch on what is appropriate values for this in the system. So either the restriction needs to be lifted in the cli, or the system must have a way of honoring the names.",Windows XP 32 bit,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/May/10 21:50;urandom;0001-support-all-legal-keyspace-and-column-names-in-cli.patch;https://issues.apache.org/jira/secure/attachment/12445206/0001-support-all-legal-keyspace-and-column-names-in-cli.patch","21/May/10 21:50;urandom;cli.sh;https://issues.apache.org/jira/secure/attachment/12445207/cli.sh",,,,,,,,,,,,,2.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19950,,,Mon May 24 16:04:41 UTC 2010,,,,,,,,,,"0|i0g2f3:",91822,,,,,Low,,,,,,,,,,,,,,,,,"19/Apr/10 20:36;kingjamm;changed from major to minor as we have a current workaround.;;;","06/May/10 03:21;jbellis;is this another ""abandon all hope"" antlr thing?;;;","21/May/10 21:50;urandom;The attached patch seems to do it.

Also attached is the cassandra-cli script I used to test. To run it, first create keyspaces named {{1Space}} and {{0000}}, with column families named {{2Family}} and {{1111}} respectively, then run:

{noformat}
$ cassandra-cli < cli.sh
{noformat};;;","24/May/10 15:57;jbellis;+1;;;","24/May/10 16:04;urandom;committed.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fat client example cannot find schema,CASSANDRA-1002,12462441,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,johanoskarsson,johanoskarsson,19/Apr/10 14:59,16/Apr/19 09:33,14/Jul/23 05:51,26/Apr/10 22:04,0.7 beta 1,,,,0,,,,,,"Running the client example in contrib shows that it cannot find the schema, possibly caused by CASSANDRA-44.

Throws this error:
Exception in thread ""main"" java.lang.IllegalArgumentException: Unknown ColumnFamily Standard1 in keyspace Keyspace1
	at org.apache.cassandra.config.DatabaseDescriptor.getComparator(DatabaseDescriptor.java:1123)
	at org.apache.cassandra.db.ColumnFamily.getComparatorFor(ColumnFamily.java:437)
	at ClientOnlyExample.testWriting(ClientOnlyExample.java:52)
	at ClientOnlyExample.main(ClientOnlyExample.java:169)
",,jeromatron,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Apr/10 20:48;gdusbabek;0001-modify-migrations-to-respect-client-only-mode.patch;https://issues.apache.org/jira/secure/attachment/12442892/0001-modify-migrations-to-respect-client-only-mode.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19949,,,Mon Apr 26 21:45:33 UTC 2010,,,,,,,,,,"0|i0g2ef:",91819,,,,,Normal,,,,,,,,,,,,,,,,,"26/Apr/10 20:49;gdusbabek;I dislike all of the 'if-clientMode' stuff, but Migrations weren't designed to separate schema-state from schema-storage.;;;","26/Apr/10 21:11;jbellis;so this makes clientmode not make changes to local storage, is there anything else i should be noticing?;;;","26/Apr/10 21:20;gdusbabek;No, that's basically it.;;;","26/Apr/10 21:45;jbellis;+1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Javadoc for thrift interface is not generated,CASSANDRA-997,12462357,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,hannes@helma.at,hannes@helma.at,hannes@helma.at,18/Apr/10 15:07,16/Apr/19 09:33,14/Jul/23 05:51,24/May/10 22:34,0.6.3,,Legacy/Documentation and Website,,0,,,,,,In both 0.6 and svn trunk no javadoc is generated for thrift-generated classes like org.apache.cassandra.thrift.Cassandra. The problem is that the wrong directory is included in the javadoc ant target (interface/thrift instead of interface/thrift/gen-java). ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Apr/10 15:09;hannes@helma.at;ASF.LICENSE.NOT.GRANTED--thrift-javadoc.diff;https://issues.apache.org/jira/secure/attachment/12442111/ASF.LICENSE.NOT.GRANTED--thrift-javadoc.diff",,,,,,,,,,,,,,1.0,hannes@helma.at,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19948,,,Mon May 24 22:34:37 UTC 2010,,,,,,,,,,"0|i0g2db:",91814,,,,,Low,,,,,,,,,,,,,,,,,"18/Apr/10 15:09;hannes@helma.at;Simple patch to use proper directory for thrift-generated classes in javadoc task.;;;","24/May/10 22:34;urandom;committed; thanks Hannes.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"restarting node crashes with NPE when, while replaying the commitlog, the cfMetaData is requested",CASSANDRA-995,12462287,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,gdusbabek,tzz,tzz,16/Apr/10 20:31,16/Apr/19 09:33,14/Jul/23 05:51,21/Apr/10 13:51,0.7 beta 1,,,,0,,,,,,"Removing the commitlog directory completely fixes this.   I can reliably reproduce it by 1) starting and configuring a schema with one keyspace, one super CF with LongType supercolumns; 2) inserting data; 3) shutting down and restarting the node.

Here's my schema expressed in cassidy.pl, should be obvious what the parameters are:
./cassidy.pl -server X -port Y -keyspace system 'kdefine test org.apache.cassandra.locator.RackUnawareStrategy 2 org.apache.cassandra.locator.EndPointSnitch'
./cassidy.pl -server X -port Y -keyspace test 'fdefine Status Super LongType BytesType comment=statuschanges,row_cache_size=0,key_cache_size=20000'

The problem seems to be related to CASSANDRA-44 as it happens when the CF metadata is requested but I don't know what's causing it.

10/04/16 15:25:11 INFO commitlog.CommitLog: Replaying /home/cassandra/commitlog/CommitLog-1271449410100.log, /home/cassandra/commitlog/CommitLog-1271449378151.log, /home/cassandra/commitlog/CommitLog-1271449415800.log
java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.commons.daemon.support.DaemonLoader.load(DaemonLoader.java:160)
Caused by: java.lang.NullPointerException
        at org.apache.cassandra.db.Table.<init>(Table.java:261)
        at org.apache.cassandra.db.Table.open(Table.java:102)
        at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:233)
        at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:172)
        at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:104)
        at org.apache.cassandra.thrift.CassandraDaemon.init(CassandraDaemon.java:151)
        ... 5 more
",SVN rev 935070,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Apr/10 14:23;gdusbabek;0001-include-all-keyspaces-when-creating-the-schema-migra.patch;https://issues.apache.org/jira/secure/attachment/12442298/0001-include-all-keyspaces-when-creating-the-schema-migra.patch","20/Apr/10 14:23;gdusbabek;0002-Use-RackUnawareStrategy-in-unit-tests-because-it-doe.patch;https://issues.apache.org/jira/secure/attachment/12442299/0002-Use-RackUnawareStrategy-in-unit-tests-because-it-doe.patch","16/Apr/10 21:11;tzz;ASF.LICENSE.NOT.GRANTED--crashlog-995;https://issues.apache.org/jira/secure/attachment/12442006/ASF.LICENSE.NOT.GRANTED--crashlog-995","16/Apr/10 22:29;gdusbabek;ASF.LICENSE.NOT.GRANTED--run_1.txt;https://issues.apache.org/jira/secure/attachment/12442014/ASF.LICENSE.NOT.GRANTED--run_1.txt","16/Apr/10 22:29;gdusbabek;ASF.LICENSE.NOT.GRANTED--run_2.txt;https://issues.apache.org/jira/secure/attachment/12442015/ASF.LICENSE.NOT.GRANTED--run_2.txt","19/Apr/10 16:46;tzz;Tester.java;https://issues.apache.org/jira/secure/attachment/12442199/Tester.java",,,,,,,,,6.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19946,,,Tue Apr 20 17:00:59 UTC 2010,,,,,,,,,,"0|i0g2cv:",91812,,,,,Critical,,,,,,,,,,,,,,,,,"16/Apr/10 20:39;jbellis;If this is just saying that ""I can't replay a commitlog written before -44, after applying 44 and restarting,"" then that is expected.  Use nodetool drain before upgrading (or simply r/m the commitlog as you say).;;;","16/Apr/10 20:45;tzz;I wouldn't report it as a bug if it wasn't on a commitlog written by the same version of the software.  All the steps (1,2,3) are on the same SVN revision I stated in the Environment section.;;;","16/Apr/10 21:11;tzz;This is the complete log.  First start is fresh without commitlog or data.  Second start is after shutting down completely by killing jsvc (through /etc/init.d/cassandra restart on a Debian system).;;;","16/Apr/10 21:19;tzz;My complete schema, although only Status and Property are used.  Sorry I edited the original but it was not substantially different.

./cassidy.pl -server X -port 9170 -keyspace system 'kdefine HB3-prod org.apache.cassandra.locator.RackUnawareStrategy 2 org.apache.cassandra.locator.EndPointSnitch'
./cassidy.pl -server X -port 9170 -keyspace HB3-prod 'fdefine Status Super LongType BytesType comment=statuschanges,row_cache_size=0,key_cache_size=20000'
./cassidy.pl -server X -port 9170 -keyspace HB3-prod 'fdefine Property Super LongType BytesType comment=statuschanges,row_cache_size=0,key_cache_size=20000'
./cassidy.pl -server X -port 9170 -keyspace HB3-prod 'fdefine Analysis Super LongType BytesType comment=statuschanges,row_cache_size=0,key_cache_size=20000'
./cassidy.pl -server X -port 9170 -keyspace HB3-prod 'fdefine Relationships Super LongType BytesType comment=statuschanges,row_cache_size=0,key_cache_size=20000'
./cassidy.pl -server X -port 9170 -keyspace HB3-prod 'fdefine Knowledge Super LongType BytesType comment=statuschanges,row_cache_size=0,key_cache_size=20000'

./cassidy.pl -server X -port 9170 -keyspace system 'kdefine CM org.apache.cassandra.locator.RackUnawareStrategy 2 org.apache.cassandra.locator.EndPointSnitch'
./cassidy.pl -server X -port 9170 -keyspace CM 'fdefine Inventory Super LongType BytesType comment=statuschanges,row_cache_size=0,key_cache_size=20000'

When I tried to trigger the error manually with cassidy with just a few inserts like this (the below inserts test=abc into SC 0 in the Status CF):

./cassidy.pl -server X -port 9170 -keyspace HB3-prod 'ins Status testkey 0 test=abc'
./cassidy.pl -server X -port 9170 -keyspace HB3-prod 'get Status testkey 0'

the problem doesn't happen.  I don't know how much data causes it.  My typical writes that trigger this, over a minute, are about 20-30 columns per supercolumn, about 2500 keys, about 5 SCs per key.  I can reliably trigger it with a one-minute population run.

Thanks and I hope this is enough information to replicate the bug.  If not I'll try to give you more including a better test case.;;;","16/Apr/10 22:29;gdusbabek;I couldn't reproduce this.  run_1.txt is a log from defining a KS with a SC and then inserting 100 rows.  run_2.txt is what happens after a restart.

Ted, can you reproduce this outside of cassidy.pl?;;;","19/Apr/10 15:12;tzz;I'm working on replicating the inserts I do from Perl but so far haven't been able to replicate in Java.  I'll keep trying.;;;","19/Apr/10 16:43;tzz;OK, I can prepare a proper test if you need it but the atteched Tester.java definitely causes the NPE and should work with minor changes for you (makeOpenLoginClient and getLongAsBytes are really simple helper methods).  I do ""sudo /etc/init.d/cassandra stop; rm -rf *; sudo /etc/init.d/cassandra start"", run the test, then ""sudo /etc/init.d/cassandra restart"" and get the NPE I showed earlier.  This is with today's SVN (r935659).

It definitely is a combination of the number of keyspaces and CFs together with the number of inserts.  If I do less that 1000 iterations or if I define fewer CFs and keyspaces, the problem doesn't happen on restart.  So it took me a long time to hunt it down.
;;;","19/Apr/10 19:34;gdusbabek;Thanks Ted.  I can reproduce this problem now.;;;","20/Apr/10 14:23;gdusbabek;Migration code was only storing the most recently modified keyspace when recording a migration instead of all of them.;;;","20/Apr/10 16:01;jbellis;+1 except don't commit the .iml :);;;","20/Apr/10 17:00;tzz;I tested and the fix works for me. Thank you.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Server fails to join cluster if IPv6 only,CASSANDRA-969,12461722,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,cody.lerum,cody.lerum,10/Apr/10 18:16,16/Apr/19 09:33,14/Jul/23 05:51,14/Apr/10 13:37,0.6.1,,,,0,,,,,,"When configuring Cassandra for IPv6 connectivity on the server to server side the addition of a second node causes the both servers to loop on ArrayIndexOutOfBoundsExection for 5 minutes

The first server has 

Caused by: java.lang.ArrayIndexOutOfBoundsException: 65536
        at org.apache.cassandra.net.HeaderSerializer.deserialize(Header.java:155)

While the second has

Caused by: java.lang.ArrayIndexOutOfBoundsException: 131072
        at org.apache.cassandra.net.HeaderSerializer.deserialize(Header.java:155)

the index is double.

These servers work find in a cluster together if they are configured IPv4

server1 in the output is 2607:f3d0:0:2::16
server2 is 2607:f3d0:0:1::f","Ubuntu 9.10 x64
java: Java(TM) SE Runtime Environment (build 1.6.0_15-b03)
cassandra 0.6.0-rc1",cody.lerum,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Apr/10 18:25;cody.lerum;ASF.LICENSE.NOT.GRANTED--cassandra-v6-2-filtered.pcap;https://issues.apache.org/jira/secure/attachment/12441347/ASF.LICENSE.NOT.GRANTED--cassandra-v6-2-filtered.pcap","10/Apr/10 18:18;cody.lerum;ASF.LICENSE.NOT.GRANTED--cassandra-v6.pcap;https://issues.apache.org/jira/secure/attachment/12441346/ASF.LICENSE.NOT.GRANTED--cassandra-v6.pcap","12/Apr/10 13:01;gdusbabek;ASF.LICENSE.NOT.GRANTED--encode_decode_ipv6_addresses_safely.txt;https://issues.apache.org/jira/secure/attachment/12441480/ASF.LICENSE.NOT.GRANTED--encode_decode_ipv6_addresses_safely.txt","10/Apr/10 18:16;cody.lerum;ASF.LICENSE.NOT.GRANTED--server1.log;https://issues.apache.org/jira/secure/attachment/12441344/ASF.LICENSE.NOT.GRANTED--server1.log","10/Apr/10 18:16;cody.lerum;ASF.LICENSE.NOT.GRANTED--server2.log;https://issues.apache.org/jira/secure/attachment/12441345/ASF.LICENSE.NOT.GRANTED--server2.log",,,,,,,,,,5.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19942,,,Wed Apr 14 04:40:26 UTC 2010,,,,,,,,,,"0|i0g273:",91786,,,,,Low,,,,,,,,,,,,,,,,,"10/Apr/10 18:16;cody.lerum;system.log files for both servers;;;","10/Apr/10 18:18;cody.lerum;wireshark capture of the networking traffic on server1;;;","10/Apr/10 18:25;cody.lerum;this file shows the initial server startup networking traffic as well.

second server starts up at about 6 seconds in ;;;","12/Apr/10 12:59;gdusbabek;Looks like CompactEndPointSerializationHelper is assuming a 4 byte address during deserialization, but actually writes a full 16 byte IPv6 address during serialization.;;;","12/Apr/10 13:01;gdusbabek;This patch should address your specific problem.  What we really need to do is audit the code for this problem.  There are quite a few places where we send addresses over the wire.;;;","12/Apr/10 13:10;jbellis;+1;;;","12/Apr/10 13:30;cody.lerum;I'll try and recompile later today and test.;;;","12/Apr/10 21:43;cody.lerum;I checked out the .6 branch and built off that.

Still getting errors

ERROR [MESSAGE-DESERIALIZER-POOL:1] 2010-04-12 15:37:57,020 DebuggableThreadPoolExecutor.java (line 94) Error in executor futuretask
java.util.concurrent.ExecutionException: java.lang.ArrayIndexOutOfBoundsException: 65536
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:86)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 65536
        at org.apache.cassandra.net.HeaderSerializer.deserialize(Header.java:155)
        at org.apache.cassandra.net.HeaderSerializer.deserialize(Header.java:113)
        at org.apache.cassandra.net.MessageSerializer.deserialize(Message.java:136)
        at org.apache.cassandra.net.MessageDeserializationTask.run(MessageDeserializationTask.java:45)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        ... 2 more
;;;","12/Apr/10 21:45;cody.lerum;actually I take that back

-rw-r--r-- 1 root root 1275022 2010-03-28 09:25 apache-cassandra-0.6.0-rc1.jar

The lib in my new build is still old.;;;","12/Apr/10 22:19;cody.lerum;ok got it built..


The joining server shows

ERROR 16:17:52,106 Error in executor futuretask
java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.io.EOFException
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:86)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.RuntimeException: java.io.EOFException
        at org.apache.cassandra.net.MessageDeserializationTask.run(MessageDeserializationTask.java:49)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        ... 2 more
Caused by: java.io.EOFException
        at java.io.DataInputStream.readFully(DataInputStream.java:180)
        at java.io.DataInputStream.readUTF(DataInputStream.java:592)
        at java.io.DataInputStream.readUTF(DataInputStream.java:547)
        at org.apache.cassandra.net.HeaderSerializer.deserialize(Header.java:140)
        at org.apache.cassandra.net.HeaderSerializer.deserialize(Header.java:113)
        at org.apache.cassandra.net.MessageSerializer.deserialize(Message.java:136)
        at org.apache.cassandra.net.MessageDeserializationTask.run(MessageDeserializationTask.java:45)
        ... 6 more

and existing

ERROR 16:17:42,991 Error in executor futuretask
java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.net.UnknownHostException: addr is of illegal length
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:86)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.RuntimeException: java.net.UnknownHostException: addr is of illegal length
        at org.apache.cassandra.net.MessageDeserializationTask.run(MessageDeserializationTask.java:49)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        ... 2 more
Caused by: java.net.UnknownHostException: addr is of illegal length
        at java.net.InetAddress.getByAddress(InetAddress.java:935)
        at java.net.InetAddress.getByAddress(InetAddress.java:1311)
        at org.apache.cassandra.net.CompactEndPointSerializationHelper.deserialize(CompactEndPointSerializationHelper.java:37)
        at org.apache.cassandra.net.HeaderSerializer.deserialize(Header.java:139)
        at org.apache.cassandra.net.HeaderSerializer.deserialize(Header.java:113)
        at org.apache.cassandra.net.MessageSerializer.deserialize(Message.java:136)
        at org.apache.cassandra.net.MessageDeserializationTask.run(MessageDeserializationTask.java:45)
;;;","13/Apr/10 01:18;gdusbabek;As I suspected: we have more code that is not IPv6 friendly.

Cody, can you give me the low-down on how I can turn off IPv4 and test in an environment that is reasonably similar to yours?  Assume I have an ubuntu VM at my disposal.;;;","13/Apr/10 01:50;cody.lerum;Gary,

I'm running on ubuntu with dual stack (both v4 and v6) I am merely only using ipv6 addresses in the storage and seed portions of the storage-conf.xml.

in your simply set

/etc/network/interfaces

iface eth0 inet6 static
        address 2607:f3d0:0:2::A
        netmask 64
        gateway 2607:f3d0:0:2::1

and on the other server

iface eth0 inet6 static
        address 2607:f3d0:0:2::B
        netmask 64
        gateway 2607:f3d0:0:2::1


Then in your storage-conf.xml

<Seeds>
      <Seed>2607:f3d0:0:1::b</Seed>
 </Seeds>
 <ListenAddress>2607:f3d0:0:2::a</ListenAddress>
  <!-- internal communications port -->
  <StoragePort>7000</StoragePort>

As long as both the vm's are on the same network (non-routed) you should be able to test just fine.




;;;","13/Apr/10 17:52;gdusbabek;I am not able to reproduce the latest problem.  I went as far as creating a unit test to test CompactEndPointSerializationHelper for all manner of IPv4 and IPv6 addresses.  It seems to do the job.

The EOF in the new stack trace makes me think that one of the nodes might not be up on the same code.  Cody, can you verify?;;;","13/Apr/10 18:47;cody.lerum;I may have screwed up the build. I will try the latest from Hudson ;;;","14/Apr/10 04:40;cody.lerum;Gary, I tested off http://hudson.zones.apache.org/hudson/job/Cassandra/405/ and it all looks good.

root@cassandra:/opt/cassandra# bin/cassandra -f
 INFO 22:32:35,577 Auto DiskAccessMode determined to be mmap
 WARN 22:32:35,840 Couldn't detect any schema definitions in local storage. I hope you've got a plan.
 INFO 22:32:35,851 Replaying /var/lib/cassandra/commitlog/CommitLog-1271219308493.log
 INFO 22:32:35,899 Creating new commitlog segment /var/lib/cassandra/commitlog/CommitLog-1271219555899.log
 INFO 22:32:35,910 LocationInfo has reached its threshold; switching in a fresh Memtable at CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1271219555899.log', position=163)
 INFO 22:32:35,911 Enqueuing flush of Memtable(LocationInfo)@1971599989
 INFO 22:32:35,913 Writing Memtable(LocationInfo)@1971599989
 INFO 22:32:36,012 Completed flushing /var/lib/cassandra/data/system/LocationInfo-b-1-Data.db
 INFO 22:32:36,025 Log replay complete
 INFO 22:32:36,051 Saved Token found: 149994310325493222650165912864788358013
 INFO 22:32:36,052 Saved ClusterName found: CLEARFLY-1
 INFO 22:32:36,062 Starting up server gossip
 INFO 22:32:36,110 Binding thrift service to /2607:f3d0:0:2:0:0:0:16:9160
 INFO 22:32:36,115 Cassandra starting up...
 INFO 22:33:35,564 Node /2607:f3d0:0:1:0:0:0:f is now part of the cluster
 INFO 22:33:36,553 InetAddress /2607:f3d0:0:1:0:0:0:f is now UP


You can close this out.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
StorageService.getPartitioner() and QueryFilter.getColumnComparator() should be statically accessed,CASSANDRA-966,12461576,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,tupshin,tupshin,tupshin,08/Apr/10 19:34,16/Apr/19 09:33,14/Jul/23 05:51,09/Apr/10 14:37,0.7 beta 1,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Apr/10 19:35;tupshin;static_access.diff;https://issues.apache.org/jira/secure/attachment/12441201/static_access.diff",,,,,,,,,,,,,,1.0,tupshin,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19941,,,Tue Apr 13 12:41:32 UTC 2010,,,,,,,,,,"0|i0g26f:",91783,,,,,Low,,,,,,,,,,,,,,,,,"09/Apr/10 14:37;jbellis;committed, thanks!;;;","13/Apr/10 12:41;hudson;Integrated in Cassandra #405 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/405/])
    access static members by class name.  patch by Tupshin Harper; reviewed by jbellis for CASSANDRA-966
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
remove deprecated get_string*_property() thrift methods,CASSANDRA-965,12461539,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,urandom,urandom,08/Apr/10 15:51,16/Apr/19 09:33,14/Jul/23 05:51,08/Apr/10 19:28,0.7 beta 1,,,,0,,,,,,"The get_string_property() and get_string_list_property() methods were deprecated in 0.6, they can now be removed in preparation for 0.7.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Apr/10 18:59;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-965-remove-deprecated-methods-update-depende.txt;https://issues.apache.org/jira/secure/attachment/12441196/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-965-remove-deprecated-methods-update-depende.txt","08/Apr/10 18:59;urandom;ASF.LICENSE.NOT.GRANTED--v1-0002-RingCache-fixups-in-the-wake-of-CASSANDRA-44.txt;https://issues.apache.org/jira/secure/attachment/12441197/ASF.LICENSE.NOT.GRANTED--v1-0002-RingCache-fixups-in-the-wake-of-CASSANDRA-44.txt",,,,,,,,,,,,,2.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19940,,,Fri Apr 09 13:43:11 UTC 2010,,,,,,,,,,"0|i0g267:",91782,,,,,Low,,,,,,,,,,,,,,,,,"08/Apr/10 19:00;urandom;patches attached (see patch headers for explanations);;;","08/Apr/10 19:16;jbellis;+1;;;","08/Apr/10 19:28;urandom;committed.;;;","09/Apr/10 13:43;hudson;Integrated in Cassandra #402 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/402/])
    CASSANDRA-965 remove deprecated methods, update dependent code

 * removed method defs and regenerated thrift code
 * removed CassandraServer implementations
 * updated cassandra-cli to call new (describe_*) methods
 * updated RingCache to use describe_ring()
 * removed ""show config file"" from cli (no thrift access for this anymore).
 * updated release notes.

Patch by eevans for CASSANDRA-965
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
loadSchemaFromXml records no migrations,CASSANDRA-963,12461451,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,07/Apr/10 20:01,16/Apr/19 09:33,14/Jul/23 05:51,08/Apr/10 13:48,0.7 beta 1,,,,0,,,,,,This means that there is nothing to propagate to new nodes when schema is force loaded from xml.,,stuhood,,,,,,,,,,,,,,,,,,CASSANDRA-962,,,,,,,,,,"08/Apr/10 00:15;gdusbabek;0001-SS.loadSchemaFromXML-should-record-migrations.patch;https://issues.apache.org/jira/secure/attachment/12441094/0001-SS.loadSchemaFromXML-should-record-migrations.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19939,,,Fri Apr 09 13:43:11 UTC 2010,,,,,,,,,,"0|i0g25r:",91780,,,,,Normal,,,,,,,,,,,,,,,,,"08/Apr/10 13:43;jbellis;+1;;;","09/Apr/10 13:43;hudson;Integrated in Cassandra #402 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/402/])
    SS.loadSchemaFromXML should record migrations. Patch by Gary Dusbabek, reviewed by Jonathan Ellis. CASSANDRA-963
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DC Quorum broken @ trunk,CASSANDRA-952,12461108,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,vijay2win@yahoo.com,vijay2win@yahoo.com,vijay2win@yahoo.com,04/Apr/10 05:43,16/Apr/19 09:33,14/Jul/23 05:51,18/May/10 17:16,0.7 beta 1,,,,0,,,,,,"Currently DCQuorum is broken in trunk, Suggesting the following fix... 

Write to DC's
1) Move determineBlockFor(int expandedTargets, ConsistencyLevel consistency_level) to AbstractEndpointSnitch
2) Add the same to support DC Quorum in DatacenterShardStategy

Read to DC's
1) find suitable nodes was a list which was returning a list of local DC's earlier but now it is just one node and MD is been sent by other nodes. Need to have an option to even avoid MD from other DC's?","Linux, Cassandra",jeromatron,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/10 23:55;vijay2win@yahoo.com;0002-dcquorum-fixes-v2.txt;https://issues.apache.org/jira/secure/attachment/12444546/0002-dcquorum-fixes-v2.txt","09/Apr/10 05:31;vijay2win@yahoo.com;952-Canges_To_Stategy_V002.txt;https://issues.apache.org/jira/secure/attachment/12441264/952-Canges_To_Stategy_V002.txt","05/Apr/10 17:07;vijay2win@yahoo.com;952-Change_BlockFor.txt;https://issues.apache.org/jira/secure/attachment/12440777/952-Change_BlockFor.txt","09/Apr/10 05:31;vijay2win@yahoo.com;952-Changes_To_ResponseHandler_v002.txt;https://issues.apache.org/jira/secure/attachment/12441265/952-Changes_To_ResponseHandler_v002.txt","06/Apr/10 01:16;vijay2win@yahoo.com;952-Fix_Refactor_DCStatergy.txt;https://issues.apache.org/jira/secure/attachment/12440820/952-Fix_Refactor_DCStatergy.txt","17/May/10 14:29;jbellis;952-v3.txt;https://issues.apache.org/jira/secure/attachment/12444683/952-v3.txt","28/Apr/10 06:31;vijay2win@yahoo.com;952-v3.txt;https://issues.apache.org/jira/secure/attachment/12443042/952-v3.txt","17/May/10 18:49;vijay2win@yahoo.com;952-v4.txt;https://issues.apache.org/jira/secure/attachment/12444724/952-v4.txt","29/Apr/10 17:42;vijay2win@yahoo.com;952-v4.txt;https://issues.apache.org/jira/secure/attachment/12443208/952-v4.txt","01/May/10 20:55;vijay2win@yahoo.com;952-v5.txt;https://issues.apache.org/jira/secure/attachment/12443389/952-v5.txt","12/May/10 21:48;jbellis;ASF.LICENSE.NOT.GRANTED--0001-clean-out-callback-purging-from-truncate-writerh.txt;https://issues.apache.org/jira/secure/attachment/12444346/ASF.LICENSE.NOT.GRANTED--0001-clean-out-callback-purging-from-truncate-writerh.txt","12/May/10 21:48;jbellis;ASF.LICENSE.NOT.GRANTED--0002-dcquorum-fixes.txt;https://issues.apache.org/jira/secure/attachment/12444347/ASF.LICENSE.NOT.GRANTED--0002-dcquorum-fixes.txt","01/May/10 20:55;vijay2win@yahoo.com;DC-Config.xml;https://issues.apache.org/jira/secure/attachment/12443390/DC-Config.xml",,13.0,vijay2win@yahoo.com,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19935,,,Tue May 18 17:16:20 UTC 2010,,,,,,,,,,"0|i0g23b:",91769,,,,,Low,,,,,,,,,,,,,,,,,"06/Apr/10 14:47;jbellis;The fundamental problem here is that an int count of replicas to block for is not sufficient to represent the DC strategy wants: we want to SEND to all replicas, but only count replicas in the CURRENT DC towards success.  Allowing other DC replicas will mostly work, since they will typically be slower to arrive than local ones, but if there are failure conditions locally then it could succeed where it should not, which would violate its contract to readers.

I think you will need to push the concept of what to block for into the WriteResponseHandler, and similarly for reads.

;;;","09/Apr/10 05:31;vijay2win@yahoo.com;Made Changes as suggested;;;","27/Apr/10 18:49;jbellis;Finally ready to get this in (now that CASSANDRA-994 is done).  Can you rebase?  Sorry, it's going to be a bit messy.;;;","28/Apr/10 06:31;vijay2win@yahoo.com;this patch works in my environment, and i think we need couple of methods to be added to RackInferringSnitch which is getReplicationFactor and getDatacenters to make it work with the DCSS. Let me know if you dont agree with the changes, i have renamed the DCEPS to XMLFileSnitch. there is a lot of changes in these classes.... ;;;","28/Apr/10 13:50;jbellis;We're not adding DCEPS/XMLFileSnitch back, and we shouldn't need to make any changes to the Snitch classes.  It should be able to run against any RackAwareSnitch, since it gets the per-DC settings from DCSS/datacenters.properties now.;;;","29/Apr/10 17:42;vijay2win@yahoo.com;Attached is the modified version, please note that XMLFileSnitch included in this patch, uses a different logic than PFS to read the hosts, if you choose not to include that thats fine too.;;;","30/Apr/10 17:11;jbellis;It looks like this is mixing code from CASSANDRA-967 in.  Let's do these one at a time, or we're more likely to introduce bugs.;;;","01/May/10 20:55;vijay2win@yahoo.com;I have attached the changes, Please note that we have to change a bit of logic in rangeslice in order to remove blockFor for from the SP, IF you think it is unnecessary, i put blockFor for now and add a depreciated annotation on it (by doing this i can leave the rangeslice untouched).;;;","12/May/10 21:55;jbellis;patch 01 cleans out callback purging from WriteResponseHandler (leaving ExpiringMap to clean it out automatically).

02 adds the dcquorum changes, extracting AbstractWRH so the DQSyncRH doesn't have to subclass WRH which is a poor fit, and cleans up the WRH heirarchy.;;;","13/May/10 16:49;jeromatron;Reviewing part of it and I know this wasn't part of the change - but in RackAwareStrategy couldn't we save some instruction execution by moving the check for whether we already have found another datacenter/rack outside of the checks?  Like so:

{code}
Token t = iter.next();

// First try to find one in a different data center
// If we have already found something in a diff datacenter no need to find another
if (!bDataCenter)
{
    if (!snitch.getDatacenter(metadata.getEndpoint(primaryToken)).equals(snitch.getDatacenter(metadata.getEndpoint(t))))
    {
        endpoints.add(metadata.getEndpoint(t));
        bDataCenter = true;
        continue;
    }
}

// Now  try to find one on a different rack
// If we have already found something in a diff rack no need to find another
if (!bOtherRack)
{
    if (!snitch.getRack(metadata.getEndpoint(primaryToken)).equals(snitch.getRack(metadata.getEndpoint(t))) &&
        snitch.getDatacenter(metadata.getEndpoint(primaryToken)).equals(snitch.getDatacenter(metadata.getEndpoint(t))))
    {
        endpoints.add(metadata.getEndpoint(t));
        bOtherRack = true;
        continue;
    }
}
{code}

not that big of a deal, but since it's done on every write, might be helpful.  Maybe I'm missing something there though...;;;","13/May/10 17:01;vijay2win@yahoo.com;Jeremy, Thanks... different datacenter is physically a different rack.... I dont think we need additional check for that....;;;","13/May/10 17:36;jeromatron;Vijay - okay - I wasn't thinking of doing an additional check, I was just thinking of bringing the check for bDatacenter and bOtherRack outside of the block they were in, in RackAwareStrategy.;;;","13/May/10 17:38;jeromatron;Jonathan - in your 0002 patch, the DatacenterShardStrategy changes - you refactored forLoopReturn into endpoints.  I'm not sure that you want to do that.  forLoopReturn is re-initialized on every loop iteration to include all of the replicas needed for that particular datacenter.  Endpoints includes all replicas regardless of datacenter.;;;","13/May/10 20:05;jeromatron;Jonathan - Also it looks like you're doing the datacenter replication factor per keyspace now, which is what we're hoping to have for multi-tenants.  However, in StorageService, I was under the impression that the replication strategy is handled as though it was per keyspace but in reality it is a quasi singleton.  So all keyspaces will share the same RS of that type.  Is that not true now?  I didn't see any change to that in your patches.  Just wanted to make sure that doesn't cause odd problems - if all of the keyspaces are sharing the same DatacenterShardStrategy instance which is only meant for one of those keyspaces.;;;","14/May/10 17:59;vijay2win@yahoo.com;Jeremy, 
For 002 i am submitting the update for the patch... Thanks!
replication strategy - Yes currently thats the case, but DSS can handle all the required levels it will just forward the requests to AbstractReplicationStrategy if other than DCQuorum or DCQuorumSync.;;;","14/May/10 19:59;jeromatron;Cool - yeah - looking at it again, DSS contains DC RF information for all keyspaces, so it really wouldn't matter if it was a singleton for all keyspaces.

Btw, I was mostly just reviewing the getNaturalEndpointsInternal method of DSS - Jonathan had asked me to take a look at it in IRC.  Just so you know I wasn't reviewing the entire patch.  I don't know if that matters too much, but thought I would clarify.;;;","14/May/10 23:55;vijay2win@yahoo.com;Attached is the fix and along with it i have a testcase, so we dont miss this in future.

Thanks
Vijay;;;","17/May/10 14:29;jbellis;v3 attached is the same as v2 w/ (unintentional?) breakages to TruncateResponseHandler reverted and formatting fixed.

the new test needs to work with normal propertyfilesnitch, XMLFS is not going back in.;;;","17/May/10 18:49;vijay2win@yahoo.com;Yes that was unintentional... This has updates to the test and also fix to the PEPS. And Hope it works... ;;;","18/May/10 13:31;hudson;Integrated in Cassandra #439 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/439/])
    make DCQUORUM CLs actually wait for the nodes per DC rather than attempting a purely count-based approach that didn't really work as advertised.  patch by Vijay Parthasarathy and jbellis; reviewed by Jeremy Hanna for CASSANDRA-952
;;;","18/May/10 17:16;jbellis;committed v4.

there is still a minor issue w/ replica placement but I have opened CASSANDRA-1103 instead of round-tripping this again.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cannot Start Cassandra Under Windows,CASSANDRA-948,12461065,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,nberardi,nberardi,02/Apr/10 21:22,16/Apr/19 09:33,14/Jul/23 05:51,05/May/10 20:53,0.6.2,0.7 beta 1,,,0,windows,wont-start,,,,"I get the following error when I try to launch the RC of Cassandra from the command line:

Starting Cassandra Server
Listening for transport dt_socket at address: 8888
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/cassandra/thrift/CassandraDaemon
Caused by: java.lang.ClassNotFoundException: org.apache.cassandra.thrift.CassandraDaemon
        at java.net.URLClassLoader$1.run(Unknown Source)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(Unknown Source)
        at java.lang.ClassLoader.loadClass(Unknown Source)
        at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)
        at java.lang.ClassLoader.loadClass(Unknown Source)
Could not find the main class: org.apache.cassandra.thrift.CassandraDaemon.  Program will exit.","Windows 7 (NT 6.1) 64-bit, Java 6 Update 19 64-bit, Cassandra 0.6 RC",astrouk,mgreene,nberardi,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Apr/10 21:09;gdusbabek;cassandra-with-fixes.bat;https://issues.apache.org/jira/secure/attachment/12442349/cassandra-with-fixes.bat","02/Apr/10 21:34;nberardi;cassandra.bat;https://issues.apache.org/jira/secure/attachment/12440652/cassandra.bat","04/May/10 21:54;niarck;ccassandra.bat;https://issues.apache.org/jira/secure/attachment/12443649/ccassandra.bat","02/Apr/10 21:24;nberardi;storage-conf.xml;https://issues.apache.org/jira/secure/attachment/12440650/storage-conf.xml","20/Apr/10 21:07;gdusbabek;trunk-CASSANDRA-948.txt;https://issues.apache.org/jira/secure/attachment/12442348/trunk-CASSANDRA-948.txt",,,,,,,,,,5.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19934,,,Wed May 05 20:53:39 UTC 2010,,,,,,,,,,"0|i0g22f:",91765,,,,,Normal,,,,,,,,,,,,,,,,,"02/Apr/10 21:24;nberardi;Here is my storage-conf.xml file.;;;","02/Apr/10 21:34;nberardi;Here is a copy of my cassandra.bat file.;;;","03/Apr/10 15:19;rodrigoap;Did you run ant before? Have you asked for help on the users mailing list before creating this issue?;;;","03/Apr/10 18:06;nberardi;This was an already pre built binary downloaded from the Cassandra site, so I didn't run the ant build tool.  

This appears to be related to data storage paths I set, because if I switch the paths back to the default UNIX paths.  Everything runs fine. 

These paths that I have set worked fine in the 0.5.1 build of Cassandra.  Please see my attached config file for more details.;;;","19/Apr/10 04:44;jbellis;Mark, are we broken again on Windows?;;;","20/Apr/10 14:22;reldan;Hi guys. 
User skanga from http://www.sodeso.nl/?p=80 resolve the problem such way: 

The substitution in the batch file did not work for me as shown below.

C:\Java\servers\Apache-Cassandra-0.6.0-beta2\bin>cassandra
Invalid parameter - P:
Starting Cassandra Server
Listening for transport dt_socket at address: 8888
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/cassandra/thrift/CassandraDaemon
Caused by: java.lang.ClassNotFoundException: org.apache.cassandra.thrift.CassandraDaemon
at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
Could not find the main class: org.apache.cassandra.thrift.CassandraDaemon. Program will exit.

C:\Java\servers\Apache-Cassandra-0.6.0-beta2\bin>cassandra.bat

I fixed it in cassandra.bat by replacing

REM Shorten lib path for old platforms
subst P: ""%CASSANDRA_HOME%\lib""
P:
set CLASSPATH=P:\

for %%i in (*.jar) do call :append %%i
goto okClasspath

:append
set CLASSPATH=%CLASSPATH%;P:\%*
goto :eof

WITH

REM For each jar in the CASSANDRA_HOME lib directory call append to build the CLASSPATH variable.
for %%i in (%CASSANDRA_HOME%\lib\*.jar) do call :append %%~fi
goto okClasspath

:append
set CLASSPATH=%CLASSPATH%;%1%2
goto :eof
;;;","20/Apr/10 16:20;nberardi;Thanks Eldar,

I know you are trying to be helpful, but as I indicated in my comments above the issue has to do with the CommitLogDirectory and DataFileDirectory when changed from a UNIX path to a Windows path.  

This issue appears to be solved. Because I took my config file from above and started it on 0.6.1 this morning.  

Nick;;;","20/Apr/10 21:07;gdusbabek;This fixes the problem in trunk and 0.6.  

I will commit the change after someone tests and gives it a +1 review.;;;","20/Apr/10 21:09;gdusbabek;Including a patched version of the batch file for the patch-averse.;;;","22/Apr/10 00:48;mgreene;Using the cassandra-with-fixes.bat I was able to start cassandra 0.6.1 on windows. However, this error did appear in the log:

log4j:ERROR Could not read configuration file [null\log4j.properties].
java.io.FileNotFoundException: null\log4j.properties (The system cannot find the path specified)
        at java.io.FileInputStream.open(Native Method)
        at java.io.FileInputStream.<init>(FileInputStream.java:106)
        at java.io.FileInputStream.<init>(FileInputStream.java:66)
        at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:306)
        at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:324)
        at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:62)
        at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:177)
log4j:ERROR Ignoring configuration file [null\log4j.properties].;;;","22/Apr/10 01:16;gdusbabek;Thanks Mark.  Can you tell me where you keep log4j.properties in relation to everything else?;;;","22/Apr/10 01:27;mgreene;@Gary Sure....for me it's C:\dev\apache-cassandra-0.6.1\conf\log4j.properties.

;;;","28/Apr/10 04:01;astrouk;Hi Gary and Mark,
I have just tried running cassandra-with-fixes.bat on fresh installation of 0.6.1 and have received an original error. 
It is Windows 2003 Server R2 32-bit and JDK 6.0.20 if it makes any sense.
Thank you.

Alex;;;","28/Apr/10 11:44;mgreene;@Alexander Hint: You may want to give the details, perhaps the stack trace or the log line that is this ""original error"" :-);;;","28/Apr/10 18:14;astrouk;Sure, Mark.  I have meant an error reported by Nick. I am trying to launch cassandra from command line and receive the following output:

C:\Program Files\apache-cassandra-0.6.1\bin>cassandra-with-fixes.bat
Starting Cassandra Server
Listening for transport dt_socket at address: 8888
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/cassandra/
thrift/CassandraDaemon
Caused by: java.lang.ClassNotFoundException: org.apache.cassandra.thrift.Cassand
raDaemon
        at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
Could not find the main class: org.apache.cassandra.thrift.CassandraDaemon.  Pro
gram will exit.

This is all I have.

Thank you;;;","29/Apr/10 01:10;astrouk;I got it. CLASSPATH variable breaks at whitespace in a folder name (""Program Files"" in my case). I have just moved it to a different folder, ""Cassandra"", and it works fine.

Thank you.;;;","29/Apr/10 01:19;gdusbabek;Thanks.  I'll treat that as a +1.  I'll add some documentation in a few places about the space-in-classpath problem and then commit this.;;;","29/Apr/10 01:26;jbellis;http://lkamal.blogspot.com/2006/12/setting-java-classpath-option-with.html;;;","30/Apr/10 22:20;astrouk;Thank you, Gary. However log4j error described above by Mark still occurs. See below:

C:\Cassandra\apache-cassandra-0.6.1\bin>cassandra.bat
Starting Cassandra Server
Listening for transport dt_socket at address: 8888
log4j:ERROR Could not read configuration file [null\log4j.properties].
java.io.FileNotFoundException: null\log4j.properties (The system cannot find the
 path specified)
        at java.io.FileInputStream.open(Native Method)
        at java.io.FileInputStream.<init>(FileInputStream.java:106)
        at java.io.FileInputStream.<init>(FileInputStream.java:66)
        at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurato
r.java:306)
        at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.
java:324)
        at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.jav
a:62)
        at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java
:177);;;","03/May/10 14:49;gdusbabek;cassandra-with-fixes.bat (and all the previous versions afaict) already quote the classpath.  My windows VM is ill and I don't feel like doctoring it atm, so if there are any windows users willing to take this one up and work on it, that would be great.;;;","04/May/10 21:54;niarck;my version of the batch file without the space-in-classpath problem and the logj4 error;;;","05/May/10 20:19;akapuya;Fixed by adding CASSANDRA_HOME environment in Windows;;;","05/May/10 20:35;gdusbabek;from IRC:  n]> gdusbabek, ccassandra.bat is the one working.

I'm committing it.
;;;","05/May/10 20:53;gdusbabek;Thanks for the patch Leif!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
org.apache.cassandra.config.CFMetaData defines equals but does not define hashCode,CASSANDRA-945,12460992,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,mdennis,mdennis,mdennis,02/Apr/10 03:07,16/Apr/19 09:33,14/Jul/23 05:51,06/Apr/10 21:45,0.7 beta 1,,,,0,,,,,,"org.apache.cassandra.config.CFMetaData defines equals but does not define hashCode

On a related note, it should probably be using org.apache.commons.lang.builder.[EqualsBuilder | HashCodeBuider]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Apr/10 02:07;mdennis;CASSANDRA-945.patch;https://issues.apache.org/jira/secure/attachment/12440669/CASSANDRA-945.patch",,,,,,,,,,,,,,1.0,mdennis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19933,,,Wed Apr 07 12:41:55 UTC 2010,,,,,,,,,,"0|i0g21r:",91762,,,,,Normal,,,,,,,,,,,,,,,,,"03/Apr/10 02:07;mdennis;patch against trunk r930452;;;","06/Apr/10 20:33;stuhood;+1

Thanks Matt.;;;","06/Apr/10 21:45;jbellis;committed, thanks!;;;","07/Apr/10 12:41;hudson;Integrated in Cassandra #400 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/400/])
    add CFMetaData.hashCode.  patch by Matthew Dennis; reviewed by Stu Hood for 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
system.test_thrift_server.TestMutations.test_batch_mutate_standard_columns appears to be non deterministic,CASSANDRA-944,12460991,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,brandon.williams,mdennis,mdennis,02/Apr/10 03:02,16/Apr/19 09:33,14/Jul/23 05:51,06/Apr/10 21:33,0.7 beta 1,,Legacy/Tools,,0,,,,,,"system.test_thrift_server.TestMutations.test_batch_mutate_standard_columns appears to be non deterministic.  The first time I ran the thrift tests after a clean checkout it failed.  However, it did not fail the ~10 times after that.

{code}
mdennis@mdennis:~/c/cassandra$ nosetests test/system/test_thrift_server.py 
...........E....................................
======================================================================
ERROR: system.test_thrift_server.TestMutations.test_batch_mutate_standard_columns
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/usr/lib/pymodules/python2.6/nose/case.py"", line 183, in runTest
    self.test(*self.arg)
  File ""/home/mdennis/c/cassandra/test/system/test_thrift_server.py"", line 318, in test_batch_mutate_standard_columns
    _assert_column('Keyspace1', column_family, key, 'c1', 'value1')
  File ""/home/mdennis/c/cassandra/test/system/test_thrift_server.py"", line 43, in _assert_column
    raise Exception('expected %s:%s:%s:%s:%s, but was not present' % (keyspace, column_family, key, column, value) )
Exception: expected Keyspace1:Standard1:key_27:c1:value1, but was not present

----------------------------------------------------------------------
Ran 48 tests in 184.700s

FAILED (errors=1)
{code}","xubuntu 9.10
Linux mdennis 2.6.31-20-generic #58-Ubuntu SMP Fri Mar 12 05:23:09 UTC 2010 i686 GNU/Linux
",johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Apr/10 16:19;brandon.williams;944.patch;https://issues.apache.org/jira/secure/attachment/12440920/944.patch",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19932,,,Wed Apr 07 12:41:54 UTC 2010,,,,,,,,,,"0|i0g21j:",91761,,,,,Normal,,,,,,,,,,,,,,,,,"02/Apr/10 11:22;gdusbabek;I bet you're running a mac.

If you increase the time.sleep(0.1) to a larger value, the problem will go away.  The problem is that the operation being tested is happening at ConsistencyLevel.ZERO and you are feeling the 'eventual' part of 'eventual consistency.'

I wonder if it would be a good idea to make the sleep value a constant and have it set to 0.15 if MacOS is detected.;;;","02/Apr/10 17:24;mdennis;Sorry, not on a mac, on Linux (see environment field for details )

I was thinking more like lowering the sleep, but putting it in a loop with a much higher max wait time (like an entire second).

Assuming the test is trying to verify that eventually the correct data shows up (and is not trying to verify the data shows up in under 0.1 seconds), then I believe something similar to the following would address the issue.

wait = 1s
start = now
verified = false
while not (verified = try_to_verify) and now < start+wait:
  sleep(0.05)

if not verified:
  fail_test


thoughts?
;;;","02/Apr/10 18:39;gdusbabek;That would work.  Maybe something like a assert_within(func, wait) function.  If func doesn't return true within wait, then the test fails.;;;","06/Apr/10 16:19;brandon.williams;Patch to add a loop as described and use it in conjunction with CL.ZERO;;;","06/Apr/10 21:33;jbellis;committed;;;","07/Apr/10 12:41;hudson;Integrated in Cassandra #400 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/400/])
    fix heisenbug in system tests, especially common on OS X.  patch by Brandon Williams; reviewed by jbellis for 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Spelling correction: rename DatacenterShardStategy to DatacenterShardStrategy,CASSANDRA-943,12460982,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,esigler,rodrigoap,rodrigoap,01/Apr/10 23:47,16/Apr/19 09:33,14/Jul/23 05:51,20/Apr/10 18:44,0.7 beta 1,,,,0,,,,,,Missing 'r' Stategy.,,esigler,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Apr/10 17:22;esigler;CASSANDRA-943.patch;https://issues.apache.org/jira/secure/attachment/12442327/CASSANDRA-943.patch",,,,,,,,,,,,,,1.0,esigler,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19931,,,Tue Apr 20 18:44:56 UTC 2010,,,,,,,,,,"0|i0g21b:",91760,,,,,Low,,,,,,,,,,,,,,,,,"20/Apr/10 17:22;esigler;This is a quick rename of the file and class. The base set of tests appears to run successfully after the rename, but I didn't find any other references to it, and there doesn't seem to be any unit testing around this Strategy, so I'm not certain I've done all that is needed.;;;","20/Apr/10 18:44;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Command line arguments inversion in clustertool,CASSANDRA-942,12460956,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,slebresne,slebresne,01/Apr/10 16:36,16/Apr/19 09:33,14/Jul/23 05:51,02/Apr/10 21:42,0.6.1,,Legacy/Tools,,0,,,,,,"The arguments (table and key) of the get_endpoints command of clustertool are in the wrong order
(the call to getNaturalEndpoints also have it's argument in the wrong order so it kinda works in the end
but the printing of the 'Key' is wrong.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Apr/10 16:37;slebresne;ClusterCmdArgumentsError.diff;https://issues.apache.org/jira/secure/attachment/12440523/ClusterCmdArgumentsError.diff",,,,,,,,,,,,,,1.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19930,,,Fri Apr 02 21:42:39 UTC 2010,,,,,,,,,,"0|i0g213:",91759,,,,,Low,,,,,,,,,,,,,,,,,"01/Apr/10 16:37;slebresne;The patch also make it so that if it misses an argument, it crashes 
gracefully;;;","02/Apr/10 21:42;urandom;committed w/ minor modifications; thanks Sylvain!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Invalid Response count 4,CASSANDRA-937,12460750,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,dispalt,dispalt,30/Mar/10 22:00,16/Apr/19 09:33,14/Jul/23 05:51,01/Apr/10 01:48,0.6.1,,,,0,,,,,,"2010-03-30_21:59:04.64973 ERROR - Error in ThreadPoolExecutor
2010-03-30_21:59:04.64973 java.lang.AssertionError: invalid response count 4
2010-03-30_21:59:04.64973 	at org.apache.cassandra.service.ReadResponseResolver.<init>(ReadResponseResolver.java:54)
2010-03-30_21:59:04.64973 	at org.apache.cassandra.service.ConsistencyManager$DigestResponseHandler.doReadRepair(ConsistencyManager.java:89)
2010-03-30_21:59:04.64973 	at org.apache.cassandra.service.ConsistencyManager$DigestResponseHandler.handleDigestResponses(ConsistencyManager.java:75)
2010-03-30_21:59:04.64973 	at org.apache.cassandra.service.ConsistencyManager$DigestResponseHandler.response(ConsistencyManager.java:60)
2010-03-30_21:59:04.64973 	at org.apache.cassandra.net.ResponseVerbHandler.doVerb(ResponseVerbHandler.java:35)
2010-03-30_21:59:04.64973 	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:40)
2010-03-30_21:59:04.64973 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
2010-03-30_21:59:04.64973 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
2010-03-30_21:59:04.64973 	at java.lang.Thread.run(Thread.java:636)
2010-03-30_21:59:04.64973 ERROR - Fatal exception in thread Thread[RESPONSE-STAGE:5,5,main]
2010-03-30_21:59:04.64973 java.lang.AssertionError: invalid response count 4
2010-03-30_21:59:04.64973 	at org.apache.cassandra.service.ReadResponseResolver.<init>(ReadResponseResolver.java:54)
2010-03-30_21:59:04.64973 	at org.apache.cassandra.service.ConsistencyManager$DigestResponseHandler.doReadRepair(ConsistencyManager.java:89)
2010-03-30_21:59:04.64973 	at org.apache.cassandra.service.ConsistencyManager$DigestResponseHandler.handleDigestResponses(ConsistencyManager.java:75)
2010-03-30_21:59:04.64973 	at org.apache.cassandra.service.ConsistencyManager$DigestResponseHandler.response(ConsistencyManager.java:60)
2010-03-30_21:59:04.64973 	at org.apache.cassandra.net.ResponseVerbHandler.doVerb(ResponseVerbHandler.java:35)
2010-03-30_21:59:04.64973 	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:40)
2010-03-30_21:59:04.64973 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
2010-03-30_21:59:04.64973 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
2010-03-30_21:59:04.64973 	at java.lang.Thread.run(Thread.java:636)
",replication factor is set to 3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Mar/10 20:51;jbellis;937-2.txt;https://issues.apache.org/jira/secure/attachment/12440403/937-2.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19927,,,Thu Apr 01 01:48:24 UTC 2010,,,,,,,,,,"0|i0g1zz:",91754,,,,,Normal,,,,,,,,,,,,,,,,,"30/Mar/10 22:05;jbellis;were you moving nodes around at all?;;;","30/Mar/10 22:09;dispalt;No, just restarting machines;;;","30/Mar/10 22:20;jbellis;I think this in doReadRepair is the culprit

            replicas_.add(FBUtilities.getLocalAddress());

to make up for

                endpoints.remove(FBUtilities.getLocalAddress());

in ReadVerbHandler.

The problem is, in the case where local node isn't actually a replica for the read in question it will cause this bug.;;;","31/Mar/10 20:51;jbellis;Repair is always invoked by a node that has a copy of the data, or thinks it should (that is how it gets the ""initial row"" to compare digests against), but if the definition of who should have replicas changes either from bootstrap or during rebuilding of the ring after a cluster restart then local node could be an ""extra"" replica at repair time.

This patch changes repair to keep the replica set constant throughout the process.  It also fixes repair to start comparing digests immediately rather than waiting for all responses first for no reason, and avoids an extra read from the local replica, re-using the one that we've been comparing digests with.;;;","31/Mar/10 21:27;gdusbabek;looks good. +1;;;","01/Apr/10 01:48;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Discard Commitlog Exception,CASSANDRA-936,12460748,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,dispalt,dispalt,30/Mar/10 21:47,16/Apr/19 09:33,14/Jul/23 05:51,05/Apr/10 19:54,0.6.1,,,,0,,,,,,"2010-03-30_21:19:02.31041 java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard called on obsolete context CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1269983937410.log', position=8780)
2010-03-30_21:19:02.31041 	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)
2010-03-30_21:19:02.31041 	at java.util.concurrent.FutureTask.get(FutureTask.java:111)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:86)
2010-03-30_21:19:02.31041 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1118)
2010-03-30_21:19:02.31041 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
2010-03-30_21:19:02.31041 	at java.lang.Thread.run(Thread.java:636)
2010-03-30_21:19:02.31041 Caused by: java.lang.RuntimeException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard called on obsolete context CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1269983937410.log', position=8780)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
2010-03-30_21:19:02.31041 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
2010-03-30_21:19:02.31041 	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
2010-03-30_21:19:02.31041 	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
2010-03-30_21:19:02.31041 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
2010-03-30_21:19:02.31041 	... 2 more
2010-03-30_21:19:02.31041 Caused by: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard called on obsolete context CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1269983937410.log', position=8780)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegments(CommitLog.java:358)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.db.ColumnFamilyStore$1.runMayThrow(ColumnFamilyStore.java:371)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
2010-03-30_21:19:02.31041 	... 6 more
2010-03-30_21:19:02.31041 Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard called on obsolete context CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1269983937410.log', position=8780)
2010-03-30_21:19:02.31041 	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)
2010-03-30_21:19:02.31041 	at java.util.concurrent.FutureTask.get(FutureTask.java:111)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegments(CommitLog.java:350)
2010-03-30_21:19:02.31041 	... 8 more
2010-03-30_21:19:02.31041 Caused by: java.lang.AssertionError: discard called on obsolete context CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1269983937410.log', position=8780)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegmentsInternal(CommitLog.java:378)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.db.commitlog.CommitLog.access$300(CommitLog.java:72)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.db.commitlog.CommitLog$6.call(CommitLog.java:344)
2010-03-30_21:19:02.31041 	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
2010-03-30_21:19:02.31041 	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.db.commitlog.CommitLogExecutorService.process(CommitLogExecutorService.java:113)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.db.commitlog.CommitLogExecutorService.access$200(CommitLogExecutorService.java:35)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.db.commitlog.CommitLogExecutorService$1.runMayThrow(CommitLogExecutorService.java:67)
2010-03-30_21:19:02.31041 	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
2010-03-30_21:19:02.31041 	... 1 more",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Apr/10 19:20;jbellis;936.txt;https://issues.apache.org/jira/secure/attachment/12440784/936.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19926,,,Mon Apr 05 19:54:29 UTC 2010,,,,,,,,,,"0|i0g1zr:",91753,,,,,Normal,,,,,,,,,,,,,,,,,"01/Apr/10 16:35;jbellis;Thought I had this figured out but I was wrong.

Can you turn on debug logging for the commitlog and include the log up to the next exception?

You can do this w/ JConsole under the service.StorageService MBean, Operations group, setLog4jLevel(org.apache.cassandra.db.commitlog, DEBUG)
;;;","02/Apr/10 18:02;dispalt;2010-04-02_04:12:48.85690 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178196299.log); dirty is 1, 
2010-04-02_04:12:48.87690 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178421319.log); dirty is 1, 
2010-04-02_04:12:48.87690 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178736305.log); dirty is 1, 5, 15, 
2010-04-02_04:12:48.88690 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178971505.log); dirty is 1, 5, 15, 
2010-04-02_04:12:48.88690 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179198585.log); dirty is 1, 5, 15, 
2010-04-02_04:12:48.99689 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179421825.log); dirty is 1, 5, 7, 9, 15, 2010-04-02_04:12:49.01689 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179734722.log); dirty is 1, 5, 9, 15, 
2010-04-02_04:12:49.04689 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179957332.log); dirty is 1, 5, 9, 15, 
2010-04-02_04:12:49.05689 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180177252.log); dirty is 1, 5, 9, 15, 
2010-04-02_04:12:49.16688 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180484668.log); dirty is 1, 9, 15, 
2010-04-02_04:12:49.21688 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180714597.log); dirty is 1, 6, 9, 12, 15, 16, 
2010-04-02_04:12:49.23688 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180931705.log); dirty is 1, 3, 5, 6, 9, 12, 14, 15, 16, 
2010-04-02_04:12:49.28688 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270181242081.log); dirty is 1, 3, 4, 5, 6, 9, 11, 12, 15, 16, 
2010-04-02_04:12:49.29688 DEBUG - Marking replay position 67674133 on commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270181459011.log)2010-04-02_04:14:33.32220 INFO - Rollup4h has reached its threshold; switching in a fresh Memtable at CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1270181459011.log', position=117622522)
2010-04-02_04:14:33.33219 INFO - Enqueuing flush of Memtable(Rollup4h)@1686682813
2010-04-02_04:14:33.34219 INFO - Writing Memtable(Rollup4h)@1686682813
2010-04-02_04:14:36.60205 INFO - Completed flushing /var/lib/cassandra/data/MonitorApp/Rollup4h-2483-Data.db2010-04-02_04:14:36.60205 DEBUG - discard completed log segments for CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1270181459011.log', position=117622522), column family 16. CFIDs are {system: TableMetadata({LocationInfo: 0, HintsColumnFamily: 1, }), MonitorApp: TableMetadata({AppCounter: 2, Rollup5m: 3, Rollup20m: 4, TextChangeLog: 5, Rollup12h: 6, CheckDetails: 7, TextArchive: 8, StatusArchive: 9,
 NumericArchive: 10, Rollup30m: 11, Rollup1d: 12, StatusChangeLog: 15, ChangeLog: 13, MetricSummary: 14, Rollup60m: 17, Rollup4h: 16, RollupBookeeper: 18, }), }
2010-04-02_04:14:36.60205 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270083637654.log); dirty is 0, 2010-04-02_04:14:36.67204 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270159986913.log); dirty is 10, 2010-04-02_04:14:36.72204 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178196299.log); dirty is 1, 
2010-04-02_04:14:36.74204 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178421319.log); dirty is 1, 
2010-04-02_04:14:36.80204 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178736305.log); dirty is 1, 5, 15, 2010-04-02_04:14:36.83204 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178971505.log); dirty is 1, 5, 15, 
2010-04-02_04:14:36.88204 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179198585.log); dirty is 1, 5, 15, 
2010-04-02_04:14:36.91203 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179421825.log); dirty is 1, 5, 7, 9, 15, 
2010-04-02_04:14:36.96203 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179734722.log); dirty is 1, 5, 9, 15, 
2010-04-02_04:14:37.01203 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179957332.log); dirty is 1, 5, 9, 15, 
2010-04-02_04:14:37.05203 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180177252.log); dirty is 1, 5, 9, 15, 
2010-04-02_04:14:37.18202 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180484668.log); dirty is 1, 9, 15, 
2010-04-02_04:14:37.32202 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180714597.log); dirty is 1, 6, 9, 12, 15, 2010-04-02_04:14:37.35201 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180931705.log); dirty is 1, 3, 5, 6, 9, 12, 14, 15, 
2010-04-02_04:14:37.38201 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270181242081.log); dirty is 1, 3, 4, 5, 6, 9, 11, 12, 15, 
2010-04-02_04:14:37.40201 DEBUG - Marking replay position 117622522 on commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270181459011.log)
2010-04-02_04:14:37.69200 INFO - Rollup12h has reached its threshold; switching in a fresh Memtable at CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1270181459011.log', position=130228458)
2010-04-02_04:14:37.70200 INFO - Enqueuing flush of Memtable(Rollup12h)@298933940
2010-04-02_04:14:37.70200 INFO - Writing Memtable(Rollup12h)@298933940
2010-04-02_04:14:39.40192 INFO - Creating new commitlog segment /var/lib/cassandra/commitlog/CommitLog-1270181679401.log
2010-04-02_04:14:39.44192 INFO - Rollup1d has reached its threshold; switching in a fresh Memtable at CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1270181679401.log', position=169)2010-04-02_04:14:39.45192 INFO - Enqueuing flush of Memtable(Rollup1d)@46303223
2010-04-02_04:14:40.10189 INFO - Completed flushing /var/lib/cassandra/data/MonitorApp/Rollup12h-2511-Data.db
2010-04-02_04:14:40.10189 INFO - Writing Memtable(Rollup1d)@46303223
2010-04-02_04:14:40.10189 DEBUG - discard completed log segments for CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1270181459011.log', position=130228458), column family 6. CFIDs are {system: T
ableMetadata({LocationInfo: 0, HintsColumnFamily: 1, }), MonitorApp: TableMetadata({AppCounter: 2, Rollup5m: 3, Rollup20m: 4, TextChangeLog: 5, Rollup12h: 6, CheckDetails: 7, TextArchive: 8, StatusArchive: 9, 
NumericArchive: 10, Rollup30m: 11, Rollup1d: 12, StatusChangeLog: 15, ChangeLog: 13, MetricSummary: 14, Rollup60m: 17, Rollup4h: 16, RollupBookeeper: 18, }), }2010-04-02_04:14:40.10189 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270083637654.log); dirty is 0, 
2010-04-02_04:14:40.20189 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270159986913.log); dirty is 10, 
2010-04-02_04:14:40.25188 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178196299.log); dirty is 1, 
2010-04-02_04:14:40.27188 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178421319.log); dirty is 1, 
2010-04-02_04:14:40.30188 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178736305.log); dirty is 1, 5, 15, 
2010-04-02_04:14:40.40188 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270178971505.log); dirty is 1, 5, 15, 
2010-04-02_04:14:40.44187 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179198585.log); dirty is 1, 5, 15, 
2010-04-02_04:14:40.47187 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179421825.log); dirty is 1, 5, 7, 9, 15, 
2010-04-02_04:14:40.50187 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179734722.log); dirty is 1, 5, 9, 15, 
2010-04-02_04:14:40.52187 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270179957332.log); dirty is 1, 5, 9, 15, 
2010-04-02_04:14:40.54187 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180177252.log); dirty is 1, 5, 9, 15, 
2010-04-02_04:14:40.56187 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180484668.log); dirty is 1, 9, 15, 
2010-04-02_04:14:40.67186 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180714597.log); dirty is 1, 9, 12, 15, 
2010-04-02_04:14:40.68186 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270180931705.log); dirty is 1, 3, 5, 9, 12, 14, 15, 
2010-04-02_04:14:40.76186 DEBUG - Not safe to delete commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270181242081.log); dirty is 1, 3, 4, 5, 9, 11, 12, 15, 
2010-04-02_04:14:40.76186 DEBUG - Marking replay position 130228458 on commit log CommitLogSegment(/var/lib/cassandra/commitlog/CommitLog-1270181459011.log)
2010-04-02_04:14:43.51174 INFO - Completed flushing /var/lib/cassandra/data/MonitorApp/Rollup1d-2568-Data.db
2010-04-02_04:14:43.51174 DEBUG - discard completed log segments for CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1270181679401.log', position=169), column family 12. CFIDs are {system: TableMetadata({LocationInfo: 0, HintsColumnFamily: 1, }), MonitorApp: TableMetadata({AppCounter: 2, Rollup5m: 3, Rollup20m: 4, TextChangeLog: 5, Rollup12h: 6, CheckDetails: 7, TextArchive: 8, StatusArchive: 9, NumericArchive: 10, Rollup30m: 11, Rollup1d: 12, StatusChangeLog: 15, ChangeLog: 13, MetricSummary: 14, Rollup60m: 17, Rollup4h: 16, RollupBookeeper: 18, }), }
2010-04-02_04:14:43.52174 ERROR - Error in executor futuretask
2010-04-02_04:14:43.52174 java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard called on obsolete context CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1270181679401.log', position=169)
2010-04-02_04:14:43.52174       at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)
2010-04-02_04:14:43.52174       at java.util.concurrent.FutureTask.get(FutureTask.java:111)
2010-04-02_04:14:43.52174       at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:86)
2010-04-02_04:14:43.52174       at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1118)
2010-04-02_04:14:43.52174       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
2010-04-02_04:14:43.52174       at java.lang.Thread.run(Thread.java:636)
2010-04-02_04:14:43.52174 Caused by: java.lang.RuntimeException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard called on obsolete context CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1270181679401.log', position=169)
2010-04-02_04:14:43.52174       at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
2010-04-02_04:14:43.52174       at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
2010-04-02_04:14:43.52174       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
2010-04-02_04:14:43.52174       at java.util.concurrent.FutureTask.run(FutureTask.java:166)
2010-04-02_04:14:43.52174       at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
2010-04-02_04:14:43.52174       ... 2 more
2010-04-02_04:14:43.52174 Caused by: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard called on obsolete context CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1270181679401.log', position=169)
2010-04-02_04:14:43.52174       at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegments(CommitLog.java:358)
2010-04-02_04:14:43.52174       at org.apache.cassandra.db.ColumnFamilyStore$1.runMayThrow(ColumnFamilyStore.java:371)
2010-04-02_04:14:43.52174       at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
2010-04-02_04:14:43.52174       ... 6 more
2010-04-02_04:14:43.52174 Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError: discard called on obsolete context CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1270181679401.log', position=169)
2010-04-02_04:14:43.52174       at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)
2010-04-02_04:14:43.52174       at java.util.concurrent.FutureTask.get(FutureTask.java:111)
2010-04-02_04:14:43.52174       at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegments(CommitLog.java:350)
2010-04-02_04:14:43.52174       ... 8 more
2010-04-02_04:14:43.52174 Caused by: java.lang.AssertionError: discard called on obsolete context CommitLogContext(file='/var/lib/cassandra/commitlog/CommitLog-1270181679401.log', position=169)
2010-04-02_04:14:43.52174       at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegmentsInternal(CommitLog.java:378)
2010-04-02_04:14:43.52174       at org.apache.cassandra.db.commitlog.CommitLog.access$300(CommitLog.java:72)
2010-04-02_04:14:43.52174       at org.apache.cassandra.db.commitlog.CommitLog$6.call(CommitLog.java:344)
2010-04-02_04:14:43.52174       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
2010-04-02_04:14:43.52174       at java.util.concurrent.FutureTask.run(FutureTask.java:166)
2010-04-02_04:14:43.52174       at org.apache.cassandra.db.commitlog.CommitLogExecutorService.process(CommitLogExecutorService.java:113)
2010-04-02_04:14:43.52174       at org.apache.cassandra.db.commitlog.CommitLogExecutorService.access$200(CommitLogExecutorService.java:35)
2010-04-02_04:14:43.52174       at org.apache.cassandra.db.commitlog.CommitLogExecutorService$1.runMayThrow(CommitLogExecutorService.java:67)
2010-04-02_04:14:43.52174       at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
2010-04-02_04:14:43.52174       ... 1 more
;;;","02/Apr/10 18:04;dispalt;Those are the log lines before the exception with the commitlog debugging on full.;;;","05/Apr/10 19:20;jbellis;Okay, here's what's happening.

The assert in question is
        assert context.position > context.getSegment().getHeader().getPosition(id) : ""discard called on obsolete context "" + context;

The first argument, context.position, is ""the position in the current commitlog segment at the time the currently-finishing flush began.""  The second argument is ""the position we wrote in the commitlog segment header showing where the position was for last-completed flush.""  If the current flush position is less than the last flush position, then the last flush potentially deleted segments whose data wasn't turned into sstables yet, which would be Very Bad.  If the positions are equal, that would mean we're flushing a CF that hasn't had any new data since the last one, which isn't supposed to happen either.

But, there's a discontinuity in the position measuring, and that's when a new commitlog context is swapped in.  Let me give a diagram here of the CL segement's contents:

{code}
XXXXXXXXXXXXXXYYYYYYYYYYYYYYZZZZZZZZZZZZZ
0             H             F            etc
{code}

The first H bytes are the header.  From H to position F represents the first mutation written to the fresh segment.

Normally, if you force a memtable to flush after a new commitlog segment is rolled in, one of two things will happen:

(1) you will flush with a context position of H, and a header lastFlushedPosition of 0 (the initial value) or
(2) you will flush with a context position of F or higher, and a header lastFlushedPosition of H (after some writes occur)

But, if the flush context gets measured at H before any writes happen, THEN A WRITE OCCURS DURING THE FLUSH BEFORE THE DISCARD PHASE, you will have context position == lastFlushedPosition == H, because making a write calls turnOn which edits lastFlushedAt, even though no flushes have occurred, because lastFlushedAt is also semantically startReplayAt, and 0 is not a valid place to start mutation replay.  So in the latest stacktrace, H == 169, and it's failing in exactly this scenario.

The least invasive fix for this in 0.6 is to change the assert from > to >=.
;;;","05/Apr/10 19:49;gdusbabek;+1;;;","05/Apr/10 19:54;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"login() request via Thrift/PHP fails with ""Unexpected authentication problem"" in cassandra log / ""Internal error processing login"" in Thrift",CASSANDRA-935,12460737,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,rschildmeijer,redsolar,redsolar,30/Mar/10 20:22,16/Apr/19 09:33,14/Jul/23 05:51,03/Apr/10 21:59,0.7 beta 1,,,,0,,,,,,"When issuing a login request via PHP Thrift with the following parameters:

$auth_request = new cassandra_AuthenticationRequest;
$auth_request->credentials = array (
    ""username"" => ""jsmith"",
     ""password"" => ""havebadpass"",
);
$client->login(""Keyspace1"", $auth_request);

I get an exception, with the following details

PHP Exception:
PHP Fatal error:  Uncaught exception 'TApplicationException' with message 'Internal error processing login' in /home/redsolar/html/includes/thrift/packages/cassandra/Cassandra.php:73

Cassandra log:

ERROR 13:00:53,823 Internal error processing login
java.lang.RuntimeException: Unexpected authentication problem
        at org.apache.cassandra.auth.SimpleAuthenticator.login(SimpleAuthenticator.java:113)
        at org.apache.cassandra.thrift.CassandraServer.login(CassandraServer.java:651)
        at org.apache.cassandra.thrift.Cassandra$Processor$login.process(Cassandra.java:1147)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:1125)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
Caused by: java.lang.NullPointerException
        at java.io.FileInputStream.<init>(FileInputStream.java:133)
        at java.io.FileInputStream.<init>(FileInputStream.java:96)
        at org.apache.cassandra.auth.SimpleAuthenticator.login(SimpleAuthenticator.java:82)
        ... 7 more

File contents (all chmod 777 for testing):

""conf/access.properties""
Keyspace1=jsmith,Elvis Presley,dilbert

""conf/password.properties""
jsmith=havebadpass
Elvis\ Presley=graceland4evar
dilbert=nomoovertime","PHP 5.3, Cassandra 0.6.0-rc1 (as in current vote), CentOS 5.4 x64, 4-node cluster",rschildmeijer,tzz,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Mar/10 19:13;tzz;CASSANDRA-935-check-properties.patch;https://issues.apache.org/jira/secure/attachment/12440379/CASSANDRA-935-check-properties.patch","31/Mar/10 18:56;tzz;CASSANDRA-935-check-properties.patch;https://issues.apache.org/jira/secure/attachment/12440378/CASSANDRA-935-check-properties.patch","31/Mar/10 18:07;rschildmeijer;CASSANDRA-935-v2.patch;https://issues.apache.org/jira/secure/attachment/12440370/CASSANDRA-935-v2.patch","03/Apr/10 07:04;rschildmeijer;CASSANDRA-935-v3.patch;https://issues.apache.org/jira/secure/attachment/12440672/CASSANDRA-935-v3.patch","30/Mar/10 20:52;rschildmeijer;CASSANDRA-935.patch;https://issues.apache.org/jira/secure/attachment/12440275/CASSANDRA-935.patch",,,,,,,,,,5.0,rschildmeijer,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19925,,,Tue Apr 06 13:10:16 UTC 2010,,,,,,,,,,"0|i0g1zj:",91752,,,,,Low,,,,,,,,,,,,,,,,,"30/Mar/10 20:24;jbellis;are you setting -DPASSWD_FILENAME_PROPERTY=path/to/access.properties ?  because that is what SimpleAuthenticator looks for.  (it should probably just try to load from classpath, that seems more java-ish.);;;","30/Mar/10 20:29;rschildmeijer;In fact the property keys are called passwd.properties and access.properties. 
    -Dpasswd.properties=<PATH>/passwd.properties
    -Daccess.properties=<PATH>access.properties

(The PASSWD_FILENAME_PROPERTY is just the name of the static constant)

;;;","30/Mar/10 20:39;redsolar;Running cassandra with ""bin/cassandra -f -Dpasswd.properties=conf/passwd.properties -Daccess.properties=conf/access.properties"" solved the issue
;;;","30/Mar/10 20:51;rschildmeijer;We should probably add a check that everything was properly defined and ""bail out"" otherwise;;;","30/Mar/10 20:52;rschildmeijer;Verifies that access.properties and passwd.properties are defined if SimpleAuthenticator is used (in storage-conf.xml);;;","31/Mar/10 14:30;urandom;I think I'm -1 on this patch Roger. Those authenticators are pluggable, I'd rather that we didn't have implementation details leaking out of them.;;;","31/Mar/10 14:49;rschildmeijer;I agree. 

I was considering a solution that augmented the IAuthenticator interface with methods like isAuthenticationRequired(), getAccessFileName(), getPasswordFileName, but that felt like polluting the interface with implementation specific details.

What speaks for the submitted solution (atleast to some extent) is that we are handling faulty configuration more correctly when using the built in/shipped authentication (SimpleAuthenticator).   ;;;","31/Mar/10 14:57;urandom;I think the correct solution is just to make SimpleAuthenticator produce a clearer error message when it's been misconfigured.;;;","31/Mar/10 15:08;jbellis;Could we add a validateConfiguration method to IAuthenticator?;;;","31/Mar/10 15:28;urandom;works for me.;;;","31/Mar/10 18:56;tzz;What should validateConfiguration() do that login() should not do as well?

I'd rather add the necessary checks to login().  The performance penalty is negligible.  See attached patch.;;;","31/Mar/10 19:01;jbellis;> What should validateConfiguration() do that login() should not do as well? 

fail the startup rather than breaking things when you try to query, which as we've seen here is the wrong approach.;;;","31/Mar/10 19:13;tzz;How about checking in the constructor?  Attaching patch to do it this way.;;;","31/Mar/10 20:08;rschildmeijer;I totaly agree that we should do the validation as early as possible (prefer startup check instead of ""on query check"").
I think the IAuthenticator API is easier to get a correct implementation for using the two method version (see CASSANDRA-935-v2.patch) instead of relying on that implementors throws an exception in the ctor.;;;","31/Mar/10 20:25;tzz;Either validateConfiguration() or in the constructor works.  Assuming your patch goes in, I would distinguish between the two kinds of configuration exception for the two possible missing items or show the actual values in the exception message, e.g.

String.format(""When using %s, properties %s (currently %s) and %s (currently %s) must be defined, ...)
;;;","02/Apr/10 22:22;urandom;I think I prefer the validateConfiguration() approach.

Roger, can you use o.a.c.config.DatabaseDescriptor.ConfigurationException instead of javax.naming.ConfigurationException? I'm also having some trouble applying your patch to trunk/ (maybe it just needs to be rebased).
;;;","03/Apr/10 07:04;rschildmeijer;Patch rebased (v3);;;","03/Apr/10 21:59;urandom;committed; thanks Roger!;;;","06/Apr/10 13:10;hudson;Integrated in Cassandra #399 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/399/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in sstable2json,CASSANDRA-934,12460731,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,brandon.williams,brandon.williams,brandon.williams,30/Mar/10 19:13,16/Apr/19 09:33,14/Jul/23 05:51,30/Mar/10 19:44,0.6.1,,Legacy/Tools,,0,,,,,,"When sstable2json is not passed any excluded keys via -x, an NPE is raised.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Mar/10 19:14;brandon.williams;934.patch;https://issues.apache.org/jira/secure/attachment/12440266/934.patch",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19924,,,Tue Mar 30 19:44:27 UTC 2010,,,,,,,,,,"0|i0g1zb:",91751,,,,,Low,,,,,,,,,,,,,,,,,"30/Mar/10 19:44;jbellis;committed to 0.6 branch;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OutOfBoundException in StorageService.getAllRanges ,CASSANDRA-933,12460730,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,riffraff,riffraff,riffraff,30/Mar/10 19:07,16/Apr/19 09:33,14/Jul/23 05:51,02/Apr/10 13:20,0.6.1,,,,0,,,,,,"this was seen on 0.6-beta3 but it appears to be in trunk too, given the same code for getAllRanges. The problem appeared while accessing a bootstraping node via nodetool, giving the following stacktrace

Exception in thread ""main"" java.lang.ArrayIndexOutOfBoundsException: -1
        at java.util.ArrayList.get(ArrayList.java:324)
        at java.util.Collections$UnmodifiableList.get(Collections.java:1154)
        at org.apache.cassandra.service.StorageService.getAllRanges(StorageService.java:1133)
        at org.apache.cassandra.service.StorageService.getRangeToAddressMap(StorageService.java:440)
        at org.apache.cassandra.service.StorageService.getRangeToEndPointMap(StorageService.java:431)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27)
        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)
        at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:120)
        at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:262)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:836)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:761)
        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1426)
...


Basically, no test is performed for non-emptyness of the input token list. If such list should never be empty, I guess this should be explicit in the interface/javadoc, otherwise I'm attaching a patch & testcase (pretty silly code, but the test passes :) ) ",,,,,,,,,,,600,600,,0%,600,600,,,,,,,,,,,,,,"30/Mar/10 19:09;riffraff;CASSANDRA-933.patch;https://issues.apache.org/jira/secure/attachment/12440265/CASSANDRA-933.patch",,,,,,,,,,,,,,1.0,riffraff,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19923,,,Fri Apr 02 13:20:11 UTC 2010,,,,,,,,,,"0|i0g1z3:",91750,,,,,Low,,,,,,,,,,,,,,,,,"30/Mar/10 19:09;riffraff;simply return empty output on empty input. ;;;","02/Apr/10 13:20;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
incorrect neighbor calculation in repair,CASSANDRA-924,12460506,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,hujn,hujn,29/Mar/10 06:00,16/Apr/19 09:33,14/Jul/23 05:51,05/Apr/10 21:04,0.6.1,,,,0,,,,,,"With Replicationfactor=2, if a server is brought down and its data directory wiped out, it doesn't restore its data replica after restart and nodeprobe repair.
Steps to reproduce:
1) Bring up a cluster with three servers cs1,2,3, with their initial token set to 'foo3', 'foo6', and 'foo9', respectively. ReplicationFactor is set to 2 on all 3.
2) Insert 9 columns with keys from 'foo1' to 'foo9', and flush. Now I have foo1,2,3,7,8,9 on cs1, foo1,2,3,4,5,6, on cs2, and foo4,5,6,7,8,9
on cs3. So far so good
3) Bring down cs3 and wipe out its data directory
4) Bring up cs3
5) run nodeprobe repair Keyspace1 on cs3, the flush
At this point I expect to see cs3 getting its data back. But there's nothing in its data directory. I also tried getting all columns with
ConsistencyLevel::ALL to see if that'll do a read pair. But still cs3's data directory is empty.
",CentOS 5.2,rschildmeijer,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Apr/10 05:08;stuhood;0001-Calculate-neighbors-using-getRangeToEndpointMap.patch;https://issues.apache.org/jira/secure/attachment/12440577/0001-Calculate-neighbors-using-getRangeToEndpointMap.patch","02/Apr/10 05:08;stuhood;0002-Always-trigger-streaming-repairs.patch;https://issues.apache.org/jira/secure/attachment/12440578/0002-Always-trigger-streaming-repairs.patch","02/Apr/10 05:08;stuhood;0003-Unit-test-for-AEService-neighbor-calculation.patch;https://issues.apache.org/jira/secure/attachment/12440579/0003-Unit-test-for-AEService-neighbor-calculation.patch","30/Mar/10 00:39;hujn;cs1.log;https://issues.apache.org/jira/secure/attachment/12440155/cs1.log","29/Mar/10 21:33;hujn;cs1.log;https://issues.apache.org/jira/secure/attachment/12440113/cs1.log","30/Mar/10 00:39;hujn;cs2.log;https://issues.apache.org/jira/secure/attachment/12440156/cs2.log","29/Mar/10 21:33;hujn;cs2.log;https://issues.apache.org/jira/secure/attachment/12440114/cs2.log","30/Mar/10 00:39;hujn;cs3.log;https://issues.apache.org/jira/secure/attachment/12440157/cs3.log","29/Mar/10 21:33;hujn;cs3.log;https://issues.apache.org/jira/secure/attachment/12440115/cs3.log","29/Mar/10 16:59;hujn;error.log;https://issues.apache.org/jira/secure/attachment/12440082/error.log","29/Mar/10 16:09;hujn;error.log;https://issues.apache.org/jira/secure/attachment/12440075/error.log","29/Mar/10 06:02;hujn;error.log;https://issues.apache.org/jira/secure/attachment/12440040/error.log","29/Mar/10 06:02;hujn;storage-conf.xml;https://issues.apache.org/jira/secure/attachment/12440039/storage-conf.xml",,13.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19922,,,Mon Apr 05 21:04:38 UTC 2010,,,,,,,,,,"0|i0g1x3:",91741,,,,,Normal,,,,,,,,,,,,,,,,,"29/Mar/10 06:02;hujn;conf file used in the test and error log;;;","29/Mar/10 14:32;stuhood;Do you have the logs from one of the other machines? AntiEntropyService on the failed box appears to have given the correct result, but both of the other boxes should have had tree mismatches.;;;","29/Mar/10 16:09;hujn;log file from cs1;;;","29/Mar/10 16:35;rschildmeijer;I could be wrong but isn't this exception very simliar to the ""upgrade to jdk build 18""-problem?;;;","29/Mar/10 16:59;hujn;log file from cs2;;;","29/Mar/10 18:47;stuhood;This one is pretty serious... apparently AntiEntropyService is always calculating who to initiate repairs with using getNaturalEndpoints(mytoken), so when RF is less than the number of nodes, it is likely that trees are only sent in one direction (clockwise around the ring). Additionally, we need to do the inverse of getNaturalEndpoints, and determine which other nodes we are holding replicas for.;;;","29/Mar/10 19:44;stuhood;Uses getRangeToAddressMap to calculate all endpoints that node A is storing replicas for, in addition to endpoints storing replicas for node A.;;;","29/Mar/10 20:06;stuhood;Backport of the 924.patch for 0.5.

Jianing: would you mind testing the appropriate patch for your version?;;;","29/Mar/10 21:33;hujn;still doesn't work for me. i've attached logs from all servers.
(i added the ""get neighbors"" log just to be sure i was running the patched code);;;","29/Mar/10 22:51;stuhood;Soo, we resolved one issue, and exposed another. Because less than 5% of possible keys (in the UTF-8 space) were out of sync between the nodes, AntiEntropyService decided not to do a repair.

I'll update the patches with a solution this evening. Thanks for your patience!;;;","29/Mar/10 23:39;jbellis;is the problem that it's guessing for % of ""utf8 space"" instead of ""keys actually on the servers?"";;;","29/Mar/10 23:53;stuhood;Yea, it's a naive comparison based only on the trees. But fixing the stubbed out 'range read-repair' option is much easier.;;;","30/Mar/10 00:06;stuhood;Patches updated to remove stubbed out 'range read-repair' option.

Jianing: can you give your test one more try?;;;","30/Mar/10 00:39;hujn;still no luck. log files attached.;;;","30/Mar/10 01:34;stuhood;I think you might have used the wrong version of the patch (I see log entries that I removed in the most recent version). I just deleted the older version, and I've tested that this version works on a 3 node cluster with RF=2.

Very sorry to use you like a guinea pig like that, but thank you very much for trying out each version.;;;","30/Mar/10 01:53;hujn;Sorry my bad. I was indeed using the wrong patch in my last test (wget renamed the file). The latest patch works!

Thank you so much for bearing with me and getting it fixed so fast.;;;","30/Mar/10 02:04;jbellis;is this something we can add a unit test for?;;;","02/Apr/10 05:08;stuhood;Patchset for 0.6 and trunk, including a test for neighbor calculation.;;;","05/Apr/10 19:44;jbellis;why does the test patch add

endpoints.add(FBUtilities.getLocalAddress());

to forceTableRepair?;;;","05/Apr/10 19:49;stuhood;> why does the test patch add endpoints.add to forceTableRepair?
Rather than implementing the neighbor calculation in two places, I wanted to reuse the logic in AES. In addition to the neighbors, forceTableRepair sends a tree request to localhost, so we add it back to the neighbor list.;;;","05/Apr/10 21:04;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable DEBUG file logging during unit tests,CASSANDRA-923,12460460,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,stuhood,stuhood,28/Mar/10 01:48,16/Apr/19 09:33,14/Jul/23 05:51,28/Mar/10 02:00,0.6,,,,0,,,,,,DEBUG logging to the build/test/logs directory was disabled at some point.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Mar/10 01:48;stuhood;test-logging.patch;https://issues.apache.org/jira/secure/attachment/12439996/test-logging.patch",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19921,,,Sun Mar 28 02:00:39 UTC 2010,,,,,,,,,,"0|i0g1wv:",91740,,,,,Normal,,,,,,,,,,,,,,,,,"28/Mar/10 02:00;jbellis;committed to 0.6 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Deleting and re-inserting row causes error in get_slice count parameter,CASSANDRA-920,12460296,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,brandon.williams,bflorian,bflorian,25/Mar/10 22:52,16/Apr/19 09:33,14/Jul/23 05:51,12/Apr/10 21:14,0.6.1,,,,0,,,,,,"I've found that when I delete an entire row in a column family with super columns, and then re-insert values with the same row and super column keys, the count parameter to the get_slice call no longer works properly.  Its like it is still counting the deleted columns, but only returning the new columns.

The following example uses the Ruby Cassandra client (see link below), but I've seen the same behavior with the Java Thrift interface.

Test code:
--------------
require 'rubygems'
require 'cassandra'
cc = Cassandra.new('Keyspace1')
cc.insert(:Super1,'test-key1',{'bucket1' => {'1' => 'Item 1', '2' => 'Item 2', '5' => 'Item 5'}})
items = cc.get(:Super1,'test-key1','bucket1')
puts ""returned #{items.size} items, should be 3""
cc.remove(:Super1,'test-key1')
items = cc.get(:Super1,'test-key1','bucket1')
puts ""returned #{items.size} items, should be 0""
cc.insert(:Super1,'test-key1',{'bucket1' => {'3' => 'Item 3', '4' => 'Item 4', '6' => 'Item 6'}})
items = cc.get(:Super1,'test-key1','bucket1')
puts ""returned #{items.size} items, should be 3""
items = cc.get(:Super1,'test-key1','bucket1',:count => 3)
puts ""returned #{items.size} items, should be 3""
items = cc.get(:Super1,'test-key1','bucket1',:count => 4)
puts ""returned #{items.size} items, should be 3""
items = cc.get(:Super1,'test-key1','bucket1',:count => 5)
puts ""returned #{items.size} items, should be 3""
items = cc.get(:Super1,'test-key1','bucket1',:count => 6)
puts ""returned #{items.size} items, should be 3""

Output:
returned 3 items, should be 3
returned 0 items, should be 0
returned 3 items, should be 3
returned 1 items, should be 3
returned 2 items, should be 3
returned 2 items, should be 3
returned 3 items, should be 3

Ruby library link:
http://blog.evanweaver.com/files/doc/fauna/cassandra/files/README_rdoc.html",Mac OS/ Java 6,brandon.williams,kingryan,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Apr/10 19:47;brandon.williams;ASF.LICENSE.NOT.GRANTED--0001_add_system_test.txt;https://issues.apache.org/jira/secure/attachment/12441537/ASF.LICENSE.NOT.GRANTED--0001_add_system_test.txt","12/Apr/10 20:58;jbellis;ASF.LICENSE.NOT.GRANTED--920.txt;https://issues.apache.org/jira/secure/attachment/12441545/ASF.LICENSE.NOT.GRANTED--920.txt",,,,,,,,,,,,,2.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19918,,,Mon Apr 12 21:14:32 UTC 2010,,,,,,,,,,"0|i0g1w7:",91737,,,,,Low,,,,,,,,,,,,,,,,,"07/Apr/10 20:38;brandon.williams;Patch to reproduce with a system test.  Note that there is a commented get_count in here.  If you uncomment it, strangely enough, the test passes.;;;","08/Apr/10 00:04;brandon.williams;Oops, I had a bug in that patch.  Now with this one I'm unable to reproduce.;;;","08/Apr/10 19:37;jbellis;Bob, closing since it appears to work fine in Brandon's test.  (Maybe it's a timestamping problem?  I have no idea what resolution the rb client uses by default.);;;","08/Apr/10 19:52;jbellis;reopening to commit test;;;","08/Apr/10 21:03;kingryan;I've rewritten this in terms of our cassandra.gem test suite and can't seem to find a bug in the client. It fails on the last line.

{code}
    @twitter.insert(:StatusRelationships, key,  {'user_timelines' => {@uuids[0] => 'Item 0', @uuids[1] => 'Item 1', @uuids[2] => 'Item 2'}})
    @twitter.remove(:StatusRelationships, key)

    items = @twitter.get(:StatusRelationships, key, 'user_timelines')
    assert_equal 0, items.size

    @twitter.insert(:StatusRelationships, key,
        {'user_timelines' => {@uuids[2] => 'Item 2', @uuids[3] => 'Item 3', @uuids[4] => 'Item 4'}})

    items = @twitter.get(:StatusRelationships, key, 'user_timelines')
    assert_equal 3, items.size

    items = @twitter.get(:StatusRelationships,key,'user_timelines',:count => 3)
    assert_equal 3, items.size 
{code}

And the server logs for this whole test:

{code}
DEBUG - batch_mutate
DEBUG - insert writing local key test_get_super_sub_keys_with_count_after_remove
DEBUG - remove
DEBUG - insert writing local key test_get_super_sub_keys_with_count_after_remove
DEBUG - multiget_slice
DEBUG - weakreadlocal reading SliceFromReadCommand(table='Twitter', key='test_get_super_sub_keys_with_count_after_remove', column_parent='QueryPath(columnFamilyName='StatusRelationships', superColumnName='[B@746a63d3', columnName='null')', start='', finish='', reversed=false, count=100)
DEBUG - batch_mutate
DEBUG - insert writing local key test_get_super_sub_keys_with_count_after_remove
DEBUG - multiget_slice
DEBUG - weakreadlocal reading SliceFromReadCommand(table='Twitter', key='test_get_super_sub_keys_with_count_after_remove', column_parent='QueryPath(columnFamilyName='StatusRelationships', superColumnName='[B@3bd840d9', columnName='null')', start='', finish='', reversed=false, count=100)
DEBUG - collecting 93814000-b668-11b2-8e6a-06dc05f11207:false:6@1270760311002397
DEBUG - collecting 13814000-4eff-11b3-88b0-351600af16aa:false:6@1270760311002397
DEBUG - collecting 13814000-802c-11b4-8782-bede78b81183:false:6@1270760311069304
DEBUG - collecting 13814000-e286-11b6-9ea9-48a9edd974b6:false:6@1270760311069304
DEBUG - collecting 13814000-a73a-11bb-8a14-b8d289de6d53:false:6@1270760311069304
DEBUG - multiget_slice
DEBUG - weakreadlocal reading SliceFromReadCommand(table='Twitter', key='test_get_super_sub_keys_with_count_after_remove', column_parent='QueryPath(columnFamilyName='StatusRelationships', superColumnName='[B@6e37d490', columnName='null')', start='', finish='', reversed=false, count=3)
DEBUG - collecting 93814000-b668-11b2-8e6a-06dc05f11207:false:6@1270760311002397
DEBUG - collecting 13814000-4eff-11b3-88b0-351600af16aa:false:6@1270760311002397
DEBUG - collecting 13814000-802c-11b4-8782-bede78b81183:false:6@1270760311069304
DEBUG - GC for ParNew: 7 ms, 20659648 reclaimed leaving 19819056 used; max is 1211826176
{code}

And the thrift structures for the failing multiget_slice

{code}
<CassandraThrift::ColumnParent column_family:""StatusRelationships"", super_column:""user_timelines"">
<CassandraThrift::SlicePredicate slice_range:<CassandraThrift::SliceRange start:"""", finish:"""", reversed:false, count:3>>
{code}
;;;","08/Apr/10 22:38;brandon.williams;After much head scratching, Ryan and I figured out you have to remove the entire row, not just the subcolumns, to cause this.  Updated system test which does indeed fail.;;;","08/Apr/10 23:17;brandon.williams;Oh, and just to come full circle... if you put a get_count in between the the remove and subsequent slice, it passes.  I guess I had it right in the first patch after all. ;;;","12/Apr/10 18:44;jbellis;{code}
PYTHONPATH=test nosetests --tests=system.test_server:TestMutations.test_super_reinsert
.
----------------------------------------------------------------------
Ran 1 test in 2.432s

OK
{code};;;","12/Apr/10 19:47;brandon.williams;I must have attached the wrong patch, try this one.;;;","12/Apr/10 20:58;jbellis;(Brief) fix attached.

SuperColumns suck.;;;","12/Apr/10 21:03;brandon.williams;+1, both to the patch and SCs sucking.;;;","12/Apr/10 21:14;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
disallow column family names containing hyphens,CASSANDRA-915,12460046,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,,urandom,urandom,23/Mar/10 21:33,16/Apr/19 09:33,14/Jul/23 05:51,19/Apr/10 21:58,0.7 beta 1,,,,0,,,,,,"You cannot use use hyphens in column family names because hyphens are used as delimiters in sstable filenames (which are derived from the CF name). 

It should be an error to configure such a column family name.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-44,"23/Mar/10 22:35;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-915-don-t-allow-hyphens-in-column-family-nam.txt;https://issues.apache.org/jira/secure/attachment/12439616/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-915-don-t-allow-hyphens-in-column-family-nam.txt",,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19917,,,Wed Mar 24 12:40:18 UTC 2010,,,,,,,,,,"0|i0g1v3:",91732,,,,,Low,,,,,,,,,,,,,,,,,"23/Mar/10 22:37;urandom;The attached patch should take care of 0.6 (and trunk for the time being), but this ticket will need to be added as a dependency to CASSANDRA-44 in order to make sure that the new-shiny handles this case as well.;;;","23/Mar/10 22:45;jbellis;+1;;;","23/Mar/10 23:00;urandom;committed to 0.6 and trunk;;;","24/Mar/10 12:40;hudson;Integrated in Cassandra #389 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/389/])
    don't allow hyphens in column family names

Patch by eevans; reviewed by jbellis for 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
QuorumResponseHandler sets timeout incorrectly,CASSANDRA-911,12459899,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,lenn0x,lenn0x,lenn0x,22/Mar/10 19:01,16/Apr/19 09:33,14/Jul/23 05:51,26/Mar/10 01:16,0.6,,,,0,,,,,,"We noticed that the timeout calculation seems wrong:

long timeout = System.currentTimeMillis() - startTime + DatabaseDescriptor.getRpcTimeout();

Lets propose that 3 seconds elapse (currentTime - startTime). It will take that value and add the default RpcTimeout (5 seconds) making the timeout 8 seconds.",,rschildmeijer,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Mar/10 19:02;lenn0x;0001-CASSANDRA-911-fixed-incorrect-timeout-calculation.patch;https://issues.apache.org/jira/secure/attachment/12439491/0001-CASSANDRA-911-fixed-incorrect-timeout-calculation.patch","25/Mar/10 19:17;rschildmeijer;CASSANDRA-911.patch;https://issues.apache.org/jira/secure/attachment/12439812/CASSANDRA-911.patch",,,,,,,,,,,,,2.0,lenn0x,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19915,,,Fri Mar 26 17:40:51 UTC 2010,,,,,,,,,,"0|i0g1u7:",91728,,,,,Low,,,,,,,,,,,,,,,,,"22/Mar/10 19:18;jbellis;+1, can you apply to WRH and AsyncResult too?;;;","25/Mar/10 19:17;rschildmeijer;Fixed timeout calculation for QRH, WRH and AsyncResult;;;","25/Mar/10 22:17;lenn0x;+1. Ill commit;;;","26/Mar/10 17:40;jbellis;updated CHANGES;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TimeUUID comparator identify different UUID as long as they have same timestamp,CASSANDRA-907,12459667,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,slebresne,slebresne,19/Mar/10 15:57,16/Apr/19 09:33,14/Jul/23 05:51,19/Mar/10 19:51,0.6,,,,0,,,,,,Everything's in the title. As such TimeUUID behave as simple timestamp which is weird at best.,,david.pan,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Mar/10 15:58;slebresne;TimeUUID_compareSameTimestamp.diff;https://issues.apache.org/jira/secure/attachment/12439283/TimeUUID_compareSameTimestamp.diff","19/Mar/10 16:12;jalessi;test case.txt;https://issues.apache.org/jira/secure/attachment/12439287/test+case.txt","19/Mar/10 16:41;slebresne;testDifferentTimeUUIDSameTimestamp.diff;https://issues.apache.org/jira/secure/attachment/12439292/testDifferentTimeUUIDSameTimestamp.diff",,,,,,,,,,,,3.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19913,,,Fri Mar 19 19:51:11 UTC 2010,,,,,,,,,,"0|i0g1tb:",91724,,,,,Low,,,,,,,,,,,,,,,,,"19/Mar/10 16:03;jbellis;can you add a Test case that catches the original bug?;;;","19/Mar/10 16:12;jalessi;The attached file has a test case in it that reproduces the bug;;;","19/Mar/10 16:18;jbellis;to clarify: a junit test case for ""ant test"" :);;;","19/Mar/10 16:41;slebresne;Posting a test for the test_server.py script.
I can come up with a test for the junit test if you prefer but there 
doesn't seems to be junit tests for TimeUUID right now.

As a side note, the system tests (test_server) seems a bit 
broken. The 'test_bad_calls' fails when insert is called with 
null argument because the thrift exception sent must have 
changed somehow. But you have to regenerate the thrift 
java binding (and recompile) to see the failing tests.;;;","19/Mar/10 19:51;jbellis;added junit test and committed to 0.6 and trunk, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mixed use of Stage's name. Must use public static field.,CASSANDRA-906,12459602,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,rodrigoap,rodrigoap,rodrigoap,19/Mar/10 02:25,16/Apr/19 09:33,14/Jul/23 05:51,02/Apr/10 13:23,0.7 beta 1,,,,0,correctness,,,,,"This line in StageManger is not using the public static field to reference the Stage's name:

        stages.put(RESPONSE_STAGE, multiThreadedStage(""RESPONSE-STAGE"", Runtime.getRuntime().availableProcessors()));

It should be:

        stages.put(RESPONSE_STAGE, multiThreadedStage(RESPONSE_STAGE, Runtime.getRuntime().availableProcessors()));
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Mar/10 02:34;rodrigoap;CASSANDRA-906.patch;https://issues.apache.org/jira/secure/attachment/12439232/CASSANDRA-906.patch",,,,,,,,,,,,,,1.0,rodrigoap,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19912,,,Tue Apr 06 13:10:16 UTC 2010,,,,,,,,,,"0|i0g1t3:",91723,,,,,Low,,,,,,,,,,,,,,,,,"02/Apr/10 13:23;jbellis;committed;;;","06/Apr/10 13:10;hudson;Integrated in Cassandra #399 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/399/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bootstrapping might skip needed ranges.,CASSANDRA-902,12459419,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,17/Mar/10 19:40,16/Apr/19 09:33,14/Jul/23 05:51,17/Mar/10 22:23,0.6,,,,0,,,,,,"Bootstrapper.getRangeWithSources should return a multimap with as many keys as myRangeAddresses.  But with the way the two loops are structured, they are not guaranteed to ever examine all of myRanges.  To see why, consider a scenario where the inner-loop breaks on the first element in myRanges.  myRangeAddresses will only ever have one key in it.

Solution is to swap the order of the loops.",,david.pan,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Mar/10 19:43;gdusbabek;bootstrap-range-addr-calculation.txt;https://issues.apache.org/jira/secure/attachment/12439060/bootstrap-range-addr-calculation.txt",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19911,,,Wed Mar 17 20:29:54 UTC 2010,,,,,,,,,,"0|i0g1s7:",91719,,,,,Normal,,,,,,,,,,,,,,,,,"17/Mar/10 19:43;gdusbabek;patched against trunk.  The same code exists in 5, so is likely a problem there too.;;;","17/Mar/10 20:17;gdusbabek;This appears to only be a problem when the number of pending ranges for a node is greater than the number of ranges currently in place (which can't happen in 0.6).  If so, this only needs to be fixed in trunk and I can roll it in to CASSANDRA-826.;;;","17/Mar/10 20:29;jbellis;+1 0.6 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
skipBytes in SSTable*Iterator is in an assert,CASSANDRA-899,12459125,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,slebresne,slebresne,15/Mar/10 10:19,16/Apr/19 09:33,14/Jul/23 05:51,15/Mar/10 15:50,0.6,,,,0,,,,,,"In SSTable Name and Slice iterator, the seek to the indexed offset is in an assert. 
As a consequence, if Cassandra is run without assertions, reads (specially for large 
rows) can be really inefficient.",,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Mar/10 10:19;slebresne;899-codeWithSideEffectInAssert.diff;https://issues.apache.org/jira/secure/attachment/12438809/899-codeWithSideEffectInAssert.diff",,,,,,,,,,,,,,1.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19910,,,Mon Mar 15 15:50:02 UTC 2010,,,,,,,,,,"0|i0g1rj:",91716,,,,,Low,,,,,,,,,,,,,,,,,"15/Mar/10 15:50;jbellis;committed, thanks!;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace incubator site with a redirect,CASSANDRA-895,12459070,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,,johanoskarsson,johanoskarsson,14/Mar/10 09:10,16/Apr/19 09:33,14/Jul/23 05:51,14/Mar/10 23:27,,,Legacy/Documentation and Website,,0,,,,,,The incubator website is still up with broken links. We should make it redirect to the new TLP version of the website.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Mar/10 09:14;johanoskarsson;index.html;https://issues.apache.org/jira/secure/attachment/12438744/index.html",,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19908,,,Sun Mar 14 23:27:26 UTC 2010,,,,,,,,,,"0|i0g1qn:",91712,,,,,Critical,,,,,,,,,,,,,,,,,"14/Mar/10 09:10;johanoskarsson;It seems I don't have access to change anything in the incubator version of the website.;;;","14/Mar/10 09:14;johanoskarsson;Snippet of html that redirects to the new site.;;;","14/Mar/10 23:27;iholsman;updated website with HTML.
will be live when it gets synced.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OOM on Commit log Replay,CASSANDRA-885,12458978,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,pquerna,pquerna,12/Mar/10 20:50,16/Apr/19 09:33,14/Jul/23 05:51,19/Mar/10 21:32,0.6,,,,0,,,,,,"Running 0.5.

We had a node reboot, and when it came back up, it was unable to replay the commit logs, it would OOM every time.

We upped the max heap to 6 gigs, but it didn't help.

I have a heap dump and have it opened in Eclipse MAT.

Anything specific I should pull out?

Class Name                                                                                   | Shallow Heap | Retained Heap | Percentage 
----------------------------------------------------------------------------------------------------------------------------------------
                                                                                             |              |               |            
org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor @ 0x7fad06454f48                |          112 | 2,604,583,312 |     84.35% 
|- java.util.concurrent.LinkedBlockingQueue @ 0x7fad06405b78                                 |           80 | 2,604,579,864 |     84.35% 
|- java.util.HashSet @ 0x7fad071b2110                                                        |           24 |         2,952 |      0.00% 
|- java.lang.String @ 0x7fad071b3588  org.apache.cassandra.concurrent:type=ROW-MUTATION-STAGE|           40 |           176 |      0.00% 
|- org.apache.cassandra.concurrent.NamedThreadFactory @ 0x7fad0714e998                       |           32 |            56 |      0.00% 
|- java.util.concurrent.locks.ReentrantLock$NonfairSync @ 0x7fad0722b570                     |           48 |            48 |      0.00% 
|- java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject @ 0x7fad071b3560    |           40 |            40 |      0.00% 
|- java.util.concurrent.atomic.AtomicInteger @ 0x7fad071b20e0                                |           24 |            24 |      0.00% 
|- java.util.concurrent.locks.ReentrantLock @ 0x7fad071b20f8                                 |           24 |            24 |      0.00% 
|- java.util.concurrent.ThreadPoolExecutor$CallerRunsPolicy @ 0x7fad071b2128                 |           16 |            16 |      0.00% 
'- Total: 9 entries                                                                          |              |               |            
org.apache.cassandra.db.ColumnFamilyStore @ 0x7fad063b3390                                   |          104 |    95,871,520 |      3.10% 
org.apache.cassandra.db.ColumnFamilyStore @ 0x7fad063b3460                                   |          104 |    82,056,536 |      2.66% 
org.apache.cassandra.db.ColumnFamilyStore @ 0x7fad063b3188                                   |          104 |    72,894,176 |      2.36% 
org.apache.cassandra.db.ColumnFamilyStore @ 0x7fad06331798                                   |          104 |    45,394,360 |      1.47% 
org.apache.cassandra.db.ColumnFamilyStore @ 0x7fad06331660                                   |          104 |    33,895,560 |      1.10% 
java.lang.Thread @ 0x7fad060e2320  main Native Stack, Thread                                 |          168 |    33,573,328 |      1.09% 
org.apache.cassandra.db.ColumnFamilyStore @ 0x7fad06287e50                                   |          104 |    33,528,680 |      1.09% 
org.apache.cassandra.db.ColumnFamilyStore @ 0x7fad063b3530                                   |          104 |    33,423,720 |      1.08% 
org.apache.cassandra.db.ColumnFamilyStore @ 0x7fad063b32c0                                   |          104 |    20,221,624 |      0.65% 
org.apache.cassandra.db.Memtable @ 0x7fad06410120                                            |           96 |     9,383,880 |      0.30% 
org.apache.cassandra.db.ColumnFamily @ 0x7fad33df3690                                        |           80 |     1,190,016 |      0.04% 
org.apache.cassandra.io.SSTableReader @ 0x7fad0653a4a0                                       |           72 |       587,008 |      0.02% 
org.apache.cassandra.io.SSTableReader @ 0x7fad06c41ef0                                       |           72 |       543,552 |      0.02% 
org.apache.cassandra.io.SSTableReader @ 0x7fad06456450                                       |           72 |       541,320 |      0.02% 
Total: 15 of 49,239 entries                                                                  |              |               |            
----------------------------------------------------------------------------------------------------------------------------------------
",,brandon.williams,david.pan,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Mar/10 22:30;jbellis;885-v3.txt;https://issues.apache.org/jira/secure/attachment/12438982/885-v3.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19903,,,Fri Mar 19 21:32:47 UTC 2010,,,,,,,,,,"0|i0g1of:",91702,,,,,Normal,,,,,,,,,,,,,,,,,"12/Mar/10 20:53;kingryan;Did you have a large number of hints on this node?;;;","12/Mar/10 21:05;pquerna;It should not of had hinted handoff, it was the only machine that was down at this time.;;;","15/Mar/10 15:29;brandon.williams;Perhaps this is related to CASSANDRA-896?  I think Paul mentioned on irc that most of his heap was in LinkedBlockingQueue.;;;","15/Mar/10 15:32;jbellis;it should definitely do a full GC before OOMing, though.  the jvm is quite thorough about that (hence the gc storm behavior as you approach the limit);;;","16/Mar/10 22:12;jbellis;If I'm reading the MAT thing correctly, it's saying 85% of the ram is used by the ROW-MUTATION executor queue, meaning that commitlog recovery was reading mutations + shoving them in the queue faster than they could be consumed and applied.

Applying the stage limits from the first patch of CASSANDRA-685 should fix this, although the rest of 685 will have to wait for 0.7.;;;","16/Mar/10 22:24;jbellis;attached.;;;","16/Mar/10 22:27;jbellis;v2 fixes buggy assert;;;","16/Mar/10 22:30;jbellis;v3 sets minimum of 2 threads on read, write, and response threads;;;","19/Mar/10 19:38;brandon.williams;+1, performance is still good.;;;","19/Mar/10 21:32;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
get_range_slice returns multiple copies of each row for ConsistencyLevel > ONE,CASSANDRA-884,12458977,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,omerhj,omerhj,omerhj,12/Mar/10 20:50,16/Apr/19 09:33,14/Jul/23 05:51,19/Mar/10 20:36,0.6,,,,0,,,,,,"I've noticed that both 0.5.1 and 0.6b2 return multiple identical copies of the data stored in my keyspace whenever I make a call to get_range_slice or get_range_slices using
ConsistencyLevel.QUORUM and ReplicationFactor is greater than one.

So with ReplicationFactor set to 2 for my application's KeySpace I get double the number of KeySlices that I expect to get. When using ConsistencyLevel.ONE I get only one KeySlice for each row.

I've seen this happen with Cassandra 0.5.1 and with 0.6 beta 2. The behavior on 0.6 beta 2 is exhibited with both get_range_slice and get_range_slices.

The attached Java program demonstrates the issue for 0.6 beta 2. The program writes a series of single-column rows into the Standard1 table, and then uses get_range_slice to receive a list of all row. The returned number of rows is consistently twice the number of rows written to the database. I wipe out the database completely before running the test.
",4-cluster Gentoo Linux 2.6.18 with a ReplicationFactor of 2,ajslater,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Mar/10 20:28;omerhj;0001-RangeSliceResponseResolver.patch;https://issues.apache.org/jira/secure/attachment/12438957/0001-RangeSliceResponseResolver.patch","16/Mar/10 20:57;jbellis;884-v2.txt;https://issues.apache.org/jira/secure/attachment/12438962/884-v2.txt","12/Mar/10 20:53;omerhj;TestApp2.java;https://issues.apache.org/jira/secure/attachment/12438639/TestApp2.java",,,,,,,,,,,,3.0,omerhj,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19902,,,Mon May 31 23:29:19 UTC 2010,,,,,,,,,,"0|i0g1o7:",91701,,,,,Normal,,,,,,,,,,,,,,,,,"12/Mar/10 20:53;omerhj;The attached Java program demonstrates that multiple copies of rows are returned by get_range_slice. At least it does here :-);;;","16/Mar/10 20:28;omerhj;I think I have identified the source of my problem. I'm still new to the Cassandra source code so I could have this completely wrong. The patch is for the 0.6 version of org.apache.cassandra.service.RangeSliceResponseResolver.

Removing redundant copies of returned rows appears to happen in the RangeSliceResponseResolver class. This class uses an anonymous innner class that extends ReducingIterator to weed out the duplicates.

ReducingIterator provides a computeNext() method that compares successive items to see if they are duplicates. It does this by comparing the current and previous ('last') items to its isEqual() method.

RangeSliceResponseResolver does not override that isEqual method. That causes Pair<Row, InetAddress> objects to be compared with each other.  The ReducingIterator.isEqual method always returns false, because (1)  Row doesn't specify an equals() method and (2) even if it did, the InetAddresses of rows retrieved from different Cassandra instances would still be different. This causes each row to be seen as unique.

The attached patch repairs this by providing the ReducingIterator derivative in RangeSliceResponseResolver with an isEqual() method that compares the key and cf members of the Row objects. It ignores the InetAddress component of the Pair.

Alternatively I could have added an equals() method to Row which would have simplified the isEqual() method in RangeSliceResponseResolver.java a bit.

;;;","16/Mar/10 20:57;jbellis;Your analysis is spot on, good work there.

I think though that equals should just look at the key: we want to collect (in the ""reduced"" list) all versions of the rows associated with that key, so we can repair any differences.  If we only collect identical versions together then the repair is a no-op.

Attached is a diff that makes this change and adds a missing versionSources.clear() call.;;;","16/Mar/10 20:58;jbellis;Can you test v2?;;;","18/Mar/10 16:05;omerhj;Your v2 patch works for me. The attached TestApp2 now gives back the expected result. Also, all JUnit test cases for my Cassandra-using application now pass. Thanks!
;;;","18/Mar/10 16:25;jbellis;committed, thanks!;;;","19/Mar/10 18:35;omerhj;We've started using the wrapper API I've written for Cassandra for light development here and quite unexpectedly I've started getting NullPointerExceptions whenever a get_range_slices request is performed against a particular CF. The CF in question has a replication factor of 2. get_range_slices still works fine against the Standard1 CF that's exercised by the TestApp2 file included in this ticket. In my storage-conf.xml Standard1 is set up with a replication factor of 3.

Here is the stack trace I'm seeing over and over again, on each of my 4 servers:

ERROR [pool-1-thread-64] 2010-03-19 12:23:30,119 Cassandra.java (line 1440) Internal error processing get_range_slices
java.lang.NullPointerException
        at org.apache.cassandra.service.RangeSliceResponseResolver$2.isEqual(RangeSliceResponseResolver.java:81)
        at org.apache.cassandra.service.RangeSliceResponseResolver$2.isEqual(RangeSliceResponseResolver.java:74)
        at org.apache.cassandra.utils.ReducingIterator.computeNext(ReducingIterator.java:69)
        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:135)
        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:130)
        at org.apache.cassandra.service.RangeSliceResponseResolver.resolve(RangeSliceResponseResolver.java:101)
        at org.apache.cassandra.service.RangeSliceResponseResolver.resolve(RangeSliceResponseResolver.java:41)
        at org.apache.cassandra.service.QuorumResponseHandler.get(QuorumResponseHandler.java:86)
        at org.apache.cassandra.service.StorageProxy.getRangeSlice(StorageProxy.java:592)
        at org.apache.cassandra.thrift.CassandraServer.getRangeSlicesInternal(CassandraServer.java:587)
        at org.apache.cassandra.thrift.CassandraServer.get_range_slices(CassandraServer.java:559)
        at org.apache.cassandra.thrift.Cassandra$Processor$get_range_slices.process(Cassandra.java:1432)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:1115)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)

Additional notes:
I'm using revision 924837 of the Cassandra 0.6 branch which includes the patch above. For some reason the line numbers in RangeSliceResponseResolver seem to be off by one in the stack trace, but I'm positive that it's the patched version being used with the isEqual() method that tests only the keys.

I guess this might be fixed by adding a few null checks to that isEqual() method, but perhaps that would just be hiding a problem somewhere else in the code.
;;;","19/Mar/10 18:56;jbellis;Can you add this to isEqual to see which part is null?  You're right, that ""shouldn't happen,"" let's not just band-aid w/ null checks.

                assert o1 != null && o2 != null : ""null pair"";
                assert o1.left != null && o2.left != null : ""null row"";
;;;","19/Mar/10 20:26;omerhj;During my last build an apache-casssandra-0.6-b2.jar somehow made its way into the lib directories, overriding the newer 0.6-b3.jar that I should have been using. I removed the older apache-casssandra-0.6-b2.jar file that contained my older patch, restarted my instances and the problem disappeared. So it looks likely that this was operator error on my part. 




;;;","19/Mar/10 20:36;jbellis;k, marking closed again;;;","31/May/10 21:07;ajslater;Please re-open or duplicate.

Testing with 0.6-trunk today:

Reading with CL > ONE returns multiple copies of the same column per key consistent with the replicas queried before return. i.e,  for RC=3, a QUORUM read yields 2 copies and an ALL read returns 3.
This is with pycassa get_range() which is using get_range_slice()

I see the same behavior with 0.6.1 and 0.6.2 debs

If my experience is not unique, anyone using get_range_slice is now deluged with duplicate data.;;;","31/May/10 22:16;jbellis;AJ, can you create a new issue with some sample code to reproduce what you are seeing?;;;","31/May/10 23:29;ajslater;CASSANDRA-1145 Opened;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RowWarningThreshold doesn't allow values more than about 2GB,CASSANDRA-882,12458946,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,slebresne,slebresne,12/Mar/10 15:08,16/Apr/19 09:33,14/Jul/23 05:51,12/Mar/10 20:34,0.6,,,,0,,,,,,"Using values bigger than 2048 for RowWarningThreshold makes 
Cassandra not start with the message: 
  Fatal error: Row warning threshold must be a positive integer",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Mar/10 15:10;slebresne;882-fix_rowWarningThresholdLimit.diff;https://issues.apache.org/jira/secure/attachment/12438617/882-fix_rowWarningThresholdLimit.diff",,,,,,,,,,,,,,1.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19900,,,Fri Mar 12 20:29:59 UTC 2010,,,,,,,,,,"0|i0g1nr:",91699,,,,,Low,,,,,,,,,,,,,,,,,"12/Mar/10 20:29;gdusbabek;+1;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Invalid host/port parameters to cassandra-cli leaves system in unrecoverable state,CASSANDRA-867,12458579,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,mwn,mwn,mwn,09/Mar/10 20:44,16/Apr/19 09:33,14/Jul/23 05:51,09/Mar/10 21:03,0.6,,Legacy/Tools,,0,,,,,,"bin\cassandra-cl.bati -host localhost -port 8880  (cassandra not running localhost/8880 ;) ) 

Starting Cassandra Client
Exception connecting to localhost/8880 - java.net.ConnectException: Connection refused: connect
Welcome to cassandra CLI.

Type 'help' or '?' for help. Type 'quit' or 'exit' to quit.
cassandra> j
Exception null
cassandra> quit
Exception null

Problem is that main does not ensure that cliClient_ is set to an instanse of CliClient.",WinXP / java 1.6 / svn @ 921110 trunk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Mar/10 20:47;mwn;CASSANDRA-867.patch;https://issues.apache.org/jira/secure/attachment/12438326/CASSANDRA-867.patch",,,,,,,,,,,,,,1.0,mwn,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19897,,,Tue Mar 09 21:03:58 UTC 2010,,,,,,,,,,"0|i0g1kf:",91684,,,,,Low,,,,,,,,,,,,,,,,,"09/Mar/10 20:47;mwn;Small patch to solve above issue.;;;","09/Mar/10 21:03;jbellis;committed, thanks;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AssertionError SSTableSliceIterator.java:126,CASSANDRA-866,12458569,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,btoddb,btoddb,09/Mar/10 18:24,16/Apr/19 09:33,14/Jul/23 05:51,13/Apr/10 02:22,0.6.1,,,,0,,,,,,"also seeing these, using cassandra-0.6.0-beta2/

2010-03-09 07:37:57,683 ERROR [ROW-READ-STAGE:77] [CassandraDaemon.java:78] Fatal exception in thread Thread[ROW-READ-STAGE:77,5,main]
java.lang.AssertionError
        at org.apache.cassandra.db.filter.SSTableSliceIterator$ColumnGroupReader.<init>(SSTableSliceIterator.java:126)
        at org.apache.cassandra.db.filter.SSTableSliceIterator.<init>(SSTableSliceIterator.java:59)
        at org.apache.cassandra.db.filter.SliceQueryFilter.getSSTableColumnIterator(SliceQueryFilter.java:63)
        at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:851)
        at org.apache.cassandra.db.ColumnFamilyStore.cacheRow(ColumnFamilyStore.java:748)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:773)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:740)
        at org.apache.cassandra.db.Table.getRow(Table.java:381)
        at org.apache.cassandra.db.SliceByNamesReadCommand.getRow(SliceByNamesReadCommand.java:56)
        at org.apache.cassandra.db.ReadVerbHandler.doVerb(ReadVerbHandler.java:80)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:40)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
",,brandon.williams,johanoskarsson,thuske,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Apr/10 13:06;jbellis;ASF.LICENSE.NOT.GRANTED--866.txt;https://issues.apache.org/jira/secure/attachment/12441337/ASF.LICENSE.NOT.GRANTED--866.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19896,,,Tue Apr 13 02:22:40 UTC 2010,,,,,,,,,,"0|i0g1k7:",91683,,,,,Normal,,,,,,,,,,,,,,,,,"09/Mar/10 18:56;jbellis;are you missing the ""caused by"" part of the exception?  this looks like CASSANDRA-857 to me;;;","09/Mar/10 19:09;btoddb;unfortunately i no longer have the log.  i don't believe i missed a caused by, but i'll keep an eye out for this error to happen again;;;","09/Mar/10 20:28;btoddb;Actually i did have the logs and there is no caused by for these AssertionErrors;;;","16/Mar/10 16:28;btoddb;i still see these a lot ... here is a slightly different stack trace:

2010-03-16 06:57:20,191 ERROR [HINTED-HANDOFF-POOL:1] [DebuggableThreadPoolExecutor.java:94] Error in executor futuretask
java.util.concurrent.ExecutionException: java.lang.AssertionError
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:86)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.AssertionError
        at org.apache.cassandra.db.filter.SSTableSliceIterator$ColumnGroupReader.<init>(SSTableSliceIterator.java:126)
        at org.apache.cassandra.db.filter.SSTableSliceIterator.<init>(SSTableSliceIterator.java:59)
        at org.apache.cassandra.db.filter.SliceQueryFilter.getSSTableColumnIterator(SliceQueryFilter.java:63)
        at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:800)
        at org.apache.cassandra.db.ColumnFamilyStore.cacheRow(ColumnFamilyStore.java:697)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:722)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:689)
        at org.apache.cassandra.db.HintedHandOffManager.sendMessage(HintedHandOffManager.java:122)
        at org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:250)
        at org.apache.cassandra.db.HintedHandOffManager.access$100(HintedHandOffManager.java:80)
        at org.apache.cassandra.db.HintedHandOffManager$2.runMayThrow(HintedHandOffManager.java:280)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
;;;","19/Mar/10 21:35;jbellis;how big are the index files corresponding to your sstables?  in particular, do you have any > 2 GB?;;;","22/Mar/10 22:10;btoddb;yes ...

-rw-rw-r-- 1 bburruss bburruss 2506278504 Mar 22 14:09 /data/cassandra-data/data/uds/bucket-2858-Index.db
-rw-rw-r-- 1 bburruss bburruss  170769982 Mar 22 14:24 /data/cassandra-data/data/uds/bucket-3150-Index.db
-rw-rw-r-- 1 bburruss bburruss  170040554 Mar 22 14:39 /data/cassandra-data/data/uds/bucket-3155-Index.db
-rw-rw-r-- 1 bburruss bburruss   45092660 Mar 22 14:41 /data/cassandra-data/data/uds/bucket-3156-Index.db
-rw-rw-r-- 1 bburruss bburruss    5758530 Mar 22 14:47 /data/cassandra-data/data/uds/bucket-3161-Index.db
-rw-rw-r-- 1 bburruss bburruss    5775322 Mar 22 14:52 /data/cassandra-data/data/uds/bucket-3166-Index.db
-rw-rw-r-- 1 bburruss bburruss    1454824 Mar 22 14:53 /data/cassandra-data/data/uds/bucket-3167-Index.db
-rw-rw-r-- 1 bburruss bburruss    1439313 Mar 22 14:54 /data/cassandra-data/data/uds/bucket-3168-Index.db
-rw-rw-r-- 1 bburruss bburruss    1448648 Mar 22 14:54 /data/cassandra-data/data/uds/bucket-3169-Index.db
-rw-rw-r-- 1 bburruss bburruss    1447836 Mar 22 14:55 /data/cassandra-data/data/uds/bucket-3170-Index.db
-rw-rw-r-- 1 bburruss bburruss    5778333 Mar 22 14:56 /data/cassandra-data/data/uds/bucket-3171-Index.db
-rw-rw-r-- 1 bburruss bburruss    1473373 Mar 22 14:56 /data/cassandra-data/data/uds/bucket-3172-Index.db
-rw-rw-r-- 1 bburruss bburruss    1457463 Mar 22 14:57 /data/cassandra-data/data/uds/bucket-3173-Index.db
-rw-rw-r-- 1 bburruss bburruss    1462000 Mar 22 14:58 /data/cassandra-data/data/uds/bucket-3174-Index.db
-rw-rw-r-- 1 bburruss bburruss    1451259 Mar 22 14:59 /data/cassandra-data/data/uds/bucket-3175-Index.db
-rw-rw-r-- 1 bburruss bburruss    5829897 Mar 22 14:59 /data/cassandra-data/data/uds/bucket-3176-Index.db
-rw-rw-r-- 1 bburruss bburruss   22964898 Mar 22 15:00 /data/cassandra-data/data/uds/bucket-3177-Index.db
-rw-rw-r-- 1 bburruss bburruss    1475776 Mar 22 15:00 /data/cassandra-data/data/uds/bucket-3178-Index.db
-rw-rw-r-- 1 bburruss bburruss    1462095 Mar 22 15:01 /data/cassandra-data/data/uds/bucket-3179-Index.db
-rw-rw-r-- 1 bburruss bburruss    1453720 Mar 22 15:02 /data/cassandra-data/data/uds/bucket-3180-Index.db
-rw-rw-r-- 1 bburruss bburruss    1337336 Mar 22 15:03 /data/cassandra-data/data/uds/bucket-3181-Index.db
-rw-rw-r-- 1 bburruss bburruss    5718888 Mar 22 15:03 /data/cassandra-data/data/uds/bucket-3182-Index.db
-rw-rw-r-- 1 bburruss bburruss    1489499 Mar 22 15:04 /data/cassandra-data/data/uds/bucket-3183-Index.db
-rw-rw-r-- 1 bburruss bburruss    1520616 Mar 22 15:05 /data/cassandra-data/data/uds/bucket-3184-Index.db
;;;","22/Mar/10 22:24;jbellis;Can you test w/ latest 0.6 svn branch, to see if the fix in CASSANDRA-857 for large index files helps?  (this did not make it into beta3 unfortunately);;;","22/Mar/10 22:41;btoddb;trying it now;;;","22/Mar/10 23:43;btoddb;slightly different, but still getting error

2010-03-22 16:39:26,164 ERROR [ROW-READ-STAGE:22] [CassandraDaemon.java:78] Fatal exception in thread Thread[ROW-READ-STAGE:22,5,main]
java.lang.AssertionError: DecoratedKey(151727172804471108783669089800305019461, vmguest85__791890602)
        at org.apache.cassandra.db.filter.SSTableNamesIterator.<init>(SSTableNamesIterator.java:56)
        at org.apache.cassandra.db.filter.NamesQueryFilter.getSSTableColumnIterator(NamesQueryFilter.java:69)
        at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:830)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:750)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:719)
        at org.apache.cassandra.db.Table.getRow(Table.java:381)
        at org.apache.cassandra.db.SliceByNamesReadCommand.getRow(SliceByNamesReadCommand.java:56)
        at org.apache.cassandra.db.ReadVerbHandler.doVerb(ReadVerbHandler.java:80)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:40)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
;;;","26/Mar/10 19:59;jbellis;What is the difference between queries that work, and queries that do not?

(I'm assuming you do have some queries that work.)

Do the problematic ones start working when you force DiskAccessMode to standard?;;;","26/Mar/10 20:16;btoddb;all of my queries are the same - i'm doing straight get, put, deletes.  one column family, one column.  get a ""bucket"" of data, put a ""bucket"" of data.

i don't know which ones are working at which ones don't.  i haven't tried correlating the AssertionError back to a particular request.  i can say that not all gets fail.

last night i saw a bunch of AssertionErrors and then eventually the node OOM exception.  what assertion is failing?

here's my column family definition.

      <ColumnFamily CompareWith=""BytesType"" Name=""bucket""
                    RowsCached=""20%""
                    KeysCached=""0%""
                    />
;;;","26/Mar/10 20:30;jbellis;I've committed an improved assertion to the 0.6 branch that will give the key and filename involved so we can have a look and see what's going on there.;;;","26/Mar/10 20:31;jbellis;Please re-test with that, and if the given data file is small enough, zip it up w/ its index and filter and send it to my gmail address.  Otherwise we can work out another way to test.;;;","28/Mar/10 02:13;jbellis;Bumping to 0.6.1.

In the meantime, if you are affected by this switching DiskAccessMode to standard should work around the bug.;;;","28/Mar/10 02:18;btoddb;I'm out of the office.  Back on 4/5/2010.
;;;","01/Apr/10 19:20;brandon.williams;I tried reproducing this with the data set provided.  I couldn't reproduce at all on a 64bit jvm, and I tried on a 32bit, which also succeeded with the disk mode set to auto.  I had a theory that this was caused by forcing mmap mode on 32bits, but that actually raises a different exception:

Exception in thread ""main"" java.io.IOException: Map failed
        at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:803)
        at org.apache.cassandra.io.SSTableReader.mmap(SSTableReader.java:206)
        at org.apache.cassandra.io.SSTableReader.<init>(SSTableReader.java:152)
        at org.apache.cassandra.io.SSTableReader.<init>(SSTableReader.java:216)
        at org.apache.cassandra.io.SSTableReader.open(SSTableReader.java:121)
        at org.apache.cassandra.io.SSTableReader.open(SSTableReader.java:112)
        at org.apache.cassandra.tools.SSTableExport.export(SSTableExport.java:304)
        at org.apache.cassandra.tools.SSTableExport.export(SSTableExport.java:329)
        at org.apache.cassandra.tools.SSTableExport.main(SSTableExport.java:373)
Caused by: java.lang.OutOfMemoryError: Map failed
        at sun.nio.ch.FileChannelImpl.map0(Native Method)
        at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:800)
        ... 8 more


Todd, can you give us more details about your environment?;;;","01/Apr/10 19:28;jbellis;the most important question is, ""what key is failing.""  (this is part of the error message, now.);;;","01/Apr/10 19:28;jbellis;... and does it fail reproducibly, and if so, what query can we use to repro.;;;","06/Apr/10 16:21;jbellis;Todd: can you update?;;;","06/Apr/10 16:50;btoddb;64bit CentOS  2.6.18

single column family, only one column.  simple get, put, deletes.  would you like my storage-conf.xml?

i don't know what key, but it is reproducible.  i could make it happen simply by starting the node.  during startup i will see the exception.  it doesn't happen until some amount of data is in the database.  in other words, it runs fine until either the number of keys or the amount of data crosses some threshold.

i can't repo it at the moment as the cluster is shared and i needed to erase data and work on something else.  but i can try again probably later this week.;;;","06/Apr/10 21:57;jbellis;Great, I'm glad we downloaded a 72 GB test corpus that you blew away. :(

The key is logged with every exception message in latest 0.6 code.  From there I would hope that it would be easy for you to track down what command is causing it.  If not, turning on debug logging on the Cassandra would get that information for you.
;;;","07/Apr/10 23:20;thuske;I think we are seeing this error as well.

ERROR [ROW-READ-STAGE:17] 2010-04-07 21:04:36,861 CassandraDaemon.java (line 78) Fatal exception in thread Thread[ROW-READ-STAGE:17,5,main]
java.lang.AssertionError: DecoratedKey(112702293498592974518440554745446764341, 4452215176) != DecoratedKey(112702294131127473014102114707935791646, 11667886399) in /data2/data/Twitter/Statuses-4327-Data.db
	at org.apache.cassandra.db.filter.SSTableSliceIterator$ColumnGroupReader.<init>(SSTableSliceIterator.java:127)
	at org.apache.cassandra.db.filter.SSTableSliceIterator.<init>(SSTableSliceIterator.java:59)
	at org.apache.cassandra.db.filter.SliceQueryFilter.getSSTableColumnIterator(SliceQueryFilter.java:63)
	at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:830)
	at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:750)
	at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:719)
	at org.apache.cassandra.db.Table.getRow(Table.java:381)
	at org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:59)
	at org.apache.cassandra.db.ReadVerbHandler.doVerb(ReadVerbHandler.java:80)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:40)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)

We're using the RandomPartitioner, and a replication factor of 3, the relevant SSTable is 146GB, and the index file is 18GB.  This assertion only occurs on the primary node, whereas the data is returned correctly from the other 2 when asked directly.  We had been running with 0.6beta2 and a DiskAccessMode of ""auto"" which set the mode to mmap.  We've since upgraded to 0.6rc1, and changed the DAM to ""standard"", but the error still occurs.

From cassandra-cli, connected to the primary node:
cassandra> get Twitter.Statuses['11667886399']           
...RpcTimeout seconds later...
Exception Internal error processing get_slice

Connected to an unrelated node:
cassandra> get Twitter.Statuses['11667886399']
...RpcTimeout seconds later...
Exception null

We have a number of these errors, and for each one, the token for the key read off disk is numerically very close to that of the requested key:
DecoratedKey(79954008423729056632733094063639634941, 8307722089) != DecoratedKey(79954009259417349514057411741701713236, 6153489921)
DecoratedKey(80379343112914474054622124950679452815, 3768834481) != DecoratedKey(80379344845214890401447094271897994174, 11653098762)
DecoratedKey(80779546346447228478584703771606621740, 8569013773) != DecoratedKey(80779548447419746111153057677392388488, 11764962920)
DecoratedKey(82844158105946904890171938436663575930, 4464394167) != DecoratedKey(82844159691805202566257389052615565753, 6874217428)
DecoratedKey(84289221786768678402050522652258180028, 6057213014) != DecoratedKey(84289224459791176731103465787486907832, 9899742458)
DecoratedKey(86300142475818241616994325294057703135, 5832470418) != DecoratedKey(86300142677962509841823563793986169119, 11448189666)
DecoratedKey(92092914035356318872651100377285498797, 3473992372) != DecoratedKey(92092915436251199165174090571909314827, 8851204821)
DecoratedKey(94745421400532682848559427993237380460, 9893103006) != DecoratedKey(94745431874154322071681265706426033545, 10438638106);;;","08/Apr/10 01:51;jbellis;Tim, can you make that sstable (+ index + filter) available for us to debug locally?;;;","08/Apr/10 21:34;btoddb;awright, big daddy ... reproduced again, and data is saved ;)

2010-04-07 21:21:10,520 ERROR [ROW-READ-STAGE:4] [CassandraDaemon.java:78] Fatal exception in thread Thread[ROW-READ-STAGE:4,5,main]
java.lang.AssertionError: DecoratedKey(147587030576932389559405437065042613628, vmguest85__-1131008275) != DecoratedKey(147587045543996727516366006491335105792, vmguest85__-888697030) in /data/cassandra-data/data/uds/bucket-1439-Data.db
        at org.apache.cassandra.db.filter.SSTableSliceIterator$ColumnGroupReader.<init>(SSTableSliceIterator.java:127)
        at org.apache.cassandra.db.filter.SSTableSliceIterator.<init>(SSTableSliceIterator.java:59)
        at org.apache.cassandra.db.filter.SliceQueryFilter.getSSTableColumnIterator(SliceQueryFilter.java:63)
        at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:830)
        at org.apache.cassandra.db.ColumnFamilyStore.cacheRow(ColumnFamilyStore.java:727)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:752)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:719)
        at org.apache.cassandra.db.Table.getRow(Table.java:381)
        at org.apache.cassandra.db.SliceByNamesReadCommand.getRow(SliceByNamesReadCommand.java:56)
        at org.apache.cassandra.db.ReadVerbHandler.doVerb(ReadVerbHandler.java:70)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:40)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)

emailed jonathan an http site to download data files that reproduce this problem.

AssertionError happened on node 105 (see ring below), and according to the keys shown in above exception, 105 is the primary for the key.  ReplicationFactor = 3 so 102 and 103 are replicas, right?  i can use the cassandra-cli to retrieve the value on the key's replica nodes, just not on the primary node.

Address       Status     Load          Range                                      Ring
                                       170141183460469231731687303715884105728
192.168.132.102Up         41.64 GB      42535295865117307932921825928971026431     |<--|
192.168.132.103Up         41.33 GB      85070591730234615865843651857942052863     |   |
192.168.132.104Up         41.52 GB      127605887595351923798765477786913079295    |   |
192.168.132.105Up         36.86 GB      170141183460469231731687303715884105728    |-->|
;;;","08/Apr/10 23:31;kingryan;Jonathan- 

We can't easily make that data available because it contains private data from some of our users. Sorry. :(;;;","10/Apr/10 13:06;jbellis;Patch attached, with unit test.

Thanks to Todd for getting us a reproducible test case!;;;","12/Apr/10 15:38;btoddb;i'll verify the fix with my dataset today by grabbing the tip of 0.6 branch and applying patch.  stay tuned;;;","12/Apr/10 16:25;gdusbabek;encodedUTF8Length doesn't account for 4-byte chars:

0x00-0x7f : 1 byte
0x80-0x7ff: 2 bytes
0x800-0xffff: 3 bytes
>=0x10000 (technically to 0x10ffff): 4 bytes.;;;","12/Apr/10 17:55;jbellis;DataInput.writeUTF, which is what keys are written with, only uses 1-3 bytes.  http://java.sun.com/javase/6/docs/api/java/io/DataInput.html;;;","12/Apr/10 19:00;gdusbabek;+1;;;","12/Apr/10 20:13;btoddb;I have been running with the patch for about 2 hrs now and haven't seen any AssertionErrors.  I would have previously seen them by now.  I'll keep watching things, but it looks good to me.;;;","12/Apr/10 23:18;jmhodges;We're pushing out a version of the current cassandra-0.6 branch with this patch applied. A canary machine is currently freaking out. We're going to move forward and hope it's just this particular machine, but is there any hope of getting this patch rebased to 0.6-rc1 (a.k.a. 0.6-final)?;;;","13/Apr/10 02:22;jbellis;committed.  it will be in 0.6.1.

no, not taking requests to rebase vs other revisions, but it should be fairly straightforward, code churn has been low in 0.6 post-rc1.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConcurrentModificationException during QuorumResponseHandler,CASSANDRA-864,12458566,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,btoddb,btoddb,09/Mar/10 18:20,16/Apr/19 09:33,14/Jul/23 05:51,10/Mar/10 17:18,0.6,,,,0,,,,,,"using cassandra-0.6.0-beta2/


2010-03-09 09:17:26,827 ERROR [pool-1-thread-675] [Cassandra.java:1166] Internal error processing get
java.util.ConcurrentModificationException
        at java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)
        at java.util.AbstractList$Itr.next(AbstractList.java:343)
        at org.apache.cassandra.service.QuorumResponseHandler.get(QuorumResponseHandler.java:68)
        at org.apache.cassandra.service.StorageProxy.strongRead(StorageProxy.java:470)
        at org.apache.cassandra.service.StorageProxy.readProtocol(StorageProxy.java:401)
        at org.apache.cassandra.thrift.CassandraServer.readColumnFamily(CassandraServer.java:101)
        at org.apache.cassandra.thrift.CassandraServer.multigetInternal(CassandraServer.java:309)
        at org.apache.cassandra.thrift.CassandraServer.get(CassandraServer.java:274)
        at org.apache.cassandra.thrift.Cassandra$Processor$get.process(Cassandra.java:1156)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:1114)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619) ",,david.pan,rschildmeijer,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Mar/10 02:02;jbellis;864-v2.txt;https://issues.apache.org/jira/secure/attachment/12438352/864-v2.txt","09/Mar/10 22:55;jbellis;864.txt;https://issues.apache.org/jira/secure/attachment/12438339/864.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19894,,,Wed Mar 10 17:18:47 UTC 2010,,,,,,,,,,"0|i0g1jr:",91681,,,,,Low,,,,,,,,,,,,,,,,,"09/Mar/10 18:54;jbellis;What's happening is, we're relying on the synchronization done by the caller of response() to make us thread-safe.  And this works fine _if_ responses arrive before the timeout; then the assumption that responses are never added after the wait in get completes holds true (since no responses may be added after the signal is fired).

But if the request times out, then the signal has not actually been fired, and a response may arrive during iteration of the messages and cause a CME, as seen here.;;;","09/Mar/10 20:18;jbellis;Fix for IAsyncCallback concurrency problems.

I've also removed a bunch of ""if (condition.isSignaled()) return;"" statements that were premature optimizations at best and possibly counterproductive to performance.  Remember that after a successful signal, we remove the callback entry in the finally {} block, so this was only useful for callbacks that arrived (a) after the signal but (b) before the callback was removed.;;;","09/Mar/10 21:02;rschildmeijer;+1;;;","09/Mar/10 22:55;jbellis;Heh, I went to commit and couldn't get the patch to apply to 0.6.  Then I realized I'd only submitted part of the patch (forgot to squash in my local git repo).

Full patch attached.;;;","10/Mar/10 02:02;jbellis;fix IllegalStateException: Queue full;;;","10/Mar/10 07:06;rschildmeijer;Reviewed once more. Still +1 :);;;","10/Mar/10 13:54;gdusbabek;Was changing the for-loop to 'if (iter.hasNext())' in QRH.get() intentional?  It seems like a while-loop is required to keep the same semantics as the old code.;;;","10/Mar/10 13:58;jbellis;I believe the responses all have the same messageid; the for loop was a clunkier way of expressing ""remove the handler, but only if we actually got a response with which to grab the id"";;;","10/Mar/10 14:27;gdusbabek;+1;;;","10/Mar/10 16:55;jbellis;actually ""responses all have the same messageid"" is only true for QRH, not WRH.  I will change both of them back to the way they were before.;;;","10/Mar/10 17:18;jbellis;committed w/ that change;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cli.bat fails to start cli client,CASSANDRA-858,12458407,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,mwn,mwn,mwn,07/Mar/10 22:59,16/Apr/19 09:33,14/Jul/23 05:51,08/Mar/10 17:36,0.6,,Legacy/Tools,,0,,,,,,"When one fetch latest and greates from svn - the cassandra.bat works. (like - the server starts and get ready to rock) but the cassandra-cli.bat fails.
java claims NoClassDefFoundErrror: jline/Completor
- after joining all four braincells I noticed that %CASSANDRA_HOME%\build\lib\jars\* is not part of the classpath that is setup inside the bat file. Adding this solved the issue.
",winxp / java 1.6 / svn @ 920147,,,,,,,,,,600,600,,0%,600,600,,,,,,,,,,,,,,"07/Mar/10 23:00;mwn;CASSANDRA-858.patch;https://issues.apache.org/jira/secure/attachment/12438152/CASSANDRA-858.patch",,,,,,,,,,,,,,1.0,mwn,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19893,,,Mon Mar 08 17:39:45 UTC 2010,,,,,,,,,,"0|i0g1if:",91675,,,,,Low,,,,,,,,,,,,,,,,,"07/Mar/10 23:00;mwn;fix;;;","08/Mar/10 17:21;jbellis;wfm on trunk, fails to apply against 0.6 (we need it there too right?);;;","08/Mar/10 17:36;jbellis;got it to apply to 0.6.  committed.;;;","08/Mar/10 17:39;staffan ericsson;%CASSANDRA_HOME%\build\lib\jars\ does not exist in the 0.6-beta2 binary package.
Correct path should be %CASSANDRA_HOME%\lib\jars\ 



;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AssertionError in MappedFileDataInput.skipBytes when slicing a large number of keys,CASSANDRA-857,12458371,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,edmonds,edmonds,07/Mar/10 04:08,16/Apr/19 09:33,14/Jul/23 05:51,20/Mar/10 01:15,0.6,,,,0,,,,,,"i'm getting the following error when performing a range query that is supposed to return a large number of keys:

ERROR [ROW-READ-STAGE:9] 2010-03-07 03:54:49,672 CassandraDaemon.java (line 78) Fatal exception in thread Thread[ROW-READ-STAGE:9,5,main]
java.lang.AssertionError
	at org.apache.cassandra.io.util.MappedFileDataInput.skipBytes(MappedFileDataInput.java:104)
	at org.apache.cassandra.io.SSTableReader.getPosition(SSTableReader.java:382)
	at org.apache.cassandra.io.SSTableReader.getFileDataInput(SSTableReader.java:481)
	at org.apache.cassandra.db.filter.SSTableSliceIterator.<init>(SSTableSliceIterator.java:54)
	at org.apache.cassandra.db.filter.SliceQueryFilter.getSSTableColumnIterator(SliceQueryFilter.java:63)
	at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:851)
	at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:771)
	at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:740)
	at org.apache.cassandra.db.ColumnFamilyStore.getRangeSlice(ColumnFamilyStore.java:1040)
	at org.apache.cassandra.service.RangeSliceVerbHandler.doVerb(RangeSliceVerbHandler.java:41)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:40)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)","debian, amd64, sun java 1.6.0_12",johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Mar/10 21:08;jbellis;857.txt;https://issues.apache.org/jira/secure/attachment/12439328/857.txt","19/Mar/10 18:10;jbellis;857.txt;https://issues.apache.org/jira/secure/attachment/12439306/857.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19892,,,Mon Mar 22 20:04:38 UTC 2010,,,,,,,,,,"0|i0g1i7:",91674,,,,,Normal,,,,,,,,,,,,,,,,,"19/Mar/10 00:53;jbellis;There are two bugs w/ index positions crossing mmap 2GB segment boundaries.

Working on fix.

--- src/java/org/apache/cassandra/io/SSTableReader.java	(revision 925055)
+++ src/java/org/apache/cassandra/io/SSTableReader.java	(working copy)
@@ -363,6 +363,7 @@
             do
             {
                 DecoratedKey indexDecoratedKey;
+                // bug: EOFing may mean ""try next mmap segment,"" rather than ""we're done""
                 try
                 {
                     indexDecoratedKey = partitioner.convertFromDiskFormat(input.readUTF());
@@ -375,6 +376,7 @@
                 int v = indexDecoratedKey.compareTo(decoratedKey);
                 if (v == 0)
                 {
+                    // bug: ""get next info"" (to find data length) can cross mmap boundary & error out
                     PositionSize info;
                     if (!input.isEOF())
                     {
;;;","19/Mar/10 18:10;jbellis;patch against 0.6 attached.  (will not apply cleanly to trunk, I will have to merge that separately.);;;","19/Mar/10 18:14;jbellis;patch moves indexPositions and spannedIndexDataPositions from SSTR into IndexSummary class, and adds spannedIndexPositions to map  indexPosition -> KeyPosition.  This lets us tell when we reach the last index entry we can safely read from a mmap segment, without having to read it.  (Relying on reading -> erroring out to tell us when this was the case is not as good, since we lose the ability to tell the difference b/t a corrupt file and a mmap buffer boundary.);;;","19/Mar/10 21:08;jbellis;rebased;;;","19/Mar/10 22:14;stuhood;+1 Looks good.;;;","20/Mar/10 01:15;jbellis;committed to 0.6; will merge to trunk;;;","22/Mar/10 20:04;jbellis;(this fix will be in 0.6 RC1, it is not in beta 3.);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ConcurrentModificationException,CASSANDRA-853,12458265,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,riffraff,btoddb,btoddb,05/Mar/10 17:11,16/Apr/19 09:33,14/Jul/23 05:51,05/Mar/10 20:12,0.6,,,,0,,,,,,"i'm seeing a lot of these ... any idea?

2010-03-04 18:53:21,455 ERROR [MEMTABLE-POST-FLUSHER:1] [DebuggableThreadPoolExecutor.java:94] Error in executor futuretask
java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.util.ConcurrentModificationException
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:86)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.RuntimeException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.util.ConcurrentModificationException
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        ... 2 more
Caused by: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.util.ConcurrentModificationException
        at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegments(CommitLog.java:357)
        at org.apache.cassandra.db.ColumnFamilyStore$2.runMayThrow(ColumnFamilyStore.java:392)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 6 more
Caused by: java.util.concurrent.ExecutionException: java.util.ConcurrentModificationException
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegments(CommitLog.java:349)
        ... 8 more
Caused by: java.util.ConcurrentModificationException
        at java.util.ArrayDeque$DeqIterator.next(ArrayDeque.java:605)
        at org.apache.cassandra.db.commitlog.CommitLog.discardCompletedSegmentsInternal(CommitLog.java:385)
        at org.apache.cassandra.db.commitlog.CommitLog.access$300(CommitLog.java:71)
        at org.apache.cassandra.db.commitlog.CommitLog$6.call(CommitLog.java:343)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at org.apache.cassandra.db.commitlog.CommitLogExecutorService.process(CommitLogExecutorService.java:113)
        at org.apache.cassandra.db.commitlog.CommitLogExecutorService.access$200(CommitLogExecutorService.java:35)
        at org.apache.cassandra.db.commitlog.CommitLogExecutorService$1.runMayThrow(CommitLogExecutorService.java:67)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 1 more
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/10 17:30;riffraff;CASSANDRA-853.patch;https://issues.apache.org/jira/secure/attachment/12438025/CASSANDRA-853.patch",,,,,,,,,,,,,,1.0,riffraff,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19890,,,Fri Mar 05 20:12:50 UTC 2010,,,,,,,,,,"0|i0g1hb:",91670,,,,,Normal,,,,,,,,,,,,,,,,,"05/Mar/10 17:29;riffraff;this seems just a mis-use of the foreach loop, attaching patch that should fix it but AFAICT there are no tests for discardCompletedSegments at all? 
;;;","05/Mar/10 19:48;riffraff;avoids collection modification while looping;;;","05/Mar/10 20:12;jbellis;Committed to 0.6 and trunk, thanks;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ant release target doesn't include all jars in binary tarball,CASSANDRA-850,12458223,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,urandom,johanoskarsson,johanoskarsson,05/Mar/10 10:18,16/Apr/19 09:33,14/Jul/23 05:51,26/Mar/10 17:53,0.6,,,,0,,,,,,"The ant release target doesn't create a complete tarball, the jars in build/lib/jars are not included.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Mar/10 15:53;urandom;ASF.LICENSE.NOT.GRANTED--v2-0001-CASSANDRA-850-runtime-dependencies-formerly-handled-by.txt;https://issues.apache.org/jira/secure/attachment/12439786/ASF.LICENSE.NOT.GRANTED--v2-0001-CASSANDRA-850-runtime-dependencies-formerly-handled-by.txt","25/Mar/10 15:53;urandom;ASF.LICENSE.NOT.GRANTED--v2-0002-licensing-and-attribution-for-newly-added-jars.txt;https://issues.apache.org/jira/secure/attachment/12439787/ASF.LICENSE.NOT.GRANTED--v2-0002-licensing-and-attribution-for-newly-added-jars.txt","25/Mar/10 15:53;urandom;ASF.LICENSE.NOT.GRANTED--v2-0003-remove-default-runtime-ivy-config.txt;https://issues.apache.org/jira/secure/attachment/12439788/ASF.LICENSE.NOT.GRANTED--v2-0003-remove-default-runtime-ivy-config.txt","25/Mar/10 15:53;urandom;ASF.LICENSE.NOT.GRANTED--v2-0004-remove-build-lib-jars-from-runtime-search-paths.txt;https://issues.apache.org/jira/secure/attachment/12439789/ASF.LICENSE.NOT.GRANTED--v2-0004-remove-build-lib-jars-from-runtime-search-paths.txt","25/Mar/10 15:53;urandom;ASF.LICENSE.NOT.GRANTED--v2-0005-do-not-ship-build.xml-and-ivy.xml-in-binary-dist.txt;https://issues.apache.org/jira/secure/attachment/12439790/ASF.LICENSE.NOT.GRANTED--v2-0005-do-not-ship-build.xml-and-ivy.xml-in-binary-dist.txt","25/Mar/10 15:53;urandom;ASF.LICENSE.NOT.GRANTED--v2-0006-update-release-notes-and-readme-for-ivy-rollback.txt;https://issues.apache.org/jira/secure/attachment/12439791/ASF.LICENSE.NOT.GRANTED--v2-0006-update-release-notes-and-readme-for-ivy-rollback.txt","05/Mar/10 10:21;johanoskarsson;CASSANDRA-850.patch;https://issues.apache.org/jira/secure/attachment/12437991/CASSANDRA-850.patch","25/Mar/10 22:19;urandom;v2-0007-remove-gratuitous-copy-of-junit-from-lib.patch;https://issues.apache.org/jira/secure/attachment/12439832/v2-0007-remove-gratuitous-copy-of-junit-from-lib.patch","25/Mar/10 22:19;urandom;v2-0008-reference-lib-licenses-from-LICENSE.txt.patch;https://issues.apache.org/jira/secure/attachment/12439833/v2-0008-reference-lib-licenses-from-LICENSE.txt.patch",,,,,,9.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19889,,,Mon Mar 29 15:42:30 UTC 2010,,,,,,,,,,"0|i0g1gn:",91667,,,,,Normal,,,,,,,,,,,,,,,,,"05/Mar/10 10:21;johanoskarsson;This patch makes the release target include all the jars;;;","05/Mar/10 13:25;jbellis;My understanding is that this is deliberate, or we'd have to go back to maintaining NOTICE for all those.;;;","05/Mar/10 13:52;johanoskarsson;Isn't the point of a binary release tarball that it should work with minimal effort out of the box? 
Surely the overhead of maintaining the notice file is a tiny bit of extra effort for a small group of developers and of a major benefit to a large group of users? I would agree that it might not be needed in the source version though.;;;","05/Mar/10 17:09;urandom;> Isn't the point of a binary release tarball that it should work with minimal effort out of the box?

The added effort basically boils down to invoking `ant ivy-retrieve' no?

> Surely the overhead of maintaining the notice file is a tiny bit of extra effort for a small group of developers and of a major benefit to a large group of users?

I think ""tedious"" is a better adjective than ""tiny"". Also, despite the very best of intentions, it wasn't being kept up properly (which is a pretty common outcome of tedious manual tasks).

We traded:

* manual dependency management
* the requirement to document license and attribution
* license incompatibility issues (caused by redistribution)

For:

* requiring ant to be installed (which doesn't seem to be too onerous)
* requiring network connectivity
* invoking `ant ivy-retrieve'

I'm not opposed to returning to the past practice of embedding all of the jars, especially if someone is stepping up to do a better job of maintaining this, but I think the changeset needs to revert Ivy, and include the jars and the necessary changes to NOTICE and LICENSE .
;;;","10/Mar/10 16:21;jbellis;Johan mentioned in IRC that http://ant.apache.org/ivy/history/latest-milestone/ivyfile/license.html could allow auto-generating LICENSE and NOTICE.

This is metadata from the maven repo right?  Not something we would maintain ourselves in ivy.xml?;;;","10/Mar/10 16:28;jbellis;For the record, the official description of NOTICE is as follows (from http://www.apache.org/legal/src-headers.html#notice):

   0.  Every Apache distribution should include a NOTICE file in the top directory, along with the standard LICENSE file.
   1. The top of each NOTICE file should include the following text, suitably modified to reflect the product name and year(s) of distribution of the current and past versions of the product:

                Apache [PRODUCT_NAME]
                Copyright [yyyy] The Apache Software Foundation

                This product includes software developed at
                The Apache Software Foundation (http://www.apache.org/).
        

   2. The remainder of the NOTICE file is to be used for required third-party notices. The NOTICE file may also include copyright notices moved from source files submitted to the ASF.

The only official description of LICENSE I found is http://apache.org/dev/apply-license.html#new, which seems to mean that LICENSE should always be the ASL 2.

I'm not sure where the practice of ""include a copy of each dependency's license in LICENSE"" comes from; I couldn't find it documented anywhere.;;;","10/Mar/10 17:01;urandom;> I'm not sure where the practice of ""include a copy of each dependency's license in LICENSE"" comes from; I couldn't find it documented anywhere.

There is obviously a hard requirement to include licensing information for everything with a license, but the requirement to put it all in LICENSE came from individuals on general@incubator and wasn't universally agreed upon.

Some folks thought it was enough to include it, others thought that it should at least be discoverable via LICENSE, and others still were adamant that they be entirely contained with LICENSE. We went with the latter primarily to avoid controversy (we needed release votes).;;;","23/Mar/10 15:26;gdusbabek;Have we reached consensus on this?  If not, I want to offer my opinion.

We started using ivy for several reasons, but the big problem I thought it was solving was avoiding license management.  If we end up having to update LICENSE.txt/NOTICE.txt manually in order to ship a full binary, I prefer to go back to keeping the dependencies in svn.  Let's rid of ivy.;;;","23/Mar/10 15:30;jbellis;+1 getting rid of ivy if we're manually updating license files.;;;","23/Mar/10 17:47;urandom;I suppose we could keep it around for managing build dependencies, stuff that we're unwilling or unable to check into subversion, (rat, cobertura, and maybe parts of antlr). I don't know if that's enough justification; just throwing out the option.;;;","24/Mar/10 23:50;urandom;0001: This patch places a copy of everything that used to be downloaded by the ivy ""default"" conf (i.e. `ant ivy-retrieve'), into lib/ (it probably requires git to apply this patch).

0002: Adds license and attribution info for the new jars, and moves the existing third-party license info from LICENSE to lib/licenses.

0003: Cleans out everything from the ivy ""default"" conf that has since been moved to lib/, and merges the ""build"" and ""qa"" confs to simplify things. Also makes the necessary changes to build.xml so that Ivy is only used to manage build dependencies.

0004: Adjusts jar file search path in scripts and batch files.

0005: Fixes the release target to no longer include build.xml and ivy.xml in the binary dist.

0006: Updates the release notes and readme files.

It would be great to have another set of eyes on this, I can't hardly imagine *not* missing something in all of these changes.;;;","25/Mar/10 03:49;jbellis;I think the commons-logging and httpclient ivy lines are just there for contrib/word_count (i was lazy).  We could totally just r/m those entirely (and any dependencies those had, in turn?) and let people who want to run the contrib example get them manually or w/ ivy.;;;","25/Mar/10 15:56;urandom;commons-{logging,httpclient} have been removed from the v2 patches.;;;","25/Mar/10 21:11;johanoskarsson;+1, looks good to me. 

Couple of thoughts:
* Is there a reason to keep the junit 3.8.1 jar in lib and also use ivy to fetch junit 4.6?
* Due to my lack of legal expertise I will assume the bits in the notice file are sufficient.
* I remember someone voiced the opinion earlier that licenses should be pulled into a single file in the root, can't remember which of license/notice it was. Personally I think that this approach with one license file per jar approach is much more user friendly and surely it must be as valid from a legal standpoint?;;;","25/Mar/10 21:31;jbellis;1. all (?) our junit tests require junit 4, so that should be an easy call. :)
3. that was someone on incubator-general pissing on our release because it wasn't The Way He Liked, there was no legal reason that per-file was invalid brought up in that discussion;;;","25/Mar/10 22:11;urandom;> Is there a reason to keep the junit 3.8.1 jar in lib and also use ivy to fetch junit 4.6? 

We were explicitly pulling in junit 4.6 to use for our unit tests, and implicitly pulling in junit 3.8.1 as a dependency for at least one of those other jars in lib/ (Ivy would resolve that to 4.6 only). So that explains why it is the way it is, though I do suspect that the jar(s) that declared a dependency on junit did so in error, (or we simply don't exercise those parts of the lib(s)). 

The unit tests, system tests and cassandra-cli (one of those aforementioned jars is jline, used by the cli) all seem to work after removing lib/junit-3.8.1.jar , so it's probably safe to leave it out.

> Due to my lack of legal expertise I will assume the bits in the notice file are sufficient. 

I'm not sure it would satisfy everyone on the incubator list, but it is correct with respect to the legal requirements, at least according to my understanding of the respective licenses (actually, it errs on the side of caution wherever I wasn't 100% sure).

> I remember someone voiced the opinion earlier that licenses should be pulled into a single file in the root

That was something else that came up on the incubator list, and TTBOMK there wasn't consensus for this either. I can find no such requirement in my reading of the actual licenses. I can however append a sentence or two to LICENSE that refers to lib/license for third-party libs, (I think that would satisfy that camp).;;;","25/Mar/10 22:20;urandom;0007: removes junit 3.8.1 and the corresponding license file

0008: adds a reference to lib/licenses from LICENSE.txt;;;","26/Mar/10 22:41;mike.javorski;Sorry.. I'm a bit late to the party (and did so because of the 6MB delta download git just pulled).  Wouldn't managing the ivy.xml and the NOTICES file in concert meet the ASF legal requirements? You could run ivy-retrieve as part of the dist process and eliminate the requirement for ant and ivy for the end user, and still get the benefits on the development side.

On a related note (and I realize this doesn't effect the official SVN users),  git users will get a nice jump in repo size every time there is a lib change with this route. Shouldn't be a regular occurrence, but if it's easily avoided, why not make it ""nicer""

I am happy to take a crack at a patch to this effect if there is interest.

[Edit:] looks like the first patch of this issue would have done that, so I guess no patch needed from me;;;","29/Mar/10 15:42;urandom;Ivy dependency retrieval is a dynamic process, I really don't see how you could make any guarantees that an ivy.xml and NOTICE/LICENSE pair maintained in lock-step would remain in syn.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
hadoop recordreader hardcodes row count,CASSANDRA-837,12457743,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,01/Mar/10 14:28,16/Apr/19 09:33,14/Jul/23 05:51,05/Mar/10 20:32,0.6,,,,0,,,,,,We need to use the split size instead.,,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Mar/10 02:53;jbellis;ASF.LICENSE.NOT.GRANTED--0001-move-configuration-static-methods-into-ConfigHelper.txt;https://issues.apache.org/jira/secure/attachment/12437667/ASF.LICENSE.NOT.GRANTED--0001-move-configuration-static-methods-into-ConfigHelper.txt","03/Mar/10 02:53;jbellis;ASF.LICENSE.NOT.GRANTED--0002-r-m-fields-from-CFSplit-that-are-redundant-to-informat.txt;https://issues.apache.org/jira/secure/attachment/12437668/ASF.LICENSE.NOT.GRANTED--0002-r-m-fields-from-CFSplit-that-are-redundant-to-informat.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19887,,,Fri Mar 05 20:32:20 UTC 2010,,,,,,,,,,"0|i0g1dr:",91654,,,,,Low,,,,,,,,,,,,,,,,,"01/Mar/10 15:19;johanoskarsson;It's worth noting that when I tried using the default split size of 16k pretty much all my tasks timed out and died, failing the job. This was before the timeout was raised to 10s though, so might work better now. But before we have improved performance of the slice operation we should probably lower the 16k limit.;;;","01/Mar/10 16:01;jbellis;In that case we should probably reduce the default to 8k, but we're testing 10k-20k rows read per second here via get_range_slice.  how big are your rows, and are you running on a VM or real hardware?;;;","01/Mar/10 18:08;johanoskarsson;The rows only contain the text from a tweet, so not very big. This was running on EC2 instances, granted it's not the best real world test but shows the margin is not very big. Hopefully it will improve after CASSANDRA-821 is resolved.;;;","03/Mar/10 02:54;jbellis;02
    r/m fields from CFSplit that are redundant to information in configuration; use split size for row count

01
    move configuration static methods into ConfigHelper
;;;","05/Mar/10 09:21;johanoskarsson;+1. 
My only concern is that having the static configuration methods in the ConfigHelper might make them harder to find for the users, most input formats I have worked with have them in the input format class itself. A class level javadoc in the input format with a short user guide might be a good complement.;;;","05/Mar/10 13:24;jbellis;Would it be better to just move CH.* to the InputFormat?

I split it out since it seemed weird to have the record reader call a bunch of static methods on the IF, but if that's the customary place then that's fine.;;;","05/Mar/10 20:32;jbellis;committed w/ extra javadoc to 0.6 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Exception during batch_mutate,CASSANDRA-834,12457340,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,brandon.williams,brandon.williams,24/Feb/10 20:34,16/Apr/19 09:33,14/Jul/23 05:51,23/Mar/10 15:10,0.6,,,,0,,,,,,"If a batch mutation is sent with deletions referring to a SCF but no SC is specified in the Deletion object, the following traceback is generated:

ERROR 15:28:16,746 Fatal exception in thread Thread[ROW-MUTATION-STAGE:22,5,main]
java.lang.RuntimeException: java.lang.ClassCastException: org.apache.cassandra.db.Column cannot be cast to org.apache.cassandra.db.SuperColumn
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
Caused by: java.lang.ClassCastException: org.apache.cassandra.db.Column cannot be cast to org.apache.cassandra.db.SuperColumn
        at org.apache.cassandra.db.SuperColumnSerializer.serialize(SuperColumn.java:300)
        at org.apache.cassandra.db.SuperColumnSerializer.serialize(SuperColumn.java:284)
        at org.apache.cassandra.db.ColumnFamilySerializer.serializeForSSTable(ColumnFamilySerializer.java:87)
        at org.apache.cassandra.db.ColumnFamilySerializer.serialize(ColumnFamilySerializer.java:73)
        at org.apache.cassandra.db.RowMutationSerializer.freezeTheMaps(RowMutation.java:329)
        at org.apache.cassandra.db.RowMutationSerializer.serialize(RowMutation.java:341)
        at org.apache.cassandra.db.RowMutationSerializer.serialize(RowMutation.java:314)
        at org.apache.cassandra.db.RowMutation.getSerializedBuffer(RowMutation.java:270)
        at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:200)
        at org.apache.cassandra.service.StorageProxy$3.runMayThrow(StorageProxy.java:282)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
        ... 3 more
","debian lenny amd64 OpenJDK 64-Bit Server VM (build 1.6.0_0-b11, mixed mode)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Feb/10 23:20;brandon.williams;834-test.patch;https://issues.apache.org/jira/secure/attachment/12436924/834-test.patch","22/Mar/10 22:08;jbellis;834-v2.txt;https://issues.apache.org/jira/secure/attachment/12439515/834-v2.txt","01/Mar/10 21:19;brandon.williams;834.patch;https://issues.apache.org/jira/secure/attachment/12437520/834.patch",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19885,,,Tue Mar 23 15:10:12 UTC 2010,,,,,,,,,,"0|i0g1d3:",91651,,,,,Low,,,,,,,,,,,,,,,,,"24/Feb/10 23:20;brandon.williams;System test to reproduce.;;;","01/Mar/10 21:19;brandon.williams;Patch to validate column paths in a slice predicate.;;;","01/Mar/10 22:24;jbellis;hmm...

shouldn't supercolumn==null mean ""apply this predicate to top level supercolumns?""  that is what we do in get_slice for instance.

this will be important when we add deletion of ranges, since there's no other way to specify ""a range of supercolumns"" than in the predicate.;;;","22/Mar/10 22:08;jbellis;Patch taking the 2nd approach, of promoting columns to supercolumns when SC is null in a super CF.;;;","23/Mar/10 13:59;brandon.williams;+1;;;","23/Mar/10 15:10;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix consistencylevel during bootstrap,CASSANDRA-833,12457318,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,24/Feb/10 17:44,16/Apr/19 09:33,14/Jul/23 05:51,21/Sep/12 15:13,1.2.0 beta 2,,,,0,,,,,,"As originally designed, bootstrap nodes should *always* get *all* writes under any consistencylevel, so when bootstrap finishes the operator can run cleanup on the old nodes w/o fear that he might lose data.

but if a bootstrap operation fails or is aborted, that means all writes will fail until the ex-bootstrapping node is decommissioned.  so starting in CASSANDRA-722, we just ignore dead nodes in consistencylevel calculations.

but this breaks the original design.  CASSANDRA-822 adds a partial fix for this (just adding bootstrap targets into the RF targets and hinting normally), but this is still broken under certain conditions.  The real fix is to consider consistencylevel for two sets of nodes:

  1. the RF targets as currently existing (no pending ranges)
  2.  the RF targets as they will exist after all movement ops are done

If we satisfy CL for both sets then we will always be in good shape.

I'm not sure if we can easily calculate 2. from the current TokenMetadata, though.",,arya,cagatayk,scode,slebresne,,,,,,,,,,,,,,,,,,,,,,,,,"06/May/11 17:23;slebresne;0001-Increase-CL-with-boostrapping-leaving-node.patch;https://issues.apache.org/jira/secure/attachment/12478450/0001-Increase-CL-with-boostrapping-leaving-node.patch","17/May/11 21:21;jbellis;833-v2.txt;https://issues.apache.org/jira/secure/attachment/12479519/833-v2.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19884,,,Fri Sep 21 15:13:10 UTC 2012,,,,,,,,,,"0|i0g1cv:",91650,,slebresne,,slebresne,Normal,,,,,,,,,,,,,,,,,"03/Mar/10 03:09;jbellis;To clarify: the #722 fix breaks the design because a bootstrapping node that goes ""down"" temporarily but completes bootstrap will not actually have all the writes that happened during bootstrap on it.;;;","05/Mar/10 14:10;jaakko;This issue is not only related to bootstrapping, since nodes leaving the ring will also cause pending ranges. If a node does not complete leaving operation properly, obsolete pending ranges will be left in metadata.

(2) above is actually almost exactly how pending ranges is calculated. All current move operations are finished and pending ranges is calculated according to what are the new natural endpoints for the ranges in question.

This is not directly related to bootstrapping IMHO, but to the fact that node movement increases quorum and due to node movement being uncertain, there is bigger possibility that something goes wrong and quorum nodes cannot be reached.
;;;","03/May/11 13:56;jbellis;Consider the case of CL=1, RF=3 to replicas A, B, C. We begin bootstrapping node D, and write a row K to the range being moved from C to D.

If the cluster is heavily loaded, it's possible that we write one copy to C, all the other writes get dropped, and once bootstrap completes we lose the row. Or if we write one copy to D, and cancel bootstrap, we again lose the row.

As said above, we want to satisfy CL for both the pre- and post-bootstrap nodes (in case bootstrap aborts).  This requires treating the old/new range owner as a unit: both D *and* C need to accept the write for it to count towards CL. So rather than considering {A, B, C, D} we should consider {A, B, (C, D)}.

This is a lot of complexity to introduce. A simplification that preserves correctness is to continue treating nodes independently but require *one more node* than normal CL. So CL=1 would actually require 2 nodes; CL=Q would require 3 (for RF=3), and so forth.  (Note that Q(3) + 1 is the same as Q(4), which is what the existing code computes; that is one reason I chose a CL=1 example to start with, since those are *not* the same even for the simple case of RF=3.)

This would mean we may fail a few writes unnecessarily (a write to A or B is actually sufficient to satisfy CL=1, but this scheme would time that out) but never allow a write to succeed that would leave CL unsatisfied post-bootstrap (or if bootstrap is cancelled).;;;","06/May/11 17:23;slebresne;Attaching patch that implements the ""simplification"" idea. The case of {LOCAL|EACH}_QUORUM requires some care but I think that by considering DC separately we are fine.;;;","17/May/11 21:21;jbellis;v2 tweaks getWriteEndpoints to avoid new Collection creation where possible, instead using Iterables.concat.

otherwise lgtm.;;;","08/Jun/11 15:37;slebresne;+1;;;","08/Jun/11 15:46;jbellis;committed;;;","09/Jun/11 02:50;hudson;Integrated in Cassandra-0.8 #158 (See [https://builds.apache.org/job/Cassandra-0.8/158/])
    fix inconsistency window duringbootstrap
patch by slebresne; reviewed by jbellis for CASSANDRA-833

jbellis : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1133443
Files : 
* /cassandra/branches/cassandra-0.8/CHANGES.txt
* /cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/service/DatacenterSyncWriteResponseHandler.java
* /cassandra/branches/cassandra-0.8/test/unit/org/apache/cassandra/locator/SimpleStrategyTest.java
* /cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/service/StorageProxy.java
* /cassandra/branches/cassandra-0.8/test/unit/org/apache/cassandra/service/LeaveAndBootstrapTest.java
* /cassandra/branches/cassandra-0.8/test/unit/org/apache/cassandra/service/MoveTest.java
* /cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/locator/AbstractReplicationStrategy.java
* /cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/service/AbstractWriteResponseHandler.java
* /cassandra/branches/cassandra-0.8/test/unit/org/apache/cassandra/service/ConsistencyLevelTest.java
* /cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/service/WriteResponseHandler.java
* /cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/service/DatacenterWriteResponseHandler.java
* /cassandra/branches/cassandra-0.8/src/java/org/apache/cassandra/locator/TokenMetadata.java
;;;","20/Sep/12 17:40;jbellis;Well, WTF.

{noformat}
commit 063c8f6cf7b12e976b0d7067037c52c548c6c0db
Author: Jonathan Ellis <jbellis@apache.org>
Date:   Thu Jun 9 00:16:27 2011 +0000

    revert 1133443
    
    git-svn-id: https://svn.apache.org/repos/asf/cassandra/branches/cassandra-0.8@1133610 13f79535-47bb-0310-9956-ffa450edef68

commit 31f0ee95e927c09183dca77be7739305ba2eeab0
Author: Jonathan Ellis <jbellis@apache.org>
Date:   Wed Jun 8 15:45:54 2011 +0000

    fix inconsistency window duringbootstrap
    patch by slebresne; reviewed by jbellis for CASSANDRA-833
    
    git-svn-id: https://svn.apache.org/repos/asf/cassandra/branches/cassandra-0.8@1133443 13f79535-47bb-0310-9956-ffa450edef68
{noformat}

I have no memory of this. :)

Maybe it caused a regression?;;;","21/Sep/12 01:11;jbellis;Pushed rebase to https://github.com/jbellis/cassandra/branches/833-3;;;","21/Sep/12 01:21;jbellis;(Not exactly a pure rebase since I split out pendingRangesFor instead of cramming everything into getWriteEndpoints.);;;","21/Sep/12 08:39;slebresne;In counterWriteTask, sendToHintedEndpoints should be called with remotes, not targets.

But other than that it lgtm. I don't remember either why it was reverted and I don't remember any specific problem with that. But in any case, you reverted it almost right away, so if that wasn't accidental the regression was likely easy to spot, so we'll see soon enough :).;;;","21/Sep/12 15:13;jbellis;committed w/ that fix;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
possible NPE in StorageService,CASSANDRA-828,12457237,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,riffraff,riffraff,riffraff,23/Feb/10 23:06,16/Apr/19 09:33,14/Jul/23 05:51,24/Feb/10 22:28,0.6,,,,0,,,,,,"the code
 {{{

     if (endPointThatLeft.equals(FBUtilities.getLocalAddress()))
            {
                logger_.info(""Received removeToken gossip about myself. Is this node a replacement for a removed one?"");
                return;
            }
            if (logger_.isDebugEnabled())
                logger_.debug(""Token "" + token + "" removed manually (endpoint was "" + ((endPointThatLeft == null) ? ""unknown"" : endPointThatLeft) + "")"");
            if (endPointThatLeft != null)
            {
                removeEndPointLocally(endPointThatLeft);
            }
}}}

appears wrong: if it is possible for the leaving endpoint to be unknown then the first ""if"" has a possible null dereference, which can be eliminated by swapping the arguments or reordering the code.

As a side note, I believe FBUtilities.getLocalAddress should probably be synchronized (or localInetAddress made volatile) per the usual ""the java MM does not guarantee any change will ever be visible""  mantra which may or may not be considered relevant :)",,,,,,,,,,,300,300,,0%,300,300,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,riffraff,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19881,,,Wed Feb 24 22:34:25 UTC 2010,,,,,,,,,,"0|i0g1br:",91645,,,,,Low,,,,,,,,,,,,,,,,,"23/Feb/10 23:16;jbellis;> if it is possible for the leaving endpoint to be null

it's not

> getLocalAddress should probably be synchronized, or localInetAddress made volatile

made localInetAddress volatile in r915580, thanks.;;;","23/Feb/10 23:23;riffraff;wow, this was fast, thanks.
 
But then aren't the following two checks for nullness unnecessary?;;;","23/Feb/10 23:27;jbellis;you're right, something is fishy here.  reopened.;;;","24/Feb/10 22:28;jbellis;the != null check is definitely redundant.  removed in r916006.;;;","24/Feb/10 22:34;jbellis;my mistake: endpoint, the argument to the method, can't be null, but endpointThatLeft can be.  Made suggested fix of inverting if condition in r916008.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unable to start Cassandra in windows if P drive exsists,CASSANDRA-824,12457227,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,kazw,kazw,23/Feb/10 22:02,16/Apr/19 09:33,14/Jul/23 05:51,24/Feb/10 15:40,0.6,,,,0,Missing-Class,P-Drive,win32,windows,wont-start,"When running bin\cassandra.bat from main dir, Cassandra exits with:
Invalid parameter - P:
Starting Cassandra Server
Listening for transport dt_socket at address: 8888
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/cassandra/service/CassandraDaemon
Caused by: java.lang.ClassNotFoundException: org.apache.cassandra.service.CassandraDaemon
        at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
Could not find the main class: org.apache.cassandra.service.CassandraDaemon.  Program will exit.",This problem should affect any version of windows with a P drive.,,,,,,,,,,0,0,,0%,0,0,,,,,,,,,,,,,,"24/Feb/10 08:05;wolfeidau;cassandra-bat-tidy.patch;https://issues.apache.org/jira/secure/attachment/12436832/cassandra-bat-tidy.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19880,,,Wed Feb 24 15:40:43 UTC 2010,,,,,,,,,,"0|i0g1av:",91641,,,,,Low,,,,,,,,,,,,,,,,,"23/Feb/10 22:06;kazw;Changing the following lines in bin\cassandra.bat will fix this issue (Substitute ""Q"" for any available drive letter):

subst Q: ""%CASSANDRA_HOME%\lib""
Q:
set CLASSPATH=Q:\

for %%i in (*.jar) do call :append %%i
goto okClasspath

:append
set CLASSPATH=%CLASSPATH%;Q:\%*
goto :eof;;;","24/Feb/10 08:05;wolfeidau;Patch to correct the issue.

I have removed the use of subst which  was mapping the P: this is unneccessary on newer windows releases.

I will give it a go on some test machines at work so far this tests fine on windows 7.;;;","24/Feb/10 15:24;gdusbabek;That patch didn't work perfectly for me.  It wasn't including the jar files located in %CASSANDRA_HOME%/build/lib/jars.  Once I added that, everything was good.

+1 on this patch.;;;","24/Feb/10 15:40;gdusbabek;r915824 (0.6), r915828 (trunk);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Wordcount contrib does not work in Hadoop distributed mode,CASSANDRA-817,12457030,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,johanoskarsson,johanoskarsson,johanoskarsson,22/Feb/10 16:41,16/Apr/19 09:33,14/Jul/23 05:51,22/Feb/10 17:23,0.6,,,,0,,,,,,The column name is set in a static variable in the job setup. That variable will be empty when the job has been distributed to the tasktrackers. The variable must be set via the setup method in the mapper.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Feb/10 16:46;johanoskarsson;CASSANDRA-817.patch;https://issues.apache.org/jira/secure/attachment/12436594/CASSANDRA-817.patch",,,,,,,,,,,,,,1.0,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19879,,,Wed Feb 24 13:07:31 UTC 2010,,,,,,,,,,"0|i0g19b:",91634,,,,,Low,,,,,,,,,,,,,,,,,"22/Feb/10 16:46;johanoskarsson;Sets the column name using the configuration and the setup method.;;;","22/Feb/10 16:51;jbellis;+1;;;","22/Feb/10 17:23;johanoskarsson;Committed to trunk and the 0.6 branch.;;;","24/Feb/10 13:07;hudson;Integrated in Cassandra #364 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/364/])
    Fix bug to allow distributed Hadoop jobs. Patch by johan, review by jbellis. 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Wordcount contrib is not including all required jars,CASSANDRA-816,12457009,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,johanoskarsson,johanoskarsson,johanoskarsson,22/Feb/10 14:45,16/Apr/19 09:33,14/Jul/23 05:51,22/Feb/10 17:50,0.6,,,,0,,,,,,The wordcount contrib build process is not including the libraries downloaded using ivy in the final jar file.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Feb/10 16:16;johanoskarsson;CASSANDRA-816.patch;https://issues.apache.org/jira/secure/attachment/12436585/CASSANDRA-816.patch","22/Feb/10 14:46;johanoskarsson;CASSANDRA-816.patch;https://issues.apache.org/jira/secure/attachment/12436574/CASSANDRA-816.patch",,,,,,,,,,,,,2.0,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19878,,,Wed Feb 24 13:07:31 UTC 2010,,,,,,,,,,"0|i0g193:",91633,,,,,Low,,,,,,,,,,,,,,,,,"22/Feb/10 14:46;johanoskarsson;Adds the required files to the jar.;;;","22/Feb/10 16:16;johanoskarsson;Created the patch in the wrong dir, this is the corrected one;;;","22/Feb/10 16:28;jbellis;do we need this in 0.6 or does this only affect the post-0.6 ivy changes?;;;","22/Feb/10 17:03;johanoskarsson;According to CASSANDRA-802 the ivy changes were in 0.6, so this one should also go into both 0.6 and trunk.;;;","22/Feb/10 17:11;jbellis;+1

please commit first to 0.6 then merge to trunk with repo merge (that is, not old-style cherry picking).  thanks!;;;","22/Feb/10 17:50;johanoskarsson;Committed to trunk and the 0.6 branch.;;;","24/Feb/10 13:07;hudson;Integrated in Cassandra #364 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/364/])
    Fix bug where ivy downloaded jar files were not included. Patch by johan, review by jbellis. 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Compaction bucketizing is computing average size incorrectly,CASSANDRA-814,12456955,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,21/Feb/10 21:48,16/Apr/19 09:33,14/Jul/23 05:51,23/Feb/10 22:47,0.6,,,,0,,,,,,"in the worst case (which doesn't seem to actually affect anyone) this could prevent sstables from being compacted, incorrectly",,david.pan,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Feb/10 22:15;jbellis;ASF.LICENSE.NOT.GRANTED--0001-rename-CM.getCompactionBuckets-CM.getBuckets.txt;https://issues.apache.org/jira/secure/attachment/12436772/ASF.LICENSE.NOT.GRANTED--0001-rename-CM.getCompactionBuckets-CM.getBuckets.txt","23/Feb/10 22:15;jbellis;ASF.LICENSE.NOT.GRANTED--0002-fix-average-size-calculation.txt;https://issues.apache.org/jira/secure/attachment/12436773/ASF.LICENSE.NOT.GRANTED--0002-fix-average-size-calculation.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19877,,,Tue Feb 23 22:47:07 UTC 2010,,,,,,,,,,"0|i0g18n:",91631,,,,,Low,,,,,,,,,,,,,,,,,"23/Feb/10 22:00;stuhood;This doesn't look right...

 * We use < and > in the if statement for existing buckets, which means that an SSTable of exactly half the average or exactly 1.5 the average will create a new bucket.
 * We always divide by 2 to calculate the average, although there will typically be more than 2 sstables in a bucket.;;;","23/Feb/10 22:16;jbellis;> We use < and > in the if statement

doesn't seem that inclusive comparisons is necessarily any more correct, really.

> We always divide by 2

good catch, fixed in new patchset.;;;","23/Feb/10 22:30;stuhood;+1;;;","23/Feb/10 22:47;jbellis;committed to 0.6;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
refactor system tests to accommodate avro,CASSANDRA-812,12456849,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,urandom,urandom,urandom,19/Feb/10 22:15,16/Apr/19 09:33,14/Jul/23 05:51,19/Feb/10 22:29,0.7 beta 1,,,,0,,,,,,The patches that follow refactor the existing functional tests in order to better accommodate functional tests for avro.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/10 22:16;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-812-stubbed-out-functional-tests-from-avro.txt;https://issues.apache.org/jira/secure/attachment/12436389/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-812-stubbed-out-functional-tests-from-avro.txt","19/Feb/10 22:16;urandom;ASF.LICENSE.NOT.GRANTED--v1-0002-renamed-thrift-tests-for-consistency.txt;https://issues.apache.org/jira/secure/attachment/12436390/ASF.LICENSE.NOT.GRANTED--v1-0002-renamed-thrift-tests-for-consistency.txt",,,,,,,,,,,,,2.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19876,,,Sat Feb 20 12:38:43 UTC 2010,,,,,,,,,,"0|i0g187:",91629,,,,,Normal,,,,,,,,,,,,,,,,,"19/Feb/10 22:19;urandom;Running these requires the Python module for avro, (works-for-me against trunk as of today).;;;","19/Feb/10 22:24;jbellis;+1;;;","19/Feb/10 22:29;urandom;committed.;;;","20/Feb/10 12:38;hudson;Integrated in Cassandra #361 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/361/])
    renamed thrift tests for consistency

Patch by eevans for 
 stubbed out functional tests from avro

Patch by eevans for 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
support starting an avro enabled node (experimental),CASSANDRA-811,12456836,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,urandom,urandom,urandom,19/Feb/10 21:10,16/Apr/19 09:33,14/Jul/23 05:51,19/Feb/10 21:33,0.7 beta 1,,,,0,,,,,,"The start script should support a  ""-a"" argument to make it possible to start an Avro enabled node. If/when Avro becomes a suitable replacement, the -a option can be dropped in favor of a -t option (as Avro becomes the deafult), which in turn can be dropped after Thrift is removed entirely.

The ThriftAddress and ThriftPort directives should also renamed to RPCAddress and RPCPort so that they can serve both RPC mechanism without creating confusion.

Patches to follow.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/10 21:11;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-811-use-less-specific-descriptors-for-Thrift.txt;https://issues.apache.org/jira/secure/attachment/12436372/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-811-use-less-specific-descriptors-for-Thrift.txt","19/Feb/10 21:11;urandom;ASF.LICENSE.NOT.GRANTED--v1-0002-start-avro-daemon-using-a-arg-to-startup-script.txt;https://issues.apache.org/jira/secure/attachment/12436373/ASF.LICENSE.NOT.GRANTED--v1-0002-start-avro-daemon-using-a-arg-to-startup-script.txt",,,,,,,,,,,,,2.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19875,,,Sat Feb 20 12:38:43 UTC 2010,,,,,,,,,,"0|i0g17z:",91628,,,,,Normal,,,,,,,,,,,,,,,,,"19/Feb/10 21:28;gdusbabek;+1 tested changes. correct daemon is run.;;;","19/Feb/10 21:33;urandom;committed.;;;","20/Feb/10 12:38;hudson;Integrated in Cassandra #361 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/361/])
    release note mentioning renamed directives

Patch by eevans for 
start avro daemon using -a arg to startup script

Patch by eevans; reviewed by gdusbabek for 
use less specific descriptors for Thrift{Address,Port}

Patch by eevans; reviewed by gdusbabek for 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unit tests log RTE to stderr even though tests still succeed.,CASSANDRA-806,12456582,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,gdusbabek,gdusbabek,17/Feb/10 20:11,16/Apr/19 09:33,14/Jul/23 05:51,17/Feb/10 21:17,0.6,,,,0,,,,,,"[junit] ------------- Standard Error -----------------
   [junit] ERROR 20:05:29,165 Error in executor futuretask
   [junit] java.util.concurrent.ExecutionException: java.lang.RuntimeException: No replica strategy configured for ltable
   [junit]     at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
   [junit]     at java.util.concurrent.FutureTask.get(FutureTask.java:83)
   [junit]     at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:65)
   [junit]     at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
   [junit]     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
   [junit]     at java.lang.Thread.run(Thread.java:619)
   [junit] Caused by: java.lang.RuntimeException: No replica strategy configured for ltable
   [junit]     at org.apache.cassandra.service.StorageService.getReplicationStrategy(StorageService.java:245)
   [junit]     at org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:1150)
   [junit]     at org.apache.cassandra.service.AntiEntropyService.getNeighbors(AntiEntropyService.java:149)
   [junit]     at org.apache.cassandra.service.AntiEntropyService.access$100(AntiEntropyService.java:88)
   [junit]     at org.apache.cassandra.service.AntiEntropyService$Validator.call(AntiEntropyService.java:487)
   [junit]     at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
   [junit]     at java.util.concurrent.FutureTask.run(FutureTask.java:138)
   [junit]     at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
   [junit]     ... 2 more
   [junit] ERROR 20:05:31,949 Error in executor futuretask
   [junit] java.util.concurrent.ExecutionException: java.lang.RuntimeException: No replica strategy configured for rtable
   [junit]     at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
   [junit]     at java.util.concurrent.FutureTask.get(FutureTask.java:83)
   [junit]     at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:65)
   [junit]     at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
   [junit]     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
   [junit]     at java.lang.Thread.run(Thread.java:619)
   [junit] Caused by: java.lang.RuntimeException: No replica strategy configured for rtable
   [junit]     at org.apache.cassandra.service.StorageService.getReplicationStrategy(StorageService.java:245)
   [junit]     at org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:1150)
   [junit]     at org.apache.cassandra.service.AntiEntropyService.getNeighbors(AntiEntropyService.java:149)
   [junit]     at org.apache.cassandra.service.AntiEntropyService.access$100(AntiEntropyService.java:88)
   [junit]     at org.apache.cassandra.service.AntiEntropyService$Validator.call(AntiEntropyService.java:487)
   [junit]     at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
   [junit]     at java.util.concurrent.FutureTask.run(FutureTask.java:138)
   [junit]     at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
   [junit]     ... 2 more
   [junit] ------------- ---------------- ---------------",,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Feb/10 20:50;gdusbabek;0001-use-real-keyspace-names-so-that-real-replication-str.patch;https://issues.apache.org/jira/secure/attachment/12436126/0001-use-real-keyspace-names-so-that-real-replication-str.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19873,,,Wed Feb 17 21:17:15 UTC 2010,,,,,,,,,,"0|i0g16v:",91623,,,,,Low,,,,,,,,,,,,,,,,,"17/Feb/10 20:52;gdusbabek;This was introduced in 620 when each table was assigned a specific replication strategy, rather than relying on a global one.;;;","17/Feb/10 21:06;stuhood;+1 Looks good to me.;;;","17/Feb/10 21:17;gdusbabek;r911178;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
using Integer.MAX_VALUE for executor keepalive time defeats the purpose of the SEDA-like stage divisions,CASSANDRA-805,12456560,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,17/Feb/10 17:02,16/Apr/19 09:33,14/Jul/23 05:51,22/Apr/10 21:06,0.7 beta 1,,,,0,,,,,,we should allow thread pools to shrink when they have excess capacity,,rodrigoap,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/10 15:59;jbellis;805.txt;https://issues.apache.org/jira/secure/attachment/12442571/805.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19872,,,Thu Apr 22 21:06:33 UTC 2010,,,,,,,,,,"0|i0g16n:",91622,,,,,Low,,,,,,,,,,,,,,,,,"19/Mar/10 02:43;rodrigoap;Maybe a StageController attached to the Stage that monitors its throughput to do runtime tuning of the thread pool.;;;","22/Apr/10 20:26;rschildmeijer;+1;;;","22/Apr/10 21:06;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Warn operator when there is not enough disk space for compaction,CASSANDRA-804,12456535,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,17/Feb/10 13:51,16/Apr/19 09:33,14/Jul/23 05:51,17/Feb/10 16:59,0.6,,,,0,,,,,,,,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Feb/10 16:25;jbellis;804-v3.txt;https://issues.apache.org/jira/secure/attachment/12436112/804-v3.txt","17/Feb/10 14:48;jbellis;804.txt;https://issues.apache.org/jira/secure/attachment/12436109/804.txt","17/Feb/10 14:51;gdusbabek;reset-compactionFileLocation.txt;https://issues.apache.org/jira/secure/attachment/12436110/reset-compactionFileLocation.txt",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19871,,,Wed Feb 17 17:54:44 UTC 2010,,,,,,,,,,"0|i0g16f:",91621,,,,,Low,,,,,,,,,,,,,,,,,"17/Feb/10 14:35;gdusbabek;I don't understand the purpose of the while loop.  If there isn't enough space (compactionFileLocation==null), shouldn't the error be reported and the function return 0?;;;","17/Feb/10 14:41;jbellis;the purpose is, if we can't compact all N files, see if we can compact N - 1, N - 2, etc.  Merging rows will actually free space in the average case, so it's possible that by merging some files rather than giving up completely that we will actually succeed at all of them next time.;;;","17/Feb/10 14:48;jbellis;better patch.;;;","17/Feb/10 14:51;gdusbabek;That makes sense, but if I'm reading the code correctly, the loop will always empty out smallerSSTables since compactionFileLocation is invariant.  Perhaps it should be reset in the while loop.  (Apply reset-compactionFileLocation.txt on top of your patch to see.);;;","17/Feb/10 15:30;jbellis;definitely, +1 your fix.;;;","17/Feb/10 16:25;jbellis;combined patch attached;;;","17/Feb/10 16:49;gdusbabek;+1;;;","17/Feb/10 16:59;jbellis;committed;;;","17/Feb/10 17:54;hudson;Integrated in Cassandra #357 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/357/])
    use while loop instead of recursion when trimming sstables compaction list to avoid blowing stack in pathological cases.
patch by jbellis; reviewed by gdusbabe for 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Spurious Gossip Up/Down and IO Errors,CASSANDRA-800,12456474,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,,kingryan,kingryan,16/Feb/10 19:48,16/Apr/19 09:33,14/Jul/23 05:51,22/Feb/10 16:36,0.5,,,,0,,,,,,"We're seeing a lot of nodes flapping. It appears to possibly be a race condition in Gossip.

on 10.209.23.110

WARN [MESSAGING-SERVICE-POOL:2] 2010-02-13 01:18:22,976 TcpConnection.java (line 484) Problem reading from socket connected to : java.nio.channels.SocketChannel[connected local=/10.209.23.110:7000 remote=/10.209.23.80:52720]
WARN [MESSAGING-SERVICE-POOL:1] 2010-02-13 01:18:22,976 TcpConnection.java (line 484) Problem reading from socket connected to : java.nio.channels.SocketChannel[connected local=/10.209.23.110:7000 remote=/10.209.23.80:36128]
 WARN [MESSAGING-SERVICE-POOL:2] 2010-02-13 01:18:22,977 TcpConnection.java (line 485) Exception was generated at : 02/13/2010 01:18:22 on thread MESSAGING-SERVICE-POOL:2
Reached an EOL or something bizzare occured. Reading from: /10.209.23.80 BufferSizeRemaining: 16
java.io.IOException: Reached an EOL or something bizzare occured. Reading from: /10.209.23.80 BufferSizeRemaining: 16
    at org.apache.cassandra.net.io.StartState.doRead(StartState.java:44)
    at org.apache.cassandra.net.io.ProtocolState.read(ProtocolState.java:39)
    at org.apache.cassandra.net.io.TcpReader.read(TcpReader.java:95)
    at org.apache.cassandra.net.TcpConnection$ReadWorkItem.run(TcpConnection.java:445)
    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    at java.lang.Thread.run(Thread.java:619)


on 10.209.23.80 about the same time


ERROR [pool-1-thread-4751] 2010-02-13 01:17:12,261 Cassandra.java (line 1096) Internal error processing batch_insert
java.util.ConcurrentModificationException
    at java.util.HashMap$HashIterator.nextEntry(HashMap.java:848)
    at java.util.HashMap$KeyIterator.next(HashMap.java:883)
    at java.util.AbstractCollection.addAll(AbstractCollection.java:305)
    at java.util.HashSet.<init>(HashSet.java:100)
    at org.apache.cassandra.gms.Gossiper.getLiveMembers(Gossiper.java:173)
    at org.apache.cassandra.locator.AbstractReplicationStrategy.getHintedMapForEndpoints(AbstractReplicationStrategy.java:120)
    at org.apache.cassandra.locator.AbstractReplicationStrategy.getHintedEndpoints(AbstractReplicationStrategy.java:78)
    at org.apache.cassandra.service.StorageService.getHintedEndpointMap(StorageService.java:1186)
    at org.apache.cassandra.service.StorageProxy.insertBlocking(StorageProxy.java:169)
    at org.apache.cassandra.service.CassandraServer.doInsert(CassandraServer.java:466)
    at org.apache.cassandra.service.CassandraServer.batch_insert(CassandraServer.java:445)
    at org.apache.cassandra.service.Cassandra$Processor$batch_insert.process(Cassandra.java:1088)
    at org.apache.cassandra.service.Cassandra$Processor.process(Cassandra.java:817)
    at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    at java.lang.Thread.run(Thread.java:619)


just before that:

INFO [Timer-1] 2010-02-13 01:17:12,070 Gossiper.java (line 194) InetAddress /10.209.21.223 is now dead.
INFO [Timer-1] 2010-02-13 01:17:12,257 Gossiper.java (line 194) InetAddress /10.209.21.217 is now dead.
INFO [Timer-1] 2010-02-13 01:17:12,257 Gossiper.java (line 194) InetAddress /10.209.21.216 is now dead.
INFO [Timer-1] 2010-02-13 01:17:12,258 Gossiper.java (line 194) InetAddress /10.209.21.215 is now dead.
INFO [Timer-1] 2010-02-13 01:17:12,258 Gossiper.java (line 194) InetAddress /10.209.23.82 is now dead.


and just after that:

INFO [Timer-1] 2010-02-13 01:17:12,261 Gossiper.java (line 194) InetAddress /10.209.23.81 is now dead.
INFO [Timer-1] 2010-02-13 01:17:12,293 Gossiper.java (line 194) InetAddress /10.209.23.79 is now dead.
INFO [Timer-1] 2010-02-13 01:17:12,304 Gossiper.java (line 194) InetAddress /10.209.21.204 is now dead.
INFO [Timer-1] 2010-02-13 01:17:12,307 Gossiper.java (line 194) InetAddress /10.209.21.197 is now dead.
INFO [Timer-1] 2010-02-13 01:17:12,308 Gossiper.java (line 194) InetAddress /10.209.21.245 is now dead.
INFO [Timer-1] 2010-02-13 01:17:12,309 Gossiper.java (line 194) InetAddress /10.209.21.242 is now dead.
INFO [Timer-1] 2010-02-13 01:17:12,310 Gossiper.java (line 194) InetAddress /10.209.23.106 is now dead.
INFO [GMFD:1] 2010-02-13 01:17:26,780 Log4jLogger.java (line 41) 02/13/2010 01:17:26 - Remaining bytes zero. Stopping deserialization in EndPointState.
INFO [GMFD:1] 2010-02-13 01:17:26,784 Gossiper.java (line 543) InetAddress /10.209.21.204 is now UP
INFO [GMFD:1] 2010-02-13 01:17:26,785 Gossiper.java (line 543) InetAddress /10.209.23.106 is now UP
INFO [GMFD:1] 2010-02-13 01:17:26,786 Gossiper.java (line 543) InetAddress /10.209.21.197 is now UP
INFO [GMFD:1] 2010-02-13 01:17:26,800 Gossiper.java (line 543) InetAddress /10.209.21.216 is now UP
INFO [GMFD:1] 2010-02-13 01:17:41,808 Gossiper.java (line 543) InetAddress /10.209.21.217 is now UP
INFO [GMFD:1] 2010-02-13 01:17:41,823 Gossiper.java (line 543) InetAddress /10.209.21.223 is now UP
INFO [GMFD:1] 2010-02-13 01:17:41,823 Gossiper.java (line 543) InetAddress /10.209.21.215 is now UP


We're on 298a0e66ba66c5d2a1e5d4a70f2f619ae3fbf72a from git.apache.org, which claims to be:

git-svn-id: https://svn.apache.org/repos/asf/incubator/cassandra/branches/cassandra-0.5@9035",,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Feb/10 12:30;jbellis;800.txt;https://issues.apache.org/jira/secure/attachment/12436488/800.txt",,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19869,,,Mon Feb 22 16:36:00 UTC 2010,,,,,,,,,,"0|i0g15j:",91617,,,,,Normal,,,,,,,,,,,,,,,,,"16/Feb/10 19:53;jbellis;the IOException is the same as #657 and is harmless (fixed in trunk, not going to be fixed in 0.5).

the ConcurrentModificationException  may be causing the deadness problem.  (it also might be related to CASSANDRA-757 but the stacktrace is different.);;;","17/Feb/10 02:41;jbellis;Ryan added in IRC:

""this may be the root of the problems I was describing above -- some threads may be dying due to OOM""

I'm skeptical that OOM could cause CME though.;;;","17/Feb/10 03:40;kingryan;I'm skeptical about it too, but I've seen stranger effects from OOME's. We've made some config changes to (hopefully) reduce heap size pressure. I'll let you know if that improves the situation or now.;;;","17/Feb/10 20:15;kingryan;After reducing the heap pressure these errors appear to have gone away. I think it would be reasonable to attribute this behavior to hitting OOME's, which killed some threads, but not all of them.

I think it would be best to kill the server when we hit an OOME.;;;","17/Feb/10 20:46;gdusbabek;OOME would appear in the logs.  I think the JVM is loaded and isn't making the right decisions about which threads to service.  I've been able to duplicate these exact errors on my dev machine when I spin up 4 cassandra instances, set RF=3 and send it a heavy write load.

The gossip thread is rather important in that if it gets stalled when the node isn't really down and the cluster is under a heavy write load, it could lead to writes getting sent to other (already loaded) nodes causing a cascade of failures.  

We might want to see about putting it in it's own thread group and giving it a higher priority.;;;","17/Feb/10 21:04;jbellis;Gary: CME is a correctness issue though, priority shouldn't affect that.

Ryan: OOME is indeed configured to kill the server by default in CassandraDaemon:

            public void uncaughtException(Thread t, Throwable e)
            {
                logger.error(""Fatal exception in thread "" + t, e);
                if (e instanceof OutOfMemoryError)
                {
                    System.exit(100);
                }

if we have a catch-all statement somewhere that is neutering that, the stacktrace should make that obvious.;;;","17/Feb/10 21:35;kingryan;gary-

we did see OOME's in the logs:

ERROR [pool-1-thread-5016] 2010-02-13 02:50:05,872 CassandraDaemon.java (line 71) Fatal exception in thread Thread[pool-1-thread-5016,5,main]
java.lang.OutOfMemoryError: Java heap space
 WARN [MESSAGING-SERVICE-POOL:2] 2010-02-13 02:46:24,194 TcpConnection.java (line 484) Problem reading from socket connected to : java.nio.channels.SocketChannel[connected local=/10.209.23.111:7000 remote=/10.209.23.84:37322]
ERROR [pool-1-thread-4994] 2010-02-13 02:45:29,807 CassandraDaemon.java (line 71) Fatal exception in thread Thread[pool-1-thread-4994,5,main]
java.lang.OutOfMemoryError: Java heap space
ERROR [main] 2010-02-13 02:45:17,044 CassandraDaemon.java (line 184) Exception encountered during startup.
ERROR [MESSAGE-DESERIALIZER-POOL:1] 2010-02-13 02:45:17,044 DebuggableThreadPoolExecutor.java (line 162) Error in executor futuretask
java.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: Java heap space
    at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
    at java.util.concurrent.FutureTask.get(FutureTask.java:83)
    at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:154)
    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:888)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.OutOfMemoryError: Java heap space;;;","21/Feb/10 12:30;jbellis;Fix for OOME not killing the server attached;;;","22/Feb/10 16:36;jbellis;i'm going to close this as a dupe of CASSANDRA-757 even though they are different errors, since the right fix for 757 will be using a concurrent structure, which will fix any other CMEs too.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cli.bat batch file not passing arguments onto the main class,CASSANDRA-797,12456369,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,wolfeidau,wolfeidau,wolfeidau,15/Feb/10 23:23,16/Apr/19 09:33,14/Jul/23 05:51,17/Feb/10 00:35,0.6,,Legacy/Tools,,0,windows,,,,,"If you run the following command in windows the arguments will not get passed to the CliMain class.

E:\Working\apache-cassandra-incubating-trunk>bin\cassandra-cli.bat --host 127.0.0.1 --port 9160
",WIndows,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Feb/10 00:13;wolfeidau;cassandra-cli-bat.patch;https://issues.apache.org/jira/secure/attachment/12436059/cassandra-cli-bat.patch",,,,,,,,,,,,,,1.0,wolfeidau,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19868,,,Wed Feb 17 17:54:43 UTC 2010,,,,,,,,,,"0|i0g14v:",91614,,,,,Normal,,,,,,,,,,,,,,,,,"15/Feb/10 23:27;wolfeidau;I have essentially rewritten the batch file using the daemon one as a template while also correcting the issue with arguments not being passed to the CLIMain class.;;;","16/Feb/10 00:29;wolfeidau;Updated patch which resolves the identified issue and cleans up the batch file a bit.

;;;","16/Feb/10 01:31;wolfeidau;Patch to the cassandra-cli.bat in attached file which has been  tested on windows.;;;","16/Feb/10 18:57;urandom;This patch isn't applying for me, perhaps it needs to be rebased against current trunk?;;;","17/Feb/10 00:13;wolfeidau;Re-created the patch the old fashion way rather than relying on Idea to generate it.

Tested this and it applies fine now.;;;","17/Feb/10 00:35;urandom;committed; thanks;;;","17/Feb/10 17:54;hudson;Integrated in Cassandra #357 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/357/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
binary artifacts need ivy for dependencies,CASSANDRA-796,12456366,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,urandom,urandom,15/Feb/10 22:18,16/Apr/19 09:33,14/Jul/23 05:51,16/Feb/10 18:59,0.6,,Legacy/Tools,,0,,,,,,"Currently, if you generate a release, the binary artifact is missing required dependencies and the means to obtain them. The patch that follows a) copies build.xml and ivy.xml into the bin artifact and b) makes build.xml smart enough to tell when it's being run from a binary artifact.

This would also require updating all installation and quickstart documentation as well (the patch updates README.txt).",,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Feb/10 22:20;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-796-adapt-build.xml-to-work-from-binary-arti.txt;https://issues.apache.org/jira/secure/attachment/12435914/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-796-adapt-build.xml-to-work-from-binary-arti.txt",,,,,,,,,,,,,,1.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19867,,,Wed Feb 17 17:54:42 UTC 2010,,,,,,,,,,"0|i0g14n:",91613,,,,,Low,,,,,,,,,,,,,,,,,"16/Feb/10 16:03;gdusbabek;tested, +1.;;;","16/Feb/10 18:59;urandom;committed; thanks;;;","17/Feb/10 17:54;hudson;Integrated in Cassandra #357 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/357/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Streaming broken on windows (FileStreamTask.CHUNK_SIZE is too big).,CASSANDRA-795,12456333,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,gdusbabek,gdusbabek,15/Feb/10 15:32,16/Apr/19 09:33,14/Jul/23 05:51,16/Feb/10 22:57,0.5,,,,0,,,,,,Setting chunk size smaller addresses the problem.  We should explore setting SO_SNDBUF higher to see if that fixes the problem.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Feb/10 19:26;gdusbabek;0001-set-SO_SNDBUF-bigger.patch;https://issues.apache.org/jira/secure/attachment/12435896/0001-set-SO_SNDBUF-bigger.patch","15/Feb/10 19:26;gdusbabek;0002-unit-test-for-streaming-a-big-file.patch;https://issues.apache.org/jira/secure/attachment/12435895/0002-unit-test-for-streaming-a-big-file.patch",,,,,,,,,,,,,2.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19866,,,Tue Feb 16 22:57:18 UTC 2010,,,,,,,,,,"0|i0g14f:",91612,,,,,Low,,,,,,,,,,,,,,,,,"15/Feb/10 15:36;jbellis;(Closed CASSANDRA-793 as dupe of this.);;;","15/Feb/10 15:38;jbellis;If you add a unit test w/ a 64MB file I can test on windows.  Writing a row w/ a single column of 64MB ought to do it.;;;","15/Feb/10 19:26;gdusbabek;Test case attached (it takes a while to complete).;;;","15/Feb/10 19:56;jbellis;it would probably be a lot faster if you put the bulk of the volume in a column value[] so it doesn't have to do a whole bunch of String serialization in the setup.

Test passes for me (64 bit windows 7) w/o patch 01 so I don't think I can usefully report on that. :);;;","16/Feb/10 12:25;tantra;On WinXp this patch doesn't work. Help only reduce CHUNK_SIZE

java.lang.RuntimeException: java.io.IOException: Невозможно выполнить операцию на сокете, т.к. буфер слишком мал или очередь переполнена
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
Caused by: java.io.IOException: Невозможно выполнить операцию на сокете, т.к. буфер слишком мал или очередь переполнена
	at sun.nio.ch.SocketDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:33)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:104)
	at sun.nio.ch.IOUtil.write(IOUtil.java:60)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)
	at sun.nio.ch.FileChannelImpl.transferToTrustedChannel(FileChannelImpl.java:449)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:520)
	at org.apache.cassandra.net.FileStreamTask.stream(FileStreamTask.java:96)
	at org.apache.cassandra.net.FileStreamTask.runMayThrow(FileStreamTask.java:64)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
	... 3 more
ERROR [MESSAGE-STREAMING-POOL:1] 2010-02-16 15:21:34,234 CassandraDaemon.java (line 78) Fatal exception in thread Thread[MESSAGE-STREAMING-POOL:1,5,main]
java.lang.RuntimeException: java.io.IOException: Невозможно выполнить операцию на сокете, т.к. буфер слишком мал или очередь переполнена
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
Caused by: java.io.IOException: Невозможно выполнить операцию на сокете, т.к. буфер слишком мал или очередь переполнена
	at sun.nio.ch.SocketDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:33)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:104)
	at sun.nio.ch.IOUtil.write(IOUtil.java:60)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)
	at sun.nio.ch.FileChannelImpl.transferToTrustedChannel(FileChannelImpl.java:449)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:520)
	at org.apache.cassandra.net.FileStreamTask.stream(FileStreamTask.java:96)
	at org.apache.cassandra.net.FileStreamTask.runMayThrow(FileStreamTask.java:64)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)
	... 3 more
;;;","16/Feb/10 22:09;gdusbabek;I was able to duplicate this in windows XP by throwing roughly 200MB at a socket in short order. SO_RCVBUF and SO_SNDBUF both default to 8k and setting them up to 256k didn't address the problem. Since the default values were so low, I didn't think that setting them in the multi-MB range was going to prove fruitful.

Google wasn't very helpful explaining the underlying cause of the error (stems from winsock err code WSAENOBUFS) except for stating the obvious (there isn't enough allocated memory somewhere). Taking it all in, I get the sense that when you chunk data up to send over a socket, those chunks end up in kernel memory (paged), not user memory, and if you use too much of that (varies across windows versions), a WSAENOBUFS ensues.

Setting FileStreamTask.CHUNK_SIZE to 32MB solves the problem though. Unless there are any objections, I think we'll stick with that solution.;;;","16/Feb/10 22:15;jbellis;+1 set to 32MB;;;","16/Feb/10 22:57;gdusbabek;r910738 (0.5), 910744 (trunk);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SSTables limited to (2^31)/15 keys",CASSANDRA-790,12456197,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Urgent,Fixed,stuhood,stuhood,stuhood,12/Feb/10 22:27,16/Apr/19 09:33,14/Jul/23 05:51,16/Feb/10 04:01,0.5,,,,0,,,,,,"The current BloomFilter implementation requires a BitSet of (bucket_count * num_keys) in size, and that calculation is currently performed in an integer, which causes overflow for around 140 million keys in one SSTable.

Short term fix: perform the calculation in a long, and cap the value to the maximum size of a BitSet.
Long term fix: begin partitioning BitSets, perhaps using Linear Bloom Filters.",,bendiken,stuhood,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-1555,,,,,"15/Feb/10 22:01;stuhood;0001-Change-parameters-to-BloomCalculations-in-order-to-c.patch;https://issues.apache.org/jira/secure/attachment/12435910/0001-Change-parameters-to-BloomCalculations-in-order-to-c.patch","14/Feb/10 04:19;stuhood;0001-Change-parameters-to-BloomCalculations-in-order-to-c.patch;https://issues.apache.org/jira/secure/attachment/12435802/0001-Change-parameters-to-BloomCalculations-in-order-to-c.patch","15/Feb/10 22:01;stuhood;0002-Add-timeouts-to-forceBlockingFlush-during-tests.patch;https://issues.apache.org/jira/secure/attachment/12435911/0002-Add-timeouts-to-forceBlockingFlush-during-tests.patch","14/Feb/10 04:19;stuhood;0002-Add-timeouts-to-forceBlockingFlush-during-tests.patch;https://issues.apache.org/jira/secure/attachment/12435803/0002-Add-timeouts-to-forceBlockingFlush-during-tests.patch",,,,,,,,,,,4.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19863,,,Tue Feb 16 04:01:01 UTC 2010,,,,,,,,,,"0|i0g13b:",91607,,,,,Critical,,,,,,,,,,,,,,,,,"12/Feb/10 22:35;stuhood;Here is the short term solution.;;;","12/Feb/10 22:41;jbellis;rather than just cap the filter size, you need to reduce bucketsPerElement too or you will get suboptimal number-of-hashes calculation, since you haven't told it it can't have as big a filter as it wanted.;;;","14/Feb/10 04:19;stuhood;Better implementation of the short term solution. Rather than capping the total number of buckets, this patch caps the number of buckets per element.

The second patch adds timeouts to blocking flushes, to minimize hanging tests.;;;","14/Feb/10 22:02;kingryan;Thanks for the work on this. I'll try and test it soon in the situation that brought up the problem.;;;","15/Feb/10 19:12;jbellis;patch 01 comments:

refactoring:
 - please split the refactoring into a separate patch; it's hard to tell what is part of the actual fix here
 - BF constructors that do not chain is a design smell; one of them only being called from tests is also a smell
 - instead of using min/max to force values into acceptable ranges, assert that they are sane
 - I feel part of the BF problems here is that BF is trying to be too high-level.  Wouldn't we be better served by having a low-level BF constructor taking hash & bucket counts, and then factories to do the high level things?

fix:
 - this feels like we're trading an obvious problem (BF constructor throws) for a more subtle one (BF is a no-op when we exceed the spec, as noted by TODO).  wouldn't it be better to log a warning, create the largest BF possible, and degrade gracefully?  This would be easier if the BF constructor were sane as mentioned above.;;;","15/Feb/10 19:21;stuhood;> please split the refactoring into a separate patch
Which refactoring? I don't think I did anything that wasn't necessary in order to cap the number of available buckets.

> BF constructors that do not chain is a design smell; one of them only being called from tests is also a smell
The 'maxFalsePosProb' constructor has never been called anywhere but tests, but it was very elegant, and someone spent a lot of time on it, so I wasn't sure whether to remove it.

> low-level BF constructor taking hash & bucket counts, and then factories to do the high level things
Agreed... that would be much better. I'll add factories with warnings.;;;","15/Feb/10 19:25;jbellis;> Which refactoring

the method renaming and constructor rearrangement;;;","15/Feb/10 22:01;stuhood;Updated to use factory functions rather than constructors. Also, for the factory function that takes a bucket/elem target, if the target can't be achieved, a warning will be logged, and the filter will degrade as gracefully as possible by using a minimum of 1 bucket/elem, and the maximum size filter.;;;","16/Feb/10 04:01;jbellis;committed 01 to 0.5 and trunk, with some changes (primarily using real exceptions for critical checks instead of asserts, and asserts instead of min() calls for others)

I'm not seeing any problems with flush that 02 is supposed to mitigate -- if you are, we should fix the code (or the test) to not be so sucky instead of not actually blocking for the requested op.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NPE in DatacenterShardStatergy,CASSANDRA-787,12456082,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,vijay2win@yahoo.com,vijay2win@yahoo.com,vijay2win@yahoo.com,11/Feb/10 23:31,16/Apr/19 09:33,14/Jul/23 05:51,18/Feb/10 20:06,0.6,,,11/Feb/10 00:00,0,,,,,,There is a long pending fix to contribute back... Plz find the patch.,Linux cassandra 0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Feb/10 23:32;vijay2win@yahoo.com;patch.txt;https://issues.apache.org/jira/secure/attachment/12435630/patch.txt",,,,,,,,,,,,,,1.0,vijay2win@yahoo.com,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19862,,,Thu Feb 18 20:06:54 UTC 2010,,,,,,,,,,"0|i0g12n:",91604,,,,,Low,,,,,,,,,,,,,,,,,"18/Feb/10 20:06;jbellis;committed to 0.6.  (would have been faster if marked Patch Submitted :);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"in a cluster, get_range_slice() does not return all the keys it should",CASSANDRA-781,12455694,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,bjc,bjc,08/Feb/10 22:32,16/Apr/19 09:33,14/Jul/23 05:51,23/Feb/10 17:06,0.5,,,,0,,,,,,"get_range_slice() does not return the same set of keys as get_key_range() in 0.5.0 final.

I posted a program to reproduce the behavior:

http://www.mail-archive.com/cassandra-dev@incubator.apache.org/msg01474.html

Apparently, you must have more than one node to get the behavior. Also, it may depend on the locations of the nodes on the ring.. I.e., if you don't generate enough keys randomly, then by chance they could all fall on the same host and you might not see the behavior, although I was able to get it to happen using only 2 nodes and 10 keys.

Here are the other emails describing the issue:

http://www.mail-archive.com/cassandra-user@incubator.apache.org/msg02423.html
","Debian 5 lenny on EC2, Gentoo linux, Windows XP",hbadenes,slebresne,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Feb/10 20:38;jbellis;781-backport.txt;https://issues.apache.org/jira/secure/attachment/12436624/781-backport.txt","15/Feb/10 17:03;jbellis;781.txt;https://issues.apache.org/jira/secure/attachment/12435887/781.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19861,,,Tue Feb 23 17:06:05 UTC 2010,,,,,,,,,,"0|i0g11b:",91598,,,,,Normal,,,,,,,,,,,,,,,,,"09/Feb/10 05:52;jbellis;Reproduced on trunk.  Can you try the attached patch there?  (We can backport to 0.5 afterwards.);;;","09/Feb/10 08:16;bjc;Before applying 781.txt to trunk I was getting an exception. The exception is now gone! Awesome. However, I still have the range scanning problem. Here are a few example runs of the test:

$ python test_bug.py get_range_slice
ebbde791748641be951802d64d48c62d not marked 0
9bfa7ad8abce48a9a45daccfa3772f29 not marked 0
$ python test_bug.py get_range_slice
c554dc532bfb462b950990b6824f11c1 not marked 0
e6c4a0100508451ea3a1d13088877dd9 not marked 0
$ python test_bug.py get_range_slice
$ python test_bug.py get_range_slice
$ python test_bug.py get_range_slice
27fc88c8e7ab489d96f4c749cc86aca1 not marked 0
$ python test_bug.py get_range_slice
b522cca4bd6f4282a507525598139f95 not marked 0
$ python test_bug.py get_range_slice
d045b3edabc949fea30242722a11587a not marked 0
$ 

Sigh, I just realized that under trunk my nodetool doesn't work. However, I got the tokens from the log:

INFO 08:10:50,338 Saved Token not found. Using 68054825649105441942293089893012253843
INFO 08:10:53,293 Saved Token not found. Using 44181284974408316254372647768836513112
;;;","09/Feb/10 12:53;hbadenes;I am hitting a similar problem on 3-node cluster I run. I do receive 5 rows in the get_range_slice query (from """" to """"), instead of an empty result set as described here (there exist more than just those 5 returned).

I am running 0.5.0 and could be able to test a patch for that version.;;;","09/Feb/10 13:30;slebresne;I add the same problem, range_slice on 2 nodes was missing results.
I updated to trunk and applied 781.txt. It fixes the missing results but
introduce a timeout exception (I don't believe it is the patch fault though).

The timeout happens with consistencyLevel.ONE (but I suspect it could happen
with QUORUM too). Looking a bit to the details, it seems that
RangeSliceResponseResolver wait for a response from every live natural
endpoints (in isDataPresent()). But in StorageProxy, the rangeSlice message is
only sent to 'responseCount' endpoints (which will be 1 for
consistencyLevel.ONE). Hence the timeout.

I'm not sure what would be the best way to deal with that though.;;;","09/Feb/10 14:27;jbellis;Sylvain: absolutely right, patch 01 has a fix for this.

Jack: updated patch 02 with more logging at INFO, maybe that will help.  I can't reproduce even w/ your tokens and several runs of 100 keys.  I am using a slightly simpler test, though:

        import uuid
        ks = ""Keyspace1""
        cf = ""Super1""
        path = ColumnPath(cf, ""foo"", ""is"")
        value = ""cool""

        # insert, record keys in `keys` set
        keys = set()
        for i in xrange(100):
            key = uuid.uuid4().hex
            client.insert(ks, key, path, value, 0, ConsistencyLevel.ONE)
            keys.add(key)
    
        # remove keys found from set
        parent = ColumnParent(column_family=cf)
        slice_range = SliceRange(start=""key"", finish=""key"")
        predicate = SlicePredicate(slice_range=slice_range)        
        result = client.get_range_slice(ks, parent, predicate, """", """", 1000, ConsistencyLevel.ONE)
        for row in result:
            keys.discard(row.key)

        # if there are any left over, there is a bug
        assert not keys, list(sorted(keys))

... this will of course only work until you insert more than 1000 keys.  (maybe your original test has a similar limitation, i don't remember.)

(Are you still testing w/ RF of 2?  If so maybe patch 01 will help you too.);;;","09/Feb/10 21:08;bjc;Ok, I checked out a fresh copy of trunk and applied both new patches (0001 and 0002). There were some errors for 0002, but upon looking at the code it seems parts of the patch have already been committed to the SVN repo, so what I ended up with is the right thing.

$ patch -p1 <0001-fix-timeout-bug.txt 
patching file src/java/org/apache/cassandra/service/StorageProxy.java
$ patch -p1 <0002-fix-slices-over-non-trivial-wrapped-ranges.txt
patching file src/java/org/apache/cassandra/db/ColumnFamilyStore.java
Hunk #1 succeeded at 43 (offset 1 line).
Hunk #2 succeeded at 1075 (offset 2 lines).
patching file src/java/org/apache/cassandra/dht/AbstractBounds.java
Hunk #1 FAILED at 29.
1 out of 1 hunk FAILED -- saving rejects to file src/java/org/apache/cassandra/dht/AbstractBounds.java.rej
patching file src/java/org/apache/cassandra/dht/Bounds.java
Hunk #1 FAILED at 1.
Hunk #2 FAILED at 11.
2 out of 2 hunks FAILED -- saving rejects to file src/java/org/apache/cassandra/dht/Bounds.java.rej
patching file src/java/org/apache/cassandra/dht/Range.java
patching file src/java/org/apache/cassandra/service/StorageProxy.java
patching file src/java/org/apache/cassandra/service/StorageService.java
Reversed (or previously applied) patch detected!  Assume -R? [n] 
Apply anyway? [n] 
Skipping patch.
3 out of 3 hunks ignored -- saving rejects to file src/java/org/apache/cassandra/service/StorageService.java.rej
patching file test/unit/org/apache/cassandra/dht/BoundsTest.java
patching file test/unit/org/apache/cassandra/dht/RangeTest.java
$ 

Copied my storage-conf.xml into place, which has only two changes: Seeds defined and binding addresses changed to null strings. Thus, my RF is 1 now, not 2 as it was before.

I now use your simpler test. Here is the test with all the import statements:

import uuid

from thrift import Thrift
from thrift.transport import TTransport
from thrift.transport import TSocket
from thrift.protocol.TBinaryProtocol import TBinaryProtocolAccelerated
from cassandra import Cassandra
from cassandra.ttypes import *

num_keys = 10

socket = TSocket.TSocket(""10.212.87.165"", 9160)
transport = TTransport.TBufferedTransport(socket)
protocol = TBinaryProtocol.TBinaryProtocolAccelerated(transport)
client = Cassandra.Client(protocol)

transport.open()

ks = ""Keyspace1""
cf = ""Super1""
path = ColumnPath(cf, ""foo"", ""is"")
value = ""cool""

# insert, record keys in `keys` set
keys = set()
for i in xrange(100):
    key = uuid.uuid4().hex
    client.insert(ks, key, path, value, 0, ConsistencyLevel.ONE)
    keys.add(key)

# remove keys found from set
parent = ColumnParent(column_family=cf)
slice_range = SliceRange(start=""key"", finish=""key"")
predicate = SlicePredicate(slice_range=slice_range)
result = client.get_range_slice(ks, parent, predicate, """", """", 1000, ConsistencyLevel.ONE)
for row in result:
    keys.discard(row.key)

# if there are any left over, there is a bug
assert not keys, list(sorted(keys))


I cleared out the data/commitlog dirs and launched both nodes. The tokens:

 INFO 21:02:08,768 Saved Token not found. Using 136351045523563703929320485474511375137
 INFO 21:02:09,509 Saved Token not found. Using 20118706661854036583649958139769313744

Now.. run the test!

$ python test_bug_simple.py
Traceback (most recent call last):
  File ""test_bug_simple.py"", line 36, in <module>
    result = client.get_range_slice(ks, parent, predicate, """", """", 1000, ConsistencyLevel.ONE) 
  File ""/usr/local/python//lib/python2.6/site-packages/cassandra/Cassandra.py"", line 486, in get_range_slice
  File ""/usr/local/python//lib/python2.6/site-packages/cassandra/Cassandra.py"", line 508, in recv_get_range_slice
thrift.Thrift.TApplicationException: Internal error processing get_range_slice


The log from the node I am querying:

 INFO 21:02:08,768 Saved Token not found. Using 13635104552356370392932048547451
1375137
 INFO 21:02:08,933 Starting up server gossip
 INFO 21:02:09,118 Cassandra starting up...
 INFO 21:02:10,686 Node /10.212.230.176 is now part of the cluster
 INFO 21:02:11,750 InetAddress /10.212.230.176 is now UP
 INFO 21:05:43,927 scanning node range (136351045523563703929320485474511375137,
20118706661854036583649958139769313744]
ERROR 21:05:43,927 Internal error processing get_range_slice
java.lang.AssertionError
        at org.apache.cassandra.dht.Bounds.<init>(Bounds.java:16)
        at org.apache.cassandra.dht.Bounds.restrictTo(Bounds.java:34)
        at org.apache.cassandra.service.StorageProxy.getRangeSlice(StorageProxy.
java:559)
        at org.apache.cassandra.thrift.CassandraServer.get_range_slice(Cassandra
Server.java:560)
        at org.apache.cassandra.thrift.Cassandra$Processor$get_range_slice.proce
ss(Cassandra.java:1189)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.jav
a:984)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadP
oolServer.java:253)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExec
utor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor
.java:908)
        at java.lang.Thread.run(Thread.java:619)



;;;","09/Feb/10 21:28;jbellis;Sorry, those patches that didn't apply were probably important. :)

I've rebased against r908163, can you revert and try again?;;;","09/Feb/10 21:44;bjc;Makes sense! Can you try one more time? I still can't apply the patch properly.. Or, maybe I'm doing something wrong? Here is the transcript.

$ svn checkout -r908163 https://svn.apache.org/repos/asf/incubator/cassandra/trunk cassandra
...
A    cassandra/README.txt
 U   cassandra
Checked out revision 908163.
$ cd cassandra
$ wget https://issues.apache.org/jira/secure/attachment/12435345/0001-fix-timeout-bug.txt
--2010-02-09 21:40:51--  https://issues.apache.org/jira/secure/attachment/124353
45/0001-fix-timeout-bug.txt
Resolving issues.apache.org... 140.211.11.140
Connecting to issues.apache.org|140.211.11.140|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1873 (1.8K) [text/plain]
Saving to: `0001-fix-timeout-bug.txt'

100%[======================================>] 1,873       --.-K/s   in 0s      

2010-02-09 21:40:52 (47.0 MB/s) - `0001-fix-timeout-bug.txt' saved [1873/1873]

$ patch -p1 <0001-fix-timeout-bug.txt 
patching file src/java/org/apache/cassandra/service/StorageProxy.java
$ wget https://issues.apache.org/jira/secure/attachment/12435346/0002-fix-slices-over-non-trivial-wrapped-ranges.txt
--2010-02-09 21:41:13--  https://issues.apache.org/jira/secure/attachment/124353
46/0002-fix-slices-over-non-trivial-wrapped-ranges.txt
Resolving issues.apache.org... 140.211.11.140
Connecting to issues.apache.org|140.211.11.140|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 14776 (14K) [text/plain]
Saving to: `0002-fix-slices-over-non-trivial-wrapped-ranges.txt'

100%[======================================>] 14,776      74.8K/s   in 0.2s    

2010-02-09 21:41:14 (74.8 KB/s) - `0002-fix-slices-over-non-trivial-wrapped-ranges.txt' saved [14776/14776]

$ patch -p1 <0002-fix-slices-over-non-trivial-wrapped-ranges.txt 
patching file src/java/org/apache/cassandra/db/ColumnFamilyStore.java
patching file src/java/org/apache/cassandra/dht/AbstractBounds.java
Hunk #1 FAILED at 29.
1 out of 1 hunk FAILED -- saving rejects to file src/java/org/apache/cassandra/dht/AbstractBounds.java.rej
patching file src/java/org/apache/cassandra/dht/Bounds.java
Hunk #1 FAILED at 1.
Hunk #2 FAILED at 11.
2 out of 2 hunks FAILED -- saving rejects to file src/java/org/apache/cassandra/dht/Bounds.java.rej
patching file src/java/org/apache/cassandra/dht/Range.java
patching file src/java/org/apache/cassandra/service/StorageProxy.java
patching file src/java/org/apache/cassandra/service/StorageService.java
patching file test/unit/org/apache/cassandra/dht/BoundsTest.java
patching file test/unit/org/apache/cassandra/dht/RangeTest.java
$ 
;;;","09/Feb/10 22:22;jbellis;weird, happens for me too.  lame!

attached Bounds and AbstractBounds as they should look, post-patch.  just do what you showed in the transcript, then overwrite the local copies with these.;;;","09/Feb/10 23:24;bjc;Ok, got the patch applied properly and things look better! The simple test passes. Awesome!! :) However, the more complicated test uses a ""start"" offset after the first get_range_slice(), and that still causes an exception. From the log:

 INFO 23:15:52,425 scanning node range (20123910036548544936247138992367052936,67283373037552029587203789575295250400]
ERROR 23:15:52,425 Internal error processing get_range_slice
java.lang.AssertionError: [124451343962032323897724984972289130546,67283373037552029587203789575295250400]
        at org.apache.cassandra.dht.Bounds.<init>(Bounds.java:26)
        at org.apache.cassandra.dht.Bounds.getRangeOrBounds(Bounds.java:74)
        at org.apache.cassandra.dht.Bounds.restrictTo(Bounds.java:59)
        at org.apache.cassandra.service.StorageProxy.getRangeSlice(StorageProxy.java:559)
        at org.apache.cassandra.thrift.CassandraServer.get_range_slice(CassandraServer.java:560)
        at org.apache.cassandra.thrift.Cassandra$Processor$get_range_slice.process(Cassandra.java:1189)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:984)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)

If you have trouble duplicating this one I can give you more information, but I did not have difficulty getting it to happen. It happened every time I tried. For example, you can get it to happen just by modifying one line of the simple test:

result = client.get_range_slice(ks, parent, predicate, ""b37e14bb37304e0096e2e77a8fc88a5b"", """", 1000, ConsistencyLevel.ONE)

Of course, if you don't scan starting from """" then the simple test doesn't make sense, because you might specifically exclude keys you are looking for by starting from the string I put in.

However, the more complicated test I posted earlier makes sense and exercises the start and end ranges of get_range_slice(). So..can we go back to the complicated test and specifically make that one work? It's also nice because you should be able to run it over and over, since it removes the keys at the end. With the simple test you have to manually flush the data and restart the servers each time.

Thanks so much for fixing this! I am getting more familiar with the java so soon I might be able to fix some bugs like this.;;;","11/Feb/10 05:27;jbellis;committed patch 1, the timeout fix.

here is a new patch that should fix the remaining range issues.;;;","11/Feb/10 06:53;bjc;Almost there I think. I found that the keys were not being returned in sorted order as they were before, so my trick of taking the last key in a limited range, and using that to start the next limited range did not work. So, I modified the test to sort the keys, then take the last one. When I did this I found another bug: when there are fewer keys in the specified range, duplicates are returned. Also, when I played around with the start and end for the range the server starting giving AssertionErrors:

ERROR 06:25:41,032 Internal error processing get_range_slice
java.lang.AssertionError: [125358492461525499902293558181143752059,1244525150549
22950280650433865080672503]
        at org.apache.cassandra.dht.Bounds.<init>(Bounds.java:26)
        at org.apache.cassandra.dht.Bounds.<init>(Bounds.java:18)
        at org.apache.cassandra.thrift.CassandraServer.get_range_slice(Cassandra
Server.java:558)
        at org.apache.cassandra.thrift.Cassandra$Processor$get_range_slice.proce
ss(Cassandra.java:1189)
        at org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.jav
a:984)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadP
oolServer.java:253)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExec
utor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor
.java:908)
        at java.lang.Thread.run(Thread.java:619)


The modified test (below) gets stuck in an infinite loop. If you run it in ipython, you can control-c to get back to the interpretor, then type ""result"" to look at it's contents. It is a sorted list of keys. Look at the last key.. Here is the transcript showing the last two keys from result:

 'ff8bfa30777f455695bf934ac7cfedac',
 'ffb701ea740646b9955f0e339f8e3ee2']

In [70]: result2 = client.get_range_slice(ks, cparent, p, start, """", seg, cl)

In [71]: len(result2)
Out[71]: 1000

In [72]: result3 = client.get_range_slice(ks, cparent, p, start, """", seg, cl)

In [73]: len(result3)
Out[73]: 1000

In [74]: start
Out[74]: 'ffb701ea740646b9955f0e339f8e3ee2'

In [75]: result4 = client.get_range_slice(ks, cparent, p, start, start, seg, cl)

In [76]: len(result4)
Out[76]: 1000

In [77]: result5 = client.get_range_slice(ks, cparent, p, start, start, seg, cl)

In [78]: len(result5)
Out[78]: 1

In [79]: 

That can't be right. Here is the latest test..

import sys
import time
import uuid

from thrift import Thrift
from thrift.transport import TTransport
from thrift.transport import TSocket
from thrift.protocol.TBinaryProtocol import TBinaryProtocolAccelerated

import sys
sys.path.insert(0,'/usr/local/cassandra/interface/thrift/gen-py')

from cassandra import Cassandra
from cassandra.ttypes import *

num_keys = 10000

socket = TSocket.TSocket(""10.212.87.165"", 9160)
transport = TTransport.TBufferedTransport(socket)
protocol = TBinaryProtocol.TBinaryProtocolAccelerated(transport)
client = Cassandra.Client(protocol)

ks = ""Keyspace1""
cf = ""Super1""
cl = ConsistencyLevel.ONE

d = {}
    
transport.open()
    
if 1:
    ## insert keys using the raw thrift interface
    cpath = ColumnPath(cf, ""foo"", ""is"")
    value = ""cool""

    for i in xrange(num_keys):
        ts = time.time()
        key = uuid.uuid4().hex
        client.insert(ks, key, cpath, value, ts, cl)
        d[key] = 1

else:
    ## insert keys using pycassa!
    import pycassa

    client = pycassa.connect([""10.212.87.165:9160""])
    cf_test = pycassa.ColumnFamily(client, ks, cf, super=True)

    for i in xrange(num_keys):
        key = uuid.uuid4().hex
        cf_test.insert(key, { 'params' : { 'is' : 'cool' }})
        d[key] = 1


cparent = ColumnParent(column_family=cf)
slice_range = SliceRange(start=""key"", finish=""key"")
p = SlicePredicate(slice_range=slice_range)

done = False
seg = 1000
start = """"

## do a scan using either get_key_range() (deprecated) or get_range_slice()
## for every key returned that is in the dictionary, mark it as found
while not done:
    print ""start"", start
    result = client.get_range_slice(ks, cparent, p, start, """", seg, cl)

    def getkey(x):
        return x.key
    result = map(getkey, result)   
    result.sort()

    for r in result:
        if d.has_key(r): 
            d[r] = 0

    if len(result) < seg: done = True
    else: start = result[seg-1]

cpath = ColumnPath(column_family=cf, super_column='foo')

## get, remove all the keys
## print all the keys that were not marked 0
for k in d:
    result = client.get(ks, k, cpath, cl)
    #print result

    if d[k] == 1: 
        print k, ""not marked 0""
    #else:
    #    print k, ""was marked 0!""

    ts = time.time()
    client.remove(ks, k, cpath, ts, cl)




BTW, this time around my nodetool worked perfectly! When I first brought the two nodes up, they selected keys that were too close, and one node ended up with all the load. So I ran loadbalance, and it worked great! That was really awesome. The only thing I noticed was a single key that should have been found returned a NotFoundException. I'll keep an eye on this one, too. Best,

Jack;;;","11/Feb/10 22:17;jbellis;new patch attached.

> ERROR 06:25:41,032 Internal error processing get_range_slice 

added InvalidRequestException when start > end, which fixes this.

> The modified test (below) gets stuck in an infinite loop

Your test is buggy. :)

range_slice (like key_range) is start-INCLUSIVE, so if you pass a key that exists as start, you will always get at least one result, the start one.

> the keys were not being returned in sorted order 

This is working fine for me.  Not sure what you were seeing.

> when there are fewer keys in the specified range, duplicates are returned

Sounds like another illustration of start-inclusiveness.

If you still see problems, can you narrow it down to a specific set of keys, rather than relying on randomness to maybe reproduce it once in a while?  That would help a lot.  Thanks!
;;;","12/Feb/10 03:44;bjc;I don't think my test is buggy. I realize that the range is start inclusive, and it does pass a key that exists as start, but sets ""done = True"" if the range scan returns less keys than requested. Since it passes """" as the end/finish, this should return less keys than requested when you get to the end, provided you ask for more than one key (which I do).

I think the last remaining problem is with the sorting! I bet that is why using """" for my finish string doesn't work. Here's the problem I see now (transcript followed by test):

I put 10 random keys in, ask for them back. They aren't sorted, so I sort them and take the highest. I use that as start, and """" as finish. This should give me one key back, but instead I get 10. Could it be that my columnfamily definition is different than yours? Here's mine:

      <ColumnFamily ColumnType=""Super""
                    CompareWith=""UTF8Type""
                    CompareSubcolumnsWith=""UTF8Type""
                    Name=""Super1""
                    RowsCached=""1000""
                    KeysCachedFraction=""0""
                    Comment=""A column family with supercolumns, whose column and subcolumn names are UTF8 strings""/>


In [17]: run test_bug_simple2.py
result1 before sorting
af37b718213b4219897ea1564ebc8900
f196ad5537294840b2de0a636202dbd2
7578ba38b66d4708a38663717e020959
b5266af926a647c3a1a4d2f62dfe952c
d729d5181bac42a48ac3e49d9700047e
4d58b6fbea214d0c9c7a9f288feba2d8
41df7aee7d674a75a4943d89153f9bde
4e121f95459e4f67a6cd3c06b2d078e7
99b2b03675a8413f94e60e3d1bbded8c
66121c5c863f4c1f804a46b8c2136fe9
result1 after sorting
41df7aee7d674a75a4943d89153f9bde
4d58b6fbea214d0c9c7a9f288feba2d8
4e121f95459e4f67a6cd3c06b2d078e7
66121c5c863f4c1f804a46b8c2136fe9
7578ba38b66d4708a38663717e020959
99b2b03675a8413f94e60e3d1bbded8c
af37b718213b4219897ea1564ebc8900
b5266af926a647c3a1a4d2f62dfe952c
d729d5181bac42a48ac3e49d9700047e
f196ad5537294840b2de0a636202dbd2
start f196ad5537294840b2de0a636202dbd2
result2
f196ad5537294840b2de0a636202dbd2
7578ba38b66d4708a38663717e020959
b5266af926a647c3a1a4d2f62dfe952c
d729d5181bac42a48ac3e49d9700047e
4d58b6fbea214d0c9c7a9f288feba2d8
41df7aee7d674a75a4943d89153f9bde
4e121f95459e4f67a6cd3c06b2d078e7
99b2b03675a8413f94e60e3d1bbded8c
66121c5c863f4c1f804a46b8c2136fe9
b8b290a864464271ad30df1bbab2f2b7
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)

/k/jack/bridge/test_bug_simple2.py in <module>()
     54 for r in result2: print r.key
     55 
---> 56 assert len(result2) == 1
     57 
     58 

AssertionError: 
WARNING: Failure executing file: <test_bug_simple2.py>

In [18]: 





import uuid

from thrift import Thrift
from thrift.transport import TTransport
from thrift.transport import TSocket
from thrift.protocol.TBinaryProtocol import TBinaryProtocolAccelerated
 
import sys
sys.path.insert(0,'/usr/local/cassandra/interface/thrift/gen-py')
 
from cassandra import Cassandra
from cassandra.ttypes import *
 
socket = TSocket.TSocket(""10.212.87.165"", 9160)
transport = TTransport.TBufferedTransport(socket)
protocol = TBinaryProtocol.TBinaryProtocolAccelerated(transport)
client = Cassandra.Client(protocol)
 
transport.open()
 
ks = ""Keyspace1""
cf = ""Super1""
path = ColumnPath(cf, ""foo"", ""is"")
value = ""cool""
    
for i in xrange(100):
    key = uuid.uuid4().hex
    client.insert(ks, key, path, value, 0, ConsistencyLevel.ONE)
 
parent = ColumnParent(column_family=cf)
slice_range = SliceRange(start=""key"", finish=""key"")
predicate = SlicePredicate(slice_range=slice_range)
 
result1 = client.get_range_slice(ks, parent, predicate, """", """", 10, ConsistencyLevel.ONE)
 
print ""result1 before sorting""
for r in result1: print r.key
 
def getkey(x): return x.key
 
print ""result1 after sorting""
result1 = map(getkey, result1)
result1.sort()
 
for r in result1: print r
 
start = result1[-1]
 
print ""start"", start
 
result2 = client.get_range_slice(ks, parent, predicate, start, """", 10, ConsistencyLevel.ONE)
 
print ""result2""
for r in result2: print r.key
 
assert len(result2) == 1


;;;","12/Feb/10 03:48;jbellis;If you're using RP instead of OPP you will see that.;;;","12/Feb/10 04:18;bjc;Ahh!! Right you are, I was using RP instead of OPP. Ok, but now here is another problem: if I insert 10 keys and then ask for them back, it works. However, if I insert 10 more and do a range scan with start="""", I don't get the lowest key:

In [17]: run test_bug_simple3.py
insert aa3cf33059d64dac8aef4a250bc5ea9c
insert a7dbda2925eb4b439c89cd71d56b5113
insert f28e92d5e5554857940c9d3386bf4121
insert 2b8ec460e7d346cbaf3dcb00e1aaaf91
insert 7792c98f0c3948299c622c73b906df66
insert 37a8bfdb69b642ba8e96d33b060f789d
insert 38c18f5d3d2c46cbb4e44b603a8acdbd
insert bef8104ea9184abaa3f0788ef7b2e0db
insert 934fe04d30cc4a96b1f1a9e7930316b8
insert 1d3413e88af946349f148c4fafeb6bf7
result 1d3413e88af946349f148c4fafeb6bf7
result 2b8ec460e7d346cbaf3dcb00e1aaaf91
result 37a8bfdb69b642ba8e96d33b060f789d
result 38c18f5d3d2c46cbb4e44b603a8acdbd
result 7792c98f0c3948299c622c73b906df66
result a7dbda2925eb4b439c89cd71d56b5113
result aa3cf33059d64dac8aef4a250bc5ea9c
result bef8104ea9184abaa3f0788ef7b2e0db
result f28e92d5e5554857940c9d3386bf4121
start f28e92d5e5554857940c9d3386bf4121
result f28e92d5e5554857940c9d3386bf4121

In [18]: run test_bug_simple3.py
insert 4eb0300540ec4b4083fbaf33741fc4a5
insert 12b43ba967314b369faff7e59902d6c2
insert 5b4b729676bc4ea2816620c3b6dff080
insert cf2fda1b11d843f1ae7949dbbb7d179d
insert c9d0cf4a1e9a48caa143afd2b0268f70
insert 9a044cff59b940d5bfbeffd58b01ee8e
insert d2ee042f0b0b4f7ea86e6e2c0dfdcfdd
insert d239aee577684c27afea2fe7e3361bdf
insert 706b20976f974de49bda61d55b9c2a63
insert 36177455bc3b4469b7e6f51897c9f3ba
result a7dbda2925eb4b439c89cd71d56b5113
result aa3cf33059d64dac8aef4a250bc5ea9c
result bef8104ea9184abaa3f0788ef7b2e0db
result c9d0cf4a1e9a48caa143afd2b0268f70
result cf2fda1b11d843f1ae7949dbbb7d179d
start cf2fda1b11d843f1ae7949dbbb7d179d
result cf2fda1b11d843f1ae7949dbbb7d179d
result d239aee577684c27afea2fe7e3361bdf
result d2ee042f0b0b4f7ea86e6e2c0dfdcfdd
result f28e92d5e5554857940c9d3386bf4121

In [19]: 


See what I mean? In the first run I inserted ""1d3413e88af946349f148c4fafeb6bf7"" but the second range scan I get ""a7dbda2925eb4b439c89cd71d56b5113"" back first, even when I set start="""". Could this somehow be my fault too?

Test follows:


import uuid

from thrift import Thrift
from thrift.transport import TTransport
from thrift.transport import TSocket
from thrift.protocol.TBinaryProtocol import TBinaryProtocolAccelerated

import sys
sys.path.insert(0,'/usr/local/cassandra/interface/thrift/gen-py')

from cassandra import Cassandra
from cassandra.ttypes import *

socket = TSocket.TSocket(""10.212.87.165"", 9160)
transport = TTransport.TBufferedTransport(socket)
protocol = TBinaryProtocol.TBinaryProtocolAccelerated(transport)
client = Cassandra.Client(protocol)

transport.open()

ks = ""Keyspace1""
cf = ""Super1""
path = ColumnPath(cf, ""foo"", ""is"")
value = ""cool""

for i in xrange(10):
    key = uuid.uuid4().hex
    print ""insert"", key
    client.insert(ks, key, path, value, 0, ConsistencyLevel.ONE)

parent = ColumnParent(column_family=cf)
slice_range = SliceRange(start=""key"", finish=""key"")
predicate = SlicePredicate(slice_range=slice_range)


result = client.get_range_slice(ks, parent, predicate, """", """", 5, ConsistencyLevel.ONE)
for row in result:
    print ""result"", row.key

start = result[-1].key

print ""start"", start

result = client.get_range_slice(ks, parent, predicate, start, """", 10, ConsistencyLevel.ONE)
for row in result:
    print ""result"", row.key

;;;","13/Feb/10 04:28;jbellis;Ah, yes, definitely reintroduced a bug in picking the range to start scanning in.  Fix attached.;;;","13/Feb/10 21:04;bjc;Some of the patches didn't apply, some problem as before? I checked out freshly just now. Can you post the individual files again? Thanks.. Or..maybe this is the problem: why does your most recently attached patch have a Wednesday time stamp on it? Here is what I get at the top:

commit 630c33353647f062134d66afa3b487d95abe03fe
Author: Jonathan Ellis <jonathan.ellis@rackspace.com>
Date:   Wed Feb 10 18:04:08 2010 -0600

    fix range queries

Shouldn't that be Friday? Here's the transcript:

$ svn checkout https://svn.apache.org/repos/asf/incubator/cassan
dra/trunk cassandra
A    cassandra/test
A    cassandra/test/unit
...
$ cd cassandra
$ wget https://issues.apache.org/jira/secure/attachment/12435762
/781.txt
--2010-02-13 20:57:49--  https://issues.apache.org/jira/secure/attachment/124357
62/781.txt
Resolving issues.apache.org... 140.211.11.140
Connecting to issues.apache.org|140.211.11.140|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 47140 (46K) [text/plain]
Saving to: `781.txt'

100%[======================================>] 47,140       120K/s   in 0.4s    

2010-02-13 20:57:50 (120 KB/s) - `781.txt' saved [47140/47140]

$ patch -p1 <781.txt 
patching file src/java/org/apache/cassandra/db/ColumnFamilyStore.java
patching file src/java/org/apache/cassandra/db/RangeSliceReply.java
patching file src/java/org/apache/cassandra/dht/AbstractBounds.java
Hunk #1 FAILED at 1.
Hunk #2 FAILED at 25.
2 out of 2 hunks FAILED -- saving rejects to file src/java/org/apache/cassandra/
dht/AbstractBounds.java.rej
patching file src/java/org/apache/cassandra/dht/Bounds.java
Hunk #1 FAILED at 1.
Hunk #2 FAILED at 8.
2 out of 2 hunks FAILED -- saving rejects to file src/java/org/apache/cassandra/
dht/Bounds.java.rej
patching file src/java/org/apache/cassandra/dht/Range.java
patching file src/java/org/apache/cassandra/service/RangeSliceResponseResolver.j
ava
patching file src/java/org/apache/cassandra/service/StorageProxy.java
patching file src/java/org/apache/cassandra/service/StorageService.java
patching file src/java/org/apache/cassandra/thrift/CassandraServer.java
patching file src/java/org/apache/cassandra/thrift/ThriftValidation.java
patching file test/system/test_server.py
patching file test/unit/org/apache/cassandra/dht/BoundsTest.java
patching file test/unit/org/apache/cassandra/dht/RangeIntersectionTest.java
patching file test/unit/org/apache/cassandra/dht/RangeTest.java
$

;;;","13/Feb/10 21:43;jbellis;re-attached w/ line endings fixed.  ;;;","14/Feb/10 00:12;bjc;Thanks for fixing the patch, but I'm sorry...it still doesn't work right.. :( I found a couple of weird things. First, sometimes when I ask for 10, it gives more. Second, if I pass start="""" it still doesn't start at the beginning. 

However, this doesn't happen every time I start fresh. Maybe it's depedent on the tokens. Here are the tokens for the case I show below: 

 INFO 23:38:21,989 Saved Token not found. Using 0njMRYmU9KiXE80d 
 INFO 23:38:20,112 Saved Token not found. Using I8LW8J6h9UCuz0dC 

The first token belongs to the node I am attaching the client to.

This functionality seems surprisingly complicated. Maybe it would help to write down pseudo-code for the way it should work? I have to admit that I cannot piece it together by reading the comments in your patch.

Here is a transcript and test: 

First run, looks ok: 

ip-10-212-87-165$ python test_bug_simple3.py 
insert 10b470f49a7c46bd938d784ca4096b63 
insert 47f70aacb3e94e10acaf8e86edac7169 
insert 9a3b7d3b921345bebc4f2bedc1db7c01 
insert c1c9dab59abd4f4ca33ee79f71a179e9 
insert cff81b145faf4648ac8ae001973c6c75 
insert c752d33e5d344312908e5008e6cdae3e 
insert 6e9e32e8b89845bb935d993a9c8bcb13 
insert c286bf2711bc45c1ab033561112c2313 
insert 2dad487ddfa94c81b52c8b4d35d3cb5c 
insert 9c62c7dafdb94dfdbdf52b527bdd2b24 

result 10b470f49a7c46bd938d784ca4096b63 
result 2dad487ddfa94c81b52c8b4d35d3cb5c 
result 47f70aacb3e94e10acaf8e86edac7169 
result 6e9e32e8b89845bb935d993a9c8bcb13 
result 9a3b7d3b921345bebc4f2bedc1db7c01 
result 9c62c7dafdb94dfdbdf52b527bdd2b24 
result c1c9dab59abd4f4ca33ee79f71a179e9 
result c286bf2711bc45c1ab033561112c2313 
result c752d33e5d344312908e5008e6cdae3e 
result cff81b145faf4648ac8ae001973c6c75 
total_keys 10 

Second run, get 18 keys when I asked for 10: 

ip-10-212-87-165$ python test_bug_simple3.py 
insert f873d662dccf46c28080a01286e09ed8 
insert 903776c2f45740389aa52675bf47c7ec 
insert 0e80401a9052405a898d11e5ae874a13 
insert 398d51ba174b4c9db8c25ca6cd2c9454 
insert 50f1cd47dd284ee9b9573b4dfce39134 
insert 20fa43d2365b4dfab9b05a93992315d0 
insert e009d5b76e8840b784fe6b9b649ae1df 
insert 63497f9d63c74b99a681fa2fc52751ac 
insert 824bbcf997de48a99cad174e9e1f1eec 
insert 01c5a6506f4247068660c20338a03bb3 

result 01c5a6506f4247068660c20338a03bb3 
result 0e80401a9052405a898d11e5ae874a13 
result 10b470f49a7c46bd938d784ca4096b63 
result 20fa43d2365b4dfab9b05a93992315d0 
result 2dad487ddfa94c81b52c8b4d35d3cb5c 
result 398d51ba174b4c9db8c25ca6cd2c9454 
result 47f70aacb3e94e10acaf8e86edac7169 
result 50f1cd47dd284ee9b9573b4dfce39134 
result 63497f9d63c74b99a681fa2fc52751ac 
result 6e9e32e8b89845bb935d993a9c8bcb13 
result 824bbcf997de48a99cad174e9e1f1eec 
result 903776c2f45740389aa52675bf47c7ec 
result c1c9dab59abd4f4ca33ee79f71a179e9 
result c286bf2711bc45c1ab033561112c2313 
result c752d33e5d344312908e5008e6cdae3e 
result cff81b145faf4648ac8ae001973c6c75 
result e009d5b76e8840b784fe6b9b649ae1df 
result f873d662dccf46c28080a01286e09ed8 
total_keys 18 

Third run, start at ""ca.."" even though I pass start="""" and all the previous keys remain: 

ip-10-212-87-165$ python test_bug_simple3.py 
insert ca97d7efb63448f8a62d6f7f73044236 
insert 91363a713b714af88ac2191caeea5351 
insert 7b6756d0ab8e450b826b1abc7210d524 
insert e6c6765497af4078b93e1a1470bd3194 
insert e3457f26754c4e7cb7ef606f98e7bb78 
insert 99643eb237ea4ca8b50cac4bb4d58edd 
insert ec3e1f81359b4ae08cfed73899934a93 
insert ae2b990ceb044bf194a879059f823ecf 
insert 2c1494f0ad3d48d2bf4feb33f40cf38e 
insert 0cb1c2e906b64fee89f7729052e0810e 

result ae2b990ceb044bf194a879059f823ecf 
result c1c9dab59abd4f4ca33ee79f71a179e9 
result c286bf2711bc45c1ab033561112c2313 
result c752d33e5d344312908e5008e6cdae3e 
result ca97d7efb63448f8a62d6f7f73044236 
result cff81b145faf4648ac8ae001973c6c75 
result e009d5b76e8840b784fe6b9b649ae1df 
result e3457f26754c4e7cb7ef606f98e7bb78 
result e6c6765497af4078b93e1a1470bd3194 
result ec3e1f81359b4ae08cfed73899934a93 
total_keys 10 
ip-10-212-87-165$ 

Here is another run (different tokens):

 INFO 00:04:17,105 Saved Token not found. Using Iw1khrAgM5sd6WnX
 INFO 00:04:15,795 Saved Token not found. Using IgLbq912n2xEP99G

In this case I don't see the problem where I get back more keys than I asked for, but I don't get the 10 lowest keys in the second request. 10 are returned, but they are not ordered consistently with what I know is in the db.

First run, notice key ""893.."" is inserted:

ip-10-212-87-165$ python test_bug_simple3.py 
insert 7be5d87bc45843cfaffd36fd654aee53
insert 8ef4727d83474570aa2111bee3929a5f
insert 9a9a91b6b662430092db0209d63a5c9e
insert e45afe1f0e364012acd0dead5b75ea13
insert 10171c87634842aea4f16d46d611c435
insert 10b6f92ac6a447088a82c4ec13056f1e
insert c1acbde9ae454ea2819322975322206b
insert 89352cf117dd4cb9ab935cbb5f230ba0
insert 0b5d924f04174459969594d6293b9aca
insert e2471db4d8f445f2b0c36f3b2a5bb650

result 0b5d924f04174459969594d6293b9aca
result 10171c87634842aea4f16d46d611c435
result 10b6f92ac6a447088a82c4ec13056f1e
result 7be5d87bc45843cfaffd36fd654aee53
result 89352cf117dd4cb9ab935cbb5f230ba0
result 8ef4727d83474570aa2111bee3929a5f
result 9a9a91b6b662430092db0209d63a5c9e
result c1acbde9ae454ea2819322975322206b
result e2471db4d8f445f2b0c36f3b2a5bb650
result e45afe1f0e364012acd0dead5b75ea13
total_keys 10

Second run, notice the results start with ""0.."" but ""893.."" is not returned (though ""b2.."" is, and other higher keys):

ip-10-212-87-165$ python test_bug_simple3.py 
insert 85d282dfa03a466eb51d03f4eb5dacd5
insert a61e7757eaed4ef79fc7bf35f47843f7
insert 9b9b6e3f22994827b0dddcc16105ff7d
insert 880b1644636845d8b1c92faf1f6d8484
insert 5d1d7d7b26ec4540a89c027bccc17e06
insert 4df05d38950f44b29df604c165e1148f
insert 0c9f818aa28a47fb832b6a0929b94280
insert 7e7b829c136046a88b120a4a373d9a6b
insert b2d497713f9342de85bb31b5c0e69af6
insert 80e250253f1942aaab2e9b49880918c0

result 0b5d924f04174459969594d6293b9aca
result 0c9f818aa28a47fb832b6a0929b94280
result 10171c87634842aea4f16d46d611c435
result 10b6f92ac6a447088a82c4ec13056f1e
result 4df05d38950f44b29df604c165e1148f
result a61e7757eaed4ef79fc7bf35f47843f7
result b2d497713f9342de85bb31b5c0e69af6
result c1acbde9ae454ea2819322975322206b
result e2471db4d8f445f2b0c36f3b2a5bb650
result e45afe1f0e364012acd0dead5b75ea13
total_keys 10
ip-10-212-87-165$ 

I found another issue with ""nodetool ring"" which might be related to the patch: 

$ sudo bin/nodetool -h localhost ring 
Exception in thread ""main"" java.lang.reflect.UndeclaredThrowableException 
        at $Proxy0.getRangeToEndPointMap(Unknown Source) 
        at org.apache.cassandra.tools.NodeProbe.getRangeToEndPointMap(NodeProbe.java:151) 
        at org.apache.cassandra.tools.NodeCmd.printRing(NodeCmd.java:74) 
        at org.apache.cassandra.tools.NodeCmd.main(NodeCmd.java:403) 
Caused by: java.rmi.UnmarshalException: error unmarshalling return; nested exception is: 
        java.io.WriteAbortedException: writing aborted; java.io.NotSerializableException: org.apache.cassandra.dht.OrderPreservingPartitioner 
        at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:173) 
        at com.sun.jmx.remote.internal.PRef.invoke(Unknown Source) 
        at javax.management.remote.rmi.RMIConnectionImpl_Stub.invoke(Unknown Source) 
        at javax.management.remote.rmi.RMIConnector$RemoteMBeanServerConnection.invoke(RMIConnector.java:993) 
        at javax.management.MBeanServerInvocationHandler.invoke(MBeanServerInvocationHandler.java:288) 
        ... 4 more 
Caused by: java.io.WriteAbortedException: writing aborted; java.io.NotSerializableException: org.apache.cassandra.dht.OrderPreservingPartitioner 
        at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1333) 
        at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) 
        at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871) 
        at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) 
        at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) 
        at java.io.ObjectInputStream.readObject(ObjectInputStream.java:351) 
        at java.util.HashMap.readObject(HashMap.java:1029) 
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) 
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) 
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) 
        at java.lang.reflect.Method.invoke(Method.java:597) 
        at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:974) 
        at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1849) 
        at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) 
        at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) 
        at java.io.ObjectInputStream.readObject(ObjectInputStream.java:351) 
        at sun.rmi.server.UnicastRef.unmarshalValue(UnicastRef.java:306) 
        at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:155) 
        ... 8 more 
Caused by: java.io.NotSerializableException: org.apache.cassandra.dht.OrderPreservingPartitioner 
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1156) 
        at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1509) 
        at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1474) 
        at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1392) 
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1150) 
        at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:326) 
        at java.util.HashMap.writeObject(HashMap.java:1000) 
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) 
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) 
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) 
        at java.lang.reflect.Method.invoke(Method.java:597) 
        at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:945) 
        at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1461) 
        at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1392) 
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1150) 
        at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:326) 
        at sun.rmi.server.UnicastRef.marshalValue(UnicastRef.java:274) 
        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:315) 
        at sun.rmi.transport.Transport$1.run(Transport.java:159) 
        at java.security.AccessController.doPrivileged(Native Method) 
        at sun.rmi.transport.Transport.serviceCall(Transport.java:155) 
        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535) 
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790) 
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649) 
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) 
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) 
        at java.lang.Thread.run(Thread.java:619) 
$ 


Here is the test I ran above: 

import uuid 

from thrift import Thrift 
from thrift.transport import TTransport 
from thrift.transport import TSocket 
from thrift.protocol.TBinaryProtocol import TBinaryProtocolAccelerated 

import sys 
sys.path.insert(0,'/usr/local/cassandra/interface/thrift/gen-py') 

from cassandra import Cassandra 
from cassandra.ttypes import * 

socket = TSocket.TSocket(""10.212.87.165"", 9160) 
transport = TTransport.TBufferedTransport(socket) 
protocol = TBinaryProtocol.TBinaryProtocolAccelerated(transport) 
client = Cassandra.Client(protocol) 

transport.open() 

ks = ""Keyspace1"" 
cf = ""Super1"" 
path = ColumnPath(cf, ""foo"", ""is"") 
value = ""cool"" 

for i in xrange(10): 
    key = uuid.uuid4().hex 
    print ""insert"", key 
    client.insert(ks, key, path, value, 0, ConsistencyLevel.ONE) 

print 

parent = ColumnParent(column_family=cf) 
slice_range = SliceRange(start=""key"", finish=""key"") 
predicate = SlicePredicate(slice_range=slice_range) 

total_keys = 0 

result = client.get_range_slice(ks, parent, predicate, """", """", 10, ConsistencyLevel.ONE) 
for row in result: 
    total_keys += 1 
    print ""result"", row.key 

print ""total_keys"", total_keys 


;;;","15/Feb/10 17:03;jbellis;Yes, it's more complicated than it looks. :)

Attached version fixes regression w/ result set size, and also start key when it falls into a wrapped node range.

There's also a ton of debug logging if you turn that on in log4j, btw.;;;","15/Feb/10 23:18;bjc;Victory!! I think this patch works. :)

One last possible issue: if I remove keys, then do a get_range_slice(), they still show up. A get() on a removed key will return a ""not found"" exception. Should get_range_slice() be aware of the removal? I'm guessing this is an issue about not properly processing the ""tombstone"".

Due to the complexity of get_range_slice(), maybe it's not worth processing the tombstone?;;;","16/Feb/10 01:38;jbellis;right, for get_range_slice we changed the contract from get_key_range -- it can't tell the difference between ""this row has other data, but not data in the columns you requested"" and ""this row has been deleted entirely"" w/o a relatively expensive query, so we decided to just return the slice as-is.;;;","16/Feb/10 02:48;jbellis;fix committed to trunk.  backport to 0.5 pending.;;;","17/Feb/10 17:54;hudson;Integrated in Cassandra #357 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/357/])
    ;;;","22/Feb/10 12:46;herchu;Is this fix going to be backported to 0.5? (any ETA?)
Thanks!;;;","22/Feb/10 13:08;jbellis;Yes, that's at the top of my list.  (I've been busy with PyCon.);;;","22/Feb/10 13:20;herchu;Great, thank you. The testcases for the current fix seem thorough, but if it helps I can do the testing with my own data as soon as a new patch is available.;;;","22/Feb/10 20:38;jbellis;attached backport of fix to 0.5.;;;","23/Feb/10 14:04;herchu;+1 to 781-backport.txt, it solved the problem in my cluster. Thank you!;;;","23/Feb/10 17:06;jbellis;committed to 0.5, thanks for testing.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bootstrapping is not threadsafe,CASSANDRA-779,12455685,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,08/Feb/10 21:21,16/Apr/19 09:33,14/Jul/23 05:51,08/Feb/10 21:55,0.6,,,,0,,,,,,"The bootstrapper thread (called from the main thread which has acquired the lock for SS via SS.init) currently makes a few calls into SS that require its lock.

Those methods need to be thread-safe, but do not need the same lock required by SS.init.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/10 21:25;gdusbabek;0001-fix-bootstrapping-deadlock.patch;https://issues.apache.org/jira/secure/attachment/12435205/0001-fix-bootstrapping-deadlock.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19860,,,Wed Feb 17 17:54:43 UTC 2010,,,,,,,,,,"0|i0g10v:",91596,,,,,Normal,,,,,,,,,,,,,,,,,"08/Feb/10 21:27;gdusbabek;This fixes the problem, but I don't see the point of having Bootstrapper launch a separate thread to make the file requests while SS.init waits for bootstrapping to finish.  Its work could mostly be replaced with a method in SS that calls into the static methods currently in Bootstrapper.;;;","08/Feb/10 21:34;jbellis;+1 on the patch.  I'm not sure what the point of having the separate BS thread is, either.  Maybe it made more sense a dozen refactors ago. :);;;","08/Feb/10 21:55;gdusbabek;r907816;;;","17/Feb/10 17:54;hudson;Integrated in Cassandra #357 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/357/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gossiper thread deadlock,CASSANDRA-778,12455667,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,gdusbabek,gdusbabek,08/Feb/10 18:49,16/Apr/19 09:33,14/Jul/23 05:51,08/Feb/10 19:39,0.6,,,,0,,,,,,"Found this while attempting to bootstrap a node with more than a trivial amount of data:

Found one Java-level deadlock:
=============================
""GMFD:1"":
  waiting to lock monitor 0x0000000100861d60 (object 0x00000001066a7ed8, a org.apache.cassandra.service.StorageService),
  which is held by ""main""
""main"":
  waiting to lock monitor 0x0000000100860710 (object 0x0000000106c7c968, a org.apache.cassandra.gms.Gossiper),
  which is held by ""GMFD:1""

Java stack information for the threads listed above:
===================================================
""GMFD:1"":
	at org.apache.cassandra.service.StorageService.getReplicationStrategy(StorageService.java:226)
	- waiting to lock <0x00000001066a7ed8> (a org.apache.cassandra.service.StorageService)
	at org.apache.cassandra.service.StorageService.calculatePendingRanges(StorageService.java:634)
	at org.apache.cassandra.service.StorageService.handleStateNormal(StorageService.java:502)
	at org.apache.cassandra.service.StorageService.onChange(StorageService.java:445)
	at org.apache.cassandra.service.StorageService.onJoin(StorageService.java:812)
	at org.apache.cassandra.gms.Gossiper.handleMajorStateChange(Gossiper.java:607)
	at org.apache.cassandra.gms.Gossiper.handleNewJoin(Gossiper.java:582)
	at org.apache.cassandra.gms.Gossiper.applyStateLocally(Gossiper.java:649)
	- locked <0x0000000106c7c968> (a org.apache.cassandra.gms.Gossiper)
	at org.apache.cassandra.gms.Gossiper$GossipDigestAck2VerbHandler.doVerb(Gossiper.java:1061)
	at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:40)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:637)
""main"":
	at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:861)
	- waiting to lock <0x0000000106c7c968> (a org.apache.cassandra.gms.Gossiper)
	at org.apache.cassandra.service.StorageService.startBootstrap(StorageService.java:347)
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:318)
	- locked <0x00000001066a7ed8> (a org.apache.cassandra.service.StorageService)
	at org.apache.cassandra.thrift.CassandraDaemon.setup(CassandraDaemon.java:99)
	at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:174)

Found 1 deadlock.

main acquires SS lock and doesn't release it before attempting to acquire the Gossiper lock.  Meanwhile, the gossip stage acquires the Gossiper lock and then attempts to acquire the SS lock.

Solution is to have finer-grained locking on the resource in SS (map of replication strategies), or to move the collection to a different class (DD maybe?).  This was introduced in CASSANDRA-620.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/10 19:18;gdusbabek;0001-fix-deadlock.patch;https://issues.apache.org/jira/secure/attachment/12435196/0001-fix-deadlock.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19859,,,Wed Feb 17 17:54:43 UTC 2010,,,,,,,,,,"0|i0g10n:",91595,,,,,Normal,,,,,,,,,,,,,,,,,"08/Feb/10 18:50;gdusbabek;introduce a fine-grained lock around SS.replicationStrategies.;;;","08/Feb/10 18:56;jbellis;Can we get rid of the manual locking entirely instead?  ISTM that either (a) instantiating all RS in the SS constructor or (b) using NBHM and the ConcurrentMap apis (putIfAbsent etc) would fix this.;;;","08/Feb/10 19:18;gdusbabek;does away with manual locking.;;;","08/Feb/10 19:23;jbellis;+1;;;","08/Feb/10 19:39;gdusbabek;r907771. 

Modified slightly so that it throws a RTE if a bogus table is given (to comply with unit tests).;;;","17/Feb/10 17:54;hudson;Integrated in Cassandra #357 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/357/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DeletingReferences not created for existing sstables on startup,CASSANDRA-772,12455525,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,stuhood,stuhood,stuhood,06/Feb/10 06:30,16/Apr/19 09:33,14/Jul/23 05:51,06/Feb/10 18:22,0.6,,,,0,,,,,,Trunk does not initialize SSTableTracker properly.,,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Feb/10 06:32;stuhood;772-remove-codepath.patch;https://issues.apache.org/jira/secure/attachment/12435066/772-remove-codepath.patch",,,,,,,,,,,,,,1.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19857,,,Wed Feb 17 17:54:42 UTC 2010,,,,,,,,,,"0|i0g0zb:",91589,,,,,Normal,,,,,,,,,,,,,,,,,"06/Feb/10 06:32;stuhood;Removes the ability to add tables using the constructor.;;;","06/Feb/10 18:22;jbellis;+1, committed.  good catch!;;;","17/Feb/10 17:54;hudson;Integrated in Cassandra #357 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/357/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JMX RowCache requests also include writes,CASSANDRA-770,12455490,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,brandon.williams,brandon.williams,05/Feb/10 20:30,16/Apr/19 09:33,14/Jul/23 05:51,05/Feb/10 20:59,0.6,,,,0,,,,,,"I have a CF that I only write to, unless I manually query it.  I have observed the RowCache request count increasing on this CF in line with my writes, but have never actually queried it.","debian lenny OpenJDK 64-Bit Server VM (build 1.6.0_0-b11, mixed mode)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Feb/10 20:38;jbellis;770.txt;https://issues.apache.org/jira/secure/attachment/12435007/770.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19856,,,Wed Feb 17 17:54:42 UTC 2010,,,,,,,,,,"0|i0g0yv:",91587,,,,,Low,,,,,,,,,,,,,,,,,"05/Feb/10 20:55;brandon.williams;+1, no longer increases due to writes.;;;","05/Feb/10 20:59;jbellis;committed;;;","17/Feb/10 17:54;hudson;Integrated in Cassandra #357 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/357/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SSTableExport can not accept -f , -k options",CASSANDRA-766,12455377,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,santal,santal,05/Feb/10 01:43,16/Apr/19 09:33,14/Jul/23 05:51,10/Feb/10 19:50,0.6,,Legacy/Tools,,0,,,,,,"the SSTableExport command can not accept -f , -k options correct, always said as bellow:

[root@hfdevcasda01 bin]# ./sstable2json -f out.json /opt/cassandra-wbx/data/CONTENT_HF/ChangeHistory-2-Data.db
You must supply exactly one sstable
Usage: org.apache.cassandra.tools.SSTableExport [-f outfile] <sstable> [-k key [-k key [...]]]",Linux,,,,,,,,,,60,60,,0%,60,60,,,,,,,,,,,,,,"10/Feb/10 19:09;jbellis;766-v2.txt;https://issues.apache.org/jira/secure/attachment/12435475/766-v2.txt","10/Feb/10 17:45;jbellis;766.txt;https://issues.apache.org/jira/secure/attachment/12435471/766.txt","05/Feb/10 01:51;santal;issue766.patch;https://issues.apache.org/jira/secure/attachment/12434916/issue766.patch",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19855,,,Wed Feb 17 17:54:46 UTC 2010,,,,,,,,,,"0|i0g0xz:",91583,,,,,Low,,,,,,,,,,,,,,,,,"05/Feb/10 01:44;santal;just remove one extra line will resolve this problem.;;;","05/Feb/10 01:46;santal;patch submit;;;","05/Feb/10 01:51;santal;my bad, create a wrong patch file;;;","10/Feb/10 17:45;jbellis;-f was supposed to be removed but I did it poorly.  this patch finishes the job and uses log4j of WARN,stderr for bin/ tools so that doesn't get in the way of redirecting stdout.;;;","10/Feb/10 19:09;jbellis;v2 now with log4j-tools goodness;;;","10/Feb/10 19:31;urandom;+1;;;","10/Feb/10 19:50;jbellis;committed;;;","17/Feb/10 17:54;hudson;Integrated in Cassandra #357 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/357/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
getRangeSlice returns keys from outside the desired range,CASSANDRA-763,12455276,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,04/Feb/10 06:35,16/Apr/19 09:33,14/Jul/23 05:51,06/Feb/10 04:14,0.6,,,,0,,,,,,,,stuhood,,,,,,,,,,,,,,,,,,CASSANDRA-342,,,,,,,,,,"05/Feb/10 20:05;jbellis;ASF.LICENSE.NOT.GRANTED--0001-add-Range.intersectsWith.txt;https://issues.apache.org/jira/secure/attachment/12435000/ASF.LICENSE.NOT.GRANTED--0001-add-Range.intersectsWith.txt","05/Feb/10 20:05;jbellis;ASF.LICENSE.NOT.GRANTED--0002-have-RangeSliceCommand-take-Range-or-Bounds-client-bou.txt;https://issues.apache.org/jira/secure/attachment/12435001/ASF.LICENSE.NOT.GRANTED--0002-have-RangeSliceCommand-take-Range-or-Bounds-client-bou.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19854,,,Wed Feb 17 17:54:46 UTC 2010,,,,,,,,,,"0|i0g0xb:",91580,,,,,Normal,,,,,,,,,,,,,,,,,"05/Feb/10 20:04;jbellis;the semantics of client start/end keys passed to get_range_slice and the tokens in a Range object are different.  CASSANDRA-759 and CASSANDRA-758 tried to add options to getRangeSlice to be able to handle both but the two are still too different.  consider for instance the case where start=end -- in the former case this is a range with exactly one (potential) key included; in the latter it is a wrapping range including the entire ring.

this partially backs out 758 and 759 and instead adds a Bounds class (that shares a common superclass w/ Range); getRangeSlice can then take either a Bounds (which has the semantics of the old start/end pair) or a Range, which is the case CASSANDRA-342 is interested in, and can now use intersectsWith to make sure we're only getting each key once.;;;","05/Feb/10 21:21;stuhood; * Are we trying not to break network compatibility in 0.6? This changes RangeSliceCommand
 * I'm worried that since the AbstractBounds class doesn't implement any methods, we are basically using the subclasses as boolean values: ('is the start included?' == x instanceof Bounds). To make the subclasses worthwhile, we need to see a path toward actually encapsulating the intersection logic in them: for instance, StorageProxy.restrictBounds should be implemented in terms of an intersection between two AbstractBounds objects.

In general, this looks like an improvement, so if we can see a way in the future to encapsulate more logic in bounds, I'd be fine with giving it a +1.;;;","05/Feb/10 21:43;jbellis;> Are we trying not to break network compatibility in 0.6

Nope, glad you are thinking about that but we already moved gossip to TCP which means no.  (Seems like a long time ago but yes that will be 0.6 :)

> we need to see a path toward actually encapsulating the intersection logic in them: for instance

You're right.  I will make that change.;;;","06/Feb/10 04:14;jbellis;committed w/ above changes;;;","17/Feb/10 17:54;hudson;Integrated in Cassandra #357 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/357/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Load balancing does not account for the load of the moving node,CASSANDRA-762,12455243,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,stuhood,stuhood,stuhood,03/Feb/10 23:20,16/Apr/19 09:33,14/Jul/23 05:51,10/Feb/10 02:15,0.5,,,,1,,,,,,"Given a node A (with load 10 gb) and a node B (with load 20 gb), running the loadbalance command against node A will:
1. Remove node A from the ring
  * Recalculates pending ranges so that node B is responsible for the entire ring
2. Pick the most loaded node
  * node B is still reporting 20 gb load, because that is all it has locally
3. Choose a token that divides the range of the most loaded node in half

Since the token calculation doesn't take into account the load that node B is 'inheriting' from node A, the token will divide node B's load in half and swap the loads. Instead, the token calculation needs to pretend that B has already inherited the 10 gb from node A, for a total of 30 gb. The token that should be chosen falls at 15 gb of the total load, or 5 gb into node B's load.",,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/10 00:09;stuhood;0001-Wait-BROADCAST_INTERVAL-for-load-information-and-cal.patch;https://issues.apache.org/jira/secure/attachment/12435142/0001-Wait-BROADCAST_INTERVAL-for-load-information-and-cal.patch","08/Feb/10 00:58;stuhood;for-0.5-0001-Wait-BROADCAST_INTERVAL-for-load-information-and-cal.patch;https://issues.apache.org/jira/secure/attachment/12435144/for-0.5-0001-Wait-BROADCAST_INTERVAL-for-load-information-and-cal.patch",,,,,,,,,,,,,2.0,stuhood,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,18550,,,Wed Feb 10 02:15:24 UTC 2010,,,,,,,,,,"0|i0g0x3:",91579,,,,,Low,,,,,,,,,,,,,,,,,"04/Feb/10 19:26;jbellis;As I said in IRC, a loadbalancing node doesn't compute its destination token until after all its data has been transferred off.  (We *should* add a sleep until load is rebroadcast, but that will only affect which node gets picked to pull half the range from.)  So if there is a bug here it is in the code, not the algorithm.

Can you reproduce this?;;;","08/Feb/10 00:09;stuhood;This patch waits for load information after leaving the ring, and lowers the BROADCAST_INTERVAL to .9 of RING_DELAY.;;;","08/Feb/10 00:58;stuhood;Here is a rebased copy of the patch for 0.5. Because 0.5 is still stat'ing files, it doesn't lower the BROADCAST_INTERVAL, although we may want to.;;;","08/Feb/10 16:12;jbellis;did you test on 0.5?;;;","08/Feb/10 16:49;stuhood;Yes, I tested on trunk and 0.5;;;","08/Feb/10 18:02;jbellis;looking at 0.5 patch:

patch does not build.  (looks like the Gossiper diff made it in by mistake.)

the load wait should probably be for BROADCAST_INTERVAL + RING_DELAY.
;;;","09/Feb/10 06:04;stuhood;Hmm... I just verified that 'for-0.5-0001...' applies cleanly to the cassandra-0.5 branch at git revision 4331781362a16e8ea444fdf478c8c63882af7bb3. There isn't anything related to gossip in that patch.

Also, the patch for trunk applies (with some offsets), and also doesn't contain anything related to gossip.;;;","09/Feb/10 23:37;jbellis;committed to 0.5 w/ my suggested change to sleep duration.

working on committing to trunk but asf svn seems to be dead in the water atm.;;;","10/Feb/10 02:15;jbellis;got the merge to trunk done.  chickened out a bit and set the broadcast period to 60s to be conservative.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Binary Memtable does not invalidate cache,CASSANDRA-761,12455240,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,lenn0x,lenn0x,03/Feb/10 23:00,16/Apr/19 09:33,14/Jul/23 05:51,10/Mar/10 17:42,0.6,,,,0,,,,,,"If you have RowCache turned on for your CF, and you do a BMT import, rows are not invalidated in cache until you restart the node.",,johanoskarsson,lenn0x,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Feb/10 21:39;jbellis;761-v2.txt;https://issues.apache.org/jira/secure/attachment/12436765/761-v2.txt","03/Feb/10 23:17;jbellis;761.txt;https://issues.apache.org/jira/secure/attachment/12434726/761.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19853,,,Wed Mar 10 17:42:41 UTC 2010,,,,,,,,,,"0|i0g0wv:",91578,,,,,Normal,,,,,,,,,,,,,,,,,"04/Feb/10 06:44;jbellis;... cache invalidation at BMT insertion time as shown in this patch actually won't work; a read could still pull the old version into the cache again, since BMT contents are not ""live"" to readers.

you'll need to add ""nodetool invalidate"" instead.;;;","13/Feb/10 22:34;tzz;Could this be related to what I saw in CASSANDRA-764, where the row cache needs to be flushed before a bitmask query will work?  Seems like a similar issue and my fix is similar (except my fix takes the shotgun approach of invalidating the whole cache).;;;","21/Feb/10 12:18;jbellis;should probably get at least the JMX stub in 0.6.0; then the nodeprobe update can be 0.6.1 if needed;;;","23/Feb/10 21:39;jbellis;jmx invalidator attached;;;","25/Feb/10 17:11;lenn0x;+1;;;","01/Mar/10 21:31;jbellis;rebased & committed to 0.6 and trunk;;;","10/Mar/10 17:42;jbellis;Resolving as Fixed.  If someone wants to add this to nodetool, let's do that in another issue.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FatClient removal causes ConcurrentModificationException,CASSANDRA-757,12455173,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,brandon.williams,brandon.williams,brandon.williams,03/Feb/10 13:33,16/Apr/19 09:33,14/Jul/23 05:51,27/Apr/10 18:36,0.7 beta 1,,,,0,,,,,,"After using a fatclient and killing it, I later receive this ST on all nodes:

 INFO 16:04:58,999 FatClient /10.242.4.13 has been silent for 3600000ms, removing from gossip
ERROR 16:04:58,999 Fatal exception in thread Thread[Timer-1,5,main]
java.lang.RuntimeException: java.util.ConcurrentModificationException
        at org.apache.cassandra.gms.Gossiper$GossipTimerTask.run(Gossiper.java:96)
        at java.util.TimerThread.mainLoop(Timer.java:534)
        at java.util.TimerThread.run(Timer.java:484)
Caused by: java.util.ConcurrentModificationException
        at java.util.Hashtable$Enumerator.next(Hashtable.java:1048)
        at org.apache.cassandra.gms.Gossiper.doStatusCheck(Gossiper.java:382)
        at org.apache.cassandra.gms.Gossiper$GossipTimerTask.run(Gossiper.java:90)
        ... 2 more
","debian lenny amd64 OpenJDK 64-Bit Server VM (build 1.6.0_0-b11, mixed mode)
",brandon.williams,johanoskarsson,kingryan,mojodna,wadey,,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/10 19:52;brandon.williams;0001_use_concurrent_structures.txt;https://issues.apache.org/jira/secure/attachment/12442616/0001_use_concurrent_structures.txt",,,,,,,,,,,,,,1.0,brandon.williams,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19852,,,Fri Jul 16 20:40:55 UTC 2010,,,,,,,,,,"0|i0g0vz:",91574,,,,,Low,,,,,,,,,,,,,,,,,"04/Feb/10 19:20;jbellis;The good news is this looks like a pretty harmless heisenbug -- eventually (usually the next timer iteration) no changes will be made to the map during iteration and it will work.;;;","08/Mar/10 22:47;brandon.williams;Patch to avoid concurrent modification.;;;","08/Mar/10 22:53;jbellis;were you able to reproduce before, and not w/ this patch?  because AFAIK using an iterator manually instead of a foreach only helps when the CME is from modifying the collection in the same loop, and you can replace that w/ iter.remove().  otherwise if the CME is happening from another thread modifying stuff you have to move to a Concurrent collection.;;;","08/Mar/10 23:19;jbellis;i think what needs to happen is take all the structures in Gossiper and make them Concurrent equivalents, encapsulate any places where we're returning them to other objects directly, and audit the rest for correctness, because the original author basically ignored threadsafety entirely;;;","19/Apr/10 21:25;brandon.williams;Patch to use concurrent structures and remove synchronization  in the Gossiper.;;;","22/Apr/10 15:08;jbellis;Jaakko hasn't replied so I'll take a stab at reviewing.

Can you rebase?  2 hunks are failing in Gossiper for me.;;;","22/Apr/10 19:52;brandon.williams;Updated w/rebased patch.;;;","27/Apr/10 18:36;jbellis;committed.  also inlined the comparator, replaced the last synchronized methods in EndpointState w/ volatile fields, and removed getSortedApplicationStates.;;;","16/Jul/10 20:35;wadey;This is a more serious bug than originally thought due to CASSANDRA-1289. When this exception gets thrown, it causes GossipTimerTask to stop running until the server is restarted. Because of this, I would recommend a backport to 0.6.x (I'll offer to do the backport as well). ;;;","16/Jul/10 20:40;jbellis;backporting this to 0.6 doesn't work for me, but a hack to log exceptions would be ok.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
avoid setting up completion handler for no-op stream in non-bootstrap mode,CASSANDRA-750,12447060,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,29/Jan/10 23:05,16/Apr/19 09:33,14/Jul/23 05:51,29/Jan/10 23:47,0.5,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jan/10 23:06;jbellis;750.txt;https://issues.apache.org/jira/secure/attachment/12431835/750.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19850,,,Fri Jan 29 23:47:33 UTC 2010,,,,,,,,,,"0|i0g0uf:",91567,,,,,Low,,,,,,,,,,,,,,,,,"29/Jan/10 23:08;gdusbabek;+1;;;","29/Jan/10 23:47;jbellis;committed to 0.5 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[multi_]get_count should take a SlicePredicate,CASSANDRA-744,12446705,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,slebresne,jbellis,jbellis,26/Jan/10 17:53,16/Apr/19 09:33,14/Jul/23 05:51,20/Apr/10 14:53,0.7 beta 1,,,,0,,,,,,"both to make it more flexible, and to emphasize that counting ""everything"" is as bad as slicing it",,bendiken,hammer,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Apr/10 14:55;slebresne;ASF.LICENSE.NOT.GRANTED--0001-Add-SlicePredicate-to-get_count.patch;https://issues.apache.org/jira/secure/attachment/12442050/ASF.LICENSE.NOT.GRANTED--0001-Add-SlicePredicate-to-get_count.patch","17/Apr/10 14:55;slebresne;ASF.LICENSE.NOT.GRANTED--0002-Add-mutliget_count.patch;https://issues.apache.org/jira/secure/attachment/12442051/ASF.LICENSE.NOT.GRANTED--0002-Add-mutliget_count.patch",,,,,,,,,,,,,2.0,slebresne,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19849,,,Tue May 11 10:25:57 UTC 2010,,,,,,,,,,"0|i0g0t3:",91561,,,,,Low,,,,,,,,,,,,,,,,,"17/Apr/10 14:55;slebresne;Got some time to kill, so I'm proposing two (quite trivial) patches.
First one add the SlicePredicate to get_count, second one add
a multiget_count.;;;","20/Apr/10 14:49;gdusbabek;+1;;;","20/Apr/10 14:53;gdusbabek;committed.  Thanks Sylvain!;;;","08/May/10 23:10;bendiken;Would it be possible to specify multiget_count in terms of i64 return values instead of i32, pretty please?;;;","09/May/10 00:19;jbellis;that's a little silly, isn't it?  surely counting over 2B columns isn't a good idea in the first place...;;;","10/May/10 20:43;bendiken;Is it? I apologize if I have too high expectations for Cassandra, but we've already used rows with up to one hundred million columns. Problems at that scale have been mostly GC churn and compaction related, and since it appears that such issues are being worked on (CASSANDRA-1014, CASSANDRA-16, and the like), a mere one order of magnitude more doesn't seem like *too* much of a stretch for Cassandra to eventually handle on sufficiently big iron.;;;","11/May/10 08:56;slebresne;That's not really the problem of having row with more than MAX_INTEGER columns. What is silly
is counting those. Counting all the columns in a row is the same than reading the whole row. Excepted
that you don't send all those columns over the network. So a call to count will never need a i64 as any 
call that would need an i64 will very likely timeout. 
That's the ""raison d'être"" of this patch. You can count a huge row by paging (but it's probably a better
idea to not count those huge row at all if you can afford it as even with paging this is expensive).;;;","11/May/10 09:54;bendiken;I guess it depends on your use case. We have one where each Cassandra row represents a very large set, each column name being a 20-byte SHA-1 binary hash identifying an object in that set and each such column's value being simply the empty string. As I mentioned, we've stored up to a hundred million columns per row in this manner. As each SHA-1 column takes 35.5 bytes of space in the SStables, that's a total of less than 4 gigs of disk storage for a row with 100 million columns. On the big iron we've run this on, these are not _inherently_ infeasible numbers. The limiting factor is Cassandra's implementation, not the hardware.

Counting the number of objects in a given set (i.e. the number of columns in a given row) is an important operation for us. It's fine for the count to take a while, as it is still vastly (many, many orders of magnitude) faster than the infeasible alternative of directly counting the source data (also stored in Cassandra, but apart) that the set data is derived from, which would (prior to your multi_get_count patch, which does alleviate it a little) involve performing an individual get_count operation for each of hundreds of millions (soon to be billions) of distinct source rows.

Now, given existing GC and SStable compaction issues that we've run into with Cassandra 0.6, we're in practice now manually sharding the larger sets into multiple rows of a size that Cassandra has less issues dealing with (on our hardware, up to 15-20 million columns per row is performing very well).

t expect that as Cassandra evolves and issues are fixed, we can keep upping this, and I don't see anything inherently ridiculous about rows of the size I've mentioned. It seems a little shortsighted to place incidental limits on the protocol, but then again I suppose the protocol will have broken backwards compatibility a couple of times by the time I get around to testing 2 billion columns with some future Cassandra 1.x version - so perhaps we can revisit this in a year or two ;-)
;;;","11/May/10 10:25;slebresne;But then again, I do not even contest the fact that it could be useful to have row with billions of columns. As you mentioned, 
there is a few limitations to that today but they will hopefully be lifted soon enough. I still think that, despite these current limitations,  
the sharding  of the row you already do is useful at some point (but maybe this point is 1 billion columns in your case) if only for the 
sake of load distribution. But that's not my point at all.

My point is that the time it takes to perform one given individual get_count() operation that count n columns is as long as the time it takes 
to read those n columns (from server-side at least, the only advantage of get_count() over get_slice() is that you don't send those n columns 
over the network). So, if n > 2 billion, it will takes a bit of time to perform this one get_count() operation, even in a year or two, even with
super duper SSD drives and even if each column is quite small. I haven't tried (I don't have a super duper SSD drive and I don't live one 
or two year from now) and it's always dangerous to make assumption in the future, but I bet it will take far time than any reasonable 
timeout you would want to set for your Cassandra operations. 

Hence, the right way to count a row with 2 billions+ columns is to do multiple get_count() operations using a predicate to limit the number 
of counted columns by each individual get_count() operation and sum all those results client side. But then only the sum needs be a 64 bit 
integer, not the result of get_count().   ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
multiget returns empty ColumnOrSuperColumn instead of null,CASSANDRA-739,12446636,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,26/Jan/10 05:03,16/Apr/19 09:33,14/Jul/23 05:51,27/Apr/10 22:13,0.7 beta 1,,,,0,,,,,,"the later is more intuitive, and the former violates the rule that COSC should have exactly one of {column, super_column} set.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Apr/10 21:26;jbellis;739-rebased.txt;https://issues.apache.org/jira/secure/attachment/12443004/739-rebased.txt","26/Apr/10 15:42;jbellis;739.txt;https://issues.apache.org/jira/secure/attachment/12442861/739.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19847,,,Tue Apr 27 22:13:01 UTC 2010,,,,,,,,,,"0|i0g0rz:",91556,,,,,Low,,,,,,,,,,,,,,,,,"26/Apr/10 15:42;jbellis;simplest solution: remove the deprecated multiget method.  (as opposed to multiget_slices, which doesn't have this problem.)

bumped thrift major version to 5.0.0.;;;","27/Apr/10 21:49;brandon.williams;+1;;;","27/Apr/10 22:13;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cli parsing error,CASSANDRA-738,12446624,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,urandom,johanhil,johanhil,26/Jan/10 01:21,16/Apr/19 09:33,14/Jul/23 05:51,24/Feb/10 16:39,0.6,,Legacy/Tools,,1,,,,,,"Steps to reproduce:
1. Download the 0.5 release
2. Start Cassandra
3. Start cassandra-cli
4. Execute ""set foo.bar['toot']='balls'""

Expected output:
An error message telling me I'm not doing it right.

Actual output:
cassandra> set foo.bar['toot']='balls'
Exception in thread ""main"" java.lang.AssertionError: serious parsing error (this is a bug).
	at org.apache.cassandra.cli.CliClient.executeSet(CliClient.java:367)
	at org.apache.cassandra.cli.CliClient.executeCLIStmt(CliClient.java:63)
	at org.apache.cassandra.cli.CliMain.processCLIStmt(CliMain.java:131)
	at org.apache.cassandra.cli.CliMain.main(CliMain.java:172)

Perhaps this is related to https://issues.apache.org/jira/browse/CASSANDRA-615 in a non-direct way.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Feb/10 01:36;urandom;ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-738-cli-friendlier-error-messages.txt;https://issues.apache.org/jira/secure/attachment/12436796/ASF.LICENSE.NOT.GRANTED--v1-0001-CASSANDRA-738-cli-friendlier-error-messages.txt",,,,,,,,,,,,,,1.0,urandom,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19846,,,Wed Feb 24 16:39:00 UTC 2010,,,,,,,,,,"0|i0g0rr:",91555,,,,,Low,,,,,,,,,,,,,,,,,"20/Feb/10 18:32;jab_doa;I experienced exactly the same problem. Setup as described in http://wiki.apache.org/cassandra/GettingStarted.;;;","24/Feb/10 03:28;jbellis;+1 Eric's fixes;;;","24/Feb/10 16:39;urandom;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Streaming code relies on sockets being bound to the correct address (InetAddress.anyLocalAddress() is bad),CASSANDRA-737,12446594,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,gdusbabek,gdusbabek,25/Jan/10 19:46,16/Apr/19 09:33,14/Jul/23 05:51,25/Jan/10 21:26,0.6,,,,0,,,,,,"I came across this while testing streaming locally.  The new streaming code makes use of the remote socket address supplied by the socket.  This means that it will return whatever address the socket is bound to, which is not necessarily the address configured for cassandra.  This confuses StreamContextManager when data comes streaming in from addresses that it doesn't recognize.

Two solutions will work.
1. bind outgoing sockets to the correct interface.
2. Include the local address in StreamContexts that get sent.

I opted for 1 since it required less code.  2 was easy enough but would have required changing the format of the message to make the source address more easily accessible (the constructor for IncomingStreamReader wants to know the source host to create the stream context at the destination).",Mac OS X.,,,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-620,,,,"25/Jan/10 20:52;gdusbabek;0001-bind-sockets-locally-to-cassandra-specified-address.patch;https://issues.apache.org/jira/secure/attachment/12431355/0001-bind-sockets-locally-to-cassandra-specified-address.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19845,,,Mon Jan 25 21:26:59 UTC 2010,,,,,,,,,,"0|i0g0rj:",91554,,,,,Low,,,,,,,,,,,,,,,,,"25/Jan/10 19:54;gdusbabek;I think I caught all the socket creation places.;;;","25/Jan/10 19:55;jbellis;does this affect 0.5 too?;;;","25/Jan/10 20:01;gdusbabek;No. This came in at the same time as IncomingStreamReader.  Before that, I don't think we relied on the remote address of a socket being the address specified in the config.  It hadn't mattered.;;;","25/Jan/10 20:45;jbellis;is your working copy up to date?  the patch to OutboundTcpConnection.java fails to apply for me;;;","25/Jan/10 20:52;gdusbabek;The last patch was Intellij generated.  Here is a git-generated patch.;;;","25/Jan/10 20:59;jbellis;+1 (damn intellij, it's not like patch format hasn't been standard for years);;;","25/Jan/10 21:26;gdusbabek;r902981;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Table.open has a broken lock in it,CASSANDRA-734,12446409,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jmhodges,jmhodges,23/Jan/10 03:52,16/Apr/19 09:33,14/Jul/23 05:51,25/Jan/10 16:55,0.5,,,,0,,,,,,Table.open's lock is used around the Map#put method call but not the #get. This makes it a source of spurious bugs. The attached patch synchronizes the entire Table.open method and removes the unused createLock static.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jan/10 03:12;jbellis;734-nbhm.txt;https://issues.apache.org/jira/secure/attachment/12431272/734-nbhm.txt","23/Jan/10 03:53;jmhodges;broken_lock_in_table_open.patch;https://issues.apache.org/jira/secure/attachment/12431190/broken_lock_in_table_open.patch",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19843,,,Mon Jan 25 16:55:41 UTC 2010,,,,,,,,,,"0|i0g0qv:",91551,,,,,Low,,,,,,,,,,,,,,,,,"23/Jan/10 04:38;jbellis;I don't think introducing full synchronized lock into a method called for basically every operation is a good idea.  We could use nonblockinghashmap for the container instead, which would take care of the get problem.  (we could just use NBHM with putIfAbsent if Table creation weren't something we want to avoid doing twice for the same keyspace in case of a race.)  what do Real Java Programmers do for ""singleton cache?"";;;","24/Jan/10 10:50;jmhodges;To start with, synchronization being slow is mostly a scary story left around from the bad old days of Java 1.3 and lower. http://www.ibm.com/developerworks/java/library/j-jtp04223.html

Second, any thing we build instead of using synchronized will be nearly exactly duplicating synchronized's behavior except broken and slower. There seems to be nothing that compiles down to just ""lock around this get and, if that's null, create this other thing and then put it in there"" in Java bytecode. The only other way to make this work is load all the tables at boot time. Which, of course, is a non-starter. However, synchronized does say ""all this work has to be done together"" which fixes our bug and has years of JVM hackers behind it making it as fast as possible. 

Third, we should be aiming as much for correctness as we can. A Cassandra node is eventually consistent, but its codebase is not. Fixing a bug that will, eventually, kick Twitter and Digg and Rackspace's ass now is better than holding off until a ""faster"" way can be found in some possible future where unicorns live and candy mountains are not just scary things in creepy guys basements.

synchronized does a bang up job of fixing this bug now and doing so in a way that is more performant than other ""correct"" ways.

After this patch goes in, we should be re-evaluate all of these calls to Table.open(), though. I'm going to bet that in most cases it would make more sense for the client object to hold on to a reference to the Table if they need it and not let go every time like they do currently after the Table.open() call goes out of scope.

Edited for a friggin' ""it's"" grammar problem.;;;","24/Jan/10 12:54;gdusbabek;> The only other way to make this work is load all the tables at boot time.
See CassandraDaemon.setup().

Why not this:
1.  Create a synchronized initTables() method that is called from CD, that sets an initDone flag and blows up it is ever called again.
2.  Take the locking  and synchronicity out of Table.open() (there really is no point as long as the backing collection is unmodifiable), and turn it into a purely 'getter'-type method.;;;","24/Jan/10 19:00;jmhodges;Sweet. I hadn't seen that call to  Table.getAllTableNames() in CD.setup(). If the laziness constraint can be relaxed, that's fine by me! I'll write up a patch.;;;","24/Jan/10 19:11;jbellis;> synchronization being slow is mostly a scary story left around from the bad old days of Java 1.3 and lower

That's true for _uncontested_ syncs but that is not what we have here.  The JVM isn't going to be able to optimize those away, and it's going to be several orders of magnitude slower than w/o the sync.

> any thing we build instead of using synchronized will be nearly exactly duplicating synchronized's behavior except broken and slower

NBHM is lock-free (which actually means it uses lower-level CAS which is much cheaper).

> we should be aiming as much for correctness as we can

I never said otherwise.  But let's do it without causing unnecessary performance regressions.
;;;","24/Jan/10 19:14;jbellis;> Take the locking and synchronicity out of Table.open() 

wouldn't we just have to undo that for CASSANDRA-44?;;;","24/Jan/10 20:17;jmhodges;bq. NBHM is lock-free (which actually means it uses lower-level CAS which is much cheaper). 

How does a NBHM solve the problem get-and-then-put-but-only-instantiate-the-object-at-all-if-get-is-null? I haven't seen any docs on get with conditional set and conditional instantiation.


bq. wouldn't we just have to undo that for CASSANDRA-44?

Not if we do the initTable work, and then later turn it in a NBHM. With initTable in place, and we go to update a Table, we would only have to do a put without the conditional instantiation.;;;","24/Jan/10 20:43;jmhodges;bq. Not if we do the initTable work, and then later turn it in a NBHM. With initTable in place, and we go to update a Table, we would only have to do a put without the conditional instantiation.

(And it seems to me that if it's possible to construct a Table in more than one thread in our solution to CASSANDRA-44, we're very likely solving CASSANDRA-44 wrong.);;;","25/Jan/10 01:15;jbellis;> How does a NBHM solve the problem get-and-then-put-but-only-instantiate-the-object-at-all-if-get-is-null?

It doesn't: it solves the problem of doing get() on a thread-unsafe object while remaining high performance.  I'm saying, we can use Table.open in close to its current form by replacing the current HashMap w/ a NBHM, and continuing to use a synchronized block for if the get() is null.

> Not if we do the initTable work, and then later turn it in a NBHM.

True enough, but is that then really simpler than just fixing Table.open?;;;","25/Jan/10 02:54;jmhodges;bq. It doesn't: it solves the problem of doing get() on a thread-unsafe object while remaining high performance. I'm saying, we can use Table.open in close to its current form by replacing the current HashMap w/ a NBHM, and continuing to use a synchronized block for if the get() is null. 

You've forgotten about instantiating the Table twice. One thread notices that the get is null and in another thread the same happens before the first thread manages to do a put.;;;","25/Jan/10 03:12;jbellis;that's why you have to do the second check once you synchronize.  it's a double-checked locking variant, using NBHM to provide thread safety on the initial get() [like you would with volatile, in standard non-broken DCL]

patch attached since i'm clearly not explaining this very well :);;;","25/Jan/10 04:49;jmhodges;Works for me. Must have missed the last of your sentence.;;;","25/Jan/10 16:55;jbellis;committed to 0.5 branch (for 0.5.1) and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a few insert operations failed while bootstrapping,CASSANDRA-731,12446281,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jaakko,david.pan,david.pan,22/Jan/10 02:42,16/Apr/19 09:33,14/Jul/23 05:51,10/Feb/10 15:57,0.5,,,,0,,,,,,"I inserted 10000 key/value while bootstrapping and found 2 insert operations failed.

DEBUG [pool-1-thread-63] 2010-01-20 17:01:57,033 StorageProxy.java (line 225) insert writing key 15530 to 10981@/10.81.37.65
ERROR [pool-1-thread-46] 2010-01-20 17:01:57,033 Cassandra.java (line 1064) Internal error processing insert
java.lang.AssertionError
at org.apache.cassandra.locator.AbstractReplicationStrategy.getHintedMapForEndpoints(AbstractReplicationStrategy.java:157)
at org.apache.cassandra.locator.AbstractReplicationStrategy.getHintedEndpoints(AbstractReplicationStrategy.java:76)
at org.apache.cassandra.service.StorageService.getHintedEndpointMap(StorageService.java:1178)
at org.apache.cassandra.service.StorageProxy.insertBlocking(StorageProxy.java:169)
at org.apache.cassandra.service.CassandraServer.doInsert(CassandraServer.java:466)
at org.apache.cassandra.service.CassandraServer.insert(CassandraServer.java:417)
at org.apache.cassandra.service.Cassandra$Processor$insert.process(Cassandra.java:1056)
at org.apache.cassandra.service.Cassandra$Processor.process(Cassandra.java:817)
at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
at java.lang.Thread.run(Thread.java:619)
ERROR [pool-1-thread-44] 2010-01-20 17:01:57,033 Cassandra.java (line 1064) Internal error processing insert
java.lang.AssertionError
at org.apache.cassandra.locator.AbstractReplicationStrategy.getHintedMapForEndpoints(AbstractReplicationStrategy.java:157)
at org.apache.cassandra.locator.AbstractReplicationStrategy.getHintedEndpoints(AbstractReplicationStrategy.java:76)
at org.apache.cassandra.service.StorageService.getHintedEndpointMap(StorageService.java:1178)
at org.apache.cassandra.service.StorageProxy.insertBlocking(StorageProxy.java:169)
at org.apache.cassandra.service.CassandraServer.doInsert(CassandraServer.java:466)
at org.apache.cassandra.service.CassandraServer.insert(CassandraServer.java:417)
at org.apache.cassandra.service.Cassandra$Processor$insert.process(Cassandra.java:1056)
at org.apache.cassandra.service.Cassandra$Processor.process(Cassandra.java:817)
at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
at java.lang.Thread.run(Thread.java:619)


I traced the code and found the following assertion failed :
/* org.apache.cassandra.locator.AbstractReplicationStrategy.getHintedMapForEndpoints(Collection<InetAddress>) */
assert map.size() == targets.size(); 

The following reasons caused this issue:
1) targets is a list , not a map, as a result there may be some duplicated IP.
2) The following codes are not atomic :
org.apache.cassandra.service.StorageService.handleStateNormal(InetAddress, String)
        tokenMetadata_.updateNormalToken(token, endPoint);
        calculatePendingRanges();

 That's to say the IP may be both in the naturalEndpoints and pendingRanges.

eg : 
targets is IPa, IPb, IPc, IPa; (size = 4)
then, the map will be IPa, IPb, IPc. (size = 3)
as a result, assert failed.







",,david.pan,,,,,,,,,86400,86400,,0%,86400,86400,,,,,,,,,,,,,,"22/Jan/10 02:49;david.pan;731-throw_internal_exception_while_bootstrapping.patch;https://issues.apache.org/jira/secure/attachment/12431087/731-throw_internal_exception_while_bootstrapping.patch","22/Jan/10 02:56;david.pan;the new log after patch.txt;https://issues.apache.org/jira/secure/attachment/12431088/the+new+log+after+patch.txt",,,,,,,,,,,,,2.0,jaakko,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19842,,,Wed Feb 10 15:57:03 UTC 2010,,,,,,,,,,"0|i0g0q7:",91548,,,,,Normal,,,,,,,,,,,,,,,,,"22/Jan/10 02:49;david.pan;This is a simple way to deal with this problem, but it's not the final solution.
I think the best way is to make the modification of TokenMetadata atomic, but that needs a big change both in the TokenMetadata and StorageService.
Consider that the pendingRange is needed in writing, bootstrapping and leaving only, this simple modification looks like ok at current time.;;;","22/Jan/10 02:56;david.pan;After patch, I add a 500ms sleep between "" tokenMetadata_.updateNormalToken(token, endPoint);"" and "" calculatePendingRanges();"" to make it easy to repeat the problem.
Through the log, you can see it :-);;;","28/Jan/10 01:41;jaakko;Yeah, you're right. I'll have a look at this.;;;","09/Feb/10 09:31;jaakko;This assert might fail for the reason David said, but it might also fail because targets includes a node with pending ranges that has died (for instance did not complete bootstrap). 

It does not matter if a node is in pending ranges and normal token map simultaneously, as that time is very short and may only result in a write going to too many nodes once in a while. Gossip propagation is far from being instant, so writes go to wrong places routinely anyway when nodes move. It's a much smaller thing than locking whole metadata for the duration of calculations. 

I think removing the assert is enough. It should be removed in any case, since it is checking a condition that is no longer valid. I don't see any other problem in this part.;;;","10/Feb/10 15:57;jbellis;+1 Jaakko's diagnosis.  Committed assertion removal to 0.5 and trunk.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bug in count columns.,CASSANDRA-729,12446189,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,,gasolwu,gasolwu,21/Jan/10 03:14,16/Apr/19 09:33,14/Jul/23 05:51,05/Feb/10 19:03,0.5,,,,0,,,,,,"same as thrift api (get_count).

Welcome to cassandra CLI.

Type 'help' or '?' for help. Type 'quit' or 'exit' to quit.
cassandra> connect localhost/9160
Connected to localhost/9160
cassandra> del Keyspace1.Standard1['1']
row removed.
cassandra> set Keyspace1.Standard1['1']['foo'] = 'foo value'
Value inserted.
cassandra> set Keyspace1.Standard1['1']['bar'] = 'bar value'
Value inserted.
cassandra> get Keyspace1.Standard1['1']
=> (column=foo, value=foo value, timestamp=1264043095206)
=> (column=bar, value=bar value, timestamp=1264043106184)
Returned 2 results.
cassandra> count Keyspace1.Standard1['1']
2 columns
cassandra> del Keyspace1.Standard1['1']['foo']
column removed.
cassandra> get Keyspace1.Standard1['1']       
=> (column=bar, value=bar value, timestamp=1264043106184)
Returned 1 results.
cassandra> count Keyspace1.Standard1['1']     
2 columns
cassandra>","debian lenny, sun jdk 1.6",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19840,,,Fri Feb 05 19:03:23 UTC 2010,,,,,,,,,,"0|i0g0pr:",91546,,,,,Low,,,,,,,,,,,,,,,,,"21/Jan/10 03:20;jbellis;this sounds like CASSANDRA-647, are you testing 0.5.0 final or an earlier release?;;;","21/Jan/10 03:25;gasolwu;yes, testing in 0.5.0-rc3 and 0.5.0 final.;;;","22/Jan/10 09:23;gasolwu;ColumnFamily.getSortedColumns() (return this.columns_) contains deleted column, it's odd.
i don't know how to fix.

CassandraServer.java
382:     Map<String, Collection<IColumn>> columnsMap = multigetColumns(commands, consistency_level);

        for (ReadCommand command: commands)
        {
            Collection<IColumn> columns = columnsMap.get(command.key);
            if(columns == null)
            {
               columnFamiliesMap.put(command.key, 0);
            }
            else
            {
394:            columnFamiliesMap.put(command.key, columns.size()); // contains removed column,
            }
        }
        return columnFamiliesMap;;;;","04/Feb/10 17:41;jbellis;Looks to me like this was fixed by the patch for CASSANDRA-703; can you verify that it works for you in the 0.5 branch?;;;","05/Feb/10 19:03;jbellis;lmorchard tested the 0.5 branch and reports that this bug is fixed now.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Insert/Get Contention,CASSANDRA-724,12446007,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,lenn0x,lenn0x,20/Jan/10 08:26,16/Apr/19 09:33,14/Jul/23 05:51,04/Feb/10 19:59,0.6,,,,0,,,,,,"We tried out the socket io patch in CASSANDRA-705, tested the latest JVM of b18 for 1.6. Still seeing very strange insert times. We see this with get_slices as well but it's easy to reproduce with batch_insert. I wonder if its related to Memtable contention, it's pretty easy to see the slow times when you restart the test script attached. We are running this on a 7 node cluster, <1% cpu. Consistency Level of 1.

Results
---------------------
Slow insert test.10882 0.203548192978
Slow insert test.18005 0.203876972198
Slow insert test.21154 0.204496860504
Slow insert test.22054 0.0444049835205
Slow insert test.26445 0.201545000076",,brandon.williams,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Feb/10 19:04;jbellis;ASF.LICENSE.NOT.GRANTED--0001-decouple-periodic-sync-mode-from-commit-log-append.txt;https://issues.apache.org/jira/secure/attachment/12434856/ASF.LICENSE.NOT.GRANTED--0001-decouple-periodic-sync-mode-from-commit-log-append.txt","04/Feb/10 19:04;jbellis;ASF.LICENSE.NOT.GRANTED--0002-replace-gc-after-each-compaction-w-gc-before-compactio.txt;https://issues.apache.org/jira/secure/attachment/12434857/ASF.LICENSE.NOT.GRANTED--0002-replace-gc-after-each-compaction-w-gc-before-compactio.txt","04/Feb/10 19:04;jbellis;ASF.LICENSE.NOT.GRANTED--0003-only-gc-if-there-are-undeleted-sstables-that-gc-ing-co.txt;https://issues.apache.org/jira/secure/attachment/12434858/ASF.LICENSE.NOT.GRANTED--0003-only-gc-if-there-are-undeleted-sstables-that-gc-ing-co.txt","20/Jan/10 23:25;jbellis;debug.patch;https://issues.apache.org/jira/secure/attachment/12430946/debug.patch","20/Jan/10 08:27;lenn0x;test_case.py;https://issues.apache.org/jira/secure/attachment/12430857/test_case.py",,,,,,,,,,5.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19838,,,Wed Feb 17 17:54:47 UTC 2010,,,,,,,,,,"0|i0g0on:",91541,,,,,Normal,,,,,,,,,,,,,,,,,"20/Jan/10 08:29;lenn0x;Just an observation, we see this happening on 99% of keys that need to send a remote write.;;;","20/Jan/10 21:48;jbellis;I can reproduce this on a single-node setup, so I think it is possible you are seeing two effects: one from the messagingservice stack (Brandon points out that this happens much more frequently w/o CASSANDRA-705, than with it), and one from the commitlog sync (which I can reproduce on a single node system).;;;","20/Jan/10 23:11;jbellis;this addresses latency from waiting for commitlog append to finish (which will be delayed if commitlog is busy syncing).  in batch mode we have to wait because that is part of our contract, but in periodic mode we do not.

705 will be committed soon and that will address that.
;;;","20/Jan/10 23:25;jbellis;patch to add debug timing info if you want to investigate further.

there does seem to be occasional latency spikes inside ColumnFamilyStore.apply that I do not yet understand.

when cpus are busy w/ compaction latency increases.  no real surprise there.

thrift sometimes adds 10s of ms of latency according to the differences b/t what my python client sees and what CassandraServer sees.  the java side of thrift does call setTcpNoDelay(true), but the python side does not -- the equivalent would be, setsockopt(SOL_TCP, TCP_NODELAY, 1).  that is probably the culprit.
;;;","21/Jan/10 21:07;lenn0x;We didn't see much change, I think applying debug is going to be required. It ranges from 45ms to 800ms sometimes.;;;","22/Jan/10 22:56;jbellis;Brandon's did some more testing and found that the System.gc() we request (to allow cleaning up obsolete sstables after a compaction) is the culprit.

Maybe it's time to experiment w/ the g1 garbage collector: http://java.sun.com/javase/technologies/hotspot/gc/g1_intro.jsp

Alternatively, one workaround might be to only issue the gc() request if we're within some percent of the disk filling up (we can use File.getUsableSpace / File.getTotalSpace for that);;;","26/Jan/10 23:27;jbellis;patches 02 and 03 will reduce your System.gc frequency (as long as you have spare disk space):

03
    only gc if there are undeleted sstables that gc-ing could free

02
    replace gc after each compaction w/ gc before compaction/flush only if we need it for the file space

01
    decouple periodic sync mode from commit log append [original patch posted]

;;;","04/Feb/10 17:23;jbellis;rebased again;;;","04/Feb/10 19:49;brandon.williams;+1, much improved for me:

Slow insert test.15910 0.0661840438843
Slow insert test.37799 0.073842048645
Slow insert test.38254 0.0541589260101
Slow insert test.46248 0.0541749000549
Slow insert test.56482 0.0474050045013
Slow insert test.70314 0.0435261726379
Slow insert test.76370 0.0660541057587
Slow insert test.170684 0.0553348064423
Slow insert test.170685 0.0560541152954
Slow insert test.202273 0.0667309761047

I also confirmed w/verbose:gc that the long gc pauses related to compaction/deletion are gone.;;;","04/Feb/10 19:59;jbellis;committed;;;","17/Feb/10 17:54;hudson;Integrated in Cassandra #357 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/357/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
batch insert failing with TokenMetadata AssertionError,CASSANDRA-722,12445995,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jaakko,dispalt,dispalt,20/Jan/10 04:38,16/Apr/19 09:33,14/Jul/23 05:51,22/Jan/10 00:01,0.5,,,,0,,,,,,"I get this during the course of an insert.

ERROR [pool-1-thread-17] 2010-01-20 03:50:40,517 Cassandra.java (line 1096) Internal error processing batch_insert
java.lang.AssertionError
        at org.apache.cassandra.locator.TokenMetadata.getToken(TokenMetadata.java:212)
        at org.apache.cassandra.locator.AbstractReplicationStrategy.getHintedMapForEndpoints(AbstractReplicationStrategy.java:129)
        at org.apache.cassandra.locator.AbstractReplicationStrategy.getHintedEndpoints(AbstractReplicationStrategy.java:76)
        at org.apache.cassandra.service.StorageService.getHintedEndpointMap(StorageService.java:1183)
        at org.apache.cassandra.service.StorageProxy.insert(StorageProxy.java:101)
        at org.apache.cassandra.service.CassandraServer.doInsert(CassandraServer.java:470)
        at org.apache.cassandra.service.CassandraServer.batch_insert(CassandraServer.java:445)
        at org.apache.cassandra.service.Cassandra$Processor$batch_insert.process(Cassandra.java:1088)
        at org.apache.cassandra.service.Cassandra$Processor.process(Cassandra.java:817)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)","r900058  4 node cluster, 1 more bootstrapping",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jan/10 01:57;jaakko;722.patch;https://issues.apache.org/jira/secure/attachment/12430977/722.patch",,,,,,,,,,,,,,1.0,jaakko,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19837,,,Fri Jan 22 00:01:08 UTC 2010,,,,,,,,,,"0|i0g0o7:",91539,,,,,Normal,,,,,,,,,,,,,,,,,"20/Jan/10 04:42;jbellis;have you done any node movement in this cluster?;;;","20/Jan/10 04:57;dispalt;I have used loadbalance quite a few times.  I have never done a decommision or a move command explicitly.

A machine does seem to be stalled in the middle of bootstrapping.  Trying to get intellij setup, to dig deeper on to what that machine is doing.;;;","20/Jan/10 05:16;jaakko;Seems there's a bug in getHintedMapForEndpoints. 

That bootsrapping node is probably considered dead by other nodes

This is what's happening:
(1) Node bootstraps -> it has pending ranges, but it is not member of token ring
(2) During write, pending ranges match -> node is added to write endpoints
(3) Node is down -> a hinted target will be searched for
(4) getToken explodes because endpoint is not member

There are two things that need to be considered:
(1) We probably should ignore endpoints that are not members when looking for hinted targets
(2) That assert in getToken is a bit outdated I think. Nodes may come and go during the time ARS and friends are looking for write targets. It might very well happen that a node was removed between getting natural endpoints and coming back to get hinted targets. There's a comment saying ""don't want to return nulls"", but perhaps we'll need to reconsider this?
;;;","20/Jan/10 05:41;jbellis;(1) definitely
(2) Under what conditions does it make sense to ask for Token of a node that is not a ring member?;;;","20/Jan/10 06:07;jaakko;(2) it does not make sense, but it might happen. Suppose a node is natural endpoint of a write. StorageProxy gets these in mutate, and then passes the same list to getHintedEndpointMap. If one of these natural endpoints is removed in between getNaturalEndpoints and finding hinted targets, there will be a call to getToken for non-existing endpoint. It does not help even if we insert isMember check right before getToken, as there is still small window that could cause this.

Basically the same can happen wherever we use getToken;;;","20/Jan/10 06:14;jbellis;We could fix that by picking a random node to start our scan of potential hint destinations; there's nothing magical about starting w/ endpoint+1.  In fact picking random is better, since currently having a node down degrades performance more than it should since all the hints go to the same node.;;;","20/Jan/10 14:20;jaakko;Is it really OK to send hints to random targets? That will scatter hinted data around the cluster as each hinted write may go to different location. Might not be problematic, but feels like we're going around the problem instead of fixing the cause. Something would certainly be gained by having the load spread amongst nodes, but isn't something also lost if (potentially) all nodes in the cluster stream hinted data instead of one node?
;;;","20/Jan/10 14:31;jbellis;no, we don't rely on hint location.

but actually using sortByProximity is probably best of all.;;;","20/Jan/10 15:12;jaakko;yeah, proximity seems good.

Attached patch ignores dead bootstrappers and looks for hinted locations based on proximity (list of addresses is from gossiper.liveMembers).

This couples ARS with Gossiper, but don't know if that matters so much as it used FD already before.

Edit: this patch has not been tested much, have to do some more testing tomorrow.;;;","20/Jan/10 15:28;jbellis;+1;;;","20/Jan/10 21:01;dispalt;Is there a way to remove the failed bootstrapped node from the cluster, decommission obviously doesn't work...

Or should this patch fix things?;;;","20/Jan/10 21:30;jbellis;this will fix your batch_insert problem;;;","20/Jan/10 21:49;dispalt;Should I add another bug for the failed bootstrapping problem?  

The node seems to be getting data; like it thinks its part of the cluster and datagrowth is that of a normal working node.  However, it doesn't have all the data (should be at least 50g and it 3 gb) and if I try to nodeprobe ring it doesn't show up.;;;","21/Jan/10 01:36;jaakko;new version. skip non-members also when considering hinted location.
;;;","21/Jan/10 01:39;jaakko;> Is there a way to remove the failed bootstrapped node from the cluster, decommission obviously doesn't work...

Actually there is an ""undocumented"" feature in removetoken command that it will clear the token from bootstrapping as well. If you know the token, remove it and that should take care of it.

Probably need to provide better tools to investigate/poke bootstrapping and leaving tokens.
;;;","21/Jan/10 01:47;dispalt;I think jonathan mentioned that I would need the patch rom 644 is that correct?;;;","21/Jan/10 01:57;jaakko;accidentally submitted a japanese version, this should be better.
;;;","21/Jan/10 01:59;jaakko;yeah, 644 is needed to remove it from gossip, but it will be removed from token metadata even without 644, which is what matters in this case.
;;;","22/Jan/10 00:01;jaakko;committed to 0.5.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix failing CompactionsPurgeTest,CASSANDRA-719,12445969,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,19/Jan/10 21:28,16/Apr/19 09:33,14/Jul/23 05:51,22/Jan/10 01:12,0.6,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jan/10 23:51;jbellis;719.txt;https://issues.apache.org/jira/secure/attachment/12431079/719.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19835,,,Fri Jan 22 12:36:21 UTC 2010,,,,,,,,,,"0|i0g0nj:",91536,,,,,Normal,,,,,,,,,,,,,,,,,"19/Jan/10 21:28;jbellis;(see CASSANDRA-710 for genesis.  Note that this test has been silently broken for we don't know how long, something in the other tests in CompactionsTest were covering it up.);;;","21/Jan/10 23:51;jbellis;invalidate cache after compaction in test so we read what's in the new sstable instead of the cache

alternatively we could fix this by making compaction invalidate the cache, but i think this is a bad idea; the system is designed so that to the client it makes no difference if the tombstones are GC'd or not since we hide them, so there is no hurry to uncache things.  And compaction (when we are doing a lot of extra io) is a particularly bad time to throw away the whole cache.  Just leave it to be invalidated eventually through natural causes.;;;","22/Jan/10 00:03;lenn0x;+1;;;","22/Jan/10 01:12;jbellis;committed;;;","22/Jan/10 12:36;hudson;Integrated in Cassandra #331 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/331/])
    invalidate cache after compaction so we read what's in the new sstable instead of the cache
patch by jbellis; reviewed by goffinet for 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
register AES verbs at SS start,CASSANDRA-717,12445948,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,19/Jan/10 17:15,16/Apr/19 09:33,14/Jul/23 05:51,21/Jan/10 21:22,0.6,,,,0,,,,,,"the reason we do all registration in one place is it prevents bugs like this one

ERROR - Error in ThreadPoolExecutor
java.lang.AssertionError: unknown verb TREE-RESPONSE-VERB
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:37)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
ERROR - Fatal exception in thread Thread[AE-SERVICE-STAGE:1,5,main]
java.lang.AssertionError: unknown verb TREE-RESPONSE-VERB
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:37)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
",,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/10 17:28;messi;0003-EnumMap-StorageService.Verb.patch.txt;https://issues.apache.org/jira/secure/attachment/12449369/0003-EnumMap-StorageService.Verb.patch.txt","19/Jan/10 19:45;jbellis;ASF.LICENSE.NOT.GRANTED--0001-mv-tree-and-gossip-verb-registration-into-StorageServi.txt;https://issues.apache.org/jira/secure/attachment/12430788/ASF.LICENSE.NOT.GRANTED--0001-mv-tree-and-gossip-verb-registration-into-StorageServi.txt","19/Jan/10 19:45;jbellis;ASF.LICENSE.NOT.GRANTED--0002-convert-verbs-to-enums.txt;https://issues.apache.org/jira/secure/attachment/12430789/ASF.LICENSE.NOT.GRANTED--0002-convert-verbs-to-enums.txt",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19833,,,Wed Jul 14 13:56:17 UTC 2010,,,,,,,,,,"0|i0g0n3:",91534,,,,,Low,,,,,,,,,,,,,,,,,"19/Jan/10 20:59;stuhood;+1... it's an improvement, although if we can find a good excuse to give the components of SS (AES, Gossiper, Streaming) an abstract base class and lifecycle, that would probably be ideal.;;;","21/Jan/10 21:22;jbellis;rebased and committed;;;","22/Jan/10 12:36;hudson;Integrated in Cassandra #331 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/331/])
    convert verbs to enums
patch by jbellis; reviewed by Stu Hood for 
mv tree and gossip verb registration into StorageService
patch by jbellis; reviewed by Stu Hood for 
;;;","13/Jul/10 17:28;messi;Use EnumMap for Map<StorageService.Verb, IVerbHandler>.;;;","13/Jul/10 19:46;jbellis;committed;;;","14/Jul/10 13:56;hudson;Integrated in Cassandra #491 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/491/])
    Use EnumMap for verbHandlers.  patch by Folke Behrens; reviewed by jbellis for CASSANDRA-717
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bootstrapping does not work properly using multiple DataFileDirectory,CASSANDRA-716,12445889,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,gdusbabek,david.pan,david.pan,19/Jan/10 06:55,16/Apr/19 09:33,14/Jul/23 05:51,21/Jan/10 23:13,0.5,,,,0,,,,,,"I was adding a new machine A which has 2 DataFileDirectories into the ring. The A will throw exception while bootstrapping.
DEBUG [MESSAGING-SERVICE-POOL:4] 2010-01-19 11:43:32,837 ContentStreamState.java (line 88) Removing stream context /home/store0/data/pic/raw_data-tmp-1-Data.db:209833142
 WARN [MESSAGING-SERVICE-POOL:4] 2010-01-19 11:43:32,837 TcpConnection.java (line 484) Problem reading from socket connected to : java.nio.channels.SocketChannel[connected local
=/10.81.37.65:7000 remote=/10.81.42.26:10418]
 WARN [MESSAGING-SERVICE-POOL:4] 2010-01-19 11:43:32,837 TcpConnection.java (line 485) Exception was generated at : 01/19/2010 11:43:32 on thread MESSAGING-SERVICE-POOL:4
java.io.IOException: rename failed of /home/store0/data/pic/raw_data-1-Filter.db
java.io.IOError: java.io.IOException: rename failed of /home/store0/data/pic/raw_data-1-Filter.db
        at org.apache.cassandra.io.SSTableWriter.rename(SSTableWriter.java:154)
        at org.apache.cassandra.io.SSTableWriter.renameAndOpen(SSTableWriter.java:162)
        at org.apache.cassandra.io.Streaming$StreamCompletionHandler.onStreamCompletion(Streaming.java:284)
        at org.apache.cassandra.net.io.ContentStreamState.handleStreamCompletion(ContentStreamState.java:108)
        at org.apache.cassandra.net.io.ContentStreamState.read(ContentStreamState.java:90)
        at org.apache.cassandra.net.io.TcpReader.read(TcpReader.java:96)
        at org.apache.cassandra.net.TcpConnection$ReadWorkItem.run(TcpConnection.java:445)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.io.IOException: rename failed of /home/store0/data/pic/raw_data-1-Filter.db
        at org.apache.cassandra.utils.FBUtilities.renameWithConfirm(FBUtilities.java:306)
        at org.apache.cassandra.io.SSTableWriter.rename(SSTableWriter.java:150)
        ... 9 more


I traced the exception and maybe found the reason.
StreamInitiateVerbHandler::doVerb() will create 3 temporary files(index, filter, data) for each ssTable. The name for each file is generated by getNewFileNameFromOldContextAndNames(). This method will generate a file name and a path for each ssTable, but the path is generated with DatabaseDescriptor.getDataFileLocationForTable() which will return different path for ech call when we configure multi-DataFileDirectory. 
eg: the ssTable raw_data-1 may have 3 temporary files : 
/home/store0/data/pic/raw_data-tmp-1-Index.db
/home/store1/data/pic/raw_data-tmp-1-Filter.db
/home/store0/data/pic/raw_data-tmp-1-Data.db

After receiving all data, StreamCompletionHandler::onStreamCompletion() will rename all temporary files and this method think all ssTable files will have the same path as data.db file. 
            if (streamContext.getTargetFile().contains(""-Data.db""))
            {
               ......
                try
                {
                    SSTableReader sstable = SSTableWriter.renameAndOpen(streamContext.getTargetFile());
                    ......
                }
                ......
            }
Then the renameAndOpen() will throw that exception.



","storage-conf.xml:
  <CommitLogDirectory>/home/store1/commitlog</CommitLogDirectory>
  <DataFileDirectories>
      <DataFileDirectory>/home/store0/data</DataFileDirectory>
      <DataFileDirectory>/home/store1/data</DataFileDirectory>
  </DataFileDirectories>
  <CalloutLocation>/home/store1/cassandra/callouts</CalloutLocation>
  <StagingFileDirectory>/home/store1/cassandra/staging</StagingFileDirectory>",david.pan,,,,,,,,,86400,86400,,0%,86400,86400,,,,,,,,,,,,,,"21/Jan/10 22:08;gdusbabek;0001-rename-DD.getDAtaFileLocationForTable-to-something-m.patch;https://issues.apache.org/jira/secure/attachment/12431070/0001-rename-DD.getDAtaFileLocationForTable-to-something-m.patch","21/Jan/10 22:08;gdusbabek;0002-ensure-all-files-for-an-sstable-are-streamed-to-the-.patch;https://issues.apache.org/jira/secure/attachment/12431071/0002-ensure-all-files-for-an-sstable-are-streamed-to-the-.patch",,,,,,,,,,,,,2.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19832,,,Thu Jan 21 23:13:04 UTC 2010,,,,,,,,,,"0|i0g0mv:",91533,,,,,Normal,,,,,,,,,,,,,,,,,"19/Jan/10 07:04;david.pan;sorry, my version is 0.5-rc1.;;;","21/Jan/10 13:36;jbellis;(CASSANDRA-730 has another example.);;;","21/Jan/10 22:08;gdusbabek;ensures that all files for a single sstable end up in the same directory.  The same round-robin approach is used in the case of multiple sstables/keyspaces.;;;","21/Jan/10 22:14;jbellis;+1;;;","21/Jan/10 23:13;gdusbabek;r901902 (0.5), r901915 (trunk);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"HHOM goes into infinite loop, wasting cpu",CASSANDRA-715,12445884,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,brandon.williams,brandon.williams,19/Jan/10 05:03,16/Apr/19 09:33,14/Jul/23 05:51,19/Jan/10 18:38,0.6,,,,0,,,,,,"To replicate: take a host down, cause hints to it, wait for HHOM to kick in

The issue is line 201 of HHOM:
startColumn = keyColumn.name(); // repeating the last as the first is fine since we just deleted it

That comment is false.  The column may not have been deleted, since the endpoint could still be down.  This causes HHOM to go into an infinite loop trying to deliver hints to a down host.","debian lenny amd64 OpenJDK 64-Bit Server VM (build 1.6.0_0-b11, mixed mode)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jan/10 17:05;jbellis;715.txt;https://issues.apache.org/jira/secure/attachment/12430771/715.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19831,,,Fri Jan 22 12:36:20 UTC 2010,,,,,,,,,,"0|i0g0mn:",91532,,,,,Normal,,,,,,,,,,,,,,,,,"19/Jan/10 15:41;jbellis;until this is fixed, running nodeprobe cleanup on each live node & restarting it should fix this (by removing undelivered hints forcibly).  depending on your replication factor you may have hints that are not removed by cleanup; in that case you can remove the hint files from data/system/*Hint*.;;;","19/Jan/10 18:10;brandon.williams;+1, infinite loop no longer occurs.;;;","19/Jan/10 18:38;jbellis;committed;;;","22/Jan/10 12:36;hudson;Integrated in Cassandra #331 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/331/])
    ;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Some Thrift Exceptions not passed down to Client,CASSANDRA-711,12445854,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,lenn0x,lenn0x,18/Jan/10 20:16,16/Apr/19 09:33,14/Jul/23 05:51,01/Mar/10 16:22,0.6,,,,0,,,,,,"We still don't pass all exceptions down to client via Thrift. We have seen a few of these when working on our client library:

org.apache.thrift.protocol.TProtocolException: Required field 'start' was not present! Struct: SliceRange(start:null, finish:null, reversed:false, count:100)

Would be good if those exceptions were passed down, instead of 'TSocket Read 0 Bytes'.
",,stuhood,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Feb/10 03:28;jbellis;711-test.txt;https://issues.apache.org/jira/secure/attachment/12435405/711-test.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19828,,,Mon Mar 01 16:22:39 UTC 2010,,,,,,,,,,"0|i0g0lr:",91528,,,,,Low,,,,,,,,,,,,,,,,,"18/Jan/10 20:18;jbellis;can you include full ST?

it sounds like a thrift bug, not ours.;;;","18/Jan/10 21:00;lenn0x;You might be right... Hmm...

ERROR [pool-1-thread-34] 2010-01-18 12:13:35,252 TThreadPoolServer.java (line 257) Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Required field 'start' was not present! Struct: SliceRange(start:null, finish:null, reversed:false, count:100)
        at org.apache.cassandra.service.SliceRange.validate(SliceRange.java:587)
        at org.apache.cassandra.service.SliceRange.read(SliceRange.java:515)
        at org.apache.cassandra.service.SlicePredicate.read(SlicePredicate.java:366)
        at org.apache.cassandra.service.Cassandra$get_slice_args.read(Cassandra.java:3063)
        at org.apache.cassandra.service.Cassandra$Processor$get_slice.process(Cassandra.java:937)
        at org.apache.cassandra.service.Cassandra$Processor.process(Cassandra.java:895)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619);;;","25/Jan/10 20:35;jbellis;fix attached to THRIFT-689.;;;","10/Feb/10 03:28;jbellis;test to demonstrate problem.  may need rebasing.;;;","25/Feb/10 15:31;nicktelford;Another example of this:

ERROR - Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Required field 'timestamp' was not found in serialized data! Struct: Column(name:null, value:null, timestamp:0)
	at org.apache.cassandra.service.Column.read(Column.java:382)
	at org.apache.cassandra.service.SuperColumn.read(SuperColumn.java:317)
	at org.apache.cassandra.service.ColumnOrSuperColumn.read(ColumnOrSuperColumn.java:295)
	at org.apache.cassandra.service.Cassandra$batch_insert_args.read(Cassandra.java:10447)
	at org.apache.cassandra.service.Cassandra$Processor$batch_insert.process(Cassandra.java:1084)
	at org.apache.cassandra.service.Cassandra$Processor.process(Cassandra.java:817)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)

Seems to arise when you don't pass a field that was marked as ""required"" in the structs Thrift interface spec. Thrift appears to do the checks on the server-side and not properly handle the exception.;;;","25/Feb/10 15:56;jbellis;yes, that is why I submitted a fix to thrift and linked the thrift ticket two comments above yours;;;","01/Mar/10 06:12;stuhood;The patch for THRIFT-689 was committed in Thrift SVN r916825. What are the next steps here? Updating Cassandra's thrift to that exact revision?;;;","01/Mar/10 13:24;jbellis;yeah, update and test for regressions :)

I'll do that today.;;;","01/Mar/10 16:22;jbellis;Done, thanks for the Thrift help Stu.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Insert, Delete and Insert into a column family doesnt work... ",CASSANDRA-703,12445593,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,vijay2win@yahoo.com,vijay2win@yahoo.com,15/Jan/10 04:35,16/Apr/19 09:33,14/Jul/23 05:51,29/Jan/10 23:47,0.5,,,,0,,,,,,"Here is the code to reproduce the issue...

        ColumnPath colpath = new ColumnPath().setColumn_family(""VERSIONS"").setSuper_column(""123"".getBytes()).setColumn(""1234"".getBytes());
        con.insert(""WBXCDOCUMENT"", ""vijay"", colpath, ""test"".getBytes(), System.currentTimeMillis(), 2);

        ColumnPath path = new ColumnPath().setColumn_family(""VERSIONS"").setSuper_column(""123"".getBytes());
        con.remove(""WBXCDOCUMENT"", ""vijay"", path, System.currentTimeMillis(), 2);

        con.insert(""WBXCDOCUMENT"", ""vijay"", colpath, ""test"".getBytes(), System.currentTimeMillis(), 2);

        ColumnOrSuperColumn col = con.get(""WBXCDOCUMENT"", ""vijay"", path, 2);
        assertEquals(col.getSuper_column().getColumns() != null, true);

Expected result, get the column family..... but it throws notfound exception which is wrong.","Linux, Cassandra .5",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jan/10 19:46;jbellis;703-05.txt;https://issues.apache.org/jira/secure/attachment/12431453/703-05.txt","26/Jan/10 19:31;jbellis;703-trunk.txt;https://issues.apache.org/jira/secure/attachment/12431451/703-trunk.txt","15/Jan/10 21:53;vijay2win@yahoo.com;bug-fix-703.txt;https://issues.apache.org/jira/secure/attachment/12430444/bug-fix-703.txt",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19826,,,Fri Jan 29 23:47:47 UTC 2010,,,,,,,,,,"0|i0g0k7:",91521,,,,,Low,,,,,,,,,,,,,,,,,"15/Jan/10 21:53;vijay2win@yahoo.com;Suggesting this changes....  This might need the users to flush the data to disk.... and then use it.... is this incompatable because the seralizer, deserializer is changed... we might need to add one more field timestamp.... not sure if it is the right way to do it.

1) Added the timestamp to the constructor for the supercolumn.
2) Added the timestamp to serializer deserializer
3) change the classes dependent on it to fix the initialization
4) When new col is added the recent chang timestamp is updated.

Thanks
Vijay;;;","25/Jan/10 21:12;jbellis;just to rule out the obvious, did you test using timestamps 0, 1, 2 instead of System.currentTimeMillis()?  if the remove takes less than 1ms, the following insert will have the same timestamp and the remove will take precedence (ties go to tombstone).;;;","25/Jan/10 21:28;vijay2win@yahoo.com;Hi Jonathan, yes actually i did the following...

first insert
System.currentTimeMillis() 

first delete
System.currentTimeMillis()  + 5

secound insert
System.currentTimeMillis()  + 10

        String supcol = ""12356"";
        Client con = ConnectionCacheUtils.getinstance().getCassandraConnection().getclient();
        ColumnPath colpath = new ColumnPath().setColumn_family(""VERSIONS"").setSuper_column(supcol.getBytes()).setColumn(""1234"".getBytes());
        con.insert(""WBXCDOCUMENT"", ""vijay"", colpath, ""test"".getBytes(), System.currentTimeMillis(), 2);
        
        ColumnPath path = new ColumnPath().setColumn_family(""VERSIONS"").setSuper_column(supcol.getBytes());
        ColumnOrSuperColumn col = con.get(""WBXCDOCUMENT"", ""vijay"", path, 2);
        assertEquals(col.getSuper_column().getColumns() != null, true);
        
        con.remove(""WBXCDOCUMENT"", ""vijay"", path, System.currentTimeMillis() + 5, 2);
        con.insert(""WBXCDOCUMENT"", ""vijay"", colpath, ""test"".getBytes(), System.currentTimeMillis() + 10, 2);
        
        ColumnOrSuperColumn col2 = con.get(""WBXCDOCUMENT"", ""vijay"", path, 2);
        assertEquals(col2.getSuper_column().getColumns() != null, true);

Regards
Vijay;;;","26/Jan/10 16:33;jbellis;I can reproduce with this system test:

    def test_vijay(self):
        key = 'vijay'
        client.insert('Keyspace1', key, ColumnPath('Super1', 'sc1', _i64(4)), 'value4', 0, ConsistencyLevel.ONE)

        client.remove('Keyspace1', key, ColumnPath('Super1', 'sc1'), 1, ConsistencyLevel.ONE)

        client.insert('Keyspace1', key, ColumnPath('Super1', 'sc1', _i64(4)), 'value4', 2, ConsistencyLevel.ONE)

        result = client.get('Keyspace1', key, ColumnPath('Super1', 'sc1'), ConsistencyLevel.ONE)
        assert result.super_column.columns is not None, result.super_column
;;;","26/Jan/10 19:31;jbellis;the internals are fine; the bug is in turning the data from the internal representation into Thrift objects.  patch attached.;;;","26/Jan/10 19:46;jbellis;0.5 version of patch;;;","26/Jan/10 20:30;vijay2win@yahoo.com;+1, tested and works... thanks Jonathan..;;;","29/Jan/10 23:47;jbellis;committed to 0.5 and trunk;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bootstrapping doesn't work on new clusters,CASSANDRA-696,12445444,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,gdusbabek,gdusbabek,13/Jan/10 22:19,16/Apr/19 09:33,14/Jul/23 05:51,14/Jan/10 16:48,0.5,,,,0,,,,,,"This is an edge case.

1. start a clean 3 node cluster with autobootstrap on.
2. load some data.
3. bootstrap in a 4th node.

the logs in the 4th node will indicate that data was not received.  If you restart the cluster in between steps 1 and 2, or 2 and 3, boot strapping works fine.  

I find that waiting on the table flush when making the streaming request solves the problem (see patch).",,,,,,,,,,,,,,,,,,,,,,,,CASSANDRA-682,,,,,,"13/Jan/10 22:20;gdusbabek;wait_for_memtable_flush.patch;https://issues.apache.org/jira/secure/attachment/12430180/wait_for_memtable_flush.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19825,,,Thu Jan 14 16:48:42 UTC 2010,,,,,,,,,,"0|i0g0in:",91514,,,,,Low,,,,,,,,,,,,,,,,,"13/Jan/10 22:20;gdusbabek;block on the table flush.;;;","13/Jan/10 22:29;jbellis;is this a 0.5 bug?;;;","13/Jan/10 23:12;gdusbabek;Just tested on 0.5... yes, the bug is there too.;;;","13/Jan/10 23:19;gdusbabek;To be precise, it looks like anything still in the memtables will not be streamed to the bootstrapping node since we're not blocking on the table.flush() call.  I haven't researched it enough, but I suspect the same thing will happen in an established cluster: everything already committed to SSTables gets streamed, and anything still left in the memtable is left behind.  It's just that in a brand new cluster, there never are any SSTables in the first place--it makes the bug more obvious.;;;","13/Jan/10 23:22;jbellis;+1.  can you commit to 0.5 and merge to trunk?

;;;","13/Jan/10 23:22;jbellis;(minor tweak: can you change the re-throw from Interrupted to AssertionError?);;;","14/Jan/10 16:48;gdusbabek;r899280 (0.5)
r899290 (trunk);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gossiper convicts same node over and over.,CASSANDRA-695,12445431,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,gdusbabek,gdusbabek,gdusbabek,13/Jan/10 19:35,16/Apr/19 09:33,14/Jul/23 05:51,21/Jan/10 22:23,0.6,,,,0,,,,,,"I can reproduce this in trunk or 0.5.  It is quite easy to see with logging set to DEBUG.
1.  Bring up several nodes.
2.  Kill one of them.

Gossip still continues to examine the failed node because it is in the ring, but gets convicted over and over at every check (see FailureDetector.interpret).  If this is expected, we should consider lowering the debug statement in MessagingService.convict to TRACE.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jan/10 22:20;gdusbabek;695.patch;https://issues.apache.org/jira/secure/attachment/12431073/695.patch",,,,,,,,,,,,,,1.0,gdusbabek,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19824,,,Fri Jan 22 12:36:21 UTC 2010,,,,,,,,,,"0|i0g0if:",91513,,,,,Low,,,,,,,,,,,,,,,,,"21/Jan/10 19:46;jbellis;From my reading this is Works As Intended.  Lowering level to trace is fine with me.  Go ahead and commit that, Gary.;;;","21/Jan/10 22:23;gdusbabek;901893. Patch by Gary Dusbabek.;;;","21/Jan/10 22:30;jbellis;+1;;;","22/Jan/10 12:36;hudson;Integrated in Cassandra #331 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/331/])
    lower MS.convict debug statement to trace. 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failure to flush commit log,CASSANDRA-694,12445429,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,ryandaum,ryandaum,13/Jan/10 19:11,16/Apr/19 09:33,14/Jul/23 05:51,14/Jan/10 20:09,0.5,,,,0,,,,,,"The following exception occurs consistently on at least node (note did not occur on other same-configured nodes) during startup:

INFO - Replaying /var/lib/cassandra/commitlog/CommitLog-1262855754427.log, /var/lib/cassandra/commitlog/CommitLog-1262832689989.log, /var/lib/cassandra/commitlog/CommitLog-1262885833186.log, /var/lib/cassandra/commitlog/CommitLog-1262900845019.log, /var/lib/cassandra/commitlog/CommitLog-1262913267844.log, /var/lib/cassandra/commitlog/CommitLog-1262927898170.log, /var/lib/cassandra/commitlog/CommitLog-1262961421039.log, /var/lib/cassandra/commitlog/CommitLog-1262977175175.log, /var/lib/cassandra/commitlog/CommitLog-1262989588783.log, /var/lib/cassandra/commitlog/CommitLog-1263000573676.log, /var/lib/cassandra/commitlog/CommitLog-1263013691393.log, /var/lib/cassandra/commitlog/CommitLog-1263044706108.log, /var/lib/cassandra/commitlog/CommitLog-1263060004191.log, /var/lib/cassandra/commitlog/CommitLog-1263071446342.log, /var/lib/cassandra/commitlog/CommitLog-1263082950154.log, /var/lib/cassandra/commitlog/CommitLog-1263095400814.log, /var/lib/cassandra/commitlog/CommitLog-1263118331046.log, /var/lib/cassandra/commitlog/CommitLog-1263143402963.log, /var/lib/cassandra/commitlog/CommitLog-1263155294308.log, /var/lib/cassandra/commitlog/CommitLog-1263166154352.log, /var/lib/cassandra/commitlog/CommitLog-1263178359247.log, /var/lib/cassandra/commitlog/CommitLog-1263202112017.log, /var/lib/cassandra/commitlog/CommitLog-1263230932274.log, /var/lib/cassandra/commitlog/CommitLog-1263250726505.log, /var/lib/cassandra/commitlog/CommitLog-1263264159438.log, /var/lib/cassandra/commitlog/CommitLog-1263289964249.log, /var/lib/cassandra/commitlog/CommitLog-1263317974387.log, /var/lib/cassandra/commitlog/CommitLog-1263331989090.log, /var/lib/cassandra/commitlog/CommitLog-1263344147667.log, /var/lib/cassandra/commitlog/CommitLog-1263359751527.log, /var/lib/cassandra/commitlog/CommitLog-1263395707008.log, /var/lib/cassandra/commitlog/CommitLog-1263397833524.log, /var/lib/cassandra/commitlog/CommitLog-1263398736183.log, /var/lib/cassandra/commitlog/CommitLog-1263399753707.log, /var/lib/cassandra/commitlog/CommitLog-1263401667504.log, /var/lib/cassandra/commitlog/CommitLog-1263404640782.log, /var/lib/cassandra/commitlog/CommitLog-1263405827234.log, /var/lib/cassandra/commitlog/CommitLog-1263406901115.log
INFO - LocationInfo has reached its threshold; switching in a fresh Memtable
INFO - Enqueuing flush of Memtable(LocationInfo)@25934689
INFO - HintsColumnFamily has reached its threshold; switching in a fresh Memtable
INFO - Enqueuing flush of Memtable(HintsColumnFamily)@4766820
INFO - AdXRequestStatistics has reached its threshold; switching in a fresh Memtable
INFO - Enqueuing flush of Memtable(AdXRequestStatistics)@21521158
INFO - TokenGoogleIDCF has reached its threshold; switching in a fresh Memtable
INFO - Enqueuing flush of Memtable(TokenGoogleIDCF)@22889075
java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.commons.daemon.support.DaemonLoader.load(DaemonLoader.java:160)
Caused by: java.lang.AssertionError: Blocking serialized executor is not yet implemented
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:84)
        at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:767)
        at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:658)
        at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:78)
        at org.apache.cassandra.db.ColumnFamilyStore.submitFlush(ColumnFamilyStore.java:1045)
        at org.apache.cassandra.db.ColumnFamilyStore.switchMemtable(ColumnFamilyStore.java:395)
        at org.apache.cassandra.db.ColumnFamilyStore.forceFlush(ColumnFamilyStore.java:448)
        at org.apache.cassandra.db.Table.flush(Table.java:464)
        at org.apache.cassandra.db.CommitLog.recover(CommitLog.java:397)
        at org.apache.cassandra.db.RecoveryManager.doRecovery(RecoveryManager.java:65)
        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:90)
        at org.apache.cassandra.service.CassandraDaemon.init(CassandraDaemon.java:135)
        ... 5 more

And the same exception occurs intermittently on other node (running) nodes during 'nodeprobe flush':

root@domU-12-31-38-00-26-31:~# nodeprobe -host localhost -port 8080 flush Logger
Exception in thread ""main"" java.lang.AssertionError: Blocking serialized executor is not yet implemented
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:84)
        at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:767)
        at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:658)
        at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:78)
        at org.apache.cassandra.db.ColumnFamilyStore.submitFlush(ColumnFamilyStore.java:1045)
        at org.apache.cassandra.db.ColumnFamilyStore.switchMemtable(ColumnFamilyStore.java:395)
        at org.apache.cassandra.db.ColumnFamilyStore.forceFlush(ColumnFamilyStore.java:448)
        at org.apache.cassandra.service.StorageService.forceTableFlush(StorageService.java:984)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27)
        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)
        at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:120)
        at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:262)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:836)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:761)
        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1426)
        at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:72)
        at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1264)
        at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1359)
        at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:788)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:305)
        at sun.rmi.transport.Transport$1.run(Transport.java:159)
        at java.security.AccessController.doPrivileged(Native Method)
        at sun.rmi.transport.Transport.serviceCall(Transport.java:155)
        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790)
        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)","Linux  2.6.21.7-2.fc8xen #1 SMP Fri Feb 15 12:39:36 EST 2008 i686 GNU/Linux, ec2 small instance",ryandaum,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jan/10 20:37;jbellis;694-0.5.txt;https://issues.apache.org/jira/secure/attachment/12430168/694-0.5.txt","13/Jan/10 21:09;jbellis;694-trunk.txt;https://issues.apache.org/jira/secure/attachment/12430173/694-trunk.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19823,,,Thu Jan 14 20:09:04 UTC 2010,,,,,,,,,,"0|i0g0i7:",91512,,,,,Normal,,,,,,,,,,,,,,,,,"13/Jan/10 19:19;ryandaum;Note that the error occurs with build off trunk (svn rev 898899) as well.;;;","13/Jan/10 20:37;jbellis;assumption that all single-threaded executors have an unbounded queue is no longer valid.  this patch provides a policy for dealing with single thread executors w/ a full queue.;;;","13/Jan/10 21:09;jbellis;version for trunk w/ more comments & a unit test.  will backport when i commit to 0.5.;;;","13/Jan/10 21:23;jbellis;from irc:

rdaum> that patch works
;;;","14/Jan/10 20:09;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multi-get slice failing Nullpointer Exception,CASSANDRA-689,12445261,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,lenn0x,lenn0x,12/Jan/10 06:36,16/Apr/19 09:33,14/Jul/23 05:51,13/Jan/10 19:11,0.6,,,,0,,,,,,"Noticed this in trunk

ERROR [pool-1-thread-40] 2010-01-11 22:13:55,333 Cassandra.java (line 960) Internal error processing multiget_slice
java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.NullPointerException
        at org.apache.cassandra.service.StorageProxy.weakReadLocal(StorageProxy.java:510)
        at org.apache.cassandra.service.StorageProxy.readProtocol(StorageProxy.java:375)
        at org.apache.cassandra.service.CassandraServer.readColumnFamily(CassandraServer.java:81)
        at org.apache.cassandra.service.CassandraServer.getSlice(CassandraServer.java:164)
        at org.apache.cassandra.service.CassandraServer.multigetSliceInternal(CassandraServer.java:237)
        at org.apache.cassandra.service.CassandraServer.multiget_slice(CassandraServer.java:209)
        at org.apache.cassandra.service.Cassandra$Processor$multiget_slice.process(Cassandra.java:952)
        at org.apache.cassandra.service.Cassandra$Processor.process(Cassandra.java:842)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:253)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.util.concurrent.ExecutionException: java.lang.NullPointerException
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.cassandra.service.StorageProxy.weakReadLocal(StorageProxy.java:506)
        ... 11 more
Caused by: java.lang.NullPointerException
        at org.apache.cassandra.db.filter.SliceQueryFilter.filterSuperColumn(SliceQueryFilter.java:70)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:809)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:750)
        at org.apache.cassandra.db.Table.getRow(Table.java:398)
        at org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:59)
        at org.apache.cassandra.service.StorageProxy$weakReadLocalCallable.call(StorageProxy.java:691)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        ... 3 more
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jan/10 06:28;jbellis;ASF.LICENSE.NOT.GRANTED--0001-fix-enabling-disabling-row-cache.txt;https://issues.apache.org/jira/secure/attachment/12430101/ASF.LICENSE.NOT.GRANTED--0001-fix-enabling-disabling-row-cache.txt","13/Jan/10 06:28;jbellis;ASF.LICENSE.NOT.GRANTED--0002-add-missing-gcBefore-parameter-to-removeDeleted-clone-.txt;https://issues.apache.org/jira/secure/attachment/12430102/ASF.LICENSE.NOT.GRANTED--0002-add-missing-gcBefore-parameter-to-removeDeleted-clone-.txt","13/Jan/10 06:28;jbellis;ASF.LICENSE.NOT.GRANTED--0003-fix-missing-update-of-local-deletion-time-from-a-while.txt;https://issues.apache.org/jira/secure/attachment/12430103/ASF.LICENSE.NOT.GRANTED--0003-fix-missing-update-of-local-deletion-time-from-a-while.txt",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19819,,,Thu Jan 14 12:35:00 UTC 2010,,,,,,,,,,"0|i0g0h3:",91507,,,,,Normal,,,,,,,,,,,,,,,,,"12/Jan/10 13:22;jbellis;looks like a bug I introduced w/ the mmap code.  I don't suppose you have a query that can reproduce it?;;;","12/Jan/10 22:41;jbellis;I can reproduce the problem; it's definitely from the cache patches (not mmap);;;","13/Jan/10 06:29;jbellis;03
    fix missing update of local deletion time from a while ago

02
    add missing gcBefore parameter to removeDeleted; clone SC from cache before modifying

01
    fix enabling/disabling row cache (which exposes rowcache to tests) and fix obvious NPE bugs

;;;","13/Jan/10 07:28;lenn0x;Applied to our unstable cluster, will update ticket when further testing is complete.;;;","13/Jan/10 17:36;lenn0x;+1;;;","13/Jan/10 19:11;jbellis;committed;;;","14/Jan/10 12:35;hudson;Integrated in Cassandra #323 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/323/])
    fix missing update of local deletion time introduced in #658.
patch by jbellis; reviewed by goffinet for 
add missing gcBefore parameter to removeDeleted; clone SC from cache before modifying
patch by jbellis; reviewed by goffinet for 
fix enabling/disabling row cache.
patch by jbellis; reviewed by goffinet for 
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Error deleting files during bootstrap,CASSANDRA-681,12444942,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,brandon.williams,brandon.williams,07/Jan/10 17:44,16/Apr/19 09:33,14/Jul/23 05:51,13/Jan/10 16:06,0.5,,,,0,,,,,,"I started a 3 node cluster and proceeded to bootstrap a 4th node.  On one of the existing nodes I began to see tracebacks like this:

ERROR - Error in executor futuretask
java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.io.IOException: Unable to delete /mnt/drive3/data/Keyspace1/stream/Standard1-158-Index.db after 10 tries
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)
        at java.util.concurrent.FutureTask.get(FutureTask.java:111)
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:53)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1118)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
Caused by: java.lang.RuntimeException: java.io.IOException: Unable to delete /mnt/drive3/data/Keyspace1/stream/Standard1-158-Index.db after 10 tries
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:13)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
        at java.util.concurrent.FutureTask.run(FutureTask.java:166)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        ... 2 more
Caused by: java.io.IOException: Unable to delete /mnt/drive3/data/Keyspace1/stream/Standard1-158-Index.db after 10 tries
        at org.apache.cassandra.io.DeletionService$2.runMayThrow(DeletionService.java:45)
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:9)
        ... 6 more

For various data, index, and filter files.","debian lenny amd64 OpenJDK 64-Bit Server VM (build 1.6.0_0-b11, mixed mode)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jan/10 20:55;jbellis;681.patch;https://issues.apache.org/jira/secure/attachment/12430045/681.patch",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19816,,,Wed Jan 13 16:06:47 UTC 2010,,,,,,,,,,"0|i0g0fb:",91499,,,,,Low,,,,,,,,,,,,,,,,,"08/Jan/10 17:06;brandon.williams;I also received this while testing CASSANDRA-680, so it is not limited to bootstrap.;;;","11/Jan/10 20:00;jbellis;were there any other errors (like the ones in CASSANDRA-657) in the logs?;;;","12/Jan/10 20:55;jbellis;it looks like the problem was that Streaming.transferSSTables and StreamManager.finish were both attempting to delete the streamed file.  this patch removes the one from transferSSTables.;;;","12/Jan/10 23:06;brandon.williams;+1, error no longer appears;;;","13/Jan/10 16:06;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
hinted handoff reads all hints for a single keyspace into memory,CASSANDRA-680,12444868,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,07/Jan/10 05:12,16/Apr/19 09:33,14/Jul/23 05:51,09/Jan/10 19:03,0.6,,,,0,,,,,,Need to add paging to HHOM.deliverAllHints,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jan/10 20:37;jbellis;ASF.LICENSE.NOT.GRANTED--0001-add-hint-delivery-paging.txt;https://issues.apache.org/jira/secure/attachment/12429671/ASF.LICENSE.NOT.GRANTED--0001-add-hint-delivery-paging.txt","07/Jan/10 20:37;jbellis;ASF.LICENSE.NOT.GRANTED--0002-cleanup-of-HHOM.txt;https://issues.apache.org/jira/secure/attachment/12429672/ASF.LICENSE.NOT.GRANTED--0002-cleanup-of-HHOM.txt",,,,,,,,,,,,,2.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19815,,,Sat Jan 09 19:03:04 UTC 2010,,,,,,,,,,"0|i0g0f3:",91498,,,,,Low,,,,,,,,,,,,,,,,,"08/Jan/10 02:03;brandon.williams;+1, this works.  The nodes keep going, but eventually run into CASSANDRA-16 when the hints family is compacted.;;;","08/Jan/10 18:25;stuhood;Jonathan: I'm not exactly sure what the rules are, but I think when you attach patches that you intend to commit, you should check the 'Grant license to ASF' radio button to make everything kosher legally.;;;","08/Jan/10 18:35;jbellis;Even the ASF understands that when I commit a patch I wrote myself, I'm giving them permission to use the code even if I didn't check a box in Jira.  (Seriously.);;;","09/Jan/10 12:35;hudson;Integrated in Cassandra #318 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/318/])
    cleanup of HHOM.  patch by jbellis; tested by Brandon Williams for .
add hint delivery paging.  patch by jbellis; tested by Brandon Williams for 
;;;","09/Jan/10 19:03;jbellis;committed;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cassandra-cli doesn't allow hyphens in hostnames,CASSANDRA-677,12444836,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,rschildmeijer,urandom,urandom,06/Jan/10 20:40,16/Apr/19 09:33,14/Jul/23 05:51,24/Mar/10 18:43,0.6,,Legacy/Tools,,2,,,,,,"It's not possible to use a hostname that contains a hyphen with the ""connect"" command interactively, (the parser does not accept hostnames that contain hyphens).

Note: It is still possible to connect to such hosts by passing it on the command line using -host.",Any,rschildmeijer,,,,,,,,,,,,,,,,,,,,CASSANDRA-914,,,,,,,,"18/Jan/10 20:08;rschildmeijer;CASSANDRA-677.patch;https://issues.apache.org/jira/secure/attachment/12430667/CASSANDRA-677.patch","17/Jan/10 16:13;rschildmeijer;CASSANDRA-677.patch;https://issues.apache.org/jira/secure/attachment/12430560/CASSANDRA-677.patch",,,,,,,,,,,,,2.0,rschildmeijer,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19814,,,Wed Mar 24 18:43:17 UTC 2010,,,,,,,,,,"0|i0g0ef:",91495,,,,,Low,,,,,,,,,,,,,,,,,"18/Jan/10 17:00;urandom;Thanks Roger. But I'm afraid this won't work for a couple of reasons.

1. Because `Identifier' is used for column family names, it permits the use of hyphens there, which as things currently stand will cause problems (hint: on disk, CFs use hypen delimited filenames).

2. Something other than `Identifier' should be used since that would allow underscores in hostnames, which should not be permitted.;;;","18/Jan/10 20:07;rschildmeijer;Improvements made after Eric's comment about the previous patch (Identifier is now left untouched).;;;","19/Jan/10 22:52;urandom;Sorry Roger, I did some quick testing and this patch seem to have issues as well. It does allow hyphens in hostnames, but only when there are no numbers involved.

cassandra> connect cass-1.lab/9160
line 1:13 mismatched input '1' expecting Identifier
Exception Cannot open null host.;;;","24/Mar/10 18:43;urandom;This has been applied. See CASSANDRA-914 for some additional background.

Thanks Roger.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bootstrapping does not work properly using multiple key space,CASSANDRA-673,12444764,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jaakko,steel_mental,steel_mental,06/Jan/10 03:14,16/Apr/19 09:33,14/Jul/23 05:51,18/Jan/10 18:35,0.5,,,,0,,,,,,"when use multiple key-spaces, and one key-space has no SSTable, then bootstrap may not work right.
Say nodes A, B, C, D have key spaces ""KS1"" and ""KS2"", KS1 is empty, now add empty node E into cluster.
Suppose E decide to drag data from A and B(bootstrap source), E will send range to A and B, and A, B will scan all key-spaces they got and send ack to E, which contains list of key-space name(StreamContextManager.StreamContext),
when E get ack from A and B, it scan this list, but when encounter first empty key-space, it will stop and remove node from bootstrap sources list:

StreamInitiateVerbHandler.doVerb:
......
                if (streamContexts.length == 0 && StorageService.instance().isBootstrapMode())
                {
                    if (logger.isDebugEnabled())
                        logger.debug(""no data needed from "" + message.getFrom());
                    StorageService.instance().removeBootstrapSource(message.getFrom());
                    return;
                }
......
If list of bootstrap sources is empty, E will finish bootstrapping

So, the result is: E get nothing from source A, B, even KS2 has lots of data.
","1.	cluster has at least one empty key-space
2.	one node be added into cluster to do bootstrap
",johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jan/10 20:21;gdusbabek;0001-keep-track-of-table-and-node-while-bootstrapping.patch;https://issues.apache.org/jira/secure/attachment/12430290/0001-keep-track-of-table-and-node-while-bootstrapping.patch","15/Jan/10 14:05;gdusbabek;0002-do-not-include-system-tables-when-setting-bootstrap-.patch;https://issues.apache.org/jira/secure/attachment/12430402/0002-do-not-include-system-tables-when-setting-bootstrap-.patch",,,,,,,,,,,,,2.0,jaakko,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19813,,,Mon Jan 18 18:35:15 UTC 2010,,,,,,,,,,"0|i0g0dr:",91492,,,,,Low,,,,,,,,,,,,,,,,,"14/Jan/10 20:21;gdusbabek;Tracks bootstrap sources on a node+table basis. Puts the table name as a message header for the case when there are no stream contexts to extract it from.;;;","14/Jan/10 20:21;gdusbabek;I decided I'd like to patch this one up to make rebasing whatever fix into my 620 changes less of a headache.;;;","15/Jan/10 13:25;jaakko;System table should probably not be included in the transfer?
;;;","15/Jan/10 13:31;gdusbabek;Good catch.  I'll put together another patch.;;;","16/Jan/10 07:52;jaakko;+1;;;","18/Jan/10 18:35;gdusbabek;r900469 (0.5)
r900499 (trunk);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Handle mmapping index files greater than 2GB,CASSANDRA-669,12444719,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,05/Jan/10 15:57,16/Apr/19 09:33,14/Jul/23 05:51,07/Jan/10 02:58,0.6,,,,0,,,,,,"""Who would ever have an index file larger than 2GB?"" I thought.  Turns out it's not that hard with narrow rows... :)",,brandon.williams,hammer,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jan/10 21:43;jbellis;ASF.LICENSE.NOT.GRANTED--0001-store-data-information-for-any-index-entries-spanning-.txt;https://issues.apache.org/jira/secure/attachment/12429581/ASF.LICENSE.NOT.GRANTED--0001-store-data-information-for-any-index-entries-spanning-.txt","06/Jan/10 21:43;jbellis;ASF.LICENSE.NOT.GRANTED--0002-add-support-for-multiple-mmapped-index-segments-and-ad.txt;https://issues.apache.org/jira/secure/attachment/12429582/ASF.LICENSE.NOT.GRANTED--0002-add-support-for-multiple-mmapped-index-segments-and-ad.txt","06/Jan/10 21:43;jbellis;ASF.LICENSE.NOT.GRANTED--0003-instead-of-providing-a-RandomAccessFile-like-interface.txt;https://issues.apache.org/jira/secure/attachment/12429583/ASF.LICENSE.NOT.GRANTED--0003-instead-of-providing-a-RandomAccessFile-like-interface.txt",,,,,,,,,,,,3.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19811,,,Fri Jan 08 12:38:35 UTC 2010,,,,,,,,,,"0|i0g0cv:",91488,,,,,Normal,,,,,,,,,,,,,,,,,"05/Jan/10 21:14;jbellis;02
    add support for multiple mmapped index segments, and add mmap_index_only option

01
    store data information for any index entries spanning a mmap segment boundary when reading the index (with a BufferedRAF)
;;;","05/Jan/10 23:21;brandon.williams;Received the following traceback after testing (during compaction):

ERROR - Error in executor futuretask
java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Negative position
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)
        at java.util.concurrent.FutureTask.get(FutureTask.java:111)
        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.afterExecute(DebuggableThreadPoolExecutor.java:53)
        at org.apache.cassandra.db.CompactionManager$CompactionExecutor.afterExecute(CompactionManager.java:591)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1118)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:636)
Caused by: java.lang.IllegalArgumentException: Negative position
        at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:739)
        at org.apache.cassandra.io.SSTableReader.mmap(SSTableReader.java:273)
        at org.apache.cassandra.io.SSTableReader.<init>(SSTableReader.java:234)
        at org.apache.cassandra.io.SSTableWriter.closeAndOpenReader(SSTableWriter.java:157)
        at org.apache.cassandra.db.CompactionManager.doCompaction(CompactionManager.java:307)
        at org.apache.cassandra.db.CompactionManager$1.call(CompactionManager.java:102)
        at org.apache.cassandra.db.CompactionManager$1.call(CompactionManager.java:83)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
        at java.util.concurrent.FutureTask.run(FutureTask.java:166)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
;;;","06/Jan/10 03:54;jbellis;heh, that's actually a 2nd bug.  patch 03 attached to fix.;;;","06/Jan/10 05:02;jbellis;fix the -- in the xml in 02, and change BUFFER_SIZE to long in 03 as well to force the promotion of the position parameter.;;;","06/Jan/10 15:35;brandon.williams;+1;;;","06/Jan/10 16:07;brandon.williams;Oops, nevermind my +1, receiving the following traceback when trying to get_slice now:

Caused by: java.lang.AssertionError
        at org.apache.cassandra.io.util.MappedFileDataInput.length(MappedFileDataInput.java:36)
        at org.apache.cassandra.io.util.MappedFileDataInput.read(MappedFileDataInput.java:52)
        at java.io.InputStream.read(InputStream.java:171)
        at org.apache.cassandra.io.util.MappedFileDataInput.readUnsignedShort(MappedFileDataInput.java:358)
        at java.io.DataInputStream.readUTF(DataInputStream.java:589)
        at org.apache.cassandra.io.util.MappedFileDataInput.readUTF(MappedFileDataInput.java:381)
        at org.apache.cassandra.io.SSTableReader.getPosition(SSTableReader.java:419)
        at org.apache.cassandra.io.SSTableReader.getFileDataInput(SSTableReader.java:537)
        at org.apache.cassandra.db.filter.SSTableSliceIterator.<init>(SSTableSliceIterator.java:54)
        at org.apache.cassandra.db.filter.SliceQueryFilter.getSSTableColumnIterator(SliceQueryFilter.java:63)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamilyInternal(ColumnFamilyStore.java:859)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:817)
        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:786)
        at org.apache.cassandra.db.Table.getRow(Table.java:405)
        at org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:59)
        at org.apache.cassandra.service.StorageProxy$weakReadLocalCallable.call(StorageProxy.java:692)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
        at java.util.concurrent.FutureTask.run(FutureTask.java:166)
        ... 3 more
;;;","06/Jan/10 17:24;jbellis;patch 04 to fix.;;;","06/Jan/10 21:44;jbellis;... latest patches fix the fd leak and index reading bugs, and rebased bugfixes into 01 and 02.;;;","07/Jan/10 02:50;brandon.williams;+1, for real this time.  40M narrow keys used to create a 2.2GB index when fully compacted, all is well.;;;","07/Jan/10 02:58;jbellis;committed;;;","07/Jan/10 13:08;hudson;Integrated in Cassandra #316 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/316/])
    instead of providing a RandomAccessFile-like interface in FileDataInput implementing seek and trying to keep people from shooting themselves in the foot by forgetting that it may only represent a 2GB segment of a larger file, provide an InputStream-like interface emphasizing mark/reset
patch by jbellis; tested by Brandon Williams for 
add support for multiple mmapped index segments, and add mmap_index_only option
patch by jbellis; tested by Brandon Williams for 
store data information for any index entries spanning a mmap segment boundary when reading the index (with a BufferedRAF) so we don't have to deal with that at read time.
patch by jbellis; tested by Brandon Williams for 
;;;","08/Jan/10 12:38;hudson;Integrated in Cassandra #317 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/317/])
    fix bad rebase causing regression in the  patchset (use index path to open index file).  patch by jbellis
;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
long commitlog syncs can cause write pauses,CASSANDRA-668,12444649,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Low,Fixed,jbellis,jbellis,jbellis,05/Jan/10 02:29,16/Apr/19 09:33,14/Jul/23 05:51,05/Jan/10 17:32,0.5,,,,0,,,,,,"on a heavily loaded system (deliberately exacerbated by running the bonnie++ i/o benchmarking tool at the same time as cassandra -- which might not be too far off from the environment you would see on some VPS hosts), we're seeing CL sync times of 1-5s, causing write pauses.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jan/10 02:37;jbellis;668.patch;https://issues.apache.org/jira/secure/attachment/12429410/668.patch",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19810,,,Tue Jan 05 17:32:49 UTC 2010,,,,,,,,,,"0|i0g0cn:",91487,,,,,Low,,,,,,,,,,,,,,,,,"05/Jan/10 02:37;jbellis;increase default sync period, and wait for last sync to finish before submitting another;;;","05/Jan/10 17:15;brandon.williams;+1, no more write pauses with bonnie++ running.;;;","05/Jan/10 17:18;jbellis;There's still some mystery here, because the commitlog was on a separate device + xfs filesystem, so syncing that shouldn't have to wait for IO from the data filesystem.  But short term this patch is better than nothing.;;;","05/Jan/10 17:19;jbellis;(committed patch to 0.5 and trunk);;;","05/Jan/10 17:29;jbellis;(un-tagging 0.5 since any further work almost certainly won't be backported there);;;","05/Jan/10 17:32;jbellis;(actually I think the best thing to do is tag this 0.5 and resolve it, and create a new issue for further investigation);;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Abort bootstrap if our IP is already in the token ring,CASSANDRA-663,12444552,Bug,Resolved,CASSANDRA,Cassandra,software,mck,"<p>The Cassandra Project is a distributed storage system for managing structured/unstructured data while providing reliability at a massive scale.</p>
<br/>
<p>Please request the <b>creation of a jira account</b> on either the <a href=""https://cassandra.apache.org/_/community.html#discussions"">dev@cassandra.apache.org</a> mailing list or the ASF slack channel <a href=""https://cassandra.apache.org/_/community.html#discussions"">#cassandra-dev</a></p>",http://cassandra.apache.org/,Normal,Fixed,jbellis,jbellis,jbellis,04/Jan/10 01:31,16/Apr/19 09:33,14/Jul/23 05:51,05/Jan/10 17:16,0.5,,,,0,,,,,,Trying to bootstrap a node w/ the same IP as one that is Down but not removed from the ring should give an error.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/10 17:07;jbellis;663.txt;https://issues.apache.org/jira/secure/attachment/12429355/663.txt",,,,,,,,,,,,,,1.0,jbellis,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,19809,,,Tue Jan 05 17:11:50 UTC 2010,,,,,,,,,,"0|i0g0bj:",91482,,,,,Normal,,,,,,,,,,,,,,,,,"04/Jan/10 17:12;urandom;+1;;;","04/Jan/10 23:32;jaakko;IMHO this check should be done before starting the bootstrap process (immediately after ""... got load info""). At that point we've already slept for RING_DELAY, so waiting for another RING_DELAY in startBootstrap is probably not useful. If we do the check at its current place, we've already started to gossip our bootsrap token, which will cause the other rightful IP owner to be removed from token metadata.
;;;","04/Jan/10 23:46;jbellis;I'd like to have this as a sanity check on all move operations, not just the initial bootstrap.  What about putting the check at the beginning of SS.startBootstrap?;;;","05/Jan/10 00:52;jaakko;As long as it is before gossip, it does not make so big difference.

However, I don't know what this check would achieve in a move operation. If the node is up and running in order to do a move operation, it must be in token metadata as well. Move does not change IP address, so this check for duplicate IP address is relevant only in first bootstrap.
;;;","05/Jan/10 17:11;jbellis;you're right,  this makes the most sense after ""got load info.""  committed with that change.;;;",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
